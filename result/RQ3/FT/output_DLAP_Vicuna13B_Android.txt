Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_get_buf_info(iv_obj_t *ps_dechdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 dec_state_t *ps_dec_state;
 dec_state_multi_core_t *ps_dec_state_multi_core;
 impeg2d_ctl_getbufinfo_ip_t *ps_ctl_bufinfo_ip =
 (impeg2d_ctl_getbufinfo_ip_t *)pv_api_ip;
 impeg2d_ctl_getbufinfo_op_t *ps_ctl_bufinfo_op =
 (impeg2d_ctl_getbufinfo_op_t *)pv_api_op;
    UWORD32 u4_i, u4_stride, u4_height;
    UNUSED(ps_ctl_bufinfo_ip);

    ps_dec_state_multi_core =
 (dec_state_multi_core_t *)(ps_dechdl->pv_codec_handle);
    ps_dec_state = ps_dec_state_multi_core->ps_dec_state[0];

    ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_in_bufs = 1;
    ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_out_bufs = 1;

 if(ps_dec_state->i4_chromaFormat == IV_YUV_420P)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_out_bufs =
                        MIN_OUT_BUFS_420;
 }
 else if((ps_dec_state->i4_chromaFormat == IV_YUV_420SP_UV)
 || (ps_dec_state->i4_chromaFormat == IV_YUV_420SP_VU))
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_out_bufs =
                        MIN_OUT_BUFS_420SP;
 }
 else if(ps_dec_state->i4_chromaFormat == IV_YUV_422ILE)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_out_bufs =
                        MIN_OUT_BUFS_422ILE;
 }
 else if(ps_dec_state->i4_chromaFormat == IV_RGB_565)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_out_bufs =
                        MIN_OUT_BUFS_RGB565;
 }
 else
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code =
                        IVD_INIT_DEC_COL_FMT_NOT_SUPPORTED;
 return IV_FAIL;
 }

 for(u4_i = 0; u4_i < IVD_VIDDEC_MAX_IO_BUFFERS; u4_i++)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_in_buf_size[u4_i] =
 0;
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[u4_i] =
 0;
 }

 for(u4_i = 0;
        u4_i < ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_num_in_bufs;
        u4_i++)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_in_buf_size[u4_i] =
                        MAX_BITSTREAM_BUFFER_SIZE;
 }

 if (0 == ps_dec_state->u4_frm_buf_stride)
 {
 if (1 == ps_dec_state->u2_header_done)
 {
            u4_stride   = ps_dec_state->u2_horizontal_size;
 }
 else
 {
            u4_stride   = ps_dec_state->u2_create_max_width;
 }
 }
 else
 {
        u4_stride = ps_dec_state->u4_frm_buf_stride;
 }
    u4_height = ((ps_dec_state->u2_frame_height + 15) >> 4) << 4;

 if(ps_dec_state->i4_chromaFormat == IV_YUV_420P)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[0] =
 (u4_stride * u4_height);
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[1] =
 (u4_stride * u4_height) >> 2;
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[2] =
 (u4_stride * u4_height) >> 2;
 }
 else if((ps_dec_state->i4_chromaFormat == IV_YUV_420SP_UV)
 || (ps_dec_state->i4_chromaFormat == IV_YUV_420SP_VU))
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[0] =
 (u4_stride * u4_height);
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[1] =
 (u4_stride * u4_height) >> 1;
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[2] = 0;
 }
 else if(ps_dec_state->i4_chromaFormat == IV_YUV_422ILE)
 {
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[0] =
 (u4_stride * u4_height) * 2;
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[1] =
                        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_min_out_buf_size[2] =
 0;
 }

 /* Adding initialization for 2 uninitialized values */
    ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_num_disp_bufs = 1;
 if(ps_dec_state->u4_share_disp_buf)
        ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_num_disp_bufs =
                        NUM_INT_FRAME_BUFFERS;
    ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_size = MAX_FRM_SIZE;

    ps_ctl_bufinfo_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code = IV_SUCCESS;

 return (IV_SUCCESS);
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: CuePoint::~CuePoint()
{
    delete[] m_track_positions;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::sendCacheStats() {
 int32_t kbps = 0;
 status_t err = UNKNOWN_ERROR;

 if (mWVMExtractor != NULL) {
        err = mWVMExtractor->getEstimatedBandwidthKbps(&kbps);
 } else if (mCachedSource != NULL) {
        err = mCachedSource->getEstimatedBandwidthKbps(&kbps);
 }

 if (err == OK) {
        sp<AMessage> notify = dupNotify();
        notify->setInt32("what", kWhatCacheStats);
        notify->setInt32("bandwidth", kbps);
        notify->post();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline void close_cmd_fd(int h)
{
 if(ts[h].cmd_fdr != -1)
 {
        close(ts[h].cmd_fdr);
        ts[h].cmd_fdr = -1;
 }
 if(ts[h].cmd_fdw != -1)
 {
        close(ts[h].cmd_fdw);
        ts[h].cmd_fdw = -1;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraDeviceClient::notifyError() {
    sp<ICameraDeviceCallbacks> remoteCb = getRemoteCallback();

 if (remoteCb != 0) {
        remoteCb->onDeviceError(ICameraDeviceCallbacks::ERROR_CAMERA_DEVICE);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char packet_put_head_l(l2cap_socket *sock, const void *data, uint32_t len)
{
 struct packet *p = packet_alloc((const uint8_t*)data, len);

 /*
     * We do not check size limits here since this is used to undo "getting" a
     * packet that the user read incompletely. That is to say the packet was
     * already in the queue. We do check thos elimits in packet_put_tail_l() since
     * that function is used to put new data into the queue.
     */

 if (!p)
 return FALSE;

    p->prev = NULL;
    p->next = sock->first_packet;
    sock->first_packet = p;
 if (p->next)
        p->next->prev = p;
 else
        sock->last_packet = p;

    sock->bytes_buffered += len;

 return TRUE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool parse_args(int argc, char **argv) {
 while (1) {
 int option_index = 0;
 int c = getopt_long_only(argc, argv, "", long_options, &option_index);
 if (c != 0)
 break;

 switch (c) {
 case 0:
 if (option_index == 0) {
 if (!string_to_bdaddr(optarg, &bt_remote_bdaddr)) {
 return false;
 }
 }
 if (option_index == 1) {
          discover = true;
 }
 if (option_index == 2) {
          discoverable = true;
 }
 if (option_index == 3) {
          timeout_in_sec = atoi(optarg);
 }
 if (option_index == 4) {
          bond  = true;
 }
 if (option_index == 5) {
          up = true;
 }
 if (option_index == 6) {
          f_verbose++;
 }
 if (option_index == 7) {
          get_name = true;
 }
 if (option_index == 8) {
          bd_name = (char *)optarg;
          set_name = true;
 }
 if (option_index == 9) {
          sco_listen = true;
 }
 if (option_index == 10) {
          sco_connect = true;
 }
 break;

 default:
        fprintf(stderr, "?? getopt returned character code 0%o ??\n", c);
 }
 }

 if (optind < argc) {
    fprintf(stderr, "non-option ARGV-elements: ");
 while (optind < argc)
      fprintf(stderr, "%s ", argv[optind++]);
    fprintf(stderr, "\n");
 return false;
 }
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleTable::setTimeToSampleParams(
 off64_t data_offset, size_t data_size) {
 if (mTimeToSample != NULL || data_size < 8) {
 return ERROR_MALFORMED;
 }

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;

     }
 
     mTimeToSampleCount = U32_AT(&header[4]);
    uint64_t allocSize = mTimeToSampleCount * 2 * sizeof(uint32_t);
     if (allocSize > SIZE_MAX) {
         return ERROR_OUT_OF_RANGE;
     }
    mTimeToSample = new uint32_t[mTimeToSampleCount * 2];

 size_t size = sizeof(uint32_t) * mTimeToSampleCount * 2;
 if (mDataSource->readAt(
                data_offset + 8, mTimeToSample, size) < (ssize_t)size) {
 return ERROR_IO;
 }

 for (uint32_t i = 0; i < mTimeToSampleCount * 2; ++i) {
        mTimeToSample[i] = ntohl(mTimeToSample[i]);
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SeekHead::~SeekHead() {
 delete[] m_entries;
 delete[] m_void_elements;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual ssize_t decrypt(
 bool secure,
 const uint8_t key[16],
 const uint8_t iv[16],
 CryptoPlugin::Mode mode,
 const sp<IMemory> &sharedBuffer, size_t offset,
 const CryptoPlugin::SubSample *subSamples, size_t numSubSamples,
 void *dstPtr,
 AString *errorDetailMsg) {
 Parcel data, reply;
        data.writeInterfaceToken(ICrypto::getInterfaceDescriptor());
        data.writeInt32(secure);
        data.writeInt32(mode);

 static const uint8_t kDummy[16] = { 0 };

 if (key == NULL) {
            key = kDummy;
 }

 if (iv == NULL) {
            iv = kDummy;
 }

        data.write(key, 16);
        data.write(iv, 16);

 size_t totalSize = 0;
 for (size_t i = 0; i < numSubSamples; ++i) {
            totalSize += subSamples[i].mNumBytesOfEncryptedData;
            totalSize += subSamples[i].mNumBytesOfClearData;
 }

        data.writeInt32(totalSize);
        data.writeStrongBinder(IInterface::asBinder(sharedBuffer));
        data.writeInt32(offset);

        data.writeInt32(numSubSamples);
        data.write(subSamples, sizeof(CryptoPlugin::SubSample) * numSubSamples);

 if (secure) {
            data.writeInt64(static_cast<uint64_t>(reinterpret_cast<uintptr_t>(dstPtr)));
 }

        remote()->transact(DECRYPT, data, &reply);

 ssize_t result = reply.readInt32();

 if (isCryptoError(result)) {
            errorDetailMsg->setTo(reply.readCString());
 }

 if (!secure && result >= 0) {
            reply.read(dstPtr, result);
 }

 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_dm_get_remote_service_record(bt_bdaddr_t *remote_addr,
 bt_uuid_t *uuid)
{
    tSDP_UUID sdp_uuid;
 bdstr_t bdstr;

    BTIF_TRACE_EVENT("%s: remote_addr=%s", __FUNCTION__, bdaddr_to_string(remote_addr, bdstr, sizeof(bdstr)));

    sdp_uuid.len = MAX_UUID_SIZE;
    memcpy(sdp_uuid.uu.uuid128, uuid->uu, MAX_UUID_SIZE);

    BTA_DmDiscoverUUID(remote_addr->address, &sdp_uuid,
                       bte_dm_remote_service_record_evt, TRUE);

 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API FLAC__bool FLAC__stream_decoder_set_ogg_serial_number(FLAC__StreamDecoder *decoder, long value)
{
	FLAC__ASSERT(0 != decoder);
	FLAC__ASSERT(0 != decoder->private_);
	FLAC__ASSERT(0 != decoder->protected_);
 if(decoder->protected_->state != FLAC__STREAM_DECODER_UNINITIALIZED)
 return false;
#if FLAC__HAS_OGG
 /* can't check decoder->private_->is_ogg since that's not set until init time */
	FLAC__ogg_decoder_aspect_set_serial_number(&decoder->protected_->ogg_decoder_aspect, value);
 return true;
#else
 (void)value;
 return false;
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_av_rc_opened(tBTA_AV_CB* p_cb, tBTA_AV_DATA* p_data) {
  tBTA_AV_RC_OPEN rc_open;
  tBTA_AV_SCB* p_scb;
 int i;
 uint8_t shdl = 0;
  tBTA_AV_LCB* p_lcb;
  tBTA_AV_RCB* p_rcb;
 uint8_t tmp;
 uint8_t disc = 0;

 /* find the SCB & stop the timer */
 for (i = 0; i < BTA_AV_NUM_STRS; i++) {
    p_scb = p_cb->p_scb[i];
 if (p_scb && p_scb->PeerAddress() == p_data->rc_conn_chg.peer_addr) {
      p_scb->rc_handle = p_data->rc_conn_chg.handle;
      APPL_TRACE_DEBUG("%s: shdl:%d, srch %d", __func__, i + 1,
                       p_scb->rc_handle);
      shdl = i + 1;
      LOG_INFO(LOG_TAG, "%s: allow incoming AVRCP connections:%d", __func__,
               p_scb->use_rc);
      alarm_cancel(p_scb->avrc_ct_timer);
      disc = p_scb->hndl;
 break;
 }
 }

  i = p_data->rc_conn_chg.handle;
 if (p_cb->rcb[i].handle == BTA_AV_RC_HANDLE_NONE) {
    APPL_TRACE_ERROR("%s: not a valid handle:%d any more", __func__, i);
 return;
 }

  APPL_TRACE_DEBUG("%s: local features %d peer features %d", __func__,
                   p_cb->features, p_cb->rcb[i].peer_features);

 /* listen to browsing channel when the connection is open,
   * if peer initiated AVRCP connection and local device supports browsing
   * channel */
  AVRC_OpenBrowse(p_data->rc_conn_chg.handle, AVCT_ACP);

 if (p_cb->rcb[i].lidx == (BTA_AV_NUM_LINKS + 1) && shdl != 0) {
 /* rc is opened on the RC only ACP channel, but is for a specific
     * SCB -> need to switch RCBs */
    p_rcb = bta_av_get_rcb_by_shdl(shdl);
 if (p_rcb) {
      p_rcb->shdl = p_cb->rcb[i].shdl;
      tmp = p_rcb->lidx;
      p_rcb->lidx = p_cb->rcb[i].lidx;
      p_cb->rcb[i].lidx = tmp;
      p_cb->rc_acp_handle = p_rcb->handle;
      p_cb->rc_acp_idx = (p_rcb - p_cb->rcb) + 1;
      APPL_TRACE_DEBUG("%s: switching RCB rc_acp_handle:%d idx:%d", __func__,
                       p_cb->rc_acp_handle, p_cb->rc_acp_idx);
 }
 }

  p_cb->rcb[i].shdl = shdl;
  rc_open.rc_handle = i;
  APPL_TRACE_ERROR("%s: rcb[%d] shdl:%d lidx:%d/%d", __func__, i, shdl,
                   p_cb->rcb[i].lidx, p_cb->lcb[BTA_AV_NUM_LINKS].lidx);
  p_cb->rcb[i].status |= BTA_AV_RC_CONN_MASK;

 if (!shdl && 0 == p_cb->lcb[BTA_AV_NUM_LINKS].lidx) {
 /* no associated SCB -> connected to an RC only device
     * update the index to the extra LCB */
    p_lcb = &p_cb->lcb[BTA_AV_NUM_LINKS];
    p_lcb->addr = p_data->rc_conn_chg.peer_addr;
    p_lcb->lidx = BTA_AV_NUM_LINKS + 1;
    p_cb->rcb[i].lidx = p_lcb->lidx;
    p_lcb->conn_msk = 1;
    APPL_TRACE_ERROR("%s: bd_addr: %s rcb[%d].lidx=%d, lcb.conn_msk=x%x",
                     __func__, p_lcb->addr.ToString().c_str(), i,
                     p_cb->rcb[i].lidx, p_lcb->conn_msk);
    disc = p_data->rc_conn_chg.handle | BTA_AV_CHNL_MSK;
 }

  rc_open.peer_addr = p_data->rc_conn_chg.peer_addr;
  rc_open.peer_features = p_cb->rcb[i].peer_features;
  rc_open.status = BTA_AV_SUCCESS;
  APPL_TRACE_DEBUG("%s: local features:x%x peer_features:x%x", __func__,
                   p_cb->features, rc_open.peer_features);
 if (rc_open.peer_features == 0) {
 /* we have not done SDP on peer RC capabilities.
     * peer must have initiated the RC connection */
 if (p_cb->features & BTA_AV_FEAT_RCCT)
      rc_open.peer_features |= BTA_AV_FEAT_RCTG;
 if (p_cb->features & BTA_AV_FEAT_RCTG)
      rc_open.peer_features |= BTA_AV_FEAT_RCCT;

    bta_av_rc_disc(disc);
 }
  tBTA_AV bta_av_data;
  bta_av_data.rc_open = rc_open;
 (*p_cb->p_cback)(BTA_AV_RC_OPEN_EVT, &bta_av_data);

 /* if local initiated AVRCP connection and both peer and locals device support
   * browsing channel, open the browsing channel now
   * TODO (sanketa): Some TG would not broadcast browse feature hence check
   * inter-op. */
 if ((p_cb->features & BTA_AV_FEAT_BROWSE) &&
 (rc_open.peer_features & BTA_AV_FEAT_BROWSE) &&
 ((p_cb->rcb[i].status & BTA_AV_RC_ROLE_MASK) == BTA_AV_RC_ROLE_INT)) {
    APPL_TRACE_DEBUG("%s: opening AVRC Browse channel", __func__);
    AVRC_OpenBrowse(p_data->rc_conn_chg.handle, AVCT_INT);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char *get_camera_metadata_section_name(uint32_t tag) {
 uint32_t tag_section = tag >> 16;
 if (tag_section >= VENDOR_SECTION && vendor_tag_ops != NULL) {
 return vendor_tag_ops->get_section_name(
            vendor_tag_ops,
            tag);
 }
 if (tag_section >= ANDROID_SECTION_COUNT) {
 return NULL;
 }
 return camera_metadata_section_names[tag_section];
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftOpus::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamAudioAndroidOpus:
 {

             OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *opusParams =
                 (OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *)params;
 
             if (opusParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            opusParams->nAudioBandWidth = 0;
            opusParams->nSampleRate = kRate;
            opusParams->nBitRate = 0;

 if (!isConfigured()) {
                opusParams->nChannels = 1;
 } else {
                opusParams->nChannels = mHeader->channels;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;
            pcmParams->nSamplingRate = kRate;

 if (!isConfigured()) {
                pcmParams->nChannels = 1;
 } else {
                pcmParams->nChannels = mHeader->channels;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::CreateSimpleBlock(long long st, long long sz) {
  assert(m_entries);
  assert(m_entries_size > 0);
  assert(m_entries_count >= 0);
  assert(m_entries_count < m_entries_size);

 const long idx = m_entries_count;

 BlockEntry** const ppEntry = m_entries + idx;
 BlockEntry*& pEntry = *ppEntry;

  pEntry = new (std::nothrow) SimpleBlock(this, idx, st, sz);

 if (pEntry == NULL)
 return -1; // generic error

 SimpleBlock* const p = static_cast<SimpleBlock*>(pEntry);

 const long status = p->Parse();

 if (status == 0) {
 ++m_entries_count;
 return 0;
 }

 delete pEntry;
  pEntry = 0;

 return status;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static jboolean android_net_wifi_set_log_handler(JNIEnv *env, jclass cls, jint iface, jint id) {

 JNIHelper helper(env);
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);
    ALOGD("android_net_wifi_set_log_handler = %p", handle);

    wifi_ring_buffer_data_handler handler;
    handler.on_ring_buffer_data = &on_ring_buffer_data;
 int result = hal_fn.wifi_set_log_handler(id, handle, handler);
 if (result != WIFI_SUCCESS) {
        ALOGE("Fail to set logging handler");
 return false;
 }

    wifi_alert_handler alert_handler;
    alert_handler.on_alert = &on_alert_data;
    result = hal_fn.wifi_set_alert_handler(id, handle, alert_handler);
 if (result != WIFI_SUCCESS) {
        ALOGE(" Fail to set alert handler");
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void wait_worker_and_cache_frame(vpx_codec_alg_priv_t *ctx) {
  YV12_BUFFER_CONFIG sd;
 vp9_ppflags_t flags = {0, 0, 0};
 const VPxWorkerInterface *const winterface = vpx_get_worker_interface();
 VPxWorker *const worker = &ctx->frame_workers[ctx->next_output_worker_id];
 FrameWorkerData *const frame_worker_data = (FrameWorkerData *)worker->data1;
  ctx->next_output_worker_id =
 (ctx->next_output_worker_id + 1) % ctx->num_frame_workers;
  winterface->sync(worker);
  frame_worker_data->received_frame = 0;
 ++ctx->available_threads;

  check_resync(ctx, frame_worker_data->pbi);

 if (vp9_get_raw_frame(frame_worker_data->pbi, &sd, &flags) == 0) {
    VP9_COMMON *const cm = &frame_worker_data->pbi->common;
 RefCntBuffer *const frame_bufs = cm->buffer_pool->frame_bufs;
    ctx->frame_cache[ctx->frame_cache_write].fb_idx = cm->new_fb_idx;
    yuvconfig2image(&ctx->frame_cache[ctx->frame_cache_write].img, &sd,
                    frame_worker_data->user_priv);
    ctx->frame_cache[ctx->frame_cache_write].img.fb_priv =
        frame_bufs[cm->new_fb_idx].raw_frame_buffer.priv;
    ctx->frame_cache_write =
 (ctx->frame_cache_write + 1) % FRAME_CACHE_SIZE;
 ++ctx->num_cache_frames;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static IV_API_CALL_STATUS_T api_check_struct_sanity(iv_obj_t *ps_handle,
 void *pv_api_ip,
 void *pv_api_op)
{
    IVD_API_COMMAND_TYPE_T e_cmd;
    UWORD32 *pu4_api_ip;
    UWORD32 *pu4_api_op;
    UWORD32 i, j;

 if(NULL == pv_api_op)
 return (IV_FAIL);

 if(NULL == pv_api_ip)
 return (IV_FAIL);

    pu4_api_ip = (UWORD32 *)pv_api_ip;
    pu4_api_op = (UWORD32 *)pv_api_op;
    e_cmd = *(pu4_api_ip + 1);

 /* error checks on handle */
 switch((WORD32)e_cmd)
 {
 case IV_CMD_GET_NUM_MEM_REC:
 case IV_CMD_FILL_NUM_MEM_REC:
 break;
 case IV_CMD_INIT:
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
                H264_DEC_DEBUG_PRINT(
 "Sizes do not match. Expected: %d, Got: %d",
 sizeof(iv_obj_t), ps_handle->u4_size);
 return IV_FAIL;
 }
 break;
 case IVD_CMD_REL_DISPLAY_FRAME:
 case IVD_CMD_SET_DISPLAY_FRAME:
 case IVD_CMD_GET_DISPLAY_FRAME:
 case IVD_CMD_VIDEO_DECODE:
 case IV_CMD_RETRIEVE_MEMREC:
 case IVD_CMD_VIDEO_CTL:
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_handle->pv_fxns != ih264d_api_function)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->pv_codec_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }
 break;
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_API_CMD;
 return IV_FAIL;
 }

 switch((WORD32)e_cmd)
 {
 case IV_CMD_GET_NUM_MEM_REC:
 {
 ih264d_num_mem_rec_ip_t *ps_ip =
 (ih264d_num_mem_rec_ip_t *)pv_api_ip;
 ih264d_num_mem_rec_op_t *ps_op =
 (ih264d_num_mem_rec_op_t *)pv_api_op;
            ps_op->s_ivd_num_mem_rec_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_num_mem_rec_ip_t.u4_size
 != sizeof(ih264d_num_mem_rec_ip_t))
 {
                ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_num_mem_rec_op_t.u4_size
 != sizeof(ih264d_num_mem_rec_op_t))
 {
                ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }
 }
 break;
 case IV_CMD_FILL_NUM_MEM_REC:
 {
 ih264d_fill_mem_rec_ip_t *ps_ip =
 (ih264d_fill_mem_rec_ip_t *)pv_api_ip;
 ih264d_fill_mem_rec_op_t *ps_op =
 (ih264d_fill_mem_rec_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;
            WORD32 max_wd = ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd;
            WORD32 max_ht = ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht;

            max_wd = ALIGN16(max_wd);
            max_ht = ALIGN32(max_ht);

            ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > sizeof(ih264d_fill_mem_rec_ip_t))
 || (ps_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 < sizeof(iv_fill_mem_rec_ip_t)))
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_fill_mem_rec_op_t.u4_size
 != sizeof(ih264d_fill_mem_rec_op_t))
 && (ps_op->s_ivd_fill_mem_rec_op_t.u4_size
 != sizeof(iv_fill_mem_rec_op_t)))
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(max_wd < H264_MIN_FRAME_WIDTH)
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_REQUESTED_WIDTH_NOT_SUPPPORTED;
 return (IV_FAIL);
 }

 if(max_wd > H264_MAX_FRAME_WIDTH)
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_REQUESTED_WIDTH_NOT_SUPPPORTED;
 return (IV_FAIL);
 }

 if(max_ht < H264_MIN_FRAME_HEIGHT)
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_REQUESTED_HEIGHT_NOT_SUPPPORTED;
 return (IV_FAIL);
 }

 if((max_ht * max_wd)
 > (H264_MAX_FRAME_HEIGHT * H264_MAX_FRAME_WIDTH))

 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_REQUESTED_HEIGHT_NOT_SUPPPORTED;
 return (IV_FAIL);
 }

 if(NULL == ps_ip->s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location)
 {
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                IVD_NUM_REC_NOT_SUFFICIENT;
 return (IV_FAIL);
 }

 /* check memrecords sizes are correct */
            ps_mem_rec = ps_ip->s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location;
 for(i = 0; i < MEM_REC_CNT; i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                                    IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 }
 break;

 case IV_CMD_INIT:
 {
 ih264d_init_ip_t *ps_ip = (ih264d_init_ip_t *)pv_api_ip;
 ih264d_init_op_t *ps_op = (ih264d_init_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;
            WORD32 max_wd = ps_ip->s_ivd_init_ip_t.u4_frm_max_wd;
            WORD32 max_ht = ps_ip->s_ivd_init_ip_t.u4_frm_max_ht;

            max_wd = ALIGN16(max_wd);
            max_ht = ALIGN32(max_ht);

            ps_op->s_ivd_init_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_init_ip_t.u4_size > sizeof(ih264d_init_ip_t))
 || (ps_ip->s_ivd_init_ip_t.u4_size
 < sizeof(ivd_init_ip_t)))
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_init_op_t.u4_size != sizeof(ih264d_init_op_t))
 && (ps_op->s_ivd_init_op_t.u4_size
 != sizeof(ivd_init_op_t)))
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_num_mem_rec != MEM_REC_CNT)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_NOT_SUFFICIENT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if(max_wd < H264_MIN_FRAME_WIDTH)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_WIDTH_NOT_SUPPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if(max_wd > H264_MAX_FRAME_WIDTH)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_WIDTH_NOT_SUPPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if(max_ht < H264_MIN_FRAME_HEIGHT)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_HEIGHT_NOT_SUPPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if((max_ht * max_wd)
 > (H264_MAX_FRAME_HEIGHT * H264_MAX_FRAME_WIDTH))

 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_HEIGHT_NOT_SUPPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if(NULL == ps_ip->s_ivd_init_ip_t.pv_mem_rec_location)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_NUM_REC_NOT_SUFFICIENT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if((ps_ip->s_ivd_init_ip_t.e_output_format != IV_YUV_420P)
 && (ps_ip->s_ivd_init_ip_t.e_output_format
 != IV_YUV_422ILE)
 && (ps_ip->s_ivd_init_ip_t.e_output_format
 != IV_RGB_565)
 && (ps_ip->s_ivd_init_ip_t.e_output_format
 != IV_YUV_420SP_UV)
 && (ps_ip->s_ivd_init_ip_t.e_output_format
 != IV_YUV_420SP_VU))
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_COL_FMT_NOT_SUPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 /* verify number of mem records */
 if(ps_ip->s_ivd_init_ip_t.u4_num_mem_rec < MEM_REC_CNT)
 {
                ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_init_op_t.u4_error_code |=
                                IVD_INIT_DEC_MEM_REC_NOT_SUFFICIENT;
                H264_DEC_DEBUG_PRINT("\n");
 return IV_FAIL;
 }

            ps_mem_rec = ps_ip->s_ivd_init_ip_t.pv_mem_rec_location;
 /* check memrecords sizes are correct */
 for(i = 0; i < ps_ip->s_ivd_init_ip_t.u4_num_mem_rec; i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                    ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |=
                                    IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
                    H264_DEC_DEBUG_PRINT("i: %d\n", i);
 return IV_FAIL;
 }
 /* check memrecords pointers are not NULL */

 if(ps_mem_rec[i].pv_base == NULL)
 {

                    ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |=
                                    IVD_INIT_DEC_MEM_REC_BASE_NULL;
                    H264_DEC_DEBUG_PRINT("i: %d\n", i);
 return IV_FAIL;

 }

 }

 /* verify memtabs for overlapping regions */
 {
 void *start[MEM_REC_CNT];
 void *end[MEM_REC_CNT];

                start[0] = (void *)(ps_mem_rec[0].pv_base);
                end[0] = (void *)((UWORD8 *)ps_mem_rec[0].pv_base
 + ps_mem_rec[0].u4_mem_size - 1);
 for(i = 1; i < MEM_REC_CNT; i++)
 {
 /* This array is populated to check memtab overlapp */
                    start[i] = (void *)(ps_mem_rec[i].pv_base);
                    end[i] = (void *)((UWORD8 *)ps_mem_rec[i].pv_base
 + ps_mem_rec[i].u4_mem_size - 1);

 for(j = 0; j < i; j++)
 {
 if((start[i] >= start[j]) && (start[i] <= end[j]))
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |=
                                            IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
                            H264_DEC_DEBUG_PRINT("i: %d, j: %d\n", i, j);
 return IV_FAIL;
 }

 if((end[i] >= start[j]) && (end[i] <= end[j]))
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |=
                                            IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
                            H264_DEC_DEBUG_PRINT("i: %d, j: %d\n", i, j);
 return IV_FAIL;
 }

 if((start[i] < start[j]) && (end[i] > end[j]))
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |=
                                            IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
                            H264_DEC_DEBUG_PRINT("i: %d, j: %d\n", i, j);
 return IV_FAIL;
 }
 }

 }
 }

 {
 iv_mem_rec_t mem_rec_ittiam_api[MEM_REC_CNT];
 ih264d_fill_mem_rec_ip_t s_fill_mem_rec_ip;
 ih264d_fill_mem_rec_op_t s_fill_mem_rec_op;
                IV_API_CALL_STATUS_T e_status;

                UWORD32 i;
                s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.e_cmd =
                                IV_CMD_FILL_NUM_MEM_REC;
                s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location =
                                mem_rec_ittiam_api;
                s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd =
                                max_wd;
                s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht =
                                max_ht;

 if(ps_ip->s_ivd_init_ip_t.u4_size
 > offsetof(ih264d_init_ip_t, i4_level))
 {
                    s_fill_mem_rec_ip.i4_level = ps_ip->i4_level;
 }
 else
 {
                    s_fill_mem_rec_ip.i4_level = H264_LEVEL_3_1;
 }

 if(ps_ip->s_ivd_init_ip_t.u4_size
 > offsetof(ih264d_init_ip_t, u4_num_ref_frames))
 {
                    s_fill_mem_rec_ip.u4_num_ref_frames =
                                    ps_ip->u4_num_ref_frames;
 }
 else
 {
                    s_fill_mem_rec_ip.u4_num_ref_frames =
 (H264_MAX_REF_PICS + 1);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_size
 > offsetof(ih264d_init_ip_t,
                                           u4_num_reorder_frames))
 {
                    s_fill_mem_rec_ip.u4_num_reorder_frames =
                                    ps_ip->u4_num_reorder_frames;
 }
 else
 {
                    s_fill_mem_rec_ip.u4_num_reorder_frames = (H264_MAX_REF_PICS
 + 1);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_size
 > offsetof(ih264d_init_ip_t,
                                           u4_num_extra_disp_buf))
 {
                    s_fill_mem_rec_ip.u4_num_extra_disp_buf =
                                    ps_ip->u4_num_extra_disp_buf;
 }
 else
 {
                    s_fill_mem_rec_ip.u4_num_extra_disp_buf = 0;
 }

 if(ps_ip->s_ivd_init_ip_t.u4_size
 > offsetof(ih264d_init_ip_t, u4_share_disp_buf))
 {
#ifndef LOGO_EN
                    s_fill_mem_rec_ip.u4_share_disp_buf =
                                    ps_ip->u4_share_disp_buf;
#else
                    s_fill_mem_rec_ip.u4_share_disp_buf = 0;
#endif
 }
 else
 {
                    s_fill_mem_rec_ip.u4_share_disp_buf = 0;
 }

                s_fill_mem_rec_ip.e_output_format =
                                ps_ip->s_ivd_init_ip_t.e_output_format;

 if((s_fill_mem_rec_ip.e_output_format != IV_YUV_420P)
 && (s_fill_mem_rec_ip.e_output_format
 != IV_YUV_420SP_UV)
 && (s_fill_mem_rec_ip.e_output_format
 != IV_YUV_420SP_VU))
 {
                    s_fill_mem_rec_ip.u4_share_disp_buf = 0;
 }

                s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_size =
 sizeof(ih264d_fill_mem_rec_ip_t);
                s_fill_mem_rec_op.s_ivd_fill_mem_rec_op_t.u4_size =
 sizeof(ih264d_fill_mem_rec_op_t);

 for(i = 0; i < MEM_REC_CNT; i++)
                    mem_rec_ittiam_api[i].u4_size = sizeof(iv_mem_rec_t);

                e_status = ih264d_api_function(NULL,
 (void *)&s_fill_mem_rec_ip,
 (void *)&s_fill_mem_rec_op);
 if(IV_FAIL == e_status)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code =
                                    s_fill_mem_rec_op.s_ivd_fill_mem_rec_op_t.u4_error_code;
                    H264_DEC_DEBUG_PRINT("Fail\n");
 return (IV_FAIL);
 }

 for(i = 0; i < MEM_REC_CNT; i++)
 {
 if(ps_mem_rec[i].u4_mem_size
 < mem_rec_ittiam_api[i].u4_mem_size)
 {
                        ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_init_op_t.u4_error_code |=
                                        IVD_INIT_DEC_MEM_REC_INSUFFICIENT_SIZE;
                        H264_DEC_DEBUG_PRINT("i: %d \n", i);
 return IV_FAIL;
 }
 if(ps_mem_rec[i].u4_mem_alignment
 != mem_rec_ittiam_api[i].u4_mem_alignment)
 {
                        ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_init_op_t.u4_error_code |=
                                        IVD_INIT_DEC_MEM_REC_ALIGNMENT_ERR;
                        H264_DEC_DEBUG_PRINT("i: %d \n", i);
 return IV_FAIL;
 }
 if(ps_mem_rec[i].e_mem_type
 != mem_rec_ittiam_api[i].e_mem_type)
 {
                        UWORD32 check = IV_SUCCESS;
                        UWORD32 diff = mem_rec_ittiam_api[i].e_mem_type
 - ps_mem_rec[i].e_mem_type;

 if((ps_mem_rec[i].e_mem_type
 <= IV_EXTERNAL_CACHEABLE_SCRATCH_MEM)
 && (mem_rec_ittiam_api[i].e_mem_type
 >= IV_INTERNAL_NONCACHEABLE_PERSISTENT_MEM))
 {
                            check = IV_FAIL;
 }
 if(3 != MOD(mem_rec_ittiam_api[i].e_mem_type, 4))
 {
 /*
                             * It is not IV_EXTERNAL_NONCACHEABLE_PERSISTENT_MEM or IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM
                             */
 if((diff < 1) || (diff > 3))
 {
                                check = IV_FAIL;
 }
 }
 else
 {
 if(diff == 1)
 {
 /*
                                 * This particular case is when codec asked for External Persistent, but got
                                 * Internal Scratch.
                                 */
                                check = IV_FAIL;
 }
 if((diff != 2) && (diff != 3))
 {
                                check = IV_FAIL;
 }
 }
 if(check == IV_FAIL)
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |=
                                            IVD_INIT_DEC_MEM_REC_INCORRECT_TYPE;
                            H264_DEC_DEBUG_PRINT("i: %d \n", i);
 return IV_FAIL;
 }
 }
 }
 }

 }
 break;

 case IVD_CMD_GET_DISPLAY_FRAME:
 {
 ih264d_get_display_frame_ip_t *ps_ip =
 (ih264d_get_display_frame_ip_t *)pv_api_ip;
 ih264d_get_display_frame_op_t *ps_op =
 (ih264d_get_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_get_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ih264d_get_display_frame_ip_t))
 && (ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ivd_get_display_frame_ip_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ih264d_get_display_frame_op_t))
 && (ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ivd_get_display_frame_op_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }
 }
 break;

 case IVD_CMD_REL_DISPLAY_FRAME:
 {
 ih264d_rel_display_frame_ip_t *ps_ip =
 (ih264d_rel_display_frame_ip_t *)pv_api_ip;
 ih264d_rel_display_frame_op_t *ps_op =
 (ih264d_rel_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_rel_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ih264d_rel_display_frame_ip_t))
 && (ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ivd_rel_display_frame_ip_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ih264d_rel_display_frame_op_t))
 && (ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ivd_rel_display_frame_op_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_SET_DISPLAY_FRAME:
 {
 ih264d_set_display_frame_ip_t *ps_ip =
 (ih264d_set_display_frame_ip_t *)pv_api_ip;
 ih264d_set_display_frame_op_t *ps_op =
 (ih264d_set_display_frame_op_t *)pv_api_op;
            UWORD32 j;

            ps_op->s_ivd_set_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ih264d_set_display_frame_ip_t))
 && (ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ivd_set_display_frame_ip_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ih264d_set_display_frame_op_t))
 && (ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ivd_set_display_frame_op_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs == 0)
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(j = 0; j < ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs;
                            j++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs
 == 0)
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                    IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0;
                                i
 < ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs;
                                i++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].pu1_bufs[i]
 == NULL)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_min_out_buf_size[i]
 == 0)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_DECODE:
 {
 ih264d_video_decode_ip_t *ps_ip =
 (ih264d_video_decode_ip_t *)pv_api_ip;
 ih264d_video_decode_op_t *ps_op =
 (ih264d_video_decode_op_t *)pv_api_op;

            H264_DEC_DEBUG_PRINT("The input bytes is: %d",
                                 ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes);
            ps_op->s_ivd_video_decode_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_video_decode_ip_t.u4_size
 != sizeof(ih264d_video_decode_ip_t)&&
                            ps_ip->s_ivd_video_decode_ip_t.u4_size != offsetof(ivd_video_decode_ip_t, s_out_buffer))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_video_decode_op_t.u4_size
 != sizeof(ih264d_video_decode_op_t)&&
                            ps_op->s_ivd_video_decode_op_t.u4_size != offsetof(ivd_video_decode_op_t, u4_output_present))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IV_CMD_RETRIEVE_MEMREC:
 {
 ih264d_retrieve_mem_rec_ip_t *ps_ip =
 (ih264d_retrieve_mem_rec_ip_t *)pv_api_ip;
 ih264d_retrieve_mem_rec_op_t *ps_op =
 (ih264d_retrieve_mem_rec_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;

            ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_retrieve_mem_rec_ip_t.u4_size
 != sizeof(ih264d_retrieve_mem_rec_ip_t))
 {
                ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_retrieve_mem_rec_op_t.u4_size
 != sizeof(ih264d_retrieve_mem_rec_op_t))
 {
                ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

            ps_mem_rec = ps_ip->s_ivd_retrieve_mem_rec_ip_t.pv_mem_rec_location;
 /* check memrecords sizes are correct */
 for(i = 0; i < MEM_REC_CNT; i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |=
                                    IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_CTL:
 {
            UWORD32 *pu4_ptr_cmd;
            UWORD32 sub_command;

            pu4_ptr_cmd = (UWORD32 *)pv_api_ip;
            pu4_ptr_cmd += 2;
            sub_command = *pu4_ptr_cmd;

 switch(sub_command)
 {
 case IVD_CMD_CTL_SETPARAMS:
 {
 ih264d_ctl_set_config_ip_t *ps_ip;
 ih264d_ctl_set_config_op_t *ps_op;
                    ps_ip = (ih264d_ctl_set_config_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_config_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_set_config_ip_t.u4_size
 != sizeof(ih264d_ctl_set_config_ip_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 case IVD_CMD_CTL_SETDEFAULT:
 {
 ih264d_ctl_set_config_op_t *ps_op;
                    ps_op = (ih264d_ctl_set_config_op_t *)pv_api_op;
 if(ps_op->s_ivd_ctl_set_config_op_t.u4_size
 != sizeof(ih264d_ctl_set_config_op_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETPARAMS:
 {
 ih264d_ctl_getstatus_ip_t *ps_ip;
 ih264d_ctl_getstatus_op_t *ps_op;

                    ps_ip = (ih264d_ctl_getstatus_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getstatus_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getstatus_ip_t.u4_size
 != sizeof(ih264d_ctl_getstatus_ip_t))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getstatus_op_t.u4_size
 != sizeof(ih264d_ctl_getstatus_op_t))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETBUFINFO:
 {
 ih264d_ctl_getbufinfo_ip_t *ps_ip;
 ih264d_ctl_getbufinfo_op_t *ps_op;
                    ps_ip = (ih264d_ctl_getbufinfo_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getbufinfo_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_getbufinfo_ip_t.u4_size
 != sizeof(ih264d_ctl_getbufinfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getbufinfo_op_t.u4_size
 != sizeof(ih264d_ctl_getbufinfo_op_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETVERSION:
 {
 ih264d_ctl_getversioninfo_ip_t *ps_ip;
 ih264d_ctl_getversioninfo_op_t *ps_op;
                    ps_ip = (ih264d_ctl_getversioninfo_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getversioninfo_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_size
 != sizeof(ih264d_ctl_getversioninfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getversioninfo_op_t.u4_size
 != sizeof(ih264d_ctl_getversioninfo_op_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_FLUSH:
 {
 ih264d_ctl_flush_ip_t *ps_ip;
 ih264d_ctl_flush_op_t *ps_op;
                    ps_ip = (ih264d_ctl_flush_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_flush_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_flush_ip_t.u4_size
 != sizeof(ih264d_ctl_flush_ip_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_flush_op_t.u4_size
 != sizeof(ih264d_ctl_flush_op_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_RESET:
 {
 ih264d_ctl_reset_ip_t *ps_ip;
 ih264d_ctl_reset_op_t *ps_op;
                    ps_ip = (ih264d_ctl_reset_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_reset_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_reset_ip_t.u4_size
 != sizeof(ih264d_ctl_reset_ip_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_reset_op_t.u4_size
 != sizeof(ih264d_ctl_reset_op_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IH264D_CMD_CTL_DEGRADE:
 {
 ih264d_ctl_degrade_ip_t *ps_ip;
 ih264d_ctl_degrade_op_t *ps_op;

                    ps_ip = (ih264d_ctl_degrade_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_degrade_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_degrade_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_degrade_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if((ps_ip->i4_degrade_pics < 0)
 || (ps_ip->i4_degrade_pics > 4)
 || (ps_ip->i4_nondegrade_interval < 0)
 || (ps_ip->i4_degrade_type < 0)
 || (ps_ip->i4_degrade_type > 15))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }

 break;
 }

 case IH264D_CMD_CTL_GET_BUFFER_DIMENSIONS:
 {
 ih264d_ctl_get_frame_dimensions_ip_t *ps_ip;
 ih264d_ctl_get_frame_dimensions_op_t *ps_op;

                    ps_ip = (ih264d_ctl_get_frame_dimensions_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_get_frame_dimensions_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ih264d_ctl_get_frame_dimensions_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ih264d_ctl_get_frame_dimensions_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }

 case IH264D_CMD_CTL_SET_NUM_CORES:
 {
 ih264d_ctl_set_num_cores_ip_t *ps_ip;
 ih264d_ctl_set_num_cores_op_t *ps_op;

                    ps_ip = (ih264d_ctl_set_num_cores_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_num_cores_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_set_num_cores_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_set_num_cores_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if((ps_ip->u4_num_cores != 1) && (ps_ip->u4_num_cores != 2)
 && (ps_ip->u4_num_cores != 3)
 && (ps_ip->u4_num_cores != 4))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }
 break;
 }
 case IH264D_CMD_CTL_SET_PROCESSOR:
 {
 ih264d_ctl_set_processor_ip_t *ps_ip;
 ih264d_ctl_set_processor_op_t *ps_op;

                    ps_ip = (ih264d_ctl_set_processor_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_processor_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_set_processor_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_set_processor_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_UNSUPPORTED_API_CMD;
 return IV_FAIL;
 break;
 }
 }
 break;
 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  write_png(const char **name, FILE *fp, int color_type, int bit_depth,
    volatile png_fixed_point gamma, chunk_insert * volatile insert,
   unsigned int filters, unsigned int *colors)
 {
    png_structp png_ptr = png_create_write_struct(PNG_LIBPNG_VER_STRING,
       name, makepng_error, makepng_warning);
 volatile png_infop info_ptr = NULL;
 volatile png_bytep row = NULL;

 if (png_ptr == NULL)
 {
      fprintf(stderr, "makepng: OOM allocating write structure\n");
 return 1;
 }

 if (setjmp(png_jmpbuf(png_ptr)))
 {
      png_structp nv_ptr = png_ptr;
      png_infop nv_info = info_ptr;

      png_ptr = NULL;
      info_ptr = NULL;
      png_destroy_write_struct(&nv_ptr, &nv_info);
 if (row != NULL) free(row);
 return 1;
 }

 
    /* Allow benign errors so that we can write PNGs with errors */
    png_set_benign_errors(png_ptr, 1/*allowed*/);
    png_init_io(png_ptr, fp);
 
    info_ptr = png_create_info_struct(png_ptr);
 if (info_ptr == NULL)

       png_error(png_ptr, "OOM allocating info structure");
 
    {
      unsigned int size = image_size_of_type(color_type, bit_depth, colors);
       png_fixed_point real_gamma = 45455; /* For sRGB */
       png_byte gamma_table[256];
       double conv;
 
       /* This function uses the libpng values used on read to carry extra
        * information about the gamma:
        */
 if (gamma == PNG_GAMMA_MAC_18)
         gamma = 65909;

 else if (gamma > 0 && gamma < 1000)
         gamma = PNG_FP_1;

 if (gamma > 0)
         real_gamma = gamma;

 {
 unsigned int i;

 if (real_gamma == 45455) for (i=0; i<256; ++i)
 {
            gamma_table[i] = (png_byte)i;
            conv = 1.;
 }

 else
 {
 /* Convert 'i' from sRGB (45455) to real_gamma, this makes
             * the images look the same regardless of the gAMA chunk.
             */
            conv = real_gamma;
            conv /= 45455;


             gamma_table[0] = 0;
 
             for (i=1; i<255; ++i)
               gamma_table[i] = (png_byte)floor(pow(i/255.,conv) * 255 + .5);
 
             gamma_table[255] = 255;
          }
       }
 
      png_set_IHDR(png_ptr, info_ptr, size, size, bit_depth, color_type,
          PNG_INTERLACE_NONE, PNG_COMPRESSION_TYPE_BASE, PNG_FILTER_TYPE_BASE);
 
       if (color_type & PNG_COLOR_MASK_PALETTE)
 {
 int npalette;
         png_color palette[256];
         png_byte trans[256];


          npalette = generate_palette(palette, trans, bit_depth, gamma_table,
             colors);
          png_set_PLTE(png_ptr, info_ptr, palette, npalette);
         png_set_tRNS(png_ptr, info_ptr, trans, npalette-1,
            NULL/*transparent color*/);
 
          /* Reset gamma_table to prevent the image rows being changed */
          for (npalette=0; npalette<256; ++npalette)
             gamma_table[npalette] = (png_byte)npalette;
       }
 
       if (gamma == PNG_DEFAULT_sRGB)
          png_set_sRGB(png_ptr, info_ptr, PNG_sRGB_INTENT_ABSOLUTE);
 
 else if (gamma > 0) /* Else don't set color space information */
 {
         png_set_gAMA_fixed(png_ptr, info_ptr, real_gamma);

 /* Just use the sRGB values here. */
         png_set_cHRM_fixed(png_ptr, info_ptr,
 /* color      x       y */
 /* white */ 31270, 32900,
 /* red   */ 64000, 33000,
 /* green */ 30000, 60000,
 /* blue  */ 15000, 6000
 );
 }

 /* Insert extra information. */
 while (insert != NULL)
 {
         insert->insert(png_ptr, info_ptr, insert->nparams, insert->parameters);
         insert = insert->next;
 }

 /* Write the file header. */
      png_write_info(png_ptr, info_ptr);

 /* Restrict the filters */

       png_set_filter(png_ptr, PNG_FILTER_TYPE_BASE, filters);
 
       {
         int passes = png_set_interlace_handling(png_ptr);
          int pass;
          png_size_t rowbytes = png_get_rowbytes(png_ptr, info_ptr);
 
         row = malloc(rowbytes);

 if (row == NULL)
            png_error(png_ptr, "OOM allocating row buffer");

 for (pass = 0; pass < passes; ++pass)

          {
             unsigned int y;
 
            for (y=0; y<size; ++y)
             {
               generate_row(row, rowbytes, y, color_type, bit_depth,
                  gamma_table, conv, colors);
                png_write_row(png_ptr, row);
             }
          }
 }
 }

 /* Finish writing the file. */
   png_write_end(png_ptr, info_ptr);

 {
      png_structp nv_ptr = png_ptr;
      png_infop nv_info = info_ptr;

      png_ptr = NULL;
      info_ptr = NULL;
      png_destroy_write_struct(&nv_ptr, &nv_info);
 }
   free(row);
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: AMRExtractor::AMRExtractor(const sp<DataSource> &source)
 : mDataSource(source),
      mInitCheck(NO_INIT),
      mOffsetTableLength(0) {
 String8 mimeType;
 float confidence;
 if (!SniffAMR(mDataSource, &mimeType, &confidence, NULL)) {
 return;
 }

    mIsWide = (mimeType == MEDIA_MIMETYPE_AUDIO_AMR_WB);

    mMeta = new MetaData;
    mMeta->setCString(
            kKeyMIMEType, mIsWide ? MEDIA_MIMETYPE_AUDIO_AMR_WB
 : MEDIA_MIMETYPE_AUDIO_AMR_NB);

    mMeta->setInt32(kKeyChannelCount, 1);
    mMeta->setInt32(kKeySampleRate, mIsWide ? 16000 : 8000);

 off64_t offset = mIsWide ? 9 : 6;
 off64_t streamSize;
 size_t frameSize, numFrames = 0;
 int64_t duration = 0;

 if (mDataSource->getSize(&streamSize) == OK) {
 while (offset < streamSize) {
 status_t status = getFrameSizeByOffset(source, offset, mIsWide, &frameSize);
 if (status == ERROR_END_OF_STREAM) {
 break;
 } else if (status != OK) {
 return;
 }

 if ((numFrames % 50 == 0) && (numFrames / 50 < OFFSET_TABLE_LEN)) {
                CHECK_EQ(mOffsetTableLength, numFrames / 50);
                mOffsetTable[mOffsetTableLength] = offset - (mIsWide ? 9: 6);
                mOffsetTableLength ++;
 }

            offset += frameSize;
            duration += 20000; // Each frame is 20ms
            numFrames ++;
 }

        mMeta->setInt64(kKeyDuration, duration);
 }

    mInitCheck = OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AudioSource::rampVolume(
 int32_t startFrame, int32_t rampDurationFrames,
 uint8_t *data, size_t bytes) {

 const int32_t kShift = 14;
 int32_t fixedMultiplier = (startFrame << kShift) / rampDurationFrames;
 const int32_t nChannels = mRecord->channelCount();
 int32_t stopFrame = startFrame + bytes / sizeof(int16_t);
 int16_t *frame = (int16_t *) data;
 if (stopFrame > rampDurationFrames) {
        stopFrame = rampDurationFrames;
 }

 while (startFrame < stopFrame) {
 if (nChannels == 1) { // mono
            frame[0] = (frame[0] * fixedMultiplier) >> kShift;
 ++frame;
 ++startFrame;
 } else { // stereo
            frame[0] = (frame[0] * fixedMultiplier) >> kShift;
            frame[1] = (frame[1] * fixedMultiplier) >> kShift;
            frame += 2;
            startFrame += 2;
 }

 if ((startFrame & 3) == 0) {
            fixedMultiplier = (startFrame << kShift) / rampDurationFrames;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeParcelFileDescriptor(int fd, int commChannel) {
 status_t status;

 if (fd < 0) {
        status = writeInt32(0); // ParcelFileDescriptor is null
 if (status) return status;
 } else {
        status = writeInt32(1); // ParcelFileDescriptor is not null
 if (status) return status;
        status = writeDupFileDescriptor(fd);
 if (status) return status;
 if (commChannel < 0) {
            status = writeInt32(0); // commChannel is null
 if (status) return status;
 } else {
            status = writeInt32(1); // commChannel is not null
 if (status) return status;
            status = writeDupFileDescriptor(commChannel);
 }
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::free_output_buffer(OMX_BUFFERHEADERTYPE *bufferHdr)
{
 unsigned int index = 0;

 if (bufferHdr == NULL || m_out_mem_ptr == NULL) {
 return OMX_ErrorBadParameter;
 }

    index = bufferHdr - m_out_mem_ptr;
    DEBUG_PRINT_LOW("Free ouput Buffer index = %d",index);

 if (index < drv_ctx.op_buf.actualcount
 && drv_ctx.ptr_outputbuffer) {
        DEBUG_PRINT_LOW("Free ouput Buffer index = %d addr = %p", index,
                drv_ctx.ptr_outputbuffer[index].bufferaddr);

 struct vdec_setbuffer_cmd setbuffers;
        setbuffers.buffer_type = VDEC_BUFFER_TYPE_OUTPUT;
        memcpy (&setbuffers.buffer,&drv_ctx.ptr_outputbuffer[index],
 sizeof (vdec_bufferpayload));

 if (!dynamic_buf_mode) {
#ifdef _ANDROID_
 if (m_enable_android_native_buffers) {
 if (!secure_mode) {
 if (drv_ctx.ptr_outputbuffer[index].pmem_fd > 0) {
                        munmap(drv_ctx.ptr_outputbuffer[index].bufferaddr,
                                drv_ctx.ptr_outputbuffer[index].mmaped_size);
 }
 }
                drv_ctx.ptr_outputbuffer[index].pmem_fd = -1;
 } else {
#endif
 if (drv_ctx.ptr_outputbuffer[0].pmem_fd > 0 && !ouput_egl_buffers && !m_use_output_pmem) {
 if (!secure_mode) {
                        DEBUG_PRINT_LOW("unmap the output buffer fd = %d",
                                drv_ctx.ptr_outputbuffer[0].pmem_fd);
                        DEBUG_PRINT_LOW("unmap the ouput buffer size=%u  address = %p",
 (unsigned int)drv_ctx.ptr_outputbuffer[0].mmaped_size * drv_ctx.op_buf.actualcount,
                                drv_ctx.ptr_outputbuffer[0].bufferaddr);
                        munmap (drv_ctx.ptr_outputbuffer[0].bufferaddr,
                                drv_ctx.ptr_outputbuffer[0].mmaped_size * drv_ctx.op_buf.actualcount);
 }
                    close (drv_ctx.ptr_outputbuffer[0].pmem_fd);
                    drv_ctx.ptr_outputbuffer[0].pmem_fd = -1;
#ifdef USE_ION
                    free_ion_memory(&drv_ctx.op_buf_ion_info[0]);
#endif
 }
#ifdef _ANDROID_
 }
#endif
 } //!dynamic_buf_mode
 if (release_output_done()) {
            free_extradata();
 }
 }

 return OMX_ErrorNone;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int sock_send_fd(int sock_fd, const uint8_t* buf, int len, int send_fd)
{
 ssize_t ret;
 struct msghdr msg;
 unsigned char *buffer = (unsigned char *)buf;
    memset(&msg, 0, sizeof(msg));

 struct cmsghdr *cmsg;
 char msgbuf[CMSG_SPACE(1)];
    asrt(send_fd != -1);
 if(sock_fd == -1 || send_fd == -1)
 return -1;
    msg.msg_control = msgbuf;
    msg.msg_controllen = sizeof msgbuf;
    cmsg = CMSG_FIRSTHDR(&msg);
    cmsg->cmsg_level = SOL_SOCKET;
    cmsg->cmsg_type = SCM_RIGHTS;
    cmsg->cmsg_len = CMSG_LEN(sizeof send_fd);
    memcpy(CMSG_DATA(cmsg), &send_fd, sizeof send_fd);

 int ret_len = len;
 while (len > 0) {
 struct iovec iv;
        memset(&iv, 0, sizeof(iv));

        iv.iov_base = buffer;
        iv.iov_len = len;

        msg.msg_iov = &iv;

         msg.msg_iovlen = 1;
 
         do {
            ret = sendmsg(sock_fd, &msg, MSG_NOSIGNAL);
         } while (ret < 0 && errno == EINTR);
 
         if (ret < 0) {
            BTIF_TRACE_ERROR("fd:%d, send_fd:%d, sendmsg ret:%d, errno:%d, %s",
                              sock_fd, send_fd, (int)ret, errno, strerror(errno));
            ret_len = -1;
 break;
 }

        buffer += ret;
        len -= ret;

        memset(&msg, 0, sizeof(msg));
 }
    BTIF_TRACE_DEBUG("close fd:%d after sent", send_fd);
    close(send_fd);
 return ret_len;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_io_capabilities_rsp (UINT8 *p)
{
    tBTM_SEC_DEV_REC *p_dev_rec;
    tBTM_SP_IO_RSP evt_data;

    STREAM_TO_BDADDR (evt_data.bd_addr, p);
    STREAM_TO_UINT8 (evt_data.io_cap, p);
    STREAM_TO_UINT8 (evt_data.oob_data, p);
    STREAM_TO_UINT8 (evt_data.auth_req, p);

 /* Allocate a new device record or reuse the oldest one */
    p_dev_rec = btm_find_or_alloc_dev (evt_data.bd_addr);

 /* If no security is in progress, this indicates incoming security */
 if (btm_cb.pairing_state == BTM_PAIR_STATE_IDLE)
 {
        memcpy (btm_cb.pairing_bda, evt_data.bd_addr, BD_ADDR_LEN);

        btm_sec_change_pairing_state (BTM_PAIR_STATE_INCOMING_SSP);

 /* Make sure we reset the trusted mask to help against attacks */
        BTM_SEC_CLR_TRUSTED_DEVICE(p_dev_rec->trusted_mask);

 /* work around for FW bug */
        btm_inq_stop_on_ssp();
 }

 /* Notify L2CAP to increase timeout */
    l2c_pin_code_request (evt_data.bd_addr);

 /* We must have a device record here.
     * Use the connecting device's CoD for the connection */
/* coverity[uninit_use_in_call]
Event uninit_use_in_call: Using uninitialized element of array "evt_data.bd_addr" in call to function "memcmp"
FALSE-POSITIVE error from Coverity test-tool. evt_data.bd_addr is set at the beginning with:     STREAM_TO_BDADDR (evt_data.bd_addr, p);
*/
 if (!memcmp (evt_data.bd_addr, btm_cb.connecting_bda, BD_ADDR_LEN))
        memcpy (p_dev_rec->dev_class, btm_cb.connecting_dc, DEV_CLASS_LEN);

 /* peer sets dedicated bonding bit and we did not initiate dedicated bonding */
 if (btm_cb.pairing_state == BTM_PAIR_STATE_INCOMING_SSP /* peer initiated bonding */
 && (evt_data.auth_req & BTM_AUTH_DD_BOND) ) /* and dedicated bonding bit is set */
 {
        btm_cb.pairing_flags |= BTM_PAIR_FLAGS_PEER_STARTED_DD;
 }

 /* save the IO capability in the device record */
    p_dev_rec->rmt_io_caps  = evt_data.io_cap;
    p_dev_rec->rmt_auth_req = evt_data.auth_req;

 if (btm_cb.api.p_sp_callback)
 (*btm_cb.api.p_sp_callback) (BTM_SP_IO_RSP_EVT, (tBTM_SP_EVT_DATA *)&evt_data);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::deleteReprocessStream(int id) {
    ATRACE_CALL();
 (void)id;

    CLOGE("Unimplemented");
 return INVALID_OPERATION;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraSourceListener::postData(int32_t msgType, const sp<IMemory> &dataPtr,
 camera_frame_metadata_t * /* metadata */) {
    ALOGV("postData(%d, ptr:%p, size:%zu)",
         msgType, dataPtr->pointer(), dataPtr->size());

    sp<CameraSource> source = mSource.promote();
 if (source.get() != NULL) {
        source->dataCallback(msgType, dataPtr);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeInt64Vector(const std::vector<int64_t>& val)
{
 return writeTypedVector(val, &Parcel::writeInt64);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int VisualizerLib_Create(const effect_uuid_t *uuid,
 int32_t /*sessionId*/,
 int32_t /*ioId*/,
 effect_handle_t *pHandle) {
 int ret;
 int i;

 if (pHandle == NULL || uuid == NULL) {
 return -EINVAL;
 }

 if (memcmp(uuid, &gVisualizerDescriptor.uuid, sizeof(effect_uuid_t)) != 0) {
 return -EINVAL;
 }

 VisualizerContext *pContext = new VisualizerContext;

    pContext->mItfe = &gVisualizerInterface;
    pContext->mState = VISUALIZER_STATE_UNINITIALIZED;

    ret = Visualizer_init(pContext);
 if (ret < 0) {
        ALOGW("VisualizerLib_Create() init failed");
 delete pContext;
 return ret;
 }

 *pHandle = (effect_handle_t)pContext;

    pContext->mState = VISUALIZER_STATE_INITIALIZED;

    ALOGV("VisualizerLib_Create %p", pContext);

 return 0;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::useGraphicBuffer(
        OMX_U32 portIndex, const sp<GraphicBuffer>& graphicBuffer,
        OMX::buffer_id *buffer) {
 Mutex::Autolock autoLock(mLock);

    OMX_INDEXTYPE index;
 if (OMX_GetExtensionIndex(
            mHandle,
 const_cast<OMX_STRING>("OMX.google.android.index.useAndroidNativeBuffer2"),
 &index) == OMX_ErrorNone) {
 return useGraphicBuffer2_l(portIndex, graphicBuffer, buffer);
 }

    OMX_STRING name = const_cast<OMX_STRING>(
 "OMX.google.android.index.useAndroidNativeBuffer");
    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, name, &index);
 if (err != OMX_ErrorNone) {
        CLOG_ERROR(getExtensionIndex, err, "%s", name);

         return StatusFromOMXError(err);
     }
 
    BufferMeta *bufferMeta = new BufferMeta(graphicBuffer);
 
     OMX_BUFFERHEADERTYPE *header;
 
    OMX_VERSIONTYPE ver;
    ver.s.nVersionMajor = 1;
    ver.s.nVersionMinor = 0;
    ver.s.nRevision = 0;
    ver.s.nStep = 0;
 UseAndroidNativeBufferParams params = {
 sizeof(UseAndroidNativeBufferParams), ver, portIndex, bufferMeta,
 &header, graphicBuffer,
 };

    err = OMX_SetParameter(mHandle, index, &params);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(setParameter, err, "%s(%#x): %s:%u meta=%p GB=%p", name, index,
                portString(portIndex), portIndex, bufferMeta, graphicBuffer->handle);

 delete bufferMeta;
        bufferMeta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, bufferMeta);

 *buffer = makeBufferID(header);

    addActiveBuffer(portIndex, *buffer);
    CLOG_BUFFER(useGraphicBuffer, NEW_BUFFER_FMT(
 *buffer, portIndex, "GB=%p", graphicBuffer->handle));
 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_hl_co_put_echo_data (UINT8 app_id, tBTA_HL_MCL_HANDLE mcl_handle,
                              UINT16 data_size, UINT8 *p_data, UINT16 evt)
{
    tBTA_HL_STATUS status = BTA_HL_STATUS_FAIL;
    UNUSED(app_id);
    UNUSED(data_size);
    UNUSED(p_data);

    BTIF_TRACE_ERROR("%s not supported",__FUNCTION__);
    bta_hl_ci_put_echo_data(mcl_handle,  status, evt);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::allocate_output_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes)
{
 (void)hComp, (void)port;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
    OMX_BUFFERHEADERTYPE       *bufHdr= NULL; // buffer header
 unsigned                         i= 0; // Temporary counter
#ifdef _MSM8974_
 int align_size;
#endif
    DEBUG_PRINT_HIGH("allocate_output_buffer()for %u bytes", (unsigned int)bytes);
 if (!m_out_mem_ptr) {
 int nBufHdrSize        = 0;
        DEBUG_PRINT_HIGH("%s: size = %u, actual cnt %u", __FUNCTION__,
 (unsigned int)m_sOutPortDef.nBufferSize, (unsigned int)m_sOutPortDef.nBufferCountActual);
        nBufHdrSize        = m_sOutPortDef.nBufferCountActual * sizeof(OMX_BUFFERHEADERTYPE);

 /*
         * Memory for output side involves the following:
         * 1. Array of Buffer Headers
         * 2. Bitmask array to hold the buffer allocation details
         * In order to minimize the memory management entire allocation
         * is done in one step.
         */
        m_out_mem_ptr = (OMX_BUFFERHEADERTYPE  *)calloc(nBufHdrSize,1);

#ifdef USE_ION
        m_pOutput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif
        m_pOutput_pmem = (struct pmem *) calloc(sizeof(struct pmem), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_pmem");
 return OMX_ErrorInsufficientResources;
 }
 if (m_out_mem_ptr && m_pOutput_pmem) {
            bufHdr          =  m_out_mem_ptr;

 for (i=0; i < m_sOutPortDef.nBufferCountActual ; i++) {
                bufHdr->nSize              = sizeof(OMX_BUFFERHEADERTYPE);
                bufHdr->nVersion.nVersion  = OMX_SPEC_VERSION;
                bufHdr->nAllocLen          = bytes;
                bufHdr->nFilledLen         = 0;
                bufHdr->pAppPrivate        = appData;
                bufHdr->nOutputPortIndex   = PORT_INDEX_OUT;
                bufHdr->pOutputPortPrivate = (OMX_PTR)&m_pOutput_pmem[i];
                bufHdr->pBuffer            = NULL;
                bufHdr++;
                m_pOutput_pmem[i].fd = -1;
#ifdef USE_ION
                m_pOutput_ion[i].ion_device_fd =-1;
                m_pOutput_ion[i].fd_ion_data.fd=-1;
                m_pOutput_ion[i].ion_alloc_data.handle = 0;
#endif
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: calloc() failed for m_out_mem_ptr/m_pOutput_pmem");
            eRet = OMX_ErrorInsufficientResources;
 }
 }

    DEBUG_PRINT_HIGH("actual cnt = %u", (unsigned int)m_sOutPortDef.nBufferCountActual);
 for (i=0; i< m_sOutPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_out_bm_count,i)) {
            DEBUG_PRINT_LOW("Found a Free Output Buffer %d",i);
 break;
 }
 }
 if (eRet == OMX_ErrorNone) {
 if (i < m_sOutPortDef.nBufferCountActual) {
#ifdef USE_ION
#ifdef _MSM8974_
            align_size = ((m_sOutPortDef.nBufferSize + 4095)/4096) * 4096;
            m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(align_size,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data, ION_FLAG_CACHED);
#else
            m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sOutPortDef.nBufferSize,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pOutput_ion[i].ion_device_fd < 0) {
                DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }

            m_pOutput_pmem[i].fd = m_pOutput_ion[i].fd_ion_data.fd;
#else
            m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 if (m_pOutput_pmem[i].fd == 0) {
                m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pOutput_pmem[i].fd < 0) {
                DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() failed");
 return OMX_ErrorInsufficientResources;
 }
#endif
            m_pOutput_pmem[i].size = m_sOutPortDef.nBufferSize;
            m_pOutput_pmem[i].offset = 0;

            m_pOutput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
 if(!secure_session) {
#ifdef _MSM8974_
                m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                    align_size,PROT_READ|PROT_WRITE,
                    MAP_SHARED,m_pOutput_pmem[i].fd,0);
#else
                m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                    m_pOutput_pmem[i].size,PROT_READ|PROT_WRITE,
                    MAP_SHARED,m_pOutput_pmem[i].fd,0);
#endif
 if (m_pOutput_pmem[i].buffer == MAP_FAILED) {
                    DEBUG_PRINT_ERROR("ERROR: MMAP_FAILED in o/p alloc buffer");
                close (m_pOutput_pmem[i].fd);
#ifdef USE_ION
                free_ion_memory(&m_pOutput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 }
 else {

                 m_pOutput_pmem[i].buffer = malloc(sizeof(OMX_U32) + sizeof(native_handle_t*));
                 native_handle_t *handle = native_handle_create(1, 0);
                 handle->data[0] = m_pOutput_pmem[i].fd;
                 char *data = (char*) m_pOutput_pmem[i].buffer;
                OMX_U32 type = 1;
                memcpy(data, &type, sizeof(OMX_U32));
                memcpy(data + sizeof(OMX_U32), &handle, sizeof(native_handle_t*));
 }

 *bufferHdr = (m_out_mem_ptr + i );
 (*bufferHdr)->pBuffer = (OMX_U8 *)m_pOutput_pmem[i].buffer;
 (*bufferHdr)->pAppPrivate = appData;

            BITMASK_SET(&m_out_bm_count,i);

 if (dev_use_buf(&m_pOutput_pmem[i],PORT_INDEX_OUT,i) != true) {
                DEBUG_PRINT_ERROR("ERROR: dev_use_buf FAILED for o/p buf");
 return OMX_ErrorInsufficientResources;
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: All o/p buffers are allocated, invalid allocate buf call"
 "for index [%d] actual: %u", i, (unsigned int)m_sOutPortDef.nBufferCountActual);
 }
 }

 return eRet;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: OMX_ERRORTYPE SimpleSoftOMXComponent::fillThisBuffer(
        OMX_BUFFERHEADERTYPE *buffer) {
    sp<AMessage> msg = new AMessage(kWhatFillThisBuffer, mHandler);
    msg->setPointer("header", buffer);
    msg->post();

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  ExternalFrameBufferTest()
 : video_(NULL),
        decoder_(NULL),
        num_buffers_(0) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void cancelBuffer(int buf, const sp<Fence>& fence) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor());
        data.writeInt32(buf);
        data.write(*fence.get());
        remote()->transact(CANCEL_BUFFER, data, &reply);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMX::allocateBufferWithBackup(
        node_id node, OMX_U32 port_index, const sp<IMemory> &params,
        buffer_id *buffer, OMX_U32 allottedSize) {
 return findInstance(node)->allocateBufferWithBackup(
            port_index, params, buffer, allottedSize);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int bta_co_rfc_data_outgoing(void *user_data, uint8_t *buf, uint16_t size) {
  pthread_mutex_lock(&slot_lock);

 uint32_t id = (uintptr_t)user_data;
 int ret = false;
 rfc_slot_t *slot = find_rfc_slot_by_id(id);

   if (!slot)
     goto out;
 
  int received = recv(slot->fd, buf, size, 0);
   if(received == size) {
     ret = true;
   } else {
    LOG_ERROR("%s error receiving RFCOMM data from app: %s", __func__, strerror(errno));
    cleanup_rfc_slot(slot);
 }

out:;
  pthread_mutex_unlock(&slot_lock);
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long CuePoint::GetTime(const Segment* pSegment) const
{
    assert(pSegment);
    assert(m_timecode >= 0);
    const SegmentInfo* const pInfo = pSegment->GetInfo();
    assert(pInfo);
    const long long scale = pInfo->GetTimeCodeScale();
    assert(scale >= 1);
    const long long time = scale * m_timecode;
    return time;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void reactor_free(reactor_t *reactor) {
 if (!reactor)
 return;

  list_free(reactor->invalidation_list);
  close(reactor->event_fd);
  close(reactor->epoll_fd);
  osi_free(reactor);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlSAXParseDoc(xmlSAXHandlerPtr sax, const xmlChar *cur, int recovery) {
    xmlDocPtr ret;
    xmlParserCtxtPtr ctxt;
    xmlSAXHandlerPtr oldsax = NULL;

 if (cur == NULL) return(NULL);


    ctxt = xmlCreateDocParserCtxt(cur);
 if (ctxt == NULL) return(NULL);
 if (sax != NULL) {
        oldsax = ctxt->sax;
        ctxt->sax = sax;
        ctxt->userData = NULL;
 }
    xmlDetectSAX2(ctxt);

    xmlParseDocument(ctxt);
 if ((ctxt->wellFormed) || recovery) ret = ctxt->myDoc;
 else {
       ret = NULL;
       xmlFreeDoc(ctxt->myDoc);
       ctxt->myDoc = NULL;
 }
 if (sax != NULL)
	ctxt->sax = oldsax;
    xmlFreeParserCtxt(ctxt);

 return(ret);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void eager_reader_register(eager_reader_t *reader, reactor_t *reactor, eager_reader_cb read_cb, void *context) {
  assert(reader != NULL);
  assert(reactor != NULL);
  assert(read_cb != NULL);

  eager_reader_unregister(reader);

  reader->outbound_read_ready = read_cb;
  reader->outbound_context = context;
  reader->outbound_registration = reactor_register(reactor, reader->bytes_available_fd, reader, internal_outbound_read_ready, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    void RunMemCheck() {
     ACMRandom rnd(ACMRandom::DeterministicSeed());
     const int count_test_block = 1000;
    DECLARE_ALIGNED_ARRAY(16, int16_t, input_block, kNumCoeffs);
    DECLARE_ALIGNED_ARRAY(16, int16_t, input_extreme_block, kNumCoeffs);
    DECLARE_ALIGNED_ARRAY(16, int16_t, output_ref_block, kNumCoeffs);
    DECLARE_ALIGNED_ARRAY(16, int16_t, output_block, kNumCoeffs);
 
     for (int i = 0; i < count_test_block; ++i) {
       for (int j = 0; j < kNumCoeffs; ++j) {
        input_block[j] = rnd.Rand8() - rnd.Rand8();
        input_extreme_block[j] = rnd.Rand8() % 2 ? 255 : -255;
       }
      if (i == 0)
         for (int j = 0; j < kNumCoeffs; ++j)
          input_extreme_block[j] = 255;
      if (i == 1)
         for (int j = 0; j < kNumCoeffs; ++j)
          input_extreme_block[j] = -255;
 
       fwd_txfm_ref(input_extreme_block, output_ref_block, pitch_, tx_type_);
      REGISTER_STATE_CHECK(RunFwdTxfm(input_extreme_block,
                                      output_block, pitch_));
 
       for (int j = 0; j < kNumCoeffs; ++j) {
         EXPECT_EQ(output_block[j], output_ref_block[j]);
        EXPECT_GE(4 * DCT_MAX_VALUE, abs(output_block[j]))
             << "Error: 16x16 FDCT has coefficient larger than 4*DCT_MAX_VALUE";
       }
     }
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void setup_token_decoder(VP8D_COMP *pbi,
 const unsigned char* token_part_sizes)
{
    vp8_reader *bool_decoder = &pbi->mbc[0];
 unsigned int partition_idx;
 unsigned int fragment_idx;
 unsigned int num_token_partitions;
 const unsigned char *first_fragment_end = pbi->fragments.ptrs[0] +
                                          pbi->fragments.sizes[0];

    TOKEN_PARTITION multi_token_partition =
 (TOKEN_PARTITION)vp8_read_literal(&pbi->mbc[8], 2);
 if (!vp8dx_bool_error(&pbi->mbc[8]))
        pbi->common.multi_token_partition = multi_token_partition;
    num_token_partitions = 1 << pbi->common.multi_token_partition;

 /* Check for partitions within the fragments and unpack the fragments
     * so that each fragment pointer points to its corresponding partition. */
 for (fragment_idx = 0; fragment_idx < pbi->fragments.count; ++fragment_idx)
 {
 unsigned int fragment_size = pbi->fragments.sizes[fragment_idx];
 const unsigned char *fragment_end = pbi->fragments.ptrs[fragment_idx] +
                                            fragment_size;
 /* Special case for handling the first partition since we have already
         * read its size. */
 if (fragment_idx == 0)
 {
 /* Size of first partition + token partition sizes element */
 ptrdiff_t ext_first_part_size = token_part_sizes -
                pbi->fragments.ptrs[0] + 3 * (num_token_partitions - 1);
            fragment_size -= (unsigned int)ext_first_part_size;
 if (fragment_size > 0)
 {
                pbi->fragments.sizes[0] = (unsigned int)ext_first_part_size;
 /* The fragment contains an additional partition. Move to
                 * next. */
                fragment_idx++;
                pbi->fragments.ptrs[fragment_idx] = pbi->fragments.ptrs[0] +
                  pbi->fragments.sizes[0];
 }
 }
 /* Split the chunk into partitions read from the bitstream */
 while (fragment_size > 0)
 {
 ptrdiff_t partition_size = read_available_partition_size(
                                                 pbi,
                                                 token_part_sizes,
                                                 pbi->fragments.ptrs[fragment_idx],
                                                 first_fragment_end,
                                                 fragment_end,
                                                 fragment_idx - 1,
                                                 num_token_partitions);
            pbi->fragments.sizes[fragment_idx] = (unsigned int)partition_size;
            fragment_size -= (unsigned int)partition_size;
            assert(fragment_idx <= num_token_partitions);
 if (fragment_size > 0)
 {
 /* The fragment contains an additional partition.
                 * Move to next. */
                fragment_idx++;
                pbi->fragments.ptrs[fragment_idx] =
                    pbi->fragments.ptrs[fragment_idx - 1] + partition_size;
 }
 }
 }

    pbi->fragments.count = num_token_partitions + 1;

 for (partition_idx = 1; partition_idx < pbi->fragments.count; ++partition_idx)
 {
 if (vp8dx_start_decode(bool_decoder,
                               pbi->fragments.ptrs[partition_idx],
                               pbi->fragments.sizes[partition_idx],
                               pbi->decrypt_cb, pbi->decrypt_state))
            vpx_internal_error(&pbi->common.error, VPX_CODEC_MEM_ERROR,
 "Failed to allocate bool decoder %d",
                               partition_idx);

        bool_decoder++;

     }
 
 #if CONFIG_MULTITHREAD
    /* Clamp number of decoder threads */
    if (pbi->decoding_thread_count > num_token_partitions - 1)
        pbi->decoding_thread_count = num_token_partitions - 1;
 #endif
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: get_option_string(const struct dhcp_message *dhcp, uint8_t option)
{
 int type = 0;
 int len;
 const uint8_t *p;
 char *s;

	p = get_option(dhcp, option, &len, &type);
 if (!p || *p == '\0')
 return NULL;

 if (type & RFC3397) {
		type = decode_rfc3397(NULL, 0, len, p);
 if (!type) {
			errno = EINVAL;
 return NULL;
 }
		s = xmalloc(sizeof(char) * type);
		decode_rfc3397(s, type, len, p);
 return s;
 }

 if (type & RFC3361)
 return decode_rfc3361(len, p);

	s = xmalloc(sizeof(char) * (len + 1));
	memcpy(s, p, len);
	s[len] = '\0';
 return s;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Visualizer_command(effect_handle_t self, uint32_t cmdCode, uint32_t cmdSize,
 void *pCmdData, uint32_t *replySize, void *pReplyData) {

 VisualizerContext * pContext = (VisualizerContext *)self;
 int retsize;

 if (pContext == NULL || pContext->mState == VISUALIZER_STATE_UNINITIALIZED) {
 return -EINVAL;
 }


 switch (cmdCode) {
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 *(int *) pReplyData = Visualizer_init(pContext);
 break;
 case EFFECT_CMD_SET_CONFIG:
 if (pCmdData == NULL || cmdSize != sizeof(effect_config_t)
 || pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 *(int *) pReplyData = Visualizer_setConfig(pContext,
 (effect_config_t *) pCmdData);
 break;
 case EFFECT_CMD_GET_CONFIG:
 if (pReplyData == NULL || replySize == NULL ||
 *replySize != sizeof(effect_config_t)) {
 return -EINVAL;
 }
 Visualizer_getConfig(pContext, (effect_config_t *)pReplyData);
 break;
 case EFFECT_CMD_RESET:
 Visualizer_reset(pContext);
 break;
 case EFFECT_CMD_ENABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 if (pContext->mState != VISUALIZER_STATE_INITIALIZED) {
 return -ENOSYS;
 }
        pContext->mState = VISUALIZER_STATE_ACTIVE;
        ALOGV("EFFECT_CMD_ENABLE() OK");
 *(int *)pReplyData = 0;
 break;
 case EFFECT_CMD_DISABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 if (pContext->mState != VISUALIZER_STATE_ACTIVE) {
 return -ENOSYS;
 }
        pContext->mState = VISUALIZER_STATE_INITIALIZED;
        ALOGV("EFFECT_CMD_DISABLE() OK");
 *(int *)pReplyData = 0;
 break;
 case EFFECT_CMD_GET_PARAM: {
 if (pCmdData == NULL ||
            cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t)) ||
            pReplyData == NULL || replySize == NULL ||
 *replySize < (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t))) {
 return -EINVAL;
 }
        memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + sizeof(uint32_t));
 effect_param_t *p = (effect_param_t *)pReplyData;
        p->status = 0;
 *replySize = sizeof(effect_param_t) + sizeof(uint32_t);
 if (p->psize != sizeof(uint32_t)) {
            p->status = -EINVAL;
 break;
 }
 switch (*(uint32_t *)p->data) {
 case VISUALIZER_PARAM_CAPTURE_SIZE:
            ALOGV("get mCaptureSize = %" PRIu32, pContext->mCaptureSize);
 *((uint32_t *)p->data + 1) = pContext->mCaptureSize;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 case VISUALIZER_PARAM_SCALING_MODE:
            ALOGV("get mScalingMode = %" PRIu32, pContext->mScalingMode);
 *((uint32_t *)p->data + 1) = pContext->mScalingMode;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 case VISUALIZER_PARAM_MEASUREMENT_MODE:
            ALOGV("get mMeasurementMode = %" PRIu32, pContext->mMeasurementMode);
 *((uint32_t *)p->data + 1) = pContext->mMeasurementMode;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 default:
            p->status = -EINVAL;
 }
 } break;
 case EFFECT_CMD_SET_PARAM: {
 if (pCmdData == NULL ||
            cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t)) ||
            pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
 return -EINVAL;
 }
 *(int32_t *)pReplyData = 0;
 effect_param_t *p = (effect_param_t *)pCmdData;
 if (p->psize != sizeof(uint32_t) || p->vsize != sizeof(uint32_t)) {
 *(int32_t *)pReplyData = -EINVAL;

             break;
         }
         switch (*(uint32_t *)p->data) {
        case VISUALIZER_PARAM_CAPTURE_SIZE:
            pContext->mCaptureSize = *((uint32_t *)p->data + 1);
            ALOGV("set mCaptureSize = %" PRIu32, pContext->mCaptureSize);
            break;
         case VISUALIZER_PARAM_SCALING_MODE:
             pContext->mScalingMode = *((uint32_t *)p->data + 1);
             ALOGV("set mScalingMode = %" PRIu32, pContext->mScalingMode);
             break;
        case VISUALIZER_PARAM_LATENCY:
            pContext->mLatency = *((uint32_t *)p->data + 1);
            ALOGV("set mLatency = %" PRIu32, pContext->mLatency);
            break;
         case VISUALIZER_PARAM_MEASUREMENT_MODE:
             pContext->mMeasurementMode = *((uint32_t *)p->data + 1);
             ALOGV("set mMeasurementMode = %" PRIu32, pContext->mMeasurementMode);
 break;
 default:
 *(int32_t *)pReplyData = -EINVAL;
 }
 } break;
 case EFFECT_CMD_SET_DEVICE:
 case EFFECT_CMD_SET_VOLUME:
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;


 case VISUALIZER_CMD_CAPTURE: {
 uint32_t captureSize = pContext->mCaptureSize;
 if (pReplyData == NULL || replySize == NULL || *replySize != captureSize) {
            ALOGV("VISUALIZER_CMD_CAPTURE() error *replySize %" PRIu32 " captureSize %" PRIu32,
 *replySize, captureSize);
 return -EINVAL;
 }
 if (pContext->mState == VISUALIZER_STATE_ACTIVE) {
 const uint32_t deltaMs = Visualizer_getDeltaTimeMsFromUpdatedTime(pContext);

 if ((pContext->mLastCaptureIdx == pContext->mCaptureIdx) &&
 (pContext->mBufferUpdateTime.tv_sec != 0) &&
 (deltaMs > MAX_STALL_TIME_MS)) {
                    ALOGV("capture going to idle");
                    pContext->mBufferUpdateTime.tv_sec = 0;
                    memset(pReplyData, 0x80, captureSize);
 } else {
 int32_t latencyMs = pContext->mLatency;
                latencyMs -= deltaMs;

                 if (latencyMs < 0) {
                     latencyMs = 0;
                 }
                const uint32_t deltaSmpl =
                    pContext->mConfig.inputCfg.samplingRate * latencyMs / 1000;
                int32_t capturePoint = pContext->mCaptureIdx - captureSize - deltaSmpl;
 
                 if (capturePoint < 0) {
                     uint32_t size = -capturePoint;
                     if (size > captureSize) {
                        size = captureSize;
 }
                    memcpy(pReplyData,
                           pContext->mCaptureBuf + CAPTURE_BUF_SIZE + capturePoint,
                           size);
                    pReplyData = (char *)pReplyData + size;
                    captureSize -= size;
                    capturePoint = 0;
 }
                memcpy(pReplyData,
                       pContext->mCaptureBuf + capturePoint,
                       captureSize);
 }

            pContext->mLastCaptureIdx = pContext->mCaptureIdx;
 } else {
            memset(pReplyData, 0x80, captureSize);
 }

 } break;

 case VISUALIZER_CMD_MEASURE: {
 if (pReplyData == NULL || replySize == NULL ||
 *replySize < (sizeof(int32_t) * MEASUREMENT_COUNT)) {
 if (replySize == NULL) {
                ALOGV("VISUALIZER_CMD_MEASURE() error replySize NULL");
 } else {
                ALOGV("VISUALIZER_CMD_MEASURE() error *replySize %" PRIu32
 " < (sizeof(int32_t) * MEASUREMENT_COUNT) %" PRIu32,
 *replySize,
 uint32_t(sizeof(int32_t)) * MEASUREMENT_COUNT);
 }
            android_errorWriteLog(0x534e4554, "30229821");
 return -EINVAL;
 }
 uint16_t peakU16 = 0;
 float sumRmsSquared = 0.0f;
 uint8_t nbValidMeasurements = 0;
 const int32_t delayMs = Visualizer_getDeltaTimeMsFromUpdatedTime(pContext);
 if (delayMs > DISCARD_MEASUREMENTS_TIME_MS) {
            ALOGV("Discarding measurements, last measurement is %" PRId32 "ms old", delayMs);
 for (uint32_t i=0 ; i<pContext->mMeasurementWindowSizeInBuffers ; i++) {
                pContext->mPastMeasurements[i].mIsValid = false;
                pContext->mPastMeasurements[i].mPeakU16 = 0;
                pContext->mPastMeasurements[i].mRmsSquared = 0;
 }
            pContext->mMeasurementBufferIdx = 0;
 } else {
 for (uint32_t i=0 ; i < pContext->mMeasurementWindowSizeInBuffers ; i++) {
 if (pContext->mPastMeasurements[i].mIsValid) {
 if (pContext->mPastMeasurements[i].mPeakU16 > peakU16) {
                        peakU16 = pContext->mPastMeasurements[i].mPeakU16;
 }
                    sumRmsSquared += pContext->mPastMeasurements[i].mRmsSquared;
                    nbValidMeasurements++;
 }
 }
 }
 float rms = nbValidMeasurements == 0 ? 0.0f : sqrtf(sumRmsSquared / nbValidMeasurements);
 int32_t* pIntReplyData = (int32_t*)pReplyData;
 if (rms < 0.000016f) {
            pIntReplyData[MEASUREMENT_IDX_RMS] = -9600; //-96dB
 } else {
            pIntReplyData[MEASUREMENT_IDX_RMS] = (int32_t) (2000 * log10(rms / 32767.0f));
 }
 if (peakU16 == 0) {
            pIntReplyData[MEASUREMENT_IDX_PEAK] = -9600; //-96dB
 } else {
            pIntReplyData[MEASUREMENT_IDX_PEAK] = (int32_t) (2000 * log10(peakU16 / 32767.0f));
 }
        ALOGV("VISUALIZER_CMD_MEASURE peak=%" PRIu16 " (%" PRId32 "mB), rms=%.1f (%" PRId32 "mB)",
                peakU16, pIntReplyData[MEASUREMENT_IDX_PEAK],
                rms, pIntReplyData[MEASUREMENT_IDX_RMS]);
 }
 break;

 default:
        ALOGW("Visualizer_command invalid command %" PRIu32, cmdCode);
 return -EINVAL;
 }

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: skip_chunk_type(const struct global *global, png_uint_32 type)
 /* Return true if this chunk is to be skipped according to the --strip
    * option.  This code needs to recognize all known ancillary chunks in order
    * to handle the --strip=unsafe option.
    */
{
 /* Never strip critical chunks: */
 if (CRITICAL(type))
 return 0;

 switch (type)
 {
 /* Chunks that are treated as, effectively, critical because they affect
       * correct interpretation of the pixel values:
       */
 case png_tRNS: case png_sBIT:
 return 0;

 /* Chunks that specify gamma encoding which should therefore only be
       * removed the the user insists:
       */
 case png_gAMA: case png_sRGB:
 if (global->skip >= SKIP_ALL)
 return 1;
 return 0;

 /* Chunks that affect color interpretation - not used by libpng and rarely
       * used by applications, but technically still required for correct
       * interpretation of the image data:
       */
 case png_cHRM: case png_iCCP:
 if (global->skip >= SKIP_COLOR)
 return 1;
 return 0;

 /* Other chunks that are used by libpng in image transformations (as
       * opposed to known chunks that have get/set APIs but are not otherwise
       * used.)
       */
 case png_bKGD:
 if (global->skip >= SKIP_TRANSFORM)
 return 1;
 return 0;

 /* All other chunks that libpng knows about and affect neither image
       * interpretation nor libpng transforms - chunks that are effectively
       * unused by libpng even though libpng might recognize and store them.
       */
 case png_fRAc: case png_gIFg: case png_gIFt: case png_gIFx: case png_hIST:
 case png_iTXt: case png_oFFs: case png_pCAL: case png_pHYs: case png_sCAL:
 case png_sPLT: case png_sTER: case png_tEXt: case png_tIME: case png_zTXt:
 if (global->skip >= SKIP_UNUSED)
 return 1;
 return 0;

 /* Chunks that libpng does not know about (notice that this depends on the
       * list above including all known chunks!)  The decision here depends on
       * whether the safe-to-copy bit is set in the chunk type.
       */
 default:
 if (SAFE_TO_COPY(type))
 {
 if (global->skip >= SKIP_UNUSED) /* as above */
 return 1;
 }

 else if (global->skip >= SKIP_UNSAFE)
 return 1;

 return 0;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: unsigned FLAC__stream_decoder_get_input_bytes_unconsumed(const FLAC__StreamDecoder *decoder)
{
	FLAC__ASSERT(0 != decoder);
	FLAC__ASSERT(FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input));
	FLAC__ASSERT(!(FLAC__bitreader_get_input_bits_unconsumed(decoder->private_->input) & 7));
 return FLAC__bitreader_get_input_bits_unconsumed(decoder->private_->input) / 8;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_br_process_pairing_command(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = (uint8_t*)p_data;
 uint8_t reason = SMP_ENC_KEY_SIZE;
  tBTM_SEC_DEV_REC* p_dev_rec = btm_find_dev(p_cb->pairing_bda);

  SMP_TRACE_DEBUG("%s", __func__);
 /* rejecting BR pairing request over non-SC BR link */
 if (!p_dev_rec->new_encryption_key_is_p256 && p_cb->role == HCI_ROLE_SLAVE) {
    reason = SMP_XTRANS_DERIVE_NOT_ALLOW;
    smp_br_state_machine_event(p_cb, SMP_BR_AUTH_CMPL_EVT, &reason);
 return;
 }

 /* erase all keys if it is slave proc pairing req*/
 if (p_dev_rec && (p_cb->role == HCI_ROLE_SLAVE))
    btm_sec_clear_ble_keys(p_dev_rec);

  p_cb->flags |= SMP_PAIR_FLAG_ENC_AFTER_PAIR;

  STREAM_TO_UINT8(p_cb->peer_io_caps, p);
  STREAM_TO_UINT8(p_cb->peer_oob_flag, p);
  STREAM_TO_UINT8(p_cb->peer_auth_req, p);
  STREAM_TO_UINT8(p_cb->peer_enc_size, p);
  STREAM_TO_UINT8(p_cb->peer_i_key, p);
  STREAM_TO_UINT8(p_cb->peer_r_key, p);

 if (smp_command_has_invalid_parameters(p_cb)) {
    reason = SMP_INVALID_PARAMETERS;
    smp_br_state_machine_event(p_cb, SMP_BR_AUTH_CMPL_EVT, &reason);
 return;
 }

 /* peer (master) started pairing sending Pairing Request */
 /* or being master device always use received i/r key as keys to distribute */
  p_cb->local_i_key = p_cb->peer_i_key;
  p_cb->local_r_key = p_cb->peer_r_key;

 if (p_cb->role == HCI_ROLE_SLAVE) {
    p_dev_rec->new_encryption_key_is_p256 = false;
 /* shortcut to skip Security Grant step */
    p_cb->cb_evt = SMP_BR_KEYS_REQ_EVT;
 } else {
 /* Master receives pairing response */
    SMP_TRACE_DEBUG(
 "%s master rcvs valid PAIRING RESPONSE."
 " Supposed to move to key distribution phase. ",
        __func__);
 }

 /* auth_req received via BR/EDR SM channel is set to 0,
     but everything derived/exchanged has to be saved */
  p_cb->peer_auth_req |= SMP_AUTH_BOND;
  p_cb->loc_auth_req |= SMP_AUTH_BOND;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_process_secure_connection_long_term_key(void) {
  tSMP_CB* p_cb = &smp_cb;

  SMP_TRACE_DEBUG("%s", __func__);
  smp_save_secure_connections_long_term_key(p_cb);

  smp_update_key_mask(p_cb, SMP_SEC_KEY_TYPE_ENC, false);
  smp_key_distribution(p_cb, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: u32 h264bsdIsStartOfPicture(storage_t *pStorage)
{

/* Variables */


/* Code */

 if (pStorage->validSliceInAccessUnit == HANTRO_FALSE)
 return(HANTRO_TRUE);
 else
 return(HANTRO_FALSE);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void ReconfigureImpl(Handle<JSObject> object,
 Handle<FixedArrayBase> store, uint32_t entry,
 Handle<Object> value,
 PropertyAttributes attributes) {
 uint32_t length = static_cast<uint32_t>(GetString(*object)->length());
 if (entry < length) {
 return; // String contents can't be reconfigured.
 }
 BackingStoreAccessor::ReconfigureImpl(object, store, entry - length, value,
                                          attributes);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MetaData> OggExtractor::getTrackMetaData(
 size_t index, uint32_t /* flags */) {
 if (index >= 1) {
 return NULL;
 }

 return mImpl->getFormat();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: check_handling(display *d, int def, png_uint_32 chunks, png_uint_32 known,
   png_uint_32 unknown, const char *position, int set_callback)
{
 while (chunks)
 {
      png_uint_32 flag = chunks & -(png_int_32)chunks;
 int i = find_by_flag(flag);
 int keep = chunk_info[i].keep;
 const char *type;
 const char *errorx = NULL;

 if (chunk_info[i].unknown)
 {
 if (keep == PNG_HANDLE_CHUNK_AS_DEFAULT)
 {
            type = "UNKNOWN (default)";
            keep = def;
 }

 else
            type = "UNKNOWN (specified)";

 if (flag & known)
            errorx = "chunk processed";

 else switch (keep)
 {
 case PNG_HANDLE_CHUNK_AS_DEFAULT:
 if (flag & unknown)
                  errorx = "DEFAULT: unknown chunk saved";
 break;

 case PNG_HANDLE_CHUNK_NEVER:
 if (flag & unknown)
                  errorx = "DISCARD: unknown chunk saved";
 break;

 case PNG_HANDLE_CHUNK_IF_SAFE:
 if (ancillary(chunk_info[i].name))
 {
 if (!(flag & unknown))
                     errorx = "IF-SAFE: unknown ancillary chunk lost";
 }

 else if (flag & unknown)
                  errorx = "IF-SAFE: unknown critical chunk saved";
 break;

 case PNG_HANDLE_CHUNK_ALWAYS:
 if (!(flag & unknown))
                  errorx = "SAVE: unknown chunk lost";
 break;

 default:
               errorx = "internal error: bad keep";
 break;
 }
 } /* unknown chunk */

 else /* known chunk */
 {
         type = "KNOWN";

 if (flag & known)
 {
 /* chunk was processed, it won't have been saved because that is
             * caught below when checking for inconsistent processing.
             */
 if (keep != PNG_HANDLE_CHUNK_AS_DEFAULT)
               errorx = "!DEFAULT: known chunk processed";
 }

 else /* not processed */ switch (keep)
 {
 case PNG_HANDLE_CHUNK_AS_DEFAULT:
               errorx = "DEFAULT: known chunk not processed";
 break;

 case PNG_HANDLE_CHUNK_NEVER:
 if (flag & unknown)
                  errorx = "DISCARD: known chunk saved";
 break;

 case PNG_HANDLE_CHUNK_IF_SAFE:
 if (ancillary(chunk_info[i].name))
 {
 if (!(flag & unknown))
                     errorx = "IF-SAFE: known ancillary chunk lost";
 }

 else if (flag & unknown)
                  errorx = "IF-SAFE: known critical chunk saved";
 break;

 case PNG_HANDLE_CHUNK_ALWAYS:
 if (!(flag & unknown))
                  errorx = "SAVE: known chunk lost";
 break;

 default:
               errorx = "internal error: bad keep (2)";
 break;
 }
 }

 if (errorx != NULL)
 {
 ++(d->error_count);
         fprintf(stderr, "%s(%s%s): %s %s %s: %s\n", d->file, d->test,
            set_callback ? ",callback" : "",
            type, chunk_info[i].name, position, errorx);
 }

      chunks &= ~flag;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static bt_status_t get_protocol (bt_bdaddr_t *bd_addr, bthh_protocol_mode_t protocolMode)
{
    CHECK_BTHH_INIT();
 btif_hh_device_t *p_dev;
    BD_ADDR* bda = (BD_ADDR*) bd_addr;
    UNUSED(protocolMode);

    BTIF_TRACE_DEBUG(" addr = %02X:%02X:%02X:%02X:%02X:%02X",
 (*bda)[0], (*bda)[1], (*bda)[2], (*bda)[3], (*bda)[4], (*bda)[5]);

 if (btif_hh_cb.status == BTIF_HH_DISABLED) {
        BTIF_TRACE_ERROR("%s: Error, HH status = %d", __FUNCTION__, btif_hh_cb.status);
 return BT_STATUS_FAIL;
 }

    p_dev = btif_hh_find_connected_dev_by_bda(bd_addr);
 if (p_dev != NULL) {

        BTA_HhGetProtoMode(p_dev->dev_handle);
 }
 else {
 return BT_STATUS_FAIL;
 }
 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: tBTA_AV_RCB* bta_av_get_rcb_by_shdl(uint8_t shdl) {
  tBTA_AV_RCB* p_rcb = NULL;
 int i;

 for (i = 0; i < BTA_AV_NUM_RCB; i++) {
 if (bta_av_cb.rcb[i].shdl == shdl &&
        bta_av_cb.rcb[i].handle != BTA_AV_RC_HANDLE_NONE) {
      p_rcb = &bta_av_cb.rcb[i];
 break;
 }
 }
 return p_rcb;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: nsPush(xmlParserCtxtPtr ctxt, const xmlChar *prefix, const xmlChar *URL)
{
 if (ctxt->options & XML_PARSE_NSCLEAN) {
 int i;
 for (i = ctxt->nsNr - 2;i >= 0;i -= 2) {
 if (ctxt->nsTab[i] == prefix) {
 /* in scope */
 if (ctxt->nsTab[i + 1] == URL)
 return(-2);
 /* out of scope keep it */
 break;
 }
 }
 }
 if ((ctxt->nsMax == 0) || (ctxt->nsTab == NULL)) {
	ctxt->nsMax = 10;
	ctxt->nsNr = 0;
	ctxt->nsTab = (const xmlChar **)
	              xmlMalloc(ctxt->nsMax * sizeof(xmlChar *));
 if (ctxt->nsTab == NULL) {
	    xmlErrMemory(ctxt, NULL);
	    ctxt->nsMax = 0;
 return (-1);
 }
 } else if (ctxt->nsNr >= ctxt->nsMax) {
 const xmlChar ** tmp;
        ctxt->nsMax *= 2;
        tmp = (const xmlChar **) xmlRealloc((char *) ctxt->nsTab,
				    ctxt->nsMax * sizeof(ctxt->nsTab[0]));
 if (tmp == NULL) {
            xmlErrMemory(ctxt, NULL);
	    ctxt->nsMax /= 2;
 return (-1);
 }
	ctxt->nsTab = tmp;
 }
    ctxt->nsTab[ctxt->nsNr++] = prefix;
    ctxt->nsTab[ctxt->nsNr++] = URL;
 return (ctxt->nsNr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<FixedArray> CreateListFromArrayImpl(Isolate* isolate,
 Handle<JSArray> array) {
    UNREACHABLE();
 return Handle<FixedArray>();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t setConsumerUsageBits(uint32_t usage) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeUint32(usage);
 status_t result = remote()->transact(SET_CONSUMER_USAGE_BITS, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    size_t file_size() const { return file_size_; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::AudioOutput::getPlaybackRate(AudioPlaybackRate *rate)
{
    ALOGV("setPlaybackRate");
 Mutex::Autolock lock(mLock);
 if (mTrack == 0) {
 return NO_INIT;
 }
 *rate = mTrack->getPlaybackRate();
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MediaSource> ATSParser::Program::getSource(SourceType type) {
 size_t index = (type == AUDIO) ? 0 : 0;

 for (size_t i = 0; i < mStreams.size(); ++i) {
        sp<MediaSource> source = mStreams.editValueAt(i)->getSource(type);
 if (source != NULL) {
 if (index == 0) {
 return source;
 }
 --index;
 }
 }

 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static tBTM_STATUS btm_sec_send_hci_disconnect (tBTM_SEC_DEV_REC *p_dev_rec, UINT8 reason, UINT16 conn_handle)
{
    UINT8       old_state = p_dev_rec->sec_state;
    tBTM_STATUS status = BTM_CMD_STARTED;

    BTM_TRACE_EVENT ("btm_sec_send_hci_disconnect:  handle:0x%x, reason=0x%x",
                      conn_handle, reason);

 /* if some other thread disconnecting, we do not send second command */
 if (BTM_SEC_STATE_DISCONNECTING != old_state)
 {
        p_dev_rec->sec_state = BTM_SEC_STATE_DISCONNECTING;

#if BTM_DISC_DURING_RS == TRUE
 /* If a Role Switch is in progress, delay the HCI Disconnect to avoid controller problem (4329B1) */
 if (p_dev_rec->rs_disc_pending == BTM_SEC_RS_PENDING &&
             p_dev_rec->hci_handle == conn_handle)

 {
                 BTM_TRACE_DEBUG("RS in progress - Set DISC Pending flag in btm_sec_send_hci_disconnect to delay disconnect");
                 p_dev_rec->rs_disc_pending = BTM_SEC_DISC_PENDING;
                 status = BTM_SUCCESS;
 }
 else
#endif
 /* Tear down the HCI link */
 if (!btsnd_hcic_disconnect (conn_handle, reason))
 {
 /* could not send disconnect. restore old state */
            p_dev_rec->sec_state = old_state;
            status = BTM_NO_RESOURCES;
 }
 }
 return (status);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::AudioOutput::open(
 uint32_t sampleRate, int channelCount, audio_channel_mask_t channelMask,
 audio_format_t format, int bufferCount,
 AudioCallback cb, void *cookie,
 audio_output_flags_t flags,
 const audio_offload_info_t *offloadInfo,
 bool doNotReconnect,
 uint32_t suggestedFrameCount)
{
    ALOGV("open(%u, %d, 0x%x, 0x%x, %d, %d 0x%x)", sampleRate, channelCount, channelMask,
                format, bufferCount, mSessionId, flags);

 if (((flags & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != 0) &&
 ((cb == NULL) || (offloadInfo == NULL))) {
 return BAD_VALUE;
 }

 size_t frameCount;
 if ((flags & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != 0) {
        frameCount = 0; // AudioTrack will get frame count from AudioFlinger
 } else {
 uint32_t afSampleRate;
 size_t afFrameCount;
 if (AudioSystem::getOutputFrameCount(&afFrameCount, mStreamType) != NO_ERROR) {
 return NO_INIT;
 }
 if (AudioSystem::getOutputSamplingRate(&afSampleRate, mStreamType) != NO_ERROR) {
 return NO_INIT;
 }
 const size_t framesPerBuffer =
 (unsigned long long)sampleRate * afFrameCount / afSampleRate;

 if (bufferCount == 0) {
            bufferCount = (suggestedFrameCount + framesPerBuffer - 1) / framesPerBuffer;
 }
 if (bufferCount != 0 && bufferCount < mMinBufferCount) {
            ALOGV("bufferCount (%d) increased to %d", bufferCount, mMinBufferCount);
            bufferCount = mMinBufferCount;
 }
        frameCount = bufferCount * framesPerBuffer;
 }

 if (channelMask == CHANNEL_MASK_USE_CHANNEL_ORDER) {
        channelMask = audio_channel_out_mask_from_count(channelCount);
 if (0 == channelMask) {
            ALOGE("open() error, can\'t derive mask for %d audio channels", channelCount);
 return NO_INIT;
 }
 }

 Mutex::Autolock lock(mLock);
    mCallback = cb;
    mCallbackCookie = cookie;

 bool reuse = false;
 bool bothOffloaded = false;

 if (mRecycledTrack != 0) {
        bothOffloaded = (flags & mRecycledTrack->getFlags()
 & AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD) != 0;

        reuse = true;

 if ((mCallbackData == NULL && mCallback != NULL) ||
 (mCallbackData != NULL && mCallback == NULL)) {
            ALOGV("can't chain callback and write");
            reuse = false;
 } else if ((mRecycledTrack->getSampleRate() != sampleRate) ||
 (mRecycledTrack->channelCount() != (uint32_t)channelCount) ) {
            ALOGV("samplerate, channelcount differ: %u/%u Hz, %u/%d ch",
                  mRecycledTrack->getSampleRate(), sampleRate,
                  mRecycledTrack->channelCount(), channelCount);
            reuse = false;
 } else if (flags != mFlags) {
            ALOGV("output flags differ %08x/%08x", flags, mFlags);
            reuse = false;
 } else if (mRecycledTrack->format() != format) {
            reuse = false;
 }
 } else {
        ALOGV("no track available to recycle");
 }

    ALOGV_IF(bothOffloaded, "both tracks offloaded");

 if (bothOffloaded && !reuse) {
        ALOGV("both offloaded and not recycling");
        deleteRecycledTrack_l();
 }

    sp<AudioTrack> t;
 CallbackData *newcbd = NULL;


 if (!(reuse && bothOffloaded)) {
        ALOGV("creating new AudioTrack");

 if (mCallback != NULL) {
            newcbd = new CallbackData(this);
            t = new AudioTrack(
                    mStreamType,
                    sampleRate,
                    format,
                    channelMask,
                    frameCount,
                    flags,
 CallbackWrapper,
                    newcbd,
 0, // notification frames
                    mSessionId,
 AudioTrack::TRANSFER_CALLBACK,
                    offloadInfo,
                    mUid,
                    mPid,
                    mAttributes,
                    doNotReconnect);
 } else {
 const float targetSpeed =
                    std::min(std::max(mPlaybackRate.mSpeed, 1.0f), kMaxRequiredSpeed);
            ALOGW_IF(targetSpeed != mPlaybackRate.mSpeed,
 "track target speed:%f clamped from playback speed:%f",
                    targetSpeed, mPlaybackRate.mSpeed);
            t = new AudioTrack(
                    mStreamType,
                    sampleRate,
                    format,
                    channelMask,
                    frameCount,
                    flags,
                    NULL, // callback
                    NULL, // user data
 0, // notification frames
                    mSessionId,
 AudioTrack::TRANSFER_DEFAULT,
                    NULL, // offload info
                    mUid,
                    mPid,
                    mAttributes,
                    doNotReconnect,
                    targetSpeed);
 }

 if ((t == 0) || (t->initCheck() != NO_ERROR)) {
            ALOGE("Unable to create audio track");
 delete newcbd;
 return NO_INIT;
 } else {
            mStreamType = t->streamType();
 }
 }

 if (reuse) {
        CHECK(mRecycledTrack != NULL);

 if (!bothOffloaded) {
 if (mRecycledTrack->frameCount() != t->frameCount()) {
                ALOGV("framecount differs: %zu/%zu frames",
                      mRecycledTrack->frameCount(), t->frameCount());
                reuse = false;
 }
 }

 if (reuse) {
            ALOGV("chaining to next output and recycling track");
            close_l();
            mTrack = mRecycledTrack;
            mRecycledTrack.clear();
 if (mCallbackData != NULL) {
                mCallbackData->setOutput(this);
 }
 delete newcbd;
 return OK;
 }
 }

 if (!bothOffloaded) {
        deleteRecycledTrack_l();
 }

    CHECK((t != NULL) && ((mCallback == NULL) || (newcbd != NULL)));

    mCallbackData = newcbd;
    ALOGV("setVolume");
    t->setVolume(mLeftVolume, mRightVolume);

    mSampleRateHz = sampleRate;
    mFlags = flags;
    mMsecsPerFrame = 1E3f / (mPlaybackRate.mSpeed * sampleRate);
    mFrameSize = t->frameSize();
    mTrack = t;

 status_t res = NO_ERROR;
 if ((t->getFlags() & (AUDIO_OUTPUT_FLAG_COMPRESS_OFFLOAD | AUDIO_OUTPUT_FLAG_DIRECT)) == 0) {
        res = t->setPlaybackRate(mPlaybackRate);
 if (res == NO_ERROR) {
            t->setAuxEffectSendLevel(mSendLevel);
            res = t->attachAuxEffect(mAuxEffectId);
 }
 }
    ALOGV("open() DONE status %d", res);
 return res;
}

Labels: No
----------------lora model----------------
Response: bool</s>


Instruction: 
Input: SoftVorbis::SoftVorbis(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mInputBufferCount(0),
      mState(NULL),
      mVi(NULL),
      mAnchorTimeUs(0),
      mNumFramesOutput(0),
      mNumFramesLeftOnPage(-1),
      mSawInputEos(false),
      mSignalledOutputEos(false),
      mOutputPortSettingsChange(NONE) {
    initPorts();
    CHECK_EQ(initDecoder(), (status_t)OK);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::parseChunk(off64_t *offset) {
 uint32_t hdr[2];
 if (mDataSource->readAt(*offset, hdr, 8) < 8) {
 return ERROR_IO;
 }
 uint64_t chunk_size = ntohl(hdr[0]);
 uint32_t chunk_type = ntohl(hdr[1]);
 off64_t data_offset = *offset + 8;

 if (chunk_size == 1) {
 if (mDataSource->readAt(*offset + 8, &chunk_size, 8) < 8) {
 return ERROR_IO;
 }
        chunk_size = ntoh64(chunk_size);
        data_offset += 8;

 if (chunk_size < 16) {
 return ERROR_MALFORMED;
 }
 } else if (chunk_size < 8) {
 return ERROR_MALFORMED;
 }

 char chunk[5];
 MakeFourCCString(chunk_type, chunk);
    ALOGV("MPEG4Source chunk %s @ %#llx", chunk, (long long)*offset);

 off64_t chunk_data_size = *offset + chunk_size - data_offset;

 switch(chunk_type) {

 case FOURCC('t', 'r', 'a', 'f'):
 case FOURCC('m', 'o', 'o', 'f'): {
 off64_t stop_offset = *offset + chunk_size;
 *offset = data_offset;
 while (*offset < stop_offset) {
 status_t err = parseChunk(offset);
 if (err != OK) {
 return err;
 }
 }
 if (chunk_type == FOURCC('m', 'o', 'o', 'f')) {

 while (true) {
 if (mDataSource->readAt(*offset, hdr, 8) < 8) {
 break;
 }
                    chunk_size = ntohl(hdr[0]);
                    chunk_type = ntohl(hdr[1]);
 if (chunk_size == 1) {
 if (mDataSource->readAt(*offset + 8, &chunk_size, 8) < 8) {
 return ERROR_IO;
 }
                        chunk_size = ntoh64(chunk_size);
 if (chunk_size < 16) {
 return ERROR_MALFORMED;
 }
 } else if (chunk_size == 0) {
 } else if (chunk_size < 8) {
 return ERROR_MALFORMED;
 }

 if (chunk_type == FOURCC('m', 'o', 'o', 'f')) {
                        mNextMoofOffset = *offset;
 break;
 } else if (chunk_size == 0) {
 break;
 }
 *offset += chunk_size;
 }
 }
 break;
 }

 case FOURCC('t', 'f', 'h', 'd'): {
 status_t err;
 if ((err = parseTrackFragmentHeader(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }

 case FOURCC('t', 'r', 'u', 'n'): {
 status_t err;
 if (mLastParsedTrackId == mTrackId) {
 if ((err = parseTrackFragmentRun(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 }

 *offset += chunk_size;
 break;
 }

 case FOURCC('s', 'a', 'i', 'z'): {
 status_t err;
 if ((err = parseSampleAuxiliaryInformationSizes(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }
 case FOURCC('s', 'a', 'i', 'o'): {
 status_t err;
 if ((err = parseSampleAuxiliaryInformationOffsets(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }

 case FOURCC('m', 'd', 'a', 't'): {
            ALOGV("MPEG4Source::parseChunk mdat");
 *offset += chunk_size;
 break;
 }

 default: {
 *offset += chunk_size;
 break;
 }
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftRaw::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.raw",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            mChannelCount = pcmParams->nChannels;
            mSampleRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::processSecurityPolicy(int32_t transformId, int32_t direction,
 const std::string& localAddress,
 const std::string& remoteAddress,
 int32_t spi, int32_t markValue,
 int32_t markMask, int32_t msgType) {
    ALOGD("XfrmController::%s, line=%d", __FUNCTION__, __LINE__);
    ALOGD("transformId=%d", transformId);
    ALOGD("direction=%d", direction);
    ALOGD("localAddress=%s", localAddress.c_str());
    ALOGD("remoteAddress=%s", remoteAddress.c_str());
    ALOGD("spi=%0.8x", spi);
    ALOGD("markValue=%d", markValue);
    ALOGD("markMask=%d", markMask);
    ALOGD("msgType=%d", msgType);

 XfrmSaInfo saInfo{};
    saInfo.mode = XfrmMode::TUNNEL;

 XfrmSocketImpl sock;
    RETURN_IF_NOT_OK(sock.open());

    RETURN_IF_NOT_OK(
        fillXfrmId(localAddress, remoteAddress, spi, markValue, markMask, transformId, &saInfo));

 if (msgType == XFRM_MSG_DELPOLICY) {
 return deleteTunnelModeSecurityPolicy(saInfo, sock, static_cast<XfrmDirection>(direction));
 } else {
 return updateTunnelModeSecurityPolicy(saInfo, sock, static_cast<XfrmDirection>(direction),
                                              msgType);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE OMXNodeInstance::OnFillBufferDone(
        OMX_IN OMX_HANDLETYPE /* hComponent */,
        OMX_IN OMX_PTR pAppData,
        OMX_IN OMX_BUFFERHEADERTYPE* pBuffer) {
 if (pAppData == NULL) {
        ALOGE("b/25884056");
 return OMX_ErrorBadParameter;
 }
 OMXNodeInstance *instance = static_cast<OMXNodeInstance *>(pAppData);
 if (instance->mDying) {
 return OMX_ErrorNone;
 }
 int fenceFd = instance->retrieveFenceFromMeta_l(pBuffer, kPortIndexOutput);
 return instance->owner()->OnFillBufferDone(instance->nodeID(),
            instance->findBufferID(pBuffer), pBuffer, fenceFd);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_parse_sei(codec_t *ps_codec)
{
    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    UNUSED(ps_codec);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::sNotify(const camera3_callback_ops *cb,
 const camera3_notify_msg *msg) {
 Camera3Device *d =
 const_cast<Camera3Device*>(static_cast<const Camera3Device*>(cb));
    d->notify(msg);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftFlacEncoder::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
    ALOGV("SoftFlacEncoder::internalGetParameter(index=0x%x)", index);

 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }


         case OMX_IndexParamAudioFlac:
         {
             OMX_AUDIO_PARAM_FLACTYPE *flacParams = (OMX_AUDIO_PARAM_FLACTYPE *)params;
             flacParams->nCompressionLevel = mCompressionLevel;
             flacParams->nChannels = mNumChannels;
             flacParams->nSampleRate = mSampleRate;
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundPool::addToRestartList(SoundChannel* channel)
{
 Mutex::Autolock lock(&mRestartLock);
 if (!mQuit) {
        mRestart.push_back(channel);
        mCondition.signal();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int release_buffers(omx_vdec* obj, enum vdec_buffer buffer_type)
{
 struct v4l2_requestbuffers bufreq;
 int rc = 0;
 if (buffer_type == VDEC_BUFFER_TYPE_OUTPUT) {
        bufreq.memory = V4L2_MEMORY_USERPTR;
        bufreq.count = 0;
        bufreq.type=V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
        rc = ioctl(obj->drv_ctx.video_driver_fd,VIDIOC_REQBUFS, &bufreq);
 } else if(buffer_type == VDEC_BUFFER_TYPE_INPUT) {
        bufreq.memory = V4L2_MEMORY_USERPTR;
        bufreq.count = 0;
        bufreq.type=V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
        rc = ioctl(obj->drv_ctx.video_driver_fd,VIDIOC_REQBUFS, &bufreq);
 }
 return rc;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaRecorder::release()
{
    ALOGV("release");
 if (mMediaRecorder != NULL) {
 return mMediaRecorder->release();
 }
 return INVALID_OPERATION;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int32_t DownmixLib_Create(const effect_uuid_t *uuid,
 int32_t sessionId __unused,
 int32_t ioId __unused,
 effect_handle_t *pHandle) {
 int ret;
 int i;
 downmix_module_t *module;
 const effect_descriptor_t *desc;

    ALOGV("DownmixLib_Create()");

#ifdef DOWNMIX_TEST_CHANNEL_INDEX
    ALOGI("DOWNMIX_TEST_CHANNEL_INDEX: should work:");
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                    AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_BACK_CENTER);
 Downmix_testIndexComputation(CHANNEL_MASK_QUAD_SIDE | CHANNEL_MASK_QUAD_BACK);
 Downmix_testIndexComputation(CHANNEL_MASK_5POINT1_SIDE | AUDIO_CHANNEL_OUT_BACK_CENTER);
 Downmix_testIndexComputation(CHANNEL_MASK_5POINT1_BACK | AUDIO_CHANNEL_OUT_BACK_CENTER);
    ALOGI("DOWNMIX_TEST_CHANNEL_INDEX: should NOT work:");
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                        AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_BACK_LEFT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                            AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_SIDE_LEFT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT |
                        AUDIO_CHANNEL_OUT_BACK_LEFT | AUDIO_CHANNEL_OUT_BACK_RIGHT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT |
                            AUDIO_CHANNEL_OUT_SIDE_LEFT | AUDIO_CHANNEL_OUT_SIDE_RIGHT);
#endif

 if (pHandle == NULL || uuid == NULL) {
 return -EINVAL;
 }

 for (i = 0 ; i < kNbEffects ; i++) {
        desc = gDescriptors[i];
 if (memcmp(uuid, &desc->uuid, sizeof(effect_uuid_t)) == 0) {
 break;
 }
 }

 if (i == kNbEffects) {
 return -ENOENT;
 }

    module = malloc(sizeof(downmix_module_t));

    module->itfe = &gDownmixInterface;

    module->context.state = DOWNMIX_STATE_UNINITIALIZED;

    ret = Downmix_Init(module);
 if (ret < 0) {
        ALOGW("DownmixLib_Create() init failed");
        free(module);
 return ret;
 }

 *pHandle = (effect_handle_t) module;

    ALOGV("DownmixLib_Create() %p , size %zu", module, sizeof(downmix_module_t));

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void convertTimeToDate(int64_t time_1904, String8 *s) {
 time_t time_1970 = time_1904 - (((66 * 365 + 17) * 24) * 3600);

 char tmp[32];
    strftime(tmp, sizeof(tmp), "%Y%m%dT%H%M%S.000Z", gmtime(&time_1970));

    s->setTo(tmp);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const BlockEntry* Cues::GetBlock(
    const CuePoint* pCP,
    const CuePoint::TrackPosition* pTP) const
{
    if (pCP == NULL)
        return NULL;
 
    if (pTP == NULL)
        return NULL;
    return m_pSegment->GetBlock(*pCP, *pTP);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void config_free(config_t *config) {
 if (!config)
 return;

  list_free(config->sections);
  osi_free(config);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: random_color(png_colorp color)
{
 static png_uint_32 color_seed[2] = { 0x12345678, 0x9abcdef };
   make_random_bytes(color_seed, color, sizeof *color);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readUtf8FromUtf16(std::string* str) const {
 size_t utf16Size = 0;
 const char16_t* src = readString16Inplace(&utf16Size);
 if (!src) {
 return UNEXPECTED_NULL;
 }

 if (utf16Size == 0u) {
        str->clear();

        return NO_ERROR;
     }
 
    ssize_t utf8Size = utf16_to_utf8_length(src, utf16Size);
    if (utf8Size < 0) {
         return BAD_VALUE;
     }
    str->resize(utf8Size + 1);
    utf16_to_utf8(src, utf16Size, &((*str)[0]));
     str->resize(utf8Size);
     return NO_ERROR;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean android_net_wifi_doBooleanCommand(JNIEnv* env, jobject, jstring javaCommand) {
 return doBooleanCommand(env, javaCommand);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::ensureCacheIsFetching() {
 if (mCachedSource != NULL) {
        mCachedSource->resumeFetchingIfNecessary();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int bta_co_rfc_data_incoming(void *user_data, BT_HDR *p_buf) {
  pthread_mutex_lock(&slot_lock);

 int ret = 0;
 uint32_t id = (uintptr_t)user_data;
 rfc_slot_t *slot = find_rfc_slot_by_id(id);
 if (!slot)
 goto out;

 if (list_is_empty(slot->incoming_queue)) {
 switch (send_data_to_app(slot->fd, p_buf)) {
 case SENT_NONE:
 case SENT_PARTIAL:
        list_append(slot->incoming_queue, p_buf);
        btsock_thread_add_fd(pth, slot->fd, BTSOCK_RFCOMM, SOCK_THREAD_FD_WR, slot->id);
 break;

 case SENT_ALL:
        GKI_freebuf(p_buf);
        ret = 1; // Enable data flow.
 break;

 case SENT_FAILED:
        GKI_freebuf(p_buf);
        cleanup_rfc_slot(slot);
 break;
 }
 } else {
    list_append(slot->incoming_queue, p_buf);
 }

out:;
  pthread_mutex_unlock(&slot_lock);
 return ret; // Return 0 to disable data flow.
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_ble_test_end_cback(void *p)
{
    btif_transfer_context(btif_dm_generic_evt, BTIF_DM_CB_LE_TEST_END,
 (char *)p, 3, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Cluster::GetTimeCode() const {
 long long pos;
 long len;

 const long status = Load(pos, len);

 if (status < 0) // error
 return status;

 return m_timecode;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Session_GetConfig(preproc_session_t *session, effect_config_t *config)
{
    memset(config, 0, sizeof(effect_config_t));
    config->inputCfg.samplingRate = config->outputCfg.samplingRate = session->samplingRate;
    config->inputCfg.format = config->outputCfg.format = AUDIO_FORMAT_PCM_16_BIT;
    config->inputCfg.channels = audio_channel_in_mask_from_count(session->inChannelCount);
    config->outputCfg.channels = audio_channel_in_mask_from_count(session->outChannelCount);
    config->inputCfg.mask = config->outputCfg.mask =
 (EFFECT_CONFIG_SMP_RATE | EFFECT_CONFIG_CHANNELS | EFFECT_CONFIG_FORMAT);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_metadata_vorbiscomment_(FLAC__StreamDecoder *decoder, FLAC__StreamMetadata_VorbisComment *obj, unsigned length)
{
	FLAC__uint32 i;

	FLAC__ASSERT(FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input));

 /* read vendor string */
 if (length >= 8) {
		length -= 8; /* vendor string length + num comments entries alone take 8 bytes */
		FLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_ENTRY_LENGTH_LEN == 32);
 if (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->vendor_string.length))
 return false; /* read_callback_ sets the state for us */
 if (obj->vendor_string.length > 0) {
 if (length < obj->vendor_string.length) {
				obj->vendor_string.length = 0;
				obj->vendor_string.entry = 0;
 goto skip;
 }
 else
				length -= obj->vendor_string.length;
 if (0 == (obj->vendor_string.entry = safe_malloc_add_2op_(obj->vendor_string.length, /*+*/1))) {
				decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 return false;
 }
 if (!FLAC__bitreader_read_byte_block_aligned_no_crc(decoder->private_->input, obj->vendor_string.entry, obj->vendor_string.length))
 return false; /* read_callback_ sets the state for us */
			obj->vendor_string.entry[obj->vendor_string.length] = '\0';
 }
 else
			obj->vendor_string.entry = 0;

 /* read num comments */
		FLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_NUM_COMMENTS_LEN == 32);
 if (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->num_comments))
 return false; /* read_callback_ sets the state for us */

 /* read comments */
 if (obj->num_comments > 100000) {
 /* Possibly malicious file. */
			obj->num_comments = 0;
 return false;
 }

 		if (obj->num_comments > 0) {
 			if (0 == (obj->comments = safe_malloc_mul_2op_p(obj->num_comments, /*times*/sizeof(FLAC__StreamMetadata_VorbisComment_Entry)))) {
 				decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 				return false;
 			}
 			for (i = 0; i < obj->num_comments; i++) {
 /* Initialize here just to make sure. */
				obj->comments[i].length = 0;
				obj->comments[i].entry = 0;

				FLAC__ASSERT(FLAC__STREAM_METADATA_VORBIS_COMMENT_ENTRY_LENGTH_LEN == 32);
 if (length < 4) {
					obj->num_comments = i;
 goto skip;
 }
 else
					length -= 4;
 if (!FLAC__bitreader_read_uint32_little_endian(decoder->private_->input, &obj->comments[i].length))
 return false; /* read_callback_ sets the state for us */
 if (obj->comments[i].length > 0) {
 if (length < obj->comments[i].length) {
						obj->num_comments = i;
 goto skip;
 }
 else
						length -= obj->comments[i].length;
 if (0 == (obj->comments[i].entry = safe_malloc_add_2op_(obj->comments[i].length, /*+*/1))) {
						decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 return false;
 }
					memset (obj->comments[i].entry, 0, obj->comments[i].length) ;
 if (!FLAC__bitreader_read_byte_block_aligned_no_crc(decoder->private_->input, obj->comments[i].entry, obj->comments[i].length)) {
						obj->num_comments = i;
 goto skip;
 }
					obj->comments[i].entry[obj->comments[i].length] = '\0';
 }
 else
					obj->comments[i].entry = 0;
 }
 }
 else
			obj->comments = 0;
 }

  skip:
 if (length > 0) {
 /* This will only happen on files with invalid data in comments */
 if(!FLAC__bitreader_skip_byte_block_aligned_no_crc(decoder->private_->input, length))
 return false; /* read_callback_ sets the state for us */
 }

 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static uint32_t readU32(const uint8_t* data, size_t offset) {
    return data[offset] << 24 | data[offset + 1] << 16 | data[offset + 2] << 8 | data[offset + 3];
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void on_firmware_memory_dump(char *buffer, int buffer_size) {

 JNIHelper helper(mVM);
 /* ALOGD("on_firmware_memory_dump called, vm = %p, obj = %p, env = %p buffer_size = %d"
            , mVM, mCls, env, buffer_size); */

 if (buffer_size > 0) {
 JNIObject<jbyteArray> dump = helper.newByteArray(buffer_size);
        jbyte *bytes = (jbyte *) (buffer);
        helper.setByteArrayRegion(dump, 0, buffer_size, bytes);
        helper.reportEvent(mCls,"onWifiFwMemoryAvailable","([B)V", dump.get());
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void SetUp() {
 InitializeConfig();
 SetMode(GET_PARAM(1));
    set_cpu_used_ = GET_PARAM(2);
 ResetModel();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_dec_seq_hdr(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    ps_stream = &ps_dec->s_bit_stream;
    UWORD16 u2_height;
    UWORD16 u2_width;

 if (impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN) != SEQUENCE_HEADER_CODE)
 {
        impeg2d_bit_stream_flush(ps_stream,START_CODE_LEN);
 return IMPEG2D_FRM_HDR_START_CODE_NOT_FOUND;

 }
    impeg2d_bit_stream_flush(ps_stream,START_CODE_LEN);

    u2_width    = impeg2d_bit_stream_get(ps_stream,12);
    u2_height   = impeg2d_bit_stream_get(ps_stream,12);

 if ((u2_width != ps_dec->u2_horizontal_size)
 || (u2_height != ps_dec->u2_vertical_size))
 {
 if (0 == ps_dec->u2_header_done)
 {
 /* This is the first time we are reading the resolution */
            ps_dec->u2_horizontal_size = u2_width;
            ps_dec->u2_vertical_size = u2_height;
 if (0 == ps_dec->u4_frm_buf_stride)
 {
                ps_dec->u4_frm_buf_stride  = (UWORD32) ALIGN16(u2_width);
 }
 }
 else
 {
 if((u2_width > ps_dec->u2_create_max_width)
 || (u2_height > ps_dec->u2_create_max_height))
 {
                IMPEG2D_ERROR_CODES_T e_error = IMPEG2D_UNSUPPORTED_DIMENSIONS;

                ps_dec->u2_reinit_max_height   = u2_height;
                ps_dec->u2_reinit_max_width    = u2_width;

 return e_error;
 }
 else
 {
 /* The resolution has changed */
 return (IMPEG2D_ERROR_CODES_T)IVD_RES_CHANGED;
 }
 }
 }

 if((ps_dec->u2_horizontal_size > ps_dec->u2_create_max_width)
 || (ps_dec->u2_vertical_size > ps_dec->u2_create_max_height))
 {
        IMPEG2D_ERROR_CODES_T e_error = IMPEG2D_UNSUPPORTED_DIMENSIONS;
 return SET_IVD_FATAL_ERROR(e_error);
 }


 /*------------------------------------------------------------------------*/
 /* Flush the following as they are not being used                         */
 /* aspect_ratio_info (4 bits)                                             */
 /*------------------------------------------------------------------------*/
    ps_dec->u2_aspect_ratio_info = impeg2d_bit_stream_get(ps_stream,4);

 /*------------------------------------------------------------------------*/

     /* Frame rate code(4 bits)                                                */
     /*------------------------------------------------------------------------*/
     ps_dec->u2_frame_rate_code = impeg2d_bit_stream_get(ps_stream,4);
     /*------------------------------------------------------------------------*/
     /* Flush the following as they are not being used                         */
     /* bit_rate_value (18 bits)                                               */
 /*------------------------------------------------------------------------*/
    impeg2d_bit_stream_flush(ps_stream,18);
    GET_MARKER_BIT(ps_dec,ps_stream);
 /*------------------------------------------------------------------------*/
 /* Flush the following as they are not being used                         */
 /* vbv_buffer_size_value(10 bits), constrained_parameter_flag (1 bit)     */
 /*------------------------------------------------------------------------*/
    impeg2d_bit_stream_flush(ps_stream,11);

 /*------------------------------------------------------------------------*/
 /* Quantization matrix for the intra blocks                               */
 /*------------------------------------------------------------------------*/
 if(impeg2d_bit_stream_get_bit(ps_stream) == 1)
 {
        UWORD16 i;
 for(i = 0; i < NUM_PELS_IN_BLOCK; i++)
 {
            ps_dec->au1_intra_quant_matrix[gau1_impeg2_inv_scan_zig_zag[i]] = (UWORD8)impeg2d_bit_stream_get(ps_stream,8);
 }

 }
 else
 {
        memcpy(ps_dec->au1_intra_quant_matrix,gau1_impeg2_intra_quant_matrix_default,
                NUM_PELS_IN_BLOCK);
 }

 /*------------------------------------------------------------------------*/
 /* Quantization matrix for the inter blocks                               */
 /*------------------------------------------------------------------------*/
 if(impeg2d_bit_stream_get_bit(ps_stream) == 1)
 {
        UWORD16 i;
 for(i = 0; i < NUM_PELS_IN_BLOCK; i++)
 {
            ps_dec->au1_inter_quant_matrix[gau1_impeg2_inv_scan_zig_zag[i]] = (UWORD8)impeg2d_bit_stream_get(ps_stream,8);
 }
 }
 else
 {
        memcpy(ps_dec->au1_inter_quant_matrix,gau1_impeg2_inter_quant_matrix_default,
            NUM_PELS_IN_BLOCK);
 }
    impeg2d_next_start_code(ps_dec);

 return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseGetLasts(xmlParserCtxtPtr ctxt, const xmlChar **lastlt,
 const xmlChar **lastgt) {
 const xmlChar *tmp;

 if ((ctxt == NULL) || (lastlt == NULL) || (lastgt == NULL)) {
	xmlGenericError(xmlGenericErrorContext,
 "Internal error: xmlParseGetLasts\n");
 return;
 }
 if ((ctxt->progressive != 0) && (ctxt->inputNr == 1)) {
        tmp = ctxt->input->end;
	tmp--;
 while ((tmp >= ctxt->input->base) && (*tmp != '<')) tmp--;
 if (tmp < ctxt->input->base) {
 *lastlt = NULL;
 *lastgt = NULL;
 } else {
 *lastlt = tmp;
	    tmp++;
 while ((tmp < ctxt->input->end) && (*tmp != '>')) {
 if (*tmp == '\'') {
		    tmp++;
 while ((tmp < ctxt->input->end) && (*tmp != '\'')) tmp++;
 if (tmp < ctxt->input->end) tmp++;
 } else if (*tmp == '"') {
		    tmp++;
 while ((tmp < ctxt->input->end) && (*tmp != '"')) tmp++;
 if (tmp < ctxt->input->end) tmp++;
 } else
		    tmp++;
 }
 if (tmp < ctxt->input->end)
 *lastgt = tmp;
 else {
	        tmp = *lastlt;
		tmp--;
 while ((tmp >= ctxt->input->base) && (*tmp != '>')) tmp--;
 if (tmp >= ctxt->input->base)
 *lastgt = tmp;
 else
 *lastgt = NULL;
 }
 }
 } else {
 *lastlt = NULL;
 *lastgt = NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gp_g8(Pixel *p, png_const_voidp pb)
{
   png_const_bytep pp = voidcast(png_const_bytep, pb);

   p->r = p->g = p->b = pp[0];
   p->a = 255;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::allocateSecureBuffer(
        OMX_U32 portIndex, size_t size, OMX::buffer_id *buffer,
 void **buffer_data, sp<NativeHandle> *native_handle) {
 if (buffer == NULL || buffer_data == NULL || native_handle == NULL) {
        ALOGE("b/25884056");

         return BAD_VALUE;
     }
 
     Mutex::Autolock autoLock(mLock);
 
     BufferMeta *buffer_meta = new BufferMeta(size, portIndex);

    OMX_BUFFERHEADERTYPE *header;

    OMX_ERRORTYPE err = OMX_AllocateBuffer(
            mHandle, &header, portIndex, buffer_meta, size);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(allocateBuffer, err, BUFFER_FMT(portIndex, "%zu@", size));
 delete buffer_meta;
        buffer_meta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, buffer_meta);

 *buffer = makeBufferID(header);
 if (mSecureBufferType[portIndex] == kSecureBufferTypeNativeHandle) {
 *buffer_data = NULL;
 *native_handle = NativeHandle::create(
 (native_handle_t *)header->pBuffer, false /* ownsHandle */);
 } else {
 *buffer_data = header->pBuffer;
 *native_handle = NULL;
 }

    addActiveBuffer(portIndex, *buffer);

    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && portIndex == kPortIndexInput) {
        bufferSource->addCodecBuffer(header);
 }
    CLOG_BUFFER(allocateSecureBuffer, NEW_BUFFER_FMT(
 *buffer, portIndex, "%zu@%p:%p", size, *buffer_data,
 *native_handle == NULL ? NULL : (*native_handle)->handle()));

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ACodec::BaseState::BaseState(ACodec *codec, const sp<AState> &parentState)
 : AState(parentState),
      mCodec(codec) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void SetUp() {
 AllocationTestHarness::SetUp();
      pipe(pipefd);
      done = semaphore_new(0);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ACodec::LoadedState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case ACodec::kWhatConfigureComponent:
 {
            onConfigureComponent(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatCreateInputSurface:
 {
            onCreateInputSurface(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatSetInputSurface:
 {
            onSetInputSurface(msg);
            handled = true;
 break;
 }

 case ACodec::kWhatStart:
 {
            onStart();
            handled = true;
 break;
 }

 case ACodec::kWhatShutdown:
 {
 int32_t keepComponentAllocated;
            CHECK(msg->findInt32(
 "keepComponentAllocated", &keepComponentAllocated));

            mCodec->mExplicitShutdown = true;
            onShutdown(keepComponentAllocated);

            handled = true;
 break;
 }

 case ACodec::kWhatFlush:
 {
            sp<AMessage> notify = mCodec->mNotify->dup();
            notify->setInt32("what", CodecBase::kWhatFlushCompleted);
            notify->post();

            handled = true;
 break;
 }

 default:
 return BaseState::onMessageReceived(msg);
 }

 return handled;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void fdct16x16_ref(const int16_t *in, int16_t *out, int stride, int tx_type) {
  vp9_fdct16x16_c(in, out, stride);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SimpleSoftOMXComponent::getState(OMX_STATETYPE *state) {
 Mutex::Autolock autoLock(mLock);

 *state = mState;

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::initNativeWindow() {
 if (mNativeWindow != NULL) {
 return mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_TRUE);
 }

    mOMX->enableGraphicBuffers(mNode, kPortIndexOutput, OMX_FALSE);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void lock_buffer_pool(BufferPool *const pool) {
#if CONFIG_MULTITHREAD
  pthread_mutex_lock(&pool->pool_mutex);
#else
 (void)pool;
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int touch(char* path, mode_t mode) {
 int fd = open(path, O_RDWR | O_CREAT | O_EXCL | O_NOFOLLOW, mode);
 if (fd == -1) {
 if (errno == EEXIST) {
 return 0;
 } else {
            ERROR("Failed to open(%s): %s\n", path, strerror(errno));
 return -1;
 }
 }
    close(fd);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool isDebuggable() {
 char debuggable[PROP_VALUE_MAX];
    property_get("ro.debuggable", debuggable, "0");
 if (strcmp(debuggable, "1") == 0) {
 return true;
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jobject Bitmap_creator(JNIEnv* env, jobject, jintArray jColors,
                              jint offset, jint stride, jint width, jint height,
                              jint configHandle, jboolean isMutable) {
 SkColorType colorType = GraphicsJNI::legacyBitmapConfigToColorType(configHandle);
 if (NULL != jColors) {
 size_t n = env->GetArrayLength(jColors);
 if (n < SkAbs32(stride) * (size_t)height) {
            doThrowAIOOBE(env);
 return NULL;
 }
 }

 if (colorType == kARGB_4444_SkColorType) {
        colorType = kN32_SkColorType;
 }

 SkBitmap bitmap;
    bitmap.setInfo(SkImageInfo::Make(width, height, colorType, kPremul_SkAlphaType));

    jbyteArray buff = GraphicsJNI::allocateJavaPixelRef(env, &bitmap, NULL);
 if (NULL == buff) {
 return NULL;
 }

 if (jColors != NULL) {
 GraphicsJNI::SetPixels(env, jColors, offset, stride,
 0, 0, width, height, bitmap);
 }

 return GraphicsJNI::createBitmap(env, new SkBitmap(bitmap), buff,
            getPremulBitmapCreateFlags(isMutable), NULL, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Backtrace::Backtrace(pid_t pid, pid_t tid, BacktraceMap* map)
 : pid_(pid), tid_(tid), map_(map), map_shared_(true) {
 if (map_ == nullptr) {
    map_ = BacktraceMap::Create(pid);
    map_shared_ = false;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  BufferMeta(const sp<GraphicBuffer> &graphicBuffer, OMX_U32 portIndex)
 : mGraphicBuffer(graphicBuffer),
          mCopyFromOmx(false),
          mCopyToOmx(false),
          mPortIndex(portIndex),
          mBackup(NULL) {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_venc::dev_get_seq_hdr(void *buffer, unsigned size, unsigned *hdrlen)
{
 return handle->venc_get_seq_hdr(buffer, size, hdrlen);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dump_thread_info(log_t* log, pid_t pid, pid_t tid) {
 char path[64];
 char threadnamebuf[1024];
 char* threadname = NULL;
 FILE *fp;

  snprintf(path, sizeof(path), "/proc/%d/comm", tid);
 if ((fp = fopen(path, "r"))) {
    threadname = fgets(threadnamebuf, sizeof(threadnamebuf), fp);
    fclose(fp);
 if (threadname) {
 size_t len = strlen(threadname);
 if (len && threadname[len - 1] == '\n') {
        threadname[len - 1] = '\0';
 }
 }
 }
 static const char logd[] = "logd";
 if (!strncmp(threadname, logd, sizeof(logd) - 1)
 && (!threadname[sizeof(logd) - 1] || (threadname[sizeof(logd) - 1] == '.'))) {
    log->should_retrieve_logcat = false;
 }

 char procnamebuf[1024];
 char* procname = NULL;

  snprintf(path, sizeof(path), "/proc/%d/cmdline", pid);
 if ((fp = fopen(path, "r"))) {
    procname = fgets(procnamebuf, sizeof(procnamebuf), fp);
    fclose(fp);
 }

  _LOG(log, logtype::HEADER, "pid: %d, tid: %d, name: %s  >>> %s <<<\n", pid, tid,
       threadname ? threadname : "UNKNOWN", procname ? procname : "UNKNOWN");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseITunesMetaData(off64_t offset, size_t size) {
 if (size < 4 || size == SIZE_MAX) {
 return ERROR_MALFORMED;
 }

 uint8_t *buffer = new (std::nothrow) uint8_t[size + 1];
 if (buffer == NULL) {
 return ERROR_MALFORMED;
 }
 if (mDataSource->readAt(
                offset, buffer, size) != (ssize_t)size) {
 delete[] buffer;
        buffer = NULL;

 return ERROR_IO;
 }

 uint32_t flags = U32_AT(buffer);

 uint32_t metadataKey = 0;
 char chunk[5];
 MakeFourCCString(mPath[4], chunk);
    ALOGV("meta: %s @ %lld", chunk, (long long)offset);
 switch ((int32_t)mPath[4]) {
 case FOURCC(0xa9, 'a', 'l', 'b'):
 {
            metadataKey = kKeyAlbum;
 break;
 }
 case FOURCC(0xa9, 'A', 'R', 'T'):
 {
            metadataKey = kKeyArtist;
 break;
 }
 case FOURCC('a', 'A', 'R', 'T'):
 {
            metadataKey = kKeyAlbumArtist;
 break;
 }
 case FOURCC(0xa9, 'd', 'a', 'y'):
 {
            metadataKey = kKeyYear;
 break;
 }
 case FOURCC(0xa9, 'n', 'a', 'm'):
 {
            metadataKey = kKeyTitle;
 break;
 }
 case FOURCC(0xa9, 'w', 'r', 't'):
 {
            metadataKey = kKeyWriter;
 break;
 }
 case FOURCC('c', 'o', 'v', 'r'):
 {
            metadataKey = kKeyAlbumArt;
 break;
 }
 case FOURCC('g', 'n', 'r', 'e'):
 {
            metadataKey = kKeyGenre;
 break;
 }
 case FOURCC(0xa9, 'g', 'e', 'n'):
 {
            metadataKey = kKeyGenre;
 break;
 }
 case FOURCC('c', 'p', 'i', 'l'):
 {
 if (size == 9 && flags == 21) {
 char tmp[16];
                sprintf(tmp, "%d",
 (int)buffer[size - 1]);

                mFileMetaData->setCString(kKeyCompilation, tmp);
 }
 break;
 }
 case FOURCC('t', 'r', 'k', 'n'):
 {
 if (size == 16 && flags == 0) {
 char tmp[16];
 uint16_t* pTrack = (uint16_t*)&buffer[10];
 uint16_t* pTotalTracks = (uint16_t*)&buffer[12];
                sprintf(tmp, "%d/%d", ntohs(*pTrack), ntohs(*pTotalTracks));

                mFileMetaData->setCString(kKeyCDTrackNumber, tmp);
 }
 break;
 }
 case FOURCC('d', 'i', 's', 'k'):
 {
 if ((size == 14 || size == 16) && flags == 0) {
 char tmp[16];
 uint16_t* pDisc = (uint16_t*)&buffer[10];
 uint16_t* pTotalDiscs = (uint16_t*)&buffer[12];
                sprintf(tmp, "%d/%d", ntohs(*pDisc), ntohs(*pTotalDiscs));

                mFileMetaData->setCString(kKeyDiscNumber, tmp);
 }
 break;
 }
 case FOURCC('-', '-', '-', '-'):
 {
            buffer[size] = '\0';
 switch (mPath[5]) {
 case FOURCC('m', 'e', 'a', 'n'):
                    mLastCommentMean.setTo((const char *)buffer + 4);
 break;
 case FOURCC('n', 'a', 'm', 'e'):
                    mLastCommentName.setTo((const char *)buffer + 4);
 break;
 case FOURCC('d', 'a', 't', 'a'):
 if (size < 8) {
 delete[] buffer;
                        buffer = NULL;
                        ALOGE("b/24346430");
 return ERROR_MALFORMED;
 }
                    mLastCommentData.setTo((const char *)buffer + 8);
 break;
 }

 if ((mLastCommentMean.length() != 0) &&
 (mLastCommentName.length() != 0) &&
 (mLastCommentData.length() != 0)) {

 if (mLastCommentMean == "com.apple.iTunes"
 && mLastCommentName == "iTunSMPB") {
 int32_t delay, padding;
 if (sscanf(mLastCommentData,
 " %*x %x %x %*x", &delay, &padding) == 2) {
 if (mLastTrack == NULL)
 return ERROR_MALFORMED;

                        mLastTrack->meta->setInt32(kKeyEncoderDelay, delay);
                        mLastTrack->meta->setInt32(kKeyEncoderPadding, padding);
 }
 }

                mLastCommentMean.clear();
                mLastCommentName.clear();
                mLastCommentData.clear();
 }
 break;
 }

 default:
 break;
 }

 if (size >= 8 && metadataKey && !mFileMetaData->hasData(metadataKey)) {
 if (metadataKey == kKeyAlbumArt) {
            mFileMetaData->setData(
                    kKeyAlbumArt, MetaData::TYPE_NONE,
                    buffer + 8, size - 8);
 } else if (metadataKey == kKeyGenre) {
 if (flags == 0) {
 int genrecode = (int)buffer[size - 1];
                genrecode--;
 if (genrecode < 0) {
                    genrecode = 255; // reserved for 'unknown genre'
 }
 char genre[10];
                sprintf(genre, "%d", genrecode);

                mFileMetaData->setCString(metadataKey, genre);
 } else if (flags == 1) {
                buffer[size] = '\0';

                mFileMetaData->setCString(
                        metadataKey, (const char *)buffer + 8);
 }
 } else {
            buffer[size] = '\0';

            mFileMetaData->setCString(
                    metadataKey, (const char *)buffer + 8);
 }
 }

 delete[] buffer;
    buffer = NULL;

 return OK;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t OMXNodeInstance::setParameter(
        OMX_INDEXTYPE index, const void *params, size_t size) {
 Mutex::Autolock autoLock(mLock);
    OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
    CLOG_CONFIG(setParameter, "%s(%#x), %zu@%p)", asString(extIndex), index, size, params);

    OMX_ERRORTYPE err = OMX_SetParameter(
            mHandle, index, const_cast<void *>(params));
    CLOG_IF_ERROR(setParameter, err, "%s(%#x)", asString(extIndex), index);
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void fht8x8_ref(const int16_t *in, int16_t *out, int stride, int tx_type) {
   vp9_fht8x8_c(in, out, stride, tx_type);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modifier_current_encoding(PNG_CONST png_modifier *pm, color_encoding *ce)
 {
    if (pm->current_encoding != 0)
       *ce = *pm->current_encoding;

 else
      memset(ce, 0, sizeof *ce);

   ce->gamma = pm->current_gamma;

 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int alloc_seg_map(VP9_COMMON *cm, int seg_map_size) {
 int i;

 for (i = 0; i < NUM_PING_PONG_BUFFERS; ++i) {
    cm->seg_map_array[i] = (uint8_t *)vpx_calloc(seg_map_size, 1);
 if (cm->seg_map_array[i] == NULL)
 return 1;
 }
  cm->seg_map_alloc_size = seg_map_size;

  cm->seg_map_idx = 0;
  cm->prev_seg_map_idx = 1;

  cm->current_frame_seg_map = cm->seg_map_array[cm->seg_map_idx];
 if (!cm->frame_parallel_decode)
    cm->last_frame_seg_map = cm->seg_map_array[cm->prev_seg_map_idx];

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  EBMLHeader::~EBMLHeader() { delete[] m_docType; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeNativeHandle(const native_handle* handle)
{
 if (!handle || handle->version != sizeof(native_handle))
 return BAD_TYPE;

 status_t err;
    err = writeInt32(handle->numFds);
 if (err != NO_ERROR) return err;

    err = writeInt32(handle->numInts);
 if (err != NO_ERROR) return err;

 for (int i=0 ; err==NO_ERROR && i<handle->numFds ; i++)
        err = writeDupFileDescriptor(handle->data[i]);

 if (err != NO_ERROR) {
        ALOGD("write native handle, write dup fd failed");
 return err;
 }
    err = write(handle->data + handle->numFds, sizeof(int)*handle->numInts);
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ATSParser::Stream::parsePES(ABitReader *br, SyncEvent *event) {
 unsigned packet_startcode_prefix = br->getBits(24);

    ALOGV("packet_startcode_prefix = 0x%08x", packet_startcode_prefix);

 if (packet_startcode_prefix != 1) {
        ALOGV("Supposedly payload_unit_start=1 unit does not start "
 "with startcode.");

 return ERROR_MALFORMED;
 }

 unsigned stream_id = br->getBits(8);
    ALOGV("stream_id = 0x%02x", stream_id);

 unsigned PES_packet_length = br->getBits(16);
    ALOGV("PES_packet_length = %u", PES_packet_length);

 if (stream_id != 0xbc // program_stream_map
 && stream_id != 0xbe // padding_stream
 && stream_id != 0xbf // private_stream_2
 && stream_id != 0xf0 // ECM
 && stream_id != 0xf1 // EMM
 && stream_id != 0xff // program_stream_directory
 && stream_id != 0xf2 // DSMCC
 && stream_id != 0xf8) { // H.222.1 type E
 if (br->getBits(2) != 2u) {
 return ERROR_MALFORMED;
 }

        MY_LOGV("PES_scrambling_control = %u", br->getBits(2));
        MY_LOGV("PES_priority = %u", br->getBits(1));
        MY_LOGV("data_alignment_indicator = %u", br->getBits(1));
        MY_LOGV("copyright = %u", br->getBits(1));
        MY_LOGV("original_or_copy = %u", br->getBits(1));

 unsigned PTS_DTS_flags = br->getBits(2);
        ALOGV("PTS_DTS_flags = %u", PTS_DTS_flags);

 unsigned ESCR_flag = br->getBits(1);
        ALOGV("ESCR_flag = %u", ESCR_flag);

 unsigned ES_rate_flag = br->getBits(1);
        ALOGV("ES_rate_flag = %u", ES_rate_flag);

 unsigned DSM_trick_mode_flag = br->getBits(1);
        ALOGV("DSM_trick_mode_flag = %u", DSM_trick_mode_flag);

 unsigned additional_copy_info_flag = br->getBits(1);
        ALOGV("additional_copy_info_flag = %u", additional_copy_info_flag);

        MY_LOGV("PES_CRC_flag = %u", br->getBits(1));
        MY_LOGV("PES_extension_flag = %u", br->getBits(1));

 unsigned PES_header_data_length = br->getBits(8);
        ALOGV("PES_header_data_length = %u", PES_header_data_length);

 unsigned optional_bytes_remaining = PES_header_data_length;

 uint64_t PTS = 0, DTS = 0;

 if (PTS_DTS_flags == 2 || PTS_DTS_flags == 3) {
 if (optional_bytes_remaining < 5u) {
 return ERROR_MALFORMED;
 }

 if (br->getBits(4) != PTS_DTS_flags) {
 return ERROR_MALFORMED;
 }
            PTS = ((uint64_t)br->getBits(3)) << 30;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
            PTS |= ((uint64_t)br->getBits(15)) << 15;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
            PTS |= br->getBits(15);
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }

            ALOGV("PTS = 0x%016" PRIx64 " (%.2f)", PTS, PTS / 90000.0);

            optional_bytes_remaining -= 5;

 if (PTS_DTS_flags == 3) {
 if (optional_bytes_remaining < 5u) {
 return ERROR_MALFORMED;
 }

 if (br->getBits(4) != 1u) {
 return ERROR_MALFORMED;
 }

                DTS = ((uint64_t)br->getBits(3)) << 30;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
                DTS |= ((uint64_t)br->getBits(15)) << 15;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
                DTS |= br->getBits(15);
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }

                ALOGV("DTS = %" PRIu64, DTS);

                optional_bytes_remaining -= 5;
 }
 }

 if (ESCR_flag) {
 if (optional_bytes_remaining < 6u) {
 return ERROR_MALFORMED;
 }

            br->getBits(2);

 uint64_t ESCR = ((uint64_t)br->getBits(3)) << 30;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
            ESCR |= ((uint64_t)br->getBits(15)) << 15;
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
            ESCR |= br->getBits(15);
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }

            ALOGV("ESCR = %" PRIu64, ESCR);
            MY_LOGV("ESCR_extension = %u", br->getBits(9));

 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }

            optional_bytes_remaining -= 6;
 }

 if (ES_rate_flag) {
 if (optional_bytes_remaining < 3u) {
 return ERROR_MALFORMED;
 }

 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }
            MY_LOGV("ES_rate = %u", br->getBits(22));
 if (br->getBits(1) != 1u) {
 return ERROR_MALFORMED;
 }

            optional_bytes_remaining -= 3;
 }

        br->skipBits(optional_bytes_remaining * 8);


 if (PES_packet_length != 0) {
 if (PES_packet_length < PES_header_data_length + 3) {
 return ERROR_MALFORMED;
 }

 unsigned dataLength =
                PES_packet_length - 3 - PES_header_data_length;

 if (br->numBitsLeft() < dataLength * 8) {
                ALOGE("PES packet does not carry enough data to contain "
 "payload. (numBitsLeft = %zu, required = %u)",
                     br->numBitsLeft(), dataLength * 8);

 return ERROR_MALFORMED;
 }

            onPayloadData(
                    PTS_DTS_flags, PTS, DTS, br->data(), dataLength, event);

            br->skipBits(dataLength * 8);
 } else {
            onPayloadData(
                    PTS_DTS_flags, PTS, DTS,
                    br->data(), br->numBitsLeft() / 8, event);

 size_t payloadSizeBits = br->numBitsLeft();
 if (payloadSizeBits % 8 != 0u) {
 return ERROR_MALFORMED;
 }

            ALOGV("There's %zu bytes of payload.", payloadSizeBits / 8);
 }
 } else if (stream_id == 0xbe) { // padding_stream
 if (PES_packet_length == 0u) {
 return ERROR_MALFORMED;
 }
        br->skipBits(PES_packet_length * 8);
 } else {
 if (PES_packet_length == 0u) {
 return ERROR_MALFORMED;
 }
        br->skipBits(PES_packet_length * 8);
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static bool get_build_id(
 Backtrace* backtrace, uintptr_t base_addr, uint8_t* e_ident, std::string* build_id) {
 HdrType hdr;

  memcpy(&hdr.e_ident[0], e_ident, EI_NIDENT);

 if (backtrace->Read(base_addr + EI_NIDENT, reinterpret_cast<uint8_t*>(&hdr) + EI_NIDENT,
 sizeof(HdrType) - EI_NIDENT) != sizeof(HdrType) - EI_NIDENT) {
 return false;
 }

 for (size_t i = 0; i < hdr.e_phnum; i++) {
 PhdrType phdr;
 if (backtrace->Read(base_addr + hdr.e_phoff + i * hdr.e_phentsize,
 reinterpret_cast<uint8_t*>(&phdr), sizeof(phdr)) != sizeof(phdr)) {
 return false;
 }
 if (phdr.p_type == PT_NOTE) {
 size_t hdr_size = phdr.p_filesz;
 uintptr_t addr = base_addr + phdr.p_offset;
 while (hdr_size >= sizeof(NhdrType)) {
 NhdrType nhdr;
 if (backtrace->Read(addr, reinterpret_cast<uint8_t*>(&nhdr), sizeof(nhdr)) != sizeof(nhdr)) {
 return false;
 }
        addr += sizeof(nhdr);

         if (nhdr.n_type == NT_GNU_BUILD_ID) {
           addr += NOTE_ALIGN(nhdr.n_namesz);
          uint8_t build_id_data[128];
          if (nhdr.n_namesz > sizeof(build_id_data)) {
            ALOGE("Possible corrupted note, name size value is too large: %u",
                  nhdr.n_namesz);
             return false;
           }
           if (backtrace->Read(addr, build_id_data, nhdr.n_descsz) != nhdr.n_descsz) {
 return false;
 }

          build_id->clear();
 for (size_t bytes = 0; bytes < nhdr.n_descsz; bytes++) {
 *build_id += android::base::StringPrintf("%02x", build_id_data[bytes]);
 }

 return true;
 } else {
          hdr_size -= sizeof(nhdr);
 size_t skip_bytes = NOTE_ALIGN(nhdr.n_namesz) + NOTE_ALIGN(nhdr.n_descsz);
          addr += skip_bytes;
 if (hdr_size < skip_bytes) {
 break;
 }
          hdr_size -= skip_bytes;
 }
 }
 }
 }
 return false;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Chapters* Segment::GetChapters() const
{
  return m_pChapters;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    void RunCoeffCheck() {
     ACMRandom rnd(ACMRandom::DeterministicSeed());
     const int count_test_block = 1000;
    DECLARE_ALIGNED_ARRAY(16, int16_t, input_block, kNumCoeffs);
    DECLARE_ALIGNED_ARRAY(16, int16_t, output_ref_block, kNumCoeffs);
    DECLARE_ALIGNED_ARRAY(16, int16_t, output_block, kNumCoeffs);
 
     for (int i = 0; i < count_test_block; ++i) {
       for (int j = 0; j < kNumCoeffs; ++j)
        input_block[j] = rnd.Rand8() - rnd.Rand8();
 
       fwd_txfm_ref(input_block, output_ref_block, pitch_, tx_type_);
      REGISTER_STATE_CHECK(RunFwdTxfm(input_block, output_block, pitch_));
 
       for (int j = 0; j < kNumCoeffs; ++j)
        EXPECT_EQ(output_block[j], output_ref_block[j]);
 }
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: FLAC__StreamDecoderTellStatus FLACParser::tell_callback(
 const FLAC__StreamDecoder * /* decoder */,
        FLAC__uint64 *absolute_byte_offset, void *client_data)
{
 return ((FLACParser *) client_data)->tellCallback(absolute_byte_offset);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline void SetImpl(FixedArrayBase* backing_store, uint32_t entry,
 Object* value, WriteBarrierMode mode) {
 FixedArray::cast(backing_store)->set(entry, value, mode);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void on_l2cap_write_fixed_done(void* req_id, uint32_t id)
{
    l2cap_socket *sock;

 if (req_id != NULL) {
        osi_free(req_id); //free the buffer
 }

    pthread_mutex_lock(&state_lock);
    sock = btsock_l2cap_find_by_id_l(id);
 if (sock && !sock->outgoing_congest) {
        btsock_thread_add_fd(pth, sock->our_fd, BTSOCK_L2CAP, SOCK_THREAD_FD_RD, sock->id);
 }
    pthread_mutex_unlock(&state_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void silk_NLSF_stabilize(
          opus_int16            *NLSF_Q15, /* I/O   Unstable/stabilized normalized LSF vector in Q15 [L]       */
 const opus_int16            *NDeltaMin_Q15, /* I     Min distance vector, NDeltaMin_Q15[L] must be >= 1 [L+1]   */
 const opus_int              L                   /* I     Number of NLSF parameters in the input vector              */
)
{
    opus_int   i, I=0, k, loops;
    opus_int16 center_freq_Q15;
    opus_int32 diff_Q15, min_diff_Q15, min_center_Q15, max_center_Q15;

 /* This is necessary to ensure an output within range of a opus_int16 */
    silk_assert( NDeltaMin_Q15[L] >= 1 );

 for( loops = 0; loops < MAX_LOOPS; loops++ ) {
 /**************************/
 /* Find smallest distance */
 /**************************/
 /* First element */
        min_diff_Q15 = NLSF_Q15[0] - NDeltaMin_Q15[0];
        I = 0;
 /* Middle elements */
 for( i = 1; i <= L-1; i++ ) {
            diff_Q15 = NLSF_Q15[i] - ( NLSF_Q15[i-1] + NDeltaMin_Q15[i] );
 if( diff_Q15 < min_diff_Q15 ) {
                min_diff_Q15 = diff_Q15;
                I = i;
 }
 }
 /* Last element */
        diff_Q15 = ( 1 << 15 ) - ( NLSF_Q15[L-1] + NDeltaMin_Q15[L] );
 if( diff_Q15 < min_diff_Q15 ) {
            min_diff_Q15 = diff_Q15;
            I = L;
 }

 /***************************************************/
 /* Now check if the smallest distance non-negative */
 /***************************************************/
 if( min_diff_Q15 >= 0 ) {
 return;
 }

 if( I == 0 ) {
 /* Move away from lower limit */
            NLSF_Q15[0] = NDeltaMin_Q15[0];

 } else if( I == L) {
 /* Move away from higher limit */
            NLSF_Q15[L-1] = ( 1 << 15 ) - NDeltaMin_Q15[L];

 } else {
 /* Find the lower extreme for the location of the current center frequency */
            min_center_Q15 = 0;
 for( k = 0; k < I; k++ ) {
                min_center_Q15 += NDeltaMin_Q15[k];
 }
            min_center_Q15 += silk_RSHIFT( NDeltaMin_Q15[I], 1 );

 /* Find the upper extreme for the location of the current center frequency */
            max_center_Q15 = 1 << 15;
 for( k = L; k > I; k-- ) {
                max_center_Q15 -= NDeltaMin_Q15[k];
 }
            max_center_Q15 -= silk_RSHIFT( NDeltaMin_Q15[I], 1 );

 /* Move apart, sorted by value, keeping the same center frequency */
            center_freq_Q15 = (opus_int16)silk_LIMIT_32( silk_RSHIFT_ROUND( (opus_int32)NLSF_Q15[I-1] + (opus_int32)NLSF_Q15[I], 1 ),
                min_center_Q15, max_center_Q15 );
            NLSF_Q15[I-1] = center_freq_Q15 - silk_RSHIFT( NDeltaMin_Q15[I], 1 );
            NLSF_Q15[I] = NLSF_Q15[I-1] + NDeltaMin_Q15[I];
 }
 }

 /* Safe and simple fall back method, which is less ideal than the above */
 if( loops == MAX_LOOPS )
 {
 /* Insertion sort (fast for already almost sorted arrays):   */
 /* Best case:  O(n)   for an already sorted array            */
 /* Worst case: O(n^2) for an inversely sorted array          */
        silk_insertion_sort_increasing_all_values_int16( &NLSF_Q15[0], L );

 /* First NLSF should be no less than NDeltaMin[0] */
        NLSF_Q15[0] = silk_max_int( NLSF_Q15[0], NDeltaMin_Q15[0] );

 
         /* Keep delta_min distance between the NLSFs */
         for( i = 1; i < L; i++ )
            NLSF_Q15[i] = silk_max_int( NLSF_Q15[i], NLSF_Q15[i-1] + NDeltaMin_Q15[i] );
 
         /* Last NLSF should be no higher than 1 - NDeltaMin[L] */
         NLSF_Q15[L-1] = silk_min_int( NLSF_Q15[L-1], (1<<15) - NDeltaMin_Q15[L] );

 /* Keep NDeltaMin distance between the NLSFs */
 for( i = L-2; i >= 0; i-- )
            NLSF_Q15[i] = silk_min_int( NLSF_Q15[i], NLSF_Q15[i+1] - NDeltaMin_Q15[i+1] );
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  void setPID(unsigned pid) { mElementaryPID = pid; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int adev_open_output_stream(struct audio_hw_device *dev,
 audio_io_handle_t handle,
 audio_devices_t devices,
 audio_output_flags_t flags,
 struct audio_config *config,
 struct audio_stream_out **stream_out,
 const char *address)

{
 struct a2dp_audio_device *a2dp_dev = (struct a2dp_audio_device *)dev;
 struct a2dp_stream_out *out;
 int ret = 0;
 int i;
    UNUSED(address);
    UNUSED(handle);
    UNUSED(devices);
    UNUSED(flags);

    INFO("opening output");

    out = (struct a2dp_stream_out *)calloc(1, sizeof(struct a2dp_stream_out));

 if (!out)
 return -ENOMEM;

    out->stream.common.get_sample_rate = out_get_sample_rate;
    out->stream.common.set_sample_rate = out_set_sample_rate;
    out->stream.common.get_buffer_size = out_get_buffer_size;
    out->stream.common.get_channels = out_get_channels;
    out->stream.common.get_format = out_get_format;
    out->stream.common.set_format = out_set_format;
    out->stream.common.standby = out_standby;
    out->stream.common.dump = out_dump;
    out->stream.common.set_parameters = out_set_parameters;
    out->stream.common.get_parameters = out_get_parameters;
    out->stream.common.add_audio_effect = out_add_audio_effect;
    out->stream.common.remove_audio_effect = out_remove_audio_effect;
    out->stream.get_latency = out_get_latency;
    out->stream.set_volume = out_set_volume;
    out->stream.write = out_write;
    out->stream.get_render_position = out_get_render_position;
    out->stream.get_presentation_position = out_get_presentation_position;


 /* initialize a2dp specifics */
    a2dp_stream_common_init(&out->common);

    out->common.cfg.channel_flags = AUDIO_STREAM_DEFAULT_CHANNEL_FLAG;
    out->common.cfg.format = AUDIO_STREAM_DEFAULT_FORMAT;
    out->common.cfg.rate = AUDIO_STREAM_DEFAULT_RATE;

 /* set output config values */
 if (config)
 {
      config->format = out_get_format((const struct audio_stream *)&out->stream);
      config->sample_rate = out_get_sample_rate((const struct audio_stream *)&out->stream);
      config->channel_mask = out_get_channels((const struct audio_stream *)&out->stream);
 }
 *stream_out = &out->stream;
    a2dp_dev->output = out;

    a2dp_open_ctrl_path(&out->common);
 if (out->common.ctrl_fd == AUDIO_SKT_DISCONNECTED)
 {
        ERROR("ctrl socket failed to connect (%s)", strerror(errno));
        ret = -1;
 goto err_open;
 }


     DEBUG("success");
     /* Delay to ensure Headset is in proper state when START is initiated
        from DUT immediately after the connection due to ongoing music playback. */
    usleep(250000);
     return 0;
 
 err_open:
    free(out);
 *stream_out = NULL;
    a2dp_dev->output = NULL;
    ERROR("failed");
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::doNotifyANRLockedInterruptible(
 CommandEntry* commandEntry) {
    mLock.unlock();

 nsecs_t newTimeout = mPolicy->notifyANR(
            commandEntry->inputApplicationHandle, commandEntry->inputWindowHandle,
            commandEntry->reason);

    mLock.lock();

    resumeAfterTargetsNotReadyTimeoutLocked(newTimeout,
            commandEntry->inputWindowHandle != NULL
 ? commandEntry->inputWindowHandle->getInputChannel() : NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SimpleSoftOMXComponent::onQueueFilled(OMX_U32 portIndex __unused) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t StreamingProcessor::recordingStreamNeedsUpdate(
 const Parameters &params, bool *needsUpdate) {
 status_t res;

 if (needsUpdate == 0) {
        ALOGE("%s: Camera %d: invalid argument", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (mRecordingStreamId == NO_STREAM) {
 *needsUpdate = true;
 return OK;
 }

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 uint32_t currentWidth, currentHeight, currentFormat;
    android_dataspace currentDataSpace;
    res = device->getStreamInfo(mRecordingStreamId,
 &currentWidth, &currentHeight, &currentFormat, &currentDataSpace);
 if (res != OK) {
        ALOGE("%s: Camera %d: Error querying recording output stream info: "
 "%s (%d)", __FUNCTION__, mId,
                strerror(-res), res);
 return res;
 }

 if (mRecordingConsumer == 0 ||
            currentWidth != (uint32_t)params.videoWidth ||
            currentHeight != (uint32_t)params.videoHeight ||
            currentFormat != (uint32_t)mRecordingFormat ||
            currentDataSpace != mRecordingDataSpace) {
 *needsUpdate = true;
 }
 *needsUpdate = false;
 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeInt32(int32_t val)
{
 return writeAligned(val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IPCThreadState* IPCThreadState::selfOrNull()
{
 if (gHaveTLS) {
 const pthread_key_t k = gTLS;
 IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k);
 return st;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual ~Trans4x4DCT() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void mca_ccb_rsp_tout(tMCA_CCB* p_ccb, UNUSED_ATTR tMCA_CCB_EVT* p_data) {
  tMCA_CTRL evt_data;

  mca_ccb_report_event(p_ccb, MCA_RSP_TOUT_IND_EVT, &evt_data);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Chapters::Display::Clear() {
 delete[] m_string;
  m_string = NULL;

 delete[] m_language;
  m_language = NULL;

 delete[] m_country;
  m_country = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void update_keyboard_lockstates(btif_hh_device_t *p_dev)
{
    UINT8 len = 2; /* reportid + 1 byte report*/
    BD_ADDR* bda;
    BT_HDR* p_buf;
    UINT8 data[] = {0x01, /* report id */
                    btif_hh_keylockstates}; /* keystate */

 /* Set report for other keyboards */
    BTIF_TRACE_EVENT("%s: setting report on dev_handle %d to 0x%x",
         __FUNCTION__, p_dev->dev_handle, btif_hh_keylockstates);

 /* Get SetReport buffer */
    p_buf = create_pbuf(len, data);
 if (p_buf != NULL) {
        p_buf->layer_specific = BTA_HH_RPTT_OUTPUT;
        bda = (BD_ADDR*) (&p_dev->bd_addr);
        BTA_HhSendData(p_dev->dev_handle, *bda, p_buf);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long BlockGroup::GetNextTimeCode() const
{
    return m_next;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual void AlertMessage(String16 message) {
 String8 m8(message);
    std::string mstd(m8.string());

    ALOGD("PAC-alert: %s\n", mstd.c_str()); // Helpful when debugging.
    alerts.push_back(mstd);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  const Cues* Segment::GetCues() const { return m_pCues; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::enqueueDispatchEntryLocked(
 const sp<Connection>& connection, EventEntry* eventEntry, const InputTarget* inputTarget,
 int32_t dispatchMode) {
 int32_t inputTargetFlags = inputTarget->flags;
 if (!(inputTargetFlags & dispatchMode)) {
 return;
 }
    inputTargetFlags = (inputTargetFlags & ~InputTarget::FLAG_DISPATCH_MASK) | dispatchMode;

 DispatchEntry* dispatchEntry = new DispatchEntry(eventEntry, // increments ref
            inputTargetFlags, inputTarget->xOffset, inputTarget->yOffset,
            inputTarget->scaleFactor);

 switch (eventEntry->type) {
 case EventEntry::TYPE_KEY: {
 KeyEntry* keyEntry = static_cast<KeyEntry*>(eventEntry);
        dispatchEntry->resolvedAction = keyEntry->action;
        dispatchEntry->resolvedFlags = keyEntry->flags;

 if (!connection->inputState.trackKey(keyEntry,
                dispatchEntry->resolvedAction, dispatchEntry->resolvedFlags)) {
#if DEBUG_DISPATCH_CYCLE
            ALOGD("channel '%s' ~ enqueueDispatchEntryLocked: skipping inconsistent key event",
                    connection->getInputChannelName());
#endif
 delete dispatchEntry;
 return; // skip the inconsistent event
 }
 break;
 }

 case EventEntry::TYPE_MOTION: {
 MotionEntry* motionEntry = static_cast<MotionEntry*>(eventEntry);
 if (dispatchMode & InputTarget::FLAG_DISPATCH_AS_OUTSIDE) {
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_OUTSIDE;
 } else if (dispatchMode & InputTarget::FLAG_DISPATCH_AS_HOVER_EXIT) {
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_HOVER_EXIT;
 } else if (dispatchMode & InputTarget::FLAG_DISPATCH_AS_HOVER_ENTER) {
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_HOVER_ENTER;
 } else if (dispatchMode & InputTarget::FLAG_DISPATCH_AS_SLIPPERY_EXIT) {
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_CANCEL;
 } else if (dispatchMode & InputTarget::FLAG_DISPATCH_AS_SLIPPERY_ENTER) {
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_DOWN;
 } else {
            dispatchEntry->resolvedAction = motionEntry->action;
 }
 if (dispatchEntry->resolvedAction == AMOTION_EVENT_ACTION_HOVER_MOVE
 && !connection->inputState.isHovering(
                        motionEntry->deviceId, motionEntry->source, motionEntry->displayId)) {
#if DEBUG_DISPATCH_CYCLE
        ALOGD("channel '%s' ~ enqueueDispatchEntryLocked: filling in missing hover enter event",
                connection->getInputChannelName());
#endif
            dispatchEntry->resolvedAction = AMOTION_EVENT_ACTION_HOVER_ENTER;
 }

        dispatchEntry->resolvedFlags = motionEntry->flags;

         if (dispatchEntry->targetFlags & InputTarget::FLAG_WINDOW_IS_OBSCURED) {
             dispatchEntry->resolvedFlags |= AMOTION_EVENT_FLAG_WINDOW_IS_OBSCURED;
         }
 
         if (!connection->inputState.trackMotion(motionEntry,
                 dispatchEntry->resolvedAction, dispatchEntry->resolvedFlags)) {
#if DEBUG_DISPATCH_CYCLE
            ALOGD("channel '%s' ~ enqueueDispatchEntryLocked: skipping inconsistent motion event",
                    connection->getInputChannelName());
#endif
 delete dispatchEntry;
 return; // skip the inconsistent event
 }
 break;
 }
 }

 if (dispatchEntry->hasForegroundTarget()) {
        incrementPendingForegroundDispatchesLocked(eventEntry);
 }

    connection->outboundQueue.enqueueAtTail(dispatchEntry);
    traceOutboundQueueLengthLocked(connection);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ID3::removeUnsynchronization() {
 for (size_t i = 0; i + 1 < mSize; ++i) {
 if (mData[i] == 0xff && mData[i + 1] == 0x00) {
            memmove(&mData[i + 1], &mData[i + 2], mSize - i - 2);
 --mSize;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static uint32_t GetEntryForIndexImpl(Isolate* isolate, JSObject* holder,
 FixedArrayBase* backing_store,
 uint32_t index, PropertyFilter filter) {
 return index < AccessorClass::GetCapacityImpl(holder, backing_store)
 ? index
 : kMaxUInt32;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ilineara_g22(int fixed_srgb, int alpha)
{
 return u16d((257 * alpha) * g22_to_d[fixed_srgb]);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MetadataRetrieverClient::MetadataRetrieverClient(pid_t pid)
{
    ALOGV("MetadataRetrieverClient constructor pid(%d)", pid);
    mPid = pid;
    mThumbnail = NULL;
    mAlbumArt = NULL;
    mRetriever = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: configure_env(char **env, const char *prefix, const struct dhcp_message *dhcp,
 const struct if_options *ifo)
{
 unsigned int i;
 const uint8_t *p;
 int pl;
 struct in_addr addr;
 struct in_addr net;
 struct in_addr brd;
 char *val, *v;
 const struct dhcp_opt *opt;
 ssize_t len, e = 0;
 char **ep;
 char cidr[4];
 uint8_t overl = 0;

	get_option_uint8(&overl, dhcp, DHO_OPTIONSOVERLOADED);

 if (!env) {
 for (opt = dhcp_opts; opt->option; opt++) {
 if (!opt->var)
 continue;
 if (has_option_mask(ifo->nomask, opt->option))
 continue;
 if (get_option_raw(dhcp, opt->option))
				e++;
 }
 if (dhcp->yiaddr || dhcp->ciaddr)
			e += 5;
 if (*dhcp->bootfile && !(overl & 1))
			e++;
 if (*dhcp->servername && !(overl & 2))
			e++;
 return e;
 }

	ep = env;
 if (dhcp->yiaddr || dhcp->ciaddr) {
 /* Set some useful variables that we derive from the DHCP
		 * message but are not necessarily in the options */
		addr.s_addr = dhcp->yiaddr ? dhcp->yiaddr : dhcp->ciaddr;
		setvar(&ep, prefix, "ip_address", inet_ntoa(addr));
 if (get_option_addr(&net, dhcp, DHO_SUBNETMASK) == -1) {
			net.s_addr = get_netmask(addr.s_addr);
			setvar(&ep, prefix, "subnet_mask", inet_ntoa(net));
 }
		i = inet_ntocidr(net);
		snprintf(cidr, sizeof(cidr), "%d", inet_ntocidr(net));
		setvar(&ep, prefix, "subnet_cidr", cidr);
 if (get_option_addr(&brd, dhcp, DHO_BROADCAST) == -1) {
			brd.s_addr = addr.s_addr | ~net.s_addr;
			setvar(&ep, prefix, "broadcast_address", inet_ntoa(brd));
 }
		addr.s_addr = dhcp->yiaddr & net.s_addr;
		setvar(&ep, prefix, "network_number", inet_ntoa(addr));
 }

 if (*dhcp->bootfile && !(overl & 1))
		setvar(&ep, prefix, "filename", (const char *)dhcp->bootfile);
 if (*dhcp->servername && !(overl & 2))
		setvar(&ep, prefix, "server_name", (const char *)dhcp->servername);

 for (opt = dhcp_opts; opt->option; opt++) {
 if (!opt->var)
 continue;
 if (has_option_mask(ifo->nomask, opt->option))
 continue;
		val = NULL;
		p = get_option(dhcp, opt->option, &pl, NULL);
 if (!p)
 continue;
 /* We only want the FQDN name */
 if (opt->option == DHO_FQDN) {
			p += 3;
			pl -= 3;
 }
		len = print_option(NULL, 0, opt->type, pl, p);
 if (len < 0)
 return -1;
		e = strlen(prefix) + strlen(opt->var) + len + 4;
		v = val = *ep++ = xmalloc(e);
		v += snprintf(val, e, "%s_%s=", prefix, opt->var);
 if (len != 0)
			print_option(v, len, opt->type, pl, p);
 }

 return ep - env;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_reset(iv_obj_t *dec_hdl, void *pv_api_ip, void *pv_api_op)
{
 dec_struct_t * ps_dec;
 ivd_ctl_reset_op_t *ps_ctl_op = (ivd_ctl_reset_op_t *)pv_api_op;
    UNUSED(pv_api_ip);
    ps_ctl_op->u4_error_code = 0;

    ps_dec = (dec_struct_t *)(dec_hdl->pv_codec_handle);

 if(ps_dec != NULL)
 {
        ih264d_init_decoder(ps_dec);
 }
 else
 {
        H264_DEC_DEBUG_PRINT(
 "\nReset called without Initializing the decoder\n");
        ps_ctl_op->u4_error_code = ERROR_INIT_NOT_DONE;
 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<AudioFlinger::EffectModule> AudioFlinger::EffectChain::getEffectFromType_l(
 const effect_uuid_t *type)
{
 size_t size = mEffects.size();

 for (size_t i = 0; i < size; i++) {
 if (memcmp(&mEffects[i]->desc().type, type, sizeof(effect_uuid_t)) == 0) {
 return mEffects[i];
 }
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static nl_sock * wifi_create_nl_socket(int port)
{
 struct nl_sock *sock = nl_socket_alloc();
 if (sock == NULL) {
        ALOGE("Could not create handle");
 return NULL;
 }

    wifi_socket_set_local_port(sock, port);

 struct sockaddr *addr = NULL;

 if (nl_connect(sock, NETLINK_GENERIC)) {
        ALOGE("Could not connect handle");
        nl_socket_free(sock);
 return NULL;
 }

 /*
    if (nl_socket_set_nonblocking(sock)) {
        ALOGE("Could make socket non-blocking");
        nl_socket_free(sock);
        return NULL;
    }
    */

 return sock;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::initiateCreateInputSurface() {
 (new AMessage(kWhatCreateInputSurface, this))->post();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_process_video_bit_stream(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    UWORD32 u4_next_bits, u4_start_code_found;
    IMPEG2D_ERROR_CODES_T e_error;

    ps_stream = &ps_dec->s_bit_stream;
    impeg2d_next_start_code(ps_dec);
 /* If the stream is MPEG-2 compliant stream */
    u4_start_code_found = 0;

 if(ps_dec->u2_is_mpeg2)
 {
 /* MPEG2 decoding starts */
 while((u4_start_code_found == 0) && (ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset))
 {
            u4_next_bits = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);

 if(u4_next_bits == SEQUENCE_HEADER_CODE)
 {
 if(ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 {
                    e_error = impeg2d_dec_seq_hdr(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }

                    u4_start_code_found = 0;

 }
 else
 {
 return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;
 }


 if(ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 {
                    IMPEG2D_ERROR_CODES_T e_error;
                    e_error = impeg2d_dec_seq_ext(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                    u4_start_code_found = 0;

 }
 else
 {
 return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;
 }
 }
 else if((u4_next_bits == USER_DATA_START_CODE) || (u4_next_bits == EXTENSION_START_CODE))
 {
 if(ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 {
                    impeg2d_dec_seq_ext_data(ps_dec);
                    u4_start_code_found = 0;

 }

 }
 else if((ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 && (u4_next_bits == GOP_START_CODE))
 {
                impeg2d_dec_grp_of_pic_hdr(ps_dec);
                impeg2d_dec_user_data(ps_dec);
                u4_start_code_found = 0;

 }
 else if((ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 && (u4_next_bits == PICTURE_START_CODE))
 {
                ps_dec->i4_pic_count++;

                e_error = impeg2d_dec_pic_hdr(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                e_error = impeg2d_dec_pic_coding_ext(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                e_error = impeg2d_dec_pic_ext_data(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                e_error = impeg2d_pre_pic_dec_proc(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T) IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                impeg2d_dec_pic_data(ps_dec);
                impeg2d_post_pic_dec_proc(ps_dec);
                u4_start_code_found = 1;
 }
 else

 {
                FLUSH_BITS(ps_dec->s_bit_stream.u4_offset, ps_dec->s_bit_stream.u4_buf, ps_dec->s_bit_stream.u4_buf_nxt, 8, ps_dec->s_bit_stream.pu4_buf_aligned);

 }
 if(u4_start_code_found == 0)
 {
                impeg2d_next_start_code(ps_dec);
 /* In case a dec_pic_data call has not been made, the number of
                 * bytes consumed in the previous header decode has to be
                 * consumed. Not consuming it will result in zero bytes consumed
                 * loops in case there are multiple headers and the second
                 * or a future header has a resolution change/other error where
                 * the bytes of the last header are not consumed.
                 */
                ps_dec->i4_bytes_consumed = (ps_dec->s_bit_stream.u4_offset + 7) >> 3;
                ps_dec->i4_bytes_consumed -= ((size_t)ps_dec->s_bit_stream.pv_bs_buf & 3);
 }
 }
 if((u4_start_code_found == 0) && (ps_dec->s_bit_stream.u4_offset > ps_dec->s_bit_stream.u4_max_offset))
 {
 return IMPEG2D_FRM_HDR_START_CODE_NOT_FOUND;
 }

 }
 /* If the stream is MPEG-1 compliant stream */
 else
 {
 while((u4_start_code_found == 0) && (ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset))
 {
            u4_next_bits = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);

 if(impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN) == SEQUENCE_HEADER_CODE)
 {
 if(ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset)
 {
                    e_error = impeg2d_dec_seq_hdr(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }

                    u4_start_code_found = 0;
 }
 else
 {
 return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;
 }
 }
 else if((ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset) && (u4_next_bits == EXTENSION_START_CODE || u4_next_bits == USER_DATA_START_CODE))
 {
                impeg2d_flush_ext_and_user_data(ps_dec);
                u4_start_code_found = 0;
 }


 else if ((impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN) == GOP_START_CODE)
 && (ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset))
 {
                impeg2d_dec_grp_of_pic_hdr(ps_dec);
                impeg2d_flush_ext_and_user_data(ps_dec);
                u4_start_code_found = 0;
 }
 else if ((impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN) == PICTURE_START_CODE)
 && (ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset))
 {
                ps_dec->i4_pic_count++;

                e_error = impeg2d_dec_pic_hdr(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }
                impeg2d_flush_ext_and_user_data(ps_dec);
                impeg2d_pre_pic_dec_proc(ps_dec);
                impeg2d_dec_pic_data(ps_dec);
                impeg2d_post_pic_dec_proc(ps_dec);
                u4_start_code_found = 1;
 }
 else
 {
                FLUSH_BITS(ps_dec->s_bit_stream.u4_offset, ps_dec->s_bit_stream.u4_buf, ps_dec->s_bit_stream.u4_buf_nxt, 8, ps_dec->s_bit_stream.pu4_buf_aligned);
 }
            impeg2d_next_start_code(ps_dec);
 if (0 == u4_start_code_found)
 {
 /* In case a dec_pic_data call has not been made, the number of
                 * bytes consumed in the previous header decode has to be
                 * consumed. Not consuming it will result in zero bytes consumed
                 * loops in case there are multiple headers and the second
                 * or a future header has a resolution change/other error where
                 * the bytes of the last header are not consumed.
                 */
                ps_dec->i4_bytes_consumed = (ps_dec->s_bit_stream.u4_offset + 7) >> 3;
                ps_dec->i4_bytes_consumed -= ((size_t)ps_dec->s_bit_stream.pv_bs_buf & 3);
 }
 }
 if((u4_start_code_found == 0) && (ps_dec->s_bit_stream.u4_offset > ps_dec->s_bit_stream.u4_max_offset))
 {
 return IMPEG2D_FRM_HDR_START_CODE_NOT_FOUND;
 }
 }

 return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  static uint32_t NumberOfElementsImpl(JSObject* receiver,
 FixedArrayBase* backing_store) {
 return AccessorClass::GetCapacityImpl(receiver, backing_store);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::useGraphicBuffer2_l(
        OMX_U32 portIndex, const sp<GraphicBuffer>& graphicBuffer,
        OMX::buffer_id *buffer) {

    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;
    OMX_ERRORTYPE err = OMX_GetParameter(mHandle, OMX_IndexParamPortDefinition, &def);
 if (err != OMX_ErrorNone) {
        OMX_INDEXTYPE index = OMX_IndexParamPortDefinition;
        CLOG_ERROR(getParameter, err, "%s(%#x): %s:%u",
                asString(index), index, portString(portIndex), portIndex);

         return UNKNOWN_ERROR;
     }
 
    BufferMeta *bufferMeta = new BufferMeta(graphicBuffer);
 
     OMX_BUFFERHEADERTYPE *header = NULL;
     OMX_U8* bufferHandle = const_cast<OMX_U8*>(
 reinterpret_cast<const OMX_U8*>(graphicBuffer->handle));

    err = OMX_UseBuffer(
            mHandle,
 &header,
            portIndex,
            bufferMeta,
            def.nBufferSize,
            bufferHandle);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(useBuffer, err, BUFFER_FMT(portIndex, "%u@%p", def.nBufferSize, bufferHandle));
 delete bufferMeta;
        bufferMeta = NULL;
 *buffer = 0;
 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pBuffer, bufferHandle);
    CHECK_EQ(header->pAppPrivate, bufferMeta);

 *buffer = makeBufferID(header);

    addActiveBuffer(portIndex, *buffer);
    CLOG_BUFFER(useGraphicBuffer2, NEW_BUFFER_FMT(
 *buffer, portIndex, "%u@%p", def.nBufferSize, bufferHandle));
 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::dispatchDeviceResetLocked(
 nsecs_t currentTime, DeviceResetEntry* entry) {
#if DEBUG_OUTBOUND_EVENT_DETAILS
    ALOGD("dispatchDeviceReset - eventTime=%lld, deviceId=%d", entry->eventTime, entry->deviceId);
#endif

 CancelationOptions options(CancelationOptions::CANCEL_ALL_EVENTS,
 "device was reset");
    options.deviceId = entry->deviceId;
    synthesizeCancelationEventsForAllConnectionsLocked(options);
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CuePoint::TrackPosition::Parse(IMkvReader* pReader, long long start_,
                                     long long size_) {
   const long long stop = start_ + size_;
   long long pos = start_;

  m_track = -1;
  m_pos = -1;
  m_block = 1; // default


   while (pos < stop) {
     long len;
 
    const long long id = ReadUInt(pReader, pos, len);
    assert(id >= 0);  // TODO
    assert((pos + len) <= stop);
 
     pos += len;  // consume ID
 
     const long long size = ReadUInt(pReader, pos, len);
    assert(size >= 0);
    assert((pos + len) <= stop);
 
     pos += len;  // consume Size field
    assert((pos + size) <= stop);
 
     if (id == 0x77)  // CueTrack ID
       m_track = UnserializeUInt(pReader, pos, size);

 else if (id == 0x71) // CueClusterPos ID
      m_pos = UnserializeUInt(pReader, pos, size);

 else if (id == 0x1378) // CueBlockNumber

       m_block = UnserializeUInt(pReader, pos, size);
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
  assert(m_pos >= 0);
  assert(m_track > 0);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Parcel::readStrongBinderVector(std::unique_ptr<std::vector<sp<IBinder>>>* val) const {
 return readNullableTypedVector(val, &Parcel::readStrongBinder);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeObject(const flat_binder_object& val, bool nullMetaData)
{
 const bool enoughData = (mDataPos+sizeof(val)) <= mDataCapacity;
 const bool enoughObjects = mObjectsSize < mObjectsCapacity;
 if (enoughData && enoughObjects) {
restart_write:
 *reinterpret_cast<flat_binder_object*>(mData+mDataPos) = val;

 if (val.type == BINDER_TYPE_FD) {
 if (!mAllowFds) {
 return FDS_NOT_ALLOWED;
 }
            mHasFds = mFdsKnown = true;
 }

 if (nullMetaData || val.binder != 0) {
            mObjects[mObjectsSize] = mDataPos;
            acquire_object(ProcessState::self(), val, this, &mOpenAshmemSize);
            mObjectsSize++;
 }

 return finishWrite(sizeof(flat_binder_object));
 }

 if (!enoughData) {
 const status_t err = growData(sizeof(val));
 if (err != NO_ERROR) return err;
 }
 if (!enoughObjects) {
 size_t newSize = ((mObjectsSize+2)*3)/2;
 if (newSize < mObjectsSize) return NO_MEMORY; // overflow
 binder_size_t* objects = (binder_size_t*)realloc(mObjects, newSize*sizeof(binder_size_t));
 if (objects == NULL) return NO_MEMORY;
        mObjects = objects;
        mObjectsCapacity = newSize;
 }

 goto restart_write;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  INLINE void impeg2d_bit_stream_flush(void* pv_ctxt, UWORD32 u4_no_of_bits)
 {
     stream_t *ps_stream = (stream_t *)pv_ctxt;
    if (ps_stream->u4_offset < ps_stream->u4_max_offset)
     {
         FLUSH_BITS(ps_stream->u4_offset,ps_stream->u4_buf,ps_stream->u4_buf_nxt,u4_no_of_bits,ps_stream->pu4_buf_aligned)
     }
     return;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: InputDispatcher::DeviceResetEntry::DeviceResetEntry(nsecs_t eventTime, int32_t deviceId) :
 EventEntry(TYPE_DEVICE_RESET, eventTime, 0),
        deviceId(deviceId) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<IBinder> Parcel::readStrongBinder() const
{
    sp<IBinder> val;
    readStrongBinder(&val);
 return val;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SYSCALL_DEFINE1(newuname, struct new_utsname __user *, name)
{
 int errno = 0;

	down_read(&uts_sem);
 if (copy_to_user(name, utsname(), sizeof *name))
		errno = -EFAULT;
	up_read(&uts_sem);

 if (!errno && override_release(name->release, sizeof(name->release)))
		errno = -EFAULT;
 if (!errno && override_architecture(name))
		errno = -EFAULT;
 return errno;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlIsNameStartChar(xmlParserCtxtPtr ctxt, int c) {
 if ((ctxt->options & XML_PARSE_OLD10) == 0) {
 /*
	 * Use the new checks of production [4] [4a] amd [5] of the
	 * Update 5 of XML-1.0
	 */
 if ((c != ' ') && (c != '>') && (c != '/') && /* accelerators */
 (((c >= 'a') && (c <= 'z')) ||
 ((c >= 'A') && (c <= 'Z')) ||
 (c == '_') || (c == ':') ||
 ((c >= 0xC0) && (c <= 0xD6)) ||
 ((c >= 0xD8) && (c <= 0xF6)) ||
 ((c >= 0xF8) && (c <= 0x2FF)) ||
 ((c >= 0x370) && (c <= 0x37D)) ||
 ((c >= 0x37F) && (c <= 0x1FFF)) ||
 ((c >= 0x200C) && (c <= 0x200D)) ||
 ((c >= 0x2070) && (c <= 0x218F)) ||
 ((c >= 0x2C00) && (c <= 0x2FEF)) ||
 ((c >= 0x3001) && (c <= 0xD7FF)) ||
 ((c >= 0xF900) && (c <= 0xFDCF)) ||
 ((c >= 0xFDF0) && (c <= 0xFFFD)) ||
 ((c >= 0x10000) && (c <= 0xEFFFF))))
 return(1);
 } else {
 if (IS_LETTER(c) || (c == '_') || (c == ':'))
 return(1);
 }
 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static IHEVCD_ERROR_T ihevcd_parse_profile_tier_level_layer(bitstrm_t *ps_bitstrm,
 profile_tier_lvl_t *ps_ptl)
{
    WORD32 value;
    WORD32 i;
    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;

    BITS_PARSE("XXX_profile_space[]", value, ps_bitstrm, 2);
    ps_ptl->i1_profile_space = value;

    BITS_PARSE("XXX_tier_flag[]", value, ps_bitstrm, 1);
    ps_ptl->i1_tier_flag = value;

    BITS_PARSE("XXX_profile_idc[]", value, ps_bitstrm, 5);
    ps_ptl->i1_profile_idc = value;

 for(i = 0; i < MAX_PROFILE_COMPATBLTY; i++)
 {
        BITS_PARSE("XXX_profile_compatibility_flag[][j]", value, ps_bitstrm, 1);
        ps_ptl->ai1_profile_compatibility_flag[i] = value;
 }

    BITS_PARSE("general_progressive_source_flag", value, ps_bitstrm, 1);
    ps_ptl->i1_general_progressive_source_flag = value;

    BITS_PARSE("general_interlaced_source_flag", value, ps_bitstrm, 1);
    ps_ptl->i1_general_interlaced_source_flag = value;

    BITS_PARSE("general_non_packed_constraint_flag", value, ps_bitstrm, 1);
    ps_ptl->i1_general_non_packed_constraint_flag = value;

    BITS_PARSE("general_frame_only_constraint_flag", value, ps_bitstrm, 1);
    ps_ptl->i1_frame_only_constraint_flag = value;

    BITS_PARSE("XXX_reserved_zero_44bits[0..15]", value, ps_bitstrm, 16);

    BITS_PARSE("XXX_reserved_zero_44bits[16..31]", value, ps_bitstrm, 16);

    BITS_PARSE("XXX_reserved_zero_44bits[32..43]", value, ps_bitstrm, 12);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_ssp_key_notif_evt(tBTA_DM_SP_KEY_NOTIF *p_ssp_key_notif)
{
 bt_bdaddr_t bd_addr;
 bt_bdname_t bd_name;
    UINT32 cod;
 int dev_type;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

 /* Remote properties update */
 if (!btif_get_device_type(p_ssp_key_notif->bd_addr, &dev_type))
 {
        dev_type = BT_DEVICE_TYPE_BREDR;
 }
    btif_update_remote_properties(p_ssp_key_notif->bd_addr, p_ssp_key_notif->bd_name,
                                  p_ssp_key_notif->dev_class, (tBT_DEVICE_TYPE) dev_type);

    bdcpy(bd_addr.address, p_ssp_key_notif->bd_addr);
    memcpy(bd_name.name, p_ssp_key_notif->bd_name, BD_NAME_LEN);

    bond_state_changed(BT_STATUS_SUCCESS, &bd_addr, BT_BOND_STATE_BONDING);
    pairing_cb.is_ssp = TRUE;
    cod = devclass2uint(p_ssp_key_notif->dev_class);

 if (cod == 0) {
        LOG_DEBUG("%s cod is 0, set as unclassified", __func__);
        cod = COD_UNCLASSIFIED;
 }

    HAL_CBACK(bt_hal_cbacks, ssp_request_cb, &bd_addr, &bd_name,
                     cod, BT_SSP_VARIANT_PASSKEY_NOTIFICATION,
                     p_ssp_key_notif->passkey);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int strzcmp16(const char16_t *s1, size_t n1, const char16_t *s2, size_t n2)
{
 const char16_t* e1 = s1+n1;
 const char16_t* e2 = s2+n2;

 while (s1 < e1 && s2 < e2) {
 const int d = (int)*s1++ - (int)*s2++;
 if (d) {
 return d;
 }
 }

 return n1 < n2
 ? (0 - (int)*s2)
 : (n1 > n2
 ? ((int)*s1 - 0)
 : 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_freefile(png_store_file **ppf)
{
 if (*ppf != NULL)
 {
      store_freefile(&(*ppf)->next);

      store_freebuffer(&(*ppf)->data);
 (*ppf)->datacount = 0;
 if ((*ppf)->palette != NULL)
 {
         free((*ppf)->palette);
 (*ppf)->palette = NULL;
 (*ppf)->npalette = 0;
 }
      free(*ppf);
 *ppf = NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modification_init(png_modification *pmm)
{
   memset(pmm, 0, sizeof *pmm);
   pmm->next = NULL;
   pmm->chunk = 0;
   pmm->modify_fn = NULL;
   pmm->add = 0;
   modification_reset(pmm);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::configureVideoTunnelMode(
        OMX_U32 portIndex, OMX_BOOL tunneled, OMX_U32 audioHwSync,
 native_handle_t **sidebandHandle) {
 Mutex::Autolock autolock(mLock);
    CLOG_CONFIG(configureVideoTunnelMode, "%s:%u tun=%d sync=%u",
            portString(portIndex), portIndex, tunneled, audioHwSync);

    OMX_INDEXTYPE index;
    OMX_STRING name = const_cast<OMX_STRING>(
 "OMX.google.android.index.configureVideoTunnelMode");

    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, name, &index);
 if (err != OMX_ErrorNone) {
        CLOG_ERROR_IF(tunneled, getExtensionIndex, err, "%s", name);
 return StatusFromOMXError(err);
 }

 ConfigureVideoTunnelModeParams tunnelParams;
 InitOMXParams(&tunnelParams);
    tunnelParams.nPortIndex = portIndex;
    tunnelParams.bTunneled = tunneled;
    tunnelParams.nAudioHwSync = audioHwSync;
    err = OMX_SetParameter(mHandle, index, &tunnelParams);
 if (err != OMX_ErrorNone) {
        CLOG_ERROR(setParameter, err, "%s(%#x): %s:%u tun=%d sync=%u", name, index,
                portString(portIndex), portIndex, tunneled, audioHwSync);
 return StatusFromOMXError(err);
 }

    err = OMX_GetParameter(mHandle, index, &tunnelParams);
 if (err != OMX_ErrorNone) {
        CLOG_ERROR(getParameter, err, "%s(%#x): %s:%u tun=%d sync=%u", name, index,
                portString(portIndex), portIndex, tunneled, audioHwSync);
 return StatusFromOMXError(err);
 }
 if (sidebandHandle) {
 *sidebandHandle = (native_handle_t*)tunnelParams.pSidebandWindow;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: transform_height(png_const_structp pp, png_byte colour_type, png_byte bit_depth)
{
 switch (bit_size(pp, colour_type, bit_depth))
 {
 case 1:
 case 2:
 case 4:
 return 1; /* Total of 128 pixels */

 case 8:
 return 2; /* Total of 256 pixels/bytes */

 case 16:
 return 512; /* Total of 65536 pixels */

 case 24:
 case 32:
 return 512; /* 65536 pixels */

 case 48:
 case 64:
 return 2048;/* 4 x 65536 pixels. */
#        define TRANSFORM_HEIGHTMAX 2048

 default:
 return 0; /* Error, will be caught later */
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint8_t* AMediaCodec_getInputBuffer(AMediaCodec *mData, size_t idx, size_t *out_size) {
 if (mData->mAsyncNotify != NULL) {
        sp<MediaCodecBuffer> abuf;
 if (mData->mCodec->getInputBuffer(idx, &abuf) != 0) {
 return NULL;
 }

 if (out_size != NULL) {
 *out_size = abuf->capacity();
 }
 return abuf->data();
 }

    android::Vector<android::sp<android::MediaCodecBuffer> > abufs;
 if (mData->mCodec->getInputBuffers(&abufs) == 0) {
 size_t n = abufs.size();
 if (idx >= n) {
            ALOGE("buffer index %zu out of range", idx);
 return NULL;
 }
 if (abufs[idx] == NULL) {
            ALOGE("buffer index %zu is NULL", idx);
 return NULL;
 }
 if (out_size != NULL) {
 *out_size = abufs[idx]->capacity();
 }
 return abufs[idx]->data();
 }
    ALOGE("couldn't get input buffers");
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MediaMetadataRetriever::disconnect()
{
    ALOGV("disconnect");
    sp<IMediaMetadataRetriever> retriever;
 {
 Mutex::Autolock _l(mLock);
        retriever = mRetriever;
        mRetriever.clear();
 }
 if (retriever != 0) {
        retriever->disconnect();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_get_next_display_field(dec_struct_t * ps_dec,
 ivd_out_bufdesc_t *ps_out_buffer,
 ivd_get_display_frame_op_t *pv_disp_op)
{
 pic_buffer_t *pic_buf;

    UWORD8 i1_cur_fld;
    WORD32 u4_api_ret = -1;
    WORD32 i4_disp_buf_id;
 iv_yuv_buf_t *ps_op_frm;



    ps_op_frm = &(ps_dec->s_disp_frame_info);
    H264_MUTEX_LOCK(&ps_dec->process_disp_mutex);
    pic_buf = (pic_buffer_t *)ih264_disp_mgr_get(
 (disp_mgr_t *)ps_dec->pv_disp_buf_mgr, &i4_disp_buf_id);
    ps_dec->u4_num_fld_in_frm = 0;
    u4_api_ret = -1;
    pv_disp_op->u4_ts = -1;
    pv_disp_op->e_output_format = ps_dec->u1_chroma_format;

    pv_disp_op->s_disp_frm_buf.pv_y_buf = ps_out_buffer->pu1_bufs[0];
    pv_disp_op->s_disp_frm_buf.pv_u_buf = ps_out_buffer->pu1_bufs[1];
    pv_disp_op->s_disp_frm_buf.pv_v_buf = ps_out_buffer->pu1_bufs[2];
 if(pic_buf != NULL)
 {
        pv_disp_op->e4_fld_type = 0;
        pv_disp_op->u4_disp_buf_id = i4_disp_buf_id;

        ps_op_frm->u4_y_ht = pic_buf->u2_disp_height << 1;
        ps_op_frm->u4_u_ht = ps_op_frm->u4_v_ht = ps_op_frm->u4_y_ht >> 1;
        ps_op_frm->u4_y_wd = pic_buf->u2_disp_width;

        ps_op_frm->u4_u_wd = ps_op_frm->u4_v_wd = ps_op_frm->u4_y_wd >> 1;

        ps_op_frm->u4_y_strd = pic_buf->u2_frm_wd_y;
        ps_op_frm->u4_u_strd = ps_op_frm->u4_v_strd = pic_buf->u2_frm_wd_uv;

 /* ! */
        pv_disp_op->u4_ts = pic_buf->u4_ts;

 /* set the start of the Y, U and V buffer pointer for display    */
        ps_op_frm->pv_y_buf = pic_buf->pu1_buf1 + pic_buf->u2_crop_offset_y;
        ps_op_frm->pv_u_buf = pic_buf->pu1_buf2 + pic_buf->u2_crop_offset_uv;
        ps_op_frm->pv_v_buf = pic_buf->pu1_buf3 + pic_buf->u2_crop_offset_uv;
        ps_dec->u4_num_fld_in_frm++;
        ps_dec->u4_num_fld_in_frm++;
        u4_api_ret = 0;

 if(pic_buf->u1_picturetype == 0)
            pv_disp_op->u4_progressive_frame_flag = 1;
 else
            pv_disp_op->u4_progressive_frame_flag = 0;

 } H264_MUTEX_UNLOCK(&ps_dec->process_disp_mutex);
    pv_disp_op->u4_error_code = u4_api_ret;
    pv_disp_op->e_pic_type = 0xFFFFFFFF; //Junk;

 if(u4_api_ret)
 {
        pv_disp_op->u4_error_code = 1; //put a proper error code here
 }
 else
 {

        UWORD32 temp;
        UWORD32 dest_inc_Y = 0, dest_inc_UV = 0;

        pv_disp_op->s_disp_frm_buf.u4_y_wd = temp = MIN(ps_op_frm->u4_y_wd,
                                                        ps_op_frm->u4_y_strd);
        pv_disp_op->s_disp_frm_buf.u4_u_wd = pv_disp_op->s_disp_frm_buf.u4_y_wd
 >> 1;
        pv_disp_op->s_disp_frm_buf.u4_v_wd = pv_disp_op->s_disp_frm_buf.u4_y_wd
 >> 1;

        pv_disp_op->s_disp_frm_buf.u4_y_ht = ps_op_frm->u4_y_ht;
        pv_disp_op->s_disp_frm_buf.u4_u_ht = pv_disp_op->s_disp_frm_buf.u4_y_ht
 >> 1;
        pv_disp_op->s_disp_frm_buf.u4_v_ht = pv_disp_op->s_disp_frm_buf.u4_y_ht
 >> 1;
 if(0 == ps_dec->u4_share_disp_buf)
 {
            pv_disp_op->s_disp_frm_buf.u4_y_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_wd;
            pv_disp_op->s_disp_frm_buf.u4_u_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_wd >> 1;
            pv_disp_op->s_disp_frm_buf.u4_v_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_wd >> 1;

 }
 else
 {
            pv_disp_op->s_disp_frm_buf.u4_y_strd = ps_op_frm->u4_y_strd;
 }

 if(ps_dec->u4_app_disp_width)
 {
            pv_disp_op->s_disp_frm_buf.u4_y_strd = MAX(
                            ps_dec->u4_app_disp_width,
                            pv_disp_op->s_disp_frm_buf.u4_y_strd);
 }

        pv_disp_op->u4_error_code = 0;
 if(pv_disp_op->e_output_format == IV_YUV_420P)
 {
            UWORD32 i;
            pv_disp_op->s_disp_frm_buf.u4_u_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_strd >> 1;
            pv_disp_op->s_disp_frm_buf.u4_v_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_strd >> 1;

            pv_disp_op->s_disp_frm_buf.u4_u_wd = ps_op_frm->u4_y_wd >> 1;
            pv_disp_op->s_disp_frm_buf.u4_v_wd = ps_op_frm->u4_y_wd >> 1;

 if(1 == ps_dec->u4_share_disp_buf)
 {
                pv_disp_op->s_disp_frm_buf.pv_y_buf = ps_op_frm->pv_y_buf;

 for(i = 0; i < MAX_DISP_BUFS_NEW; i++)
 {
                    UWORD8 *buf = ps_dec->disp_bufs[i].buf[0];
                    buf += ps_dec->disp_bufs[i].u4_ofst[0];
 if(((UWORD8 *)pv_disp_op->s_disp_frm_buf.pv_y_buf
 - pic_buf->u2_crop_offset_y) == buf)
 {
                        buf = ps_dec->disp_bufs[i].buf[1];
                        buf += ps_dec->disp_bufs[i].u4_ofst[1];
                        pv_disp_op->s_disp_frm_buf.pv_u_buf = buf
 + pic_buf->u2_crop_offset_uv;

                        buf = ps_dec->disp_bufs[i].buf[2];
                        buf += ps_dec->disp_bufs[i].u4_ofst[2];
                        pv_disp_op->s_disp_frm_buf.pv_v_buf = buf
 + pic_buf->u2_crop_offset_uv;
 }
 }
 }

 }
 else if((pv_disp_op->e_output_format == IV_YUV_420SP_UV)
 || (pv_disp_op->e_output_format == IV_YUV_420SP_VU))
 {
            pv_disp_op->s_disp_frm_buf.u4_u_strd =
                            pv_disp_op->s_disp_frm_buf.u4_y_strd;
            pv_disp_op->s_disp_frm_buf.u4_v_strd = 0;

 if(1 == ps_dec->u4_share_disp_buf)
 {
                UWORD32 i;

                pv_disp_op->s_disp_frm_buf.pv_y_buf = ps_op_frm->pv_y_buf;

 for(i = 0; i < MAX_DISP_BUFS_NEW; i++)
 {
                    UWORD8 *buf = ps_dec->disp_bufs[i].buf[0];
                    buf += ps_dec->disp_bufs[i].u4_ofst[0];
 if((UWORD8 *)pv_disp_op->s_disp_frm_buf.pv_y_buf
 - pic_buf->u2_crop_offset_y == buf)
 {
                        buf = ps_dec->disp_bufs[i].buf[1];
                        buf += ps_dec->disp_bufs[i].u4_ofst[1];
                        pv_disp_op->s_disp_frm_buf.pv_u_buf = buf
 + pic_buf->u2_crop_offset_uv;
 ;

                        buf = ps_dec->disp_bufs[i].buf[2];
                        buf += ps_dec->disp_bufs[i].u4_ofst[2];
                        pv_disp_op->s_disp_frm_buf.pv_v_buf = buf
 + pic_buf->u2_crop_offset_uv;
 ;
 }
 }
 }
            pv_disp_op->s_disp_frm_buf.u4_u_wd =
                            pv_disp_op->s_disp_frm_buf.u4_y_wd;
            pv_disp_op->s_disp_frm_buf.u4_v_wd = 0;

 }
 else if((pv_disp_op->e_output_format == IV_RGB_565)
 || (pv_disp_op->e_output_format == IV_YUV_422ILE))
 {

            pv_disp_op->s_disp_frm_buf.u4_u_strd = 0;
            pv_disp_op->s_disp_frm_buf.u4_v_strd = 0;
            pv_disp_op->s_disp_frm_buf.u4_u_wd = 0;
            pv_disp_op->s_disp_frm_buf.u4_v_wd = 0;
            pv_disp_op->s_disp_frm_buf.u4_u_ht = 0;
            pv_disp_op->s_disp_frm_buf.u4_v_ht = 0;

 }


 }

 return u4_api_ret;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void AudioFlinger::EffectHandle::disconnect()
{
    disconnect(true);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMP3::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.mp3",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (const OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            mNumChannels = pcmParams->nChannels;
            mSamplingRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseExternalEntity(xmlDocPtr doc, xmlSAXHandlerPtr sax, void *user_data,
 int depth, const xmlChar *URL, const xmlChar *ID, xmlNodePtr *lst) {
 return(xmlParseExternalEntityPrivate(doc, NULL, sax, user_data, depth, URL,
		                       ID, lst));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int equalizer_set_preset(equalizer_context_t *context, int preset)
{
 int i;

    ALOGV("%s: preset: %d", __func__, preset);
    context->preset = preset;
 for (i=0; i<NUM_EQ_BANDS; i++)
        context->band_levels[i] =
                 equalizer_band_presets_level[i + preset * NUM_EQ_BANDS];

    offload_eq_set_preset(&(context->offload_eq), preset);
    offload_eq_set_bands_level(&(context->offload_eq),
                               NUM_EQ_BANDS,
                               equalizer_band_presets_freq,
                               context->band_levels);
 if(context->ctl)
        offload_eq_send_params(context->ctl, &context->offload_eq,
                               OFFLOAD_SEND_EQ_ENABLE_FLAG |
                               OFFLOAD_SEND_EQ_PRESET);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;


 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
        ih264d_err_pic_dispbuf_mgr(ps_dec);
 return 0;
 }

 if(prev_slice_err == 1)
 {
 /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;


 if(!ps_dec->u1_first_slice_in_stream)
 {
            ih264d_end_of_pic(ps_dec, u1_is_idr_slice,
                ps_dec->ps_cur_slice->u2_frame_num);
            ps_dec->s_cur_pic_poc.u2_frame_num =
                ps_dec->ps_cur_slice->u2_frame_num;
 }

 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = 0;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
                       j = i;
 {
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }
 }
 }
 else
 {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;

 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info - 1;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

            ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
            ps_dec->u2_cur_mb_addr--;
            ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if(u1_num_mbs)
 {
 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

            ps_dec->u2_cur_slice_num++;
             ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
            ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
            ps_dec->ps_parse_cur_slice++;

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

    H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);

    ps_dec->u2_cur_slice_num++;

 /* incremented here only if first slice is inserted */
 if(ps_dec->u4_first_slice_in_pic != 0)
        ps_dec->ps_parse_cur_slice++;

    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void btif_dm_on_disable()
{
 /* cancel any pending pairing requests */
 if (pairing_cb.state == BT_BOND_STATE_BONDING)
 {
 bt_bdaddr_t bd_addr;

        BTIF_TRACE_DEBUG("%s: Cancel pending pairing request", __FUNCTION__);
        bdcpy(bd_addr.address, pairing_cb.bd_addr);
        btif_dm_cancel_bond(&bd_addr);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void DeleteImpl(Handle<JSObject> obj, uint32_t entry) {
 Handle<SeededNumberDictionary> dict(
 SeededNumberDictionary::cast(obj->elements()));
 uint32_t index = GetIndexForEntryImpl(*dict, entry);
 Handle<Object> result = SeededNumberDictionary::DeleteProperty(dict, entry);
    USE(result);
    DCHECK(result->IsTrue(dict->GetIsolate()));
 Handle<FixedArray> new_elements =
 SeededNumberDictionary::Shrink(dict, index);
    obj->set_elements(*new_elements);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool hal_open() {
  LOG_INFO("%s", __func__);

 int fd_array[CH_MAX];
 int number_of_ports = vendor->send_command(VENDOR_OPEN_USERIAL, &fd_array);

 if (number_of_ports != 1) {
    LOG_ERROR("%s opened the wrong number of ports: got %d, expected 1.", __func__, number_of_ports);
 goto error;
 }

  uart_fd = fd_array[0];
 if (uart_fd == INVALID_FD) {
    LOG_ERROR("%s unable to open the uart serial port.", __func__);
 goto error;
 }

  uart_stream = eager_reader_new(uart_fd, &allocator_malloc, HCI_HAL_SERIAL_BUFFER_SIZE, SIZE_MAX, "hci_single_channel");
 if (!uart_stream) {
    LOG_ERROR("%s unable to create eager reader for the uart serial port.", __func__);
 goto error;
 }

  stream_has_interpretation = false;
  stream_corruption_detected = false;
  stream_corruption_bytes_to_ignore = 0;
  eager_reader_register(uart_stream, thread_get_reactor(thread), event_uart_has_bytes, NULL);

  thread_set_priority(thread, HCI_THREAD_PRIORITY);
  thread_set_priority(eager_reader_get_read_thread(uart_stream), HCI_THREAD_PRIORITY);

 return true;

error:
  interface.close();
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int StreamingProcessor::getPreviewStreamId() const {
 Mutex::Autolock m(mMutex);
 return mPreviewStreamId;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static const void* printCommand(TextOutput& out, const void* _cmd)
{
 static const size_t N = sizeof(kCommandStrings)/sizeof(kCommandStrings[0]);
 const int32_t* cmd = (const int32_t*)_cmd;
 uint32_t code = (uint32_t)*cmd++;
 size_t cmdIndex = code & 0xff;

 if (cmdIndex >= N) {
        out << "Unknown command: " << code << endl;
 return cmd;
 }
    out << kCommandStrings[cmdIndex];

 switch (code) {
 case BC_TRANSACTION:
 case BC_REPLY: {
            out << ": " << indent;
            cmd = (const int32_t *)printBinderTransactionData(out, cmd);
            out << dedent;
 } break;
 
 case BC_ACQUIRE_RESULT: {
 const int32_t res = *cmd++;
            out << ": " << res << (res ? " (SUCCESS)" : " (FAILURE)");
 } break;
 
 case BC_FREE_BUFFER: {
 const int32_t buf = *cmd++;
            out << ": buffer=" << (void*)(long)buf;
 } break;
 
 case BC_INCREFS:
 case BC_ACQUIRE:
 case BC_RELEASE:
 case BC_DECREFS: {
 const int32_t d = *cmd++;
            out << ": desc=" << d;
 } break;
 
 case BC_INCREFS_DONE:
 case BC_ACQUIRE_DONE: {
 const int32_t b = *cmd++;
 const int32_t c = *cmd++;
            out << ": target=" << (void*)(long)b << " (cookie " << (void*)(long)c << ")";
 } break;
 
 case BC_ATTEMPT_ACQUIRE: {
 const int32_t p = *cmd++;
 const int32_t d = *cmd++;
            out << ": desc=" << d << ", pri=" << p;
 } break;
 
 case BC_REQUEST_DEATH_NOTIFICATION:
 case BC_CLEAR_DEATH_NOTIFICATION: {
 const int32_t h = *cmd++;
 const int32_t c = *cmd++;
            out << ": handle=" << h << " (death cookie " << (void*)(long)c << ")";
 } break;

 case BC_DEAD_BINDER_DONE: {
 const int32_t c = *cmd++;
            out << ": death cookie " << (void*)(long)c;
 } break;

 default:
 break;
 }
 
    out << endl;
 return cmd;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_venc::component_deinit(OMX_IN OMX_HANDLETYPE hComp)
{
 (void) hComp;
    OMX_U32 i = 0;
    DEBUG_PRINT_HIGH("omx_venc(): Inside component_deinit()");
 if (OMX_StateLoaded != m_state) {
        DEBUG_PRINT_ERROR("WARNING:Rxd DeInit,OMX not in LOADED state %d",\
                m_state);
 }
 if (m_out_mem_ptr) {
        DEBUG_PRINT_LOW("Freeing the Output Memory");
 for (i=0; i< m_sOutPortDef.nBufferCountActual; i++ ) {
 if (BITMASK_PRESENT(&m_out_bm_count, i)) {
                BITMASK_CLEAR(&m_out_bm_count, i);
                free_output_buffer (&m_out_mem_ptr[i]);
 }

 if (release_output_done()) {
 break;
 }
 }
        free(m_out_mem_ptr);
        m_out_mem_ptr = NULL;
 }

 /*Check if the input buffers have to be cleaned up*/
 if (m_inp_mem_ptr
#ifdef _ANDROID_ICS_
 && !meta_mode_enable
#endif
 ) {
        DEBUG_PRINT_LOW("Freeing the Input Memory");
 for (i=0; i<m_sInPortDef.nBufferCountActual; i++ ) {
 if (BITMASK_PRESENT(&m_inp_bm_count, i)) {
                BITMASK_CLEAR(&m_inp_bm_count, i);
                free_input_buffer (&m_inp_mem_ptr[i]);
 }

 if (release_input_done()) {
 break;
 }
 }


        free(m_inp_mem_ptr);
        m_inp_mem_ptr = NULL;
 }

    m_ftb_q.m_size=0;
    m_cmd_q.m_size=0;
    m_etb_q.m_size=0;
    m_ftb_q.m_read = m_ftb_q.m_write =0;
    m_cmd_q.m_read = m_cmd_q.m_write =0;
    m_etb_q.m_read = m_etb_q.m_write =0;

#ifdef _ANDROID_
    DEBUG_PRINT_HIGH("Calling m_heap_ptr.clear()");
    m_heap_ptr.clear();
#endif // _ANDROID_
    DEBUG_PRINT_HIGH("Calling venc_close()");
 if (handle) {
        handle->venc_close();
        DEBUG_PRINT_HIGH("Deleting HANDLE[%p]", handle);
 delete (handle);
        handle = NULL;
 }
    DEBUG_PRINT_INFO("Component Deinit");
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_fill_buf(void *buffer, void *pmem_data_buf,unsigned index,unsigned fd)
{
 struct pmem *temp_buffer = NULL;
 struct venc_buffer  frameinfo;
 struct v4l2_buffer buf;
 struct v4l2_plane plane[VIDEO_MAX_PLANES];
 int rc = 0;
 unsigned int extra_idx;
 struct OMX_BUFFERHEADERTYPE *bufhdr;

 if (buffer == NULL)
 return false;

    bufhdr = (OMX_BUFFERHEADERTYPE *)buffer;

 if (pmem_data_buf) {
        DEBUG_PRINT_LOW("Internal PMEM addr for o/p Heap UseBuf: %p", pmem_data_buf);
        plane[0].m.userptr = (unsigned long)pmem_data_buf;
 } else {
        DEBUG_PRINT_LOW("Shared PMEM addr for o/p PMEM UseBuf/AllocateBuf: %p", bufhdr->pBuffer);
        plane[0].m.userptr = (unsigned long)bufhdr->pBuffer;
 }

    buf.index = index;
    buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
    buf.memory = V4L2_MEMORY_USERPTR;
    plane[0].length = bufhdr->nAllocLen;
    plane[0].bytesused = bufhdr->nFilledLen;
    plane[0].reserved[0] = fd;
    plane[0].reserved[1] = 0;
    plane[0].data_offset = bufhdr->nOffset;
    buf.m.planes = plane;
    buf.length = num_planes;

    extra_idx = EXTRADATA_IDX(num_planes);

 if (extra_idx && (extra_idx < VIDEO_MAX_PLANES)) {
        plane[extra_idx].bytesused = 0;
        plane[extra_idx].length = extradata_info.buffer_size;
        plane[extra_idx].m.userptr = (unsigned long) (extradata_info.uaddr + index * extradata_info.buffer_size);
#ifdef USE_ION
        plane[extra_idx].reserved[0] = extradata_info.ion.fd_ion_data.fd;
#endif
        plane[extra_idx].reserved[1] = extradata_info.buffer_size * index;
        plane[extra_idx].data_offset = 0;
 } else if (extra_idx >= VIDEO_MAX_PLANES) {
        DEBUG_PRINT_ERROR("Extradata index higher than expected: %d", extra_idx);
 return false;
 }

    rc = ioctl(m_nDriver_fd, VIDIOC_QBUF, &buf);

 if (rc) {
        DEBUG_PRINT_ERROR("Failed to qbuf (ftb) to driver");
 return false;
 }

    ftb++;
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btm_sec_start_get_name (tBTM_SEC_DEV_REC *p_dev_rec)
{
    UINT8 tempstate = p_dev_rec->sec_state;

    p_dev_rec->sec_state = BTM_SEC_STATE_GETTING_NAME;

 /* Device should be connected, no need to provide correct page params */
 /* 0 and NULL are as timeout and callback params because they are not used in security get name case */
 if ((btm_initiate_rem_name (p_dev_rec->bd_addr, NULL, BTM_RMT_NAME_SEC,
 0, NULL)) != BTM_CMD_STARTED)
 {
        p_dev_rec->sec_state = tempstate;
 return(FALSE);
 }

 return(TRUE);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: RIL_startEventLoop(void) {
 /* spin up eventLoop thread and wait for it to get started */
    s_started = 0;
    pthread_mutex_lock(&s_startupMutex);

 pthread_attr_t attr;
    pthread_attr_init(&attr);
    pthread_attr_setdetachstate(&attr, PTHREAD_CREATE_DETACHED);

 int result = pthread_create(&s_tid_dispatch, &attr, eventLoop, NULL);
 if (result != 0) {
        RLOGE("Failed to create dispatch thread: %s", strerror(result));
 goto done;
 }

 while (s_started == 0) {
        pthread_cond_wait(&s_startupCond, &s_startupMutex);
 }

done:
    pthread_mutex_unlock(&s_startupMutex);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Camera3Device::PreparerThread::~PreparerThread() {
 Thread::requestExitAndWait();
 if (mCurrentStream != nullptr) {
        mCurrentStream->cancelPrepare();
        ATRACE_ASYNC_END("stream prepare", mCurrentStream->getId());
        mCurrentStream.clear();
 }
    clear();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MediaPlayerService::AudioOutput::setAudioStreamType(audio_stream_type_t streamType)
{
 Mutex::Autolock lock(mLock);
 if (mAttributes == NULL) {
        mStreamType = streamType;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API FLAC__bool FLAC__stream_decoder_process_until_end_of_metadata(FLAC__StreamDecoder *decoder)
{
	FLAC__ASSERT(0 != decoder);
	FLAC__ASSERT(0 != decoder->protected_);

 while(1) {
 switch(decoder->protected_->state) {
 case FLAC__STREAM_DECODER_SEARCH_FOR_METADATA:
 if(!find_metadata_(decoder))
 return false; /* above function sets the status for us */
 break;
 case FLAC__STREAM_DECODER_READ_METADATA:
 if(!read_metadata_(decoder))
 return false; /* above function sets the status for us */
 break;
 case FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC:
 case FLAC__STREAM_DECODER_READ_FRAME:
 case FLAC__STREAM_DECODER_END_OF_STREAM:
 case FLAC__STREAM_DECODER_ABORTED:
 return true;
 default:
				FLAC__ASSERT(0);
 return false;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint16_t AVRC_MsgReq(uint8_t handle, uint8_t label, uint8_t ctype,
                     BT_HDR* p_pkt) {
 uint8_t* p_data;
 uint8_t cr = AVCT_CMD;
 bool chk_frag = true;
 uint8_t* p_start = NULL;
  tAVRC_FRAG_CB* p_fcb;
 uint16_t len;
 uint16_t status;
 uint8_t msg_mask = 0;
 uint16_t peer_mtu;

 if (!p_pkt) return AVRC_BAD_PARAM;

  AVRC_TRACE_DEBUG("%s handle = %u label = %u ctype = %u len = %d", __func__,
                   handle, label, ctype, p_pkt->len);

 if (ctype >= AVRC_RSP_NOT_IMPL) cr = AVCT_RSP;

 if (p_pkt->event == AVRC_OP_VENDOR) {
 /* add AVRCP Vendor Dependent headers */
    p_start = ((uint8_t*)(p_pkt + 1) + p_pkt->offset);
    p_pkt->offset -= AVRC_VENDOR_HDR_SIZE;
    p_pkt->len += AVRC_VENDOR_HDR_SIZE;
    p_data = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
 *p_data++ = (ctype & AVRC_CTYPE_MASK);
 *p_data++ = (AVRC_SUB_PANEL << AVRC_SUBTYPE_SHIFT);
 *p_data++ = AVRC_OP_VENDOR;
    AVRC_CO_ID_TO_BE_STREAM(p_data, AVRC_CO_METADATA);

 /* Check if this is a AVRC_PDU_REQUEST_CONTINUATION_RSP */
 if (cr == AVCT_CMD) {
      msg_mask |= AVRC_MSG_MASK_IS_VENDOR_CMD;

 if ((*p_start == AVRC_PDU_REQUEST_CONTINUATION_RSP) ||
 (*p_start == AVRC_PDU_ABORT_CONTINUATION_RSP)) {
        msg_mask |= AVRC_MSG_MASK_IS_CONTINUATION_RSP;
 }
 }
 } else if (p_pkt->event == AVRC_OP_PASS_THRU) {
 /* add AVRCP Pass Through headers */
    p_start = ((uint8_t*)(p_pkt + 1) + p_pkt->offset);
    p_pkt->offset -= AVRC_PASS_THRU_SIZE;
    p_pkt->len += AVRC_PASS_THRU_SIZE;
    p_data = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
 *p_data++ = (ctype & AVRC_CTYPE_MASK);
 *p_data++ = (AVRC_SUB_PANEL << AVRC_SUBTYPE_SHIFT);
 *p_data++ = AVRC_OP_PASS_THRU; /* opcode */
 *p_data++ = AVRC_ID_VENDOR; /* operation id */
 *p_data++ = 5; /* operation data len */
    AVRC_CO_ID_TO_BE_STREAM(p_data, AVRC_CO_METADATA);
 } else {
    chk_frag = false;
    peer_mtu = AVCT_GetBrowseMtu(handle);
 if (p_pkt->len > (peer_mtu - AVCT_HDR_LEN_SINGLE)) {
      AVRC_TRACE_ERROR(
 "%s bigger than peer mtu (p_pkt->len(%d) > peer_mtu(%d-%d))",
          __func__, p_pkt->len, peer_mtu, AVCT_HDR_LEN_SINGLE);
      osi_free(p_pkt);
 return AVRC_MSG_TOO_BIG;
 }
 }

 /* abandon previous fragments */
  p_fcb = &avrc_cb.fcb[handle];

 if (p_fcb == NULL) {
    AVRC_TRACE_ERROR("%s p_fcb is NULL", __func__);
    osi_free(p_pkt);
 return AVRC_NOT_OPEN;
 }

 if (p_fcb->frag_enabled) p_fcb->frag_enabled = false;

  osi_free_and_reset((void**)&p_fcb->p_fmsg);

 /* AVRCP spec has not defined any control channel commands that needs
   * fragmentation at this level
   * check for fragmentation only on the response */
 if ((cr == AVCT_RSP) && (chk_frag)) {
 if (p_pkt->len > AVRC_MAX_CTRL_DATA_LEN) {
 int offset_len = MAX(AVCT_MSG_OFFSET, p_pkt->offset);
      BT_HDR* p_pkt_new =
 (BT_HDR*)osi_malloc(AVRC_PACKET_LEN + offset_len + BT_HDR_SIZE);
 if (p_start != NULL) {
        p_fcb->frag_enabled = true;
        p_fcb->p_fmsg = p_pkt;
        p_fcb->frag_pdu = *p_start;
        p_pkt = p_pkt_new;
        p_pkt_new = p_fcb->p_fmsg;
        p_pkt->len = AVRC_MAX_CTRL_DATA_LEN;
        p_pkt->offset = p_pkt_new->offset;
        p_pkt->layer_specific = p_pkt_new->layer_specific;
        p_pkt->event = p_pkt_new->event;
        p_data = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
        p_start -= AVRC_VENDOR_HDR_SIZE;
        memcpy(p_data, p_start, AVRC_MAX_CTRL_DATA_LEN);
 /* use AVRC start packet type */
        p_data += AVRC_VENDOR_HDR_SIZE;
        p_data++; /* pdu */
 *p_data++ = AVRC_PKT_START;

 /* 4 pdu, pkt_type & len */
        len = (AVRC_MAX_CTRL_DATA_LEN - AVRC_VENDOR_HDR_SIZE -
               AVRC_MIN_META_HDR_SIZE);
        UINT16_TO_BE_STREAM(p_data, len);

 /* prepare the left over for as an end fragment */
        avrc_prep_end_frag(handle);
        AVRC_TRACE_DEBUG("%s p_pkt len:%d/%d, next len:%d", __func__,
                         p_pkt->len, len, p_fcb->p_fmsg->len);
 } else {
 /* TODO: Is this "else" block valid? Remove it? */
        AVRC_TRACE_ERROR("%s no buffers for fragmentation", __func__);
        osi_free(p_pkt);
 return AVRC_NO_RESOURCES;
 }
 }
 } else if ((p_pkt->event == AVRC_OP_VENDOR) && (cr == AVCT_CMD) &&
 (avrc_cb.ccb_int[handle].flags & AVRC_CB_FLAGS_RSP_PENDING) &&
 !(msg_mask & AVRC_MSG_MASK_IS_CONTINUATION_RSP)) {
 /* If we are sending a vendor specific command, and a response is pending,
     * then enqueue the command until the response has been received.
     * This is to interop with TGs that abort sending responses whenever a new
     * command
     * is received (exception is continuation request command
     * must sent that to get additional response frags) */
    AVRC_TRACE_DEBUG(
 "AVRC: Enqueuing command 0x%08x (handle=0x%02x, label=0x%02x)", p_pkt,
        handle, label);

 /* label in BT_HDR (will need this later when the command is dequeued) */
    p_pkt->layer_specific = (label << 8) | (p_pkt->layer_specific & 0xFF);

 /* Enqueue the command */
    fixed_queue_enqueue(avrc_cb.ccb_int[handle].cmd_q, p_pkt);
 return AVRC_SUCCESS;
 }

 /* Send the message */
  status = AVCT_MsgReq(handle, label, cr, p_pkt);
 if ((status == AVCT_SUCCESS) && (cr == AVCT_CMD)) {
 /* If a command was successfully sent, indicate that a response is pending
     */
    avrc_cb.ccb_int[handle].flags |= AVRC_CB_FLAGS_RSP_PENDING;

 /* Start command timer to wait for response */
    avrc_start_cmd_timer(handle, label, msg_mask);
 }

 return status;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void btif_hl_clean_pcb(btif_hl_pending_chan_cb_t *p_pcb)
{
    BTIF_TRACE_DEBUG("%s", __FUNCTION__ );
    memset(p_pcb, 0 , sizeof(btif_hl_pending_chan_cb_t));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual uint32_t getCaps() {
 Parcel data, reply;
        data.writeInterfaceToken(IHDCP::getInterfaceDescriptor());
        remote()->transact(HDCP_GET_CAPS, data, &reply);
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_set_default(iv_obj_t *ps_dechdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 dec_state_t *ps_dec_state;
 dec_state_multi_core_t *ps_dec_state_multi_core;
 impeg2d_ctl_set_config_op_t *ps_ctl_dec_op =
 (impeg2d_ctl_set_config_op_t *)pv_api_op;

    UNUSED(pv_api_ip);

    ps_ctl_dec_op->s_ivd_ctl_set_config_op_t.u4_error_code  = IV_SUCCESS;
    ps_ctl_dec_op->s_ivd_ctl_set_config_op_t.u4_size        =
 sizeof(impeg2d_ctl_set_config_op_t);

    ps_dec_state_multi_core =
 (dec_state_multi_core_t *)(ps_dechdl->pv_codec_handle);
    ps_dec_state            = ps_dec_state_multi_core->ps_dec_state[0];

    ps_dec_state->u1_flushfrm   = 0;
    ps_dec_state->u2_decode_header = 1;

 if (1 == ps_dec_state->u2_header_done)
 {
        ps_dec_state->u4_frm_buf_stride = ps_dec_state->u2_frame_width;
 }

    ps_ctl_dec_op->s_ivd_ctl_set_config_op_t.u4_error_code = IV_SUCCESS;

 return (IV_SUCCESS);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAAC2::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {
 const OMX_PARAM_COMPONENTROLETYPE *roleParams =
 (const OMX_PARAM_COMPONENTROLETYPE *)params;

 if (!isValidOMXParam(roleParams)) {
 return OMX_ErrorBadParameter;
 }

 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.aac",
                        OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {
 const OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
 (const OMX_AUDIO_PARAM_AACPROFILETYPE *)params;

 if (!isValidOMXParam(aacParams)) {
 return OMX_ErrorBadParameter;
 }

 if (aacParams->nPortIndex != 0) {
 return OMX_ErrorUndefined;
 }

 if (aacParams->eAACStreamFormat == OMX_AUDIO_AACStreamFormatMP4FF) {
                mIsADTS = false;
 } else if (aacParams->eAACStreamFormat
 == OMX_AUDIO_AACStreamFormatMP4ADTS) {
                mIsADTS = true;
 } else {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidAacPresentation:
 {
 const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *aacPresParams =
 (const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *)params;

 if (!isValidOMXParam(aacPresParams)) {
 return OMX_ErrorBadParameter;
 }

 if (aacPresParams->nMaxOutputChannels >= 0) {
 int max;
 if (aacPresParams->nMaxOutputChannels >= 8) { max = 8; }
 else if (aacPresParams->nMaxOutputChannels >= 6) { max = 6; }
 else if (aacPresParams->nMaxOutputChannels >= 2) { max = 2; }
 else {
                    max = aacPresParams->nMaxOutputChannels;
 }
                ALOGV("set nMaxOutputChannels=%d", max);
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_MAX_OUTPUT_CHANNELS, max);
 }
 bool updateDrcWrapper = false;
 if (aacPresParams->nDrcBoost >= 0) {
                ALOGV("set nDrcBoost=%d", aacPresParams->nDrcBoost);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_BOOST_FACTOR,
                        aacPresParams->nDrcBoost);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nDrcCut >= 0) {
                ALOGV("set nDrcCut=%d", aacPresParams->nDrcCut);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_ATT_FACTOR, aacPresParams->nDrcCut);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nHeavyCompression >= 0) {
                ALOGV("set nHeavyCompression=%d", aacPresParams->nHeavyCompression);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_HEAVY,
                        aacPresParams->nHeavyCompression);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nTargetReferenceLevel >= 0) {
                ALOGV("set nTargetReferenceLevel=%d", aacPresParams->nTargetReferenceLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_TARGET,
                        aacPresParams->nTargetReferenceLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nEncodedTargetLevel >= 0) {
                ALOGV("set nEncodedTargetLevel=%d", aacPresParams->nEncodedTargetLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_ENCODER_TARGET,
                        aacPresParams->nEncodedTargetLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nPCMLimiterEnable >= 0) {
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_LIMITER_ENABLE,
 (aacPresParams->nPCMLimiterEnable != 0));
 }
 if (updateDrcWrapper) {
                mDrcWrap.update();
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {
 const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE SoftG711::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {
            OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex > 1) {
 return OMX_ErrorUndefined;
 }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
 if (pcmParams->nPortIndex == 0) {
                pcmParams->ePCMMode = mIsMLaw ? OMX_AUDIO_PCMModeMULaw
 : OMX_AUDIO_PCMModeALaw;
 } else {
                pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
 }
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool btif_av_state_started_handler(btif_sm_event_t event, void* p_data) {
  tBTA_AV* p_av = (tBTA_AV*)p_data;

  BTIF_TRACE_DEBUG("%s: event=%s flags=0x%x", __func__,
                   dump_av_sm_event_name((btif_av_sm_event_t)event),
                   btif_av_cb.flags);

 switch (event) {
 case BTIF_SM_ENTER_EVT:

 /* we are again in started state, clear any remote suspend flags */
      btif_av_cb.flags &= ~BTIF_AV_FLAG_REMOTE_SUSPEND;

 /**
       * Report to components above that we have entered the streaming
       * stage, this should usually be followed by focus grant.
       * see update_audio_focus_state()
       */
      btif_report_audio_state(BTAV_AUDIO_STATE_STARTED, &(btif_av_cb.peer_bda));
 break;

 case BTIF_SM_EXIT_EVT:
 break;

 case BTIF_AV_START_STREAM_REQ_EVT:
 /* we were remotely started, just ack back the local request */
 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK)
        btif_a2dp_on_started(NULL, true);
 break;

 case BTIF_AV_SOURCE_CONFIG_REQ_EVT:
      btif_update_source_codec(p_data);
 break;

 case BTIF_AV_SOURCE_CONFIG_UPDATED_EVT:
      btif_report_source_codec_state(p_data);
 break;

 /* fixme -- use suspend = true always to work around issue with BTA AV */
 case BTIF_AV_STOP_STREAM_REQ_EVT:
 case BTIF_AV_SUSPEND_STREAM_REQ_EVT:
      BTIF_TRACE_WARNING("%s: event=%s flags=0x%x", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event),
                         btif_av_cb.flags);
 /* set pending flag to ensure btif task is not trying to restart
         stream while suspend is in progress */
      btif_av_cb.flags |= BTIF_AV_FLAG_LOCAL_SUSPEND_PENDING;

 /* if we were remotely suspended but suspend locally, local suspend
         always overrides */
      btif_av_cb.flags &= ~BTIF_AV_FLAG_REMOTE_SUSPEND;

 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK) {
 /*
         * Immediately stop transmission of frames while suspend is
         * pending.
         */
        btif_a2dp_source_set_tx_flush(true);
 }

 if (btif_av_cb.peer_sep == AVDT_TSEP_SRC) {
        btif_a2dp_on_stopped(NULL);
 }

      BTA_AvStop(true);
 break;

 case BTIF_AV_DISCONNECT_REQ_EVT:
      BTIF_TRACE_WARNING("%s: event=%s flags=0x%x", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event),
                         btif_av_cb.flags);

 /* request avdtp to close */
      BTA_AvClose(btif_av_cb.bta_handle);
 if (btif_av_cb.peer_sep == AVDT_TSEP_SRC) {
        BTA_AvCloseRc(btif_av_cb.bta_handle);
 }

 /* inform the application that we are disconnecting */
      btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTING,
 &(btif_av_cb.peer_bda));

 /* wait in closing state until fully closed */
      btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_CLOSING);
 break;

 case BTA_AV_SUSPEND_EVT:
      BTIF_TRACE_WARNING(
 "%s: BTA_AV_SUSPEND_EVT status=%d initiator=%d flags=0x%x", __func__,
          p_av->suspend.status, p_av->suspend.initiator, btif_av_cb.flags);

 /* a2dp suspended, stop media task until resumed */
      btif_a2dp_on_suspended(&p_av->suspend);

 /* if not successful, remain in current state */
 if (p_av->suspend.status != BTA_AV_SUCCESS) {
        btif_av_cb.flags &= ~BTIF_AV_FLAG_LOCAL_SUSPEND_PENDING;

 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK) {
 /* suspend failed, reset back tx flush state */
          btif_a2dp_source_set_tx_flush(false);
 }
 return false;
 }

 if (p_av->suspend.initiator != true) {
 /* remote suspend, notify HAL and await audioflinger to
           suspend/stop stream */

 /* set remote suspend flag to block media task from restarting
           stream only if we did not already initiate a local suspend */
 if ((btif_av_cb.flags & BTIF_AV_FLAG_LOCAL_SUSPEND_PENDING) == 0)
          btif_av_cb.flags |= BTIF_AV_FLAG_REMOTE_SUSPEND;

        btif_report_audio_state(BTAV_AUDIO_STATE_REMOTE_SUSPEND,
 &(btif_av_cb.peer_bda));
 } else {
        btif_report_audio_state(BTAV_AUDIO_STATE_STOPPED,
 &(btif_av_cb.peer_bda));
 }

      btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_OPENED);

 /* suspend completed and state changed, clear pending status */
      btif_av_cb.flags &= ~BTIF_AV_FLAG_LOCAL_SUSPEND_PENDING;
 break;

 case BTA_AV_STOP_EVT:
      BTIF_TRACE_WARNING("%s: event=%s flags=0x%x", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event),
                         btif_av_cb.flags);

      btif_av_cb.flags |= BTIF_AV_FLAG_PENDING_STOP;
      btif_a2dp_on_stopped(&p_av->suspend);

      btif_report_audio_state(BTAV_AUDIO_STATE_STOPPED, &(btif_av_cb.peer_bda));

 /* if stop was successful, change state to open */
 if (p_av->suspend.status == BTA_AV_SUCCESS)
        btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_OPENED);

 break;

 case BTA_AV_CLOSE_EVT:
      BTIF_TRACE_WARNING("%s: event=%s flags=0x%x", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event),
                         btif_av_cb.flags);

      btif_av_cb.flags |= BTIF_AV_FLAG_PENDING_STOP;

 /* avdtp link is closed */
      btif_a2dp_on_stopped(NULL);

 /* inform the application that we are disconnected */
      btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTED,
 &(btif_av_cb.peer_bda));

      btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_IDLE);
 break;

 case BTIF_AV_OFFLOAD_START_REQ_EVT:
      BTA_AvOffloadStart(btif_av_cb.bta_handle);
 break;

 case BTA_AV_OFFLOAD_START_RSP_EVT:
      btif_a2dp_on_offload_started(p_av->status);
 break;

      CHECK_RC_EVENT(event, (tBTA_AV*)p_data);

 default:
      BTIF_TRACE_WARNING("%s: unhandled event=%s", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event));
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: BOOLEAN btm_sec_create_conn (BD_ADDR bda, UINT16 packet_types,
                             UINT8 page_scan_rep_mode, UINT8 page_scan_mode,
                             UINT16 clock_offset, UINT8 allow_switch)
{
    tBTM_SEC_DEV_REC *p_dev_rec = btm_find_or_alloc_dev (bda);

    memcpy (btm_cb.connecting_bda, p_dev_rec->bd_addr,   BD_ADDR_LEN);
    memcpy (btm_cb.connecting_dc,  p_dev_rec->dev_class, DEV_CLASS_LEN);

    btm_cb.acl_disc_reason = 0xff ;

    p_dev_rec->sec_state   = BTM_SEC_STATE_IDLE;
    p_dev_rec->role_master = TRUE;

 /* If any SCO link up, do not allow a switch */
 if (BTM_GetNumScoLinks() != 0)
        allow_switch = HCI_CR_CONN_NOT_ALLOW_SWITCH;

 return(btsnd_hcic_create_conn (bda, packet_types, page_scan_rep_mode,
                                   page_scan_mode, clock_offset, allow_switch));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_assign_display_seq(dec_struct_t *ps_dec)
{
    WORD32 i;
    WORD32 i4_min_poc;
    WORD32 i4_min_poc_buf_id;
    WORD32 i4_min_index;
 dpb_manager_t *ps_dpb_mgr = ps_dec->ps_dpb_mgr;
    WORD32 (*i4_poc_buf_id_map)[3] = ps_dpb_mgr->ai4_poc_buf_id_map;

    i4_min_poc = 0x7fffffff;
    i4_min_poc_buf_id = -1;
    i4_min_index = -1;

 if(ps_dpb_mgr->i1_poc_buf_id_entries >= ps_dec->i4_display_delay)
 {
 for(i = 0; i < MAX_FRAMES; i++)
 {
 if((i4_poc_buf_id_map[i][0] != -1)
 && (DO_NOT_DISP
 != ps_dpb_mgr->ai4_poc_buf_id_map[i][0]))
 {
 if(i4_poc_buf_id_map[i][1] < i4_min_poc)
 {
                    i4_min_poc = i4_poc_buf_id_map[i][1];
                    i4_min_poc_buf_id = i4_poc_buf_id_map[i][0];
                    i4_min_index = i;
 }
 }
 }

 if((i4_min_index != -1) && (DO_NOT_DISP != i4_min_poc_buf_id))
 {
            ps_dec->i4_cur_display_seq++;
            ih264_disp_mgr_add(
 (disp_mgr_t *)ps_dec->pv_disp_buf_mgr,
                            i4_min_poc_buf_id, ps_dec->i4_cur_display_seq,
                            ps_dec->apv_buf_id_pic_buf_map[i4_min_poc_buf_id]);
            i4_poc_buf_id_map[i4_min_index][0] = -1;
            i4_poc_buf_id_map[i4_min_index][1] = 0x7fffffff;
            ps_dpb_mgr->i1_poc_buf_id_entries--;
 }
 else if(DO_NOT_DISP == i4_min_poc_buf_id)
 {
            WORD32 i4_error_code;
            i4_error_code = ERROR_GAPS_IN_FRM_NUM;
 return i4_error_code;
 }
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint8_t bta_av_find_lcb_index_by_scb_and_address(
 const RawAddress& peer_address) {
  APPL_TRACE_DEBUG("%s: peer_address: %s conn_lcb: 0x%x", __func__,
                   peer_address.ToString().c_str(), bta_av_cb.conn_lcb);

 for (uint8_t index = 0; index < BTA_AV_NUM_LINKS; index++) {
 uint8_t mask = 1 << index;
 if (mask & bta_av_cb.conn_lcb) {
 continue;
 }
    tBTA_AV_SCB* p_scb = bta_av_cb.p_scb[index];
 if (p_scb == nullptr) {
 continue;
 }
 if (p_scb->PeerAddress() == peer_address) {
 return index;
 }
 }

 for (uint8_t index = 0; index < BTA_AV_NUM_LINKS; index++) {
 uint8_t mask = 1 << index;
 if (mask & bta_av_cb.conn_lcb) {
 continue;
 }
    tBTA_AV_SCB* p_scb = bta_av_cb.p_scb[index];
 if (p_scb == nullptr) {
 continue;
 }
 if (!p_scb->IsAssigned()) {
 return index;
 }
 }

 return BTA_AV_NUM_LINKS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::createGraphicBufferSource(

         OMX_U32 portIndex, sp<IGraphicBufferConsumer> bufferConsumer, MetadataBufferType *type) {
     status_t err;
 
    const sp<GraphicBufferSource>& surfaceCheck = getGraphicBufferSource();
     if (surfaceCheck != NULL) {
         if (portIndex < NELEM(mMetadataType) && type != NULL) {
             *type = mMetadataType[portIndex];
 }
 return ALREADY_EXISTS;
 }

 if (type != NULL) {
 *type = kMetadataBufferTypeANWBuffer;
 }
    err = storeMetaDataInBuffers_l(portIndex, OMX_TRUE, type);
 if (err != OK) {
 return err;
 }

    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;
    OMX_ERRORTYPE oerr = OMX_GetParameter(
            mHandle, OMX_IndexParamPortDefinition, &def);
 if (oerr != OMX_ErrorNone) {
        OMX_INDEXTYPE index = OMX_IndexParamPortDefinition;
        CLOG_ERROR(getParameter, oerr, "%s(%#x): %s:%u",
                asString(index), index, portString(portIndex), portIndex);
 return UNKNOWN_ERROR;
 }

 if (def.format.video.eColorFormat != OMX_COLOR_FormatAndroidOpaque) {
        CLOGW("createInputSurface requires COLOR_FormatSurface "
 "(AndroidOpaque) color format instead of %s(%#x)",
                asString(def.format.video.eColorFormat), def.format.video.eColorFormat);
 return INVALID_OPERATION;
 }

 uint32_t usageBits;
    oerr = OMX_GetParameter(
            mHandle, (OMX_INDEXTYPE)OMX_IndexParamConsumerUsageBits, &usageBits);
 if (oerr != OMX_ErrorNone) {
        usageBits = 0;
 }

    sp<GraphicBufferSource> bufferSource = new GraphicBufferSource(this,
            def.format.video.nFrameWidth,
            def.format.video.nFrameHeight,
            def.nBufferCountActual,
            usageBits,
            bufferConsumer);

 if ((err = bufferSource->initCheck()) != OK) {
 return err;
 }
    setGraphicBufferSource(bufferSource);

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bt_status_t init( bthl_callbacks_t* callbacks ){
 bt_status_t status = BT_STATUS_SUCCESS;

    BTIF_TRACE_EVENT("%s", __FUNCTION__);
    btif_hl_display_calling_process_name();
    bt_hl_callbacks_cb = *callbacks;
    bt_hl_callbacks = &bt_hl_callbacks_cb;
    btif_hl_soc_thread_init();
    reg_counter = 0;
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual ~TileIndependenceTest() {
 delete fw_dec_;
 delete inv_dec_;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: AudioTrack::AudioTrack(Segment* pSegment, long long element_start,
 long long element_size)
 : Track(pSegment, element_start, element_size) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::use_input_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes,
        OMX_IN OMX_U8*                   buffer)
{
 (void) hComp;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;

 unsigned   i = 0;
 unsigned char *buf_addr = NULL;

    DEBUG_PRINT_HIGH("use_input_buffer: port = %u appData = %p bytes = %u buffer = %p",(unsigned int)port,appData,(unsigned int)bytes,buffer);
 if (bytes != m_sInPortDef.nBufferSize) {
        DEBUG_PRINT_ERROR("ERROR: use_input_buffer: Size Mismatch!! "
 "bytes[%u] != Port.nBufferSize[%u]", (unsigned int)bytes, (unsigned int)m_sInPortDef.nBufferSize);
 return OMX_ErrorBadParameter;
 }

 if (!m_inp_mem_ptr) {
        input_use_buffer = true;
        m_inp_mem_ptr = (OMX_BUFFERHEADERTYPE*) \
                        calloc( (sizeof(OMX_BUFFERHEADERTYPE)), m_sInPortDef.nBufferCountActual);
 if (m_inp_mem_ptr == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_inp_mem_ptr");
 return OMX_ErrorInsufficientResources;
 }
        DEBUG_PRINT_LOW("Successfully allocated m_inp_mem_ptr = %p", m_inp_mem_ptr);


        m_pInput_pmem = (struct pmem *) calloc(sizeof (struct pmem), m_sInPortDef.nBufferCountActual);
 if (m_pInput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_pmem");
 return OMX_ErrorInsufficientResources;
 }
#ifdef USE_ION
        m_pInput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sInPortDef.nBufferCountActual);
 if (m_pInput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif

 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
            m_pInput_pmem[i].fd = -1;
#ifdef USE_ION
            m_pInput_ion[i].ion_device_fd =-1;
            m_pInput_ion[i].fd_ion_data.fd =-1;
            m_pInput_ion[i].ion_alloc_data.handle = 0;
#endif
 }

 }

 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_inp_bm_count,i)) {
 break;
 }
 }

 if (i < m_sInPortDef.nBufferCountActual) {

 *bufferHdr = (m_inp_mem_ptr + i);
        BITMASK_SET(&m_inp_bm_count,i);

 (*bufferHdr)->pBuffer           = (OMX_U8 *)buffer;
 (*bufferHdr)->nSize             = sizeof(OMX_BUFFERHEADERTYPE);
 (*bufferHdr)->nVersion.nVersion = OMX_SPEC_VERSION;
 (*bufferHdr)->nAllocLen         = m_sInPortDef.nBufferSize;
 (*bufferHdr)->pAppPrivate       = appData;
 (*bufferHdr)->nInputPortIndex   = PORT_INDEX_IN;

 if (!m_use_input_pmem) {
#ifdef USE_ION
#ifdef _MSM8974_
            m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,0);
#else
            m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pInput_ion[i].ion_device_fd < 0) {
                DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }
            m_pInput_pmem[i].fd = m_pInput_ion[i].fd_ion_data.fd;
#else
            m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 if (m_pInput_pmem[i].fd == 0) {
                m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pInput_pmem[i] .fd < 0) {
                DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() Failed");
 return OMX_ErrorInsufficientResources;
 }
#endif

             m_pInput_pmem[i].size = m_sInPortDef.nBufferSize;
             m_pInput_pmem[i].offset = 0;
 
            m_pInput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
             if(!secure_session) {
                 m_pInput_pmem[i].buffer = (unsigned char *)mmap(
                     NULL,m_pInput_pmem[i].size,PROT_READ|PROT_WRITE,
                    MAP_SHARED,m_pInput_pmem[i].fd,0);

 
             if (m_pInput_pmem[i].buffer == MAP_FAILED) {
                     DEBUG_PRINT_ERROR("ERROR: mmap() Failed");
                 close(m_pInput_pmem[i].fd);
 #ifdef USE_ION
                 free_ion_memory(&m_pInput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 }

 } else {
            OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO *pParam = reinterpret_cast<OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO *>((*bufferHdr)->pAppPrivate);
            DEBUG_PRINT_LOW("Inside qcom_ext with luma:(fd:%lu,offset:0x%x)", pParam->pmem_fd, (unsigned)pParam->offset);

 if (pParam) {
                m_pInput_pmem[i].fd = pParam->pmem_fd;
                m_pInput_pmem[i].offset = pParam->offset;
                m_pInput_pmem[i].size = m_sInPortDef.nBufferSize;
                m_pInput_pmem[i].buffer = (unsigned char *)buffer;
                DEBUG_PRINT_LOW("DBG:: pParam->pmem_fd = %u, pParam->offset = %u",
 (unsigned int)pParam->pmem_fd, (unsigned int)pParam->offset);
 } else {
                DEBUG_PRINT_ERROR("ERROR: Invalid AppData given for PMEM i/p UseBuffer case");
 return OMX_ErrorBadParameter;
 }
 }

        DEBUG_PRINT_LOW("use_inp:: bufhdr = %p, pBuffer = %p, m_pInput_pmem[i].buffer = %p",
 (*bufferHdr), (*bufferHdr)->pBuffer, m_pInput_pmem[i].buffer);
 if ( dev_use_buf(&m_pInput_pmem[i],PORT_INDEX_IN,i) != true) {
            DEBUG_PRINT_ERROR("ERROR: dev_use_buf() Failed for i/p buf");
 return OMX_ErrorInsufficientResources;
 }
 } else {
        DEBUG_PRINT_ERROR("ERROR: All buffers are already used, invalid use_buf call for "
 "index = %u", i);
        eRet = OMX_ErrorInsufficientResources;
 }

 return eRet;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void local_socket_ready_notify(asocket* s) {
    s->ready = local_socket_ready;
    s->shutdown = NULL;
    s->close = local_socket_close;
 SendOkay(s->fd);
    s->ready(s);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: config_t *config_new_empty(void) {
 config_t *config = osi_calloc(sizeof(config_t));
 if (!config) {
    LOG_ERROR("%s unable to allocate memory for config_t.", __func__);
 goto error;
 }

  config->sections = list_new(section_free);
 if (!config->sections) {
    LOG_ERROR("%s unable to allocate list for sections.", __func__);
 goto error;
 }

 return config;

error:;
  config_free(config);
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_unpack_coeff8x8_8x8blk_cavlc(dec_struct_t * ps_dec,
 dec_mb_info_t * ps_cur_mb_info,
                                            UWORD16 ui2_luma_csbp,
                                            WORD16 *pi2_out_coeff_data)
{
    UWORD8 *pu1_inv_scan;
    UWORD8 u1_mb_field_decoding_flag = ps_cur_mb_info->u1_mb_field_decodingflag;
    UWORD8 u1_field_coding_flag = ps_cur_mb_info->ps_curmb->u1_mb_fld;
    WORD32 dc_only_flag = 0;

    PROFILE_DISABLE_UNPACK_LUMA()
 if(ui2_luma_csbp & 0x33)
 {
        memset(pi2_out_coeff_data,0,64*sizeof(WORD16));
 }

 if(!u1_mb_field_decoding_flag)
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[0];
 }
 else
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[0];
 }
 if(ui2_luma_csbp & 0x1)
 {
        dc_only_flag = ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
 }

 if(!u1_mb_field_decoding_flag)
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[1];
 }
 else
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[1];
 }
 if(ui2_luma_csbp & 0x2)
 {
        dc_only_flag = 0;
        ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
 }

 if(!u1_mb_field_decoding_flag)
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[2];
 }
 else
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[2];
 }
 if(ui2_luma_csbp & 0x10)
 {
        dc_only_flag = 0;
        ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
 }

 if(!u1_mb_field_decoding_flag)
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[3];
 }
 else
 {
        pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[3];
 }
 if(ui2_luma_csbp & 0x20)
 {
        dc_only_flag = 0;
        ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
 }
 return dc_only_flag;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: perform_one_test(FILE *fp, int argc, const char **argv,
   png_uint_32 *default_flags, display *d, int set_callback)
{
 int def;
   png_uint_32 flags[2][4];

   rewind(fp);
   clear_keep();
   memcpy(flags[0], default_flags, sizeof flags[0]);

   def = check(fp, argc, argv, flags[1], d, set_callback);

 /* Chunks should either be known or unknown, never both and this should apply
    * whether the chunk is before or after the IDAT (actually, the app can
    * probably change this by swapping the handling after the image, but this
    * test does not do that.)
    */
   check_error(d, (flags[0][0]|flags[0][2]) & (flags[0][1]|flags[0][3]),
 "chunk handled inconsistently in count tests");
   check_error(d, (flags[1][0]|flags[1][2]) & (flags[1][1]|flags[1][3]),
 "chunk handled inconsistently in option tests");

 /* Now find out what happened to each chunk before and after the IDAT and
    * determine if the behavior was correct.  First some basic sanity checks,
    * any known chunk should be known in the original count, any unknown chunk
    * should be either known or unknown in the original.
    */
 {
      png_uint_32 test;

      test = flags[1][0] & ~flags[0][0];
      check_error(d, test, "new known chunk before IDAT");
      test = flags[1][1] & ~(flags[0][0] | flags[0][1]);
      check_error(d, test, "new unknown chunk before IDAT");
      test = flags[1][2] & ~flags[0][2];
      check_error(d, test, "new known chunk after IDAT");
      test = flags[1][3] & ~(flags[0][2] | flags[0][3]);
      check_error(d, test, "new unknown chunk after IDAT");
 }

 /* Now each chunk in the original list should have been handled according to
    * the options set for that chunk, regardless of whether libpng knows about
    * it or not.
    */
   check_handling(d, def, flags[0][0] | flags[0][1], flags[1][0], flags[1][1],
 "before IDAT", set_callback);
   check_handling(d, def, flags[0][2] | flags[0][3], flags[1][2], flags[1][3],
 "after IDAT", set_callback);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Parcel::writeByteVector(const std::vector<int8_t>& val) {
 return writeByteVectorInternal(this, val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: print_pixel(png_structp png_ptr, png_infop info_ptr, png_const_bytep row,
   png_uint_32 x)
{
   PNG_CONST unsigned int bit_depth = png_get_bit_depth(png_ptr, info_ptr);

 switch (png_get_color_type(png_ptr, info_ptr))
 {
 case PNG_COLOR_TYPE_GRAY:
         printf("GRAY %u\n", component(row, x, 0, bit_depth, 1));
 return;

 /* The palette case is slightly more difficult - the palette and, if
       * present, the tRNS ('transparency', though the values are really
       * opacity) data must be read to give the full picture:

        */
       case PNG_COLOR_TYPE_PALETTE:
          {
            PNG_CONST unsigned int index = component(row, x, 0, bit_depth, 1);
             png_colorp palette = NULL;
             int num_palette = 0;
 
 if ((png_get_PLTE(png_ptr, info_ptr, &palette, &num_palette) &
               PNG_INFO_PLTE) && num_palette > 0 && palette != NULL)
 {
               png_bytep trans_alpha = NULL;
 int num_trans = 0;
 if ((png_get_tRNS(png_ptr, info_ptr, &trans_alpha, &num_trans,
                  NULL) & PNG_INFO_tRNS) && num_trans > 0 &&
                  trans_alpha != NULL)
                  printf("INDEXED %u = %d %d %d %d\n", index,
                     palette[index].red, palette[index].green,
                     palette[index].blue,
                     index < num_trans ? trans_alpha[index] : 255);

 else /* no transparency */
                  printf("INDEXED %u = %d %d %d\n", index,
                     palette[index].red, palette[index].green,
                     palette[index].blue);
 }

 else
               printf("INDEXED %u = invalid index\n", index);
 }
 return;

 case PNG_COLOR_TYPE_RGB:
         printf("RGB %u %u %u\n", component(row, x, 0, bit_depth, 3),
            component(row, x, 1, bit_depth, 3),
            component(row, x, 2, bit_depth, 3));
 return;

 case PNG_COLOR_TYPE_GRAY_ALPHA:
         printf("GRAY+ALPHA %u %u\n", component(row, x, 0, bit_depth, 2),
            component(row, x, 1, bit_depth, 2));
 return;

 case PNG_COLOR_TYPE_RGB_ALPHA:
         printf("RGBA %u %u %u %u\n", component(row, x, 0, bit_depth, 4),
            component(row, x, 1, bit_depth, 4),
            component(row, x, 2, bit_depth, 4),
            component(row, x, 3, bit_depth, 4));
 return;

 default:
         png_error(png_ptr, "pngpixel: invalid color type");
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: AudioSource::AudioSource(
 audio_source_t inputSource, const String16 &opPackageName,
 uint32_t sampleRate, uint32_t channelCount, uint32_t outSampleRate)

     : mStarted(false),
       mSampleRate(sampleRate),
       mOutSampleRate(outSampleRate > 0 ? outSampleRate : sampleRate),
       mPrevSampleTimeUs(0),
       mFirstSampleTimeUs(-1ll),
       mNumFramesReceived(0),
       mNumClientOwnedBuffers(0) {
     ALOGV("sampleRate: %u, outSampleRate: %u, channelCount: %u",
            sampleRate, outSampleRate, channelCount);
    CHECK(channelCount == 1 || channelCount == 2);
    CHECK(sampleRate > 0);

 size_t minFrameCount;
 status_t status = AudioRecord::getMinFrameCount(&minFrameCount,
                                           sampleRate,
                                           AUDIO_FORMAT_PCM_16_BIT,
                                           audio_channel_in_mask_from_count(channelCount));
 if (status == OK) {
 uint32_t frameCount = kMaxBufferSize / sizeof(int16_t) / channelCount;

 size_t bufCount = 2;
 while ((bufCount * frameCount) < minFrameCount) {
            bufCount++;
 }

        mRecord = new AudioRecord(
                    inputSource, sampleRate, AUDIO_FORMAT_PCM_16_BIT,
                    audio_channel_in_mask_from_count(channelCount),
                    opPackageName,
 (size_t) (bufCount * frameCount),
 AudioRecordCallbackFunction,
 this,
                    frameCount /*notificationFrames*/);
        mInitCheck = mRecord->initCheck();
 if (mInitCheck != OK) {
            mRecord.clear();
 }
 } else {
        mInitCheck = status;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftVorbis(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeDouble(double val)
{
 union {
 double d;
 unsigned long long ll;
 } u;
    u.d = val;
 return writeAligned(u.ll);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t signRSA(Vector<uint8_t> const &sessionId,
 String8 const &algorithm,
 Vector<uint8_t> const &message,
 Vector<uint8_t> const &wrappedKey,
 Vector<uint8_t> &signature) {
 Parcel data, reply;
        data.writeInterfaceToken(IDrm::getInterfaceDescriptor());

        writeVector(data, sessionId);
        data.writeString8(algorithm);
        writeVector(data, message);
        writeVector(data, wrappedKey);

 status_t status = remote()->transact(SIGN_RSA, data, &reply);
 if (status != OK) {
 return status;
 }
        readVector(reply, signature);

 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: freeimage(Image *image)
{
   freebuffer(image);
   png_image_free(&image->image);

 if (image->input_file != NULL)
 {
      fclose(image->input_file);
      image->input_file = NULL;
 }

 if (image->input_memory != NULL)
 {
      free(image->input_memory);
      image->input_memory = NULL;
      image->input_memory_size = 0;
 }

 
    if (image->tmpfile_name[0] != 0 && (image->opts & KEEP_TMPFILES) == 0)
    {
      remove(image->tmpfile_name);
       image->tmpfile_name[0] = 0;
    }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraSource::checkVideoSize(
 const CameraParameters& params,
 int32_t width, int32_t height) {

    ALOGV("checkVideoSize");
 int32_t frameWidthActual = -1;
 int32_t frameHeightActual = -1;
 Vector<Size> sizes;
    params.getSupportedVideoSizes(sizes);
 if (sizes.size() == 0) {
        params.getPreviewSize(&frameWidthActual, &frameHeightActual);
 } else {
        params.getVideoSize(&frameWidthActual, &frameHeightActual);
 }
 if (frameWidthActual < 0 || frameHeightActual < 0) {
        ALOGE("Failed to retrieve video frame size (%dx%d)",
                frameWidthActual, frameHeightActual);
 return UNKNOWN_ERROR;
 }

 if (width != -1 && height != -1) {
 if (frameWidthActual != width || frameHeightActual != height) {
            ALOGE("Failed to set video frame size to %dx%d. "
 "The actual video size is %dx%d ", width, height,
                    frameWidthActual, frameHeightActual);
 return UNKNOWN_ERROR;
 }
 }

    mVideoSize.width = frameWidthActual;
    mVideoSize.height = frameHeightActual;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: unsigned long ContentEncoding::GetEncryptionCount() const {
 const ptrdiff_t count = encryption_entries_end_ - encryption_entries_;
  assert(count >= 0);

 return static_cast<unsigned long>(count);

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Chapters::Atom::GetStartTime(const Chapters* pChapters) const {
 return GetTime(pChapters, m_start_timecode);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void ProcessExifDir(unsigned char * DirStart, unsigned char * OffsetBase,
 unsigned ExifLength, int NestingLevel)
{
 int de;
 int a;
 int NumDirEntries;
 unsigned ThumbnailOffset = 0;
 unsigned ThumbnailSize = 0;
 char IndentString[25];

    printf("ProcessExifDir");
 if (NestingLevel > 4){
 ErrNonfatal("Maximum directory nesting exceeded (corrupt exif header)", 0,0);
 return;
 }

    memset(IndentString, ' ', 25);
 IndentString[NestingLevel * 4] = '\0';


 NumDirEntries = Get16u(DirStart);
 #define DIR_ENTRY_ADDR(Start, Entry) (Start+2+12*(Entry))

 {
 unsigned char * DirEnd;
 DirEnd = DIR_ENTRY_ADDR(DirStart, NumDirEntries);
 if (DirEnd+4 > (OffsetBase+ExifLength)){
 if (DirEnd+2 == OffsetBase+ExifLength || DirEnd == OffsetBase+ExifLength){
 }else{
 ErrNonfatal("Illegally sized exif subdirectory (%d entries)",NumDirEntries,0);
 return;
 }
 }
 if (DumpExifMap){
            printf("Map: %05d-%05d: Directory\n",(int)(DirStart-OffsetBase), (int)(DirEnd+4-OffsetBase));
 }


 }

 if (ShowTags){
        printf("(dir has %d entries)\n",NumDirEntries);
 }

 for (de=0;de<NumDirEntries;de++){
 int Tag, Format, Components;
 unsigned char * ValuePtr;
 int ByteCount;
 unsigned char * DirEntry;
 DirEntry = DIR_ENTRY_ADDR(DirStart, de);

 Tag = Get16u(DirEntry);
 Format = Get16u(DirEntry+2);
 Components = Get32u(DirEntry+4);

 if ((Format-1) >= NUM_FORMATS) {
 ErrNonfatal("Illegal number format %d for tag %04x", Format, Tag);
 continue;
 }

 if ((unsigned)Components > 0x10000){
 ErrNonfatal("Illegal number of components %d for tag %04x", Components, Tag);
 continue;
 }

 ByteCount = Components * BytesPerFormat[Format];

 if (ByteCount > 4){

             unsigned OffsetVal;
             OffsetVal = Get32u(DirEntry+8);
            if (OffsetVal+ByteCount > ExifLength){
                 ErrNonfatal("Illegal value pointer for tag %04x", Tag,0);
                 continue;
 }
 ValuePtr = OffsetBase+OffsetVal;

 if (OffsetVal > ImageInfo.LargestExifOffset){
 ImageInfo.LargestExifOffset = OffsetVal;
 }

 if (DumpExifMap){
                printf("Map: %05d-%05d:   Data for tag %04x\n",OffsetVal, OffsetVal+ByteCount, Tag);
 }
 }else{
 ValuePtr = DirEntry+8;
 }

 if (Tag == TAG_MAKER_NOTE){
 if (ShowTags){
                printf("%s    Maker note: ",IndentString);
 }
 ProcessMakerNote(ValuePtr, ByteCount, OffsetBase, ExifLength);
 continue;
 }

 if (ShowTags){
 for (a=0;;a++){
 if (a >= (int)TAG_TABLE_SIZE){
                    printf("%s", IndentString);
                    printf("    Unknown Tag %04x Value = ", Tag);
 break;
 }
 if (TagTable[a].Tag == Tag){
                    printf("%s", IndentString);
                    printf("    %s = ",TagTable[a].Desc);
 break;
 }
 }

 switch(Format){
 case FMT_BYTE:
 if(ByteCount>1){
                        printf("%.*ls\n", ByteCount/2, (wchar_t *)ValuePtr);
 }else{
 PrintFormatNumber(ValuePtr, Format, ByteCount);
                        printf("\n");
 }
 break;

 case FMT_UNDEFINED:

 case FMT_STRING:
 {
                          printf("\"%s\"", ValuePtr);
 }
 break;

 default:
 PrintFormatNumber(ValuePtr, Format, ByteCount);
                    printf("\n");
 }
 }

 switch(Tag){

 case TAG_MAKE:
                strncpy(ImageInfo.CameraMake, (char *)ValuePtr, ByteCount < 31 ? ByteCount : 31);
 break;

 case TAG_MODEL:
                strncpy(ImageInfo.CameraModel, (char *)ValuePtr, ByteCount < 39 ? ByteCount : 39);
 break;

 case TAG_SUBSEC_TIME:
                strlcpy(ImageInfo.SubSecTime, (char *)ValuePtr, sizeof(ImageInfo.SubSecTime));
 break;

 case TAG_SUBSEC_TIME_ORIG:
                strlcpy(ImageInfo.SubSecTimeOrig, (char *)ValuePtr,
 sizeof(ImageInfo.SubSecTimeOrig));
 break;

 case TAG_SUBSEC_TIME_DIG:
                strlcpy(ImageInfo.SubSecTimeDig, (char *)ValuePtr,
 sizeof(ImageInfo.SubSecTimeDig));
 break;

 case TAG_DATETIME_DIGITIZED:
                strlcpy(ImageInfo.DigitizedTime, (char *)ValuePtr,
 sizeof(ImageInfo.DigitizedTime));

 if (ImageInfo.numDateTimeTags >= MAX_DATE_COPIES){
 ErrNonfatal("More than %d date fields!  This is nuts", MAX_DATE_COPIES, 0);
 break;
 }
 ImageInfo.DateTimeOffsets[ImageInfo.numDateTimeTags++] =
 (char *)ValuePtr - (char *)OffsetBase;
 break;

 case TAG_DATETIME_ORIGINAL:
                strncpy(ImageInfo.DateTime, (char *)ValuePtr, 19);

 case TAG_DATETIME:
 if (!isdigit(ImageInfo.DateTime[0])){
                    strncpy(ImageInfo.DateTime, (char *)ValuePtr, 19);
 }

 if (ImageInfo.numDateTimeTags >= MAX_DATE_COPIES){
 ErrNonfatal("More than %d date fields!  This is nuts", MAX_DATE_COPIES, 0);
 break;
 }
 ImageInfo.DateTimeOffsets[ImageInfo.numDateTimeTags++] =
 (char *)ValuePtr - (char *)OffsetBase;
 break;

 case TAG_WINXP_COMMENT:
 if (ImageInfo.Comments[0]){ // We already have a jpeg comment.
 if (ShowTags) printf("Windows XP commend and other comment in header\n");
 break; // Already have a windows comment, skip this one.
 }

 if (ByteCount > 1){
 if (ByteCount > MAX_COMMENT_SIZE) ByteCount = MAX_COMMENT_SIZE;
                    memcpy(ImageInfo.Comments, ValuePtr, ByteCount);
 ImageInfo.CommentWidchars = ByteCount/2;
 }
 break;

 case TAG_USERCOMMENT:
 if (ImageInfo.Comments[0]){ // We already have a jpeg comment.
 if (ShowTags) printf("Multiple comments in exif header\n");
 break; // Already have a windows comment, skip this one.
 }

 for (a=ByteCount;;){
                    a--;
 if ((ValuePtr)[a] == ' '){
 (ValuePtr)[a] = '\0';
 }else{
 break;
 }
 if (a == 0) break;
 }

 {
 int msiz = ExifLength - (ValuePtr-OffsetBase);
 if (msiz > ByteCount) msiz = ByteCount;
 if (msiz > MAX_COMMENT_SIZE - 1) msiz = MAX_COMMENT_SIZE - 1;
 if (msiz > 5 && memcmp(ValuePtr, "ASCII", 5) == 0) {
 for (a = 5; a < 10 && a < msiz; a++) {
 int c = (ValuePtr)[a];
 if (c != '\0' && c != ' ') {
                                strncpy(ImageInfo.Comments,
 (char *)ValuePtr + a, msiz - a);
 break;
 }
 }
 } else {
                        strncpy(ImageInfo.Comments, (char *)ValuePtr, msiz);
 }
 }
 break;

 case TAG_FNUMBER:
 ImageInfo.ApertureFNumber = (float)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_APERTURE:
 case TAG_MAXAPERTURE:
 if (ImageInfo.ApertureFNumber == 0){
 ImageInfo.ApertureFNumber
 = (float)exp(ConvertAnyFormat(ValuePtr, Format)*log(2)*0.5);
 }
 break;

 case TAG_FOCALLENGTH:
 ImageInfo.FocalLength.num = Get32u(ValuePtr);
 ImageInfo.FocalLength.denom = Get32u(4+(char *)ValuePtr);
 break;

 case TAG_SUBJECT_DISTANCE:
 ImageInfo.Distance = (float)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_EXPOSURETIME:
 ImageInfo.ExposureTime = (float)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_SHUTTERSPEED:
 if (ImageInfo.ExposureTime == 0){
 ImageInfo.ExposureTime
 = (float)(1/exp(ConvertAnyFormat(ValuePtr, Format)*log(2)));
 }
 break;


 case TAG_FLASH:
 ImageInfo.FlashUsed=(int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_ORIENTATION:
 if (NumOrientations >= 2){
 ErrNonfatal("More than two orientation tags!",0,0);
 break;
 }
 OrientationPtr[NumOrientations] = ValuePtr;
 OrientationNumFormat[NumOrientations] = Format;
 if (NumOrientations == 0){
 ImageInfo.Orientation = (int)ConvertAnyFormat(ValuePtr, Format);
 }
 if (ImageInfo.Orientation < 0 || ImageInfo.Orientation > 8){
 ErrNonfatal("Undefined rotation value %d", ImageInfo.Orientation, 0);
 ImageInfo.Orientation = 0;
 }
 NumOrientations += 1;
 break;

 case TAG_EXIF_IMAGELENGTH:
 case TAG_EXIF_IMAGEWIDTH:
                a = (int)ConvertAnyFormat(ValuePtr, Format);
 if (ExifImageWidth < a) ExifImageWidth = a;
 break;

 case TAG_FOCAL_PLANE_XRES:
 FocalplaneXRes = ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_FOCAL_PLANE_UNITS:
 switch((int)ConvertAnyFormat(ValuePtr, Format)){
 case 1: FocalplaneUnits = 25.4; break; // inch
 case 2:
 FocalplaneUnits = 25.4;
 break;

 case 3: FocalplaneUnits = 10; break; // centimeter
 case 4: FocalplaneUnits = 1; break; // millimeter
 case 5: FocalplaneUnits = .001; break; // micrometer
 }
 break;

 case TAG_EXPOSURE_BIAS:
 ImageInfo.ExposureBias = (float)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_WHITEBALANCE:
 ImageInfo.Whitebalance = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_LIGHT_SOURCE:
 ImageInfo.LightSource = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_METERING_MODE:
 ImageInfo.MeteringMode = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_EXPOSURE_PROGRAM:
 ImageInfo.ExposureProgram = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_EXPOSURE_INDEX:
 if (ImageInfo.ISOequivalent == 0){
 ImageInfo.ISOequivalent = (int)ConvertAnyFormat(ValuePtr, Format);
 }
 break;

 case TAG_EXPOSURE_MODE:
 ImageInfo.ExposureMode = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_ISO_EQUIVALENT:
 ImageInfo.ISOequivalent = (int)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_DIGITALZOOMRATIO:
 ImageInfo.DigitalZoomRatio = (float)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_THUMBNAIL_OFFSET:
 ThumbnailOffset = (unsigned)ConvertAnyFormat(ValuePtr, Format);
 DirWithThumbnailPtrs = DirStart;
 break;

 case TAG_THUMBNAIL_LENGTH:
 ThumbnailSize = (unsigned)ConvertAnyFormat(ValuePtr, Format);
 ImageInfo.ThumbnailSizeOffset = ValuePtr-OffsetBase;
 break;

 case TAG_EXIF_OFFSET:
 if (ShowTags) printf("%s    Exif Dir:",IndentString);

 case TAG_INTEROP_OFFSET:
 if (Tag == TAG_INTEROP_OFFSET && ShowTags) printf("%s    Interop Dir:",IndentString);
 {
 unsigned char * SubdirStart;
 SubdirStart = OffsetBase + Get32u(ValuePtr);
 if (SubdirStart < OffsetBase || SubdirStart > OffsetBase+ExifLength){
 ErrNonfatal("Illegal exif or interop ofset directory link",0,0);
 }else{
 ProcessExifDir(SubdirStart, OffsetBase, ExifLength, NestingLevel+1);
 }
 continue;
 }
 break;

 case TAG_GPSINFO:
 if (ShowTags) printf("%s    GPS info dir:",IndentString);
 {
 unsigned char * SubdirStart;
 SubdirStart = OffsetBase + Get32u(ValuePtr);
 if (SubdirStart < OffsetBase || SubdirStart > OffsetBase+ExifLength){
 ErrNonfatal("Illegal GPS directory link",0,0);
 }else{
 ProcessGpsInfo(SubdirStart, ByteCount, OffsetBase, ExifLength);
 }
 continue;
 }
 break;

 case TAG_FOCALLENGTH_35MM:
 ImageInfo.FocalLength35mmEquiv = (unsigned)ConvertAnyFormat(ValuePtr, Format);
 break;

 case TAG_DISTANCE_RANGE:
 ImageInfo.DistanceRange = (int)ConvertAnyFormat(ValuePtr, Format);
 break;
 }
 }


 {
 unsigned char * SubdirStart;
 unsigned Offset;

 if (DIR_ENTRY_ADDR(DirStart, NumDirEntries) + 4 <= OffsetBase+ExifLength){
            printf("DirStart %p offset from dirstart %d", DirStart, 2+12*NumDirEntries);
 Offset = Get32u(DirStart+2+12*NumDirEntries);
 if (Offset){
 SubdirStart = OffsetBase + Offset;
 if (SubdirStart > OffsetBase+ExifLength || SubdirStart < OffsetBase){
                    printf("SubdirStart %p OffsetBase %p ExifLength %d Offset %d",
 SubdirStart, OffsetBase, ExifLength, Offset);
 if (SubdirStart > OffsetBase && SubdirStart < OffsetBase+ExifLength+20){
 if (ShowTags) printf("Thumbnail removed with Jhead 1.3 or earlier\n");
 }else{
 ErrNonfatal("Illegal subdirectory link",0,0);
 }
 }else{
 if (SubdirStart <= OffsetBase+ExifLength){
 if (ShowTags) printf("%s    Continued directory ",IndentString);
 ProcessExifDir(SubdirStart, OffsetBase, ExifLength, NestingLevel+1);
 }
 }
 if (Offset > ImageInfo.LargestExifOffset){
 ImageInfo.LargestExifOffset = Offset;
 }
 }
 }else{
 }
 }

 if (ThumbnailOffset){
 ImageInfo.ThumbnailAtEnd = FALSE;

 if (DumpExifMap){
            printf("Map: %05d-%05d: Thumbnail\n",ThumbnailOffset, ThumbnailOffset+ThumbnailSize);
 }

 if (ThumbnailOffset <= ExifLength){
 if (ThumbnailSize > ExifLength-ThumbnailOffset){
 ThumbnailSize = ExifLength-ThumbnailOffset;
 if (ShowTags) printf("Thumbnail incorrectly placed in header\n");

 }
 ImageInfo.ThumbnailOffset = ThumbnailOffset;
 ImageInfo.ThumbnailSize = ThumbnailSize;

 if (ShowTags){
                printf("Thumbnail size: %d bytes\n",ThumbnailSize);
 }
 }
 }
    printf("returning from ProcessExifDir");
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 ih264d_parse_recovery_point(dec_bit_stream_t *ps_bitstrm,
 dec_struct_t *ps_dec,
                                   UWORD32 ui4_payload_size)
{
    sei *ps_sei = ps_dec->ps_sei;
 dec_err_status_t *ps_err = ps_dec->ps_dec_err_status;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UNUSED(ui4_payload_size);
    ps_sei->u2_recovery_frame_cnt = ih264d_uev(pu4_bitstrm_ofst,
                                               pu4_bitstrm_buf);
    ps_err->u4_frm_sei_sync = ps_err->u4_cur_frm
 + ps_sei->u2_recovery_frame_cnt;
    ps_sei->u1_exact_match_flag = ih264d_get_bit_h264(ps_bitstrm);
    ps_sei->u1_broken_link_flag = ih264d_get_bit_h264(ps_bitstrm);
    ps_sei->u1_changing_slice_grp_idc = ih264d_get_bits_h264(ps_bitstrm, 2);

 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t MediaPlayerService::AudioOutput::frameCount() const
{
 Mutex::Autolock lock(mLock);
 if (mTrack == 0) return NO_INIT;
 return mTrack->frameCount();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t GraphicBuffer::lockYCbCr(uint32_t usage, const Rect& rect,
        android_ycbcr *ycbcr)
{
 if (rect.left < 0 || rect.right  > this->width ||
        rect.top  < 0 || rect.bottom > this->height) {
        ALOGE("locking pixels (%d,%d,%d,%d) outside of buffer (w=%d, h=%d)",
                rect.left, rect.top, rect.right, rect.bottom,
 this->width, this->height);
 return BAD_VALUE;
 }
 status_t res = getBufferMapper().lockYCbCr(handle, usage, rect, ycbcr);
 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static ToColorProc ChooseToColorProc(const SkBitmap& src) {
 switch (src.colorType()) {
 case kN32_SkColorType:
 switch (src.alphaType()) {
 case kOpaque_SkAlphaType:
 return ToColor_S32_Opaque;
 case kPremul_SkAlphaType:
 return ToColor_S32_Alpha;
 case kUnpremul_SkAlphaType:
 return ToColor_S32_Raw;
 default:
 return NULL;
 }
 case kARGB_4444_SkColorType:
 switch (src.alphaType()) {
 case kOpaque_SkAlphaType:
 return ToColor_S4444_Opaque;
 case kPremul_SkAlphaType:
 return ToColor_S4444_Alpha;
 case kUnpremul_SkAlphaType:
 return ToColor_S4444_Raw;
 default:
 return NULL;
 }
 case kRGB_565_SkColorType:
 return ToColor_S565;
 case kIndex_8_SkColorType:
 if (src.getColorTable() == NULL) {
 return NULL;
 }
 switch (src.alphaType()) {
 case kOpaque_SkAlphaType:
 return ToColor_SI8_Opaque;
 case kPremul_SkAlphaType:
 return ToColor_SI8_Alpha;
 case kUnpremul_SkAlphaType:
 return ToColor_SI8_Raw;
 default:
 return NULL;
 }
 default:
 break;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int main(void)
{
   fprintf(stderr, "pngstest: no read support in libpng, test skipped\n");
 /* So the test is skipped: */
 return 77;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Chapters::Atom::Parse(
    IMkvReader* pReader,
    long long pos,
    long long size)
{
    const long long stop = pos + size;
    while (pos < stop)
    {
        long long id, size;
        long status = ParseElementHeader(
                        pReader,
                        pos,
                        stop,
                        id,
                        size);
        if (status < 0)  // error
            return status;
        if (size == 0)  // weird
            continue;
        if (id == 0x00)  // Display ID
        {
            status = ParseDisplay(pReader, pos, size);
            if (status < 0)  // error
                return status;
        }
        else if (id == 0x1654)  // StringUID ID
        {
            status = UnserializeString(pReader, pos, size, m_string_uid);
            if (status < 0)  // error
                return status;
        }
        else if (id == 0x33C4)  // UID ID
        {
            long long val;
            status = UnserializeInt(pReader, pos, size, val);
            if (status < 0)  // error
                return status;
            m_uid = val;
        }
        else if (id == 0x11)  // TimeStart ID
        {
            const long long val = UnserializeUInt(pReader, pos, size);
            if (val < 0)  // error
                return static_cast<long>(val);
            m_start_timecode = val;
        }
        else if (id == 0x12)  // TimeEnd ID
        {
            const long long val = UnserializeUInt(pReader, pos, size);
            if (val < 0)  // error
                return static_cast<long>(val);
            m_stop_timecode = val;
        }
        pos += size;
        assert(pos <= stop);
    }
    assert(pos == stop);
    return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void vp8mt_alloc_temp_buffers(VP8D_COMP *pbi, int width, int prev_mb_rows)
{
    VP8_COMMON *const pc = & pbi->common;
 int i;
 int uv_width;

 if (pbi->b_multithreaded_rd)
 {
        vp8mt_de_alloc_temp_buffers(pbi, prev_mb_rows);

 /* our internal buffers are always multiples of 16 */
 if ((width & 0xf) != 0)
            width += 16 - (width & 0xf);

 if (width < 640) pbi->sync_range = 1;
 else if (width <= 1280) pbi->sync_range = 8;
 else if (width <= 2560) pbi->sync_range =16;
 else pbi->sync_range = 32;

        uv_width = width >>1;

 /* Allocate an int for each mb row. */
        CALLOC_ARRAY(pbi->mt_current_mb_col, pc->mb_rows);

 /* Allocate memory for above_row buffers. */
        CALLOC_ARRAY(pbi->mt_yabove_row, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_yabove_row[i], vpx_memalign(16,sizeof(unsigned char) * (width + (VP8BORDERINPIXELS<<1))));

        CALLOC_ARRAY(pbi->mt_uabove_row, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_uabove_row[i], vpx_memalign(16,sizeof(unsigned char) * (uv_width + VP8BORDERINPIXELS)));

        CALLOC_ARRAY(pbi->mt_vabove_row, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_vabove_row[i], vpx_memalign(16,sizeof(unsigned char) * (uv_width + VP8BORDERINPIXELS)));

 /* Allocate memory for left_col buffers. */
        CALLOC_ARRAY(pbi->mt_yleft_col, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_yleft_col[i], vpx_calloc(sizeof(unsigned char) * 16, 1));

        CALLOC_ARRAY(pbi->mt_uleft_col, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_uleft_col[i], vpx_calloc(sizeof(unsigned char) * 8, 1));

        CALLOC_ARRAY(pbi->mt_vleft_col, pc->mb_rows);
 for (i = 0; i < pc->mb_rows; i++)
            CHECK_MEM_ERROR(pbi->mt_vleft_col[i], vpx_calloc(sizeof(unsigned char) * 8, 1));
 }

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMP3::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {
            OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex > 1) {
 return OMX_ErrorUndefined;
 }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioMp3:
 {
            OMX_AUDIO_PARAM_MP3TYPE *mp3Params =
 (OMX_AUDIO_PARAM_MP3TYPE *)params;

 if (!isValidOMXParam(mp3Params)) {
 return OMX_ErrorBadParameter;
 }

 if (mp3Params->nPortIndex > 1) {
 return OMX_ErrorUndefined;
 }

            mp3Params->nChannels = mNumChannels;
            mp3Params->nBitRate = 0 /* unknown */;
            mp3Params->nSampleRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::dumpBuffers(OMX_U32 portIndex) {
    CHECK(portIndex == kPortIndexInput || portIndex == kPortIndexOutput);
    ALOGI("[%s] %s port has %zu buffers:", mComponentName.c_str(),
            portIndex == kPortIndexInput ? "input" : "output", mBuffers[portIndex].size());
 for (size_t i = 0; i < mBuffers[portIndex].size(); ++i) {
 const BufferInfo &info = mBuffers[portIndex][i];
        ALOGI("  slot %2zu: #%8u %p/%p %s(%d) dequeued:%u",
                i, info.mBufferID, info.mGraphicBuffer.get(),
                info.mGraphicBuffer == NULL ? NULL : info.mGraphicBuffer->getNativeBuffer(),
                _asString(info.mStatus), info.mStatus, info.mDequeuedAt);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t BpMemoryHeap::getFlags() const {
    assertMapped();
 return mFlags;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void String8::clear() {
 SharedBuffer::bufferFromData(mString)->release();
    mString = getEmptyString();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BOOLEAN btif_hl_proc_pending_op(UINT8 app_idx, UINT8 mcl_idx)

{

 btif_hl_app_cb_t *p_acb = BTIF_HL_GET_APP_CB_PTR(app_idx);
 btif_hl_mcl_cb_t *p_mcb = BTIF_HL_GET_MCL_CB_PTR(app_idx, mcl_idx);
 btif_hl_pending_chan_cb_t *p_pcb;
    BOOLEAN                     status = FALSE;
    tBTA_HL_DCH_OPEN_PARAM      dch_open;
    tBTA_HL_MDL_ID              mdl_id;
    tBTA_HL_DCH_RECONNECT_PARAM reconnect_param;

    p_pcb = BTIF_HL_GET_PCB_PTR(app_idx, mcl_idx);
 if (p_pcb->in_use)
 {
 switch (p_pcb->op)
 {
 case BTIF_HL_PEND_DCH_OP_OPEN:
 if (!p_pcb->abort_pending)
 {
                    BTIF_TRACE_DEBUG("op BTIF_HL_PEND_DCH_OP_OPEN");
                    dch_open.ctrl_psm = p_mcb->ctrl_psm;
                    dch_open.local_mdep_id = p_acb->sup_feature.mdep[p_pcb->mdep_cfg_idx].mdep_id;
 if (btif_hl_find_peer_mdep_id(p_acb->app_id, p_mcb->bd_addr,
                                                  p_acb->sup_feature.mdep[p_pcb->mdep_cfg_idx].mdep_cfg.mdep_role,
                                                  p_acb->sup_feature.mdep[p_pcb->mdep_cfg_idx].mdep_cfg.data_cfg[0].data_type, &dch_open.peer_mdep_id ))
 {
                        dch_open.local_cfg = p_acb->channel_type[p_pcb->mdep_cfg_idx];
 if ((p_acb->sup_feature.mdep[p_pcb->mdep_cfg_idx].mdep_cfg.mdep_role == BTA_HL_MDEP_ROLE_SOURCE)
 && !btif_hl_is_the_first_reliable_existed(app_idx, mcl_idx))
 {
                            dch_open.local_cfg = BTA_HL_DCH_CFG_RELIABLE;
 }
                        dch_open.sec_mask = (BTA_SEC_AUTHENTICATE | BTA_SEC_ENCRYPT);
                        BTIF_TRACE_DEBUG("dch_open.local_cfg=%d  ", dch_open.local_cfg);
                        btif_hl_send_setup_connecting_cb(app_idx,mcl_idx);

 if (!btif_hl_is_reconnect_possible(app_idx, mcl_idx, p_pcb->mdep_cfg_idx, &dch_open, &mdl_id ))
 {
                            BTIF_TRACE_DEBUG("Issue DCH open, mcl_handle=%d",p_mcb->mcl_handle);
                            BTA_HlDchOpen(p_mcb->mcl_handle, &dch_open);
 }
 else
 {
                            reconnect_param.ctrl_psm = p_mcb->ctrl_psm;
                            reconnect_param.mdl_id = mdl_id;;
                            BTIF_TRACE_DEBUG("Issue Reconnect ctrl_psm=0x%x mdl_id=0x%x",reconnect_param.ctrl_psm, reconnect_param.mdl_id);
                            BTA_HlDchReconnect(p_mcb->mcl_handle, &reconnect_param);
 }
                        status = TRUE;
 }
 }
 else
 {
                    btif_hl_send_setup_disconnected_cb(app_idx, mcl_idx);
                    status = TRUE;
 }
 break;
 case BTIF_HL_PEND_DCH_OP_DELETE_MDL:
                BTA_HlDeleteMdl(p_mcb->mcl_handle, p_acb->delete_mdl.mdl_id);
                status = TRUE;
 break;

 default:
 break;
 }
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool set_one_prio_perm(struct task_struct *p)
{
 const struct cred *cred = current_cred(), *pcred = __task_cred(p);

 if (pcred->user->user_ns == cred->user->user_ns &&
 (pcred->uid  == cred->euid ||
	     pcred->euid == cred->euid))
 return true;
 if (ns_capable(pcred->user->user_ns, CAP_SYS_NICE))
 return true;
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_get_remote_service_record(bt_bdaddr_t *remote_addr,
 bt_uuid_t *uuid)
{
 if (!btif_is_enabled())
 return BT_STATUS_NOT_READY;

 return btif_dm_get_remote_service_record(remote_addr, uuid);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void event_postload(UNUSED_ATTR void *context) {
  LOG_INFO("%s", __func__);
 if(vendor->send_async_command(VENDOR_CONFIGURE_SCO, NULL) == -1) {
    sco_config_callback(false);

 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleTable::setCompositionTimeToSampleParams(
 off64_t data_offset, size_t data_size) {
    ALOGI("There are reordered frames present.");

 if (mCompositionTimeDeltaEntries != NULL || data_size < 8) {
 return ERROR_MALFORMED;
 }

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header))
 < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;
 }

 size_t numEntries = U32_AT(&header[4]);

 if (data_size != (numEntries + 1) * 8) {
 return ERROR_MALFORMED;
 }

    mNumCompositionTimeDeltaEntries = numEntries;
 uint64_t allocSize = numEntries * 2 * (uint64_t)sizeof(uint32_t);
 if (allocSize > SIZE_MAX) {
 return ERROR_OUT_OF_RANGE;
 }

    mCompositionTimeDeltaEntries = new uint32_t[2 * numEntries];

 if (mDataSource->readAt(
                data_offset + 8, mCompositionTimeDeltaEntries, numEntries * 8)
 < (ssize_t)numEntries * 8) {
 delete[] mCompositionTimeDeltaEntries;
        mCompositionTimeDeltaEntries = NULL;

 return ERROR_IO;
 }

 for (size_t i = 0; i < 2 * numEntries; ++i) {
        mCompositionTimeDeltaEntries[i] = ntohl(mCompositionTimeDeltaEntries[i]);
 }

    mCompositionDeltaLookup->setEntries(
            mCompositionTimeDeltaEntries, mNumCompositionTimeDeltaEntries);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t decoder_get_si(vpx_codec_alg_priv_t *ctx,
 vpx_codec_stream_info_t *si) {
 const size_t sz = (si->sz >= sizeof(vp9_stream_info_t))
 ? sizeof(vp9_stream_info_t)
 : sizeof(vpx_codec_stream_info_t);
  memcpy(si, &ctx->si, sz);
  si->sz = (unsigned int)sz;

 return VPX_CODEC_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  const Block* BlockGroup::GetBlock() const { return &m_block; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t signalEndOfInputStream(node_id node) {
 Parcel data, reply;
 status_t err;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        err = remote()->transact(SIGNAL_END_OF_INPUT_STREAM, data, &reply);
 if (err != OK) {
            ALOGW("binder transaction failed: %d", err);
 return err;
 }

 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void omx_video::omx_release_meta_buffer(OMX_BUFFERHEADERTYPE *buffer)
{
 if (buffer && meta_mode_enable) {
        encoder_media_buffer_type *media_ptr;
 struct pmem Input_pmem;
 unsigned int index_pmem = 0;
 bool meta_error = false;

        index_pmem = (buffer - m_inp_mem_ptr);
 if (mUsesColorConversion &&
 (index_pmem < m_sInPortDef.nBufferCountActual)) {
 if (!dev_free_buf((&m_pInput_pmem[index_pmem]),PORT_INDEX_IN)) {
                DEBUG_PRINT_ERROR("omx_release_meta_buffer dev free failed");
 }
 } else {
            media_ptr = (encoder_media_buffer_type *) buffer->pBuffer;
 if (media_ptr && media_ptr->meta_handle) {
 if (media_ptr->buffer_type == kMetadataBufferTypeCameraSource &&
                        media_ptr->meta_handle->numFds == 1 &&
                        media_ptr->meta_handle->numInts >= 2) {
 Input_pmem.fd = media_ptr->meta_handle->data[0];
 Input_pmem.buffer = media_ptr;
 Input_pmem.size = media_ptr->meta_handle->data[2];
 Input_pmem.offset = media_ptr->meta_handle->data[1];
                    DEBUG_PRINT_LOW("EBD fd = %d, offset = %d, size = %d",Input_pmem.fd,
 Input_pmem.offset,
 Input_pmem.size);
 } else if (media_ptr->buffer_type == kMetadataBufferTypeGrallocSource) {
 private_handle_t *handle = (private_handle_t *)media_ptr->meta_handle;
 Input_pmem.buffer = media_ptr;
 Input_pmem.fd = handle->fd;
 Input_pmem.offset = 0;
 Input_pmem.size = handle->size;
 } else {
                    meta_error = true;
                    DEBUG_PRINT_ERROR(" Meta Error set in EBD");
 }
 if (!meta_error)
                    meta_error = !dev_free_buf(&Input_pmem,PORT_INDEX_IN);
 if (meta_error) {
                    DEBUG_PRINT_ERROR(" Warning dev_free_buf failed flush value is %d",
                            input_flush_progress);
 }
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftMP3::initDecoder() {
    mConfig->equalizerType = flat;
    mConfig->crcEnabled = false;

 uint32_t memRequirements = pvmp3_decoderMemRequirements();
    mDecoderBuf = malloc(memRequirements);

    pvmp3_InitDecoder(mConfig, mDecoderBuf);
    mIsFirst = true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_ctl(iv_obj_t *ps_codec_obj, void *pv_api_ip, void *pv_api_op)
{
 ivd_ctl_set_config_ip_t *ps_ctl_ip;
 ivd_ctl_set_config_op_t *ps_ctl_op;
    WORD32 ret = 0;
    WORD32 subcommand;
 codec_t *ps_codec = (codec_t *)ps_codec_obj->pv_codec_handle;

    ps_ctl_ip = (ivd_ctl_set_config_ip_t *)pv_api_ip;
    ps_ctl_op = (ivd_ctl_set_config_op_t *)pv_api_op;

 if(ps_codec->i4_init_done != 1)
 {
        ps_ctl_op->u4_error_code |= 1 << IVD_FATALERROR;
        ps_ctl_op->u4_error_code |= IHEVCD_INIT_NOT_DONE;
 return IV_FAIL;
 }
    subcommand = ps_ctl_ip->e_sub_cmd;

 switch(subcommand)
 {
 case IVD_CMD_CTL_GETPARAMS:
            ret = ihevcd_get_status(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_SETPARAMS:
            ret = ihevcd_set_params(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_RESET:
            ret = ihevcd_reset(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_SETDEFAULT:
 {
 ivd_ctl_set_config_op_t *s_ctl_dynparams_op =
 (ivd_ctl_set_config_op_t *)pv_api_op;

            ret = ihevcd_set_default_params(ps_codec);
 if(IV_SUCCESS == ret)
                s_ctl_dynparams_op->u4_error_code = 0;
 break;
 }
 case IVD_CMD_CTL_FLUSH:
            ret = ihevcd_set_flush_mode(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_GETBUFINFO:
            ret = ihevcd_get_buf_info(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_GETVERSION:
 {
 ivd_ctl_getversioninfo_ip_t *ps_ip;
 ivd_ctl_getversioninfo_op_t *ps_op;
            IV_API_CALL_STATUS_T ret;
            ps_ip = (ivd_ctl_getversioninfo_ip_t *)pv_api_ip;
            ps_op = (ivd_ctl_getversioninfo_op_t *)pv_api_op;

            ps_op->u4_error_code = IV_SUCCESS;

 if((WORD32)ps_ip->u4_version_buffer_size <= 0)
 {
                ps_op->u4_error_code = IHEVCD_CXA_VERS_BUF_INSUFFICIENT;
                ret = IV_FAIL;
 }
 else
 {
                ret = ihevcd_get_version((CHAR *)ps_ip->pv_version_buffer,
                                         ps_ip->u4_version_buffer_size);
 if(ret != IV_SUCCESS)
 {
                    ps_op->u4_error_code = IHEVCD_CXA_VERS_BUF_INSUFFICIENT;
                    ret = IV_FAIL;
 }
 }
 }
 break;
 case IHEVCD_CXA_CMD_CTL_DEGRADE:
            ret = ihevcd_set_degrade(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IHEVCD_CXA_CMD_CTL_SET_NUM_CORES:
            ret = ihevcd_set_num_cores(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IHEVCD_CXA_CMD_CTL_GET_BUFFER_DIMENSIONS:
            ret = ihevcd_get_frame_dimensions(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IHEVCD_CXA_CMD_CTL_GET_VUI_PARAMS:
            ret = ihevcd_get_vui_params(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IHEVCD_CXA_CMD_CTL_GET_SEI_MASTERING_PARAMS:
            ret = ihevcd_get_sei_mastering_params(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IHEVCD_CXA_CMD_CTL_SET_PROCESSOR:
            ret = ihevcd_set_processor(ps_codec_obj, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 default:
            DEBUG("\nDo nothing\n");
 break;
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void adapter_state_change_callback(bt_state_t status) {
 if (!checkCallbackThread()) {
       ALOGE("Callback: '%s' is not called on the correct thread", __FUNCTION__);
 return;
 }
    ALOGV("%s: Status is: %d", __FUNCTION__, status);

    callbackEnv->CallVoidMethod(sJniCallbacksObj, method_stateChangeCallback, (jint)status);

    checkAndClearExceptionFromCallback(callbackEnv, __FUNCTION__);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t StreamingProcessor::togglePauseStream(bool pause) {
    ATRACE_CALL();
 status_t res;

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

    ALOGV("%s: Camera %d: toggling pause to %d", __FUNCTION__, mId, pause);

 Mutex::Autolock m(mMutex);

 if (mActiveRequest == NONE) {
        ALOGE("%s: Camera %d: Can't toggle pause, streaming was not started",
              __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

 if (mPaused == pause) {
 return OK;
 }

 if (pause) {
        res = device->clearStreamingRequest();
 if (res != OK) {
            ALOGE("%s: Camera %d: Can't clear stream request: %s (%d)",
                    __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 } else {
 CameraMetadata &request =
 (mActiveRequest == PREVIEW) ? mPreviewRequest
 : mRecordingRequest;
        res = device->setStreamingRequest(request);
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to set preview request to resume: "
 "%s (%d)",
                    __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
 }

    mPaused = pause;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: pid_t IPCThreadState::getCallingPid() const
{
 return mCallingPid;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    AqSegmentTest() : EncoderTest(GET_PARAM(0)) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlNsErr(xmlParserCtxtPtr ctxt, xmlParserErrors error,
 const char *msg,
 const xmlChar * info1, const xmlChar * info2,
 const xmlChar * info3)
{
 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 if (ctxt != NULL)
	ctxt->errNo = error;
    __xmlRaiseError(NULL, NULL, NULL, ctxt, NULL, XML_FROM_NAMESPACE, error,
                    XML_ERR_ERROR, NULL, 0, (const char *) info1,
 (const char *) info2, (const char *) info3, 0, 0, msg,
                    info1, info2, info3);
 if (ctxt != NULL)
	ctxt->nsWellFormed = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: double VideoTrack::GetFrameRate() const
{
    return m_rate;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: CameraClient::CameraClient(const sp<CameraService>& cameraService,
 const sp<ICameraClient>& cameraClient,
 const String16& clientPackageName,
 int cameraId, int cameraFacing,
 int clientPid, int clientUid,
 int servicePid):
 Client(cameraService, cameraClient, clientPackageName,
                cameraId, cameraFacing, clientPid, clientUid, servicePid)
{
 int callingPid = getCallingPid();
    LOG1("CameraClient::CameraClient E (pid %d, id %d)", callingPid, cameraId);

    mHardware = NULL;
    mMsgEnabled = 0;
    mSurface = 0;
    mPreviewWindow = 0;
    mDestructionStarted = false;

    mPreviewCallbackFlag = CAMERA_FRAME_CALLBACK_FLAG_NOOP;
    mOrientation = getOrientation(0, mCameraFacing == CAMERA_FACING_FRONT);
    mPlayShutterSound = true;
    LOG1("CameraClient::CameraClient X (pid %d, id %d)", callingPid, cameraId);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void GKI_delay(UINT32 timeout_ms) {
 struct timespec delay;
  delay.tv_sec = timeout_ms / 1000;
  delay.tv_nsec = 1000 * 1000 * (timeout_ms % 1000);

 
   int err;
   do {
    err = nanosleep(&delay, &delay);
   } while (err == -1 && errno == EINTR);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void usage_exit() {
   fprintf(stderr, "Usage: %s <width> <height> <infile> <outfile> <frame>\n",
           exec_name);
   exit(EXIT_FAILURE);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CuePoint::Load(IMkvReader* pReader) {
 
   if (m_timecode >= 0)  // already loaded
    return;
 
   assert(m_track_positions == NULL);
   assert(m_track_positions_count == 0);

 long long pos_ = -m_timecode;
 const long long element_start = pos_;

 long long stop;


   {
     long len;
 
    const long long id = ReadUInt(pReader, pos_, len);
    assert(id == 0x3B);  // CuePoint ID
     if (id != 0x3B)
      return;
 
     pos_ += len;  // consume ID
 
 const long long size = ReadUInt(pReader, pos_, len);
    assert(size >= 0);

    pos_ += len; // consume Size field

    stop = pos_ + size;
 }

 const long long element_size = stop - element_start;

 long long pos = pos_;



   while (pos < stop) {
     long len;
 
    const long long id = ReadUInt(pReader, pos, len);
    assert(id >= 0);  // TODO
    assert((pos + len) <= stop);
 
     pos += len;  // consume ID
 
     const long long size = ReadUInt(pReader, pos, len);
    assert(size >= 0);
    assert((pos + len) <= stop);
 
     pos += len;  // consume Size field
    assert((pos + size) <= stop);
 
     if (id == 0x33)  // CueTime ID
       m_timecode = UnserializeUInt(pReader, pos, size);

 else if (id == 0x37) // CueTrackPosition(s) ID

       ++m_track_positions_count;
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
  assert(m_timecode >= 0);
  assert(m_track_positions_count > 0);
 
 
  m_track_positions = new TrackPosition[m_track_positions_count];
 
 
 TrackPosition* p = m_track_positions;
  pos = pos_;


   while (pos < stop) {
     long len;
 
    const long long id = ReadUInt(pReader, pos, len);
    assert(id >= 0);  // TODO
    assert((pos + len) <= stop);
 
     pos += len;  // consume ID
 
 const long long size = ReadUInt(pReader, pos, len);
    assert(size >= 0);
    assert((pos + len) <= stop);

    pos += len; // consume Size field
    assert((pos + size) <= stop);

 
     if (id == 0x37) {  // CueTrackPosition(s) ID
       TrackPosition& tp = *p++;
      tp.Parse(pReader, pos, size);
     }
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
   assert(size_t(p - m_track_positions) == m_track_positions_count);
 
   m_element_start = element_start;
   m_element_size = element_size;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void Parcel::Blob::init(bool mapped, void* data, size_t size) {
    mMapped = mapped;
    mData = data;
    mSize = size;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sample_scale(double sample_value, unsigned int scale)
{
   sample_value = floor(sample_value * scale + .5);

 /* Return NaN as 0: */
 if (!(sample_value > 0))
      sample_value = 0;
 else if (sample_value > scale)
      sample_value = scale;

 return (unsigned int)sample_value;

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: write_function(png_structp pp, png_bytep data, png_size_t size)
{
   buffer_write(get_dp(pp), get_buffer(pp), data, size);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_sei_message(dec_struct_t *ps_dec,
 dec_bit_stream_t *ps_bitstrm)
{
    UWORD32 ui4_payload_type, ui4_payload_size;
    UWORD32 u4_bits;
    WORD32 i4_status = 0;

 do
 {

         ui4_payload_type = 0;
 
         u4_bits = ih264d_get_bits_h264(ps_bitstrm, 8);
        while(0xff == u4_bits)
         {
             u4_bits = ih264d_get_bits_h264(ps_bitstrm, 8);
             ui4_payload_type += 255;
 }
        ui4_payload_type += u4_bits;

 
         ui4_payload_size = 0;
         u4_bits = ih264d_get_bits_h264(ps_bitstrm, 8);
        while(0xff == u4_bits)
         {
             u4_bits = ih264d_get_bits_h264(ps_bitstrm, 8);
             ui4_payload_size += 255;
 }
        ui4_payload_size += u4_bits;

        i4_status = ih264d_parse_sei_payload(ps_bitstrm, ui4_payload_type,
                                             ui4_payload_size, ps_dec);
 if(i4_status == -1)
 {
            i4_status = 0;
 break;
 }

 if(i4_status != OK)
 return i4_status;

 if(ih264d_check_byte_aligned(ps_bitstrm) == 0)
 {
            u4_bits = ih264d_get_bit_h264(ps_bitstrm);
 if(0 == u4_bits)

             {
                 H264_DEC_DEBUG_PRINT("\nError in parsing SEI message");
             }
            while(0 == ih264d_check_byte_aligned(ps_bitstrm))
             {
                 u4_bits = ih264d_get_bit_h264(ps_bitstrm);
                 if(u4_bits)
 {
                    H264_DEC_DEBUG_PRINT("\nError in parsing SEI message");
 }
 }
 }
 }
 while(ps_bitstrm->u4_ofst < ps_bitstrm->u4_max_ofst);
 return (i4_status);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t OMXNodeInstance::getParameter(
         OMX_INDEXTYPE index, void *params, size_t /* size */) {
     Mutex::Autolock autoLock(mLock);
 
     OMX_ERRORTYPE err = OMX_GetParameter(mHandle, index, params);
     OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
 if (err != OMX_ErrorNoMore) {
        CLOG_IF_ERROR(getParameter, err, "%s(%#x)", asString(extIndex), index);
 }
 return StatusFromOMXError(err);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int btsock_thread_post_cmd(int h, int type, const unsigned char* data, int size, uint32_t user_id)
{
 if(h < 0 || h >= MAX_THREAD)
 {
        APPL_TRACE_ERROR("invalid bt thread handle:%d", h);
 return FALSE;
 }
 if(ts[h].cmd_fdw == -1)
 {
        APPL_TRACE_ERROR("cmd socket is not created. socket thread may not initialized");
 return FALSE;
 }
 sock_cmd_t cmd = {CMD_USER_PRIVATE, 0, type, size, user_id};
    APPL_TRACE_DEBUG("post cmd type:%d, size:%d, h:%d, ", type, size, h);
 sock_cmd_t* cmd_send = &cmd;
 int size_send = sizeof(cmd);
 if(data && size)
 {
        size_send = sizeof(cmd) + size;
        cmd_send = (sock_cmd_t*)alloca(size_send);
 if(cmd_send)
 {
 *cmd_send = cmd;
            memcpy(cmd_send + 1, data, size);
 }
 else
 {
            APPL_TRACE_ERROR("alloca failed at h:%d, cmd type:%d, size:%d", h, type, size_send);

             return FALSE;
         }
     }
    return send(ts[h].cmd_fdw, cmd_send, size_send, 0) == size_send;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: omx_vdec::~omx_vdec()
{
    m_pmem_info = NULL;
 struct v4l2_decoder_cmd dec;
    DEBUG_PRINT_HIGH("In OMX vdec Destructor");
 if (m_pipe_in) close(m_pipe_in);
 if (m_pipe_out) close(m_pipe_out);
    m_pipe_in = -1;
    m_pipe_out = -1;
    DEBUG_PRINT_HIGH("Waiting on OMX Msg Thread exit");
 if (msg_thread_created)
        pthread_join(msg_thread_id,NULL);
    DEBUG_PRINT_HIGH("Waiting on OMX Async Thread exit");
    dec.cmd = V4L2_DEC_CMD_STOP;
 if (drv_ctx.video_driver_fd >=0 ) {
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_DECODER_CMD, &dec))
            DEBUG_PRINT_ERROR("STOP Command failed");
 }
 if (async_thread_created)
        pthread_join(async_thread_id,NULL);
    unsubscribe_to_events(drv_ctx.video_driver_fd);

     close(drv_ctx.video_driver_fd);
     pthread_mutex_destroy(&m_lock);
     pthread_mutex_destroy(&c_lock);
     sem_destroy(&m_cmd_lock);
     if (perf_flag) {
         DEBUG_PRINT_HIGH("--> TOTAL PROCESSING TIME");
        dec_time.end();
 }
    DEBUG_PRINT_INFO("Exit OMX vdec Destructor: fd=%d",drv_ctx.video_driver_fd);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void BTM_SetPairableMode (BOOLEAN allow_pairing, BOOLEAN connect_only_paired)
{
    BTM_TRACE_API ("BTM_SetPairableMode()  allow_pairing: %u   connect_only_paired: %u", allow_pairing, connect_only_paired);

    btm_cb.pairing_disabled    = !allow_pairing;
    btm_cb.connect_only_paired = connect_only_paired;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftAVCEncoder::~SoftAVCEncoder() {
    ALOGV("Destruct SoftAVCEncoder");
    releaseEncoder();
 List<BufferInfo *> &outQueue = getPortQueue(1);
 List<BufferInfo *> &inQueue = getPortQueue(0);
    CHECK(outQueue.empty());
    CHECK(inQueue.empty());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SYSCALL_DEFINE2(setdomainname, char __user *, name, int, len)
{
 int errno;
 char tmp[__NEW_UTS_LEN];

 if (!ns_capable(current->nsproxy->uts_ns->user_ns, CAP_SYS_ADMIN))
 return -EPERM;
 if (len < 0 || len > __NEW_UTS_LEN)
 return -EINVAL;

	down_write(&uts_sem);
	errno = -EFAULT;
 if (!copy_from_user(tmp, name, len)) {
 struct new_utsname *u = utsname();

		memcpy(u->domainname, tmp, len);
		memset(u->domainname + len, 0, sizeof(u->domainname) - len);
		errno = 0;
 }
	uts_proc_notify(UTS_PROC_DOMAINNAME);
	up_write(&uts_sem);
 return errno;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::onEvent(
        OMX_EVENTTYPE event, OMX_U32 arg1, OMX_U32 arg2) {
 const char *arg1String = "??";
 const char *arg2String = "??";
 ADebug::Level level = ADebug::kDebugInternalState;

 switch (event) {
 case OMX_EventCmdComplete:
            arg1String = asString((OMX_COMMANDTYPE)arg1);
 switch (arg1) {
 case OMX_CommandStateSet:
                    arg2String = asString((OMX_STATETYPE)arg2);
                    level = ADebug::kDebugState;
 break;
 case OMX_CommandFlush:
 case OMX_CommandPortEnable:
 {
 Mutex::Autolock _l(mDebugLock);
                    bumpDebugLevel_l(2 /* numInputBuffers */, 2 /* numOutputBuffers */);
 }
 default:
                    arg2String = portString(arg2);
 }
 break;
 case OMX_EventError:
            arg1String = asString((OMX_ERRORTYPE)arg1);
            level = ADebug::kDebugLifeCycle;
 break;
 case OMX_EventPortSettingsChanged:
            arg2String = asString((OMX_INDEXEXTTYPE)arg2);
 default:
            arg1String = portString(arg1);
 }

    CLOGI_(level, onEvent, "%s(%x), %s(%x), %s(%x)",
            asString(event), event, arg1String, arg1, arg2String, arg2);
 const sp<GraphicBufferSource>& bufferSource(getGraphicBufferSource());

 if (bufferSource != NULL
 && event == OMX_EventCmdComplete
 && arg1 == OMX_CommandStateSet
 && arg2 == OMX_StateExecuting) {
        bufferSource->omxExecuting();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void uipc_check_task_flags_locked(void)
{
 int i;

 for (i=0; i<UIPC_CH_NUM; i++)
 {
 if (uipc_main.ch[i].task_evt_flags & UIPC_TASK_FLAG_DISCONNECT_CHAN)
 {
            uipc_main.ch[i].task_evt_flags &= ~UIPC_TASK_FLAG_DISCONNECT_CHAN;
            uipc_close_ch_locked(i);
 }

 /* add here */

 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::overrideResultForPrecaptureCancel(
 CameraMetadata *result, const AeTriggerCancelOverride_t &aeTriggerCancelOverride) {
 if (aeTriggerCancelOverride.applyAeLock) {
        assert(mDeviceVersion <= CAMERA_DEVICE_API_VERSION_3_2);
        result->update(ANDROID_CONTROL_AE_LOCK, &aeTriggerCancelOverride.aeLock, 1);
 }

 if (aeTriggerCancelOverride.applyAePrecaptureTrigger) {
        assert(mDeviceVersion <= CAMERA_DEVICE_API_VERSION_3_2);
        result->update(ANDROID_CONTROL_AE_PRECAPTURE_TRIGGER,
 &aeTriggerCancelOverride.aePrecaptureTrigger, 1);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void AddImpl(Handle<JSObject> object, uint32_t index,
 Handle<Object> value, PropertyAttributes attributes,
 uint32_t new_capacity) {
 Handle<FixedArray> parameter_map(FixedArray::cast(object->elements()));
 Handle<FixedArrayBase> old_elements(
 FixedArrayBase::cast(parameter_map->get(1)));
 Handle<SeededNumberDictionary> dictionary =
        old_elements->IsSeededNumberDictionary()
 ? Handle<SeededNumberDictionary>::cast(old_elements)
 : JSObject::NormalizeElements(object);
 PropertyDetails details(kData, attributes, 0, PropertyCellType::kNoCell);
 Handle<SeededNumberDictionary> new_dictionary =
 SeededNumberDictionary::AddNumberEntry(dictionary, index, value,
                                               details, object);
 if (attributes != NONE) object->RequireSlowElements(*new_dictionary);
 if (*dictionary != *new_dictionary) {
 FixedArray::cast(object->elements())->set(1, *new_dictionary);
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_parse_transform_tree(codec_t *ps_codec,
                                   WORD32 x0, WORD32 y0,
                                   WORD32 cu_x_base, WORD32 cu_y_base,
                                   WORD32 log2_trafo_size,
                                   WORD32 trafo_depth,
                                   WORD32 blk_idx,
                                   WORD32 intra_pred_mode)
{
    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 sps_t *ps_sps;
 pps_t *ps_pps;
    WORD32 value;
    WORD32 x1, y1;
    WORD32 max_trafo_depth;

 bitstrm_t *ps_bitstrm = &ps_codec->s_parse.s_bitstrm;
    WORD32 intra_split_flag;
    WORD32 split_transform_flag;
    WORD32 ctxt_idx;
 cab_ctxt_t *ps_cabac = &ps_codec->s_parse.s_cabac;

    max_trafo_depth = ps_codec->s_parse.s_cu.i4_max_trafo_depth;
    ps_sps = ps_codec->s_parse.ps_sps;
    ps_pps = ps_codec->s_parse.ps_pps;
    intra_split_flag = ps_codec->s_parse.s_cu.i4_intra_split_flag;

 {
        split_transform_flag = 0;
 if((log2_trafo_size <= ps_sps->i1_log2_max_transform_block_size) &&
 (log2_trafo_size > ps_sps->i1_log2_min_transform_block_size) &&
 (trafo_depth < max_trafo_depth) &&
 !(intra_split_flag && (trafo_depth == 0)))
 {
 /* encode the split transform flag, context derived as per Table9-37 */
            ctxt_idx = IHEVC_CAB_SPLIT_TFM + (5 - log2_trafo_size);

            TRACE_CABAC_CTXT("split_transform_flag", ps_cabac->u4_range, ctxt_idx);
            split_transform_flag = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx);
            AEV_TRACE("split_transform_flag", split_transform_flag,
                      ps_cabac->u4_range);

 }
 else
 {
            WORD32 inter_split_flag = 0;

 if((0 == ps_sps->i1_max_transform_hierarchy_depth_inter) &&
 (PRED_MODE_INTER == ps_codec->s_parse.s_cu.i4_pred_mode) &&
 (PART_2Nx2N != ps_codec->s_parse.s_cu.i4_part_mode) &&
 (0 == trafo_depth))
 {
                inter_split_flag = 1;
 }

 if((log2_trafo_size > ps_sps->i1_log2_max_transform_block_size) ||
 ((1 == intra_split_flag) && (0 == trafo_depth)) ||
 (1 == inter_split_flag))
 {
                split_transform_flag = 1;
 }
 }

 if(0 == trafo_depth)
 {
            ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth] = 0;
            ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth] = 0;
 }
 else
 {
            ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth] = ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth - 1];
            ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth] = ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth - 1];
 }
 if(trafo_depth == 0 || log2_trafo_size > 2)
 {
            ctxt_idx = IHEVC_CAB_CBCR_IDX + trafo_depth;
 /* CBF for Cb/Cr is sent only if the parent CBF for Cb/Cr is non-zero */
 if((trafo_depth == 0) || ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth - 1])
 {
                TRACE_CABAC_CTXT("cbf_cb", ps_cabac->u4_range, ctxt_idx);
                value = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx);
                AEV_TRACE("cbf_cb", value, ps_cabac->u4_range);
                ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth] = value;
 }

 if((trafo_depth == 0) || ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth - 1])
 {
                TRACE_CABAC_CTXT("cbf_cr", ps_cabac->u4_range, ctxt_idx);
                value = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx);
                AEV_TRACE("cbf_cr", value, ps_cabac->u4_range);
                ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth] = value;
 }
 }
 if(split_transform_flag)
 {
            WORD32 intra_pred_mode_tmp;
            x1 = x0 + ((1 << log2_trafo_size) >> 1);
            y1 = y0 + ((1 << log2_trafo_size) >> 1);

 /* For transform depth of zero, intra pred mode as decoded at CU */
 /* level is sent to the transform tree nodes */
 /* When depth is non-zero intra pred mode of parent node is sent */
 /* This takes care of passing correct mode to all the child nodes */
            intra_pred_mode_tmp = trafo_depth ? intra_pred_mode : ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[0];
            ihevcd_parse_transform_tree(ps_codec, x0, y0, x0, y0, log2_trafo_size - 1, trafo_depth + 1, 0, intra_pred_mode_tmp);

            intra_pred_mode_tmp = trafo_depth ? intra_pred_mode : ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[1];
            ihevcd_parse_transform_tree(ps_codec, x1, y0, x0, y0, log2_trafo_size - 1, trafo_depth + 1, 1, intra_pred_mode_tmp);

            intra_pred_mode_tmp = trafo_depth ? intra_pred_mode : ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[2];
            ihevcd_parse_transform_tree(ps_codec, x0, y1, x0, y0, log2_trafo_size - 1, trafo_depth + 1, 2, intra_pred_mode_tmp);

            intra_pred_mode_tmp = trafo_depth ? intra_pred_mode : ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[3];
            ihevcd_parse_transform_tree(ps_codec, x1, y1, x0, y0, log2_trafo_size - 1, trafo_depth + 1, 3, intra_pred_mode_tmp);

 }
 else
 {
            WORD32 ctb_x_base;
            WORD32 ctb_y_base;
            WORD32 cu_qp_delta_abs;



 tu_t *ps_tu = ps_codec->s_parse.ps_tu;
            cu_qp_delta_abs = 0;
            ctb_x_base = ps_codec->s_parse.i4_ctb_x << ps_sps->i1_log2_ctb_size;
            ctb_y_base = ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size;

 if((ps_codec->s_parse.s_cu.i4_pred_mode == PRED_MODE_INTRA) ||
 (trafo_depth != 0) ||
 (ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth]) ||
 (ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth]))
 {
                ctxt_idx = IHEVC_CAB_CBF_LUMA_IDX;
                ctxt_idx += (trafo_depth == 0) ? 1 : 0;

                TRACE_CABAC_CTXT("cbf_luma", ps_cabac->u4_range, ctxt_idx);
                value = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx);
                AEV_TRACE("cbf_luma", value, ps_cabac->u4_range);

                ps_codec->s_parse.s_cu.i1_cbf_luma = value;
 }
 else
 {
                ps_codec->s_parse.s_cu.i1_cbf_luma = 1;
 }

 /* Initialize ps_tu to default values */
 /* If required change this to WORD32 packed write */
            ps_tu->b1_cb_cbf = 0;
            ps_tu->b1_cr_cbf = 0;
            ps_tu->b1_y_cbf = 0;
            ps_tu->b4_pos_x = ((x0 - ctb_x_base) >> 2);
            ps_tu->b4_pos_y = ((y0 - ctb_y_base) >> 2);
            ps_tu->b1_transquant_bypass = ps_codec->s_parse.s_cu.i4_cu_transquant_bypass;
            ps_tu->b3_size = (log2_trafo_size - 2);
            ps_tu->b7_qp = ps_codec->s_parse.u4_qp;

            ps_tu->b6_luma_intra_mode = intra_pred_mode;
            ps_tu->b3_chroma_intra_mode_idx = ps_codec->s_parse.s_cu.i4_intra_chroma_pred_mode_idx;

 /* Section:7.3.12  Transform unit syntax inlined here */
 if(ps_codec->s_parse.s_cu.i1_cbf_luma ||
                            ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth] ||
                            ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth])
 {
                WORD32 intra_pred_mode_chroma;
 if(ps_pps->i1_cu_qp_delta_enabled_flag && !ps_codec->s_parse.i4_is_cu_qp_delta_coded)
 {


                    WORD32 c_max        = TU_MAX_QP_DELTA_ABS;
                    WORD32 ctxt_inc     = IHEVC_CAB_QP_DELTA_ABS;
                    WORD32 ctxt_inc_max = CTXT_MAX_QP_DELTA_ABS;

                    TRACE_CABAC_CTXT("cu_qp_delta_abs", ps_cabac->u4_range, ctxt_inc);
 /* qp_delta_abs is coded as combination of tunary and eg0 code  */
 /* See Table 9-32 and Table 9-37 for details on cu_qp_delta_abs */
                    cu_qp_delta_abs = ihevcd_cabac_decode_bins_tunary(ps_cabac,
                                                                      ps_bitstrm,
                                                                      c_max,
                                                                      ctxt_inc,
 0,
                                                                      ctxt_inc_max);
 if(cu_qp_delta_abs >= c_max)
 {
                        value = ihevcd_cabac_decode_bypass_bins_egk(ps_cabac, ps_bitstrm, 0);
                        cu_qp_delta_abs += value;

                     }
                     AEV_TRACE("cu_qp_delta_abs", cu_qp_delta_abs, ps_cabac->u4_range);
 
                     ps_codec->s_parse.i4_is_cu_qp_delta_coded = 1;
 
 
 if(cu_qp_delta_abs)
 {
                        value = ihevcd_cabac_decode_bypass_bin(ps_cabac, ps_bitstrm);
                        AEV_TRACE("cu_qp_delta_sign", value, ps_cabac->u4_range);

 if(value)

                             cu_qp_delta_abs = -cu_qp_delta_abs;
 
                     }
                     ps_codec->s_parse.s_cu.i4_cu_qp_delta = cu_qp_delta_abs;
 
                 }

 if(ps_codec->s_parse.s_cu.i1_cbf_luma)
 {
                    ps_tu->b1_y_cbf = 1;
                    ihevcd_parse_residual_coding(ps_codec, x0, y0, log2_trafo_size, 0, intra_pred_mode);
 }

 if(4 == ps_codec->s_parse.s_cu.i4_intra_chroma_pred_mode_idx)
                    intra_pred_mode_chroma = ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[0];
 else
 {
                    intra_pred_mode_chroma = gau1_intra_pred_chroma_modes[ps_codec->s_parse.s_cu.i4_intra_chroma_pred_mode_idx];

 if(intra_pred_mode_chroma ==
                                    ps_codec->s_parse.s_cu.ai4_intra_luma_pred_mode[0])
 {
                        intra_pred_mode_chroma = INTRA_ANGULAR(34);
 }

 }
 if(log2_trafo_size > 2)
 {
 if(ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth])
 {
                        ps_tu->b1_cb_cbf = 1;
                        ihevcd_parse_residual_coding(ps_codec, x0, y0, log2_trafo_size - 1, 1, intra_pred_mode_chroma);
 }

 if(ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth])
 {
                        ps_tu->b1_cr_cbf = 1;
                        ihevcd_parse_residual_coding(ps_codec, x0, y0, log2_trafo_size - 1, 2, intra_pred_mode_chroma);
 }
 }
 else if(blk_idx == 3)
 {
 if(ps_codec->s_parse.s_cu.ai1_cbf_cb[trafo_depth])
 {
                        ps_tu->b1_cb_cbf = 1;
                        ihevcd_parse_residual_coding(ps_codec, cu_x_base, cu_y_base, log2_trafo_size, 1, intra_pred_mode_chroma);
 }

 if(ps_codec->s_parse.s_cu.ai1_cbf_cr[trafo_depth])
 {
                        ps_tu->b1_cr_cbf = 1;
                        ihevcd_parse_residual_coding(ps_codec, cu_x_base, cu_y_base, log2_trafo_size, 2, intra_pred_mode_chroma);
 }
 }
 else
 {
                    ps_tu->b3_chroma_intra_mode_idx = INTRA_PRED_CHROMA_IDX_NONE;
 }
 }
 else
 {
 if((3 != blk_idx) && (2 == log2_trafo_size))
 {
                    ps_tu->b3_chroma_intra_mode_idx = INTRA_PRED_CHROMA_IDX_NONE;
 }
 }

 /* Set the first TU in CU flag */
 {
 if((ps_codec->s_parse.s_cu.i4_pos_x << 3) == (ps_tu->b4_pos_x << 2) &&
 (ps_codec->s_parse.s_cu.i4_pos_y << 3) == (ps_tu->b4_pos_y << 2))
 {
                    ps_tu->b1_first_tu_in_cu = 1;
 }
 else
 {
                    ps_tu->b1_first_tu_in_cu = 0;
 }
 }
            ps_codec->s_parse.ps_tu++;
            ps_codec->s_parse.s_cu.i4_tu_cnt++;
            ps_codec->s_parse.i4_pic_tu_idx++;
 }
 }
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  int main(int argc, char **argv) {
 FILE *infile = NULL;
 vpx_codec_ctx_t codec = {0};
 vpx_codec_enc_cfg_t cfg = {0};
 int frame_count = 0;
 vpx_image_t raw;
 vpx_codec_err_t res;
 VpxVideoInfo info = {0};
 VpxVideoWriter *writer = NULL;
 const VpxInterface *encoder = NULL;
 int update_frame_num = 0;
 const int fps = 30; // TODO(dkovalev) add command line argument
 const int bitrate = 200; // kbit/s TODO(dkovalev) add command line argument

  exec_name = argv[0];

 if (argc != 6)
    die("Invalid number of arguments");

  encoder = get_vpx_encoder_by_name("vp8");
 if (!encoder)
    die("Unsupported codec.");

  update_frame_num = atoi(argv[5]);
 if (!update_frame_num)
    die("Couldn't parse frame number '%s'\n", argv[5]);

  info.codec_fourcc = encoder->fourcc;
  info.frame_width = strtol(argv[1], NULL, 0);
  info.frame_height = strtol(argv[2], NULL, 0);
  info.time_base.numerator = 1;
  info.time_base.denominator = fps;

 if (info.frame_width <= 0 ||
      info.frame_height <= 0 ||
 (info.frame_width % 2) != 0 ||
 (info.frame_height % 2) != 0) {
    die("Invalid frame size: %dx%d", info.frame_width, info.frame_height);
 }

 if (!vpx_img_alloc(&raw, VPX_IMG_FMT_I420, info.frame_width,
                                             info.frame_height, 1)) {

     die("Failed to allocate image.");
   }
 
  printf("Using %s\n", vpx_codec_iface_name(encoder->interface()));
 
  res = vpx_codec_enc_config_default(encoder->interface(), &cfg, 0);
   if (res)
     die_codec(&codec, "Failed to get default codec config.");
 
  cfg.g_w = info.frame_width;
  cfg.g_h = info.frame_height;
  cfg.g_timebase.num = info.time_base.numerator;
  cfg.g_timebase.den = info.time_base.denominator;
  cfg.rc_target_bitrate = bitrate;

  writer = vpx_video_writer_open(argv[4], kContainerIVF, &info);
 if (!writer)
    die("Failed to open %s for writing.", argv[4]);


   if (!(infile = fopen(argv[3], "rb")))
     die("Failed to open %s for reading.", argv[3]);
 
  if (vpx_codec_enc_init(&codec, encoder->interface(), &cfg, 0))
     die_codec(&codec, "Failed to initialize encoder");
 
   while (vpx_img_read(&raw, infile)) {
     if (frame_count + 1 == update_frame_num) {
       vpx_ref_frame_t ref;
      ref.frame_type = VP8_LAST_FRAME;
      ref.img = raw;
 if (vpx_codec_control(&codec, VP8_SET_REFERENCE, &ref))
        die_codec(&codec, "Failed to set reference frame");
 }

 
     encode_frame(&codec, &raw, frame_count++, writer);
   }
  encode_frame(&codec, NULL, -1, writer);
 
   printf("\n");
   fclose(infile);
  printf("Processed %d frames.\n", frame_count);

  vpx_img_free(&raw);
 if (vpx_codec_destroy(&codec))
    die_codec(&codec, "Failed to destroy codec.");

  vpx_video_writer_close(writer);

 return EXIT_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool ACodec::isFlexibleColorFormat(
 const sp<IOMX> &omx, IOMX::node_id node,
 uint32_t colorFormat, bool usingNativeBuffers, OMX_U32 *flexibleEquivalent) {
 DescribeColorFormatParams describeParams;
 InitOMXParams(&describeParams);
    describeParams.eColorFormat = (OMX_COLOR_FORMATTYPE)colorFormat;
    describeParams.nFrameWidth = 128;
    describeParams.nFrameHeight = 128;
    describeParams.nStride = 128;
    describeParams.nSliceHeight = 128;
    describeParams.bUsingNativeBuffers = (OMX_BOOL)usingNativeBuffers;

    CHECK(flexibleEquivalent != NULL);

 if (!describeColorFormat(omx, node, describeParams)) {
 return false;
 }

 const MediaImage &img = describeParams.sMediaImage;
 if (img.mType == MediaImage::MEDIA_IMAGE_TYPE_YUV) {
 if (img.mNumPlanes != 3 ||
            img.mPlane[img.Y].mHorizSubsampling != 1 ||
            img.mPlane[img.Y].mVertSubsampling != 1) {
 return false;
 }

 if (img.mPlane[img.U].mHorizSubsampling == 2
 && img.mPlane[img.U].mVertSubsampling == 2
 && img.mPlane[img.V].mHorizSubsampling == 2
 && img.mPlane[img.V].mVertSubsampling == 2) {
 if (img.mBitDepth <= 8) {
 *flexibleEquivalent = OMX_COLOR_FormatYUV420Flexible;
 return true;
 }
 }
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Equalizer_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int status = 0;
 int32_t preset;
 int32_t band;
 int32_t level;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param) {
 case EQ_PARAM_CUR_PRESET:
        preset = (int32_t)(*(uint16_t *)pValue);

 if ((preset >= EqualizerGetNumPresets())||(preset < 0)) {
            status = -EINVAL;
 break;
 }
 EqualizerSetPreset(pContext, preset);
 break;
 case EQ_PARAM_BAND_LEVEL:
        band = *pParamTemp;
        level = (int32_t)(*(int16_t *)pValue);
 if (band >= FIVEBAND_NUMBANDS) {
            status = -EINVAL;
 break;
 }
 EqualizerSetBandLevel(pContext, band, level);
 break;
 case EQ_PARAM_PROPERTIES: {
 int16_t *p = (int16_t *)pValue;
 if ((int)p[0] >= EqualizerGetNumPresets()) {
            status = -EINVAL;
 break;
 }
 if (p[0] >= 0) {
 EqualizerSetPreset(pContext, (int)p[0]);
 } else {
 if ((int)p[1] != FIVEBAND_NUMBANDS) {
                status = -EINVAL;
 break;
 }
 for (int i = 0; i < FIVEBAND_NUMBANDS; i++) {
 EqualizerSetBandLevel(pContext, i, (int)p[2 + i]);
 }
 }
 } break;
 default:
        ALOGV("\tLVM_ERROR : Equalizer_setParameter() invalid param %d", param);
        status = -EINVAL;
 break;
 }

 return status;
} /* end Equalizer_setParameter */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t dequeueBuffer(int *buf, sp<Fence>* fence, bool async,
 uint32_t width, uint32_t height, PixelFormat format,
 uint32_t usage) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor());
        data.writeInt32(static_cast<int32_t>(async));
        data.writeUint32(width);
        data.writeUint32(height);
        data.writeInt32(static_cast<int32_t>(format));
        data.writeUint32(usage);
 status_t result = remote()->transact(DEQUEUE_BUFFER, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 *buf = reply.readInt32();
 bool nonNull = reply.readInt32();
 if (nonNull) {
 *fence = new Fence();
            reply.read(**fence);
 }
        result = reply.readInt32();
 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::use_android_native_buffer(OMX_IN OMX_HANDLETYPE hComp, OMX_PTR data)
{
    DEBUG_PRINT_LOW("Inside use_android_native_buffer");
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 UseAndroidNativeBufferParams *params = (UseAndroidNativeBufferParams *)data;

 if ((params == NULL) ||
 (params->nativeBuffer == NULL) ||
 (params->nativeBuffer->handle == NULL) ||
 !m_enable_android_native_buffers)
 return OMX_ErrorBadParameter;
    m_use_android_native_buffers = OMX_TRUE;
    sp<android_native_buffer_t> nBuf = params->nativeBuffer;
 private_handle_t *handle = (private_handle_t *)nBuf->handle;
 if (OMX_CORE_OUTPUT_PORT_INDEX == params->nPortIndex) { //android native buffers can be used only on Output port
        OMX_U8 *buffer = NULL;
 if (!secure_mode) {
            buffer = (OMX_U8*)mmap(0, handle->size,
                    PROT_READ|PROT_WRITE, MAP_SHARED, handle->fd, 0);
 if (buffer == MAP_FAILED) {
                DEBUG_PRINT_ERROR("Failed to mmap pmem with fd = %d, size = %d", handle->fd, handle->size);
 return OMX_ErrorInsufficientResources;
 }
 }
        eRet = use_buffer(hComp,params->bufferHeader,params->nPortIndex,data,handle->size,buffer);
 } else {
        eRet = OMX_ErrorBadParameter;
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool IsSoftwareCodec(const char *componentName) {
 if (!strncmp("OMX.google.", componentName, 11)) {
 return true;
 }

 if (!strncmp("OMX.", componentName, 4)) {
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftGSM::~SoftGSM() {
    gsm_destroy(mGsm);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_initiate_av_open_timer_timeout(UNUSED_ATTR void* data) {
 RawAddress peer_addr;
 btif_av_connect_req_t connect_req;

 /* is there at least one RC connection - There should be */
 if (btif_rc_get_connected_peer(&peer_addr)) {
    BTIF_TRACE_DEBUG("%s: Issuing connect to the remote RC peer", __func__);
 /* In case of AVRCP connection request, we will initiate SRC connection */
    connect_req.target_bda = &peer_addr;
 if (bt_av_sink_callbacks != NULL)
      connect_req.uuid = UUID_SERVCLASS_AUDIO_SINK;
 else if (bt_av_src_callbacks != NULL)
      connect_req.uuid = UUID_SERVCLASS_AUDIO_SOURCE;
    btif_dispatch_sm_event(BTIF_AV_CONNECT_REQ_EVT, (char*)&connect_req,
 sizeof(connect_req));
 } else {
    BTIF_TRACE_ERROR("%s: No connected RC peers", __func__);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long long BlockGroup::GetPrevTimeCode() const { return m_prev; }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void WT_SustainPedal (S_VOICE_MGR *pVoiceMgr, S_SYNTH *pSynth, S_SYNTH_VOICE *pVoice, S_SYNTH_CHANNEL *pChannel, EAS_I32 voiceNum)
{
    S_WT_VOICE *pWTVoice;

#ifdef DLS_SYNTHESIZER
 if (pVoice->regionIndex & FLAG_RGN_IDX_DLS_SYNTH)
 {
        DLS_SustainPedal(pVoiceMgr, pSynth, pVoice, pChannel, voiceNum);
 return;
 }
#endif

 /* don't catch the voice if below the sustain level */
    pWTVoice = &pVoiceMgr->wtVoices[voiceNum];
 if (pWTVoice->eg1Value < pSynth->pEAS->pArticulations[pWTVoice->artIndex].eg1.sustainLevel)
 return;

 /* sustain flag is set, damper pedal is on */
 /* defer releasing this note until the damper pedal is off */
    pWTVoice->eg1State = eEnvelopeStateDecay;
    pVoice->voiceState = eVoiceStatePlay;

 /*
    because sustain pedal is on, this voice
    should defer releasing its note
    */
    pVoice->voiceFlags |= VOICE_FLAG_SUSTAIN_PEDAL_DEFER_NOTE_OFF;

#ifdef _DEBUG_SYNTH
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_INFO, "WT_SustainPedal: defer note off because sustain pedal is on\n"); */ }
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MBMotionComp(
 VideoDecData *video,
 int CBP
)
{

 /*----------------------------------------------------------------------------
    ; Define all local variables
    ----------------------------------------------------------------------------*/
 /* Previous Video Object Plane */
 Vop *prev = video->prevVop;

 /* Current Macroblock (MB) in the VOP */
 int mbnum = video->mbnum;

 /* Number of MB per data row */
 int MB_in_width = video->nMBPerRow;
 int ypos, xpos;
    PIXEL *c_comp, *c_prev;
    PIXEL *cu_comp, *cu_prev;
    PIXEL *cv_comp, *cv_prev;
 int height, width, pred_width;
 int imv, mvwidth;
 int32 offset;
 uint8 mode;
 uint8 *pred_block, *pred;

 /* Motion vector (dx,dy) in half-pel resolution */
 int dx, dy;

    MOT px[4], py[4];
 int xpred, ypred;
 int xsum;
 int round1;
#ifdef PV_POSTPROC_ON // 2/14/2001      
 /* Total number of pixels in the VOL */
 int32 size = (int32) video->nTotalMB << 8;
 uint8 *pp_dec_y, *pp_dec_u;
 int ll[4];
 int tmp = 0;
 uint8 msk_deblock = 0;
#endif
 /*----------------------------------------------------------------------------
    ; Function body here
    ----------------------------------------------------------------------------*/
 /* Set rounding type */
 /* change from array to single 09/29/2000 */
    round1 = (int)(1 - video->currVop->roundingType);

 /* width of luminance data in pixels (y axis) */
    width = video->width;

 /* heigth of luminance data in pixels (x axis) */
    height = video->height;

 /* number of blocks per row */
    mvwidth = MB_in_width << 1;

 /* starting y position in current MB; origin of MB */
    ypos = video->mbnum_row << 4 ;
 /* starting x position in current MB; origin of MB */
    xpos = video->mbnum_col << 4 ;

 /* offset to (x,y) position in current luminance MB */
 /* in pixel resolution                              */
 /* ypos*width -> row, +x -> column */
    offset = (int32)ypos * width + xpos;

 /* get mode for current MB */
    mode = video->headerInfo.Mode[mbnum];

 /* block index */
 /* imv = (xpos/8) + ((ypos/8) * mvwidth) */
    imv = (offset >> 6) - (xpos >> 6) + (xpos >> 3);
 if (mode & INTER_1VMASK)
 {
        dx = px[0] = px[1] = px[2] = px[3] = video->motX[imv];
        dy = py[0] = py[1] = py[2] = py[3] = video->motY[imv];
 if ((dx & 3) == 0)
 {
            dx = dx >> 1;
 }
 else
 {
 /* x component of MV is or'ed for rounding (?) */
            dx = (dx >> 1) | 1;
 }

 /* y component of motion vector; divide by 2 for to */
 /* convert to full-pel resolution.                  */
 if ((dy & 3) == 0)
 {
            dy = dy >> 1;
 }
 else
 {
 /* y component of MV is or'ed for rounding (?) */
            dy = (dy >> 1) | 1;
 }
 }
 else
 {
        px[0] = video->motX[imv];
        px[1] = video->motX[imv+1];
        px[2] = video->motX[imv+mvwidth];
        px[3] = video->motX[imv+mvwidth+1];
        xsum = px[0] + px[1] + px[2] + px[3];
        dx = PV_SIGN(xsum) * (roundtab16[(PV_ABS(xsum)) & 0xF] +
 (((PV_ABS(xsum)) >> 4) << 1));
        py[0] = video->motY[imv];
        py[1] = video->motY[imv+1];
        py[2] = video->motY[imv+mvwidth];
        py[3] = video->motY[imv+mvwidth+1];
        xsum = py[0] + py[1] + py[2] + py[3];
        dy = PV_SIGN(xsum) * (roundtab16[(PV_ABS(xsum)) & 0xF] +
 (((PV_ABS(xsum)) >> 4) << 1));
 }

 
     /* Pointer to previous luminance frame */
     c_prev  = prev->yChan;
 
     pred_block = video->mblock->pred_block;
 
 /* some blocks have no residue or INTER4V */
 /*if (mode == MODE_INTER4V)   05/08/15 */
 /* Motion Compensation for an 8x8 block within a MB */
 /* (4 MV per MB) */



 /* Call function that performs luminance prediction */
 /*      luminance_pred_mode_inter4v(xpos, ypos, px, py, c_prev,
                    video->mblock->pred_block, width, height,
                    round1, mvwidth, &xsum, &ysum);*/
    c_comp = video->currVop->yChan + offset;


    xpred = (int)((xpos << 1) + px[0]);
    ypred = (int)((ypos << 1) + py[0]);

 if ((CBP >> 5)&1)
 {
        pred = pred_block;
        pred_width = 16;
 }
 else
 {
        pred = c_comp;
        pred_width = width;
 }

 /* check whether the MV points outside the frame */
 if (xpred >= 0 && xpred <= ((width << 1) - (2*B_SIZE)) &&
            ypred >= 0 && ypred <= ((height << 1) - (2*B_SIZE)))
 { /*****************************/
 /* (x,y) is inside the frame */
 /*****************************/
 ;
 GetPredAdvBTable[ypred&1][xpred&1](c_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);
 }
 else
 { /******************************/
 /* (x,y) is outside the frame */
 /******************************/
 GetPredOutside(xpred, ypred, c_prev,
                       pred, width, height, round1, pred_width);
 }


 /* Compute prediction values over current luminance MB */
 /* (blocks 1); add motion vector prior to input;       */
 /* add 8 to x_pos to advance to next block         */
    xpred = (int)(((xpos + B_SIZE) << 1) + px[1]);
    ypred = (int)((ypos << 1) + py[1]);

 if ((CBP >> 4)&1)
 {
        pred = pred_block + 8;
        pred_width = 16;
 }
 else
 {
        pred = c_comp + 8;
        pred_width = width;
 }

 /* check whether the MV points outside the frame */
 if (xpred >= 0 && xpred <= ((width << 1) - (2*B_SIZE)) &&
            ypred >= 0 && ypred <= ((height << 1) - (2*B_SIZE)))
 { /*****************************/
 /* (x,y) is inside the frame */
 /*****************************/
 GetPredAdvBTable[ypred&1][xpred&1](c_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);
 }
 else
 { /******************************/
 /* (x,y) is outside the frame */
 /******************************/
 GetPredOutside(xpred, ypred, c_prev,
                       pred, width, height, round1, pred_width);
 }



 /* Compute prediction values over current luminance MB */
 /* (blocks 2); add motion vector prior to input        */
 /* add 8 to y_pos to advance to block on next row      */
    xpred = (int)((xpos << 1) + px[2]);
    ypred = (int)(((ypos + B_SIZE) << 1) + py[2]);

 if ((CBP >> 3)&1)
 {
        pred = pred_block + 128;
        pred_width = 16;
 }
 else
 {
        pred = c_comp + (width << 3);
        pred_width = width;
 }

 /* check whether the MV points outside the frame */
 if (xpred >= 0 && xpred <= ((width << 1) - (2*B_SIZE)) &&
            ypred >= 0 && ypred <= ((height << 1) - (2*B_SIZE)))
 { /*****************************/
 /* (x,y) is inside the frame */
 /*****************************/
 GetPredAdvBTable[ypred&1][xpred&1](c_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);
 }
 else
 { /******************************/
 /* (x,y) is outside the frame */
 /******************************/
 GetPredOutside(xpred, ypred, c_prev,
                       pred, width, height, round1, pred_width);
 }



 /* Compute prediction values over current luminance MB */
 /* (blocks 3); add motion vector prior to input;       */
 /* add 8 to x_pos and y_pos to advance to next block   */
 /* on next row                         */
    xpred = (int)(((xpos + B_SIZE) << 1) + px[3]);
    ypred = (int)(((ypos + B_SIZE) << 1) + py[3]);

 if ((CBP >> 2)&1)
 {
        pred = pred_block + 136;
        pred_width = 16;
 }
 else
 {
        pred = c_comp + (width << 3) + 8;
        pred_width = width;
 }

 /* check whether the MV points outside the frame */
 if (xpred >= 0 && xpred <= ((width << 1) - (2*B_SIZE)) &&
            ypred >= 0 && ypred <= ((height << 1) - (2*B_SIZE)))
 { /*****************************/
 /* (x,y) is inside the frame */
 /*****************************/
 GetPredAdvBTable[ypred&1][xpred&1](c_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);
 }
 else
 { /******************************/
 /* (x,y) is outside the frame */
 /******************************/
 GetPredOutside(xpred, ypred, c_prev,
                       pred, width, height, round1, pred_width);
 }
 /* Call function to set de-blocking and de-ringing */
 /*   semaphores for luminance                      */

#ifdef PV_POSTPROC_ON
 if (video->postFilterType != PV_NO_POST_PROC)
 {
 if (mode&INTER_1VMASK)
 {
            pp_dec_y = video->pstprcTypCur + imv;
            ll[0] = 1;
            ll[1] = mvwidth - 1;
            ll[2] = 1;
            ll[3] = -mvwidth - 1;
            msk_deblock = pp_semaphore_luma(xpred, ypred, pp_dec_y,
                                            video->pstprcTypPrv, ll, &tmp, px[0], py[0], mvwidth,
                                            width, height);

            pp_dec_u = video->pstprcTypCur + (size >> 6) +
 ((imv + (xpos >> 3)) >> 2);

            pp_semaphore_chroma_inter(xpred, ypred, pp_dec_u,
                                      video->pstprcTypPrv, dx, dy, mvwidth, height, size,
                                      tmp, msk_deblock);
 }
 else
 {
 /* Post-processing mode (MBM_INTER8) */
 /* deblocking and deringing) */
            pp_dec_y = video->pstprcTypCur + imv;
 *pp_dec_y = 4;
 *(pp_dec_y + 1) = 4;
 *(pp_dec_y + mvwidth) = 4;
 *(pp_dec_y + mvwidth + 1) = 4;
            pp_dec_u = video->pstprcTypCur + (size >> 6) +
 ((imv + (xpos >> 3)) >> 2);
 *pp_dec_u = 4;
            pp_dec_u[size>>8] = 4;
 }
 }
#endif


 /* xpred and ypred calculation for Chrominance is */
 /* in full-pel resolution.                        */

 /* Chrominance */
 /* width of chrominance data in pixels (y axis) */
    width >>= 1;

 /* heigth of chrominance data in pixels (x axis) */
    height >>= 1;

 /* Pointer to previous chrominance b frame */
    cu_prev = prev->uChan;

 /* Pointer to previous chrominance r frame */
    cv_prev = prev->vChan;

 /* x position in prediction data offset by motion vector */
 /* xpred calculation for Chrominance is in full-pel      */
 /* resolution.                                           */
    xpred = xpos + dx;

 /* y position in prediction data offset by motion vector */
 /* ypred calculation for Chrominance is in full-pel      */
 /* resolution.                                           */
    ypred = ypos + dy;

    cu_comp = video->currVop->uChan + (offset >> 2) + (xpos >> 2);
    cv_comp = video->currVop->vChan + (offset >> 2) + (xpos >> 2);

 /* Call function that performs chrominance prediction */
 /*      chrominance_pred(xpred, ypred, cu_prev, cv_prev,
            pred_block, width_uv, height_uv,
            round1);*/
 if (xpred >= 0 && xpred <= ((width << 1) - (2*B_SIZE)) && ypred >= 0 &&
            ypred <= ((height << 1) - (2*B_SIZE)))
 {
 /*****************************/
 /* (x,y) is inside the frame */
 /*****************************/
 if ((CBP >> 1)&1)
 {
            pred = pred_block + 256;
            pred_width = 16;
 }
 else
 {
            pred = cu_comp;
            pred_width = width;
 }

 /* Compute prediction for Chrominance b (block[4]) */
 GetPredAdvBTable[ypred&1][xpred&1](cu_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);

 if (CBP&1)
 {
            pred = pred_block + 264;
            pred_width = 16;
 }
 else
 {
            pred = cv_comp;
            pred_width = width;
 }
 /* Compute prediction for Chrominance r (block[5]) */
 GetPredAdvBTable[ypred&1][xpred&1](cv_prev + (xpred >> 1) + ((ypred >> 1)*width),
                                           pred, width, (pred_width << 1) | round1);

 return ;
 }
 else
 {
 /******************************/
 /* (x,y) is outside the frame */
 /******************************/
 if ((CBP >> 1)&1)
 {
            pred = pred_block + 256;
            pred_width = 16;
 }
 else
 {
            pred = cu_comp;
            pred_width = width;
 }

 /* Compute prediction for Chrominance b (block[4]) */
 GetPredOutside(xpred, ypred,    cu_prev,
                       pred, width, height, round1, pred_width);

 if (CBP&1)
 {
            pred = pred_block + 264;
            pred_width = 16;
 }
 else
 {
            pred = cv_comp;
            pred_width = width;
 }

 /* Compute prediction for Chrominance r (block[5]) */
 GetPredOutside(xpred, ypred,    cv_prev,
                       pred, width, height, round1, pred_width);

 return ;
 }

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void ref_cnt_fb (int *buf, int *idx, int new_idx)
{
 if (buf[*idx] > 0)
        buf[*idx]--;

 *idx = new_idx;

    buf[new_idx]++;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void uipc_close_locked(tUIPC_CH_ID ch_id)
{
 if (uipc_main.ch[ch_id].srvfd == UIPC_DISCONNECTED)
 {
        BTIF_TRACE_EVENT("CHANNEL %d ALREADY CLOSED", ch_id);
 return;
 }

 /* schedule close on this channel */
    uipc_main.ch[ch_id].task_evt_flags |= UIPC_TASK_FLAG_DISCONNECT_CHAN;
    uipc_wakeup_locked();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMediaDeathNotifier::removeObitRecipient(const wp<IMediaDeathNotifier>& recipient)
{
    ALOGV("removeObitRecipient");
 Mutex::Autolock _l(sServiceLock);
    sObitRecipients.remove(recipient);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t ReverbGetDecayTime(ReverbContext *pContext){

    LVREV_ControlParams_st    ActiveParams; /* Current control Parameters */
    LVREV_ReturnStatus_en     LvmStatus=LVREV_SUCCESS; /* Function call status */

 /* Get the current settings */
 LvmStatus = LVREV_GetControlParameters(pContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVREV_GetControlParameters", "ReverbGetDecayTime")

 if(ActiveParams.T60 != pContext->SavedDecayTime){
        ALOGV("\tLVM_ERROR : ReverbGetDecayTime() has wrong level -> %d %d\n",
 ActiveParams.T60, pContext->SavedDecayTime);
 }

 return (uint32_t)ActiveParams.T60;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long AudioTrack::Parse(Segment* pSegment, const Info& info,
 long long element_start, long long element_size,
 AudioTrack*& pResult) {
 if (pResult)
 return -1;

 if (info.type != Track::kAudio)
 return -1;

 IMkvReader* const pReader = pSegment->m_pReader;

 const Settings& s = info.settings;
  assert(s.start >= 0);
  assert(s.size >= 0);

 long long pos = s.start;
  assert(pos >= 0);

 const long long stop = pos + s.size;

 double rate = 8000.0; // MKV default
 long long channels = 1;
 long long bit_depth = 0;

 while (pos < stop) {
 long long id, size;

 long status = ParseElementHeader(pReader, pos, stop, id, size);

 if (status < 0) // error
 return status;

 if (id == 0x35) { // Sample Rate
      status = UnserializeFloat(pReader, pos, size, rate);

 if (status < 0)
 return status;

 if (rate <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x1F) { // Channel Count
      channels = UnserializeUInt(pReader, pos, size);

 if (channels <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x2264) { // Bit Depth
      bit_depth = UnserializeUInt(pReader, pos, size);

 if (bit_depth <= 0)
 return E_FILE_FORMAT_INVALID;

     }
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
  assert(pos == stop);
 
   AudioTrack* const pTrack =
       new (std::nothrow) AudioTrack(pSegment, element_start, element_size);

 if (pTrack == NULL)
 return -1; // generic error

 const int status = info.Copy(pTrack->m_info);

 if (status) {
 delete pTrack;
 return status;
 }

  pTrack->m_rate = rate;
  pTrack->m_channels = channels;
  pTrack->m_bitDepth = bit_depth;

  pResult = pTrack;
 return 0; // success
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean removeBondNative(JNIEnv* env, jobject obj, jbyteArray address) {
    ALOGV("%s:",__FUNCTION__);

    jbyte *addr;
    jboolean result;
 if (!sBluetoothInterface) return JNI_FALSE;

    addr = env->GetByteArrayElements(address, NULL);
 if (addr == NULL) {
        jniThrowIOException(env, EINVAL);
 return JNI_FALSE;
 }

 int ret = sBluetoothInterface->remove_bond((bt_bdaddr_t *)addr);
    env->ReleaseByteArrayElements(address, addr, 0);
    result = (ret == BT_STATUS_SUCCESS) ? JNI_TRUE : JNI_FALSE;

 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SoftHEVC::setNumCores() {
 ivdext_ctl_set_num_cores_ip_t s_set_cores_ip;
 ivdext_ctl_set_num_cores_op_t s_set_cores_op;
    IV_API_CALL_STATUS_T status;
    s_set_cores_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_set_cores_ip.e_sub_cmd = IVDEXT_CMD_CTL_SET_NUM_CORES;
    s_set_cores_ip.u4_num_cores = MIN(mNumCores, CODEC_MAX_NUM_CORES);
    s_set_cores_ip.u4_size = sizeof(ivdext_ctl_set_num_cores_ip_t);
    s_set_cores_op.u4_size = sizeof(ivdext_ctl_set_num_cores_op_t);
    ALOGV("Set number of cores to %u", s_set_cores_ip.u4_num_cores);
    status = ivdec_api_function(mCodecCtx, (void *)&s_set_cores_ip,
 (void *)&s_set_cores_op);
 if (IV_SUCCESS != status) {
        ALOGE("Error in setting number of cores: 0x%x",
                s_set_cores_op.u4_error_code);
 return UNKNOWN_ERROR;
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlSAXParseEntity(xmlSAXHandlerPtr sax, const char *filename) {
    xmlDocPtr ret;
    xmlParserCtxtPtr ctxt;

    ctxt = xmlCreateFileParserCtxt(filename);
 if (ctxt == NULL) {
 return(NULL);
 }
 if (sax != NULL) {
 if (ctxt->sax != NULL)
	    xmlFree(ctxt->sax);
        ctxt->sax = sax;
        ctxt->userData = NULL;
 }

    xmlParseExtParsedEnt(ctxt);

 if (ctxt->wellFormed)
	ret = ctxt->myDoc;
 else {
        ret = NULL;
        xmlFreeDoc(ctxt->myDoc);
        ctxt->myDoc = NULL;
 }
 if (sax != NULL)
        ctxt->sax = NULL;
    xmlFreeParserCtxt(ctxt);

 return(ret);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int XfrmController::fillUserSaId(const XfrmId& record, xfrm_usersa_id* said) {
    said->daddr = record.dstAddr;
    said->spi = record.spi;
    said->family = record.addrFamily;
    said->proto = IPPROTO_ESP;

 return sizeof(*said);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::allocateOutputMetadataBuffers() {
    OMX_U32 bufferCount, bufferSize, minUndequeuedBuffers;
 status_t err = configureOutputBuffersFromNativeWindow(
 &bufferCount, &bufferSize, &minUndequeuedBuffers);
 if (err != 0)
 return err;
    mNumUndequeuedBuffers = minUndequeuedBuffers;

    ALOGV("[%s] Allocating %u meta buffers on output port",
         mComponentName.c_str(), bufferCount);

 size_t bufSize = mOutputMetadataType == kMetadataBufferTypeANWBuffer ?
 sizeof(struct VideoNativeMetadata) : sizeof(struct VideoGrallocMetadata);
 size_t totalSize = bufferCount * bufSize;
    mDealer[kPortIndexOutput] = new MemoryDealer(totalSize, "ACodec");

 for (OMX_U32 i = 0; i < bufferCount; i++) {
 BufferInfo info;
        info.mStatus = BufferInfo::OWNED_BY_NATIVE_WINDOW;
        info.mFenceFd = -1;
        info.mRenderInfo = NULL;
        info.mGraphicBuffer = NULL;
        info.mDequeuedAt = mDequeueCounter;

        sp<IMemory> mem = mDealer[kPortIndexOutput]->allocate(bufSize);
 if (mem == NULL || mem->pointer() == NULL) {
 return NO_MEMORY;
 }
 if (mOutputMetadataType == kMetadataBufferTypeANWBuffer) {
 ((VideoNativeMetadata *)mem->pointer())->nFenceFd = -1;
 }
        info.mData = new ABuffer(mem->pointer(), mem->size());

        err = mOMX->useBuffer(
                mNode, kPortIndexOutput, mem, &info.mBufferID, mem->size());

        mBuffers[kPortIndexOutput].push(info);

        ALOGV("[%s] allocated meta buffer with ID %u (pointer = %p)",
             mComponentName.c_str(), info.mBufferID, mem->pointer());
 }

 if (mLegacyAdaptiveExperiment) {
 static_cast<Surface *>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(true);

        ALOGV("[%s] Allocating %u buffers from a native window of size %u on "
 "output port",
             mComponentName.c_str(), bufferCount, bufferSize);

 for (OMX_U32 i = 0; i < bufferCount; i++) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);

 ANativeWindowBuffer *buf;
 int fenceFd;
            err = mNativeWindow->dequeueBuffer(mNativeWindow.get(), &buf, &fenceFd);
 if (err != 0) {
                ALOGE("dequeueBuffer failed: %s (%d)", strerror(-err), -err);
 break;
 }

            sp<GraphicBuffer> graphicBuffer(new GraphicBuffer(buf, false));
            mOMX->updateGraphicBufferInMeta(
                    mNode, kPortIndexOutput, graphicBuffer, info->mBufferID);
            info->mStatus = BufferInfo::OWNED_BY_US;
            info->setWriteFence(fenceFd, "allocateOutputMetadataBuffers for legacy");
            info->mGraphicBuffer = graphicBuffer;
 }

 for (OMX_U32 i = 0; i < mBuffers[kPortIndexOutput].size(); i++) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_US) {
 status_t error = cancelBufferToNativeWindow(info);
 if (err == OK) {
                    err = error;
 }
 }
 }

 static_cast<Surface*>(mNativeWindow.get())
 ->getIGraphicBufferProducer()->allowAllocation(false);
 }

    mMetadataBuffersToSubmit = bufferCount - minUndequeuedBuffers;
 return err;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool omx_venc::dev_free_buf(void *buf_addr,unsigned port)
{
 return handle->venc_free_buf(buf_addr,port);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int res_unpack(vorbis_info_residue *info,
		vorbis_info *vi,oggpack_buffer *opb){
   int j,k;
   codec_setup_info     *ci=(codec_setup_info *)vi->codec_setup;
   memset(info,0,sizeof(*info));

  info->type=oggpack_read(opb,16);
 if(info->type>2 || info->type<0)goto errout;
  info->begin=oggpack_read(opb,24);
  info->end=oggpack_read(opb,24);
  info->grouping=oggpack_read(opb,24)+1;
  info->partitions=(char)(oggpack_read(opb,6)+1);
  info->groupbook=(unsigned char)oggpack_read(opb,8);
 if(info->groupbook>=ci->books)goto errout;

  info->stagemasks=_ogg_malloc(info->partitions*sizeof(*info->stagemasks));
  info->stagebooks=_ogg_malloc(info->partitions*8*sizeof(*info->stagebooks));

 for(j=0;j<info->partitions;j++){
 int cascade=oggpack_read(opb,3);
 if(oggpack_read(opb,1))
      cascade|=(oggpack_read(opb,5)<<3);
    info->stagemasks[j]=cascade;
 }


   for(j=0;j<info->partitions;j++){
     for(k=0;k<8;k++){
       if((info->stagemasks[j]>>k)&1){
	unsigned char book=(unsigned char)oggpack_read(opb,8);
	if(book>=ci->books)goto errout;
	info->stagebooks[j*8+k]=book;
	if(k+1>info->stages)info->stages=k+1;
       }else
	info->stagebooks[j*8+k]=0xff;
     }
   }
 
 if(oggpack_eop(opb))goto errout;

 return 0;
 errout:
  res_clear_info(info);
 return 1;

 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readPointer(uintptr_t *pArg) const
{
 status_t ret;
 binder_uintptr_t ptr;
    ret = readAligned(&ptr);
 if (!ret)
 *pArg = ptr;
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t SampleTable::setTimeToSampleParams(
         off64_t data_offset, size_t data_size) {
    if (mTimeToSample != NULL || data_size < 8) {
         return ERROR_MALFORMED;
     }
 
 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;

     }
 
     mTimeToSampleCount = U32_AT(&header[4]);
    uint64_t allocSize = (uint64_t)mTimeToSampleCount * 2 * sizeof(uint32_t);
    if (allocSize > UINT32_MAX) {
         return ERROR_OUT_OF_RANGE;
     }
    mTimeToSample = new (std::nothrow) uint32_t[mTimeToSampleCount * 2];
    if (!mTimeToSample)
        return ERROR_OUT_OF_RANGE;
 
    size_t size = sizeof(uint32_t) * mTimeToSampleCount * 2;
    if (mDataSource->readAt(
                data_offset + 8, mTimeToSample, size) < (ssize_t)size) {
         return ERROR_IO;
     }
 
    for (uint32_t i = 0; i < mTimeToSampleCount * 2; ++i) {
        mTimeToSample[i] = ntohl(mTimeToSample[i]);
     }
     return OK;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::growData(size_t len)
{
 if (len > INT32_MAX) {
 return BAD_VALUE;
 }

 size_t newSize = ((mDataSize+len)*3)/2;
 return (newSize <= mDataSize)
 ? (status_t) NO_MEMORY
 : continueWrite(newSize);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void RilSapSocket::addSocketToList(const char *socketName, RIL_SOCKET_ID socketid,
        RIL_RadioFunctions *uimFuncs) {
 RilSapSocket* socket = NULL;
 RilSapSocketList *current;

 if(!SocketExists(socketName)) {
        socket = new RilSapSocket(socketName, socketid, uimFuncs);
 RilSapSocketList* listItem = (RilSapSocketList*)malloc(sizeof(RilSapSocketList));
 if (!listItem) {
            RLOGE("addSocketToList: OOM");
 return;
 }
        listItem->socket = socket;
        listItem->next = NULL;

        RLOGD("Adding socket with id: %d", socket->id);

 if(NULL == head) {
            head = listItem;
            head->next = NULL;
 }
 else {
            current = head;
 while(NULL != current->next) {
                current = current->next;
 }
            current->next = listItem;
 }
        socket->socketInit();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: extern BOOLEAN UIPC_Ioctl(tUIPC_CH_ID ch_id, UINT32 request, void *param)
{
    BTIF_TRACE_DEBUG("#### UIPC_Ioctl : ch_id %d, request %d ####", ch_id, request);

    UIPC_LOCK();

 switch(request)
 {
 case UIPC_REQ_RX_FLUSH:
            uipc_flush_locked(ch_id);
 break;

 case UIPC_REG_CBACK:
            uipc_main.ch[ch_id].cback = (tUIPC_RCV_CBACK*)param;
 break;

 case UIPC_REG_REMOVE_ACTIVE_READSET:

 /* user will read data directly and not use select loop */
 if (uipc_main.ch[ch_id].fd != UIPC_DISCONNECTED)
 {
 /* remove this channel from active set */
                FD_CLR(uipc_main.ch[ch_id].fd, &uipc_main.active_set);

 /* refresh active set */
                uipc_wakeup_locked();
 }
 break;

 case UIPC_SET_READ_POLL_TMO:
            uipc_main.ch[ch_id].read_poll_tmo_ms = (intptr_t)param;
            BTIF_TRACE_EVENT("UIPC_SET_READ_POLL_TMO : CH %d, TMO %d ms", ch_id, uipc_main.ch[ch_id].read_poll_tmo_ms );
 break;

 default:
            BTIF_TRACE_EVENT("UIPC_Ioctl : request not handled (%d)", request);
 break;
 }

    UIPC_UNLOCK();

 return FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;


 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
        ih264d_err_pic_dispbuf_mgr(ps_dec);
 return 0;
 }
    ps_dec->ps_dpb_cmds->u1_long_term_reference_flag = 0;
 if(prev_slice_err == 1)
 {
 /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;


 if(!ps_dec->u1_first_slice_in_stream)
 {
            ih264d_end_of_pic(ps_dec, u1_is_idr_slice,
                ps_dec->ps_cur_slice->u2_frame_num);
            ps_dec->s_cur_pic_poc.u2_frame_num =
                ps_dec->ps_cur_slice->u2_frame_num;
 }

 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = 0;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
                       j = i;
 {
                ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
                ps_dec->ps_cur_slice->u1_nal_ref_idc = 1;
                ps_dec->ps_cur_slice->u1_nal_unit_type = 1;
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;

                 }
             }
         }
     }
     else
     {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;

 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info - 1;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

            ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
            ps_dec->u2_cur_mb_addr--;
            ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if(u1_num_mbs)
 {
 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

            ps_dec->u2_cur_slice_num++;
             ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
            ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
            ps_dec->ps_parse_cur_slice++;

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MAX_FRAMES;
 if((1 >= ps_dec->ps_cur_sps->u1_num_ref_frames) &&
 (0 == ps_dec->i4_display_delay))
 {
            num_entries = 1;
 }
        num_entries = ((2 * num_entries) + 1);
 if(BASE_PROFILE_IDC != ps_dec->ps_cur_sps->u1_profile_idc)
 {
            num_entries *= 2;
 }
        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
    ps_dec->ps_cur_slice->i1_slice_alpha_c0_offset = 0;
    ps_dec->ps_cur_slice->i1_slice_beta_offset = 0;

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

 
     H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);
 
    ps_dec->u2_cur_slice_num++;
 
     /* incremented here only if first slice is inserted */
     if(ps_dec->u4_first_slice_in_pic != 0)
         ps_dec->ps_parse_cur_slice++;
 
     ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
     ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Camera2Client::setPreviewTarget(
 const sp<IGraphicBufferProducer>& bufferProducer) {
    ATRACE_CALL();
    ALOGV("%s: E", __FUNCTION__);
 Mutex::Autolock icl(mBinderSerializationLock);
 status_t res;
 if ( (res = checkPid(__FUNCTION__) ) != OK) return res;

    sp<IBinder> binder;
    sp<ANativeWindow> window;
 if (bufferProducer != 0) {
        binder = bufferProducer->asBinder();
        window = new Surface(bufferProducer, /*controlledByApp*/ true);
 }
 return setPreviewWindowL(binder, window);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::fragmentedRead(
 MediaBuffer **out, const ReadOptions *options) {

    ALOGV("MPEG4Source::fragmentedRead");

    CHECK(mStarted);

 *out = NULL;

 int64_t targetSampleTimeUs = -1;

 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if (options && options->getSeekTo(&seekTimeUs, &mode)) {

 int numSidxEntries = mSegments.size();
 if (numSidxEntries != 0) {
 int64_t totalTime = 0;
 off64_t totalOffset = mFirstMoofOffset;
 for (int i = 0; i < numSidxEntries; i++) {
 const SidxEntry *se = &mSegments[i];
 if (totalTime + se->mDurationUs > seekTimeUs) {
 if ((mode == ReadOptions::SEEK_NEXT_SYNC && seekTimeUs > totalTime) ||
 (mode == ReadOptions::SEEK_CLOSEST_SYNC &&
 (seekTimeUs - totalTime) > (totalTime + se->mDurationUs - seekTimeUs))) {
                        totalTime += se->mDurationUs;
                        totalOffset += se->mSize;
 }
 break;
 }
                totalTime += se->mDurationUs;
                totalOffset += se->mSize;
 }
            mCurrentMoofOffset = totalOffset;
            mCurrentSamples.clear();
            mCurrentSampleIndex = 0;
            parseChunk(&totalOffset);
            mCurrentTime = totalTime * mTimescale / 1000000ll;
 } else {
            mCurrentMoofOffset = mFirstMoofOffset;
            mCurrentSamples.clear();
            mCurrentSampleIndex = 0;
 off64_t tmp = mCurrentMoofOffset;
            parseChunk(&tmp);
            mCurrentTime = 0;
 }

 if (mBuffer != NULL) {
            mBuffer->release();
            mBuffer = NULL;
 }

 }

 off64_t offset = 0;
 size_t size = 0;
 uint32_t cts = 0;
 bool isSyncSample = false;
 bool newBuffer = false;
 if (mBuffer == NULL) {
        newBuffer = true;

 if (mCurrentSampleIndex >= mCurrentSamples.size()) {
 if (mNextMoofOffset <= mCurrentMoofOffset) {
 return ERROR_END_OF_STREAM;
 }
 off64_t nextMoof = mNextMoofOffset;
            mCurrentMoofOffset = nextMoof;
            mCurrentSamples.clear();
            mCurrentSampleIndex = 0;
            parseChunk(&nextMoof);
 if (mCurrentSampleIndex >= mCurrentSamples.size()) {
 return ERROR_END_OF_STREAM;
 }
 }

 const Sample *smpl = &mCurrentSamples[mCurrentSampleIndex];
        offset = smpl->offset;
        size = smpl->size;
        cts = mCurrentTime + smpl->compositionOffset;
        mCurrentTime += smpl->duration;
        isSyncSample = (mCurrentSampleIndex == 0); // XXX

 status_t err = mGroup->acquire_buffer(&mBuffer);

 if (err != OK) {
            CHECK(mBuffer == NULL);
            ALOGV("acquire_buffer returned %d", err);
 return err;
 }
 }

 const Sample *smpl = &mCurrentSamples[mCurrentSampleIndex];
 const sp<MetaData> bufmeta = mBuffer->meta_data();
    bufmeta->clear();
 if (smpl->encryptedsizes.size()) {
        bufmeta->setData(kKeyPlainSizes, 0,
                smpl->clearsizes.array(), smpl->clearsizes.size() * 4);
        bufmeta->setData(kKeyEncryptedSizes, 0,
                smpl->encryptedsizes.array(), smpl->encryptedsizes.size() * 4);
        bufmeta->setData(kKeyCryptoIV, 0, smpl->iv, 16); // use 16 or the actual size?
        bufmeta->setInt32(kKeyCryptoDefaultIVSize, mDefaultIVSize);
        bufmeta->setInt32(kKeyCryptoMode, mCryptoMode);
        bufmeta->setData(kKeyCryptoKey, 0, mCryptoKey, 16);
 }

 if ((!mIsAVC && !mIsHEVC)|| mWantsNALFragments) {
 if (newBuffer) {
 ssize_t num_bytes_read =
                mDataSource->readAt(offset, (uint8_t *)mBuffer->data(), size);

 if (num_bytes_read < (ssize_t)size) {
                mBuffer->release();
                mBuffer = NULL;

                ALOGV("i/o error");
 return ERROR_IO;
 }

            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);
            mBuffer->meta_data()->setInt64(
                    kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
            mBuffer->meta_data()->setInt64(
                    kKeyDuration, ((int64_t)smpl->duration * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
                mBuffer->meta_data()->setInt64(
                        kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
                mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;
 }

 if (!mIsAVC && !mIsHEVC) {
 *out = mBuffer;
            mBuffer = NULL;

 return OK;
 }


        CHECK(mBuffer->range_length() >= mNALLengthSize);

 const uint8_t *src =
 (const uint8_t *)mBuffer->data() + mBuffer->range_offset();

 size_t nal_size = parseNALSize(src);
 if (mBuffer->range_length() < mNALLengthSize + nal_size) {
            ALOGE("incomplete NAL unit.");

            mBuffer->release();
            mBuffer = NULL;

 return ERROR_MALFORMED;
 }

 MediaBuffer *clone = mBuffer->clone();
        CHECK(clone != NULL);
        clone->set_range(mBuffer->range_offset() + mNALLengthSize, nal_size);

        CHECK(mBuffer != NULL);
        mBuffer->set_range(
                mBuffer->range_offset() + mNALLengthSize + nal_size,
                mBuffer->range_length() - mNALLengthSize - nal_size);

 if (mBuffer->range_length() == 0) {
            mBuffer->release();
            mBuffer = NULL;
 }

 *out = clone;

 return OK;
 } else {
        ALOGV("whole NAL");
 ssize_t num_bytes_read = 0;
 int32_t drm = 0;
 bool usesDRM = (mFormat->findInt32(kKeyIsDRM, &drm) && drm != 0);
 if (usesDRM) {
            num_bytes_read =
                mDataSource->readAt(offset, (uint8_t*)mBuffer->data(), size);
 } else {
            num_bytes_read = mDataSource->readAt(offset, mSrcBuffer, size);
 }

 if (num_bytes_read < (ssize_t)size) {
            mBuffer->release();
            mBuffer = NULL;

            ALOGV("i/o error");
 return ERROR_IO;
 }

 if (usesDRM) {
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);

 } else {
 uint8_t *dstData = (uint8_t *)mBuffer->data();
 size_t srcOffset = 0;

             size_t dstOffset = 0;
 
             while (srcOffset < size) {
                bool isMalFormed = (srcOffset + mNALLengthSize > size);
                 size_t nalLength = 0;
                 if (!isMalFormed) {
                     nalLength = parseNALSize(&mSrcBuffer[srcOffset]);
                     srcOffset += mNALLengthSize;
                    isMalFormed = srcOffset + nalLength > size;
                 }
 
                 if (isMalFormed) {
                    ALOGE("Video is malformed");
                    mBuffer->release();
                    mBuffer = NULL;
 return ERROR_MALFORMED;
 }

 if (nalLength == 0) {
 continue;
 }

                CHECK(dstOffset + 4 <= mBuffer->size());

                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 1;
                memcpy(&dstData[dstOffset], &mSrcBuffer[srcOffset], nalLength);
                srcOffset += nalLength;
                dstOffset += nalLength;
 }
            CHECK_EQ(srcOffset, size);
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, dstOffset);
 }

        mBuffer->meta_data()->setInt64(
                kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
        mBuffer->meta_data()->setInt64(
                kKeyDuration, ((int64_t)smpl->duration * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
            mBuffer->meta_data()->setInt64(
                    kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
            mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;

 *out = mBuffer;
        mBuffer = NULL;

 return OK;
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  const Chapters* Segment::GetChapters() const { return m_pChapters; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t setListener(const sp<IDrmClient>& listener) {
 Parcel data, reply;
        data.writeInterfaceToken(IDrm::getInterfaceDescriptor());
        data.writeStrongBinder(IInterface::asBinder(listener));
 status_t status = remote()->transact(SET_LISTENER, data, &reply);
 if (status != OK) {
 return status;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::~InputDispatcher() {
 { // acquire lock
 AutoMutex _l(mLock);

        resetKeyRepeatLocked();
        releasePendingEventLocked();
        drainInboundQueueLocked();
 }

 while (mConnectionsByFd.size() != 0) {
        unregisterInputChannel(mConnectionsByFd.valueAt(0)->inputChannel);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::component_role_enum(OMX_IN OMX_HANDLETYPE hComp,
        OMX_OUT OMX_U8*        role,
        OMX_IN OMX_U32        index)
{
 (void) hComp;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;

 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            eRet = OMX_ErrorNoMore;
 }
 }
 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.h263",OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.h263",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 }

 else if ((!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.divx",OMX_MAX_STRINGNAME_SIZE)) ||
 (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.divx311",OMX_MAX_STRINGNAME_SIZE))) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.divx",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.avc",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mvc", OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.mvc", OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.hevc", OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.hevc", OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s", role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else if ( (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vc1",OMX_MAX_STRINGNAME_SIZE)) ||
 (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.wmv",OMX_MAX_STRINGNAME_SIZE))
 ) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.vc1",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8",OMX_MAX_STRINGNAME_SIZE)) {
 if ((0 == index) && role) {
            strlcpy((char *)role, "video_decoder.vp8",OMX_MAX_STRINGNAME_SIZE);
            DEBUG_PRINT_LOW("component_role_enum: role %s",role);
 } else {
            DEBUG_PRINT_LOW("No more roles");
            eRet = OMX_ErrorNoMore;
 }
 } else {
        DEBUG_PRINT_ERROR("ERROR:Querying Role on Unknown Component");
        eRet = OMX_ErrorInvalidComponentName;
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Display::Display() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int AgcGetParameter(preproc_effect_t *effect,
 void *pParam,
 uint32_t *pValueSize,
 void *pValue)
{
 int status = 0;
 uint32_t param = *(uint32_t *)pParam;
    t_agc_settings *pProperties = (t_agc_settings *)pValue;
    webrtc::GainControl *agc = static_cast<webrtc::GainControl *>(effect->engine);

 switch (param) {
 case AGC_PARAM_TARGET_LEVEL:
 case AGC_PARAM_COMP_GAIN:
 if (*pValueSize < sizeof(int16_t)) {
 *pValueSize = 0;
 return -EINVAL;
 }
 break;
 case AGC_PARAM_LIMITER_ENA:
 if (*pValueSize < sizeof(bool)) {
 *pValueSize = 0;
 return -EINVAL;
 }
 break;
 case AGC_PARAM_PROPERTIES:
 if (*pValueSize < sizeof(t_agc_settings)) {
 *pValueSize = 0;
 return -EINVAL;
 }
 break;

 default:
        ALOGW("AgcGetParameter() unknown param %08x", param);
        status = -EINVAL;
 break;
 }

 switch (param) {
 case AGC_PARAM_TARGET_LEVEL:
 *(int16_t *) pValue = (int16_t)(agc->target_level_dbfs() * -100);
        ALOGV("AgcGetParameter() target level %d milliBels", *(int16_t *) pValue);
 break;
 case AGC_PARAM_COMP_GAIN:
 *(int16_t *) pValue = (int16_t)(agc->compression_gain_db() * 100);
        ALOGV("AgcGetParameter() comp gain %d milliBels", *(int16_t *) pValue);
 break;
 case AGC_PARAM_LIMITER_ENA:
 *(bool *) pValue = (bool)agc->is_limiter_enabled();
        ALOGV("AgcGetParameter() limiter enabled %s",
 (*(int16_t *) pValue != 0) ? "true" : "false");
 break;
 case AGC_PARAM_PROPERTIES:
        pProperties->targetLevel = (int16_t)(agc->target_level_dbfs() * -100);
        pProperties->compGain = (int16_t)(agc->compression_gain_db() * 100);
        pProperties->limiterEnabled = (bool)agc->is_limiter_enabled();
 break;
 default:
        ALOGW("AgcGetParameter() unknown param %d", param);
        status = -EINVAL;
 break;
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectHandle::disable()
{
    ALOGV("disable %p", this);
 if (!mHasControl) {
 return INVALID_OPERATION;
 }
 if (mEffect == 0) {
 return DEAD_OBJECT;
 }

 if (!mEnabled) {
 return NO_ERROR;
 }
    mEnabled = false;

 if (mEffect->suspended()) {
 return NO_ERROR;
 }

 status_t status = mEffect->setEnabled(false);

    sp<ThreadBase> thread = mEffect->thread().promote();
 if (thread != 0) {
        thread->checkSuspendOnEffectEnabled(mEffect, false, mEffect->sessionId());
 if (thread->type() == ThreadBase::OFFLOAD) {
 PlaybackThread *t = (PlaybackThread *)thread.get();
 Mutex::Autolock _l(t->mLock);
            t->broadcast_l();
 }
 }

 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ESDS::InitCheck() const {
 return mInitCheck;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_dm_load_local_oob(void)
{
 char prop_oob[PROPERTY_VALUE_MAX];
    property_get("service.brcm.bt.oob", prop_oob, "3");
    BTIF_TRACE_DEBUG("btif_dm_load_local_oob prop_oob = %s",prop_oob);
 if (prop_oob[0] != '3')
 {
#if (BTM_OOB_INCLUDED == TRUE)
 if (oob_cb.sp_c[0] == 0 && oob_cb.sp_c[1] == 0 &&
            oob_cb.sp_c[2] == 0 && oob_cb.sp_c[3] == 0 )
 {
            BTIF_TRACE_DEBUG("btif_dm_load_local_oob: read OOB, call BTA_DmLocalOob()");
            BTA_DmLocalOob();
 }
#else
        BTIF_TRACE_ERROR("BTM_OOB_INCLUDED is FALSE!!(btif_dm_load_local_oob)");
#endif
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int uipc_close_ch_locked(tUIPC_CH_ID ch_id)
{
 int wakeup = 0;

    BTIF_TRACE_EVENT("CLOSE CHANNEL %d", ch_id);

 if (ch_id >= UIPC_CH_NUM)
 return -1;

 if (uipc_main.ch[ch_id].srvfd != UIPC_DISCONNECTED)
 {
        BTIF_TRACE_EVENT("CLOSE SERVER (FD %d)", uipc_main.ch[ch_id].srvfd);
        close(uipc_main.ch[ch_id].srvfd);
        FD_CLR(uipc_main.ch[ch_id].srvfd, &uipc_main.active_set);
        uipc_main.ch[ch_id].srvfd = UIPC_DISCONNECTED;
        wakeup = 1;
 }

 if (uipc_main.ch[ch_id].fd != UIPC_DISCONNECTED)
 {
        BTIF_TRACE_EVENT("CLOSE CONNECTION (FD %d)", uipc_main.ch[ch_id].fd);
        close(uipc_main.ch[ch_id].fd);
        FD_CLR(uipc_main.ch[ch_id].fd, &uipc_main.active_set);
        uipc_main.ch[ch_id].fd = UIPC_DISCONNECTED;
        wakeup = 1;
 }

 /* notify this connection is closed */
 if (uipc_main.ch[ch_id].cback)
        uipc_main.ch[ch_id].cback(ch_id, UIPC_CLOSE_EVT);

 /* trigger main thread update if something was updated */
 if (wakeup)
        uipc_wakeup_locked();

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_av_event_deep_copy(uint16_t event, char* p_dest, char* p_src) {
  BTIF_TRACE_DEBUG("%s", __func__);
  tBTA_AV* av_src = (tBTA_AV*)p_src;
  tBTA_AV* av_dest = (tBTA_AV*)p_dest;

  maybe_non_aligned_memcpy(av_dest, av_src, sizeof(*av_src));
 switch (event) {
 case BTA_AV_META_MSG_EVT:
 if (av_src->meta_msg.p_data && av_src->meta_msg.len) {
        av_dest->meta_msg.p_data = (uint8_t*)osi_calloc(av_src->meta_msg.len);
        memcpy(av_dest->meta_msg.p_data, av_src->meta_msg.p_data,
               av_src->meta_msg.len);
 }

 if (av_src->meta_msg.p_msg) {
        av_dest->meta_msg.p_msg = (tAVRC_MSG*)osi_calloc(sizeof(tAVRC_MSG));
        memcpy(av_dest->meta_msg.p_msg, av_src->meta_msg.p_msg,
 sizeof(tAVRC_MSG));

        tAVRC_MSG* p_msg_src = av_src->meta_msg.p_msg;
        tAVRC_MSG* p_msg_dest = av_dest->meta_msg.p_msg;

 if ((p_msg_src->hdr.opcode == AVRC_OP_VENDOR) &&
 (p_msg_src->vendor.p_vendor_data && p_msg_src->vendor.vendor_len)) {
          p_msg_dest->vendor.p_vendor_data =
 (uint8_t*)osi_calloc(p_msg_src->vendor.vendor_len);

           memcpy(p_msg_dest->vendor.p_vendor_data,
                  p_msg_src->vendor.p_vendor_data, p_msg_src->vendor.vendor_len);
         }
       }
       break;
 
 default:
 break;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int handle_getattr(struct fuse* fuse, struct fuse_handler* handler,
 const struct fuse_in_header *hdr, const struct fuse_getattr_in *req)
{
 struct node* node;
 char path[PATH_MAX];

    pthread_mutex_lock(&fuse->global->lock);
    node = lookup_node_and_path_by_id_locked(fuse, hdr->nodeid, path, sizeof(path));
    TRACE("[%d] GETATTR flags=%x fh=%"PRIx64" @ %"PRIx64" (%s)\n", handler->token,
            req->getattr_flags, req->fh, hdr->nodeid, node ? node->name : "?");
    pthread_mutex_unlock(&fuse->global->lock);

 if (!node) {
 return -ENOENT;
 }
 if (!check_caller_access_to_node(fuse, hdr, node, R_OK)) {
 return -EACCES;
 }

 return fuse_reply_attr(fuse, hdr->unique, node, path);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::removeActiveBuffer(
        OMX_U32 portIndex, OMX::buffer_id id) {
 for (size_t i = 0; i < mActiveBuffers.size(); ++i) {
 if (mActiveBuffers[i].mPortIndex == portIndex
 && mActiveBuffers[i].mID == id) {
            mActiveBuffers.removeItemsAt(i);

 if (portIndex < NELEM(mNumPortBuffers)) {
 --mNumPortBuffers[portIndex];
 }
 return;
 }
 }

     CLOGW("Attempt to remove an active buffer [%#x] we know nothing about...", id);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int LvmBundle_init(EffectContext *pContext){
 int status;

    ALOGV("\tLvmBundle_init start");

    pContext->config.inputCfg.accessMode                    = EFFECT_BUFFER_ACCESS_READ;
    pContext->config.inputCfg.channels                      = AUDIO_CHANNEL_OUT_STEREO;
    pContext->config.inputCfg.format                        = AUDIO_FORMAT_PCM_16_BIT;
    pContext->config.inputCfg.samplingRate                  = 44100;
    pContext->config.inputCfg.bufferProvider.getBuffer      = NULL;
    pContext->config.inputCfg.bufferProvider.releaseBuffer  = NULL;
    pContext->config.inputCfg.bufferProvider.cookie         = NULL;
    pContext->config.inputCfg.mask                          = EFFECT_CONFIG_ALL;
    pContext->config.outputCfg.accessMode                   = EFFECT_BUFFER_ACCESS_ACCUMULATE;
    pContext->config.outputCfg.channels                     = AUDIO_CHANNEL_OUT_STEREO;
    pContext->config.outputCfg.format                       = AUDIO_FORMAT_PCM_16_BIT;
    pContext->config.outputCfg.samplingRate                 = 44100;
    pContext->config.outputCfg.bufferProvider.getBuffer     = NULL;
    pContext->config.outputCfg.bufferProvider.releaseBuffer = NULL;
    pContext->config.outputCfg.bufferProvider.cookie        = NULL;
    pContext->config.outputCfg.mask                         = EFFECT_CONFIG_ALL;

    CHECK_ARG(pContext != NULL);

 if (pContext->pBundledContext->hInstance != NULL){
        ALOGV("\tLvmBundle_init pContext->pBassBoost != NULL "
 "-> Calling pContext->pBassBoost->free()");

 LvmEffect_free(pContext);

        ALOGV("\tLvmBundle_init pContext->pBassBoost != NULL "
 "-> Called pContext->pBassBoost->free()");
 }

    LVM_ReturnStatus_en     LvmStatus=LVM_SUCCESS; /* Function call status */
 LVM_ControlParams_t     params; /* Control Parameters */
 LVM_InstParams_t InstParams; /* Instance parameters */
 LVM_EQNB_BandDef_t BandDefs[MAX_NUM_BANDS]; /* Equaliser band definitions */
 LVM_HeadroomParams_t HeadroomParams; /* Headroom parameters */
 LVM_HeadroomBandDef_t HeadroomBandDef[LVM_HEADROOM_MAX_NBANDS];
 LVM_MemTab_t MemTab; /* Memory allocation table */
 bool                    bMallocFailure = LVM_FALSE;

 /* Set the capabilities */
 InstParams.BufferMode = LVM_UNMANAGED_BUFFERS;
 InstParams.MaxBlockSize = MAX_CALL_SIZE;
 InstParams.EQNB_NumBands    = MAX_NUM_BANDS;
 InstParams.PSA_Included     = LVM_PSA_ON;

 /* Allocate memory, forcing alignment */
 LvmStatus = LVM_GetMemoryTable(LVM_NULL,
 &MemTab,
 &InstParams);

    LVM_ERROR_CHECK(LvmStatus, "LVM_GetMemoryTable", "LvmBundle_init")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

    ALOGV("\tCreateInstance Succesfully called LVM_GetMemoryTable\n");

 /* Allocate memory */
 for (int i=0; i<LVM_NR_MEMORY_REGIONS; i++){
 if (MemTab.Region[i].Size != 0){
 MemTab.Region[i].pBaseAddress = malloc(MemTab.Region[i].Size);

 if (MemTab.Region[i].pBaseAddress == LVM_NULL){
                ALOGV("\tLVM_ERROR :LvmBundle_init CreateInstance Failed to allocate %" PRIu32
 " bytes for region %u\n", MemTab.Region[i].Size, i );
                bMallocFailure = LVM_TRUE;
 }else{
                ALOGV("\tLvmBundle_init CreateInstance allocated %" PRIu32
 " bytes for region %u at %p\n",
 MemTab.Region[i].Size, i, MemTab.Region[i].pBaseAddress);
 }
 }
 }

 /* If one or more of the memory regions failed to allocate, free the regions that were
     * succesfully allocated and return with an error
     */
 if(bMallocFailure == LVM_TRUE){
 for (int i=0; i<LVM_NR_MEMORY_REGIONS; i++){
 if (MemTab.Region[i].pBaseAddress == LVM_NULL){
                ALOGV("\tLVM_ERROR :LvmBundle_init CreateInstance Failed to allocate %" PRIu32
 " bytes for region %u Not freeing\n", MemTab.Region[i].Size, i );
 }else{
                ALOGV("\tLVM_ERROR :LvmBundle_init CreateInstance Failed: but allocated %" PRIu32
 " bytes for region %u at %p- free\n",
 MemTab.Region[i].Size, i, MemTab.Region[i].pBaseAddress);
                free(MemTab.Region[i].pBaseAddress);
 }
 }
 return -EINVAL;
 }
    ALOGV("\tLvmBundle_init CreateInstance Succesfully malloc'd memory\n");

 /* Initialise */
    pContext->pBundledContext->hInstance = LVM_NULL;

 /* Init sets the instance handle */
 LvmStatus = LVM_GetInstanceHandle(&pContext->pBundledContext->hInstance,
 &MemTab,
 &InstParams);

    LVM_ERROR_CHECK(LvmStatus, "LVM_GetInstanceHandle", "LvmBundle_init")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

    ALOGV("\tLvmBundle_init CreateInstance Succesfully called LVM_GetInstanceHandle\n");

 /* Set the initial process parameters */
 /* General parameters */
    params.OperatingMode = LVM_MODE_ON;
    params.SampleRate = LVM_FS_44100;
    params.SourceFormat = LVM_STEREO;
    params.SpeakerType = LVM_HEADPHONES;

    pContext->pBundledContext->SampleRate = LVM_FS_44100;

 /* Concert Sound parameters */
    params.VirtualizerOperatingMode = LVM_MODE_OFF;
    params.VirtualizerType = LVM_CONCERTSOUND;
    params.VirtualizerReverbLevel = 100;
    params.CS_EffectLevel             = LVM_CS_EFFECT_NONE;

 /* N-Band Equaliser parameters */
    params.EQNB_OperatingMode     = LVM_EQNB_OFF;
    params.EQNB_NBands            = FIVEBAND_NUMBANDS;
    params.pEQNB_BandDefinition   = &BandDefs[0];

 for (int i=0; i<FIVEBAND_NUMBANDS; i++)
 {
 BandDefs[i].Frequency = EQNB_5BandPresetsFrequencies[i];
 BandDefs[i].QFactor = EQNB_5BandPresetsQFactors[i];
 BandDefs[i].Gain = EQNB_5BandSoftPresets[i];
 }

 /* Volume Control parameters */
    params.VC_EffectLevel         = 0;
    params.VC_Balance             = 0;

 /* Treble Enhancement parameters */
    params.TE_OperatingMode       = LVM_TE_OFF;
    params.TE_EffectLevel         = 0;

 /* PSA Control parameters */
    params.PSA_Enable             = LVM_PSA_OFF;
    params.PSA_PeakDecayRate      = (LVM_PSA_DecaySpeed_en)0;

 /* Bass Enhancement parameters */
    params.BE_OperatingMode       = LVM_BE_OFF;
    params.BE_EffectLevel         = 0;
    params.BE_CentreFreq          = LVM_BE_CENTRE_90Hz;
    params.BE_HPF                 = LVM_BE_HPF_ON;

 /* PSA Control parameters */
    params.PSA_Enable             = LVM_PSA_OFF;
    params.PSA_PeakDecayRate      = LVM_PSA_SPEED_MEDIUM;

 /* TE Control parameters */
    params.TE_OperatingMode       = LVM_TE_OFF;
    params.TE_EffectLevel         = 0;

 /* Activate the initial settings */
 LvmStatus = LVM_SetControlParameters(pContext->pBundledContext->hInstance,
 &params);

    LVM_ERROR_CHECK(LvmStatus, "LVM_SetControlParameters", "LvmBundle_init")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

    ALOGV("\tLvmBundle_init CreateInstance Succesfully called LVM_SetControlParameters\n");

 /* Set the headroom parameters */
 HeadroomBandDef[0].Limit_Low = 20;
 HeadroomBandDef[0].Limit_High = 4999;
 HeadroomBandDef[0].Headroom_Offset = 0;
 HeadroomBandDef[1].Limit_Low = 5000;
 HeadroomBandDef[1].Limit_High = 24000;
 HeadroomBandDef[1].Headroom_Offset = 0;
 HeadroomParams.pHeadroomDefinition    = &HeadroomBandDef[0];
 HeadroomParams.Headroom_OperatingMode = LVM_HEADROOM_ON;
 HeadroomParams.NHeadroomBands = 2;

 LvmStatus = LVM_SetHeadroomParams(pContext->pBundledContext->hInstance,
 &HeadroomParams);

    LVM_ERROR_CHECK(LvmStatus, "LVM_SetHeadroomParams", "LvmBundle_init")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

    ALOGV("\tLvmBundle_init CreateInstance Succesfully called LVM_SetHeadroomParams\n");
    ALOGV("\tLvmBundle_init End");
 return 0;
} /* end LvmBundle_init */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: long Block::Frame::Read(IMkvReader* pReader, unsigned char* buf) const {
  assert(pReader);
  assert(buf);

 const long status = pReader->Read(pos, len, buf);
 return status;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static inline size_t utf8_codepoint_len(uint8_t ch)
{
 return ((0xe5000000 >> ((ch >> 3) & 0x1e)) & 3) + 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void local_socket_close_locked(asocket* s) {
    D("entered local_socket_close_locked. LS(%d) fd=%d", s->id, s->fd);
     if (s->peer) {
         D("LS(%d): closing peer. peer->id=%d peer->fd=%d", s->id, s->peer->id, s->peer->fd);
         /* Note: it's important to call shutdown before disconnecting from
         * the peer, this ensures that remote sockets can still get the id
         * of the local socket they're connected to, to send a CLOSE()
         * protocol event. */

         if (s->peer->shutdown) {
             s->peer->shutdown(s->peer);
         }
        s->peer->peer = 0;
        if (s->peer->close == local_socket_close) {
            local_socket_close_locked(s->peer);
        } else {
            s->peer->close(s->peer);
        }
        s->peer = 0;
     }
 
     /* If we are already closing, or if there are no
    ** pending packets, destroy immediately
    */
 if (s->closing || s->has_write_error || s->pkt_first == NULL) {
 int id = s->id;
        local_socket_destroy(s);
        D("LS(%d): closed", id);
 return;
 }

 /* otherwise, put on the closing list
    */
    D("LS(%d): closing", s->id);
    s->closing = 1;
    fdevent_del(&s->fde, FDE_READ);
    remove_socket(s);
    D("LS(%d): put on socket_closing_list fd=%d", s->id, s->fd);
    insert_local_socket(s, &local_socket_closing_list);
    CHECK_EQ(FDE_WRITE, s->fde.state & FDE_WRITE);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int btpan_tap_open()
{
 struct ifreq ifr;
 int fd, err;
 const char *clonedev = "/dev/tun";

 
     /* open the clone device */
 
    if ((fd = open(clonedev, O_RDWR)) < 0)
     {
         BTIF_TRACE_DEBUG("could not open %s, err:%d", clonedev, errno);
         return fd;
 }

    memset(&ifr, 0, sizeof(ifr));
    ifr.ifr_flags = IFF_TAP | IFF_NO_PI;


     strncpy(ifr.ifr_name, TAP_IF_NAME, IFNAMSIZ);
 
     /* try to create the device */
    if ((err = ioctl(fd, TUNSETIFF, (void *) &ifr)) < 0)
     {
         BTIF_TRACE_DEBUG("ioctl error:%d, errno:%s", err, strerror(errno));
         close(fd);
 return err;

     }
     if (tap_if_up(TAP_IF_NAME, controller_get_interface()->get_address()) == 0)
     {
        int flags = fcntl(fd, F_GETFL, 0);
        fcntl(fd, F_SETFL, flags | O_NONBLOCK);
         return fd;
     }
     BTIF_TRACE_ERROR("can not bring up tap interface:%s", TAP_IF_NAME);
    close(fd);
 return INVALID_FD;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::empty_this_buffer_proxy(OMX_IN OMX_HANDLETYPE  hComp,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
 (void) hComp;
 int push_cnt = 0,i=0;
 unsigned nPortIndex = 0;
    OMX_ERRORTYPE ret = OMX_ErrorNone;
 struct vdec_input_frameinfo frameinfo;
 struct vdec_bufferpayload *temp_buffer;
 struct vdec_seqheader seq_header;
 bool port_setting_changed = true;

 /*Should we generate a Aync error event*/
 if (buffer == NULL || buffer->pInputPortPrivate == NULL) {
        DEBUG_PRINT_ERROR("ERROR:empty_this_buffer_proxy is invalid");
 return OMX_ErrorBadParameter;
 }

    nPortIndex = buffer-((OMX_BUFFERHEADERTYPE *)m_inp_mem_ptr);

 if (nPortIndex > drv_ctx.ip_buf.actualcount) {
        DEBUG_PRINT_ERROR("ERROR:empty_this_buffer_proxy invalid nPortIndex[%u]",
                nPortIndex);
 return OMX_ErrorBadParameter;
 }

    pending_input_buffers++;

 /* return zero length and not an EOS buffer */
 if (!arbitrary_bytes && (buffer->nFilledLen == 0) &&
 ((buffer->nFlags & OMX_BUFFERFLAG_EOS) == 0)) {
        DEBUG_PRINT_HIGH("return zero legth buffer");
        post_event ((unsigned long)buffer,VDEC_S_SUCCESS,
                OMX_COMPONENT_GENERATE_EBD);
 return OMX_ErrorNone;
 }

 if (input_flush_progress == true) {
        DEBUG_PRINT_LOW("Flush in progress return buffer ");
        post_event ((unsigned long)buffer,VDEC_S_SUCCESS,
                OMX_COMPONENT_GENERATE_EBD);

         return OMX_ErrorNone;
     }
 
     temp_buffer = (struct vdec_bufferpayload *)buffer->pInputPortPrivate;
 
    if ((temp_buffer -  drv_ctx.ptr_inputbuffer) > (int)drv_ctx.ip_buf.actualcount) {
         return OMX_ErrorBadParameter;
     }
     /* If its first frame, H264 codec and reject is true, then parse the nal
       and get the profile. Based on this, reject the clip playback */
 if (first_frame == 0 && codec_type_parse == CODEC_TYPE_H264 &&
            m_reject_avc_1080p_mp) {
        first_frame = 1;
        DEBUG_PRINT_ERROR("Parse nal to get the profile");
        h264_parser->parse_nal((OMX_U8*)buffer->pBuffer, buffer->nFilledLen,
                NALU_TYPE_SPS);
        m_profile = h264_parser->get_profile();
        ret = is_video_session_supported();
 if (ret) {
            post_event ((unsigned long)buffer,VDEC_S_SUCCESS,OMX_COMPONENT_GENERATE_EBD);
            post_event(OMX_EventError, OMX_ErrorInvalidState,OMX_COMPONENT_GENERATE_EVENT);
 /* Move the state to Invalid to avoid queueing of pending ETB to the driver */
            m_state = OMX_StateInvalid;
 return OMX_ErrorNone;
 }
 }

    DEBUG_PRINT_LOW("ETBProxy: bufhdr = %p, bufhdr->pBuffer = %p", buffer, buffer->pBuffer);

     /*for use buffer we need to memcpy the data*/
     temp_buffer->buffer_len = buffer->nFilledLen;
 
    if (input_use_buffer) {
         if (buffer->nFilledLen <= temp_buffer->buffer_len) {
             if (arbitrary_bytes) {
                 memcpy (temp_buffer->bufferaddr, (buffer->pBuffer + buffer->nOffset),buffer->nFilledLen);
 } else {
                memcpy (temp_buffer->bufferaddr, (m_inp_heap_ptr[nPortIndex].pBuffer + m_inp_heap_ptr[nPortIndex].nOffset),
                        buffer->nFilledLen);
 }
 } else {
 return OMX_ErrorBadParameter;
 }

 }

    frameinfo.bufferaddr = temp_buffer->bufferaddr;
    frameinfo.client_data = (void *) buffer;
    frameinfo.datalen = temp_buffer->buffer_len;
    frameinfo.flags = 0;
    frameinfo.offset = buffer->nOffset;
    frameinfo.pmem_fd = temp_buffer->pmem_fd;
    frameinfo.pmem_offset = temp_buffer->offset;
    frameinfo.timestamp = buffer->nTimeStamp;
 if (drv_ctx.disable_dmx && m_desc_buffer_ptr && m_desc_buffer_ptr[nPortIndex].buf_addr) {
        DEBUG_PRINT_LOW("ETB: dmx enabled");
 if (m_demux_entries == 0) {
            extract_demux_addr_offsets(buffer);
 }

        DEBUG_PRINT_LOW("ETB: handle_demux_data - entries=%u",(unsigned int)m_demux_entries);
        handle_demux_data(buffer);
        frameinfo.desc_addr = (OMX_U8 *)m_desc_buffer_ptr[nPortIndex].buf_addr;
        frameinfo.desc_size = m_desc_buffer_ptr[nPortIndex].desc_data_size;
 } else {
        frameinfo.desc_addr = NULL;
        frameinfo.desc_size = 0;
 }
 if (!arbitrary_bytes) {
        frameinfo.flags |= buffer->nFlags;
 }

#ifdef _ANDROID_
 if (m_debug_timestamp) {
 if (arbitrary_bytes) {
            DEBUG_PRINT_LOW("Inserting TIMESTAMP (%lld) into queue", buffer->nTimeStamp);
            m_timestamp_list.insert_ts(buffer->nTimeStamp);
 } else if (!arbitrary_bytes && !(buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG)) {
            DEBUG_PRINT_LOW("Inserting TIMESTAMP (%lld) into queue", buffer->nTimeStamp);
            m_timestamp_list.insert_ts(buffer->nTimeStamp);
 }
 }
#endif

log_input_buffers((const char *)temp_buffer->bufferaddr, temp_buffer->buffer_len);

 if (buffer->nFlags & QOMX_VIDEO_BUFFERFLAG_EOSEQ) {
        frameinfo.flags |= QOMX_VIDEO_BUFFERFLAG_EOSEQ;
        buffer->nFlags &= ~QOMX_VIDEO_BUFFERFLAG_EOSEQ;
 }

 if (temp_buffer->buffer_len == 0 || (buffer->nFlags & OMX_BUFFERFLAG_EOS)) {
        DEBUG_PRINT_HIGH("Rxd i/p EOS, Notify Driver that EOS has been reached");
        frameinfo.flags |= VDEC_BUFFERFLAG_EOS;
        h264_scratch.nFilledLen = 0;
        nal_count = 0;
        look_ahead_nal = false;
        frame_count = 0;
 if (m_frame_parser.mutils)
            m_frame_parser.mutils->initialize_frame_checking_environment();
        m_frame_parser.flush();
        h264_last_au_ts = LLONG_MAX;
        h264_last_au_flags = 0;
        memset(m_demux_offsets, 0, ( sizeof(OMX_U32) * 8192) );
        m_demux_entries = 0;
 }
 struct v4l2_buffer buf;
 struct v4l2_plane plane;
    memset( (void *)&buf, 0, sizeof(buf));
    memset( (void *)&plane, 0, sizeof(plane));
 int rc;
 unsigned long  print_count;
 if (temp_buffer->buffer_len == 0 || (buffer->nFlags & OMX_BUFFERFLAG_EOS)) {
        buf.flags = V4L2_QCOM_BUF_FLAG_EOS;
        DEBUG_PRINT_HIGH("INPUT EOS reached") ;
 }
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
    buf.index = nPortIndex;
    buf.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
    buf.memory = V4L2_MEMORY_USERPTR;
    plane.bytesused = temp_buffer->buffer_len;
    plane.length = drv_ctx.ip_buf.buffer_size;
    plane.m.userptr = (unsigned long)temp_buffer->bufferaddr -
 (unsigned long)temp_buffer->offset;
    plane.reserved[0] = temp_buffer->pmem_fd;
    plane.reserved[1] = temp_buffer->offset;
    plane.data_offset = 0;
    buf.m.planes = &plane;
    buf.length = 1;
 if (frameinfo.timestamp >= LLONG_MAX) {
        buf.flags |= V4L2_QCOM_BUF_TIMESTAMP_INVALID;
 }
    buf.timestamp.tv_sec = frameinfo.timestamp / 1000000;
    buf.timestamp.tv_usec = (frameinfo.timestamp % 1000000);
    buf.flags |= (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG) ? V4L2_QCOM_BUF_FLAG_CODECCONFIG: 0;
    buf.flags |= (buffer->nFlags & OMX_BUFFERFLAG_DECODEONLY) ? V4L2_QCOM_BUF_FLAG_DECODEONLY: 0;

 if (buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
        DEBUG_PRINT_LOW("Increment codec_config buffer counter");
        android_atomic_inc(&m_queued_codec_config_count);
 }

    rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_QBUF, &buf);
 if (rc) {
        DEBUG_PRINT_ERROR("Failed to qbuf Input buffer to driver");
 return OMX_ErrorHardware;
 }

 if (codec_config_flag && !(buffer->nFlags & OMX_BUFFERFLAG_CODECCONFIG)) {
        codec_config_flag = false;
 }
 if (!streaming[OUTPUT_PORT]) {
 enum v4l2_buf_type buf_type;
 int ret,r;

        buf_type=V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
        DEBUG_PRINT_LOW("send_command_proxy(): Idle-->Executing");
        ret=ioctl(drv_ctx.video_driver_fd, VIDIOC_STREAMON,&buf_type);
 if (!ret) {
            DEBUG_PRINT_HIGH("Streamon on OUTPUT Plane was successful");
            streaming[OUTPUT_PORT] = true;
 } else if (errno == EBUSY) {
            DEBUG_PRINT_ERROR("Failed to call stream on OUTPUT due to HW_OVERLOAD");
            post_event ((unsigned long)buffer, VDEC_S_SUCCESS,
                    OMX_COMPONENT_GENERATE_EBD);
 return OMX_ErrorInsufficientResources;
 } else {
            DEBUG_PRINT_ERROR("Failed to call streamon on OUTPUT");
            DEBUG_PRINT_LOW("If Stream on failed no buffer should be queued");
            post_event ((unsigned long)buffer,VDEC_S_SUCCESS,
                    OMX_COMPONENT_GENERATE_EBD);
 return OMX_ErrorBadParameter;
 }
 }
    DEBUG_PRINT_LOW("[ETBP] pBuf(%p) nTS(%lld) Sz(%u)",
            frameinfo.bufferaddr, (long long)frameinfo.timestamp,
 (unsigned int)frameinfo.datalen);

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void MediaPlayerService::Client::disconnectNativeWindow() {
 if (mConnectedWindow != NULL) {
 status_t err = native_window_api_disconnect(mConnectedWindow.get(),
                NATIVE_WINDOW_API_MEDIA);

 if (err != OK) {
            ALOGW("native_window_api_disconnect returned an error: %s (%d)",
                    strerror(-err), err);
 }
 }
    mConnectedWindow.clear();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_send_confirm(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);
  smp_send_cmd(SMP_OPCODE_CONFIRM, p_cb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t ctrl_set_skip_loop_filter(vpx_codec_alg_priv_t *ctx,
                                                 va_list args) {
  ctx->skip_loop_filter = va_arg(args, int);

 if (ctx->frame_workers) {
 VPxWorker *const worker = ctx->frame_workers;
 FrameWorkerData *const frame_worker_data = (FrameWorkerData *)worker->data1;
    frame_worker_data->pbi->common.skip_loop_filter = ctx->skip_loop_filter;
 }

 return VPX_CODEC_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_dm_pin_reply( const bt_bdaddr_t *bd_addr, uint8_t accept,
 uint8_t pin_len, bt_pin_code_t *pin_code)
{
    BTIF_TRACE_EVENT("%s: accept=%d", __FUNCTION__, accept);
 if (pin_code == NULL || pin_len > PIN_CODE_LEN)
 return BT_STATUS_FAIL;
#if (defined(BLE_INCLUDED) && (BLE_INCLUDED == TRUE))

 if (pairing_cb.is_le_only)
 {
 int i;
        UINT32 passkey = 0;
 int multi[] = {100000, 10000, 1000, 100, 10,1};
        BD_ADDR remote_bd_addr;
        bdcpy(remote_bd_addr, bd_addr->address);
 for (i = 0; i < 6; i++)
 {
            passkey += (multi[i] * (pin_code->pin[i] - '0'));
 }
        BTIF_TRACE_DEBUG("btif_dm_pin_reply: passkey: %d", passkey);
        BTA_DmBlePasskeyReply(remote_bd_addr, accept, passkey);

 }
 else
 {
        BTA_DmPinReply( (UINT8 *)bd_addr->address, accept, pin_len, pin_code->pin);
 if (accept)
            pairing_cb.pin_code_len = pin_len;
 }
#else
    BTA_DmPinReply( (UINT8 *)bd_addr->address, accept, pin_len, pin_code->pin);

 if (accept)
        pairing_cb.pin_code_len = pin_len;
#endif
 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: AudioTrack::AudioTrack(
    Segment* pSegment,
    long long element_start,
    long long element_size) :
    Track(pSegment, element_start, element_size)
{
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  AudioTrack::AudioTrack(Segment* pSegment, long long element_start,
 long long element_size)
 : Track(pSegment, element_start, element_size) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::commandStartSmoothZoomL() {
    ALOGE("%s: Unimplemented!", __FUNCTION__);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 using namespace android;
 if (!strcmp(name, "OMX.google.h263.decoder")) {
 return new android::SoftMPEG4(
                name, "video_decoder.h263", OMX_VIDEO_CodingH263,
                kH263ProfileLevels, ARRAY_SIZE(kH263ProfileLevels),
                callbacks, appData, component);
 } else if (!strcmp(name, "OMX.google.mpeg4.decoder")) {
 return new android::SoftMPEG4(
                name, "video_decoder.mpeg4", OMX_VIDEO_CodingMPEG4,
                kM4VProfileLevels, ARRAY_SIZE(kM4VProfileLevels),
                callbacks, appData, component);
 } else {
        CHECK(!"Unknown component");
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OggExtractor::OggExtractor(const sp<DataSource> &source)
 : mDataSource(source),
      mInitCheck(NO_INIT),
      mImpl(NULL) {
 for (int i = 0; i < 2; ++i) {
 if (mImpl != NULL) {
 delete mImpl;
 }
 if (i == 0) {
            mImpl = new MyVorbisExtractor(mDataSource);
 } else {
            mImpl = new MyOpusExtractor(mDataSource);
 }
        mInitCheck = mImpl->seekToOffset(0);

 if (mInitCheck == OK) {
            mInitCheck = mImpl->init();
 if (mInitCheck == OK) {
 break;
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::allocateSpi(const XfrmSaInfo& record, uint32_t minSpi,
 uint32_t maxSpi, uint32_t* outSpi,
 const XfrmSocket& sock) {
    xfrm_userspi_info spiInfo{};

 enum { NLMSG_HDR, USERSAID, USERSAID_PAD };

    std::vector<iovec> iov = {
 {NULL, 0}, // reserved for the eventual addition of a NLMSG_HDR
 {&spiInfo, 0}, // main userspi_info struct
 {kPadBytes, 0}, // up to NLMSG_ALIGNTO pad bytes of padding
 };

 int len;
 if (fillUserSaInfo(record, &spiInfo.info) == 0) {
        ALOGE("Failed to fill transport SA Info");
 }

    len = iov[USERSAID].iov_len = sizeof(spiInfo);
    iov[USERSAID_PAD].iov_len = NLMSG_ALIGN(len) - len;

 RandomSpi spiGen = RandomSpi(minSpi, maxSpi);
 int spi;
    netdutils::Status ret;
 while ((spi = spiGen.next()) != INVALID_SPI) {
        spiInfo.min = spi;
        spiInfo.max = spi;
        ret = sock.sendMessage(XFRM_MSG_ALLOCSPI, NETLINK_REQUEST_FLAGS, 0, &iov);

 /* If the SPI is in use, we'll get ENOENT */
 if (netdutils::equalToErrno(ret, ENOENT))
 continue;

 if (isOk(ret)) {
 *outSpi = spi;
            ALOGD("Allocated an SPI: %x", *outSpi);
 } else {
 *outSpi = INVALID_SPI;
            ALOGE("SPI Allocation Failed with error %d", ret.code());
 }

 return ret;
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void FromColor_D4444_Raw(void* dst, const SkColor src[], int width,
 int x, int y) {
 SkPMColor16* d = (SkPMColor16*)dst;

    DITHER_4444_SCAN(y);
 for (int stop = x + width; x < stop; x++) {
 SkColor c = *src++;

 SkPMColor pmc = SkPackARGB32NoCheck(SkColorGetA(c), SkColorGetR(c),
 SkColorGetG(c), SkColorGetB(c));
 *d++ = SkDitherARGB32To4444(pmc, DITHER_VALUE(x));
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Block::Block(long long start, long long size_, long long discard_padding)
 : m_start(start),
      m_size(size_),
      m_track(0),
      m_timecode(-1),
      m_flags(0),
      m_frames(NULL),
      m_frame_count(-1),
      m_discard_padding(discard_padding) {}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: Track::Info::Info():
    uid(0),
    defaultDuration(0),
    codecDelay(0),
    seekPreRoll(0),
    nameAsUTF8(NULL),
    language(NULL),
    codecId(NULL),
    codecNameAsUTF8(NULL),
    codecPrivate(NULL),
    codecPrivateSize(0),
    lacing(false)
{
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::setDataSource(int fd, int64_t offset, int64_t length)

 {
     ALOGV("setDataSource(%d, %" PRId64 ", %" PRId64 ")", fd, offset, length);
     status_t err = UNKNOWN_ERROR;
    const sp<IMediaPlayerService>& service(getMediaPlayerService());
     if (service != 0) {
         sp<IMediaPlayer> player(service->create(this, mAudioSessionId));
         if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
 (NO_ERROR != player->setDataSource(fd, offset, length))) {
            player.clear();
 }
        err = attachNewPlayer(player);
 }
 return err;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: template<typename Type> Type* SafeArrayAlloc(unsigned long long num_elements,
 unsigned long long element_size) {
 if (num_elements == 0 || element_size == 0)
 return NULL;

 const size_t kMaxAllocSize = 0x80000000; // 2GiB
 const unsigned long long num_bytes = num_elements * element_size;
 if (element_size > (kMaxAllocSize / num_elements))
 return NULL;

 return new (std::nothrow) Type[num_bytes];
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ASessionDescription::getFormatType(
 size_t index, unsigned long *PT,
 AString *desc, AString *params) const {
 AString format;
    getFormat(index, &format);

 const char *lastSpacePos = strrchr(format.c_str(), ' ');
    CHECK(lastSpacePos != NULL);

 char *end;
 unsigned long x = strtoul(lastSpacePos + 1, &end, 10);
    CHECK_GT(end, lastSpacePos + 1);
    CHECK_EQ(*end, '\0');

 
     *PT = x;
 
    char key[20];
    sprintf(key, "a=rtpmap:%lu", x);
 
     CHECK(findAttribute(index, key, desc));
 
    sprintf(key, "a=fmtp:%lu", x);
     if (!findAttribute(index, key, params)) {
         params->clear();
     }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: xmlParseAttribute2(xmlParserCtxtPtr ctxt,
 const xmlChar * pref, const xmlChar * elem,
 const xmlChar ** prefix, xmlChar ** value,
 int *len, int *alloc)
{
 const xmlChar *name;
    xmlChar *val, *internal_val = NULL;
 int normalize = 0;

 *value = NULL;
    GROW;
    name = xmlParseQName(ctxt, prefix);
 if (name == NULL) {
        xmlFatalErrMsg(ctxt, XML_ERR_NAME_REQUIRED,
 "error parsing attribute name\n");
 return (NULL);
 }

 /*
     * get the type if needed
     */
 if (ctxt->attsSpecial != NULL) {
 int type;

        type = (int) (long) xmlHashQLookup2(ctxt->attsSpecial,
                                            pref, elem, *prefix, name);
 if (type != 0)
            normalize = 1;
 }

 /*
     * read the value
     */
    SKIP_BLANKS;
 if (RAW == '=') {
        NEXT;
        SKIP_BLANKS;
        val = xmlParseAttValueInternal(ctxt, len, alloc, normalize);
 if (normalize) {
 /*
	     * Sometimes a second normalisation pass for spaces is needed
	     * but that only happens if charrefs or entities refernces
	     * have been used in the attribute value, i.e. the attribute
	     * value have been extracted in an allocated string already.
	     */
 if (*alloc) {
 const xmlChar *val2;

	        val2 = xmlAttrNormalizeSpace2(ctxt, val, len);
 if ((val2 != NULL) && (val2 != val)) {
		    xmlFree(val);
		    val = (xmlChar *) val2;
 }
 }
 }
        ctxt->instate = XML_PARSER_CONTENT;
 } else {
        xmlFatalErrMsgStr(ctxt, XML_ERR_ATTRIBUTE_WITHOUT_VALUE,
 "Specification mandate value for attribute %s\n",
                          name);
 return (NULL);
 }

 if (*prefix == ctxt->str_xml) {
 /*
         * Check that xml:lang conforms to the specification
         * No more registered as an error, just generate a warning now
         * since this was deprecated in XML second edition
         */
 if ((ctxt->pedantic) && (xmlStrEqual(name, BAD_CAST "lang"))) {
            internal_val = xmlStrndup(val, *len);
 if (!xmlCheckLanguageID(internal_val)) {
                xmlWarningMsg(ctxt, XML_WAR_LANG_VALUE,
 "Malformed value for xml:lang : %s\n",
                              internal_val, NULL);
 }
 }

 /*
         * Check that xml:space conforms to the specification
         */
 if (xmlStrEqual(name, BAD_CAST "space")) {
            internal_val = xmlStrndup(val, *len);
 if (xmlStrEqual(internal_val, BAD_CAST "default"))
 *(ctxt->space) = 0;
 else if (xmlStrEqual(internal_val, BAD_CAST "preserve"))
 *(ctxt->space) = 1;
 else {
                xmlWarningMsg(ctxt, XML_WAR_SPACE_VALUE,
 "Invalid value \"%s\" for xml:space : \"default\" or \"preserve\" expected\n",
                              internal_val, NULL);
 }
 }
 if (internal_val) {
            xmlFree(internal_val);
 }
 }

 *value = val;
 return (name);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int set_name(int argc, char **argv) {
 if (argc != 1) {
    printf("Device name not specified.\n");
 return 1;
 }

 size_t len = strlen(argv[0]);
 if (len > 247) {
    printf("Device name cannot exceed 247 bytes.\n");
 return 2;
 }

 uint8_t packet[251] = { 0x13, 0x0C, 248 };
  memcpy(&packet[3], argv[0], len + 1);

 if (!write_hci_command(HCI_PACKET_COMMAND, packet, sizeof(packet)))
 return 1;

  memset(&packet[0], sizeof(packet), 0);
  packet[0] = 0x52;
  packet[1] = 0x0C;
  packet[2] = 0xF1; // HCI command packet length.
  packet[3] = 0x01; // FEC required.
  packet[4] = len + 1;
  packet[5] = 0x09; // Device name field tag.
  memcpy(&packet[6], argv[0], len);
 return !write_hci_command(HCI_PACKET_COMMAND, packet, 0xF4);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftG711::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
 if (pcmParams->nPortIndex == 0) {
                pcmParams->ePCMMode = mIsMLaw ? OMX_AUDIO_PCMModeMULaw
 : OMX_AUDIO_PCMModeALaw;
 } else {
                pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
 }
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::ExecutingToIdleState::onOutputBufferDrained(
 const sp<AMessage> &msg) {
 BaseState::onOutputBufferDrained(msg);

    changeStateIfWeOwnAllBuffers();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectChain::addEffect_l(const sp<EffectModule>& effect)
{
 effect_descriptor_t desc = effect->desc();
 uint32_t insertPref = desc.flags & EFFECT_FLAG_INSERT_MASK;

 Mutex::Autolock _l(mLock);
    effect->setChain(this);
    sp<ThreadBase> thread = mThread.promote();
 if (thread == 0) {
 return NO_INIT;
 }
    effect->setThread(thread);

 if ((desc.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_AUXILIARY) {
        mEffects.insertAt(effect, 0);

 size_t numSamples = thread->frameCount();
 int32_t *buffer = new int32_t[numSamples];
        memset(buffer, 0, numSamples * sizeof(int32_t));
        effect->setInBuffer((int16_t *)buffer);
        effect->setOutBuffer(mInBuffer);
 } else {

 size_t size = mEffects.size();
 size_t idx_insert = size;
 ssize_t idx_insert_first = -1;
 ssize_t idx_insert_last = -1;

 for (size_t i = 0; i < size; i++) {
 effect_descriptor_t d = mEffects[i]->desc();
 uint32_t iMode = d.flags & EFFECT_FLAG_TYPE_MASK;
 uint32_t iPref = d.flags & EFFECT_FLAG_INSERT_MASK;
 if (iMode == EFFECT_FLAG_TYPE_INSERT) {
 if (insertPref == EFFECT_FLAG_INSERT_EXCLUSIVE ||
                    iPref == EFFECT_FLAG_INSERT_EXCLUSIVE) {
                    ALOGW("addEffect_l() could not insert effect %s: exclusive conflict with %s",
                            desc.name, d.name);
 return INVALID_OPERATION;
 }
 if (idx_insert == size) {
                    idx_insert = i;
 }
 if (iPref == EFFECT_FLAG_INSERT_FIRST) {
                    idx_insert_first = i;
 }
 if (iPref == EFFECT_FLAG_INSERT_LAST &&
                    idx_insert_last == -1) {
                    idx_insert_last = i;
 }
 }
 }

 if (insertPref == EFFECT_FLAG_INSERT_LAST) {
 if (idx_insert_last != -1) {
                idx_insert = idx_insert_last;
 } else {
                idx_insert = size;
 }
 } else {
 if (idx_insert_first != -1) {
                idx_insert = idx_insert_first + 1;
 }
 }

        effect->setInBuffer(mInBuffer);

 if (idx_insert == size) {
 if (idx_insert != 0) {
                mEffects[idx_insert-1]->setOutBuffer(mInBuffer);
                mEffects[idx_insert-1]->configure();
 }
            effect->setOutBuffer(mOutBuffer);
 } else {
            effect->setOutBuffer(mInBuffer);
 }
        mEffects.insertAt(effect, idx_insert);

        ALOGV("addEffect_l() effect %p, added in chain %p at rank %d", effect.get(), this,
                idx_insert);
 }
    effect->configure();
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void hexdump(const void *_data, size_t size) {
 const uint8_t *data = (const uint8_t *)_data;
 size_t offset = 0;
 while (offset < size) {
        printf("0x%04x  ", offset);

 size_t n = size - offset;
 if (n > 16) {
            n = 16;
 }

 for (size_t i = 0; i < 16; ++i) {
 if (i == 8) {
                printf(" ");
 }

 if (offset + i < size) {
                printf("%02x ", data[offset + i]);
 } else {
                printf("   ");
 }
 }

        printf(" ");

 for (size_t i = 0; i < n; ++i) {
 if (isprint(data[offset + i])) {
                printf("%c", data[offset + i]);
 } else {
                printf(".");
 }
 }

        printf("\n");

        offset += 16;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MediaPlayerService::AudioOutput::switchToNextOutput() {
    ALOGV("switchToNextOutput");

 const unsigned kMaxSwitchTries = 100;
 Mutex::Autolock lock(mLock);
 for (unsigned tries = 0;;) {
 if (mTrack == 0) {
 return;
 }
 if (mNextOutput != NULL && mNextOutput != this) {
 if (mCallbackData != NULL) {
#if 1
 CallbackData *callbackData = mCallbackData;
                mLock.unlock();
                callbackData->lock();
                mLock.lock();
 if (callbackData != mCallbackData || mNextOutput == NULL || mNextOutput == this) {
                    LOG_ALWAYS_FATAL_IF(++tries > kMaxSwitchTries,
 "switchToNextOutput() cannot obtain correct lock sequence");
                    callbackData->unlock();
 continue;
 }
                callbackData->mSwitching = true; // begin track switch
#else
 if (!mCallbackData->tryBeginTrackSwitch()) {
                    LOG_ALWAYS_FATAL_IF(++tries > kMaxSwitchTries,
 "switchToNextOutput() cannot obtain callback lock");
                    mLock.unlock();
                    usleep(5 * 1000 /* usec */); // allow callback to use AudioOutput
                    mLock.lock();
 continue;
 }
#endif
 }

 Mutex::Autolock nextLock(mNextOutput->mLock);

 if (mNextOutput->mTrack == NULL) {
                ALOGD("Recycling track for gapless playback");
 delete mNextOutput->mCallbackData;
                mNextOutput->mCallbackData = mCallbackData;
                mNextOutput->mRecycledTrack = mTrack;
                mNextOutput->mSampleRateHz = mSampleRateHz;
                mNextOutput->mMsecsPerFrame = mMsecsPerFrame;
                mNextOutput->mFlags = mFlags;
                mNextOutput->mFrameSize = mFrameSize;
                close_l();
                mCallbackData = NULL; // destruction handled by mNextOutput
 } else {
                ALOGW("Ignoring gapless playback because next player has already started");
 if (mCallbackData != NULL) {
                    mCallbackData->endTrackSwitch(); // release lock for callbacks before close.
 }
                close_l();
 }
 }
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool config_has_section(const config_t *config, const char *section) {
  assert(config != NULL);
  assert(section != NULL);

 return (section_find(config, section) != NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::write(const FlattenableHelperInterface& val)
{
 status_t err;

 const size_t len = val.getFlattenedSize();
 const size_t fd_count = val.getFdCount();

 if ((len > INT32_MAX) || (fd_count >= gMaxFds)) {
 return BAD_VALUE;
 }

    err = this->writeInt32(len);
 if (err) return err;

    err = this->writeInt32(fd_count);
 if (err) return err;

 void* const buf = this->writeInplace(pad_size(len));
 if (buf == NULL)
 return BAD_VALUE;

 int* fds = NULL;
 if (fd_count) {
        fds = new (std::nothrow) int[fd_count];
 if (fds == nullptr) {
            ALOGE("write: failed to allocate requested %zu fds", fd_count);
 return BAD_VALUE;
 }
 }

    err = val.flatten(buf, len, fds, fd_count);
 for (size_t i=0 ; i<fd_count && err==NO_ERROR ; i++) {
        err = this->writeDupFileDescriptor( fds[i] );
 }

 if (fd_count) {
 delete [] fds;
 }

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::shouldSendKeyToInputFilterLocked(const NotifyKeyArgs* args) {
 return mInputFilterEnabled;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftMP3::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError || mOutputPortSettingsChange != NONE) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 while ((!inQueue.empty() || (mSawInputEos && !mSignalledOutputEos)) && !outQueue.empty()) {
 BufferInfo *inInfo = NULL;
        OMX_BUFFERHEADERTYPE *inHeader = NULL;
 if (!inQueue.empty()) {
            inInfo = *inQueue.begin();
            inHeader = inInfo->mHeader;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
        outHeader->nFlags = 0;

 if (inHeader) {
 if (inHeader->nOffset == 0 && inHeader->nFilledLen) {
                mAnchorTimeUs = inHeader->nTimeStamp;
                mNumFramesOutput = 0;
 }

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                mSawInputEos = true;
 }

            mConfig->pInputBuffer =
                inHeader->pBuffer + inHeader->nOffset;

            mConfig->inputBufferCurrentLength = inHeader->nFilledLen;
 } else {
            mConfig->pInputBuffer = NULL;
            mConfig->inputBufferCurrentLength = 0;
 }
        mConfig->inputBufferMaxLength = 0;

         mConfig->inputBufferUsedLength = 0;
 
         mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);
 
         mConfig->pOutputBuffer =
             reinterpret_cast<int16_t *>(outHeader->pBuffer);

        ERROR_CODE decoderErr;
 if ((decoderErr = pvmp3_framedecoder(mConfig, mDecoderBuf))
 != NO_DECODING_ERROR) {
            ALOGV("mp3 decoder returned error %d", decoderErr);

 if (decoderErr != NO_ENOUGH_MAIN_DATA_ERROR
 && decoderErr != SIDE_INFO_ERROR) {
                ALOGE("mp3 decoder returned error %d", decoderErr);

                notify(OMX_EventError, OMX_ErrorUndefined, decoderErr, NULL);
                mSignalledError = true;
 return;
 }

 if (mConfig->outputFrameSize == 0) {
                mConfig->outputFrameSize = kOutputBufferSize / sizeof(int16_t);
 }

 if (decoderErr == NO_ENOUGH_MAIN_DATA_ERROR && mSawInputEos) {
 if (!mIsFirst) {
                    outHeader->nOffset = 0;
                    outHeader->nFilledLen = kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);

                    memset(outHeader->pBuffer, 0, outHeader->nFilledLen);
 }
                outHeader->nFlags = OMX_BUFFERFLAG_EOS;
                mSignalledOutputEos = true;
 } else {

                ALOGV_IF(mIsFirst, "insufficient data for first frame, sending silence");
                memset(outHeader->pBuffer,
 0,
                       mConfig->outputFrameSize * sizeof(int16_t));

 if (inHeader) {
                    mConfig->inputBufferUsedLength = inHeader->nFilledLen;
 }
 }
 } else if (mConfig->samplingRate != mSamplingRate
 || mConfig->num_channels != mNumChannels) {
            mSamplingRate = mConfig->samplingRate;
            mNumChannels = mConfig->num_channels;

            notify(OMX_EventPortSettingsChanged, 1, 0, NULL);
            mOutputPortSettingsChange = AWAITING_DISABLED;
 return;
 }

 if (mIsFirst) {
            mIsFirst = false;
            outHeader->nOffset =
                kPVMP3DecoderDelay * mNumChannels * sizeof(int16_t);

            outHeader->nFilledLen =
                mConfig->outputFrameSize * sizeof(int16_t) - outHeader->nOffset;
 } else if (!mSignalledOutputEos) {
            outHeader->nOffset = 0;
            outHeader->nFilledLen = mConfig->outputFrameSize * sizeof(int16_t);
 }

        outHeader->nTimeStamp =
            mAnchorTimeUs + (mNumFramesOutput * 1000000ll) / mSamplingRate;

 if (inHeader) {
            CHECK_GE(inHeader->nFilledLen, mConfig->inputBufferUsedLength);

            inHeader->nOffset += mConfig->inputBufferUsedLength;
            inHeader->nFilledLen -= mConfig->inputBufferUsedLength;


 if (inHeader->nFilledLen == 0) {
                inInfo->mOwnedByUs = false;
                inQueue.erase(inQueue.begin());
                inInfo = NULL;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;
 }
 }

        mNumFramesOutput += mConfig->outputFrameSize / mNumChannels;

        outInfo->mOwnedByUs = false;
        outQueue.erase(outQueue.begin());
        outInfo = NULL;
        notifyFillBufferDone(outHeader);
        outHeader = NULL;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual ~FwdTrans8x8HT() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::continueWrite(size_t desired)
{
 if (desired > INT32_MAX) {
 return BAD_VALUE;
 }

 size_t objectsSize = mObjectsSize;
 if (desired < mDataSize) {
 if (desired == 0) {
            objectsSize = 0;
 } else {
 while (objectsSize > 0) {
 if (mObjects[objectsSize-1] < desired)
 break;
                objectsSize--;
 }
 }
 }

 if (mOwner) {
 if (desired == 0) {
            freeData();
 return NO_ERROR;
 }

 uint8_t* data = (uint8_t*)malloc(desired);
 if (!data) {
            mError = NO_MEMORY;
 return NO_MEMORY;
 }
 binder_size_t* objects = NULL;

 if (objectsSize) {
            objects = (binder_size_t*)calloc(objectsSize, sizeof(binder_size_t));
 if (!objects) {
                free(data);

                mError = NO_MEMORY;
 return NO_MEMORY;
 }

 size_t oldObjectsSize = mObjectsSize;
            mObjectsSize = objectsSize;
            acquireObjects();
            mObjectsSize = oldObjectsSize;
 }

 if (mData) {
            memcpy(data, mData, mDataSize < desired ? mDataSize : desired);
 }
 if (objects && mObjects) {
            memcpy(objects, mObjects, objectsSize*sizeof(binder_size_t));
 }
        mOwner(this, mData, mDataSize, mObjects, mObjectsSize, mOwnerCookie);
        mOwner = NULL;

        LOG_ALLOC("Parcel %p: taking ownership of %zu capacity", this, desired);
        pthread_mutex_lock(&gParcelGlobalAllocSizeLock);
        gParcelGlobalAllocSize += desired;
        gParcelGlobalAllocCount++;
        pthread_mutex_unlock(&gParcelGlobalAllocSizeLock);

        mData = data;
        mObjects = objects;
        mDataSize = (mDataSize < desired) ? mDataSize : desired;
        ALOGV("continueWrite Setting data size of %p to %zu", this, mDataSize);
        mDataCapacity = desired;
        mObjectsSize = mObjectsCapacity = objectsSize;
        mNextObjectHint = 0;

 } else if (mData) {
 if (objectsSize < mObjectsSize) {
 const sp<ProcessState> proc(ProcessState::self());
 for (size_t i=objectsSize; i<mObjectsSize; i++) {
 const flat_binder_object* flat
 = reinterpret_cast<flat_binder_object*>(mData+mObjects[i]);
 if (flat->type == BINDER_TYPE_FD) {
                    mFdsKnown = false;
 }
                release_object(proc, *flat, this, &mOpenAshmemSize);
 }
 binder_size_t* objects =
 (binder_size_t*)realloc(mObjects, objectsSize*sizeof(binder_size_t));
 if (objects) {
                mObjects = objects;
 }
            mObjectsSize = objectsSize;
            mNextObjectHint = 0;
 }

 if (desired > mDataCapacity) {
 uint8_t* data = (uint8_t*)realloc(mData, desired);
 if (data) {
                LOG_ALLOC("Parcel %p: continue from %zu to %zu capacity", this, mDataCapacity,
                        desired);
                pthread_mutex_lock(&gParcelGlobalAllocSizeLock);
                gParcelGlobalAllocSize += desired;
                gParcelGlobalAllocSize -= mDataCapacity;
                pthread_mutex_unlock(&gParcelGlobalAllocSizeLock);
                mData = data;
                mDataCapacity = desired;
 } else if (desired > mDataCapacity) {
                mError = NO_MEMORY;
 return NO_MEMORY;
 }
 } else {
 if (mDataSize > desired) {
                mDataSize = desired;
                ALOGV("continueWrite Setting data size of %p to %zu", this, mDataSize);
 }
 if (mDataPos > desired) {
                mDataPos = desired;
                ALOGV("continueWrite Setting data pos of %p to %zu", this, mDataPos);
 }
 }

 } else {
 uint8_t* data = (uint8_t*)malloc(desired);
 if (!data) {
            mError = NO_MEMORY;
 return NO_MEMORY;
 }

 if(!(mDataCapacity == 0 && mObjects == NULL
 && mObjectsCapacity == 0)) {
            ALOGE("continueWrite: %zu/%p/%zu/%zu", mDataCapacity, mObjects, mObjectsCapacity, desired);
 }

        LOG_ALLOC("Parcel %p: allocating with %zu capacity", this, desired);
        pthread_mutex_lock(&gParcelGlobalAllocSizeLock);
        gParcelGlobalAllocSize += desired;
        gParcelGlobalAllocCount++;
        pthread_mutex_unlock(&gParcelGlobalAllocSizeLock);

        mData = data;
        mDataSize = mDataPos = 0;
        ALOGV("continueWrite Setting data size of %p to %zu", this, mDataSize);
        ALOGV("continueWrite Setting data pos of %p to %zu", this, mDataPos);
        mDataCapacity = desired;
 }

 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void BTM_SetPinType (UINT8 pin_type, PIN_CODE pin_code, UINT8 pin_code_len)
{
    BTM_TRACE_API ("BTM_SetPinType: pin type %d [variable-0, fixed-1], code %s, length %d",
                    pin_type, (char *) pin_code, pin_code_len);

 /* If device is not up security mode will be set as a part of startup */
 if ( (btm_cb.cfg.pin_type != pin_type)
 && (btm_cb.devcb.state > BTM_DEV_STATE_WAIT_AFTER_RESET) )
 {
        btsnd_hcic_write_pin_type (pin_type);
 }

    btm_cb.cfg.pin_type     = pin_type;
    btm_cb.cfg.pin_code_len = pin_code_len;
    memcpy (btm_cb.cfg.pin_code, pin_code, pin_code_len);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static EAS_RESULT PushcdlStack (EAS_U32 *pStack, EAS_INT *pStackPtr, EAS_U32 value)

 {
 
     /* stack overflow, return an error */
    if (*pStackPtr >= CDL_STACK_SIZE)
         return EAS_ERROR_FILE_FORMAT;
 
     /* push the value onto the stack */
     *pStackPtr = *pStackPtr + 1;
    pStack[*pStackPtr] = value;
 return EAS_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void rpng2_x_reload_bg_image(void)
{
 char *dest;
    uch r1, r2, g1, g2, b1, b2;
    uch r1_inv, r2_inv, g1_inv, g2_inv, b1_inv, b2_inv;
 int k, hmax, max;
 int xidx, yidx, yidx_max;
 int even_odd_vert, even_odd_horiz, even_odd;
 int invert_gradient2 = (bg[pat].type & 0x08);
 int invert_column;
    ulg i, row;


    bgscale = (pat == 0)? 8 : bgscale_default;
    yidx_max = bgscale - 1;

/*---------------------------------------------------------------------------
    Vertical gradients (ramps) in NxN squares, alternating direction and
    colors (N == bgscale).
  ---------------------------------------------------------------------------*/

 if ((bg[pat].type & 0x07) == 0) {
        uch r1_min  = rgb[bg[pat].rgb1_min].r;
        uch g1_min  = rgb[bg[pat].rgb1_min].g;
        uch b1_min  = rgb[bg[pat].rgb1_min].b;
        uch r2_min  = rgb[bg[pat].rgb2_min].r;
        uch g2_min  = rgb[bg[pat].rgb2_min].g;
        uch b2_min  = rgb[bg[pat].rgb2_min].b;
 int r1_diff = rgb[bg[pat].rgb1_max].r - r1_min;
 int g1_diff = rgb[bg[pat].rgb1_max].g - g1_min;
 int b1_diff = rgb[bg[pat].rgb1_max].b - b1_min;
 int r2_diff = rgb[bg[pat].rgb2_max].r - r2_min;
 int g2_diff = rgb[bg[pat].rgb2_max].g - g2_min;
 int b2_diff = rgb[bg[pat].rgb2_max].b - b2_min;

 for (row = 0;  row < rpng2_info.height; ++row) {
            yidx = (int)(row % bgscale);
            even_odd_vert = (int)((row / bgscale) & 1);

            r1 = r1_min + (r1_diff * yidx) / yidx_max;
            g1 = g1_min + (g1_diff * yidx) / yidx_max;
            b1 = b1_min + (b1_diff * yidx) / yidx_max;
            r1_inv = r1_min + (r1_diff * (yidx_max-yidx)) / yidx_max;
            g1_inv = g1_min + (g1_diff * (yidx_max-yidx)) / yidx_max;
            b1_inv = b1_min + (b1_diff * (yidx_max-yidx)) / yidx_max;

            r2 = r2_min + (r2_diff * yidx) / yidx_max;
            g2 = g2_min + (g2_diff * yidx) / yidx_max;
            b2 = b2_min + (b2_diff * yidx) / yidx_max;
            r2_inv = r2_min + (r2_diff * (yidx_max-yidx)) / yidx_max;
            g2_inv = g2_min + (g2_diff * (yidx_max-yidx)) / yidx_max;
            b2_inv = b2_min + (b2_diff * (yidx_max-yidx)) / yidx_max;

            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                even_odd_horiz = (int)((i / bgscale) & 1);
                even_odd = even_odd_vert ^ even_odd_horiz;
                invert_column =
 (even_odd_horiz && (bg[pat].type & 0x10));
 if (even_odd == 0) { /* gradient #1 */
 if (invert_column) {
 *dest++ = r1_inv;
 *dest++ = g1_inv;
 *dest++ = b1_inv;
 } else {
 *dest++ = r1;
 *dest++ = g1;
 *dest++ = b1;
 }
 } else { /* gradient #2 */
 if ((invert_column && invert_gradient2) ||
 (!invert_column && !invert_gradient2))
 {
 *dest++ = r2; /* not inverted or */
 *dest++ = g2; /*  doubly inverted */
 *dest++ = b2;
 } else {
 *dest++ = r2_inv;
 *dest++ = g2_inv; /* singly inverted */
 *dest++ = b2_inv;
 }
 }
 }
 }

/*---------------------------------------------------------------------------
    Soft gradient-diamonds with scale = bgscale.  Code contributed by Adam
    M. Costello.
  ---------------------------------------------------------------------------*/

 } else if ((bg[pat].type & 0x07) == 1) {

        hmax = (bgscale-1)/2; /* half the max weight of a color */
        max = 2*hmax; /* the max weight of a color */

        r1 = rgb[bg[pat].rgb1_max].r;
        g1 = rgb[bg[pat].rgb1_max].g;
        b1 = rgb[bg[pat].rgb1_max].b;
        r2 = rgb[bg[pat].rgb2_max].r;
        g2 = rgb[bg[pat].rgb2_max].g;
        b2 = rgb[bg[pat].rgb2_max].b;

 for (row = 0;  row < rpng2_info.height; ++row) {
            yidx = (int)(row % bgscale);
 if (yidx > hmax)
                yidx = bgscale-1 - yidx;
            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                xidx = (int)(i % bgscale);
 if (xidx > hmax)
                    xidx = bgscale-1 - xidx;
                k = xidx + yidx;
 *dest++ = (k*r1 + (max-k)*r2) / max;
 *dest++ = (k*g1 + (max-k)*g2) / max;
 *dest++ = (k*b1 + (max-k)*b2) / max;
 }
 }

/*---------------------------------------------------------------------------
    Radial "starburst" with azimuthal sinusoids; [eventually number of sinu-
    soids will equal bgscale?].  This one is slow but very cool.  Code con-
    tributed by Pieter S. van der Meulen (originally in Smalltalk).
  ---------------------------------------------------------------------------*/

 } else if ((bg[pat].type & 0x07) == 2) {
        uch ch;
 int ii, x, y, hw, hh, grayspot;
 double freq, rotate, saturate, gray, intensity;
 double angle=0.0, aoffset=0.0, maxDist, dist;
 double red=0.0, green=0.0, blue=0.0, hue, s, v, f, p, q, t;

        hh = (int)(rpng2_info.height / 2);
        hw = (int)(rpng2_info.width / 2);

 /* variables for radial waves:
         *   aoffset:  number of degrees to rotate hue [CURRENTLY NOT USED]
         *   freq:  number of color beams originating from the center
         *   grayspot:  size of the graying center area (anti-alias)
         *   rotate:  rotation of the beams as a function of radius
         *   saturate:  saturation of beams' shape azimuthally
         */
        angle = CLIP(angle, 0.0, 360.0);
        grayspot = CLIP(bg[pat].bg_gray, 1, (hh + hw));
        freq = MAX((double)bg[pat].bg_freq, 0.0);
        saturate = (double)bg[pat].bg_bsat * 0.1;
        rotate = (double)bg[pat].bg_brot * 0.1;
        gray = 0.0;
        intensity = 0.0;
        maxDist = (double)((hw*hw) + (hh*hh));

 for (row = 0;  row < rpng2_info.height; ++row) {
            y = (int)(row - hh);
            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                x = (int)(i - hw);
                angle = (x == 0)? PI_2 : atan((double)y / (double)x);
                gray = (double)MAX(ABS(y), ABS(x)) / grayspot;
                gray = MIN(1.0, gray);
                dist = (double)((x*x) + (y*y)) / maxDist;
                intensity = cos((angle+(rotate*dist*PI)) * freq) *
                  gray * saturate;
                intensity = (MAX(MIN(intensity,1.0),-1.0) + 1.0) * 0.5;
                hue = (angle + PI) * INV_PI_360 + aoffset;
                s = gray * ((double)(ABS(x)+ABS(y)) / (double)(hw + hh));
                s = MIN(MAX(s,0.0), 1.0);
                v = MIN(MAX(intensity,0.0), 1.0);

 if (s == 0.0) {
                    ch = (uch)(v * 255.0);
 *dest++ = ch;
 *dest++ = ch;
 *dest++ = ch;
 } else {
 if ((hue < 0.0) || (hue >= 360.0))
                        hue -= (((int)(hue / 360.0)) * 360.0);
                    hue /= 60.0;
                    ii = (int)hue;
                    f = hue - (double)ii;
                    p = (1.0 - s) * v;
                    q = (1.0 - (s * f)) * v;
                    t = (1.0 - (s * (1.0 - f))) * v;
 if (ii == 0) { red = v; green = t; blue = p; }
 else if (ii == 1) { red = q; green = v; blue = p; }
 else if (ii == 2) { red = p; green = v; blue = t; }
 else if (ii == 3) { red = p; green = q; blue = v; }
 else if (ii == 4) { red = t; green = p; blue = v; }
 else if (ii == 5) { red = v; green = p; blue = q; }
 *dest++ = (uch)(red * 255.0);
 *dest++ = (uch)(green * 255.0);
 *dest++ = (uch)(blue * 255.0);
 }
 }
 }
 }

} /* end function rpng2_x_reload_bg_image() */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t ACodec::setMinBufferSize(OMX_U32 portIndex, size_t size) {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 if (def.nBufferSize >= size) {
 return OK;
 }

    def.nBufferSize = size;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

 if (def.nBufferSize < size) {
        ALOGE("failed to set min buffer size to %zu (is still %u)", size, def.nBufferSize);
 return FAILED_TRANSACTION;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void get_image_md5(const vpx_image_t *img, unsigned char digest[16]) {
 int plane, y;
  MD5Context md5;

  MD5Init(&md5);

 for (plane = 0; plane < 3; ++plane) {
 const unsigned char *buf = img->planes[plane];
 const int stride = img->stride[plane];
 const int w = plane ? (img->d_w + 1) >> 1 : img->d_w;
 const int h = plane ? (img->d_h + 1) >> 1 : img->d_h;

 for (y = 0; y < h; ++y) {
      MD5Update(&md5, buf, w);
      buf += stride;
 }
 }

  MD5Final(digest, &md5);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Cues::~Cues() {
 const long n = m_count + m_preload_count;

 CuePoint** p = m_cue_points;
 CuePoint** const q = p + n;

 while (p != q) {
 CuePoint* const pCP = *p++;
    assert(pCP);

 delete pCP;
 }

 delete[] m_cue_points;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAMR::onQueueFilled(OMX_U32 /* portIndex */) {
 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 if (mSignalledError || mOutputPortSettingsChange != NONE) {
 return;
 }

 while (!inQueue.empty() && !outQueue.empty()) {

         BufferInfo *inInfo = *inQueue.begin();
         OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;
 
        if (inHeader->nFilledLen == 0) {
            inInfo->mOwnedByUs = false;
            inQueue.erase(inQueue.begin());
            notifyEmptyBufferDone(inHeader);
            continue;
        }
         BufferInfo *outInfo = *outQueue.begin();
         OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
 
 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            inQueue.erase(inQueue.begin());
            inInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inHeader);

            outHeader->nFilledLen = 0;
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outQueue.erase(outQueue.begin());
            outInfo->mOwnedByUs = false;
            notifyFillBufferDone(outHeader);

             return;
         }
 
         if (inHeader->nOffset == 0) {
             mAnchorTimeUs = inHeader->nTimeStamp;
             mNumSamplesOutput = 0;
 }

 const uint8_t *inputPtr = inHeader->pBuffer + inHeader->nOffset;
 int32_t numBytesRead;

 if (mMode == MODE_NARROW) {
 if (outHeader->nAllocLen < kNumSamplesPerFrameNB * sizeof(int16_t)) {
                ALOGE("b/27662364: NB expected output buffer %zu bytes vs %u",
                       kNumSamplesPerFrameNB * sizeof(int16_t), outHeader->nAllocLen);
                android_errorWriteLog(0x534e4554, "27662364");
                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);
                mSignalledError = true;
 return;
 }

 int16 mode = ((inputPtr[0] >> 3) & 0x0f);
 size_t frameSize = WmfDecBytesPerFrame[mode] + 1;

 if (inHeader->nFilledLen < frameSize) {
                ALOGE("b/27662364: expected %zu bytes vs %u", frameSize, inHeader->nFilledLen);
                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);
                mSignalledError = true;
 return;
 }

            numBytesRead =
 AMRDecode(mState,
 (Frame_Type_3GPP)((inputPtr[0] >> 3) & 0x0f),
 (UWord8 *)&inputPtr[1],
 reinterpret_cast<int16_t *>(outHeader->pBuffer),
                  MIME_IETF);

 if (numBytesRead == -1) {
                ALOGE("PV AMR decoder AMRDecode() call failed");

                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
                mSignalledError = true;

 return;
 }

 ++numBytesRead; // Include the frame type header byte.

 if (static_cast<size_t>(numBytesRead) > inHeader->nFilledLen) {

                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
                mSignalledError = true;

 return;
 }
 } else {
 if (outHeader->nAllocLen < kNumSamplesPerFrameWB * sizeof(int16_t)) {
                ALOGE("b/27662364: WB expected output buffer %zu bytes vs %u",
                       kNumSamplesPerFrameWB * sizeof(int16_t), outHeader->nAllocLen);
                android_errorWriteLog(0x534e4554, "27662364");
                notify(OMX_EventError, OMX_ErrorOverflow, 0, NULL);
                mSignalledError = true;
 return;
 }

 int16 mode = ((inputPtr[0] >> 3) & 0x0f);

 if (mode >= 10 && mode <= 13) {
                ALOGE("encountered illegal frame type %d in AMR WB content.",
                      mode);

                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
                mSignalledError = true;

 return;
 }

 size_t frameSize = getFrameSize(mode);
 if (inHeader->nFilledLen < frameSize) {
                ALOGE("b/27662364: expected %zu bytes vs %u", frameSize, inHeader->nFilledLen);
                notify(OMX_EventError, OMX_ErrorStreamCorrupt, 0, NULL);
                mSignalledError = true;
 return;
 }

 int16_t *outPtr = (int16_t *)outHeader->pBuffer;

 if (mode >= 9) {
                memset(outPtr, 0, kNumSamplesPerFrameWB * sizeof(int16_t));
 } else if (mode < 9) {
 int16 frameType;
                RX_State_wb rx_state;
                mime_unsorting(
 const_cast<uint8_t *>(&inputPtr[1]),
                        mInputSampleBuffer,
 &frameType, &mode, 1, &rx_state);

 int16_t numSamplesOutput;
                pvDecoder_AmrWb(
                        mode, mInputSampleBuffer,
                        outPtr,
 &numSamplesOutput,
                        mDecoderBuf, frameType, mDecoderCookie);

                CHECK_EQ((int)numSamplesOutput, (int)kNumSamplesPerFrameWB);

 for (int i = 0; i < kNumSamplesPerFrameWB; ++i) {
 /* Delete the 2 LSBs (14-bit output) */
                    outPtr[i] &= 0xfffC;
 }
 }

            numBytesRead = frameSize;
 }

        inHeader->nOffset += numBytesRead;
        inHeader->nFilledLen -= numBytesRead;

        outHeader->nFlags = 0;
        outHeader->nOffset = 0;

 if (mMode == MODE_NARROW) {
            outHeader->nFilledLen = kNumSamplesPerFrameNB * sizeof(int16_t);

            outHeader->nTimeStamp =
                mAnchorTimeUs
 + (mNumSamplesOutput * 1000000ll) / kSampleRateNB;

            mNumSamplesOutput += kNumSamplesPerFrameNB;
 } else {
            outHeader->nFilledLen = kNumSamplesPerFrameWB * sizeof(int16_t);

            outHeader->nTimeStamp =
                mAnchorTimeUs
 + (mNumSamplesOutput * 1000000ll) / kSampleRateWB;

            mNumSamplesOutput += kNumSamplesPerFrameWB;
 }

 if (inHeader->nFilledLen == 0) {
            inInfo->mOwnedByUs = false;
            inQueue.erase(inQueue.begin());
            inInfo = NULL;
            notifyEmptyBufferDone(inHeader);
            inHeader = NULL;
 }

        outInfo->mOwnedByUs = false;
        outQueue.erase(outQueue.begin());
        outInfo = NULL;
        notifyFillBufferDone(outHeader);
        outHeader = NULL;

 ++mInputBufferCount;
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: int /* OMX_VIDEO_AVCLEVELTYPE */ ACodec::getAVCLevelFor(
 int width, int height, int rate, int bitrate,
        OMX_VIDEO_AVCPROFILETYPE profile) {
 switch (profile) {
 case OMX_VIDEO_AVCProfileHigh10:
            bitrate = divUp(bitrate, 3000); break;
 case OMX_VIDEO_AVCProfileHigh:
            bitrate = divUp(bitrate, 1250); break;
 default:
            bitrate = divUp(bitrate, 1000); break;
 }

    width = divUp(width, 16);
    height = divUp(height, 16);
 int mbs = width * height;
    rate *= mbs;
 int maxDimension = max(width, height);

 static const int limits[][5] = {
 /*   MBps     MB   dim  bitrate        level */
 { 1485, 99, 28, 64, OMX_VIDEO_AVCLevel1  },
 { 1485, 99, 28, 128, OMX_VIDEO_AVCLevel1b },
 { 3000, 396, 56, 192, OMX_VIDEO_AVCLevel11 },
 { 6000, 396, 56, 384, OMX_VIDEO_AVCLevel12 },
 { 11880, 396, 56, 768, OMX_VIDEO_AVCLevel13 },
 { 11880, 396, 56, 2000, OMX_VIDEO_AVCLevel2  },
 { 19800, 792, 79, 4000, OMX_VIDEO_AVCLevel21 },
 { 20250, 1620, 113, 4000, OMX_VIDEO_AVCLevel22 },
 { 40500, 1620, 113, 10000, OMX_VIDEO_AVCLevel3  },
 { 108000, 3600, 169, 14000, OMX_VIDEO_AVCLevel31 },
 { 216000, 5120, 202, 20000, OMX_VIDEO_AVCLevel32 },
 { 245760, 8192, 256, 20000, OMX_VIDEO_AVCLevel4  },
 { 245760, 8192, 256, 50000, OMX_VIDEO_AVCLevel41 },
 { 522240, 8704, 263, 50000, OMX_VIDEO_AVCLevel42 },
 { 589824, 22080, 420, 135000, OMX_VIDEO_AVCLevel5  },
 { 983040, 36864, 543, 240000, OMX_VIDEO_AVCLevel51 },
 { 2073600, 36864, 543, 240000, OMX_VIDEO_AVCLevel52 },
 };

 for (size_t i = 0; i < ARRAY_SIZE(limits); i++) {
 const int (&limit)[5] = limits[i];
 if (rate <= limit[0] && mbs <= limit[1] && maxDimension <= limit[2]
 && bitrate <= limit[3]) {
 return limit[4];
 }
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Antagonizer::callbackThread(void* user)
{
    ALOGD("Antagonizer started");
 Antagonizer* p = reinterpret_cast<Antagonizer*>(user);
 while (!p->mExit) {
 if (p->mActive) {
            ALOGV("send event");
            p->mCb(p->mClient, 0, 0, 0);
 }
        usleep(interval);
 }
 Mutex::Autolock _l(p->mLock);
    p->mCondition.signal();
    ALOGD("Antagonizer stopped");
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: emit_string(const char *str, FILE *out)
 /* Print a string with spaces replaced by '_' and non-printing characters by
    * an octal escape.
    */
{
 for (; *str; ++str)
 if (isgraph(UCHAR_MAX & *str))
         putc(*str, out);

 
       else if (isspace(UCHAR_MAX & *str))
          putc('_', out);
       else
          fprintf(out, "\\%.3o", *str);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Equalizer_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int status = 0;
 int32_t preset;
 int32_t band;
 int32_t level;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param) {
 case EQ_PARAM_CUR_PRESET:
        preset = (int32_t)(*(uint16_t *)pValue);

 if ((preset >= EqualizerGetNumPresets())||(preset < 0)) {
            status = -EINVAL;
 break;
 }
 EqualizerSetPreset(pContext, preset);
 break;
 case EQ_PARAM_BAND_LEVEL:

         band =  *pParamTemp;
         level = (int32_t)(*(int16_t *)pValue);
        if (band >= FIVEBAND_NUMBANDS) {
             status = -EINVAL;
             break;
         }
         EqualizerSetBandLevel(pContext, band, level);
 break;
 case EQ_PARAM_PROPERTIES: {
 int16_t *p = (int16_t *)pValue;
 if ((int)p[0] >= EqualizerGetNumPresets()) {
            status = -EINVAL;
 break;
 }
 if (p[0] >= 0) {
 EqualizerSetPreset(pContext, (int)p[0]);
 } else {
 if ((int)p[1] != FIVEBAND_NUMBANDS) {
                status = -EINVAL;
 break;
 }
 for (int i = 0; i < FIVEBAND_NUMBANDS; i++) {
 EqualizerSetBandLevel(pContext, i, (int)p[2 + i]);
 }
 }
 } break;
 default:
        ALOGV("\tLVM_ERROR : Equalizer_setParameter() invalid param %d", param);
        status = -EINVAL;
 break;
 }

 return status;
} /* end Equalizer_setParameter */

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MPEG4Extractor::MPEG4Extractor(const sp<DataSource> &source)
 : mSidxDuration(0),
      mMoofOffset(0),
      mDataSource(source),
      mInitCheck(NO_INIT),
      mHasVideo(false),
      mHeaderTimescale(0),
      mFirstTrack(NULL),
      mLastTrack(NULL),
      mFileMetaData(new MetaData),
      mFirstSINF(NULL),
      mIsDrm(false) {
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE SoftRaw::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0 && pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mChannelCount;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int HAL_load(void)
{
 int err = 0;

 hw_module_t* module;
 hw_device_t* device;

    bdt_log("Loading HAL lib + extensions");

    err = hw_get_module(BT_HARDWARE_MODULE_ID, (hw_module_t const**)&module);
 if (err == 0)
 {
        err = module->methods->open(module, BT_HARDWARE_MODULE_ID, &device);
 if (err == 0) {
            bt_device = (bluetooth_device_t *)device;
            sBtInterface = bt_device->get_bluetooth_interface();
 }
 }

    bdt_log("HAL library loaded (%s)", strerror(err));

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t NuPlayer::GenericSource::seekTo(int64_t seekTimeUs) {
    sp<AMessage> msg = new AMessage(kWhatSeek, this);
    msg->setInt64("seekTimeUs", seekTimeUs);

    sp<AMessage> response;
 status_t err = msg->postAndAwaitResponse(&response);
 if (err == OK && response != NULL) {
        CHECK(response->findInt32("err", &err));
 }

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_end_of_pic_dispbuf_mgr(dec_struct_t * ps_dec)
{
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
    UWORD8 u1_num_of_users = 0;
    WORD32 ret;

    H264_MUTEX_LOCK(&ps_dec->process_disp_mutex);
 if(1)
 {

 {
            ih264d_delete_nonref_nondisplay_pics(ps_dec->ps_dpb_mgr);
 if(ps_cur_slice->u1_mmco_equalto5
 || (ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL))
 {
                ps_dec->ps_cur_pic->i4_poc = 0;
 if(ps_dec->u2_total_mbs_coded
 == (ps_dec->ps_cur_sps->u2_max_mb_addr + 1))
                    ih264d_reset_ref_bufs(ps_dec->ps_dpb_mgr);
                ih264d_release_display_bufs(ps_dec);
 }
 if(ps_dec->u4_num_reorder_frames_at_init != 0)
 {
                ret = ih264d_assign_display_seq(ps_dec);
 if(ret != OK)
 return ret;
 }
 }

 if(ps_cur_slice->u1_nal_ref_idc)
 {
 /* Mark pic buf as needed for reference */
            ih264_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                     ps_dec->u1_pic_buf_id,
                                     BUF_MGR_REF);
 /* Mark mv buf as needed for reference */
            ih264_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                     ps_dec->au1_pic_buf_id_mv_buf_id_map[ps_dec->u1_pic_buf_id],
                                     BUF_MGR_REF);
            ps_dec->au1_pic_buf_ref_flag[ps_dec->u1_pic_buf_id] = 1;
 }

 /* 420 consumer */
 /* Increment the number of users by 1 for display based upon */
 /*the SEEK KEY FRAME control sent to decoder                 */
 if(((0 == ps_dec->u1_last_pic_not_decoded)
 && (0
 == (ps_dec->ps_cur_pic->u4_pack_slc_typ
 & ps_dec->u4_skip_frm_mask)))
 || (ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL))
 {
 /* Mark pic buf as needed for display */
            ih264_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                     ps_dec->u1_pic_buf_id,
                                     BUF_MGR_IO);

 }

 if(!ps_cur_slice->u1_field_pic_flag
 || ((TOP_FIELD_ONLY | BOT_FIELD_ONLY)
 != ps_dec->u1_top_bottom_decoded))
 {
 pic_buffer_t *ps_cur_pic = ps_dec->ps_cur_pic;
            ps_cur_pic->u2_disp_width = ps_dec->u2_disp_width;
            ps_cur_pic->u2_disp_height = ps_dec->u2_disp_height >> 1;

            ps_cur_pic->u2_crop_offset_y = ps_dec->u2_crop_offset_y;
            ps_cur_pic->u2_crop_offset_uv = ps_dec->u2_crop_offset_uv;
            ps_cur_pic->u1_pic_type = 0;

            ret = ih264d_insert_pic_in_display_list(
                            ps_dec->ps_dpb_mgr,
                            ps_dec->u1_pic_buf_id,
                            ps_dec->i4_prev_max_display_seq
 + ps_dec->ps_cur_pic->i4_poc,
                            ps_dec->ps_cur_pic->i4_frame_num);
 if(ret != OK)
 return ret;

 {
 ivd_video_decode_op_t * ps_dec_output =
 (ivd_video_decode_op_t *)ps_dec->pv_dec_out;

                ps_dec_output->u4_frame_decoded_flag = 1;
 }
 if(ps_dec->au1_pic_buf_ref_flag[ps_dec->u1_pic_buf_id] == 0)
 {
                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                      ps_dec->au1_pic_buf_id_mv_buf_id_map[ps_dec->u1_pic_buf_id],
                                      BUF_MGR_REF);
                ps_dec->au1_pic_buf_ref_flag[ps_dec->u1_pic_buf_id] = 0;

 }
 }
 else
 {
            H264_DEC_DEBUG_PRINT("pic not inserted display %d %d\n",
                                 ps_cur_slice->u1_field_pic_flag,
                                 ps_dec->u1_second_field);
 }

 if(!ps_cur_slice->u1_field_pic_flag
 || ((TOP_FIELD_ONLY | BOT_FIELD_ONLY)
 == ps_dec->u1_top_bottom_decoded))
 {
 if(ps_dec->u4_num_reorder_frames_at_init == 0)
 {
                ret = ih264d_assign_display_seq(ps_dec);
 if(ret != OK)
 return ret;
 }
 }
 }

    H264_MUTEX_UNLOCK(&ps_dec->process_disp_mutex);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static PropertyDetails GetDetailsImpl(JSObject* holder, uint32_t entry) {
 return PropertyDetails(kData, DONT_DELETE, 0, PropertyCellType::kNoCell);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual uint64_t approxBitrate() const {
 return 0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraSource::releaseCamera() {
    ALOGV("releaseCamera");
    sp<Camera> camera;
 bool coldCamera = false;
 {
 Mutex::Autolock autoLock(mLock);
        camera = mCamera;
        mCamera.clear();
        coldCamera = (mCameraFlags & FLAGS_HOT_CAMERA) == 0;
 }

 if (camera != 0) {
 int64_t token = IPCThreadState::self()->clearCallingIdentity();
 if (coldCamera) {
            ALOGV("Camera was cold when we started, stopping preview");
            camera->stopPreview();
            camera->disconnect();
 }
        camera->unlock();
 IPCThreadState::self()->restoreCallingIdentity(token);
 }

 {
 Mutex::Autolock autoLock(mLock);
 if (mCameraRecordingProxy != 0) {
 IInterface::asBinder(mCameraRecordingProxy)->unlinkToDeath(mDeathNotifier);
            mCameraRecordingProxy.clear();
 }
        mCameraFlags = 0;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void in_update_aux_channels(struct stream_in *in,
 effect_handle_t effect)
{
 uint32_t aux_channels;
 channel_config_t channel_config;
 int status;

    aux_channels = in_get_aux_channels(in);

    channel_config.main_channels = in->main_channels;
    channel_config.aux_channels = aux_channels;
    status = in_reconfigure_channels(in,
                                     effect,
 &channel_config,
 (aux_channels != in->aux_channels));

 if (status != 0) {
        ALOGV("in_update_aux_channels(): in_reconfigure_channels error %d", status);
 /* resetting aux channels configuration */
        aux_channels = 0;
        channel_config.aux_channels = 0;
        in_reconfigure_channels(in, effect, &channel_config, true);
 }
    ALOGV("%s: aux_channels=%d, in->aux_channels_changed=%d", __func__, aux_channels, in->aux_channels_changed);
 if (in->aux_channels != aux_channels) {
        in->aux_channels_changed = true;
        in->aux_channels = aux_channels;
        do_in_standby_l(in);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Tags::Tag::Tag() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::waitUntilDrained() {
    ATRACE_CALL();
 Mutex::Autolock il(mInterfaceLock);
 Mutex::Autolock l(mLock);

 return waitUntilDrainedLocked();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_sec_link_key_request (UINT8 *p_bda)
{
    tBTM_SEC_DEV_REC *p_dev_rec = btm_find_or_alloc_dev (p_bda);

    BTM_TRACE_EVENT ("btm_sec_link_key_request()  BDA: %02x:%02x:%02x:%02x:%02x:%02x",
                      p_bda[0], p_bda[1], p_bda[2], p_bda[3], p_bda[4], p_bda[5]);

 if( (btm_cb.pairing_state == BTM_PAIR_STATE_WAIT_PIN_REQ) &&
 (btm_cb.collision_start_time != 0) &&
 (memcmp (btm_cb.p_collided_dev_rec->bd_addr, p_bda, BD_ADDR_LEN) == 0) )
 {
        BTM_TRACE_EVENT ("btm_sec_link_key_request() rejecting link key req "
 "State: %d START_TIMEOUT : %d",
             btm_cb.pairing_state, btm_cb.collision_start_time);
        btsnd_hcic_link_key_neg_reply (p_bda);
 return;
 }
 if (p_dev_rec->sec_flags & BTM_SEC_LINK_KEY_KNOWN)
 {
        btsnd_hcic_link_key_req_reply (p_bda, p_dev_rec->link_key);
 return;
 }

 /* Notify L2CAP to increase timeout */
    l2c_pin_code_request (p_bda);

 /* Only ask the host for a key if this guy is not already bonding */
 if ( (btm_cb.pairing_state == BTM_PAIR_STATE_IDLE)
 || (memcmp (p_bda, btm_cb.pairing_bda, BD_ADDR_LEN) != 0) )
 {
 if (btm_cb.api.p_link_key_req_callback)
 {
 if ((*btm_cb.api.p_link_key_req_callback)(p_bda, p_dev_rec->link_key) == BTM_SUCCESS)
 {
                btsnd_hcic_link_key_req_reply (p_bda, p_dev_rec->link_key);
 return;
 }
 }
 }

 /* The link key is not in the database and it is not known to the manager */
    btsnd_hcic_link_key_neg_reply (p_bda);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: control_end(struct control *control)
{
 return file_end(&control->file);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MD5Init(struct MD5Context *ctx) {
  ctx->buf[0] = 0x67452301;
  ctx->buf[1] = 0xefcdab89;
  ctx->buf[2] = 0x98badcfe;
  ctx->buf[3] = 0x10325476;

  ctx->bytes[0] = 0;
  ctx->bytes[1] = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_init_dec_mb_grp(dec_struct_t *ps_dec)
{
 dec_seq_params_t *ps_seq = ps_dec->ps_cur_sps;
    UWORD8 u1_frm = ps_seq->u1_frame_mbs_only_flag;

    ps_dec->u1_recon_mb_grp = ps_dec->u2_frm_wd_in_mbs << ps_seq->u1_mb_aff_flag;

    ps_dec->u1_recon_mb_grp_pair = ps_dec->u1_recon_mb_grp >> 1;

 if(!ps_dec->u1_recon_mb_grp)
 {
 return ERROR_MB_GROUP_ASSGN_T;
 }

    ps_dec->u4_num_mbs_prev_nmb = ps_dec->u1_recon_mb_grp;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline void SetImpl(FixedArrayBase* store, uint32_t entry,
 Object* value) {
 FixedArray* parameter_map = FixedArray::cast(store);
 uint32_t length = parameter_map->length() - 2;
 if (entry < length) {
 Object* probe = parameter_map->get(entry + 2);
 Context* context = Context::cast(parameter_map->get(0));
 int context_entry = Smi::cast(probe)->value();
      DCHECK(!context->get(context_entry)->IsTheHole(store->GetIsolate()));
      context->set(context_entry, value);
 } else {
 FixedArray* arguments = FixedArray::cast(parameter_map->get(1));
 Object* current = ArgumentsAccessor::GetRaw(arguments, entry - length);
 if (current->IsAliasedArgumentsEntry()) {
 AliasedArgumentsEntry* alias = AliasedArgumentsEntry::cast(current);
 Context* context = Context::cast(parameter_map->get(0));
 int context_entry = alias->aliased_context_slot();
        DCHECK(!context->get(context_entry)->IsTheHole(store->GetIsolate()));
        context->set(context_entry, value);
 } else {
 ArgumentsAccessor::SetImpl(arguments, entry - length, value);
 }
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int XfrmController::fillTransportModeUserSpInfo(const XfrmSaInfo& record, XfrmDirection direction,
                                                xfrm_userpolicy_info* usersp) {
    fillXfrmSelector(record, &usersp->sel);
    fillXfrmLifetimeDefaults(&usersp->lft);
    fillXfrmCurLifetimeDefaults(&usersp->curlft);
 /* if (index) index & 0x3 == dir -- must be true
     * xfrm_user.c:verify_newpolicy_info() */
    usersp->index = 0;
    usersp->dir = static_cast<uint8_t>(direction);
    usersp->action = XFRM_POLICY_ALLOW;
    usersp->flags = XFRM_POLICY_LOCALOK;
    usersp->share = XFRM_SHARE_UNIQUE;
 return sizeof(*usersp);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void listenCallback (int fd, short flags, void *param) {
 int ret;
 int err;
 int is_phone_socket;
 int fdCommand = -1;
 const char* processName;
 RecordStream *p_rs;
 MySocketListenParam* listenParam;
 RilSocket *sapSocket = NULL;
    socketClient *sClient = NULL;

 SocketListenParam *p_info = (SocketListenParam *)param;

 if(RIL_SAP_SOCKET == p_info->type) {
        listenParam = (MySocketListenParam *)param;
        sapSocket = listenParam->socket;
 }

 struct sockaddr_un peeraddr;
 socklen_t socklen = sizeof (peeraddr);

 struct ucred creds;
 socklen_t szCreds = sizeof(creds);

 struct passwd *pwd = NULL;

 if(NULL == sapSocket) {
        assert (*p_info->fdCommand < 0);
        assert (fd == *p_info->fdListen);
        processName = PHONE_PROCESS;
 } else {
        assert (sapSocket->commandFd < 0);
        assert (fd == sapSocket->listenFd);
        processName = BLUETOOTH_PROCESS;
 }


    fdCommand = accept(fd, (sockaddr *) &peeraddr, &socklen);

 if (fdCommand < 0 ) {
        RLOGE("Error on accept() errno:%d", errno);
 /* start listening for new connections again */
 if(NULL == sapSocket) {
            rilEventAddWakeup(p_info->listen_event);
 } else {
            rilEventAddWakeup(sapSocket->getListenEvent());
 }
 return;
 }

 /* check the credential of the other side and only accept socket from
     * phone process
     */
    errno = 0;
    is_phone_socket = 0;

    err = getsockopt(fdCommand, SOL_SOCKET, SO_PEERCRED, &creds, &szCreds);

 if (err == 0 && szCreds > 0) {
        errno = 0;
        pwd = getpwuid(creds.uid);
 if (pwd != NULL) {
 if (strcmp(pwd->pw_name, processName) == 0) {
                is_phone_socket = 1;
 } else {
                RLOGE("RILD can't accept socket from process %s", pwd->pw_name);
 }
 } else {
            RLOGE("Error on getpwuid() errno: %d", errno);
 }
 } else {
        RLOGD("Error on getsockopt() errno: %d", errno);
 }

 if (!is_phone_socket) {
        RLOGE("RILD must accept socket from %s", processName);

        close(fdCommand);
        fdCommand = -1;

 if(NULL == sapSocket) {
            onCommandsSocketClosed(p_info->socket_id);

 /* start listening for new connections again */
            rilEventAddWakeup(p_info->listen_event);
 } else {
            sapSocket->onCommandsSocketClosed();

 /* start listening for new connections again */
            rilEventAddWakeup(sapSocket->getListenEvent());
 }

 return;
 }

    ret = fcntl(fdCommand, F_SETFL, O_NONBLOCK);

 if (ret < 0) {
        RLOGE ("Error setting O_NONBLOCK errno:%d", errno);
 }

 if(NULL == sapSocket) {
        RLOGI("libril: new connection to %s", rilSocketIdToString(p_info->socket_id));

        p_info->fdCommand = fdCommand;
        p_rs = record_stream_new(p_info->fdCommand, MAX_COMMAND_BYTES);
        p_info->p_rs = p_rs;

        ril_event_set (p_info->commands_event, p_info->fdCommand, 1,
        p_info->processCommandsCallback, p_info);
        rilEventAddWakeup (p_info->commands_event);

        onNewCommandConnect(p_info->socket_id);
 } else {
        RLOGI("libril: new connection");

        sapSocket->setCommandFd(fdCommand);
        p_rs = record_stream_new(sapSocket->getCommandFd(), MAX_COMMAND_BYTES);
        sClient = new socketClient(sapSocket,p_rs);
        ril_event_set (sapSocket->getCallbackEvent(), sapSocket->getCommandFd(), 1,
        sapSocket->getCommandCb(), sClient);

        rilEventAddWakeup(sapSocket->getCallbackEvent());
        sapSocket->onNewCommandConnect();
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: InputDispatcherThread::InputDispatcherThread(const sp<InputDispatcherInterface>& dispatcher) :
 Thread(/*canCallJava*/ true), mDispatcher(dispatcher) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AMRSource::read(
 MediaBuffer **out, const ReadOptions *options) {
 *out = NULL;

 
     int64_t seekTimeUs;
     ReadOptions::SeekMode mode;
    if (options && options->getSeekTo(&seekTimeUs, &mode)) {
         size_t size;
         int64_t seekFrame = seekTimeUs / 20000ll;  // 20ms per frame.
         mCurrentTimeUs = seekFrame * 20000ll;

 size_t index = seekFrame < 0 ? 0 : seekFrame / 50;
 if (index >= mOffsetTableLength) {
            index = mOffsetTableLength - 1;
 }

        mOffset = mOffsetTable[index] + (mIsWide ? 9 : 6);

 for (size_t i = 0; i< seekFrame - index * 50; i++) {
 status_t err;
 if ((err = getFrameSizeByOffset(mDataSource, mOffset,
                            mIsWide, &size)) != OK) {
 return err;
 }
            mOffset += size;
 }
 }

 uint8_t header;
 ssize_t n = mDataSource->readAt(mOffset, &header, 1);

 if (n < 1) {
 return ERROR_END_OF_STREAM;
 }

 if (header & 0x83) {

        ALOGE("padding bits must be 0, header is 0x%02x", header);

 return ERROR_MALFORMED;
 }

 unsigned FT = (header >> 3) & 0x0f;

 size_t frameSize = getFrameSize(mIsWide, FT);
 if (frameSize == 0) {
 return ERROR_MALFORMED;
 }

 MediaBuffer *buffer;
 status_t err = mGroup->acquire_buffer(&buffer);
 if (err != OK) {
 return err;
 }

    n = mDataSource->readAt(mOffset, buffer->data(), frameSize);

 if (n != (ssize_t)frameSize) {
        buffer->release();
        buffer = NULL;

 if (n < 0) {
 return ERROR_IO;
 } else {
            mOffset += n;
 return ERROR_END_OF_STREAM;
 }
 }

    buffer->set_range(0, frameSize);
    buffer->meta_data()->setInt64(kKeyTime, mCurrentTimeUs);
    buffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);

    mOffset += frameSize;
    mCurrentTimeUs += 20000; // Each frame is 20ms

 *out = buffer;

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_remote_service_record_evt(UINT16 event, char *p_param)
{
    tBTA_DM_SEARCH *p_data = (tBTA_DM_SEARCH*)p_param;

    BTIF_TRACE_EVENT("%s:  event = %d", __FUNCTION__, event);
 switch (event)
 {
 case BTA_DM_DISC_RES_EVT:
 {
 bt_service_record_t rec;
 bt_property_t prop;
 bt_bdaddr_t bd_addr;

            memset(&rec, 0, sizeof(bt_service_record_t));
            bdcpy(bd_addr.address, p_data->disc_res.bd_addr);

            BTIF_TRACE_DEBUG("%s:(result=0x%x, services 0x%x)", __FUNCTION__,
                    p_data->disc_res.result, p_data->disc_res.services);
            prop.type = BT_PROPERTY_SERVICE_RECORD;
            prop.val = (void*)&rec;
            prop.len = sizeof(rec);

 /* disc_res.result is overloaded with SCN. Cannot check result */
            p_data->disc_res.services &= ~BTA_USER_SERVICE_MASK;
 /* TODO: Get the UUID as well */
            rec.channel = p_data->disc_res.result - 3;
 /* TODO: Need to get the service name using p_raw_data */
            rec.name[0] = 0;

            HAL_CBACK(bt_hal_cbacks, remote_device_properties_cb,
                             BT_STATUS_SUCCESS, &bd_addr, 1, &prop);
 }
 break;

 default:
 {
           ASSERTC(0, "unhandled remote service record event", event);
 }
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual bool isCryptoSchemeSupported(const uint8_t uuid[16], const String8 &mimeType) {
 Parcel data, reply;
        data.writeInterfaceToken(IDrm::getInterfaceDescriptor());
        data.write(uuid, 16);
        data.writeString8(mimeType);
 status_t status = remote()->transact(IS_CRYPTO_SUPPORTED, data, &reply);
 if (status != OK) {
            ALOGE("isCryptoSchemeSupported: binder call failed: %d", status);
 return false;
 }

 return reply.readInt32() != 0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Chapters::Atom* Chapters::Edition::GetAtom(int index) const
{
    if (index < 0)
        return NULL;
 
    if (index >= m_atoms_count)
        return NULL;
 
    return m_atoms + index;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool omx_venc::dev_use_buf(void *buf_addr,unsigned port,unsigned index)
{
 return handle->venc_use_buf(buf_addr,port,index);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::emptyBuffer(
        OMX::buffer_id buffer,
        OMX_U32 rangeOffset, OMX_U32 rangeLength,
        OMX_U32 flags, OMX_TICKS timestamp, int fenceFd) {
 Mutex::Autolock autoLock(mLock);

 if (getGraphicBufferSource() != NULL) {
        android_errorWriteLog(0x534e4554, "29422020");
 return INVALID_OPERATION;
 }

    OMX_BUFFERHEADERTYPE *header = findBufferHeader(buffer, kPortIndexInput);
 if (header == NULL) {
        ALOGE("b/25884056");
 return BAD_VALUE;

     }
     BufferMeta *buffer_meta =
         static_cast<BufferMeta *>(header->pAppPrivate);
    sp<ABuffer> backup = buffer_meta->getBuffer(header, true /* backup */, false /* limit */);
    sp<ABuffer> codec = buffer_meta->getBuffer(header, false /* backup */, false /* limit */);
 
    if (mMetadataType[kPortIndexInput] == kMetadataBufferTypeGrallocSource
            && backup->capacity() >= sizeof(VideoNativeMetadata)
            && codec->capacity() >= sizeof(VideoGrallocMetadata)
            && ((VideoNativeMetadata *)backup->base())->eType
                    == kMetadataBufferTypeANWBuffer) {
        VideoNativeMetadata &backupMeta = *(VideoNativeMetadata *)backup->base();
        VideoGrallocMetadata &codecMeta = *(VideoGrallocMetadata *)codec->base();
        CLOG_BUFFER(emptyBuffer, "converting ANWB %p to handle %p",
                backupMeta.pBuffer, backupMeta.pBuffer->handle);
        codecMeta.pHandle = backupMeta.pBuffer != NULL ? backupMeta.pBuffer->handle : NULL;
        codecMeta.eType = kMetadataBufferTypeGrallocSource;
        header->nFilledLen = rangeLength ? sizeof(codecMeta) : 0;
         header->nOffset = 0;
     } else {
 if (rangeOffset > header->nAllocLen
 || rangeLength > header->nAllocLen - rangeOffset) {
            CLOG_ERROR(emptyBuffer, OMX_ErrorBadParameter, FULL_BUFFER(NULL, header, fenceFd));
 if (fenceFd >= 0) {
 ::close(fenceFd);
 }
 return BAD_VALUE;
 }
        header->nFilledLen = rangeLength;
        header->nOffset = rangeOffset;

        buffer_meta->CopyToOMX(header);
 }

 return emptyBuffer_l(header, flags, timestamp, (intptr_t)buffer, fenceFd);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: snd_device_t get_input_snd_device(struct audio_device *adev, audio_devices_t out_device)
{
 audio_source_t  source;
 audio_mode_t    mode   = adev->mode;
 audio_devices_t in_device;
 audio_channel_mask_t channel_mask;
 snd_device_t snd_device = SND_DEVICE_NONE;
 struct stream_in *active_input = NULL;
 struct audio_usecase *usecase;

    usecase = get_usecase_from_type(adev, PCM_CAPTURE|VOICE_CALL);
 if (usecase != NULL) {
        active_input = (struct stream_in *)usecase->stream;
 }
    source = (active_input == NULL) ?
                                AUDIO_SOURCE_DEFAULT : active_input->source;

    in_device = ((active_input == NULL) ?
                                    AUDIO_DEVICE_NONE : active_input->devices)
 & ~AUDIO_DEVICE_BIT_IN;
    channel_mask = (active_input == NULL) ?
                                AUDIO_CHANNEL_IN_MONO : active_input->main_channels;

    ALOGV("%s: enter: out_device(%#x) in_device(%#x)",
          __func__, out_device, in_device);
 if (mode == AUDIO_MODE_IN_CALL) {
 if (out_device == AUDIO_DEVICE_NONE) {
            ALOGE("%s: No output device set for voice call", __func__);
 goto exit;
 }
 if (adev->tty_mode != TTY_MODE_OFF) {
 if (out_device & AUDIO_DEVICE_OUT_WIRED_HEADPHONE ||
                out_device & AUDIO_DEVICE_OUT_WIRED_HEADSET) {
 switch (adev->tty_mode) {
 case TTY_MODE_FULL:
                    snd_device = SND_DEVICE_IN_VOICE_TTY_FULL_HEADSET_MIC;
 break;
 case TTY_MODE_VCO:
                    snd_device = SND_DEVICE_IN_VOICE_TTY_VCO_HANDSET_MIC;
 break;
 case TTY_MODE_HCO:
                    snd_device = SND_DEVICE_IN_VOICE_TTY_HCO_HEADSET_MIC;
 break;
 default:
                    ALOGE("%s: Invalid TTY mode (%#x)", __func__, adev->tty_mode);
 }
 goto exit;
 }
 }
 if (out_device & AUDIO_DEVICE_OUT_EARPIECE ||
                out_device & AUDIO_DEVICE_OUT_WIRED_HEADPHONE) {
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 } else if (out_device & AUDIO_DEVICE_OUT_WIRED_HEADSET) {
            snd_device = SND_DEVICE_IN_VOICE_HEADSET_MIC;
 } else if (out_device & AUDIO_DEVICE_OUT_SPEAKER) {
            snd_device = SND_DEVICE_IN_VOICE_SPEAKER_MIC;
 }
 } else if (source == AUDIO_SOURCE_CAMCORDER) {
 if (in_device & AUDIO_DEVICE_IN_BUILTIN_MIC ||
            in_device & AUDIO_DEVICE_IN_BACK_MIC) {
            snd_device = SND_DEVICE_IN_CAMCORDER_MIC;
 }
 } else if (source == AUDIO_SOURCE_VOICE_RECOGNITION) {
 if (in_device & AUDIO_DEVICE_IN_BUILTIN_MIC) {
 if (adev->dualmic_config == DUALMIC_CONFIG_1) {
 if (channel_mask == AUDIO_CHANNEL_IN_FRONT_BACK)
                    snd_device = SND_DEVICE_IN_VOICE_REC_DMIC_1;
 else if (adev->ns_in_voice_rec)
                    snd_device = SND_DEVICE_IN_VOICE_REC_DMIC_NS_1;
 }

 if (snd_device == SND_DEVICE_NONE) {
                snd_device = SND_DEVICE_IN_VOICE_REC_MIC;
 }
 } else if (in_device & AUDIO_DEVICE_IN_WIRED_HEADSET) {
            snd_device = SND_DEVICE_IN_VOICE_REC_HEADSET_MIC;
 }
 } else if (source == AUDIO_SOURCE_VOICE_COMMUNICATION || source == AUDIO_SOURCE_MIC) {
 if (out_device & AUDIO_DEVICE_OUT_SPEAKER)
            in_device = AUDIO_DEVICE_IN_BACK_MIC;
 if (active_input) {
 if (active_input->enable_aec) {
 if (in_device & AUDIO_DEVICE_IN_BACK_MIC) {
                    snd_device = SND_DEVICE_IN_SPEAKER_MIC_AEC;
 } else if (in_device & AUDIO_DEVICE_IN_BUILTIN_MIC) {
 if (out_device & AUDIO_DEVICE_OUT_WIRED_HEADPHONE) {
                        snd_device = SND_DEVICE_IN_SPEAKER_MIC_AEC;
 } else {
                        snd_device = SND_DEVICE_IN_HANDSET_MIC_AEC;
 }
 } else if (in_device & AUDIO_DEVICE_IN_WIRED_HEADSET) {
                    snd_device = SND_DEVICE_IN_HEADSET_MIC_AEC;
 }
 }
 /* TODO: set echo reference */
 }
 } else if (source == AUDIO_SOURCE_DEFAULT) {
 goto exit;
 }


 if (snd_device != SND_DEVICE_NONE) {
 goto exit;
 }

 if (in_device != AUDIO_DEVICE_NONE &&
 !(in_device & AUDIO_DEVICE_IN_VOICE_CALL) &&
 !(in_device & AUDIO_DEVICE_IN_COMMUNICATION)) {
 if (in_device & AUDIO_DEVICE_IN_BUILTIN_MIC) {
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 } else if (in_device & AUDIO_DEVICE_IN_BACK_MIC) {
            snd_device = SND_DEVICE_IN_SPEAKER_MIC;
 } else if (in_device & AUDIO_DEVICE_IN_WIRED_HEADSET) {
            snd_device = SND_DEVICE_IN_HEADSET_MIC;
 } else if (in_device & AUDIO_DEVICE_IN_AUX_DIGITAL) {
            snd_device = SND_DEVICE_IN_HDMI_MIC;
 } else {
            ALOGE("%s: Unknown input device(s) %#x", __func__, in_device);
            ALOGW("%s: Using default handset-mic", __func__);
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 }
 } else {
 if (out_device & AUDIO_DEVICE_OUT_EARPIECE) {
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 } else if (out_device & AUDIO_DEVICE_OUT_WIRED_HEADSET) {
            snd_device = SND_DEVICE_IN_HEADSET_MIC;
 } else if (out_device & AUDIO_DEVICE_OUT_SPEAKER) {
            snd_device = SND_DEVICE_IN_SPEAKER_MIC;
 } else if (out_device & AUDIO_DEVICE_OUT_WIRED_HEADPHONE) {
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 } else {
            ALOGE("%s: Unknown output device(s) %#x", __func__, out_device);
            ALOGW("%s: Using default handset-mic", __func__);
            snd_device = SND_DEVICE_IN_HANDSET_MIC;
 }
 }
exit:
    ALOGV("%s: exit: in_snd_device(%s)", __func__, device_table[snd_device]);
 return snd_device;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: String8& String8::appendPath(const char* name)
{
 if (name[0] != OS_PATH_SEPARATOR) {
 if (*name == '\0') {
 return *this;
 }

 size_t len = length();
 if (len == 0) {
            setPathName(name);
 return *this;
 }

 int newlen = strlen(name);

 char* buf = lockBuffer(len+1+newlen);

 if (buf[len-1] != OS_PATH_SEPARATOR)
            buf[len++] = OS_PATH_SEPARATOR;

        memcpy(buf+len, name, newlen+1);
        len += newlen;

        unlockBuffer(len);

 return *this;
 } else {
        setPathName(name);
 return *this;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API void FLAC__stream_decoder_delete(FLAC__StreamDecoder *decoder)
{
 unsigned i;

 if (decoder == NULL)
 return ;

	FLAC__ASSERT(0 != decoder->protected_);
	FLAC__ASSERT(0 != decoder->private_);
	FLAC__ASSERT(0 != decoder->private_->input);

 (void)FLAC__stream_decoder_finish(decoder);

 if(0 != decoder->private_->metadata_filter_ids)
		free(decoder->private_->metadata_filter_ids);

	FLAC__bitreader_delete(decoder->private_->input);

 for(i = 0; i < FLAC__MAX_CHANNELS; i++)
		FLAC__format_entropy_coding_method_partitioned_rice_contents_clear(&decoder->private_->partitioned_rice_contents[i]);

	free(decoder->private_);
	free(decoder->protected_);
	free(decoder);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: check_error(display *d, png_uint_32 flags, const char *message)
{
 while (flags)
 {
      png_uint_32 flag = flags & -(png_int_32)flags;
 int i = find_by_flag(flag);

      fprintf(stderr, "%s(%s): chunk %s: %s\n", d->file, d->test,
         chunk_info[i].name, message);
 ++(d->error_count);

      flags &= ~flag;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Block* Track::EOSBlock::GetBlock() const
{
    return NULL;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void btif_hl_proc_send_data_cfm(tBTA_HL_MDL_HANDLE mdl_handle,
                                       tBTA_HL_STATUS status){
    UINT8                   app_idx,mcl_idx, mdl_idx;
 btif_hl_mdl_cb_t *p_dcb;
    UNUSED(status);

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);
 if (btif_hl_find_mdl_idx_using_handle(mdl_handle,
 &app_idx, &mcl_idx, &mdl_idx ))
 {
        p_dcb =BTIF_HL_GET_MDL_CB_PTR(app_idx, mcl_idx, mdl_idx);
        btif_hl_free_buf((void **) &p_dcb->p_tx_pkt);
        BTIF_TRACE_DEBUG("send success free p_tx_pkt tx_size=%d", p_dcb->tx_size);
        p_dcb->tx_size = 0;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::initiateSetup(const sp<AMessage> &msg) {
    msg->setWhat(kWhatSetup);
    msg->setTarget(this);
    msg->post();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int handle_flush(struct fuse* fuse, struct fuse_handler* handler,
 const struct fuse_in_header* hdr)
{
    TRACE("[%d] FLUSH\n", handler->token);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  image_transform_png_set_strip_16_add(image_transform *this,
    PNG_CONST image_transform **that, png_byte colour_type, png_byte bit_depth)
 {
    UNUSED(colour_type)
 
 this->next = *that;
 *that = this;

 return bit_depth > 8;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int in_set_gain(struct audio_stream_in *stream, float gain)
{
    UNUSED(stream);
    UNUSED(gain);

    FNLOG();
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readBoolVector(std::unique_ptr<std::vector<bool>>* val) const {
 const int32_t start = dataPosition();
 int32_t size;
 status_t status = readInt32(&size);
    val->reset();

 if (status != OK || size < 0) {
 return status;
 }

    setDataPosition(start);
    val->reset(new (std::nothrow) std::vector<bool>());

    status = readBoolVector(val->get());

 if (status != OK) {
        val->reset();
 }

 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::signalRequestIDRFrame() {
 (new AMessage(kWhatRequestIDRFrame, this))->post();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCleanupParser(void) {
 if (!xmlParserInitialized)
 return;

    xmlCleanupCharEncodingHandlers();
#ifdef LIBXML_CATALOG_ENABLED
    xmlCatalogCleanup();
#endif
    xmlDictCleanup();
    xmlCleanupInputCallbacks();
#ifdef LIBXML_OUTPUT_ENABLED
    xmlCleanupOutputCallbacks();
#endif
#ifdef LIBXML_SCHEMAS_ENABLED
    xmlSchemaCleanupTypes();
    xmlRelaxNGCleanupTypes();
#endif
    xmlResetLastError();
    xmlCleanupGlobals();
    xmlCleanupThreads(); /* must be last if called not from the main thread */
    xmlCleanupMemory();
    xmlParserInitialized = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::LoadedState::stateEntered() {
    ALOGV("[%s] Now Loaded", mCodec->mComponentName.c_str());

    mCodec->mPortEOS[kPortIndexInput] =
        mCodec->mPortEOS[kPortIndexOutput] = false;

    mCodec->mInputEOSResult = OK;

    mCodec->mDequeueCounter = 0;
    mCodec->mMetadataBuffersToSubmit = 0;
    mCodec->mRepeatFrameDelayUs = -1ll;
    mCodec->mInputFormat.clear();
    mCodec->mOutputFormat.clear();
    mCodec->mBaseOutputFormat.clear();

 if (mCodec->mShutdownInProgress) {
 bool keepComponentAllocated = mCodec->mKeepComponentAllocated;

        mCodec->mShutdownInProgress = false;
        mCodec->mKeepComponentAllocated = false;

        onShutdown(keepComponentAllocated);
 }
    mCodec->mExplicitShutdown = false;

    mCodec->processDeferredMessages();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MetaData> NuPlayer::GenericSource::getFormatMeta(bool audio) {
    sp<AMessage> msg = new AMessage(kWhatGetFormat, id());
    msg->setInt32("audio", audio);

    sp<AMessage> response;
 void *format;
 status_t err = msg->postAndAwaitResponse(&response);
 if (err == OK && response != NULL) {
        CHECK(response->findPointer("format", &format));
 return (MetaData *)format;
 } else {
 return NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseITunesMetaData(off64_t offset, size_t size) {
 if (size < 4 || size == SIZE_MAX) {
 return ERROR_MALFORMED;
 }

 uint8_t *buffer = new (std::nothrow) uint8_t[size + 1];
 if (buffer == NULL) {
 return ERROR_MALFORMED;
 }
 if (mDataSource->readAt(
                offset, buffer, size) != (ssize_t)size) {
 delete[] buffer;
        buffer = NULL;

 return ERROR_IO;
 }

 uint32_t flags = U32_AT(buffer);

 uint32_t metadataKey = 0;
 char chunk[5];
 MakeFourCCString(mPath[4], chunk);
    ALOGV("meta: %s @ %lld", chunk, offset);
 switch (mPath[4]) {
 case FOURCC(0xa9, 'a', 'l', 'b'):
 {
            metadataKey = kKeyAlbum;
 break;
 }
 case FOURCC(0xa9, 'A', 'R', 'T'):
 {
            metadataKey = kKeyArtist;
 break;
 }
 case FOURCC('a', 'A', 'R', 'T'):
 {
            metadataKey = kKeyAlbumArtist;
 break;
 }
 case FOURCC(0xa9, 'd', 'a', 'y'):
 {
            metadataKey = kKeyYear;
 break;
 }
 case FOURCC(0xa9, 'n', 'a', 'm'):
 {
            metadataKey = kKeyTitle;
 break;
 }
 case FOURCC(0xa9, 'w', 'r', 't'):
 {
            metadataKey = kKeyWriter;
 break;
 }
 case FOURCC('c', 'o', 'v', 'r'):
 {
            metadataKey = kKeyAlbumArt;
 break;
 }
 case FOURCC('g', 'n', 'r', 'e'):
 {
            metadataKey = kKeyGenre;
 break;
 }
 case FOURCC(0xa9, 'g', 'e', 'n'):
 {
            metadataKey = kKeyGenre;
 break;
 }
 case FOURCC('c', 'p', 'i', 'l'):
 {
 if (size == 9 && flags == 21) {
 char tmp[16];
                sprintf(tmp, "%d",
 (int)buffer[size - 1]);

                mFileMetaData->setCString(kKeyCompilation, tmp);
 }
 break;
 }
 case FOURCC('t', 'r', 'k', 'n'):
 {
 if (size == 16 && flags == 0) {
 char tmp[16];
 uint16_t* pTrack = (uint16_t*)&buffer[10];
 uint16_t* pTotalTracks = (uint16_t*)&buffer[12];
                sprintf(tmp, "%d/%d", ntohs(*pTrack), ntohs(*pTotalTracks));

                mFileMetaData->setCString(kKeyCDTrackNumber, tmp);
 }
 break;
 }
 case FOURCC('d', 'i', 's', 'k'):
 {
 if ((size == 14 || size == 16) && flags == 0) {
 char tmp[16];
 uint16_t* pDisc = (uint16_t*)&buffer[10];
 uint16_t* pTotalDiscs = (uint16_t*)&buffer[12];
                sprintf(tmp, "%d/%d", ntohs(*pDisc), ntohs(*pTotalDiscs));

                mFileMetaData->setCString(kKeyDiscNumber, tmp);
 }
 break;
 }
 case FOURCC('-', '-', '-', '-'):
 {
            buffer[size] = '\0';
 switch (mPath[5]) {
 case FOURCC('m', 'e', 'a', 'n'):
                    mLastCommentMean.setTo((const char *)buffer + 4);
 break;
 case FOURCC('n', 'a', 'm', 'e'):
                    mLastCommentName.setTo((const char *)buffer + 4);
 break;
 case FOURCC('d', 'a', 't', 'a'):
 if (size < 8) {
 delete[] buffer;
                        buffer = NULL;
                        ALOGE("b/24346430");
 return ERROR_MALFORMED;
 }
                    mLastCommentData.setTo((const char *)buffer + 8);
 break;
 }

 if ((mLastCommentMean.length() != 0) &&
 (mLastCommentName.length() != 0) &&
 (mLastCommentData.length() != 0)) {

 if (mLastCommentMean == "com.apple.iTunes"
 && mLastCommentName == "iTunSMPB") {
 int32_t delay, padding;
 if (sscanf(mLastCommentData,
 " %*x %x %x %*x", &delay, &padding) == 2) {
                        mLastTrack->meta->setInt32(kKeyEncoderDelay, delay);
                        mLastTrack->meta->setInt32(kKeyEncoderPadding, padding);
 }
 }

                mLastCommentMean.clear();
                mLastCommentName.clear();
                mLastCommentData.clear();
 }
 break;
 }

 default:
 break;
 }

 if (size >= 8 && metadataKey && !mFileMetaData->hasData(metadataKey)) {
 if (metadataKey == kKeyAlbumArt) {
            mFileMetaData->setData(
                    kKeyAlbumArt, MetaData::TYPE_NONE,
                    buffer + 8, size - 8);
 } else if (metadataKey == kKeyGenre) {
 if (flags == 0) {
 int genrecode = (int)buffer[size - 1];
                genrecode--;
 if (genrecode < 0) {
                    genrecode = 255; // reserved for 'unknown genre'
 }
 char genre[10];
                sprintf(genre, "%d", genrecode);

                mFileMetaData->setCString(metadataKey, genre);
 } else if (flags == 1) {
                buffer[size] = '\0';

                mFileMetaData->setCString(
                        metadataKey, (const char *)buffer + 8);
 }
 } else {
            buffer[size] = '\0';

            mFileMetaData->setCString(
                    metadataKey, (const char *)buffer + 8);
 }
 }

 delete[] buffer;
    buffer = NULL;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BT_HDR* avrc_proc_vendor_command(uint8_t handle, uint8_t label,
                                        BT_HDR* p_pkt,
                                        tAVRC_MSG_VENDOR* p_msg) {
  BT_HDR* p_rsp = NULL;
 uint8_t* p_data;
 uint8_t* p_begin;
 uint8_t pkt_type;
 bool abort_frag = false;
  tAVRC_STS status = AVRC_STS_NO_ERROR;
  tAVRC_FRAG_CB* p_fcb;

  p_begin = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
  p_data = p_begin + AVRC_VENDOR_HDR_SIZE;
  pkt_type = *(p_data + 1) & AVRC_PKT_TYPE_MASK;

 if (pkt_type != AVRC_PKT_SINGLE) {
 /* reject - commands can only be in single packets at AVRCP level */
    AVRC_TRACE_ERROR("commands must be in single packet pdu:0x%x", *p_data);
 /* use the current GKI buffer to send the reject */
    status = AVRC_STS_BAD_CMD;
 }
 /* check if there are fragments waiting to be sent */
 else if (avrc_cb.fcb[handle].frag_enabled) {
    p_fcb = &avrc_cb.fcb[handle];
 if (p_msg->company_id == AVRC_CO_METADATA) {
 switch (*p_data) {
 case AVRC_PDU_ABORT_CONTINUATION_RSP:
 /* aborted by CT - send accept response */
          abort_frag = true;
          p_begin = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
 *p_begin = (AVRC_RSP_ACCEPT & AVRC_CTYPE_MASK);
 if (*(p_data + 4) != p_fcb->frag_pdu) {
 *p_begin = (AVRC_RSP_REJ & AVRC_CTYPE_MASK);
 *(p_data + 4) = AVRC_STS_BAD_PARAM;
 } else {
            p_data = (p_begin + AVRC_VENDOR_HDR_SIZE + 2);
            UINT16_TO_BE_STREAM(p_data, 0);
            p_pkt->len = (p_data - p_begin);
 }
          AVCT_MsgReq(handle, label, AVCT_RSP, p_pkt);
          p_msg->hdr.opcode =
              AVRC_OP_DROP; /* used the p_pkt to send response */
 break;

 case AVRC_PDU_REQUEST_CONTINUATION_RSP:
 if (*(p_data + 4) == p_fcb->frag_pdu) {
            avrc_send_continue_frag(handle, label);
            p_msg->hdr.opcode = AVRC_OP_DROP_N_FREE;
 } else {
 /* the pdu id does not match - reject the command using the current
             * GKI buffer */
            AVRC_TRACE_ERROR(
 "%s continue pdu: 0x%x does not match the current pdu: 0x%x",
                __func__, *(p_data + 4), p_fcb->frag_pdu);
            status = AVRC_STS_BAD_PARAM;
            abort_frag = true;
 }
 break;

 default:
 /* implicit abort */
          abort_frag = true;
 }
 } else {
      abort_frag = true;
 /* implicit abort */
 }

 if (abort_frag) {
      osi_free_and_reset((void**)&p_fcb->p_fmsg);
      p_fcb->frag_enabled = false;
 }
 }

 if (status != AVRC_STS_NO_ERROR) {
    p_rsp = (BT_HDR*)osi_malloc(BT_DEFAULT_BUFFER_SIZE);
    p_rsp->offset = p_pkt->offset;
    p_data = (uint8_t*)(p_rsp + 1) + p_pkt->offset;
 *p_data++ = AVRC_RSP_REJ;
    p_data += AVRC_VENDOR_HDR_SIZE; /* pdu */
 *p_data++ = 0; /* pkt_type */
    UINT16_TO_BE_STREAM(p_data, 1); /* len */
 *p_data++ = status; /* error code */
    p_rsp->len = AVRC_VENDOR_HDR_SIZE + 5;
 }

 return p_rsp;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void WriteOutput(FILE *fid, u8 *data, u32 picSize)
{
    fwrite(data, 1, picSize, fid);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modifier_encoding_iterate(png_modifier *pm)
{
 if (!pm->repeat && /* Else something needs the current encoding again. */
      pm->test_uses_encoding) /* Some transform is encoding dependent */
 {
 if (pm->test_exhaustive)
 {
 if (++pm->encoding_counter >= modifier_total_encodings(pm))
            pm->encoding_counter = 0; /* This will stop the repeat */
 }

 else
 {
 /* Not exhaustive - choose an encoding at random; generate a number in
          * the range 1..(max-1), so the result is always non-zero:
          */
 if (pm->encoding_counter == 0)
            pm->encoding_counter = random_mod(modifier_total_encodings(pm)-1)+1;
 else
            pm->encoding_counter = 0;
 }

 if (pm->encoding_counter > 0)
         pm->repeat = 1;
 }

 else if (!pm->repeat)
      pm->encoding_counter = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void h264bsdSampleAspectRatio(storage_t *pStorage, u32 *sarWidth, u32 *sarHeight)
{

/* Variables */
    u32 w = 1;
    u32 h = 1;
/* Code */

    ASSERT(pStorage);


 if (pStorage->activeSps &&
        pStorage->activeSps->vuiParametersPresentFlag &&
        pStorage->activeSps->vuiParameters &&
        pStorage->activeSps->vuiParameters->aspectRatioPresentFlag )
 {
 switch (pStorage->activeSps->vuiParameters->aspectRatioIdc)
 {
 case ASPECT_RATIO_UNSPECIFIED:  w = 0; h = 0; break;
 case ASPECT_RATIO_1_1:          w = 1; h = 1; break;
 case ASPECT_RATIO_12_11:        w = 12; h = 11; break;
 case ASPECT_RATIO_10_11:        w = 10; h = 11; break;
 case ASPECT_RATIO_16_11:        w = 16; h = 11; break;
 case ASPECT_RATIO_40_33:        w = 40; h = 33; break;
 case ASPECT_RATIO_24_11:        w = 24; h = 11; break;
 case ASPECT_RATIO_20_11:        w = 20; h = 11; break;
 case ASPECT_RATIO_32_11:        w = 32; h = 11; break;
 case ASPECT_RATIO_80_33:        w = 80; h = 33; break;
 case ASPECT_RATIO_18_11:        w = 18; h = 11; break;
 case ASPECT_RATIO_15_11:        w = 15; h = 11; break;
 case ASPECT_RATIO_64_33:        w = 64; h = 33; break;
 case ASPECT_RATIO_160_99:       w = 160; h = 99; break;
 case ASPECT_RATIO_EXTENDED_SAR:
                w = pStorage->activeSps->vuiParameters->sarWidth;
                h = pStorage->activeSps->vuiParameters->sarHeight;
 if ((w == 0) || (h == 0))
                    w = h = 0;
 break;
 default:
                w = 0;
                h = 0;
 break;
 }
 }

 /* set aspect ratio*/
 *sarWidth = w;
 *sarHeight = h;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t OMXNodeInstance::storeMetaDataInBuffers_l(
         OMX_U32 portIndex, OMX_BOOL enable, MetadataBufferType *type) {
     if (portIndex != kPortIndexInput && portIndex != kPortIndexOutput) {
         android_errorWriteLog(0x534e4554, "26324358");
         if (type != NULL) {
 *type = kMetadataBufferTypeInvalid;
 }
 return BAD_VALUE;
 }

    OMX_INDEXTYPE index;
    OMX_STRING name = const_cast<OMX_STRING>(
 "OMX.google.android.index.storeMetaDataInBuffers");

    OMX_STRING nativeBufferName = const_cast<OMX_STRING>(
 "OMX.google.android.index.storeANWBufferInMetadata");
 MetadataBufferType negotiatedType;
 MetadataBufferType requestedType = type != NULL ? *type : kMetadataBufferTypeANWBuffer;

 StoreMetaDataInBuffersParams params;
 InitOMXParams(&params);
    params.nPortIndex = portIndex;
    params.bStoreMetaData = enable;

    OMX_ERRORTYPE err =
        requestedType == kMetadataBufferTypeANWBuffer
 ? OMX_GetExtensionIndex(mHandle, nativeBufferName, &index)
 : OMX_ErrorUnsupportedIndex;
    OMX_ERRORTYPE xerr = err;
 if (err == OMX_ErrorNone) {
        err = OMX_SetParameter(mHandle, index, &params);
 if (err == OMX_ErrorNone) {
            name = nativeBufferName; // set name for debugging
            negotiatedType = requestedType;
 }
 }
 if (err != OMX_ErrorNone) {
        err = OMX_GetExtensionIndex(mHandle, name, &index);
        xerr = err;
 if (err == OMX_ErrorNone) {
            negotiatedType =
                requestedType == kMetadataBufferTypeANWBuffer
 ? kMetadataBufferTypeGrallocSource : requestedType;
            err = OMX_SetParameter(mHandle, index, &params);
 }
 }

 if (err != OMX_ErrorNone) {
 if (err == OMX_ErrorUnsupportedIndex && portIndex == kPortIndexOutput) {
            CLOGW("component does not support metadata mode; using fallback");
 } else if (xerr != OMX_ErrorNone) {
            CLOG_ERROR(getExtensionIndex, xerr, "%s", name);
 } else {
            CLOG_ERROR(setParameter, err, "%s(%#x): %s:%u en=%d type=%d", name, index,
                    portString(portIndex), portIndex, enable, negotiatedType);
 }
        negotiatedType = mMetadataType[portIndex];
 } else {
 if (!enable) {
            negotiatedType = kMetadataBufferTypeInvalid;
 }
        mMetadataType[portIndex] = negotiatedType;
 }
    CLOG_CONFIG(storeMetaDataInBuffers, "%s:%u %srequested %s:%d negotiated %s:%d",
            portString(portIndex), portIndex, enable ? "" : "UN",
            asString(requestedType), requestedType, asString(negotiatedType), negotiatedType);

 if (type != NULL) {
 *type = negotiatedType;
 }

 return StatusFromOMXError(err);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_next_start_code(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    ps_stream = &ps_dec->s_bit_stream;
    impeg2d_bit_stream_flush_to_byte_boundary(ps_stream);

 while ((impeg2d_bit_stream_nxt(ps_stream,START_CODE_PREFIX_LEN) != START_CODE_PREFIX)
 && (ps_dec->s_bit_stream.u4_offset < ps_dec->s_bit_stream.u4_max_offset))
 {
        impeg2d_bit_stream_get(ps_stream,8);
 }
 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_sec_encrypt_change (UINT16 handle, UINT8 status, UINT8 encr_enable)
{
    tBTM_SEC_DEV_REC  *p_dev_rec = btm_find_dev_by_handle (handle);
#if BLE_INCLUDED == TRUE && SMP_INCLUDED == TRUE
    tACL_CONN       *p_acl = NULL;
    UINT8           acl_idx = btm_handle_to_acl_index(handle);
#endif
    BTM_TRACE_EVENT ("Security Manager: encrypt_change status:%d State:%d, encr_enable = %d",
                      status, (p_dev_rec) ? p_dev_rec->sec_state : 0, encr_enable);
    BTM_TRACE_DEBUG ("before update p_dev_rec->sec_flags=0x%x", (p_dev_rec) ? p_dev_rec->sec_flags : 0 );

 /* For transaction collision we need to wait and repeat.  There is no need */
 /* for random timeout because only slave should receive the result */
 if ((status == HCI_ERR_LMP_ERR_TRANS_COLLISION) || (status == HCI_ERR_DIFF_TRANSACTION_COLLISION))
 {
        btm_sec_auth_collision(handle);
 return;
 }
    btm_cb.collision_start_time = 0;

 if (!p_dev_rec)
 return;

 if ((status == HCI_SUCCESS) && encr_enable)
 {
 if (p_dev_rec->hci_handle == handle)
            p_dev_rec->sec_flags |= (BTM_SEC_AUTHENTICATED | BTM_SEC_ENCRYPTED);
 else
            p_dev_rec->sec_flags |= (BTM_SEC_LE_AUTHENTICATED | BTM_SEC_LE_ENCRYPTED);
 }

 /* It is possible that we decrypted the link to perform role switch */
 /* mark link not to be encrypted, so that when we execute security next time it will kick in again */
 if ((status == HCI_SUCCESS) && !encr_enable)
 {
 if (p_dev_rec->hci_handle == handle)
            p_dev_rec->sec_flags &= ~BTM_SEC_ENCRYPTED;
 else
            p_dev_rec->sec_flags &= ~BTM_SEC_LE_ENCRYPTED;
 }

    BTM_TRACE_DEBUG ("after update p_dev_rec->sec_flags=0x%x", p_dev_rec->sec_flags );

#if BLE_INCLUDED == TRUE && SMP_INCLUDED == TRUE
 if (acl_idx != MAX_L2CAP_LINKS )
        p_acl = &btm_cb.acl_db[acl_idx];

 if (p_acl && p_acl->transport == BT_TRANSPORT_LE)
 {
 if (status == HCI_ERR_KEY_MISSING || status == HCI_ERR_AUTH_FAILURE
 ||status == HCI_ERR_ENCRY_MODE_NOT_ACCEPTABLE)
            p_dev_rec->sec_flags &= ~ (BTM_SEC_LE_LINK_KEY_KNOWN);
        btm_ble_link_encrypted(p_dev_rec->bd_addr, encr_enable);
 return;
 }
 else
 /* BR/EDR connection, update the encryption key size to be 16 as always */
        p_dev_rec->enc_key_size = 16;
#endif

 /* If this encryption was started by peer do not need to do anything */
 if (p_dev_rec->sec_state != BTM_SEC_STATE_ENCRYPTING)
 {
 if (BTM_SEC_STATE_DELAY_FOR_ENC == p_dev_rec->sec_state)
 {
            p_dev_rec->sec_state = BTM_SEC_STATE_IDLE;
            p_dev_rec->p_callback = NULL;
            l2cu_resubmit_pending_sec_req (p_dev_rec->bd_addr);
 }
 return;
 }

    p_dev_rec->sec_state = BTM_SEC_STATE_IDLE;

 /* If encryption setup failed, notify the waiting layer */
 if (status != HCI_SUCCESS)
 {
        btm_sec_dev_rec_cback_event (p_dev_rec, BTM_ERR_PROCESSING, FALSE);
 return;
 }

 /* Encryption setup succeeded, execute the next security procedure, if any */
    status = (UINT8)btm_sec_execute_procedure (p_dev_rec);

 /* If there is no next procedure, or procedure failed to start, notify the caller */
 if (status != BTM_CMD_STARTED)
        btm_sec_dev_rec_cback_event (p_dev_rec, status, FALSE);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::DispatchEntry::~DispatchEntry() {
    eventEntry->release();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void EncoderTest::InitializeConfig() {
   const vpx_codec_err_t res = codec_->DefaultEncoderConfig(&cfg_, 0);
   ASSERT_EQ(VPX_CODEC_OK, res);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_pre_pic_dec_proc(dec_state_t *ps_dec)
{
    WORD32 u4_get_disp;
 pic_buf_t *ps_disp_pic;
    IMPEG2D_ERROR_CODES_T e_error = (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;

    u4_get_disp = 0;
    ps_disp_pic = NULL;

 /* Field Picture */
 if(ps_dec->u2_picture_structure != FRAME_PICTURE)
 {
        ps_dec->u2_num_vert_mb       = (ps_dec->u2_vertical_size + 31) >> 5;

 if(ps_dec->u2_num_flds_decoded == 0)
 {
 pic_buf_t *ps_pic_buf;
            u4_get_disp = 1;

            ps_pic_buf = impeg2_buf_mgr_get_next_free(ps_dec->pv_pic_buf_mg, &ps_dec->i4_cur_buf_id);

 if (NULL == ps_pic_buf)
 {
 return IMPEG2D_NO_FREE_BUF_ERR;
 }

            impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, BUF_MGR_DISP);
            impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, BUF_MGR_REF);
 if(ps_dec->u4_deinterlace)
                impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, MPEG2_BUF_MGR_DEINT);

            ps_pic_buf->u4_ts = ps_dec->u4_inp_ts;
            ps_pic_buf->e_pic_type = ps_dec->e_pic_type;
            ps_dec->ps_cur_pic = ps_pic_buf;
            ps_dec->s_cur_frm_buf.pu1_y = ps_pic_buf->pu1_y;
            ps_dec->s_cur_frm_buf.pu1_u = ps_pic_buf->pu1_u;
            ps_dec->s_cur_frm_buf.pu1_v = ps_pic_buf->pu1_v;
 }

 if(ps_dec->u2_picture_structure == TOP_FIELD)
 {
            ps_dec->u2_fld_parity = TOP;
 }
 else
 {
            ps_dec->u2_fld_parity = BOTTOM;
 }
        ps_dec->u2_field_dct           = 0;
        ps_dec->u2_read_dct_type        = 0;
        ps_dec->u2_read_motion_type     = 1;
        ps_dec->u2_fld_pic             = 1;
        ps_dec->u2_frm_pic             = 0;
        ps_dec->ps_func_forw_or_back     = gas_impeg2d_func_fld_fw_or_bk;
        ps_dec->ps_func_bi_direct       = gas_impeg2d_func_fld_bi_direct;
 }
 /* Frame Picture */
 else
 {
 pic_buf_t *ps_pic_buf;


        ps_dec->u2_num_vert_mb       = (ps_dec->u2_vertical_size + 15) >> 4;
        u4_get_disp = 1;
        ps_pic_buf = impeg2_buf_mgr_get_next_free(ps_dec->pv_pic_buf_mg, &ps_dec->i4_cur_buf_id);

 if (NULL == ps_pic_buf)
 {
 return IMPEG2D_NO_FREE_BUF_ERR;
 }
        impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, BUF_MGR_DISP);
        impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, BUF_MGR_REF);
 if(ps_dec->u4_deinterlace)
            impeg2_buf_mgr_set_status((buf_mgr_t *)ps_dec->pv_pic_buf_mg, ps_dec->i4_cur_buf_id, MPEG2_BUF_MGR_DEINT);

        ps_pic_buf->u4_ts = ps_dec->u4_inp_ts;
        ps_pic_buf->e_pic_type = ps_dec->e_pic_type;
        ps_dec->ps_cur_pic = ps_pic_buf;
        ps_dec->s_cur_frm_buf.pu1_y = ps_pic_buf->pu1_y;
        ps_dec->s_cur_frm_buf.pu1_u = ps_pic_buf->pu1_u;
        ps_dec->s_cur_frm_buf.pu1_v = ps_pic_buf->pu1_v;


 if(ps_dec->u2_frame_pred_frame_dct == 0)
 {
            ps_dec->u2_read_dct_type    = 1;
            ps_dec->u2_read_motion_type = 1;
 }
 else
 {
            ps_dec->u2_read_dct_type    = 0;
            ps_dec->u2_read_motion_type = 0;
            ps_dec->u2_motion_type     = 2;
            ps_dec->u2_field_dct       = 0;
 }

        ps_dec->u2_fld_parity          = TOP;
        ps_dec->u2_fld_pic             = 0;
        ps_dec->u2_frm_pic             = 1;
        ps_dec->ps_func_forw_or_back     = gas_impeg2d_func_frm_fw_or_bk;
        ps_dec->ps_func_bi_direct       = gas_impeg2d_func_frm_bi_direct;
 }
    ps_dec->u2_def_dc_pred[Y_LUMA] = 128 << ps_dec->u2_intra_dc_precision;
    ps_dec->u2_def_dc_pred[U_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
    ps_dec->u2_def_dc_pred[V_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
    ps_dec->u2_num_mbs_left  = ps_dec->u2_num_horiz_mb * ps_dec->u2_num_vert_mb;
 if(u4_get_disp)
 {
 if(ps_dec->u4_num_frames_decoded > 1)
 {
            ps_disp_pic = impeg2_disp_mgr_get(&ps_dec->s_disp_mgr, &ps_dec->i4_disp_buf_id);
 }
        ps_dec->ps_disp_pic = ps_disp_pic;
 if(ps_disp_pic)
 {
 if(1 == ps_dec->u4_share_disp_buf)
 {
                ps_dec->ps_disp_frm_buf->pv_y_buf  = ps_disp_pic->pu1_y;
 if(IV_YUV_420P == ps_dec->i4_chromaFormat)
 {
                    ps_dec->ps_disp_frm_buf->pv_u_buf  = ps_disp_pic->pu1_u;
                    ps_dec->ps_disp_frm_buf->pv_v_buf  = ps_disp_pic->pu1_v;
 }
 else
 {
                    UWORD8 *pu1_buf;

                    pu1_buf = ps_dec->as_disp_buffers[ps_disp_pic->i4_buf_id].pu1_bufs[1];
                    ps_dec->ps_disp_frm_buf->pv_u_buf  = pu1_buf;

                    pu1_buf = ps_dec->as_disp_buffers[ps_disp_pic->i4_buf_id].pu1_bufs[2];
                    ps_dec->ps_disp_frm_buf->pv_v_buf  = pu1_buf;
 }
 }
 }
 }


 switch(ps_dec->e_pic_type)
 {
 case I_PIC:
 {
            ps_dec->pf_decode_slice = impeg2d_dec_i_slice;
 break;
 }
 case D_PIC:
 {
            ps_dec->pf_decode_slice = impeg2d_dec_d_slice;
 break;
 }
 case P_PIC:
 {
            ps_dec->pf_decode_slice = impeg2d_dec_p_b_slice;
            ps_dec->pu2_mb_type       = gau2_impeg2d_p_mb_type;
 break;
 }
 case B_PIC:
 {
            ps_dec->pf_decode_slice = impeg2d_dec_p_b_slice;
            ps_dec->pu2_mb_type       = gau2_impeg2d_b_mb_type;
 break;
 }
 default:
 return IMPEG2D_INVALID_PIC_TYPE;
 }

 /*************************************************************************/
 /* Set the reference pictures                                            */
 /*************************************************************************/

 /* Error resilience: If forward and backward pictures are going to be NULL*/
 /* then assign both to the current                                        */
 /* if one of them NULL then we will assign the non null to the NULL one   */

 if(ps_dec->e_pic_type == P_PIC)
 {
 if (NULL == ps_dec->as_recent_fld[1][0].pu1_y)
 {
            ps_dec->as_recent_fld[1][0] = ps_dec->s_cur_frm_buf;
 }
 if (NULL == ps_dec->as_recent_fld[1][1].pu1_y)
 {
            impeg2d_get_bottom_field_buf(&ps_dec->s_cur_frm_buf, &ps_dec->as_recent_fld[1][1],
                ps_dec->u2_frame_width);
 }

        ps_dec->as_ref_buf[FORW][TOP] = ps_dec->as_recent_fld[1][0];
        ps_dec->as_ref_buf[FORW][BOTTOM] = ps_dec->as_recent_fld[1][1];


 }
 else if(ps_dec->e_pic_type == B_PIC)
 {
 if((NULL == ps_dec->as_recent_fld[1][0].pu1_y) && (NULL == ps_dec->as_recent_fld[0][0].pu1_y))
 {
            ps_dec->as_recent_fld[1][0] = ps_dec->s_cur_frm_buf;
            impeg2d_get_bottom_field_buf(&ps_dec->s_cur_frm_buf, &ps_dec->as_recent_fld[1][1],
                ps_dec->u2_frame_width);
            ps_dec->as_recent_fld[0][0] = ps_dec->s_cur_frm_buf;
            ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];
 }
 else if ((NULL != ps_dec->as_recent_fld[1][0].pu1_y) && (NULL == ps_dec->as_recent_fld[0][0].pu1_y))
 {
            ps_dec->as_recent_fld[0][0] = ps_dec->as_recent_fld[1][0];
            ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];
 }
 else if ((NULL == ps_dec->as_recent_fld[1][0].pu1_y) && (NULL != ps_dec->as_recent_fld[0][0].pu1_y))
 {
            ps_dec->as_recent_fld[1][0] = ps_dec->as_recent_fld[0][0];
            ps_dec->as_recent_fld[1][1] = ps_dec->as_recent_fld[0][1];
 }

 /* Error resilience: If forward and backward pictures are going to be NULL*/
 /* then assign both to the current                                        */
 /* if one of them NULL then we will assign the non null to the NULL one   */

 if((NULL == ps_dec->as_recent_fld[0][1].pu1_y) && (NULL == ps_dec->as_recent_fld[1][1].pu1_y))
 {
            ps_dec->as_recent_fld[1][0] = ps_dec->s_cur_frm_buf;
            impeg2d_get_bottom_field_buf(&ps_dec->s_cur_frm_buf, &ps_dec->as_recent_fld[1][1],
                                         ps_dec->u2_frame_width);
            ps_dec->as_recent_fld[0][0] = ps_dec->s_cur_frm_buf;
            ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];
 }

 else if((NULL == ps_dec->as_recent_fld[0][1].pu1_y) && (NULL != ps_dec->as_recent_fld[1][1].pu1_y))
 {
            ps_dec->as_recent_fld[0][0] = ps_dec->as_recent_fld[1][0];
            ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];
 }

 else if((NULL == ps_dec->as_recent_fld[1][1].pu1_y) && (NULL != ps_dec->as_recent_fld[0][1].pu1_y))
 {
            ps_dec->as_recent_fld[1][0] = ps_dec->as_recent_fld[0][0];
            ps_dec->as_recent_fld[1][1] = ps_dec->as_recent_fld[0][1];
 }
        ps_dec->as_ref_buf[FORW][TOP] = ps_dec->as_recent_fld[0][0];
        ps_dec->as_ref_buf[FORW][BOTTOM] = ps_dec->as_recent_fld[0][1];
        ps_dec->as_ref_buf[BACK][TOP] = ps_dec->as_recent_fld[1][0];
        ps_dec->as_ref_buf[BACK][BOTTOM] = ps_dec->as_recent_fld[1][1];


 }

 return e_error;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: int16_t ReverbGetRoomLevel(ReverbContext *pContext){
 int16_t level;

    LVREV_ControlParams_st    ActiveParams; /* Current control Parameters */
    LVREV_ReturnStatus_en     LvmStatus=LVREV_SUCCESS; /* Function call status */
    LVM_INT32                 CombinedLevel; // Sum of room and reverb level controls

 /* Get the current settings */
 LvmStatus = LVREV_GetControlParameters(pContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVREV_GetControlParameters", "ReverbGetRoomLevel")

 CombinedLevel = (pContext->SavedRoomLevel + pContext->SavedReverbLevel-LVREV_MAX_REVERB_LEVEL);
    level = ReverbConvertLevel(CombinedLevel);


 if(ActiveParams.Level != level){
        ALOGV("\tLVM_ERROR : (ignore at start up) ReverbGetRoomLevel() has wrong level -> %d %d\n",
 ActiveParams.Level, level);
 }

 return pContext->SavedRoomLevel;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int in_add_audio_effect(const struct audio_stream *stream, effect_handle_t effect)
{
    UNUSED(stream);
    UNUSED(effect);

    FNLOG();
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void on_cli_rfc_connect(tBTA_JV_RFCOMM_OPEN *p_open, uint32_t id) {
  pthread_mutex_lock(&slot_lock);

 rfc_slot_t *slot = find_rfc_slot_by_id(id);
 if (!slot)
 goto out;

 if (p_open->status != BTA_JV_SUCCESS) {
    cleanup_rfc_slot(slot);
 goto out;
 }

  slot->rfc_port_handle = BTA_JvRfcommGetPortHdl(p_open->handle);
  memcpy(slot->addr.address, p_open->rem_bda, 6);

 if (send_app_connect_signal(slot->fd, &slot->addr, slot->scn, 0, -1))
    slot->f.connected = true;
 else
    LOG_ERROR("%s unable to send connect completion signal to caller.", __func__);

out:;
  pthread_mutex_unlock(&slot_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int readpng2_init(mainprog_info *mainprog_ptr)
{
    png_structp  png_ptr; /* note:  temporary variables! */
    png_infop  info_ptr;


 
     /* could also replace libpng warning-handler (final NULL), but no need: */
 
    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, mainprog_ptr,
       readpng2_error_handler, readpng2_warning_handler);
     if (!png_ptr)
         return 4;   /* out of memory */

    info_ptr = png_create_info_struct(png_ptr);
 if (!info_ptr) {
        png_destroy_read_struct(&png_ptr, NULL, NULL);
 return 4; /* out of memory */
 }


 /* we could create a second info struct here (end_info), but it's only
     * useful if we want to keep pre- and post-IDAT chunk info separated
     * (mainly for PNG-aware image editors and converters) */


 /* setjmp() must be called in every function that calls a PNG-reading
     * libpng function, unless an alternate error handler was installed--
     * but compatible error handlers must either use longjmp() themselves
     * (as in this program) or exit immediately, so here we are: */

 if (setjmp(mainprog_ptr->jmpbuf)) {
        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);
 return 2;
 }


#ifdef PNG_HANDLE_AS_UNKNOWN_SUPPORTED
 /* prepare the reader to ignore all recognized chunks whose data won't be
     * used, i.e., all chunks recognized by libpng except for IHDR, PLTE, IDAT,
     * IEND, tRNS, bKGD, gAMA, and sRGB (small performance improvement) */
 {
 /* These byte strings were copied from png.h.  If a future version
         * of readpng2.c recognizes more chunks, add them to this list.
         */
 static PNG_CONST png_byte chunks_to_process[] = {
 98, 75, 71, 68, '\0', /* bKGD */
 103, 65, 77, 65, '\0', /* gAMA */
 115, 82, 71, 66, '\0', /* sRGB */
 };

 /* Ignore all chunks except for IHDR, PLTE, tRNS, IDAT, and IEND */
       png_set_keep_unknown_chunks(png_ptr, -1 /* PNG_HANDLE_CHUNK_NEVER */,
          NULL, -1);

 /* But do not ignore chunks in the "chunks_to_process" list */
       png_set_keep_unknown_chunks(png_ptr,
 0 /* PNG_HANDLE_CHUNK_AS_DEFAULT */, chunks_to_process,
 sizeof(chunks_to_process)/5);
 }
#endif /* PNG_HANDLE_AS_UNKNOWN_SUPPORTED */


 /* instead of doing png_init_io() here, now we set up our callback
     * functions for progressive decoding */

    png_set_progressive_read_fn(png_ptr, mainprog_ptr,
      readpng2_info_callback, readpng2_row_callback, readpng2_end_callback);


 /* make sure we save our pointers for use in readpng2_decode_data() */

    mainprog_ptr->png_ptr = png_ptr;
    mainprog_ptr->info_ptr = info_ptr;


 /* and that's all there is to initialization */

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ihevcd_parse_sei_payload(codec_t *ps_codec,
                              UWORD32 u4_payload_type,
                              UWORD32 u4_payload_size,
                              WORD8 i1_nal_type)
{
 parse_ctxt_t *ps_parse = &ps_codec->s_parse;
 bitstrm_t *ps_bitstrm = &ps_parse->s_bitstrm;
    WORD32 payload_bits_remaining = 0;
 sps_t *ps_sps;

    UWORD32 i;

 for(i = 0; i < MAX_SPS_CNT; i++)
 {
        ps_sps = ps_codec->ps_sps_base + i;
 if(ps_sps->i1_sps_valid)
 {
 break;
 }
 }
 if(NULL == ps_sps)
 {
 return;
 }

 if(NAL_PREFIX_SEI == i1_nal_type)
 {
 switch(u4_payload_type)
 {
 case SEI_BUFFERING_PERIOD:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_buffering_period_sei(ps_codec, ps_sps);
 break;

 case SEI_PICTURE_TIMING:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_pic_timing_sei(ps_codec, ps_sps);
 break;

 case SEI_TIME_CODE:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_time_code_sei(ps_codec);
 break;

 case SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
                ps_parse->s_sei_params.i4_sei_mastering_disp_colour_vol_params_present_flags = 1;
                ihevcd_parse_mastering_disp_params_sei(ps_codec);
 break;

 
             case SEI_USER_DATA_REGISTERED_ITU_T_T35:
                 ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_user_data_registered_itu_t_t35(ps_codec,
                                                            u4_payload_size);
                 break;
 
             default:
 for(i = 0; i < u4_payload_size; i++)
 {
                    ihevcd_bits_flush(ps_bitstrm, 8);
 }
 break;
 }
 }
 else /* NAL_SUFFIX_SEI */
 {
 switch(u4_payload_type)

         {
             case SEI_USER_DATA_REGISTERED_ITU_T_T35:
                 ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_user_data_registered_itu_t_t35(ps_codec,
                                                            u4_payload_size);
                 break;
 
             default:
 for(i = 0; i < u4_payload_size; i++)
 {
                    ihevcd_bits_flush(ps_bitstrm, 8);
 }
 break;
 }
 }

 /**
     * By definition the underlying bitstream terminates in a byte-aligned manner.
     * 1. Extract all bar the last MIN(bitsremaining,nine) bits as reserved_payload_extension_data
     * 2. Examine the final 8 bits to determine the payload_bit_equal_to_one marker
     * 3. Extract the remainingreserved_payload_extension_data bits.
     *
     * If there are fewer than 9 bits available, extract them.
     */

    payload_bits_remaining = ihevcd_bits_num_bits_remaining(ps_bitstrm);
 if(payload_bits_remaining) /* more_data_in_payload() */
 {
        WORD32 final_bits;
        WORD32 final_payload_bits = 0;
        WORD32 mask = 0xFF;
        UWORD32 u4_dummy;
        UWORD32 u4_reserved_payload_extension_data;
        UNUSED(u4_dummy);
        UNUSED(u4_reserved_payload_extension_data);

 while(payload_bits_remaining > 9)
 {
            BITS_PARSE("reserved_payload_extension_data",
                       u4_reserved_payload_extension_data, ps_bitstrm, 1);
            payload_bits_remaining--;
 }

        final_bits = ihevcd_bits_nxt(ps_bitstrm, payload_bits_remaining);

 while(final_bits & (mask >> final_payload_bits))
 {
            final_payload_bits++;
 continue;
 }

 while(payload_bits_remaining > (9 - final_payload_bits))
 {
            BITS_PARSE("reserved_payload_extension_data",
                       u4_reserved_payload_extension_data, ps_bitstrm, 1);
            payload_bits_remaining--;
 }

        BITS_PARSE("payload_bit_equal_to_one", u4_dummy, ps_bitstrm, 1);
        payload_bits_remaining--;
 while(payload_bits_remaining)
 {
            BITS_PARSE("payload_bit_equal_to_zero", u4_dummy, ps_bitstrm, 1);
            payload_bits_remaining--;
 }
 }

 return;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: internalRequestTimedCallback (RIL_TimedCallback callback, void *param,
 const struct timeval *relativeTime)
{
 struct timeval myRelativeTime;
 UserCallbackInfo *p_info;

    p_info = (UserCallbackInfo *) calloc(1, sizeof(UserCallbackInfo));
 if (p_info == NULL) {
        RLOGE("Memory allocation failed in internalRequestTimedCallback");
 return p_info;

 }

    p_info->p_callback = callback;
    p_info->userParam = param;

 if (relativeTime == NULL) {
 /* treat null parameter as a 0 relative time */
        memset (&myRelativeTime, 0, sizeof(myRelativeTime));
 } else {
 /* FIXME I think event_add's tv param is really const anyway */
        memcpy (&myRelativeTime, relativeTime, sizeof(myRelativeTime));
 }

    ril_event_set(&(p_info->event), -1, false, userTimerCallback, p_info);

    ril_timer_add(&(p_info->event), &myRelativeTime);

    triggerEvLoop();
 return p_info;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_nctb_cnt(codec_t *ps_codec, sps_t *ps_sps)
{
    WORD32 nctb = 1;
    UNUSED(ps_codec);
 /* If CTB size is less than 32 x 32 then set nCTB as 4 */
 if(ps_sps->i1_log2_ctb_size < 5)
        nctb = 1;

 return nctb;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual int create() {
 int ret;

 if(feature_type == FEATURE_SET) {
            ret = mMsg.create(GOOGLE_OUI, WIFI_SUBCMD_GET_FEATURE_SET);
 } else if (feature_type == FEATURE_SET_MATRIX) {
            ret = mMsg.create(GOOGLE_OUI, WIFI_SUBCMD_GET_FEATURE_SET_MATRIX);
 } else {
            ALOGE("Unknown feature type %d", feature_type);
 return -1;
 }

 if (ret < 0) {
            ALOGE("Can't create message to send to driver - %d", ret);
 }

 return ret;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_hl_proc_dch_cong_ind(tBTA_HL *p_data)

{
 btif_hl_mdl_cb_t *p_dcb;
    UINT8                   app_idx, mcl_idx, mdl_idx;

    BTIF_TRACE_DEBUG("btif_hl_proc_dch_cong_ind");


 if (btif_hl_find_mdl_idx_using_handle(p_data->dch_cong_ind.mdl_handle, &app_idx, &mcl_idx, &mdl_idx))
 {
        p_dcb =BTIF_HL_GET_MDL_CB_PTR(app_idx, mcl_idx, mdl_idx);
        p_dcb->cong = p_data->dch_cong_ind.cong;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int32_t DownmixLib_Create(const effect_uuid_t *uuid,
        int32_t sessionId,
        int32_t ioId,
         effect_handle_t *pHandle) {
     int ret;
     int i;
 downmix_module_t *module;
 const effect_descriptor_t *desc;

    ALOGV("DownmixLib_Create()");

#ifdef DOWNMIX_TEST_CHANNEL_INDEX
    ALOGI("DOWNMIX_TEST_CHANNEL_INDEX: should work:");
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                    AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_BACK_CENTER);
 Downmix_testIndexComputation(CHANNEL_MASK_QUAD_SIDE | CHANNEL_MASK_QUAD_BACK);
 Downmix_testIndexComputation(CHANNEL_MASK_5POINT1_SIDE | AUDIO_CHANNEL_OUT_BACK_CENTER);
 Downmix_testIndexComputation(CHANNEL_MASK_5POINT1_BACK | AUDIO_CHANNEL_OUT_BACK_CENTER);
    ALOGI("DOWNMIX_TEST_CHANNEL_INDEX: should NOT work:");
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                        AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_BACK_LEFT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT | AUDIO_CHANNEL_OUT_FRONT_RIGHT |
                            AUDIO_CHANNEL_OUT_LOW_FREQUENCY | AUDIO_CHANNEL_OUT_SIDE_LEFT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT |
                        AUDIO_CHANNEL_OUT_BACK_LEFT | AUDIO_CHANNEL_OUT_BACK_RIGHT);
 Downmix_testIndexComputation(AUDIO_CHANNEL_OUT_FRONT_LEFT |
                            AUDIO_CHANNEL_OUT_SIDE_LEFT | AUDIO_CHANNEL_OUT_SIDE_RIGHT);
#endif

 if (pHandle == NULL || uuid == NULL) {
 return -EINVAL;
 }

 for (i = 0 ; i < kNbEffects ; i++) {
        desc = gDescriptors[i];
 if (memcmp(uuid, &desc->uuid, sizeof(effect_uuid_t)) == 0) {
 break;
 }
 }

 if (i == kNbEffects) {
 return -ENOENT;
 }

    module = malloc(sizeof(downmix_module_t));

    module->itfe = &gDownmixInterface;

    module->context.state = DOWNMIX_STATE_UNINITIALIZED;

    ret = Downmix_Init(module);
 if (ret < 0) {
        ALOGW("DownmixLib_Create() init failed");
        free(module);
 return ret;
 }

 *pHandle = (effect_handle_t) module;

    ALOGV("DownmixLib_Create() %p , size %zu", module, sizeof(downmix_module_t));

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void lock_output_stream(struct stream_out *out)
{
    pthread_mutex_lock(&out->pre_lock);
    pthread_mutex_lock(&out->lock);
    pthread_mutex_unlock(&out->pre_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::Client::setDataSource(
 const sp<IDataSource> &source) {
    sp<DataSource> dataSource = DataSource::CreateFromIDataSource(source);
    player_type playerType = MediaPlayerFactory::getPlayerType(this, dataSource);
    sp<MediaPlayerBase> p = setDataSource_pre(playerType);
 if (p == NULL) {
 return NO_INIT;
 }
    setDataSource_post(p, p->setDataSource(dataSource));
 return mStatus;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_hl_proc_abort_ind(tBTA_HL_MCL_HANDLE mcl_handle){

    BTIF_TRACE_DEBUG("%s", __FUNCTION__ );
 btif_hl_app_cb_t *p_acb;
    UINT8 i,j;

 for (i=0; i<BTA_HL_NUM_APPS; i++)
 {
        p_acb =BTIF_HL_GET_APP_CB_PTR(i);
 for (j=0; j < BTA_HL_NUM_MCLS ; j++)
 {
 if (p_acb->mcb[j].in_use)
                BTIF_TRACE_DEBUG("btif_hl_find_mcl_idx_using_handle: app_idx=%d,mcl_idx =%d mcl_handle=%d",i,j,p_acb->mcb[j].mcl_handle);
 if (p_acb->mcb[j].in_use &&
 (p_acb->mcb[j].mcl_handle == mcl_handle))
 {
                btif_hl_stop_cch_timer(i, j);
                btif_hl_send_setup_disconnected_cb(i, j);
                btif_hl_clean_mcl_cb(i, j);
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int LELib_GetDescriptor(const effect_uuid_t *uuid,
 effect_descriptor_t *pDescriptor) {

 if (pDescriptor == NULL || uuid == NULL){
        ALOGV("LELib_GetDescriptor() called with NULL pointer");
 return -EINVAL;
 }

 if (memcmp(uuid, &gLEDescriptor.uuid, sizeof(effect_uuid_t)) == 0) {
 *pDescriptor = gLEDescriptor;
 return 0;
 }

 return -EINVAL;
} /* end LELib_GetDescriptor */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int find_camera_metadata_ro_entry(const camera_metadata_t *src,
 uint32_t tag,
 camera_metadata_ro_entry_t *entry) {
 return find_camera_metadata_entry((camera_metadata_t*)src, tag,
 (camera_metadata_entry_t*)entry);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectModule::setMode(audio_mode_t mode)
{
 Mutex::Autolock _l(mLock);
 if (mStatus != NO_ERROR) {
 return mStatus;
 }
 status_t status = NO_ERROR;
 if ((mDescriptor.flags & EFFECT_FLAG_AUDIO_MODE_MASK) == EFFECT_FLAG_AUDIO_MODE_IND) {
 status_t cmdStatus;
 uint32_t size = sizeof(status_t);
        status = (*mEffectInterface)->command(mEffectInterface,
                                              EFFECT_CMD_SET_AUDIO_MODE,
 sizeof(audio_mode_t),
 &mode,
 &size,
 &cmdStatus);
 if (status == NO_ERROR) {
            status = cmdStatus;
 }
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ACodec::UninitializedState::onAllocateComponent(const sp<AMessage> &msg) {
    ALOGV("onAllocateComponent");

    CHECK(mCodec->mNode == 0);

 OMXClient client;
 if (client.connect() != OK) {
        mCodec->signalError(OMX_ErrorUndefined, NO_INIT);
 return false;
 }

    sp<IOMX> omx = client.interface();

    sp<AMessage> notify = new AMessage(kWhatOMXDied, mCodec);

    mDeathNotifier = new DeathNotifier(notify);
 if (IInterface::asBinder(omx)->linkToDeath(mDeathNotifier) != OK) {
        mDeathNotifier.clear();
 }

 Vector<OMXCodec::CodecNameAndQuirks> matchingCodecs;

 AString mime;

 AString componentName;
 uint32_t quirks = 0;
 int32_t encoder = false;
 if (msg->findString("componentName", &componentName)) {
 ssize_t index = matchingCodecs.add();
 OMXCodec::CodecNameAndQuirks *entry = &matchingCodecs.editItemAt(index);
        entry->mName = String8(componentName.c_str());

 if (!OMXCodec::findCodecQuirks(
                    componentName.c_str(), &entry->mQuirks)) {
            entry->mQuirks = 0;
 }
 } else {
        CHECK(msg->findString("mime", &mime));

 if (!msg->findInt32("encoder", &encoder)) {
            encoder = false;
 }

 OMXCodec::findMatchingCodecs(
                mime.c_str(),
                encoder, // createEncoder
                NULL, // matchComponentName
 0, // flags
 &matchingCodecs);
 }

    sp<CodecObserver> observer = new CodecObserver;
    IOMX::node_id node = 0;

 status_t err = NAME_NOT_FOUND;
 for (size_t matchIndex = 0; matchIndex < matchingCodecs.size();
 ++matchIndex) {
        componentName = matchingCodecs.itemAt(matchIndex).mName.string();
        quirks = matchingCodecs.itemAt(matchIndex).mQuirks;

 pid_t tid = gettid();
 int prevPriority = androidGetThreadPriority(tid);
        androidSetThreadPriority(tid, ANDROID_PRIORITY_FOREGROUND);
        err = omx->allocateNode(componentName.c_str(), observer, &node);
        androidSetThreadPriority(tid, prevPriority);

 if (err == OK) {
 break;
 } else {
            ALOGW("Allocating component '%s' failed, try next one.", componentName.c_str());
 }

        node = 0;
 }

 if (node == 0) {
 if (!mime.empty()) {
            ALOGE("Unable to instantiate a %scoder for type '%s' with err %#x.",
                    encoder ? "en" : "de", mime.c_str(), err);
 } else {
            ALOGE("Unable to instantiate codec '%s' with err %#x.", componentName.c_str(), err);
 }

        mCodec->signalError((OMX_ERRORTYPE)err, makeNoSideEffectStatus(err));
 return false;
 }

    notify = new AMessage(kWhatOMXMessageList, mCodec);
    observer->setNotificationMessage(notify);

    mCodec->mComponentName = componentName;
    mCodec->mRenderTracker.setComponentName(componentName);
    mCodec->mFlags = 0;

 if (componentName.endsWith(".secure")) {
        mCodec->mFlags |= kFlagIsSecure;
        mCodec->mFlags |= kFlagIsGrallocUsageProtected;
        mCodec->mFlags |= kFlagPushBlankBuffersToNativeWindowOnShutdown;
 }

    mCodec->mQuirks = quirks;
    mCodec->mOMX = omx;
    mCodec->mNode = node;

 {
        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatComponentAllocated);
        notify->setString("componentName", mCodec->mComponentName.c_str());
        notify->post();
 }

    mCodec->changeState(mCodec->mLoadedState);

 return true;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static jobject android_net_wifi_get_rtt_capabilities(JNIEnv *env, jclass cls, jint iface) {

 JNIHelper helper(env);
    wifi_rtt_capabilities rtt_capabilities;
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);
    wifi_error ret = hal_fn.wifi_get_rtt_capabilities(handle, &rtt_capabilities);

 if(WIFI_SUCCESS == ret) {
 JNIObject<jobject> capabilities = helper.createObject(
 "android/net/wifi/RttManager$RttCapabilities");
         helper.setBooleanField(capabilities, "oneSidedRttSupported",
                 rtt_capabilities.rtt_one_sided_supported == 1);
         helper.setBooleanField(capabilities, "twoSided11McRttSupported",
                 rtt_capabilities.rtt_ftm_supported == 1);
         helper.setBooleanField(capabilities, "lciSupported",
                 rtt_capabilities.lci_support);
         helper.setBooleanField(capabilities, "lcrSupported",
                 rtt_capabilities.lcr_support);
         helper.setIntField(capabilities, "preambleSupported",
                 rtt_capabilities.preamble_support);
         helper.setIntField(capabilities, "bwSupported",
                 rtt_capabilities.bw_support);
         ALOGD("One side RTT is: %s", rtt_capabilities.rtt_one_sided_supported ==1 ? "support" :
 "not support");
         ALOGD("Two side RTT is: %s", rtt_capabilities.rtt_ftm_supported == 1 ? "support" :
 "not support");
         ALOGD("LCR is: %s", rtt_capabilities.lcr_support == 1 ? "support" : "not support");

         ALOGD("LCI is: %s", rtt_capabilities.lci_support == 1 ? "support" : "not support");

         ALOGD("Support Preamble is : %d support BW is %d", rtt_capabilities.preamble_support,
                 rtt_capabilities.bw_support);
 return capabilities.detach();
 } else {
 return NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Cluster::GetTime() const {
 const long long tc = GetTimeCode();

 if (tc < 0)
 return tc;

 const SegmentInfo* const pInfo = m_pSegment->GetInfo();
  assert(pInfo);

 const long long scale = pInfo->GetTimeCodeScale();
  assert(scale >= 1);

 const long long t = m_timecode * scale;

 return t;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraClient::connect(const sp<ICameraClient>& client) {
 int callingPid = getCallingPid();
    LOG1("connect E (pid %d)", callingPid);
 Mutex::Autolock lock(mLock);

 if (mClientPid != 0 && checkPid() != NO_ERROR) {
        ALOGW("Tried to connect to a locked camera (old pid %d, new pid %d)",
                mClientPid, callingPid);
 return EBUSY;
 }

 if (mRemoteCallback != 0 &&
 (client->asBinder() == mRemoteCallback->asBinder())) {
        LOG1("Connect to the same client");
 return NO_ERROR;
 }

    mPreviewCallbackFlag = CAMERA_FRAME_CALLBACK_FLAG_NOOP;
    mClientPid = callingPid;
    mRemoteCallback = client;

    LOG1("connect X (pid %d)", callingPid);
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btif_hl_proc_sdp_query_cfm(tBTA_HL *p_data){
 btif_hl_app_cb_t *p_acb;
 btif_hl_mcl_cb_t *p_mcb;
    tBTA_HL_SDP                     *p_sdp;
    tBTA_HL_CCH_OPEN_PARAM          open_param;
    UINT8                           app_idx, mcl_idx, sdp_idx = 0;
    UINT8                           num_recs, i, num_mdeps, j;
 btif_hl_cch_op_t                old_cch_oper;
    BOOLEAN                         status =FALSE;
 btif_hl_pending_chan_cb_t *p_pcb;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

    p_sdp = p_data->sdp_query_cfm.p_sdp;
    num_recs = p_sdp->num_recs;

    BTIF_TRACE_DEBUG("num of SDP records=%d",num_recs);
 for (i=0; i<num_recs; i++)
 {
        BTIF_TRACE_DEBUG("rec_idx=%d ctrl_psm=0x%x data_psm=0x%x",
 (i+1),p_sdp->sdp_rec[i].ctrl_psm, p_sdp->sdp_rec[i].data_psm);
        BTIF_TRACE_DEBUG("MCAP supported procedures=0x%x",p_sdp->sdp_rec[i].mcap_sup_proc);
        num_mdeps = p_sdp->sdp_rec[i].num_mdeps;
        BTIF_TRACE_DEBUG("num of mdeps =%d",num_mdeps);
 for (j=0; j< num_mdeps; j++)
 {
            BTIF_TRACE_DEBUG("mdep_idx=%d mdep_id=0x%x data_type=0x%x mdep_role=0x%x",
 (j+1),
                              p_sdp->sdp_rec[i].mdep_cfg[j].mdep_id,
                              p_sdp->sdp_rec[i].mdep_cfg[j].data_type,
                              p_sdp->sdp_rec[i].mdep_cfg[j].mdep_role );
 }
 }

 if (btif_hl_find_app_idx_using_app_id(p_data->sdp_query_cfm.app_id, &app_idx))
 {
            p_acb = BTIF_HL_GET_APP_CB_PTR(app_idx);

 if (btif_hl_find_mcl_idx(app_idx, p_data->sdp_query_cfm.bd_addr, &mcl_idx))
 {
                p_mcb = BTIF_HL_GET_MCL_CB_PTR(app_idx, mcl_idx);
 if (p_mcb->cch_oper != BTIF_HL_CCH_OP_NONE)
 {
                    memcpy(&p_mcb->sdp, p_sdp, sizeof(tBTA_HL_SDP));
                    old_cch_oper = p_mcb->cch_oper;
                    p_mcb->cch_oper = BTIF_HL_CCH_OP_NONE;

 switch (old_cch_oper)
 {
 case BTIF_HL_CCH_OP_MDEP_FILTERING:
                            status = btif_hl_find_sdp_idx_using_mdep_filter(app_idx,
                                                                    mcl_idx, &sdp_idx);
 break;
 default:
 break;
 }

 if (status)
 {
                        p_mcb->sdp_idx       = sdp_idx;
                        p_mcb->valid_sdp_idx = TRUE;
                        p_mcb->ctrl_psm      = p_mcb->sdp.sdp_rec[sdp_idx].ctrl_psm;

 switch (old_cch_oper)
 {
 case BTIF_HL_CCH_OP_MDEP_FILTERING:
                                p_pcb = BTIF_HL_GET_PCB_PTR(app_idx, mcl_idx);
 if (p_pcb->in_use)
 {
 if (!p_pcb->abort_pending)
 {
 switch (p_pcb->op)
 {
 case BTIF_HL_PEND_DCH_OP_OPEN:
                                                btif_hl_send_setup_connecting_cb(app_idx, mcl_idx);
 break;
 case BTIF_HL_PEND_DCH_OP_DELETE_MDL:
 default:
 break;
 }
                                        open_param.ctrl_psm = p_mcb->ctrl_psm;
                                        bdcpy(open_param.bd_addr, p_mcb->bd_addr);
                                        open_param.sec_mask =
 (BTA_SEC_AUTHENTICATE | BTA_SEC_ENCRYPT);
                                        BTA_HlCchOpen(p_acb->app_id,p_acb->app_handle, &open_param);
 }
 else
 {
                                        BTIF_TRACE_DEBUG("channel abort pending");
 }
 }
 break;

 case BTIF_HL_CCH_OP_DCH_OPEN:
                                status = btif_hl_proc_pending_op(app_idx,mcl_idx);
 break;

 default:
                                BTIF_TRACE_ERROR("Invalid CCH oper %d", old_cch_oper);
 break;
 }
 }
 else
 {
                        BTIF_TRACE_ERROR("Can not find SDP idx discard CCH Open request");
 }
 }
 }
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setVideoPortFormatType(
        OMX_U32 portIndex,
        OMX_VIDEO_CODINGTYPE compressionFormat,
        OMX_COLOR_FORMATTYPE colorFormat,
 bool usingNativeBuffers) {
    OMX_VIDEO_PARAM_PORTFORMATTYPE format;
 InitOMXParams(&format);
    format.nPortIndex = portIndex;
    format.nIndex = 0;
 bool found = false;

    OMX_U32 index = 0;
 for (;;) {
        format.nIndex = index;
 status_t err = mOMX->getParameter(
                mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));

 if (err != OK) {
 return err;
 }

        OMX_U32 flexibleEquivalent;
 if (compressionFormat == OMX_VIDEO_CodingUnused
 && isFlexibleColorFormat(
                        mOMX, mNode, format.eColorFormat, usingNativeBuffers, &flexibleEquivalent)
 && colorFormat == flexibleEquivalent) {
            ALOGI("[%s] using color format %#x in place of %#x",
                    mComponentName.c_str(), format.eColorFormat, colorFormat);
            colorFormat = format.eColorFormat;
 }


 if (!strcmp("OMX.TI.Video.encoder", mComponentName.c_str())) {
 if (portIndex == kPortIndexInput
 && colorFormat == format.eColorFormat) {
                found = true;
 break;
 }
 if (portIndex == kPortIndexOutput
 && compressionFormat == format.eCompressionFormat) {
                found = true;
 break;
 }
 }

 if (format.eCompressionFormat == compressionFormat
 && format.eColorFormat == colorFormat) {
            found = true;
 break;
 }

 ++index;
 }

 if (!found) {
 return UNKNOWN_ERROR;
 }

 status_t err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: EBMLHeader::~EBMLHeader() { delete[] m_docType; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: unsigned int ScaleForFrameNumber(unsigned int frame, unsigned int val) {
 if (frame < 10)
 return val;
 if (frame < 20)
 return val / 2;
 if (frame < 30)
 return val * 2 / 3;
 if (frame < 40)
 return val / 4;
 if (frame < 50)
 return val * 7 / 8;
 return val;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::setGraphicBufferSource(
 const sp<GraphicBufferSource>& bufferSource) {
 Mutex::Autolock autoLock(mGraphicBufferSourceLock);
    CLOG_INTERNAL(setGraphicBufferSource, "%p", bufferSource.get());
    mGraphicBufferSource = bufferSource;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Bool PVDecSetEnhReference(VideoDecControls *decCtrl, uint8 *refYUV, uint32 timestamp)
{
 VideoDecData *video = (VideoDecData *) decCtrl->videoDecoderData;
 Vop *prevEnhcVop = video->prevEnhcVop;
 uint8 *dstPtr, *orgPtr, *dstPtr2, *orgPtr2;
 int32 size = (int32) video->width * video->height;

 if (video->numberOfLayers <= 1)
 return PV_FALSE;


 /* set new parameters */
    prevEnhcVop->timeStamp = timestamp;
    prevEnhcVop->predictionType = I_VOP;

    dstPtr = prevEnhcVop->yChan;
    orgPtr = refYUV;
    oscl_memcpy(dstPtr, orgPtr, size);
    dstPtr = prevEnhcVop->uChan;
    dstPtr2 = prevEnhcVop->vChan;
    orgPtr = refYUV + size;
    orgPtr2 = orgPtr + (size >> 2);
    oscl_memcpy(dstPtr, orgPtr, (size >> 2));
    oscl_memcpy(dstPtr2, orgPtr2, (size >> 2));
    video->concealFrame = video->prevEnhcVop->yChan;
    video->vop_coding_type = I_VOP;
    decCtrl->outputFrame = video->prevEnhcVop->yChan;

 return PV_TRUE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_set_default_params(iv_obj_t *dec_hdl,
 void *pv_api_ip,
 void *pv_api_op)
{

 dec_struct_t * ps_dec;
    WORD32 ret = IV_SUCCESS;

 ivd_ctl_set_config_op_t *ps_ctl_op =
 (ivd_ctl_set_config_op_t *)pv_api_op;
    ps_dec = (dec_struct_t *)(dec_hdl->pv_codec_handle);
    UNUSED(pv_api_ip);


 {
        ps_dec->u4_app_disp_width = 0;
        ps_dec->u4_skip_frm_mask = 0;
        ps_dec->i4_decode_header = 1;

        ps_ctl_op->u4_error_code = 0;
 }


 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::ConfigurationChangedEntry::appendDescription(String8& msg) const {
    msg.append("ConfigurationChangedEvent(), policyFlags=0x%08x",
            policyFlags);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_start_of_pic(dec_struct_t *ps_dec,
                         WORD32 i4_poc,
 pocstruct_t *ps_temp_poc,
                         UWORD16 u2_frame_num,
 dec_pic_params_t *ps_pps)
{
 pocstruct_t *ps_prev_poc = &ps_dec->s_cur_pic_poc;
 pocstruct_t *ps_cur_poc = ps_temp_poc;

 pic_buffer_t *pic_buf;

 ivd_video_decode_op_t * ps_dec_output =
 (ivd_video_decode_op_t *)ps_dec->pv_dec_out;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 dec_seq_params_t *ps_seq = ps_pps->ps_sps;
    UWORD8 u1_bottom_field_flag = ps_cur_slice->u1_bottom_field_flag;
    UWORD8 u1_field_pic_flag = ps_cur_slice->u1_field_pic_flag;
 /* high profile related declarations */
 high_profile_tools_t s_high_profile;
    WORD32 ret;

    H264_MUTEX_LOCK(&ps_dec->process_disp_mutex);

    ps_prev_poc->i4_pic_order_cnt_lsb = ps_cur_poc->i4_pic_order_cnt_lsb;
    ps_prev_poc->i4_pic_order_cnt_msb = ps_cur_poc->i4_pic_order_cnt_msb;
    ps_prev_poc->i4_delta_pic_order_cnt_bottom =
                    ps_cur_poc->i4_delta_pic_order_cnt_bottom;
    ps_prev_poc->i4_delta_pic_order_cnt[0] =
                    ps_cur_poc->i4_delta_pic_order_cnt[0];
    ps_prev_poc->i4_delta_pic_order_cnt[1] =
                    ps_cur_poc->i4_delta_pic_order_cnt[1];
    ps_prev_poc->u1_bot_field = ps_dec->ps_cur_slice->u1_bottom_field_flag;
    ps_prev_poc->i4_prev_frame_num_ofst = ps_cur_poc->i4_prev_frame_num_ofst;
    ps_prev_poc->u2_frame_num = u2_frame_num;
    ps_dec->i1_prev_mb_qp_delta = 0;
    ps_dec->i1_next_ctxt_idx = 0;


    ps_dec->u4_nmb_deblk = 0;
 if(ps_dec->u4_num_cores == 1)
       ps_dec->u4_nmb_deblk = 1;



 if(ps_seq->u1_mb_aff_flag == 1)
 {
        ps_dec->u4_nmb_deblk = 0;
 if(ps_dec->u4_num_cores > 2)
            ps_dec->u4_num_cores = 2;
 }

        ps_dec->u4_use_intrapred_line_copy = 0;



 if (ps_seq->u1_mb_aff_flag == 0)
 {
        ps_dec->u4_use_intrapred_line_copy = 1;
 }

    ps_dec->u4_app_disable_deblk_frm = 0;
 /* If degrade is enabled, set the degrade flags appropriately */
 if(ps_dec->i4_degrade_type && ps_dec->i4_degrade_pics)
 {
        WORD32 degrade_pic;
        ps_dec->i4_degrade_pic_cnt++;
        degrade_pic = 0;

 /* If degrade is to be done in all frames, then do not check further */
 switch(ps_dec->i4_degrade_pics)
 {
 case 4:
 {
                degrade_pic = 1;
 break;
 }
 case 3:
 {
 if(ps_cur_slice->u1_slice_type != I_SLICE)
                    degrade_pic = 1;

 break;
 }
 case 2:
 {

 /* If pic count hits non-degrade interval or it is an islice, then do not degrade */
 if((ps_cur_slice->u1_slice_type != I_SLICE)
 && (ps_dec->i4_degrade_pic_cnt
 != ps_dec->i4_nondegrade_interval))
                    degrade_pic = 1;

 break;
 }
 case 1:
 {
 /* Check if the current picture is non-ref */
 if(0 == ps_cur_slice->u1_nal_ref_idc)
 {
                    degrade_pic = 1;
 }
 break;
 }

 }
 if(degrade_pic)
 {
 if(ps_dec->i4_degrade_type & 0x2)
                ps_dec->u4_app_disable_deblk_frm = 1;

 /* MC degrading is done only for non-ref pictures */
 if(0 == ps_cur_slice->u1_nal_ref_idc)
 {
 if(ps_dec->i4_degrade_type & 0x4)
                    ps_dec->i4_mv_frac_mask = 0;

 if(ps_dec->i4_degrade_type & 0x8)
                    ps_dec->i4_mv_frac_mask = 0;
 }
 }
 else
            ps_dec->i4_degrade_pic_cnt = 0;
 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if(ps_dec->u1_sl_typ_5_9
 && ((ps_cur_slice->u1_slice_type == I_SLICE)
 || (ps_cur_slice->u1_slice_type
 == SI_SLICE)))
            ps_err->u1_cur_pic_type = PIC_TYPE_I;
 else
            ps_err->u1_cur_pic_type = PIC_TYPE_UNKNOWN;

 if(ps_err->u1_pic_aud_i == PIC_TYPE_I)
 {
            ps_err->u1_cur_pic_type = PIC_TYPE_I;
            ps_err->u1_pic_aud_i = PIC_TYPE_UNKNOWN;
 }

 if(ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL)
 {
 if(ps_err->u1_err_flag)
                ih264d_reset_ref_bufs(ps_dec->ps_dpb_mgr);
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

 if(ps_dec->u1_init_dec_flag && ps_dec->s_prev_seq_params.u1_eoseq_pending)
 {
 /* Reset the decoder picture buffers */
        WORD32 j;
 for(j = 0; j < MAX_DISP_BUFS_NEW; j++)
 {

            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                  j,
                                  BUF_MGR_REF);
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                  ps_dec->au1_pic_buf_id_mv_buf_id_map[j],
                                  BUF_MGR_REF);
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                  j,
                                  BUF_MGR_IO);
 }

 /* reset the decoder structure parameters related to buffer handling */
        ps_dec->u1_second_field = 0;
        ps_dec->i4_cur_display_seq = 0;

 /********************************************************************/
 /* indicate in the decoder output i4_status that some frames are being */
 /* dropped, so that it resets timestamp and wait for a new sequence */
 /********************************************************************/

        ps_dec->s_prev_seq_params.u1_eoseq_pending = 0;
 }
    ret = ih264d_init_pic(ps_dec, u2_frame_num, i4_poc, ps_pps);
 if(ret != OK)
 return ret;

    ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_pic_tu_coeff_data;
    ps_dec->pv_proc_tu_coeff_data  = ps_dec->pv_pic_tu_coeff_data;
    ps_dec->ps_nmb_info = ps_dec->ps_frm_mb_info;
 if(ps_dec->u1_separate_parse)
 {
        UWORD16 pic_wd = ps_dec->u4_width_at_init;
        UWORD16 pic_ht = ps_dec->u4_height_at_init;
        UWORD32 num_mbs;

 if((NULL != ps_dec->ps_cur_sps) && (1 == (ps_dec->ps_cur_sps->u1_is_valid)))
 {
            pic_wd = ps_dec->u2_pic_wd;
            pic_ht = ps_dec->u2_pic_ht;
 }
        num_mbs = (pic_wd * pic_ht) >> 8;

 if(ps_dec->pu1_dec_mb_map)
 {
            memset((void *)ps_dec->pu1_dec_mb_map, 0, num_mbs);
 }

 if(ps_dec->pu1_recon_mb_map)
 {

            memset((void *)ps_dec->pu1_recon_mb_map, 0, num_mbs);
 }

 if(ps_dec->pu2_slice_num_map)
 {
            memset((void *)ps_dec->pu2_slice_num_map, 0,
 (num_mbs * sizeof(UWORD16)));
 }

 }

    ps_dec->ps_parse_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->ps_decode_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->ps_computebs_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->u2_cur_slice_num = 0;

 /* Initialize all the HP toolsets to zero */
    ps_dec->s_high_profile.u1_scaling_present = 0;
    ps_dec->s_high_profile.u1_transform8x8_present = 0;

 /* Get Next Free Picture */
 if(1 == ps_dec->u4_share_disp_buf)
 {
        UWORD32 i;
 /* Free any buffer that is in the queue to be freed */
 for(i = 0; i < MAX_DISP_BUFS_NEW; i++)
 {
 if(0 == ps_dec->u4_disp_buf_to_be_freed[i])
 continue;
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr, i,
            BUF_MGR_IO);
            ps_dec->u4_disp_buf_to_be_freed[i] = 0;
            ps_dec->u4_disp_buf_mapping[i] = 0;

 }
 }
 if(!(u1_field_pic_flag && 0 != ps_dec->u1_top_bottom_decoded)) //ps_dec->u1_second_field))
 {
 pic_buffer_t *ps_cur_pic;
        WORD32 cur_pic_buf_id, cur_mv_buf_id;
 col_mv_buf_t *ps_col_mv;
 while(1)
 {
            ps_cur_pic = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
 &cur_pic_buf_id);
 if(ps_cur_pic == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_PICBUF_T;
 return ERROR_UNAVAIL_PICBUF_T;
 }
 if(0 == ps_dec->u4_disp_buf_mapping[cur_pic_buf_id])
 {
 break;
 }

 }
        ps_col_mv = (col_mv_buf_t *)ih264_buf_mgr_get_next_free((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
 &cur_mv_buf_id);
 if(ps_col_mv == NULL)
 {
            ps_dec->i4_error_code = ERROR_UNAVAIL_MVBUF_T;
 return ERROR_UNAVAIL_MVBUF_T;
 }

        ps_dec->ps_cur_pic = ps_cur_pic;
        ps_dec->u1_pic_buf_id = cur_pic_buf_id;
        ps_cur_pic->u4_ts = ps_dec->u4_ts;


        ps_cur_pic->u1_mv_buf_id = cur_mv_buf_id;
        ps_dec->au1_pic_buf_id_mv_buf_id_map[cur_pic_buf_id] = cur_mv_buf_id;

        ps_cur_pic->pu1_col_zero_flag = (UWORD8 *)ps_col_mv->pv_col_zero_flag;
        ps_cur_pic->ps_mv = (mv_pred_t *)ps_col_mv->pv_mv;
        ps_dec->au1_pic_buf_ref_flag[cur_pic_buf_id] = 0;

 {
 /*make first entry of list0 point to cur pic,so that if first Islice is in error, ref pic struct will have valid entries*/
            ps_dec->ps_ref_pic_buf_lx[0] = ps_dec->ps_dpb_mgr->ps_init_dpb[0];
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[0][0]) = *ps_cur_pic;
 /* Initialize for field reference as well */
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[0][MAX_REF_BUFS]) = *ps_cur_pic;
 }

 if(!ps_dec->ps_cur_pic)
 {
            WORD32 j;
            H264_DEC_DEBUG_PRINT("------- Display Buffers Reset --------\n");
 for(j = 0; j < MAX_DISP_BUFS_NEW; j++)
 {

                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                      j,
                                      BUF_MGR_REF);
                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                      ps_dec->au1_pic_buf_id_mv_buf_id_map[j],
                                      BUF_MGR_REF);
                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                      j,
                                      BUF_MGR_IO);
 }

            ps_dec->i4_cur_display_seq = 0;
            ps_dec->i4_prev_max_display_seq = 0;
            ps_dec->i4_max_poc = 0;

            ps_cur_pic = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
 &cur_pic_buf_id);
 if(ps_cur_pic == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_PICBUF_T;
 return ERROR_UNAVAIL_PICBUF_T;
 }

            ps_col_mv = (col_mv_buf_t *)ih264_buf_mgr_get_next_free((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
 &cur_mv_buf_id);
 if(ps_col_mv == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_MVBUF_T;
 return ERROR_UNAVAIL_MVBUF_T;
 }

            ps_dec->ps_cur_pic = ps_cur_pic;
            ps_dec->u1_pic_buf_id = cur_pic_buf_id;
            ps_cur_pic->u4_ts = ps_dec->u4_ts;
            ps_dec->apv_buf_id_pic_buf_map[cur_pic_buf_id] = (void *)ps_cur_pic;

            ps_cur_pic->u1_mv_buf_id = cur_mv_buf_id;
            ps_dec->au1_pic_buf_id_mv_buf_id_map[cur_pic_buf_id] = cur_mv_buf_id;

            ps_cur_pic->pu1_col_zero_flag = (UWORD8 *)ps_col_mv->pv_col_zero_flag;
            ps_cur_pic->ps_mv = (mv_pred_t *)ps_col_mv->pv_mv;
            ps_dec->au1_pic_buf_ref_flag[cur_pic_buf_id] = 0;

 }

        ps_dec->ps_cur_pic->u1_picturetype = u1_field_pic_flag;
        ps_dec->ps_cur_pic->u4_pack_slc_typ = SKIP_NONE;
        H264_DEC_DEBUG_PRINT("got a buffer\n");
 }
 else
 {
        H264_DEC_DEBUG_PRINT("did not get a buffer\n");
 }

    ps_dec->u4_pic_buf_got = 1;

    ps_dec->ps_cur_pic->i4_poc = i4_poc;
    ps_dec->ps_cur_pic->i4_frame_num = u2_frame_num;
    ps_dec->ps_cur_pic->i4_pic_num = u2_frame_num;
    ps_dec->ps_cur_pic->i4_top_field_order_cnt = ps_pps->i4_top_field_order_cnt;
    ps_dec->ps_cur_pic->i4_bottom_field_order_cnt =
                    ps_pps->i4_bottom_field_order_cnt;
    ps_dec->ps_cur_pic->i4_avg_poc = ps_pps->i4_avg_poc;
    ps_dec->ps_cur_pic->u4_time_stamp = ps_dec->u4_pts;

    ps_dec->s_cur_pic = *(ps_dec->ps_cur_pic);
 if(u1_field_pic_flag && u1_bottom_field_flag)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;
 /* Point to odd lines, since it's bottom field */
        ps_dec->s_cur_pic.pu1_buf1 += ps_dec->s_cur_pic.u2_frm_wd_y;
        ps_dec->s_cur_pic.pu1_buf2 += ps_dec->s_cur_pic.u2_frm_wd_uv;
        ps_dec->s_cur_pic.pu1_buf3 += ps_dec->s_cur_pic.u2_frm_wd_uv;
        ps_dec->s_cur_pic.ps_mv +=
 ((ps_dec->u2_pic_ht * ps_dec->u2_pic_wd) >> 5);
        ps_dec->s_cur_pic.pu1_col_zero_flag += ((ps_dec->u2_pic_ht
 * ps_dec->u2_pic_wd) >> 5);
        ps_dec->ps_cur_pic->u1_picturetype |= BOT_FLD;
        i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        i4_bot_field_order_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
        i4_temp_poc = MIN(i4_top_field_order_poc,
                                 i4_bot_field_order_poc);
        ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
 }

    ps_cur_slice->u1_mbaff_frame_flag = ps_seq->u1_mb_aff_flag
 && (!u1_field_pic_flag);

    ps_dec->ps_cur_pic->u1_picturetype |= (ps_cur_slice->u1_mbaff_frame_flag
 << 2);

    ps_dec->ps_cur_mb_row = ps_dec->ps_nbr_mb_row; //[0];
    ps_dec->ps_cur_mb_row++; //Increment by 1 ,so that left mb will always be valid
    ps_dec->ps_top_mb_row =
                    ps_dec->ps_nbr_mb_row
 + ((ps_dec->u2_frm_wd_in_mbs + 1)
 << (1
 - ps_dec->ps_cur_sps->u1_frame_mbs_only_flag));
    ps_dec->ps_top_mb_row++; //Increment by 1 ,so that left mb will always be valid

    ps_dec->pu1_y = ps_dec->pu1_y_scratch[0];
    ps_dec->pu1_u = ps_dec->pu1_u_scratch[0];
    ps_dec->pu1_v = ps_dec->pu1_v_scratch[0];
    ps_dec->u1_yuv_scratch_idx = 0;
 /* CHANGED CODE */
    ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
    ps_dec->ps_mv_top = ps_dec->ps_mv_top_p[0];
 /* CHANGED CODE */
    ps_dec->u1_mv_top_p = 0;
    ps_dec->u1_mb_idx = 0;
 /* CHANGED CODE */
    ps_dec->ps_mv_left = ps_dec->s_cur_pic.ps_mv;
    ps_dec->pu1_yleft = 0;
    ps_dec->pu1_uleft = 0;
    ps_dec->pu1_vleft = 0;
    ps_dec->u1_not_wait_rec = 2;
    ps_dec->u2_total_mbs_coded = 0;
    ps_dec->i4_submb_ofst = -(SUB_BLK_SIZE);
    ps_dec->u4_pred_info_idx = 0;
    ps_dec->u4_pred_info_pkd_idx = 0;
    ps_dec->u4_dma_buf_idx = 0;
    ps_dec->ps_mv = ps_dec->s_cur_pic.ps_mv;
    ps_dec->ps_mv_bank_cur = ps_dec->s_cur_pic.ps_mv;
    ps_dec->pu1_col_zero_flag = ps_dec->s_cur_pic.pu1_col_zero_flag;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;
    ps_dec->i2_prev_slice_mbx = -1;
    ps_dec->i2_prev_slice_mby = 0;
    ps_dec->u2_mv_2mb[0] = 0;
    ps_dec->u2_mv_2mb[1] = 0;
    ps_dec->u1_last_pic_not_decoded = 0;

    ps_dec->u2_cur_slice_num_dec_thread = 0;
    ps_dec->u2_cur_slice_num_bs = 0;
    ps_dec->u4_intra_pred_line_ofst = 0;
    ps_dec->pu1_cur_y_intra_pred_line = ps_dec->pu1_y_intra_pred_line;
    ps_dec->pu1_cur_u_intra_pred_line = ps_dec->pu1_u_intra_pred_line;
    ps_dec->pu1_cur_v_intra_pred_line = ps_dec->pu1_v_intra_pred_line;

    ps_dec->pu1_cur_y_intra_pred_line_base = ps_dec->pu1_y_intra_pred_line;
    ps_dec->pu1_cur_u_intra_pred_line_base = ps_dec->pu1_u_intra_pred_line;
    ps_dec->pu1_cur_v_intra_pred_line_base = ps_dec->pu1_v_intra_pred_line;





    ps_dec->pu1_prev_y_intra_pred_line = ps_dec->pu1_y_intra_pred_line
 + (ps_dec->u2_frm_wd_in_mbs * MB_SIZE);

    ps_dec->pu1_prev_u_intra_pred_line = ps_dec->pu1_u_intra_pred_line
 + ps_dec->u2_frm_wd_in_mbs * BLK8x8SIZE * YUV420SP_FACTOR;
    ps_dec->pu1_prev_v_intra_pred_line = ps_dec->pu1_v_intra_pred_line
 + ps_dec->u2_frm_wd_in_mbs * BLK8x8SIZE;

    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
    ps_dec->ps_deblk_mbn_curr = ps_dec->ps_deblk_mbn;
    ps_dec->ps_deblk_mbn_prev = ps_dec->ps_deblk_mbn + ps_dec->u1_recon_mb_grp;
 /* Initialize The Function Pointer Depending Upon the Entropy and MbAff Flag */
 {
 if(ps_cur_slice->u1_mbaff_frame_flag)
 {
            ps_dec->pf_compute_bs = ih264d_compute_bs_mbaff;
            ps_dec->pf_mvpred = ih264d_mvpred_mbaff;
 }
 else
 {
            ps_dec->pf_compute_bs = ih264d_compute_bs_non_mbaff;
            ps_dec->u1_cur_mb_fld_dec_flag = ps_cur_slice->u1_field_pic_flag;
 }
 }
 /* Set up the Parameter for DMA transfer */
 {
        UWORD8 u1_field_pic_flag = ps_dec->ps_cur_slice->u1_field_pic_flag;

        UWORD8 u1_mbaff = ps_cur_slice->u1_mbaff_frame_flag;

        UWORD8 uc_lastmbs = (((ps_dec->u2_pic_wd) >> 4)
 % (ps_dec->u1_recon_mb_grp >> u1_mbaff));
        UWORD16 ui16_lastmbs_widthY =
 (uc_lastmbs ? (uc_lastmbs << 4) : ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) << 4));
        UWORD16 ui16_lastmbs_widthUV =
                        uc_lastmbs ? (uc_lastmbs << 3) : ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) << 3);

        ps_dec->s_tran_addrecon.pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
        ps_dec->s_tran_addrecon.pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
        ps_dec->s_tran_addrecon.pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

        ps_dec->s_tran_addrecon.u2_frm_wd_y = ps_dec->u2_frm_wd_y
 << u1_field_pic_flag;
        ps_dec->s_tran_addrecon.u2_frm_wd_uv = ps_dec->u2_frm_wd_uv
 << u1_field_pic_flag;

 if(u1_field_pic_flag)
 {
            ui16_lastmbs_widthY += ps_dec->u2_frm_wd_y;
            ui16_lastmbs_widthUV += ps_dec->u2_frm_wd_uv;
 }

 /* Normal Increment of Pointer */
        ps_dec->s_tran_addrecon.u4_inc_y[0] = ((ps_dec->u1_recon_mb_grp << 4)
 >> u1_mbaff);
        ps_dec->s_tran_addrecon.u4_inc_uv[0] = ((ps_dec->u1_recon_mb_grp << 4)
 >> u1_mbaff);

 /* End of Row Increment */
        ps_dec->s_tran_addrecon.u4_inc_y[1] = (ui16_lastmbs_widthY
 + (PAD_LEN_Y_H << 1)
 + ps_dec->s_tran_addrecon.u2_frm_wd_y
 * ((15 << u1_mbaff) + u1_mbaff));
        ps_dec->s_tran_addrecon.u4_inc_uv[1] = (ui16_lastmbs_widthUV
 + (PAD_LEN_UV_H << 2)
 + ps_dec->s_tran_addrecon.u2_frm_wd_uv
 * ((15 << u1_mbaff) + u1_mbaff));

 /* Assign picture numbers to each frame/field  */
 /* only once per picture.                      */
        ih264d_assign_pic_num(ps_dec);
        ps_dec->s_tran_addrecon.u2_mv_top_left_inc = (ps_dec->u1_recon_mb_grp
 << 2) - 1 - (u1_mbaff << 2);
        ps_dec->s_tran_addrecon.u2_mv_left_inc = ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) - 1) << (4 + u1_mbaff);
 }
 /**********************************************************************/
 /* High profile related initialization at pictrue level               */
 /**********************************************************************/
 if(ps_seq->u1_profile_idc == HIGH_PROFILE_IDC)
 {
 if((ps_seq->i4_seq_scaling_matrix_present_flag)
 || (ps_pps->i4_pic_scaling_matrix_present_flag))
 {
            ih264d_form_scaling_matrix_picture(ps_seq, ps_pps, ps_dec);
            ps_dec->s_high_profile.u1_scaling_present = 1;
 }
 else
 {
            ih264d_form_default_scaling_matrix(ps_dec);
 }

 if(ps_pps->i4_transform_8x8_mode_flag)
 {
            ps_dec->s_high_profile.u1_transform8x8_present = 1;
 }
 }
 else
 {
        ih264d_form_default_scaling_matrix(ps_dec);
 }

 /* required while reading the transform_size_8x8 u4_flag */
    ps_dec->s_high_profile.u1_direct_8x8_inference_flag =
                    ps_seq->u1_direct_8x8_inference_flag;
    ps_dec->s_high_profile.s_cavlc_ctxt = ps_dec->s_cavlc_ctxt;

    ps_dec->i1_recon_in_thread3_flag = 1;
    ps_dec->ps_frame_buf_ip_recon = &ps_dec->s_tran_addrecon;
 if(ps_dec->u1_separate_parse)
 {
        memcpy(&ps_dec->s_tran_addrecon_parse, &ps_dec->s_tran_addrecon,
 sizeof(tfr_ctxt_t));
 if(ps_dec->u4_num_cores >= 3 && ps_dec->i1_recon_in_thread3_flag)
 {
            memcpy(&ps_dec->s_tran_iprecon, &ps_dec->s_tran_addrecon,
 sizeof(tfr_ctxt_t));
            ps_dec->ps_frame_buf_ip_recon = &ps_dec->s_tran_iprecon;
 }
 }


    ih264d_init_deblk_tfr_ctxt(ps_dec,&(ps_dec->s_pad_mgr), &(ps_dec->s_tran_addrecon),
                               ps_dec->u2_frm_wd_in_mbs, 0);

    ps_dec->ps_cur_deblk_mb = ps_dec->ps_deblk_pic;
    ps_dec->u4_cur_deblk_mb_num = 0;

    ps_dec->u4_deblk_mb_x = 0;

     ps_dec->u4_deblk_mb_y = 0;
     ps_dec->pu4_wt_ofsts = ps_dec->pu4_wts_ofsts_mat;
 
     H264_MUTEX_UNLOCK(&ps_dec->process_disp_mutex);
     return OK;
 }

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void AudioFlinger::EffectModule::process()
{
 Mutex::Autolock _l(mLock);

 if (mState == DESTROYED || mEffectInterface == NULL ||
            mConfig.inputCfg.buffer.raw == NULL ||
            mConfig.outputCfg.buffer.raw == NULL) {
 return;
 }

 if (isProcessEnabled()) {
 if ((mDescriptor.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_AUXILIARY) {
            ditherAndClamp(mConfig.inputCfg.buffer.s32,
                                        mConfig.inputCfg.buffer.s32,
                                        mConfig.inputCfg.buffer.frameCount/2);
 }

 int ret = (*mEffectInterface)->process(mEffectInterface,
 &mConfig.inputCfg.buffer,
 &mConfig.outputCfg.buffer);

 if (mState == STOPPED && ret == -ENODATA) {
            mDisableWaitCnt = 1;
 }

 if ((mDescriptor.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_AUXILIARY) {
            memset(mConfig.inputCfg.buffer.raw, 0,
                   mConfig.inputCfg.buffer.frameCount*sizeof(int32_t));
 }
 } else if ((mDescriptor.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_INSERT &&
                mConfig.inputCfg.buffer.raw != mConfig.outputCfg.buffer.raw) {
        sp<EffectChain> chain = mChain.promote();
 if (chain != 0 && chain->activeTrackCnt() != 0) {
 size_t frameCnt = mConfig.inputCfg.buffer.frameCount * 2; //always stereo here
 int16_t *in = mConfig.inputCfg.buffer.s16;
 int16_t *out = mConfig.outputCfg.buffer.s16;
 for (size_t i = 0; i < frameCnt; i++) {
                out[i] = clamp16((int32_t)out[i] + (int32_t)in[i]);
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Maybe<int64_t> IndexOfValueImpl(Isolate* isolate,
 Handle<JSObject> receiver,
 Handle<Object> value,
 uint32_t start_from, uint32_t length) {
    DCHECK(JSObject::PrototypeHasNoElements(isolate, *receiver));
 DisallowHeapAllocation no_gc;

 if (WasNeutered(*receiver)) return Just<int64_t>(-1);

 BackingStore* elements = BackingStore::cast(receiver->elements());
 if (!value->IsNumber()) return Just<int64_t>(-1);

 double search_value = value->Number();

 if (!std::isfinite(search_value)) {
 if (AccessorClass::kind() < FLOAT32_ELEMENTS ||
 AccessorClass::kind() > FLOAT64_ELEMENTS) {
 return Just<int64_t>(-1);
 }
 } else if (search_value < std::numeric_limits<ctype>::lowest() ||
               search_value > std::numeric_limits<ctype>::max()) {
 return Just<int64_t>(-1);
 }

 if (static_cast<uint32_t>(elements->length()) < length) {
      length = elements->length();
 }

 if (std::isnan(search_value)) {
 return Just<int64_t>(-1);
 }

    ctype typed_search_value = static_cast<ctype>(search_value);
 if (static_cast<double>(typed_search_value) != search_value) {
 return Just<int64_t>(-1); // Loss of precision.
 }

 for (uint32_t k = start_from; k < length; ++k) {
      ctype element_k = elements->get_scalar(k);
 if (element_k == typed_search_value) return Just<int64_t>(k);
 }
 return Just<int64_t>(-1);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int adev_set_parameters(struct audio_hw_device *dev, const char *kvpairs)
{
 struct audio_device *adev = (struct audio_device *)dev;
 struct str_parms *parms;
 char *str;
 char value[32];
 int val;
 int ret;

    ALOGV("%s: enter: %s", __func__, kvpairs);

    parms = str_parms_create_str(kvpairs);
    ret = str_parms_get_str(parms, AUDIO_PARAMETER_KEY_TTY_MODE, value, sizeof(value));
 if (ret >= 0) {
 int tty_mode;

 if (strcmp(value, AUDIO_PARAMETER_VALUE_TTY_OFF) == 0)
            tty_mode = TTY_MODE_OFF;
 else if (strcmp(value, AUDIO_PARAMETER_VALUE_TTY_VCO) == 0)
            tty_mode = TTY_MODE_VCO;
 else if (strcmp(value, AUDIO_PARAMETER_VALUE_TTY_HCO) == 0)
            tty_mode = TTY_MODE_HCO;
 else if (strcmp(value, AUDIO_PARAMETER_VALUE_TTY_FULL) == 0)
            tty_mode = TTY_MODE_FULL;
 else
 return -EINVAL;

        pthread_mutex_lock(&adev->lock);
 if (tty_mode != adev->tty_mode) {
            adev->tty_mode = tty_mode;
 if (adev->in_call)
                select_devices(adev, USECASE_VOICE_CALL);
 }
        pthread_mutex_unlock(&adev->lock);
 }

    ret = str_parms_get_str(parms, AUDIO_PARAMETER_KEY_BT_NREC, value, sizeof(value));
 if (ret >= 0) {
 /* When set to false, HAL should disable EC and NS
         * But it is currently not supported.
         */
 if (strcmp(value, AUDIO_PARAMETER_VALUE_ON) == 0)
            adev->bluetooth_nrec = true;
 else
            adev->bluetooth_nrec = false;
 }

    ret = str_parms_get_str(parms, "screen_state", value, sizeof(value));
 if (ret >= 0) {
 if (strcmp(value, AUDIO_PARAMETER_VALUE_ON) == 0)
            adev->screen_off = false;
 else
            adev->screen_off = true;
 }

    ret = str_parms_get_int(parms, "rotation", &val);
 if (ret >= 0) {
 bool reverse_speakers = false;
 switch(val) {
 /* Assume 0deg rotation means the front camera is up with the usb port
         * on the lower left when the user is facing the screen. This assumption
         * is device-specific, not platform-specific like this code.
         */
 case 180:
            reverse_speakers = true;
 break;
 case 0:
 case 90:
 case 270:
 break;
 default:
            ALOGE("%s: unexpected rotation of %d", __func__, val);
 }
        pthread_mutex_lock(&adev->lock);
 if (adev->speaker_lr_swap != reverse_speakers) {
            adev->speaker_lr_swap = reverse_speakers;
 struct mixer_card *mixer_card;
            mixer_card = adev_get_mixer_for_card(adev, SOUND_CARD);
 if (mixer_card)
                audio_route_apply_and_update_path(mixer_card->audio_route,
                        reverse_speakers ? "speaker-lr-reverse" :
 "speaker-lr-normal");
 }
        pthread_mutex_unlock(&adev->lock);
 }

    str_parms_destroy(parms);
    ALOGV("%s: exit with code(%d)", __func__, ret);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:     BufferMeta(const sp<IMemory> &mem, OMX_U32 portIndex, bool is_backup = false)
         : mMem(mem),
          mIsBackup(is_backup),
          mPortIndex(portIndex) {
     }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: YfromRGBint(int ir, int ig, int ib)
{
 double r = ir;
 double g = ig;
 double b = ib;
 return YfromRGB(r, g, b);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::getState(OMX_STATETYPE* state) {
 Mutex::Autolock autoLock(mLock);

    OMX_ERRORTYPE err = OMX_GetState(mHandle, state);
    CLOG_IF_ERROR(getState, err, "");
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void writepng_error_handler(png_structp png_ptr, png_const_charp msg)
{
    mainprog_info  *mainprog_ptr;

 /* This function, aside from the extra step of retrieving the "error
     * pointer" (below) and the fact that it exists within the application
     * rather than within libpng, is essentially identical to libpng's
     * default error handler.  The second point is critical:  since both
     * setjmp() and longjmp() are called from the same code, they are
     * guaranteed to have compatible notions of how big a jmp_buf is,
     * regardless of whether _BSD_SOURCE or anything else has (or has not)
     * been defined. */

    fprintf(stderr, "writepng libpng error: %s\n", msg);
    fflush(stderr);

    mainprog_ptr = png_get_error_ptr(png_ptr);
 if (mainprog_ptr == NULL) { /* we are completely hosed now */
        fprintf(stderr,
 "writepng severe error:  jmpbuf not recoverable; terminating.\n");
        fflush(stderr);
        exit(99);
 }

 /* Now we have our data structure we can use the information in it
     * to return control to our own higher level code (all the points
     * where 'setjmp' is called in this file.)  This will work with other
     * error handling mechanisms as well - libpng always calls png_error
     * when it can proceed no further, thus, so long as the error handler
     * is intercepted, application code can do its own error recovery.
     */
    longjmp(mainprog_ptr->jmpbuf, 1);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char16_t* Parcel::readString16Inplace(size_t* outLen) const
{
 int32_t size = readInt32();
 if (size >= 0 && size < INT32_MAX) {
 *outLen = size;
 const char16_t* str = (const char16_t*)readInplace((size+1)*sizeof(char16_t));
 if (str != NULL) {
 return str;
 }
 }
 *outLen = 0;
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: CameraService::BasicClient::BasicClient(const sp<CameraService>& cameraService,
 const sp<IBinder>& remoteCallback,
 const String16& clientPackageName,
 int cameraId, int cameraFacing,
 int clientPid, uid_t clientUid,
 int servicePid):
        mClientPackageName(clientPackageName)
{
    mCameraService = cameraService;
    mRemoteBinder = remoteCallback;
    mCameraId = cameraId;
    mCameraFacing = cameraFacing;
    mClientPid = clientPid;
    mClientUid = clientUid;
    mServicePid = servicePid;
    mOpsActive = false;
    mDestructionStarted = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long long EBMLHeader::Parse(IMkvReader* pReader, long long& pos) {
  assert(pReader);
 
   long long total, available;
 
 long status = pReader->Length(&total, &available);

 if (status < 0) // error
 return status;

  pos = 0;
 long long end = (available >= 1024) ? 1024 : available;

 for (;;) {
 unsigned char b = 0;

 while (pos < end) {
      status = pReader->Read(pos, 1, &b);

 if (status < 0) // error
 return status;

 if (b == 0x1A)
 break;

 ++pos;
 }

 if (b != 0x1A) {
 if (pos >= 1024)
 return E_FILE_FORMAT_INVALID; // don't bother looking anymore

 if ((total >= 0) && ((total - available) < 5))
 return E_FILE_FORMAT_INVALID;

 return available + 5; // 5 = 4-byte ID + 1st byte of size
 }

 if ((total >= 0) && ((total - pos) < 5))
 return E_FILE_FORMAT_INVALID;

 if ((available - pos) < 5)
 return pos + 5; // try again later

 long len;

 const long long result = ReadUInt(pReader, pos, len);

 if (result < 0) // error
 return result;

 if (result == 0x0A45DFA3) { // EBML Header ID
      pos += len; // consume ID
 break;
 }

 ++pos; // throw away just the 0x1A byte, and try again
 }



 long len;
 long long result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error
 return result;


   if (result > 0)  // need more data
     return result;
 
  assert(len > 0);
  assert(len <= 8);
 
   if ((total >= 0) && ((total - pos) < len))
     return E_FILE_FORMAT_INVALID;

 if ((available - pos) < len)
 return pos + len; // try again later


  result = ReadUInt(pReader, pos, len);

 if (result < 0) // error
 return result;

  pos += len; // consume size field


 if ((total >= 0) && ((total - pos) < result))
 return E_FILE_FORMAT_INVALID;

 if ((available - pos) < result)
 return pos + result;

  end = pos + result;

 Init();

 while (pos < end) {
 long long id, size;

    status = ParseElementHeader(pReader, pos, end, id, size);

 if (status < 0) // error
 return status;

 if (size == 0) // weird
 return E_FILE_FORMAT_INVALID;

 if (id == 0x0286) { // version
      m_version = UnserializeUInt(pReader, pos, size);

 if (m_version <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F7) { // read version
      m_readVersion = UnserializeUInt(pReader, pos, size);

 if (m_readVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F2) { // max id length
      m_maxIdLength = UnserializeUInt(pReader, pos, size);

 if (m_maxIdLength <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F3) { // max size length
      m_maxSizeLength = UnserializeUInt(pReader, pos, size);

 if (m_maxSizeLength <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x0282) { // doctype
 if (m_docType)
 return E_FILE_FORMAT_INVALID;

      status = UnserializeString(pReader, pos, size, m_docType);

 if (status) // error
 return status;
 } else if (id == 0x0287) { // doctype version
      m_docTypeVersion = UnserializeUInt(pReader, pos, size);

 if (m_docTypeVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x0285) { // doctype read version
      m_docTypeReadVersion = UnserializeUInt(pReader, pos, size);

 if (m_docTypeReadVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 }


     pos += size;
   }
 
  assert(pos == end);
   return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual void binderDied(const wp<IBinder> &) {
        mNotify->post();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void insert_local_socket(asocket* s, asocket* list) {
    s->next = list;
    s->prev = s->next->prev;
    s->prev->next = s;
    s->next->prev = s;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: png_pass_rows(png_uint_32 height, int pass)
{
   png_uint_32 tiles = height>>3;
   png_uint_32 rows = 0;
 unsigned int x, y;

   height &= 7;
 ++pass;
 for (y=0; y<8; ++y) for (x=0; x<8; ++x) if (adam7[y][x] == pass)
 {
      rows += tiles;
 if (y < height) ++rows;
 break; /* i.e. break the 'x', column, loop. */
 }

 return rows;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ESDS::parse() {
 uint8_t tag;
 size_t data_offset;
 size_t data_size;
 status_t err =
        skipDescriptorHeader(0, mSize, &tag, &data_offset, &data_size);

 if (err != OK) {
 return err;
 }

 if (tag != kTag_ESDescriptor) {
 return ERROR_MALFORMED;
 }

 return parseESDescriptor(data_offset, data_size);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_deinterlace(OMX_U32 enable)
{
    DEBUG_PRINT_LOW("venc_set_deinterlace: enable = %u", (unsigned int)enable);
 struct v4l2_control control;
 int rc;
    control.id = V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE;
 if (enable)
        control.value = V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE_ENABLED;
 else
        control.value = V4L2_CID_MPEG_VIDC_VIDEO_DEINTERLACE_ENABLED;

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%x, val=%d", control.id, control.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set Deinterlcing control");
 return false;
 }
    DEBUG_PRINT_LOW("Success IOCTL set control for id=%x, value=%d", control.id, control.value);
    deinterlace_enabled = true;
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t attach(const sound_trigger_module_handle_t handle,
 const sp<ISoundTriggerClient>& client,
                            sp<ISoundTrigger>& module)
 {
 Parcel data, reply;
        data.writeInterfaceToken(ISoundTriggerHwService::getInterfaceDescriptor());
        data.write(&handle, sizeof(sound_trigger_module_handle_t));
        data.writeStrongBinder(IInterface::asBinder(client));
        remote()->transact(ATTACH, data, &reply);
 status_t status = reply.readInt32();
 if (reply.readInt32() != 0) {
            module = interface_cast<ISoundTrigger>(reply.readStrongBinder());
 }
 return status;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Equalizer_getParameter(EffectContext *pContext,
 void *pParam,
 uint32_t *pValueSize,
 void *pValue){
 int status = 0;
 int bMute = 0;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;
 int32_t param2;
 char *name;


 switch (param) {
 case EQ_PARAM_NUM_BANDS:
 case EQ_PARAM_CUR_PRESET:
 case EQ_PARAM_GET_NUM_OF_PRESETS:
 case EQ_PARAM_BAND_LEVEL:
 case EQ_PARAM_GET_BAND:
 if (*pValueSize < sizeof(int16_t)) {
            ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid pValueSize 1  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;

 case EQ_PARAM_LEVEL_RANGE:
 if (*pValueSize < 2 * sizeof(int16_t)) {
            ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid pValueSize 2  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = 2 * sizeof(int16_t);
 break;
 case EQ_PARAM_BAND_FREQ_RANGE:
 if (*pValueSize < 2 * sizeof(int32_t)) {
            ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid pValueSize 3  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = 2 * sizeof(int32_t);
 break;

 case EQ_PARAM_CENTER_FREQ:
 if (*pValueSize < sizeof(int32_t)) {
            ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid pValueSize 5  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int32_t);
 break;

 case EQ_PARAM_GET_PRESET_NAME:
 break;

 case EQ_PARAM_PROPERTIES:
 if (*pValueSize < (2 + FIVEBAND_NUMBANDS) * sizeof(uint16_t)) {
            ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid pValueSize 1  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = (2 + FIVEBAND_NUMBANDS) * sizeof(uint16_t);
 break;

 default:
        ALOGV("\tLVM_ERROR : Equalizer_getParameter unknown param %d", param);
 return -EINVAL;
 }

 switch (param) {
 case EQ_PARAM_NUM_BANDS:
 *(uint16_t *)pValue = (uint16_t)FIVEBAND_NUMBANDS;
 break;

 case EQ_PARAM_LEVEL_RANGE:
 *(int16_t *)pValue = -1500;
 *((int16_t *)pValue + 1) = 1500;
 break;

 case EQ_PARAM_BAND_LEVEL:
        param2 = *pParamTemp;
 if (param2 < 0 || param2 >= FIVEBAND_NUMBANDS) {
            status = -EINVAL;
 if (param2 < 0) {
                android_errorWriteLog(0x534e4554, "32438598");
                ALOGW("\tERROR Equalizer_getParameter() EQ_PARAM_BAND_LEVEL band %d", param2);
 }
 break;
 }
 *(int16_t *)pValue = (int16_t)EqualizerGetBandLevel(pContext, param2);
 break;

 case EQ_PARAM_CENTER_FREQ:
        param2 = *pParamTemp;
 if (param2 < 0 || param2 >= FIVEBAND_NUMBANDS) {
            status = -EINVAL;
 if (param2 < 0) {
                android_errorWriteLog(0x534e4554, "32436341");
                ALOGW("\tERROR Equalizer_getParameter() EQ_PARAM_CENTER_FREQ band %d", param2);
 }
 break;
 }
 *(int32_t *)pValue = EqualizerGetCentreFrequency(pContext, param2);
 break;

 case EQ_PARAM_BAND_FREQ_RANGE:
        param2 = *pParamTemp;
 if (param2 < 0 || param2 >= FIVEBAND_NUMBANDS) {
            status = -EINVAL;
 if (param2 < 0) {
                android_errorWriteLog(0x534e4554, "32247948");
                ALOGW("\tERROR Equalizer_getParameter() EQ_PARAM_BAND_FREQ_RANGE band %d", param2);
 }
 break;
 }
 EqualizerGetBandFreqRange(pContext, param2, (uint32_t *)pValue, ((uint32_t *)pValue + 1));
 break;

 case EQ_PARAM_GET_BAND:
        param2 = *pParamTemp;
 *(uint16_t *)pValue = (uint16_t)EqualizerGetBand(pContext, param2);
 break;

 case EQ_PARAM_CUR_PRESET:
 *(uint16_t *)pValue = (uint16_t)EqualizerGetPreset(pContext);
 break;

 case EQ_PARAM_GET_NUM_OF_PRESETS:
 *(uint16_t *)pValue = (uint16_t)EqualizerGetNumPresets();
 break;

 
     case EQ_PARAM_GET_PRESET_NAME:
         param2 = *pParamTemp;
        if (param2 >= EqualizerGetNumPresets()) {
             status = -EINVAL;
             break;
         }
         name = (char *)pValue;
        strncpy(name, EqualizerGetPresetName(param2), *pValueSize - 1);
        name[*pValueSize - 1] = 0;
 *pValueSize = strlen(name) + 1;
 break;

 case EQ_PARAM_PROPERTIES: {
 int16_t *p = (int16_t *)pValue;
        ALOGV("\tEqualizer_getParameter() EQ_PARAM_PROPERTIES");
        p[0] = (int16_t)EqualizerGetPreset(pContext);
        p[1] = (int16_t)FIVEBAND_NUMBANDS;
 for (int i = 0; i < FIVEBAND_NUMBANDS; i++) {
            p[2 + i] = (int16_t)EqualizerGetBandLevel(pContext, i);
 }
 } break;

 default:
        ALOGV("\tLVM_ERROR : Equalizer_getParameter() invalid param %d", param);
        status = -EINVAL;
 break;
 }

 return status;
} /* end Equalizer_getParameter */

int Equalizer_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int status = 0;
 int32_t preset;
 int32_t band;
 int32_t level;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param) {
 case EQ_PARAM_CUR_PRESET:
        preset = (int32_t)(*(uint16_t *)pValue);

 if ((preset >= EqualizerGetNumPresets())||(preset < 0)) {
            status = -EINVAL;
 break;
 }
 EqualizerSetPreset(pContext, preset);
 break;
 case EQ_PARAM_BAND_LEVEL:

         band =  *pParamTemp;
         level = (int32_t)(*(int16_t *)pValue);
        if (band >= FIVEBAND_NUMBANDS) {
             status = -EINVAL;
             break;
         }
         EqualizerSetBandLevel(pContext, band, level);
 break;
 case EQ_PARAM_PROPERTIES: {
 int16_t *p = (int16_t *)pValue;
 if ((int)p[0] >= EqualizerGetNumPresets()) {
            status = -EINVAL;
 break;
 }
 if (p[0] >= 0) {
 EqualizerSetPreset(pContext, (int)p[0]);
 } else {
 if ((int)p[1] != FIVEBAND_NUMBANDS) {
                status = -EINVAL;
 break;
 }
 for (int i = 0; i < FIVEBAND_NUMBANDS; i++) {
 EqualizerSetBandLevel(pContext, i, (int)p[2 + i]);
 }
 }
 } break;
 default:
        ALOGV("\tLVM_ERROR : Equalizer_setParameter() invalid param %d", param);
        status = -EINVAL;
 break;
 }

 return status;
} /* end Equalizer_setParameter */


int Volume_getParameter(EffectContext *pContext,
 void *pParam,
 uint32_t *pValueSize,
 void *pValue){
 int status = 0;
 int bMute = 0;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;;
 char *name;


 switch (param){
 case VOLUME_PARAM_LEVEL:
 case VOLUME_PARAM_MAXLEVEL:
 case VOLUME_PARAM_STEREOPOSITION:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Volume_getParameter() invalid pValueSize 1  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;

 case VOLUME_PARAM_MUTE:
 case VOLUME_PARAM_ENABLESTEREOPOSITION:
 if (*pValueSize < sizeof(int32_t)){
                ALOGV("\tLVM_ERROR : Volume_getParameter() invalid pValueSize 2  %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int32_t);
 break;

 default:
            ALOGV("\tLVM_ERROR : Volume_getParameter unknown param %d", param);
 return -EINVAL;
 }

 switch (param){
 case VOLUME_PARAM_LEVEL:
            status = VolumeGetVolumeLevel(pContext, (int16_t *)(pValue));
 break;

 case VOLUME_PARAM_MAXLEVEL:
 *(int16_t *)pValue = 0;
 break;

 case VOLUME_PARAM_STEREOPOSITION:
 VolumeGetStereoPosition(pContext, (int16_t *)pValue);
 break;

 case VOLUME_PARAM_MUTE:
            status = VolumeGetMute(pContext, (uint32_t *)pValue);
            ALOGV("\tVolume_getParameter() VOLUME_PARAM_MUTE Value is %d",
 *(uint32_t *)pValue);
 break;

 case VOLUME_PARAM_ENABLESTEREOPOSITION:
 *(int32_t *)pValue = pContext->pBundledContext->bStereoPositionEnabled;
 break;

 default:
            ALOGV("\tLVM_ERROR : Volume_getParameter() invalid param %d", param);
            status = -EINVAL;
 break;
 }

 return status;
} /* end Volume_getParameter */



int Volume_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int      status = 0;
 int16_t  level;
 int16_t  position;
 uint32_t mute;
 uint32_t positionEnabled;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param){
 case VOLUME_PARAM_LEVEL:
            level = *(int16_t *)pValue;
            status = VolumeSetVolumeLevel(pContext, (int16_t)level);
 break;

 case VOLUME_PARAM_MUTE:
            mute = *(uint32_t *)pValue;
            status = VolumeSetMute(pContext, mute);
 break;

 case VOLUME_PARAM_ENABLESTEREOPOSITION:
            positionEnabled = *(uint32_t *)pValue;
            status = VolumeEnableStereoPosition(pContext, positionEnabled);
            status = VolumeSetStereoPosition(pContext, pContext->pBundledContext->positionSaved);
 break;

 case VOLUME_PARAM_STEREOPOSITION:
            position = *(int16_t *)pValue;
            status = VolumeSetStereoPosition(pContext, (int16_t)position);
 break;

 default:
            ALOGV("\tLVM_ERROR : Volume_setParameter() invalid param %d", param);
 break;
 }

 return status;
} /* end Volume_setParameter */

/****************************************************************************************
 * Name : LVC_ToDB_s32Tos16()
 *  Input       : Signed 32-bit integer
 *  Output      : Signed 16-bit integer
 *                  MSB (16) = sign bit
 *                  (15->05) = integer part
 *                  (04->01) = decimal part
 *  Returns     : Db value with respect to full scale
 *  Description :
 *  Remarks     :
 ****************************************************************************************/

LVM_INT16 LVC_ToDB_s32Tos16(LVM_INT32 Lin_fix)
{
    LVM_INT16   db_fix;
    LVM_INT16   Shift;
    LVM_INT16   SmallRemainder;
    LVM_UINT32  Remainder = (LVM_UINT32)Lin_fix;

 /* Count leading bits, 1 cycle in assembly*/
 for (Shift = 0; Shift<32; Shift++)
 {
 if ((Remainder & 0x80000000U)!=0)
 {
 break;
 }
 Remainder = Remainder << 1;
 }

 /*
     * Based on the approximation equation (for Q11.4 format):
     *
     * dB = -96 * Shift + 16 * (8 * Remainder - 2 * Remainder^2)
     */
    db_fix    = (LVM_INT16)(-96 * Shift); /* Six dB steps in Q11.4 format*/
 SmallRemainder = (LVM_INT16)((Remainder & 0x7fffffff) >> 24);
    db_fix = (LVM_INT16)(db_fix + SmallRemainder );
 SmallRemainder = (LVM_INT16)(SmallRemainder * SmallRemainder);
    db_fix = (LVM_INT16)(db_fix - (LVM_INT16)((LVM_UINT16)SmallRemainder >> 9));

 /* Correct for small offset */
    db_fix = (LVM_INT16)(db_fix - 5);

 return db_fix;
}


int Effect_setEnabled(EffectContext *pContext, bool enabled)
{
    ALOGV("\tEffect_setEnabled() type %d, enabled %d", pContext->EffectType, enabled);

 if (enabled) {
 bool tempDisabled = false;
 switch (pContext->EffectType) {
 case LVM_BASS_BOOST:
 if (pContext->pBundledContext->bBassEnabled == LVM_TRUE) {
                     ALOGV("\tEffect_setEnabled() LVM_BASS_BOOST is already enabled");
 return -EINVAL;
 }
 if(pContext->pBundledContext->SamplesToExitCountBb <= 0){
                    pContext->pBundledContext->NumberEffectsEnabled++;
 }
                pContext->pBundledContext->SamplesToExitCountBb =
 (LVM_INT32)(pContext->pBundledContext->SamplesPerSecond*0.1);
                pContext->pBundledContext->bBassEnabled = LVM_TRUE;
                tempDisabled = pContext->pBundledContext->bBassTempDisabled;
 break;
 case LVM_EQUALIZER:
 if (pContext->pBundledContext->bEqualizerEnabled == LVM_TRUE) {
                    ALOGV("\tEffect_setEnabled() LVM_EQUALIZER is already enabled");
 return -EINVAL;
 }
 if(pContext->pBundledContext->SamplesToExitCountEq <= 0){
                    pContext->pBundledContext->NumberEffectsEnabled++;
 }
                pContext->pBundledContext->SamplesToExitCountEq =
 (LVM_INT32)(pContext->pBundledContext->SamplesPerSecond*0.1);
                pContext->pBundledContext->bEqualizerEnabled = LVM_TRUE;
 break;
 case LVM_VIRTUALIZER:
 if (pContext->pBundledContext->bVirtualizerEnabled == LVM_TRUE) {
                    ALOGV("\tEffect_setEnabled() LVM_VIRTUALIZER is already enabled");
 return -EINVAL;
 }
 if(pContext->pBundledContext->SamplesToExitCountVirt <= 0){
                    pContext->pBundledContext->NumberEffectsEnabled++;
 }
                pContext->pBundledContext->SamplesToExitCountVirt =
 (LVM_INT32)(pContext->pBundledContext->SamplesPerSecond*0.1);
                pContext->pBundledContext->bVirtualizerEnabled = LVM_TRUE;
                tempDisabled = pContext->pBundledContext->bVirtualizerTempDisabled;
 break;
 case LVM_VOLUME:
 if (pContext->pBundledContext->bVolumeEnabled == LVM_TRUE) {
                    ALOGV("\tEffect_setEnabled() LVM_VOLUME is already enabled");
 return -EINVAL;
 }
                pContext->pBundledContext->NumberEffectsEnabled++;
                pContext->pBundledContext->bVolumeEnabled = LVM_TRUE;
 break;
 default:
                ALOGV("\tEffect_setEnabled() invalid effect type");
 return -EINVAL;
 }
 if (!tempDisabled) {
 LvmEffect_enable(pContext);
 }
 } else {
 switch (pContext->EffectType) {
 case LVM_BASS_BOOST:
 if (pContext->pBundledContext->bBassEnabled == LVM_FALSE) {
                    ALOGV("\tEffect_setEnabled() LVM_BASS_BOOST is already disabled");
 return -EINVAL;
 }
                pContext->pBundledContext->bBassEnabled = LVM_FALSE;
 break;
 case LVM_EQUALIZER:
 if (pContext->pBundledContext->bEqualizerEnabled == LVM_FALSE) {
                    ALOGV("\tEffect_setEnabled() LVM_EQUALIZER is already disabled");
 return -EINVAL;
 }
                pContext->pBundledContext->bEqualizerEnabled = LVM_FALSE;
 break;
 case LVM_VIRTUALIZER:
 if (pContext->pBundledContext->bVirtualizerEnabled == LVM_FALSE) {
                    ALOGV("\tEffect_setEnabled() LVM_VIRTUALIZER is already disabled");
 return -EINVAL;
 }
                pContext->pBundledContext->bVirtualizerEnabled = LVM_FALSE;
 break;
 case LVM_VOLUME:
 if (pContext->pBundledContext->bVolumeEnabled == LVM_FALSE) {
                    ALOGV("\tEffect_setEnabled() LVM_VOLUME is already disabled");
 return -EINVAL;
 }
                pContext->pBundledContext->bVolumeEnabled = LVM_FALSE;
 break;
 default:
                ALOGV("\tEffect_setEnabled() invalid effect type");
 return -EINVAL;
 }
 LvmEffect_disable(pContext);
 }

 return 0;
}


int16_t LVC_Convert_VolToDb(uint32_t vol){
 int16_t  dB;

    dB = LVC_ToDB_s32Tos16(vol <<7);
    dB = (dB +8)>>4;
    dB = (dB <-96) ? -96 : dB ;

 return dB;
}

} // namespace

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void print_data(int fd, const uint8_t *data_ptr, uint32_t tag,
 int type, int count, int indentation) {
 static int values_per_line[NUM_TYPES] = {
 [TYPE_BYTE] = 16,
 [TYPE_INT32] = 4,
 [TYPE_FLOAT] = 8,
 [TYPE_INT64] = 2,
 [TYPE_DOUBLE] = 4,
 [TYPE_RATIONAL] = 2,
 };
 size_t type_size = camera_metadata_type_size[type];
 char value_string_tmp[CAMERA_METADATA_ENUM_STRING_MAX_SIZE];
 uint32_t value;

 int lines = count / values_per_line[type];
 if (count % values_per_line[type] != 0) lines++;

 int index = 0;
 int j, k;
 for (j = 0; j < lines; j++) {
        dprintf(fd, "%*s[", indentation + 4, "");
 for (k = 0;
             k < values_per_line[type] && count > 0;
             k++, count--, index += type_size) {

 switch (type) {
 case TYPE_BYTE:
                    value = *(data_ptr + index);
 if (camera_metadata_enum_snprint(tag,
                                                     value,
                                                     value_string_tmp,
 sizeof(value_string_tmp))
 == OK) {
                        dprintf(fd, "%s ", value_string_tmp);
 } else {
                        dprintf(fd, "%hhu ",
 *(data_ptr + index));
 }
 break;
 case TYPE_INT32:
                    value =
 *(int32_t*)(data_ptr + index);
 if (camera_metadata_enum_snprint(tag,
                                                     value,
                                                     value_string_tmp,
 sizeof(value_string_tmp))
 == OK) {
                        dprintf(fd, "%s ", value_string_tmp);
 } else {
                        dprintf(fd, "%" PRId32 " ",
 *(int32_t*)(data_ptr + index));
 }
 break;
 case TYPE_FLOAT:
                    dprintf(fd, "%0.8f ",
 *(float*)(data_ptr + index));
 break;
 case TYPE_INT64:
                    dprintf(fd, "%" PRId64 " ",
 *(int64_t*)(data_ptr + index));
 break;
 case TYPE_DOUBLE:
                    dprintf(fd, "%0.8f ",
 *(double*)(data_ptr + index));
 break;
 case TYPE_RATIONAL: {
 int32_t numerator = *(int32_t*)(data_ptr + index);
 int32_t denominator = *(int32_t*)(data_ptr + index + 4);
                    dprintf(fd, "(%d / %d) ",
                            numerator, denominator);
 break;
 }
 default:
                    dprintf(fd, "??? ");
 }
 }
        dprintf(fd, "]\n");
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int adev_dump(const audio_hw_device_t *device, int fd)
{
    UNUSED(device);
    UNUSED(fd);

    FNLOG();

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseColorInfo(off64_t offset, size_t size) {
 if (size < 4 || size == SIZE_MAX || mLastTrack == NULL) {
 return ERROR_MALFORMED;
 }

 uint8_t *buffer = new (std::nothrow) uint8_t[size + 1];
 if (buffer == NULL) {
 return ERROR_MALFORMED;
 }
 if (mDataSource->readAt(offset, buffer, size) != (ssize_t)size) {
 delete[] buffer;
        buffer = NULL;

 return ERROR_IO;
 }

 int32_t type = U32_AT(&buffer[0]);
 if ((type == FOURCC('n', 'c', 'l', 'x') && size >= 11)
 || (type == FOURCC('n', 'c', 'l', 'c') && size >= 10)) {
 int32_t primaries = U16_AT(&buffer[4]);
 int32_t transfer = U16_AT(&buffer[6]);
 int32_t coeffs = U16_AT(&buffer[8]);
 bool fullRange = (type == FOURCC('n', 'c', 'l', 'x')) && (buffer[10] & 128);

 ColorAspects aspects;
 ColorUtils::convertIsoColorAspectsToCodecAspects(
                primaries, transfer, coeffs, fullRange, aspects);

 if (!mLastTrack->meta->hasData(kKeyColorPrimaries)) {
            mLastTrack->meta->setInt32(kKeyColorPrimaries, aspects.mPrimaries);
            mLastTrack->meta->setInt32(kKeyTransferFunction, aspects.mTransfer);
            mLastTrack->meta->setInt32(kKeyColorMatrix, aspects.mMatrixCoeffs);
            mLastTrack->meta->setInt32(kKeyColorRange, aspects.mRange);
 }
 }

 delete[] buffer;
    buffer = NULL;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ACodec::ExecutingToIdleState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 switch (event) {
 case OMX_EventCmdComplete:
 {
 if (data1 != (OMX_U32)OMX_CommandStateSet
 || data2 != (OMX_U32)OMX_StateIdle) {
                ALOGE("Unexpected command completion in ExecutingToIdleState: %s(%u) %s(%u)",
                        asString((OMX_COMMANDTYPE)data1), data1,
                        asString((OMX_STATETYPE)data2), data2);
                mCodec->signalError(OMX_ErrorUndefined, FAILED_TRANSACTION);
 return true;
 }

            mComponentNowIdle = true;

            changeStateIfWeOwnAllBuffers();

 return true;
 }

 case OMX_EventPortSettingsChanged:
 case OMX_EventBufferFlag:
 {
 return true;
 }

 default:
 return BaseState::onOMXEvent(event, data1, data2);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ATSParser::Program::parseProgramMap(ABitReader *br) {
 unsigned table_id = br->getBits(8);
    ALOGV("  table_id = %u", table_id);
 if (table_id != 0x02u) {
        ALOGE("PMT data error!");
 return ERROR_MALFORMED;
 }
 unsigned section_syntax_indicator = br->getBits(1);
    ALOGV("  section_syntax_indicator = %u", section_syntax_indicator);
 if (section_syntax_indicator != 1u) {
        ALOGE("PMT data error!");
 return ERROR_MALFORMED;
 }

    br->skipBits(1); // '0'
    MY_LOGV("  reserved = %u", br->getBits(2));

 unsigned section_length = br->getBits(12);
    ALOGV("  section_length = %u", section_length);

    MY_LOGV("  program_number = %u", br->getBits(16));
    MY_LOGV("  reserved = %u", br->getBits(2));
    MY_LOGV("  version_number = %u", br->getBits(5));
    MY_LOGV("  current_next_indicator = %u", br->getBits(1));
    MY_LOGV("  section_number = %u", br->getBits(8));
    MY_LOGV("  last_section_number = %u", br->getBits(8));
    MY_LOGV("  reserved = %u", br->getBits(3));

 unsigned PCR_PID = br->getBits(13);
    ALOGV("  PCR_PID = 0x%04x", PCR_PID);

    MY_LOGV("  reserved = %u", br->getBits(4));

 unsigned program_info_length = br->getBits(12);
    ALOGV("  program_info_length = %u", program_info_length);

    br->skipBits(program_info_length * 8); // skip descriptors

 Vector<StreamInfo> infos;

 size_t infoBytesRemaining = section_length - 9 - program_info_length - 4;

 while (infoBytesRemaining >= 5) {

 unsigned streamType = br->getBits(8);
        ALOGV("    stream_type = 0x%02x", streamType);

        MY_LOGV("    reserved = %u", br->getBits(3));

 unsigned elementaryPID = br->getBits(13);
        ALOGV("    elementary_PID = 0x%04x", elementaryPID);

        MY_LOGV("    reserved = %u", br->getBits(4));

 unsigned ES_info_length = br->getBits(12);
        ALOGV("    ES_info_length = %u", ES_info_length);

#if 0
        br->skipBits(ES_info_length * 8); // skip descriptors
#else
 unsigned info_bytes_remaining = ES_info_length;
 while (info_bytes_remaining >= 2) {
            MY_LOGV("      tag = 0x%02x", br->getBits(8));

 unsigned descLength = br->getBits(8);
            ALOGV("      len = %u", descLength);

 if (info_bytes_remaining < descLength) {
 return ERROR_MALFORMED;
 }
            br->skipBits(descLength * 8);

            info_bytes_remaining -= descLength + 2;
 }
#endif

 StreamInfo info;
        info.mType = streamType;
        info.mPID = elementaryPID;
        infos.push(info);

        infoBytesRemaining -= 5 + ES_info_length;
 }

 if (infoBytesRemaining != 0) {
        ALOGW("Section data remains unconsumed");
 }
    MY_LOGV("  CRC = 0x%08x", br->getBits(32));

 bool PIDsChanged = false;
 for (size_t i = 0; i < infos.size(); ++i) {
 StreamInfo &info = infos.editItemAt(i);

 ssize_t index = mStreams.indexOfKey(info.mPID);

 if (index >= 0 && mStreams.editValueAt(index)->type() != info.mType) {
            ALOGI("uh oh. stream PIDs have changed.");
 PIDsChanged = true;
 break;
 }
 }

 if (PIDsChanged) {
#if 0
        ALOGI("before:");
 for (size_t i = 0; i < mStreams.size(); ++i) {
            sp<Stream> stream = mStreams.editValueAt(i);

            ALOGI("PID 0x%08x => type 0x%02x", stream->pid(), stream->type());
 }

        ALOGI("after:");
 for (size_t i = 0; i < infos.size(); ++i) {
 StreamInfo &info = infos.editItemAt(i);

            ALOGI("PID 0x%08x => type 0x%02x", info.mPID, info.mType);
 }
#endif

 bool success = switchPIDs(infos);

 if (!success) {
            ALOGI("Stream PIDs changed and we cannot recover.");
 return ERROR_MALFORMED;
 }
 }

 for (size_t i = 0; i < infos.size(); ++i) {
 StreamInfo &info = infos.editItemAt(i);

 ssize_t index = mStreams.indexOfKey(info.mPID);

 if (index < 0) {
            sp<Stream> stream = new Stream(
 this, info.mPID, info.mType, PCR_PID);

            mStreams.add(info.mPID, stream);
 }
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: </s>


Instruction: 
Input: asocket* find_local_socket(unsigned local_id, unsigned peer_id) {

     asocket* s;
     asocket* result = NULL;
 
    adb_mutex_lock(&socket_list_lock);
     for (s = local_socket_list.next; s != &local_socket_list; s = s->next) {
         if (s->id != local_id) {
             continue;
 }
 if (peer_id == 0 || (s->peer && s->peer->id == peer_id)) {
            result = s;

         }
         break;
     }
    adb_mutex_unlock(&socket_list_lock);
 
     return result;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btm_send_link_key_notif (tBTM_SEC_DEV_REC *p_dev_rec)
{
 if (btm_cb.api.p_link_key_callback)
 (*btm_cb.api.p_link_key_callback) (p_dev_rec->bd_addr, p_dev_rec->dev_class,
                                           p_dev_rec->sec_bd_name, p_dev_rec->link_key,
                                           p_dev_rec->link_key_type);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ID3::removeUnsynchronizationV2_4(bool iTunesHack) {
 size_t oldSize = mSize;

 size_t offset = 0;
 while (mSize >= 10 && offset <= mSize - 10) {
 if (!memcmp(&mData[offset], "\0\0\0\0", 4)) {
 break;
 }

 size_t dataSize;
 if (iTunesHack) {
            dataSize = U32_AT(&mData[offset + 4]);
 } else if (!ParseSyncsafeInteger(&mData[offset + 4], &dataSize)) {
 return false;
 }

 if (dataSize > mSize - 10 - offset) {
 return false;
 }

 uint16_t flags = U16_AT(&mData[offset + 8]);
 uint16_t prevFlags = flags;

 if (flags & 1) {

 if (mSize < 14 || mSize - 14 < offset || dataSize < 4) {
 return false;
 }
            memmove(&mData[offset + 10], &mData[offset + 14], mSize - offset - 14);
            mSize -= 4;
            dataSize -= 4;

            flags &= ~1;
 }

 if ((flags & 2) && (dataSize >= 2)) {

 size_t readOffset = offset + 11;
 size_t writeOffset = offset + 11;
 for (size_t i = 0; i + 1 < dataSize; ++i) {
 if (mData[readOffset - 1] == 0xff
 && mData[readOffset] == 0x00) {
 ++readOffset;

                     --mSize;
                     --dataSize;
                 }
                mData[writeOffset++] = mData[readOffset++];
             }
             if (readOffset <= oldSize) {
                memmove(&mData[writeOffset], &mData[readOffset], oldSize - readOffset);
 } else {
                ALOGE("b/34618607 (%zu %zu %zu %zu)", readOffset, writeOffset, oldSize, mSize);
                android_errorWriteLog(0x534e4554, "34618607");
 }

 }
        flags &= ~2;
 if (flags != prevFlags || iTunesHack) {
 WriteSyncsafeInteger(&mData[offset + 4], dataSize);
            mData[offset + 8] = flags >> 8;
            mData[offset + 9] = flags & 0xff;
 }

        offset += 10 + dataSize;
 }

    memset(&mData[mSize], 0, oldSize - mSize);

 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void on_rfc_close(UNUSED_ATTR tBTA_JV_RFCOMM_CLOSE *p_close, uint32_t id) {
  pthread_mutex_lock(&slot_lock);

 rfc_slot_t *slot = find_rfc_slot_by_id(id);
 if (slot)
    cleanup_rfc_slot(slot);

  pthread_mutex_unlock(&slot_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void SetUp() {
 InitializeConfig();
 SetMode(GET_PARAM(1));
 ResetModel();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Track::GetFirst(const BlockEntry*& pBlockEntry) const
{
    const Cluster* pCluster = m_pSegment->GetFirst();
    for (int i = 0; ; )
    {
        if (pCluster == NULL)
        {
            pBlockEntry = GetEOS();
            return 1;
        }
        if (pCluster->EOS())
        {
 #if 0
            if (m_pSegment->Unparsed() <= 0)  //all clusters have been loaded
            {
                 pBlockEntry = GetEOS();
                 return 1;
             }
 #else
            if (m_pSegment->DoneParsing())
            {
                pBlockEntry = GetEOS();
                return 1;
            }
 #endif
 
            pBlockEntry = 0;
            return E_BUFFER_NOT_FULL;
        }
        long status = pCluster->GetFirst(pBlockEntry);
        if (status < 0)  //error
            return status;
        if (pBlockEntry == 0)  //empty cluster
        {
            pCluster = m_pSegment->GetNext(pCluster);
            continue;
        }
        for (;;)
        {
            const Block* const pBlock = pBlockEntry->GetBlock();
            assert(pBlock);
            const long long tn = pBlock->GetTrackNumber();
            if ((tn == m_info.number) && VetEntry(pBlockEntry))
                return 0;
            const BlockEntry* pNextEntry;
            status = pCluster->GetNext(pBlockEntry, pNextEntry);
            if (status < 0)  //error
                return status;
            if (pNextEntry == 0)
                break;
            pBlockEntry = pNextEntry;
        }
        ++i;
        if (i >= 100)
            break;
        pCluster = m_pSegment->GetNext(pCluster);
     }
 
 
    pBlockEntry = GetEOS();  //so we can return a non-NULL value
    return 1;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool MediaPlayerService::Client::shouldDropMetadata(media::Metadata::Type code) const
{
 Mutex::Autolock lock(mLock);

 if (findMetadata(mMetadataDrop, code)) {
 return true;
 }

 if (mMetadataAllow.isEmpty() || findMetadata(mMetadataAllow, code)) {
 return false;
 } else {
 return true;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::set_parameter(OMX_IN OMX_HANDLETYPE     hComp,
        OMX_IN OMX_INDEXTYPE paramIndex,
        OMX_IN OMX_PTR        paramData)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 int ret=0;
 struct v4l2_format fmt;
#ifdef _ANDROID_
 char property_value[PROPERTY_VALUE_MAX] = {0};
#endif
 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("Set Param in Invalid State");
 return OMX_ErrorInvalidState;
 }
 if (paramData == NULL) {
        DEBUG_PRINT_ERROR("Get Param in Invalid paramData");
 return OMX_ErrorBadParameter;
 }
 if ((m_state != OMX_StateLoaded) &&
            BITMASK_ABSENT(&m_flags,OMX_COMPONENT_OUTPUT_ENABLE_PENDING) &&
 (m_out_bEnabled == OMX_TRUE) &&
            BITMASK_ABSENT(&m_flags, OMX_COMPONENT_INPUT_ENABLE_PENDING) &&
 (m_inp_bEnabled == OMX_TRUE)) {
        DEBUG_PRINT_ERROR("Set Param in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }
 switch ((unsigned long)paramIndex) {
 case OMX_IndexParamPortDefinition: {
                               VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_PORTDEFINITIONTYPE);
                               OMX_PARAM_PORTDEFINITIONTYPE *portDefn;
                               portDefn = (OMX_PARAM_PORTDEFINITIONTYPE *) paramData;
                               DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPortDefinition H= %d, W = %d",
 (int)portDefn->format.video.nFrameHeight,
 (int)portDefn->format.video.nFrameWidth);
 if (OMX_DirOutput == portDefn->eDir) {
                                   DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPortDefinition OP port");
 bool port_format_changed = false;
                                   m_display_id = portDefn->format.video.pNativeWindow;
 unsigned int buffer_size;
 /* update output port resolution with client supplied dimensions
                                      in case scaling is enabled, else it follows input resolution set
                                   */
 if (is_down_scalar_enabled) {
                                       DEBUG_PRINT_LOW("SetParam OP: WxH(%u x %u)",
 (unsigned int)portDefn->format.video.nFrameWidth,
 (unsigned int)portDefn->format.video.nFrameHeight);
 if (portDefn->format.video.nFrameHeight != 0x0 &&
                                               portDefn->format.video.nFrameWidth != 0x0) {
                                           memset(&fmt, 0x0, sizeof(struct v4l2_format));
                                           fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
                                           fmt.fmt.pix_mp.pixelformat = capture_capability;
                                           ret = ioctl(drv_ctx.video_driver_fd, VIDIOC_G_FMT, &fmt);
 if (ret) {
                                               DEBUG_PRINT_ERROR("Get Resolution failed");
                                               eRet = OMX_ErrorHardware;
 break;
 }
 if ((portDefn->format.video.nFrameHeight != (unsigned int)fmt.fmt.pix_mp.height) ||
 (portDefn->format.video.nFrameWidth != (unsigned int)fmt.fmt.pix_mp.width)) {
                                                   port_format_changed = true;
 }
                                           update_resolution(portDefn->format.video.nFrameWidth,
                                                   portDefn->format.video.nFrameHeight,
                                                   portDefn->format.video.nFrameWidth,
                                                   portDefn->format.video.nFrameHeight);

 /* set crop info */
                                           rectangle.nLeft = 0;
                                           rectangle.nTop = 0;
                                           rectangle.nWidth = portDefn->format.video.nFrameWidth;
                                           rectangle.nHeight = portDefn->format.video.nFrameHeight;

                                           eRet = is_video_session_supported();
 if (eRet)
 break;
                                           memset(&fmt, 0x0, sizeof(struct v4l2_format));
                                           fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
                                           fmt.fmt.pix_mp.height = drv_ctx.video_resolution.frame_height;
                                           fmt.fmt.pix_mp.width = drv_ctx.video_resolution.frame_width;
                                           fmt.fmt.pix_mp.pixelformat = capture_capability;
                                           DEBUG_PRINT_LOW("fmt.fmt.pix_mp.height = %d , fmt.fmt.pix_mp.width = %d",
                                               fmt.fmt.pix_mp.height, fmt.fmt.pix_mp.width);
                                           ret = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_FMT, &fmt);
 if (ret) {
                                               DEBUG_PRINT_ERROR("Set Resolution failed");
                                               eRet = OMX_ErrorUnsupportedSetting;
 } else
                                               eRet = get_buffer_req(&drv_ctx.op_buf);
 }

 if (eRet) {
 break;
 }

 if (secure_mode) {
 struct v4l2_control control;
                                           control.id = V4L2_CID_MPEG_VIDC_VIDEO_SECURE_SCALING_THRESHOLD;
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_G_CTRL, &control) < 0) {
                                               DEBUG_PRINT_ERROR("Failed getting secure scaling threshold : %d, id was : %x", errno, control.id);
                                               eRet = OMX_ErrorHardware;
 } else {
 /* This is a workaround for a bug in fw which uses stride
                                                * and slice instead of width and height to check against
                                                * the threshold.
                                                */
                                               OMX_U32 stride, slice;
 if (drv_ctx.output_format == VDEC_YUV_FORMAT_NV12) {
                                                   stride = VENUS_Y_STRIDE(COLOR_FMT_NV12, portDefn->format.video.nFrameWidth);
                                                   slice = VENUS_Y_SCANLINES(COLOR_FMT_NV12, portDefn->format.video.nFrameHeight);
 } else {
                                                   stride = portDefn->format.video.nFrameWidth;
                                                   slice = portDefn->format.video.nFrameHeight;
 }

                                               DEBUG_PRINT_LOW("Stride is %d, slice is %d, sxs is %d\n", stride, slice, stride * slice);
                                               DEBUG_PRINT_LOW("Threshold value is %d\n", control.value);

 if (stride * slice <= (OMX_U32)control.value) {
                                                   secure_scaling_to_non_secure_opb = true;
                                                   DEBUG_PRINT_HIGH("Enabling secure scalar out of CPZ");
                                                   control.id = V4L2_CID_MPEG_VIDC_VIDEO_NON_SECURE_OUTPUT2;
                                                   control.value = 1;
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control) < 0) {
                                                       DEBUG_PRINT_ERROR("Enabling non-secure output2 failed");
                                                       eRet = OMX_ErrorUnsupportedSetting;
 }
 }
 }
 }
 }

 if (eRet) {
 break;
 }

 if (portDefn->nBufferCountActual > MAX_NUM_INPUT_OUTPUT_BUFFERS) {
                                       DEBUG_PRINT_ERROR("Requested o/p buf count (%u) exceeds limit (%u)",
                                               portDefn->nBufferCountActual, MAX_NUM_INPUT_OUTPUT_BUFFERS);
                                       eRet = OMX_ErrorBadParameter;
 } else if (!client_buffers.get_buffer_req(buffer_size)) {
                                       DEBUG_PRINT_ERROR("Error in getting buffer requirements");
                                       eRet = OMX_ErrorBadParameter;
 } else if (!port_format_changed) {

 if (!release_output_done()) {
                                           DEBUG_PRINT_ERROR("Cannot change o/p buffer count since all buffers are not freed yet !");
                                           eRet = OMX_ErrorInvalidState;
 break;
 }

 if ( portDefn->nBufferCountActual >= drv_ctx.op_buf.mincount &&
                                               portDefn->nBufferSize >=  drv_ctx.op_buf.buffer_size ) {
                                           drv_ctx.op_buf.actualcount = portDefn->nBufferCountActual;
                                           drv_ctx.op_buf.buffer_size = portDefn->nBufferSize;
                                           drv_ctx.extradata_info.count = drv_ctx.op_buf.actualcount;
                                           drv_ctx.extradata_info.size = drv_ctx.extradata_info.count *
                                               drv_ctx.extradata_info.buffer_size;
                                           eRet = set_buffer_req(&drv_ctx.op_buf);
 if (eRet == OMX_ErrorNone)
                                               m_port_def = *portDefn;
 } else {
                                           DEBUG_PRINT_ERROR("ERROR: OP Requirements(#%d: %u) Requested(#%u: %u)",
                                                   drv_ctx.op_buf.mincount, (unsigned int)drv_ctx.op_buf.buffer_size,
 (unsigned int)portDefn->nBufferCountActual, (unsigned int)portDefn->nBufferSize);
                                           eRet = OMX_ErrorBadParameter;
 }
 }
 } else if (OMX_DirInput == portDefn->eDir) {
                                   DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPortDefinition IP port");
 bool port_format_changed = false;
 if ((portDefn->format.video.xFramerate >> 16) > 0 &&
 (portDefn->format.video.xFramerate >> 16) <= MAX_SUPPORTED_FPS) {
                                       DEBUG_PRINT_HIGH("set_parameter: frame rate set by omx client : %u",
 (unsigned int)portDefn->format.video.xFramerate >> 16);
                                       Q16ToFraction(portDefn->format.video.xFramerate, drv_ctx.frame_rate.fps_numerator,
                                               drv_ctx.frame_rate.fps_denominator);
 if (!drv_ctx.frame_rate.fps_numerator) {
                                           DEBUG_PRINT_ERROR("Numerator is zero setting to 30");
                                           drv_ctx.frame_rate.fps_numerator = 30;
 }
 if (drv_ctx.frame_rate.fps_denominator)
                                           drv_ctx.frame_rate.fps_numerator = (int)
                                               drv_ctx.frame_rate.fps_numerator / drv_ctx.frame_rate.fps_denominator;
                                       drv_ctx.frame_rate.fps_denominator = 1;
                                       frm_int = drv_ctx.frame_rate.fps_denominator * 1e6 /
                                           drv_ctx.frame_rate.fps_numerator;
                                       DEBUG_PRINT_LOW("set_parameter: frm_int(%u) fps(%.2f)",
 (unsigned int)frm_int, drv_ctx.frame_rate.fps_numerator /
 (float)drv_ctx.frame_rate.fps_denominator);

 struct v4l2_outputparm oparm;
 /*XXX: we're providing timing info as seconds per frame rather than frames
                                        * per second.*/
                                       oparm.timeperframe.numerator = drv_ctx.frame_rate.fps_denominator;
                                       oparm.timeperframe.denominator = drv_ctx.frame_rate.fps_numerator;

 struct v4l2_streamparm sparm;
                                       sparm.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
                                       sparm.parm.output = oparm;
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_PARM, &sparm)) {
                                           DEBUG_PRINT_ERROR("Unable to convey fps info to driver, performance might be affected");
                                           eRet = OMX_ErrorHardware;
 break;
 }
 }

 if (drv_ctx.video_resolution.frame_height !=
                                           portDefn->format.video.nFrameHeight ||
                                           drv_ctx.video_resolution.frame_width  !=
                                           portDefn->format.video.nFrameWidth) {
                                       DEBUG_PRINT_LOW("SetParam IP: WxH(%u x %u)",
 (unsigned int)portDefn->format.video.nFrameWidth,
 (unsigned int)portDefn->format.video.nFrameHeight);
                                       port_format_changed = true;
                                       OMX_U32 frameWidth = portDefn->format.video.nFrameWidth;
                                       OMX_U32 frameHeight = portDefn->format.video.nFrameHeight;
 if (frameHeight != 0x0 && frameWidth != 0x0) {
 if (m_smoothstreaming_mode &&
 ((frameWidth * frameHeight) <
 (m_smoothstreaming_width * m_smoothstreaming_height))) {
                                               frameWidth = m_smoothstreaming_width;
                                               frameHeight = m_smoothstreaming_height;
                                               DEBUG_PRINT_LOW("NOTE: Setting resolution %u x %u "
 "for adaptive-playback/smooth-streaming",
 (unsigned int)frameWidth, (unsigned int)frameHeight);
 }
                                           update_resolution(frameWidth, frameHeight,
                                                   frameWidth, frameHeight);
                                           eRet = is_video_session_supported();
 if (eRet)
 break;
                                           memset(&fmt, 0x0, sizeof(struct v4l2_format));
                                           fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
                                           fmt.fmt.pix_mp.height = drv_ctx.video_resolution.frame_height;
                                           fmt.fmt.pix_mp.width = drv_ctx.video_resolution.frame_width;
                                           fmt.fmt.pix_mp.pixelformat = output_capability;
                                           DEBUG_PRINT_LOW("fmt.fmt.pix_mp.height = %d , fmt.fmt.pix_mp.width = %d",fmt.fmt.pix_mp.height,fmt.fmt.pix_mp.width);
                                           ret = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_FMT, &fmt);
 if (ret) {
                                               DEBUG_PRINT_ERROR("Set Resolution failed");
                                               eRet = OMX_ErrorUnsupportedSetting;
 } else {
 if (!is_down_scalar_enabled)
                                               eRet = get_buffer_req(&drv_ctx.op_buf);
 }
 }
 }
 if (m_custom_buffersize.input_buffersize
 && (portDefn->nBufferSize > m_custom_buffersize.input_buffersize)) {
                                       DEBUG_PRINT_ERROR("ERROR: Custom buffer size set by client: %d, trying to set: %d",
                                               m_custom_buffersize.input_buffersize, portDefn->nBufferSize);
                                       eRet = OMX_ErrorBadParameter;
 break;
 }
 if (portDefn->nBufferCountActual > MAX_NUM_INPUT_OUTPUT_BUFFERS) {
                                       DEBUG_PRINT_ERROR("Requested i/p buf count (%u) exceeds limit (%u)",
                                               portDefn->nBufferCountActual, MAX_NUM_INPUT_OUTPUT_BUFFERS);
                                       eRet = OMX_ErrorBadParameter;
 break;
 }
 if (!release_input_done()) {
                                       DEBUG_PRINT_ERROR("Cannot change i/p buffer count since all buffers are not freed yet !");
                                       eRet = OMX_ErrorInvalidState;
 break;
 }

 if (portDefn->nBufferCountActual >= drv_ctx.ip_buf.mincount
 || portDefn->nBufferSize != drv_ctx.ip_buf.buffer_size) {
                                       port_format_changed = true;
                                       vdec_allocatorproperty *buffer_prop = &drv_ctx.ip_buf;
                                       drv_ctx.ip_buf.actualcount = portDefn->nBufferCountActual;
                                       drv_ctx.ip_buf.buffer_size = (portDefn->nBufferSize + buffer_prop->alignment - 1) &
 (~(buffer_prop->alignment - 1));
                                       eRet = set_buffer_req(buffer_prop);
 }
 if (false == port_format_changed) {
                                       DEBUG_PRINT_ERROR("ERROR: IP Requirements(#%d: %u) Requested(#%u: %u)",
                                               drv_ctx.ip_buf.mincount, (unsigned int)drv_ctx.ip_buf.buffer_size,
 (unsigned int)portDefn->nBufferCountActual, (unsigned int)portDefn->nBufferSize);
                                       eRet = OMX_ErrorBadParameter;
 }
 } else if (portDefn->eDir ==  OMX_DirMax) {
                                   DEBUG_PRINT_ERROR(" Set_parameter: Bad Port idx %d",
 (int)portDefn->nPortIndex);
                                   eRet = OMX_ErrorBadPortIndex;
 }
 }
 break;
 case OMX_IndexParamVideoPortFormat: {
                                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_PORTFORMATTYPE);
                                OMX_VIDEO_PARAM_PORTFORMATTYPE *portFmt =
 (OMX_VIDEO_PARAM_PORTFORMATTYPE *)paramData;
 int ret=0;
 struct v4l2_format fmt;
                                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoPortFormat 0x%x, port: %u",
                                        portFmt->eColorFormat, (unsigned int)portFmt->nPortIndex);

                                memset(&fmt, 0x0, sizeof(struct v4l2_format));
 if (1 == portFmt->nPortIndex) {
                                    fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
                                    fmt.fmt.pix_mp.height = drv_ctx.video_resolution.frame_height;
                                    fmt.fmt.pix_mp.width = drv_ctx.video_resolution.frame_width;
                                    fmt.fmt.pix_mp.pixelformat = capture_capability;
 enum vdec_output_fromat op_format;
 if (portFmt->eColorFormat == (OMX_COLOR_FORMATTYPE)
                                                QOMX_COLOR_FORMATYUV420PackedSemiPlanar32m ||
                                            portFmt->eColorFormat == (OMX_COLOR_FORMATTYPE)
                                                QOMX_COLOR_FORMATYUV420PackedSemiPlanar32mMultiView ||
                                            portFmt->eColorFormat == OMX_COLOR_FormatYUV420Planar ||
                                            portFmt->eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar)
                                        op_format = (enum vdec_output_fromat)VDEC_YUV_FORMAT_NV12;
 else
                                        eRet = OMX_ErrorBadParameter;

 if (eRet == OMX_ErrorNone) {
                                        drv_ctx.output_format = op_format;
                                        ret = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_FMT, &fmt);
 if (ret) {
                                            DEBUG_PRINT_ERROR("Set output format failed");
                                            eRet = OMX_ErrorUnsupportedSetting;
 /*TODO: How to handle this case */
 } else {
                                            eRet = get_buffer_req(&drv_ctx.op_buf);
 }
 }
 if (eRet == OMX_ErrorNone) {
 if (!client_buffers.set_color_format(portFmt->eColorFormat)) {
                                            DEBUG_PRINT_ERROR("Set color format failed");
                                            eRet = OMX_ErrorBadParameter;
 }
 }
 }
 }
 break;

 case OMX_QcomIndexPortDefn: {
                            VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_PARAM_PORTDEFINITIONTYPE);
                            OMX_QCOM_PARAM_PORTDEFINITIONTYPE *portFmt =
 (OMX_QCOM_PARAM_PORTDEFINITIONTYPE *) paramData;
                            DEBUG_PRINT_LOW("set_parameter: OMX_IndexQcomParamPortDefinitionType %u",
 (unsigned int)portFmt->nFramePackingFormat);

 /* Input port */
 if (portFmt->nPortIndex == 0) {
 if (portFmt->nFramePackingFormat == OMX_QCOM_FramePacking_Arbitrary) {
 if (secure_mode) {
                                        arbitrary_bytes = false;
                                        DEBUG_PRINT_ERROR("setparameter: cannot set to arbitary bytes mode in secure session");
                                        eRet = OMX_ErrorUnsupportedSetting;
 } else {
                                        arbitrary_bytes = true;
 }
 } else if (portFmt->nFramePackingFormat ==
                                        OMX_QCOM_FramePacking_OnlyOneCompleteFrame) {
                                    arbitrary_bytes = false;
#ifdef _ANDROID_
                                    property_get("vidc.dec.debug.arbitrarybytes.mode", property_value, "0");
 if (atoi(property_value)) {
                                        DEBUG_PRINT_HIGH("arbitrary_bytes enabled via property command");
                                        arbitrary_bytes = true;
 }
#endif
 } else {
                                    DEBUG_PRINT_ERROR("Setparameter: unknown FramePacking format %u",
 (unsigned int)portFmt->nFramePackingFormat);
                                    eRet = OMX_ErrorUnsupportedSetting;
 }
 } else if (portFmt->nPortIndex == OMX_CORE_OUTPUT_PORT_INDEX) {
                                DEBUG_PRINT_HIGH("set_parameter: OMX_IndexQcomParamPortDefinitionType OP Port");
 if ( (portFmt->nMemRegion > OMX_QCOM_MemRegionInvalid &&
                                            portFmt->nMemRegion < OMX_QCOM_MemRegionMax) &&
                                        portFmt->nCacheAttr == OMX_QCOM_CacheAttrNone) {
                                    m_out_mem_region_smi = OMX_TRUE;
 if ((m_out_mem_region_smi && m_out_pvt_entry_pmem)) {
                                        DEBUG_PRINT_HIGH("set_parameter: OMX_IndexQcomParamPortDefinitionType OP Port: out pmem set");
                                        m_use_output_pmem = OMX_TRUE;
 }
 }
 }
 }
 break;

 case OMX_IndexParamStandardComponentRole: {
                                  VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_COMPONENTROLETYPE);
                                  OMX_PARAM_COMPONENTROLETYPE *comp_role;
                                  comp_role = (OMX_PARAM_COMPONENTROLETYPE *) paramData;
                                  DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamStandardComponentRole %s",
                                          comp_role->cRole);

 if ((m_state == OMX_StateLoaded)&&
 !BITMASK_PRESENT(&m_flags,OMX_COMPONENT_IDLE_PENDING)) {
                                      DEBUG_PRINT_LOW("Set Parameter called in valid state");
 } else {
                                      DEBUG_PRINT_ERROR("Set Parameter called in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }

 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((char*)comp_role->cRole,"video_decoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.avc",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mvc", OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((char*)comp_role->cRole, "video_decoder.mvc", OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole, "video_decoder.mvc", OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet = OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.h263",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.h263",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.h263",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet = OMX_ErrorUnsupportedSetting;
 }
 } else if ((!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.divx",OMX_MAX_STRINGNAME_SIZE)) ||
 (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.divx311", OMX_MAX_STRINGNAME_SIZE)) ||
 (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.divx4", OMX_MAX_STRINGNAME_SIZE))
 ) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.divx",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.divx",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if ( (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vc1",OMX_MAX_STRINGNAME_SIZE)) ||
 (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.wmv",OMX_MAX_STRINGNAME_SIZE))
 ) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.vc1",OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole,"video_decoder.vc1",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_decoder.vp8",OMX_MAX_STRINGNAME_SIZE) ||
 (!strncmp((const char*)comp_role->cRole,"video_decoder.vpx",OMX_MAX_STRINGNAME_SIZE))) {
                                          strlcpy((char*)m_cRole,"video_decoder.vp8",OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet = OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.hevc", OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole, "video_decoder.hevc", OMX_MAX_STRINGNAME_SIZE)) {
                                          strlcpy((char*)m_cRole, "video_decoder.hevc", OMX_MAX_STRINGNAME_SIZE);
 } else {
                                          DEBUG_PRINT_ERROR("Setparameter: unknown Index %s", comp_role->cRole);
                                          eRet = OMX_ErrorUnsupportedSetting;
 }
 } else {
                                      DEBUG_PRINT_ERROR("Setparameter: unknown param %s", drv_ctx.kind);
                                      eRet = OMX_ErrorInvalidComponentName;
 }
 break;
 }

 case OMX_IndexParamPriorityMgmt: {
                             VALIDATE_OMX_PARAM_DATA(paramData, OMX_PRIORITYMGMTTYPE);
 if (m_state != OMX_StateLoaded) {
                                 DEBUG_PRINT_ERROR("Set Parameter called in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }
                             OMX_PRIORITYMGMTTYPE *priorityMgmtype = (OMX_PRIORITYMGMTTYPE*) paramData;
                             DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPriorityMgmt %u",
 (unsigned int)priorityMgmtype->nGroupID);

                             DEBUG_PRINT_LOW("set_parameter: priorityMgmtype %u",
 (unsigned int)priorityMgmtype->nGroupPriority);

                             m_priority_mgm.nGroupID = priorityMgmtype->nGroupID;
                             m_priority_mgm.nGroupPriority = priorityMgmtype->nGroupPriority;

 break;
 }

 case OMX_IndexParamCompBufferSupplier: {
                                   VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_BUFFERSUPPLIERTYPE);
                                   OMX_PARAM_BUFFERSUPPLIERTYPE *bufferSupplierType = (OMX_PARAM_BUFFERSUPPLIERTYPE*) paramData;
                                   DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamCompBufferSupplier %d",
                                           bufferSupplierType->eBufferSupplier);
 if (bufferSupplierType->nPortIndex == 0 || bufferSupplierType->nPortIndex ==1)
                                       m_buffer_supplier.eBufferSupplier = bufferSupplierType->eBufferSupplier;

 else

                                       eRet = OMX_ErrorBadPortIndex;

 break;

 }
 case OMX_IndexParamVideoAvc: {
                             DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoAvc %d",
                                     paramIndex);
 break;
 }
 case (OMX_INDEXTYPE)QOMX_IndexParamVideoMvc: {
                            DEBUG_PRINT_LOW("set_parameter: QOMX_IndexParamVideoMvc %d",
                                     paramIndex);
 break;
 }
 case OMX_IndexParamVideoH263: {
                              DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoH263 %d",
                                      paramIndex);
 break;
 }
 case OMX_IndexParamVideoMpeg4: {
                               DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoMpeg4 %d",
                                       paramIndex);
 break;
 }
 case OMX_IndexParamVideoMpeg2: {
                               DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoMpeg2 %d",
                                       paramIndex);
 break;
 }
 case OMX_QcomIndexParamVideoDecoderPictureOrder: {
                                     VALIDATE_OMX_PARAM_DATA(paramData, QOMX_VIDEO_DECODER_PICTURE_ORDER);
                                     QOMX_VIDEO_DECODER_PICTURE_ORDER *pictureOrder =
 (QOMX_VIDEO_DECODER_PICTURE_ORDER *)paramData;
 struct v4l2_control control;
 int pic_order,rc=0;
                                     DEBUG_PRINT_HIGH("set_parameter: OMX_QcomIndexParamVideoDecoderPictureOrder %d",
                                             pictureOrder->eOutputPictureOrder);
 if (pictureOrder->eOutputPictureOrder == QOMX_VIDEO_DISPLAY_ORDER) {
                                         pic_order = V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DISPLAY;
 } else if (pictureOrder->eOutputPictureOrder == QOMX_VIDEO_DECODE_ORDER) {
                                         pic_order = V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DECODE;
                                         time_stamp_dts.set_timestamp_reorder_mode(false);
 } else
                                         eRet = OMX_ErrorBadParameter;
 if (eRet == OMX_ErrorNone) {
                                         control.id = V4L2_CID_MPEG_VIDC_VIDEO_OUTPUT_ORDER;
                                         control.value = pic_order;
                                         rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
                                             DEBUG_PRINT_ERROR("Set picture order failed");
                                             eRet = OMX_ErrorUnsupportedSetting;
 }
 }
 break;
 }
 case OMX_QcomIndexParamConcealMBMapExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                     eRet = enable_extradata(VDEC_EXTRADATA_MB_ERROR_MAP, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamFrameInfoExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                       eRet = enable_extradata(OMX_FRAMEINFO_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_ExtraDataFrameDimension:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                               eRet = enable_extradata(OMX_FRAMEDIMENSION_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamInterlaceExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                   eRet = enable_extradata(OMX_INTERLACE_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamH264TimeInfo:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                   eRet = enable_extradata(OMX_TIMEINFO_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamVideoFramePackingExtradata:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                               eRet = enable_extradata(OMX_FRAMEPACK_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamVideoQPExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                               eRet = enable_extradata(OMX_QP_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamVideoInputBitsInfoExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                               eRet = enable_extradata(OMX_BITSINFO_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexEnableExtnUserData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                eRet = enable_extradata(OMX_EXTNUSER_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamMpeg2SeqDispExtraData:
                               VALIDATE_OMX_PARAM_DATA(paramData, QOMX_ENABLETYPE);
                                eRet = enable_extradata(OMX_MPEG2SEQDISP_EXTRADATA, false,
 ((QOMX_ENABLETYPE *)paramData)->bEnable);
 break;
 case OMX_QcomIndexParamVideoDivx: {
                              QOMX_VIDEO_PARAM_DIVXTYPE* divXType = (QOMX_VIDEO_PARAM_DIVXTYPE *) paramData;
 }
 break;
 case OMX_QcomIndexPlatformPvt: {
                               VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_PLATFORMPRIVATE_EXTN);
                               DEBUG_PRINT_HIGH("set_parameter: OMX_QcomIndexPlatformPvt OP Port");
                               OMX_QCOM_PLATFORMPRIVATE_EXTN* entryType = (OMX_QCOM_PLATFORMPRIVATE_EXTN *) paramData;
 if (entryType->type != OMX_QCOM_PLATFORM_PRIVATE_PMEM) {
                                   DEBUG_PRINT_HIGH("set_parameter: Platform Private entry type (%d) not supported.", entryType->type);
                                   eRet = OMX_ErrorUnsupportedSetting;
 } else {
                                   m_out_pvt_entry_pmem = OMX_TRUE;
 if ((m_out_mem_region_smi && m_out_pvt_entry_pmem)) {
                                       DEBUG_PRINT_HIGH("set_parameter: OMX_QcomIndexPlatformPvt OP Port: out pmem set");
                                       m_use_output_pmem = OMX_TRUE;
 }
 }

 }
 break;
 case OMX_QcomIndexParamVideoSyncFrameDecodingMode: {
                                       DEBUG_PRINT_HIGH("set_parameter: OMX_QcomIndexParamVideoSyncFrameDecodingMode");
                                       DEBUG_PRINT_HIGH("set idr only decoding for thumbnail mode");
 struct v4l2_control control;
 int rc;
                                       drv_ctx.idr_only_decoding = 1;
                                       control.id = V4L2_CID_MPEG_VIDC_VIDEO_OUTPUT_ORDER;
                                       control.value = V4L2_MPEG_VIDC_VIDEO_OUTPUT_ORDER_DECODE;
                                       rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
                                           DEBUG_PRINT_ERROR("Set picture order failed");
                                           eRet = OMX_ErrorUnsupportedSetting;
 } else {
                                           control.id = V4L2_CID_MPEG_VIDC_VIDEO_SYNC_FRAME_DECODE;
                                           control.value = V4L2_MPEG_VIDC_VIDEO_SYNC_FRAME_DECODE_ENABLE;
                                           rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
                                               DEBUG_PRINT_ERROR("Sync frame setting failed");
                                               eRet = OMX_ErrorUnsupportedSetting;
 }
 /*Setting sync frame decoding on driver might change buffer
                                            * requirements so update them here*/
 if (get_buffer_req(&drv_ctx.ip_buf)) {
                                               DEBUG_PRINT_ERROR("Sync frame setting failed: falied to get buffer i/p requirements");
                                               eRet = OMX_ErrorUnsupportedSetting;
 }
 if (get_buffer_req(&drv_ctx.op_buf)) {
                                               DEBUG_PRINT_ERROR("Sync frame setting failed: falied to get buffer o/p requirements");
                                               eRet = OMX_ErrorUnsupportedSetting;
 }
 }
 }
 break;

 case OMX_QcomIndexParamIndexExtraDataType: {
                                    VALIDATE_OMX_PARAM_DATA(paramData, QOMX_INDEXEXTRADATATYPE);
                                       QOMX_INDEXEXTRADATATYPE *extradataIndexType = (QOMX_INDEXEXTRADATATYPE *) paramData;
 if ((extradataIndexType->nIndex == OMX_IndexParamPortDefinition) &&
 (extradataIndexType->bEnabled == OMX_TRUE) &&
 (extradataIndexType->nPortIndex == 1)) {
                                        DEBUG_PRINT_HIGH("set_parameter:  OMX_QcomIndexParamIndexExtraDataType SmoothStreaming");
                                           eRet = enable_extradata(OMX_PORTDEF_EXTRADATA, false, extradataIndexType->bEnabled);

 }
 }
 break;
 case OMX_QcomIndexParamEnableSmoothStreaming: {
#ifndef SMOOTH_STREAMING_DISABLED
                                      eRet = enable_smoothstreaming();
#else
                                      eRet = OMX_ErrorUnsupportedSetting;
#endif
 }
 break;
#if defined (_ANDROID_HONEYCOMB_) || defined (_ANDROID_ICS_)
 /* Need to allow following two set_parameters even in Idle
                                   * state. This is ANDROID architecture which is not in sync
                                   * with openmax standard. */
 case OMX_GoogleAndroidIndexEnableAndroidNativeBuffers: {
                                           VALIDATE_OMX_PARAM_DATA(paramData, EnableAndroidNativeBuffersParams);
 EnableAndroidNativeBuffersParams* enableNativeBuffers = (EnableAndroidNativeBuffersParams *) paramData;
 if (enableNativeBuffers) {
                                               m_enable_android_native_buffers = enableNativeBuffers->enable;
 }
#if !defined(FLEXYUV_SUPPORTED)
 if (m_enable_android_native_buffers) {
 if(!client_buffers.set_color_format(getPreferredColorFormatDefaultMode(0))) {
                                                   DEBUG_PRINT_ERROR("Failed to set native color format!");
                                                   eRet = OMX_ErrorUnsupportedSetting;
 }
 }
#endif
 }
 break;
 case OMX_GoogleAndroidIndexUseAndroidNativeBuffer: {
                                       VALIDATE_OMX_PARAM_DATA(paramData, UseAndroidNativeBufferParams);
                                       eRet = use_android_native_buffer(hComp, paramData);
 }
 break;
#endif
 case OMX_QcomIndexParamEnableTimeStampReorder: {
                                       VALIDATE_OMX_PARAM_DATA(paramData, QOMX_INDEXTIMESTAMPREORDER);
                                       QOMX_INDEXTIMESTAMPREORDER *reorder = (QOMX_INDEXTIMESTAMPREORDER *)paramData;
 if (drv_ctx.picture_order == (vdec_output_order)QOMX_VIDEO_DISPLAY_ORDER) {
 if (reorder->bEnable == OMX_TRUE) {
                                               frm_int =0;
                                               time_stamp_dts.set_timestamp_reorder_mode(true);
 } else
                                               time_stamp_dts.set_timestamp_reorder_mode(false);
 } else {
                                           time_stamp_dts.set_timestamp_reorder_mode(false);
 if (reorder->bEnable == OMX_TRUE) {
                                               eRet = OMX_ErrorUnsupportedSetting;
 }
 }
 }
 break;
 case OMX_IndexParamVideoProfileLevelCurrent: {
                                     VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_PROFILELEVELTYPE);
                                     OMX_VIDEO_PARAM_PROFILELEVELTYPE* pParam =
 (OMX_VIDEO_PARAM_PROFILELEVELTYPE*)paramData;
 if (pParam) {
                                         m_profile_lvl.eProfile = pParam->eProfile;
                                         m_profile_lvl.eLevel = pParam->eLevel;
 }
 break;

 }
 case OMX_QcomIndexParamVideoMetaBufferMode:
 {
            VALIDATE_OMX_PARAM_DATA(paramData, StoreMetaDataInBuffersParams);
 StoreMetaDataInBuffersParams *metabuffer =
 (StoreMetaDataInBuffersParams *)paramData;
 if (!metabuffer) {
                DEBUG_PRINT_ERROR("Invalid param: %p", metabuffer);
                eRet = OMX_ErrorBadParameter;
 break;
 }
 if (m_disable_dynamic_buf_mode) {
                DEBUG_PRINT_HIGH("Dynamic buffer mode disabled by setprop");
                eRet = OMX_ErrorUnsupportedSetting;
 break;
 }
 if (metabuffer->nPortIndex == OMX_CORE_OUTPUT_PORT_INDEX) {
 struct v4l2_control control;
 struct v4l2_format fmt;
                    control.id = V4L2_CID_MPEG_VIDC_VIDEO_ALLOC_MODE_OUTPUT;
 if (metabuffer->bStoreMetaData == true) {
                    control.value = V4L2_MPEG_VIDC_VIDEO_DYNAMIC;
 } else {
                        control.value = V4L2_MPEG_VIDC_VIDEO_STATIC;
 }
 int rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL,&control);
 if (!rc) {
                        DEBUG_PRINT_HIGH("%s buffer mode",
 (metabuffer->bStoreMetaData == true)? "Enabled dynamic" : "Disabled dynamic");
                               dynamic_buf_mode = metabuffer->bStoreMetaData;
 } else {
                        DEBUG_PRINT_ERROR("Failed to %s buffer mode",
 (metabuffer->bStoreMetaData == true)? "enable dynamic" : "disable dynamic");
                        eRet = OMX_ErrorUnsupportedSetting;
 }
 } else {
                    DEBUG_PRINT_ERROR(
 "OMX_QcomIndexParamVideoMetaBufferMode not supported for port: %u",
 (unsigned int)metabuffer->nPortIndex);
                    eRet = OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexParamVideoDownScalar:
 {
            VALIDATE_OMX_PARAM_DATA(paramData, QOMX_INDEXDOWNSCALAR);
            QOMX_INDEXDOWNSCALAR* pParam = (QOMX_INDEXDOWNSCALAR*)paramData;
 struct v4l2_control control;
 int rc;
 if (pParam) {
                is_down_scalar_enabled = pParam->bEnable;
 if (is_down_scalar_enabled) {
                    control.id = V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_MODE;
                    control.value = V4L2_CID_MPEG_VIDC_VIDEO_STREAM_OUTPUT_SECONDARY;
                    DEBUG_PRINT_LOW("set_parameter:  OMX_QcomIndexParamVideoDownScalar value = %d", pParam->bEnable);
                    rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control);
 if (rc < 0) {
                        DEBUG_PRINT_ERROR("Failed to set down scalar on driver.");
                        eRet = OMX_ErrorUnsupportedSetting;
 }
                    control.id = V4L2_CID_MPEG_VIDC_VIDEO_KEEP_ASPECT_RATIO;
                    control.value = 1;
                    rc = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control);
 if (rc < 0) {
                        DEBUG_PRINT_ERROR("Failed to set keep aspect ratio on driver.");
                        eRet = OMX_ErrorUnsupportedSetting;
 }
 }
 }
 break;
 }
#ifdef ADAPTIVE_PLAYBACK_SUPPORTED
 case OMX_QcomIndexParamVideoAdaptivePlaybackMode:
 {
            VALIDATE_OMX_PARAM_DATA(paramData, PrepareForAdaptivePlaybackParams);
            DEBUG_PRINT_LOW("set_parameter: OMX_GoogleAndroidIndexPrepareForAdaptivePlayback");
 PrepareForAdaptivePlaybackParams* pParams =
 (PrepareForAdaptivePlaybackParams *) paramData;
 if (pParams->nPortIndex == OMX_CORE_OUTPUT_PORT_INDEX) {
 if (!pParams->bEnable) {
 return OMX_ErrorNone;
 }
 if (pParams->nMaxFrameWidth > maxSmoothStreamingWidth
 || pParams->nMaxFrameHeight > maxSmoothStreamingHeight) {
                    DEBUG_PRINT_ERROR(
 "Adaptive playback request exceeds max supported resolution : [%u x %u] vs [%u x %u]",
 (unsigned int)pParams->nMaxFrameWidth, (unsigned int)pParams->nMaxFrameHeight,
 (unsigned int)maxSmoothStreamingWidth, (unsigned int)maxSmoothStreamingHeight);
                    eRet = OMX_ErrorBadParameter;
 } else {
                    eRet = enable_adaptive_playback(pParams->nMaxFrameWidth, pParams->nMaxFrameHeight);
 }
 } else {
                DEBUG_PRINT_ERROR(
 "Prepare for adaptive playback supported only on output port");
                eRet = OMX_ErrorBadParameter;
 }
 break;
 }

#endif
 case OMX_QcomIndexParamVideoCustomBufferSize:
 {
            VALIDATE_OMX_PARAM_DATA(paramData, QOMX_VIDEO_CUSTOM_BUFFERSIZE);
            DEBUG_PRINT_LOW("set_parameter: OMX_QcomIndexParamVideoCustomBufferSize");
            QOMX_VIDEO_CUSTOM_BUFFERSIZE* pParam = (QOMX_VIDEO_CUSTOM_BUFFERSIZE*)paramData;
 if (pParam->nPortIndex == OMX_CORE_INPUT_PORT_INDEX) {
 struct v4l2_control control;
                control.id = V4L2_CID_MPEG_VIDC_VIDEO_BUFFER_SIZE_LIMIT;
                control.value = pParam->nBufferSize;
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control)) {
                    DEBUG_PRINT_ERROR("Failed to set input buffer size");
                    eRet = OMX_ErrorUnsupportedSetting;
 } else {
                    eRet = get_buffer_req(&drv_ctx.ip_buf);
 if (eRet == OMX_ErrorNone) {
                        m_custom_buffersize.input_buffersize = drv_ctx.ip_buf.buffer_size;
                        DEBUG_PRINT_HIGH("Successfully set custom input buffer size = %d",
                            m_custom_buffersize.input_buffersize);
 } else {
                        DEBUG_PRINT_ERROR("Failed to get buffer requirement");
 }
 }
 } else {
                DEBUG_PRINT_ERROR("ERROR: Custom buffer size in not supported on output port");
                eRet = OMX_ErrorBadParameter;
 }
 break;
 }
 default: {
                 DEBUG_PRINT_ERROR("Setparameter: unknown param %d", paramIndex);
                 eRet = OMX_ErrorUnsupportedIndex;
 }
 }
 if (eRet != OMX_ErrorNone)
        DEBUG_PRINT_ERROR("set_parameter: Error: 0x%x, setting param 0x%x", eRet, paramIndex);
 return eRet;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 ih264d_insert_lt_node(dpb_manager_t *ps_dpb_mgr,
 struct dpb_info_t *ps_mov_node,
                           UWORD32 u4_lt_idx,
                           UWORD8 u1_fld_pic_flag)
{
    UWORD8 u1_mark_top_field_long_term = 0;
    UWORD8 u1_mark_bot_field_long_term = 0;

 {
 if(u1_fld_pic_flag)
 {
 /* Assign corresponding field (top or bottom) long_term_frame_idx */

 if((ps_mov_node->s_top_field.u1_reference_info == IS_LONG_TERM)
 && (ps_mov_node->s_bot_field.u1_reference_info
 == IS_LONG_TERM))
 {
 if(ps_mov_node->u1_lt_idx == u4_lt_idx)
                    u1_mark_bot_field_long_term = 1;
 else
 {

                    UWORD32 i4_error_code;
                    i4_error_code = ERROR_DBP_MANAGER_T;

 return i4_error_code;

 }
 }
 else if(ps_mov_node->s_top_field.u1_reference_info == IS_LONG_TERM)
 {
                u1_mark_top_field_long_term = 1;
 }

 if(!(u1_mark_top_field_long_term || u1_mark_bot_field_long_term))
 {
                UWORD32 i4_error_code;
                i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }
 }
 else
 {
            ps_mov_node->s_top_field.u1_reference_info = IS_LONG_TERM;
            ps_mov_node->s_bot_field.u1_reference_info = IS_LONG_TERM;
            ps_mov_node->s_top_field.u1_long_term_frame_idx = u4_lt_idx;
            ps_mov_node->s_bot_field.u1_long_term_frame_idx = u4_lt_idx;
 }

        ps_mov_node->u1_lt_idx = u4_lt_idx; //Assign the LT index to the node
        ps_mov_node->ps_pic_buf->u1_long_term_frm_idx = u4_lt_idx;
        ps_mov_node->u1_used_as_ref = IS_LONG_TERM;

 /* Insert the new long term in the LT list with  u4_lt_idx    */
 /* in ascending order.                                         */
 if(ps_dpb_mgr->u1_num_lt_ref_bufs > 0)
 {
 struct dpb_info_t *ps_next_dpb = ps_dpb_mgr->ps_dpb_ht_head;
 if(u4_lt_idx < ps_next_dpb->u1_lt_idx)
 {
                ps_mov_node->ps_prev_long = ps_next_dpb;
                ps_dpb_mgr->ps_dpb_ht_head = ps_mov_node;
 }
 else
 {
                WORD32 i;
 struct dpb_info_t *ps_nxtDPB = ps_next_dpb;
                ps_next_dpb = ps_next_dpb->ps_prev_long;
 for(i = 1; i < ps_dpb_mgr->u1_num_lt_ref_bufs; i++)
 {
 if(ps_next_dpb->u1_lt_idx > u4_lt_idx)
 break;
                    ps_nxtDPB = ps_next_dpb;
                    ps_next_dpb = ps_next_dpb->ps_prev_long;
 }

                ps_nxtDPB->ps_prev_long = ps_mov_node;
                ps_mov_node->ps_prev_long = ps_next_dpb;
 }
 }
 else
 {
            ps_dpb_mgr->ps_dpb_ht_head = ps_mov_node;
            ps_mov_node->ps_prev_long = NULL;
 }
 /* Identify the picture buffer as a long term picture buffer */
        ps_mov_node->ps_pic_buf->u1_is_short = 0;

 /* Increment LT buf count only if new LT node inserted    */
 /* If Increment during top_field is done, don't increment */
 /* for bottom field, as both them are part of same pic.   */
 if(!u1_mark_bot_field_long_term)
            ps_dpb_mgr->u1_num_lt_ref_bufs++;

 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  ExternalFrameBufferMD5Test()
 : DecoderTest(GET_PARAM(::libvpx_test::kCodecFactoryParam)),
        md5_file_(NULL),
        num_buffers_(0) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void append_negative_gtest_filter(const char *str) {
   std::string filter = ::testing::FLAGS_gtest_filter;
 if (filter.find('-') == std::string::npos) filter += '-';
  filter += str;
 ::testing::FLAGS_gtest_filter = filter;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAACEncoder2::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPortFormat:
 {

             OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
                 (OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;
 
             if (formatParams->nPortIndex > 1) {
                 return OMX_ErrorUndefined;
             }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

            formatParams->eEncoding =
 (formatParams->nPortIndex == 0)
 ? OMX_AUDIO_CodingPCM : OMX_AUDIO_CodingAAC;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            aacParams->nBitRate = mBitRate;
            aacParams->nAudioBandWidth = 0;
            aacParams->nAACtools = 0;
            aacParams->nAACERtools = 0;
            aacParams->eAACProfile = (OMX_AUDIO_AACPROFILETYPE) mAACProfile;
            aacParams->eAACStreamFormat = OMX_AUDIO_AACStreamFormatMP4FF;
            aacParams->eChannelMode = OMX_AUDIO_ChannelModeStereo;

            aacParams->nChannels = mNumChannels;
            aacParams->nSampleRate = mSampleRate;
            aacParams->nFrameLength = 0;

 switch (mSBRMode) {
 case 1: // sbr on
 switch (mSBRRatio) {
 case 0:
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidDSBR;
 break;
 case 1:
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidDSBR;
 break;
 case 2:
                    aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidDSBR;
 break;
 default:
                    ALOGE("invalid SBR ratio %d", mSBRRatio);
                    TRESPASS();
 }
 break;
 case 0: // sbr off
 case -1: // sbr undefined
                aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidSSBR;
                aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidDSBR;
 break;
 default:
                ALOGE("invalid SBR mode %d", mSBRMode);
                TRESPASS();
 }



 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static status_t getSampleRateTableIndex(int32_t sampleRate, int32_t &index) {
 static const int32_t kSampleRateTable[] = {
 96000, 88200, 64000, 48000, 44100, 32000,
 24000, 22050, 16000, 12000, 11025, 8000
 };
 const int32_t tableSize =
 sizeof(kSampleRateTable) / sizeof(kSampleRateTable[0]);

 for (int32_t i = 0; i < tableSize; ++i) {
 if (sampleRate == kSampleRateTable[i]) {
            index = i;
 return OK;
 }
 }

 return UNKNOWN_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void yuvconfig2image(vpx_image_t *img,
 const YV12_BUFFER_CONFIG  *yv12,
 void *user_priv)
{
 /** vpx_img_wrap() doesn't allow specifying independent strides for
      * the Y, U, and V planes, nor other alignment adjustments that
      * might be representable by a YV12_BUFFER_CONFIG, so we just
      * initialize all the fields.*/
    img->fmt = VPX_IMG_FMT_I420;
    img->w = yv12->y_stride;
    img->h = (yv12->y_height + 2 * VP8BORDERINPIXELS + 15) & ~15;
    img->d_w = yv12->y_width;
    img->d_h = yv12->y_height;
    img->x_chroma_shift = 1;
    img->y_chroma_shift = 1;
    img->planes[VPX_PLANE_Y] = yv12->y_buffer;
    img->planes[VPX_PLANE_U] = yv12->u_buffer;
    img->planes[VPX_PLANE_V] = yv12->v_buffer;
    img->planes[VPX_PLANE_ALPHA] = NULL;
    img->stride[VPX_PLANE_Y] = yv12->y_stride;
    img->stride[VPX_PLANE_U] = yv12->uv_stride;
    img->stride[VPX_PLANE_V] = yv12->uv_stride;
    img->stride[VPX_PLANE_ALPHA] = yv12->y_stride;
    img->bit_depth = 8;
    img->bps = 12;
    img->user_priv = user_priv;
    img->img_data = yv12->buffer_alloc;
    img->img_data_owner = 0;
    img->self_allocd = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modifier_setbuffer(png_modifier *pm)
{
   modifier_crc(pm->buffer);
   pm->buffer_count = png_get_uint_32(pm->buffer)+12;
   pm->buffer_position = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t getSecureStops(List<Vector<uint8_t> > &secureStops) {
 Parcel data, reply;
        data.writeInterfaceToken(IDrm::getInterfaceDescriptor());

 status_t status = remote()->transact(GET_SECURE_STOPS, data, &reply);
 if (status != OK) {
 return status;
 }

        secureStops.clear();
 uint32_t count = reply.readInt32();
 for (size_t i = 0; i < count; i++) {
 Vector<uint8_t> secureStop;
            readVector(reply, secureStop);
            secureStops.push_back(secureStop);
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: png_row_in_interlace_pass(png_uint_32 y, int pass)
{
 /* Is row 'y' in pass 'pass'? */
 int x;
   y &= 7;
 ++pass;
 for (x=0; x<8; ++x) if (adam7[y][x] == pass)
 return 1;

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: compare_read(struct display *dp, int applied_transforms)
{
 /* Compare the png_info from read_ip with original_info */
 size_t rowbytes;
   png_uint_32 width, height;
 int bit_depth, color_type;
 int interlace_method, compression_method, filter_method;
 const char *e = NULL;

   png_get_IHDR(dp->read_pp, dp->read_ip, &width, &height, &bit_depth,
 &color_type, &interlace_method, &compression_method, &filter_method);

#  define C(item) if (item != dp->item) \
      display_log(dp, APP_WARNING, "IHDR " #item "(%lu) changed to %lu",\
 (unsigned long)dp->item, (unsigned long)item), e = #item

 /* The IHDR should be identical: */
   C(width);
   C(height);
   C(bit_depth);
   C(color_type);
   C(interlace_method);
   C(compression_method);
   C(filter_method);

 /* 'e' remains set to the name of the last thing changed: */
 if (e)
      display_log(dp, APP_ERROR, "IHDR changed (%s)", e);

 /* All the chunks from the original PNG should be preserved in the output PNG
    * because the PNG format has not been changed.
    */

    {
       unsigned long chunks =
          png_get_valid(dp->read_pp, dp->read_ip, 0xffffffff);
       if (chunks != dp->chunks)
          display_log(dp, APP_FAIL, "PNG chunks changed from 0x%lx to 0x%lx",
             (unsigned long)dp->chunks, chunks);
 }

 /* rowbytes should be the same */
   rowbytes = png_get_rowbytes(dp->read_pp, dp->read_ip);

 /* NOTE: on 64-bit systems this may trash the top bits of rowbytes,
    * which could lead to weird error messages.
    */
 if (rowbytes != dp->original_rowbytes)
      display_log(dp, APP_ERROR, "PNG rowbytes changed from %lu to %lu",
 (unsigned long)dp->original_rowbytes, (unsigned long)rowbytes);

 /* The rows should be the same too, unless the applied transforms includes
    * the shift transform, in which case low bits may have been lost.
    */
 {
      png_bytepp rows = png_get_rows(dp->read_pp, dp->read_ip);
 unsigned int mask; /* mask (if not zero) for the final byte */

 if (bit_depth < 8)
 {
 /* Need the stray bits at the end, this depends only on the low bits
          * of the image width; overflow does not matter.  If the width is an
          * exact multiple of 8 bits this gives a mask of 0, not 0xff.
          */
         mask = 0xff & (0xff00 >> ((bit_depth * width) & 7));
 }

 else
         mask = 0;

 if (rows == NULL)
         display_log(dp, LIBPNG_BUG, "png_get_rows returned NULL");

 if ((applied_transforms & PNG_TRANSFORM_SHIFT) == 0 ||
 (dp->active_transforms & PNG_TRANSFORM_SHIFT) == 0 ||
         color_type == PNG_COLOR_TYPE_PALETTE)
 {
 unsigned long y;

 for (y=0; y<height; ++y)
 {
            png_bytep row = rows[y];
            png_bytep orig = dp->original_rows[y];

 if (memcmp(row, orig, rowbytes-(mask != 0)) != 0 || (mask != 0 &&
 ((row[rowbytes-1] & mask) != (orig[rowbytes-1] & mask))))
 {
 size_t x;

 /* Find the first error */
 for (x=0; x<rowbytes-1; ++x) if (row[x] != orig[x])
 break;

               display_log(dp, APP_FAIL,
 "byte(%lu,%lu) changed 0x%.2x -> 0x%.2x",
 (unsigned long)x, (unsigned long)y, orig[x], row[x]);
 return 0; /* don't keep reporting failed rows on 'continue' */
 }
 }
 }

 else
 {
 unsigned long y;
 int bpp; /* bits-per-pixel then bytes-per-pixel */
 /* components are up to 8 bytes in size */
         png_byte sig_bits[8];
         png_color_8p sBIT;

 if (png_get_sBIT(dp->read_pp, dp->read_ip, &sBIT) != PNG_INFO_sBIT)
            display_log(dp, INTERNAL_ERROR,
 "active shift transform but no sBIT in file");

 switch (color_type)
 {
 case PNG_COLOR_TYPE_GRAY:
               sig_bits[0] = sBIT->gray;
               bpp = bit_depth;
 break;

 case PNG_COLOR_TYPE_GA:
               sig_bits[0] = sBIT->gray;
               sig_bits[1] = sBIT->alpha;
               bpp = 2 * bit_depth;
 break;

 case PNG_COLOR_TYPE_RGB:
               sig_bits[0] = sBIT->red;
               sig_bits[1] = sBIT->green;
               sig_bits[2] = sBIT->blue;
               bpp = 3 * bit_depth;
 break;

 case PNG_COLOR_TYPE_RGBA:
               sig_bits[0] = sBIT->red;
               sig_bits[1] = sBIT->green;
               sig_bits[2] = sBIT->blue;
               sig_bits[3] = sBIT->alpha;
               bpp = 4 * bit_depth;
 break;

 default:
               display_log(dp, LIBPNG_ERROR, "invalid colour type %d",
                  color_type);
 /*NOTREACHED*/
               bpp = 0;
 break;
 }

 {
 int b;

 for (b=0; 8*b<bpp; ++b)
 {
 /* libpng should catch this; if not there is a security issue
                * because an app (like this one) may overflow an array. In fact
                * libpng doesn't catch this at present.
                */
 if (sig_bits[b] == 0 || sig_bits[b] > bit_depth/*!palette*/)
                  display_log(dp, LIBPNG_BUG,
 "invalid sBIT[%u]  value %d returned for PNG bit depth %d",
                     b, sig_bits[b], bit_depth);
 }
 }

 if (bpp < 8 && bpp != bit_depth)
 {
 /* sanity check; this is a grayscale PNG; something is wrong in the
             * code above.
             */
            display_log(dp, INTERNAL_ERROR, "invalid bpp %u for bit_depth %u",
               bpp, bit_depth);
 }

 switch (bit_depth)

          {
             int b;
 
            case 16: /* Two bytes per component, bit-endian */
               for (b = (bpp >> 4); b > 0; )
                {
                   unsigned int sig = (unsigned int)(0xffff0000 >> sig_bits[b]);
 
                  sig_bits[2*b+1] = (png_byte)sig;
                  sig_bits[2*b+0] = (png_byte)(sig >> 8); /* big-endian */
 }
 break;

 case 8: /* One byte per component */
 for (b=0; b*8 < bpp; ++b)
                  sig_bits[b] = (png_byte)(0xff00 >> sig_bits[b]);
 break;

 case 1: /* allowed, but dumb */
 /* Value is 1 */
               sig_bits[0] = 0xff;
 break;

 case 2: /* Replicate 4 times */
 /* Value is 1 or 2 */
               b = 0x3 & ((0x3<<2) >> sig_bits[0]);
               b |= b << 2;
               b |= b << 4;
               sig_bits[0] = (png_byte)b;
 break;

 case 4: /* Relicate twice */
 /* Value is 1, 2, 3 or 4 */
               b = 0xf & ((0xf << 4) >> sig_bits[0]);
               b |= b << 4;
               sig_bits[0] = (png_byte)b;
 break;

 default:
               display_log(dp, LIBPNG_BUG, "invalid bit depth %d", bit_depth);
 break;
 }

 /* Convert bpp to bytes; this gives '1' for low-bit depth grayscale,
          * where there are multiple pixels per byte.
          */
         bpp = (bpp+7) >> 3;

 /* The mask can be combined with sig_bits[0] */
 if (mask != 0)
 {
            mask &= sig_bits[0];

 if (bpp != 1 || mask == 0)
               display_log(dp, INTERNAL_ERROR, "mask calculation error %u, %u",
                  bpp, mask);
 }

 for (y=0; y<height; ++y)
 {
            png_bytep row = rows[y];
            png_bytep orig = dp->original_rows[y];
 unsigned long x;

 for (x=0; x<(width-(mask!=0)); ++x)
 {
 int b;

 for (b=0; b<bpp; ++b)
 {
 if ((*row++ & sig_bits[b]) != (*orig++ & sig_bits[b]))
 {
                     display_log(dp, APP_FAIL,
 "significant bits at (%lu[%u],%lu) changed %.2x->%.2x",
                        x, b, y, orig[-1], row[-1]);
 return 0;
 }
 }
 }

 if (mask != 0 && (*row & mask) != (*orig & mask))
 {
               display_log(dp, APP_FAIL,
 "significant bits at (%lu[end],%lu) changed", x, y);
 return 0;
 }
 } /* for y */
 }
 }

 return 1; /* compare succeeded */
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void *sock_poll_thread(void *arg)
{
 struct pollfd pfds[MAX_POLL];
    memset(pfds, 0, sizeof(pfds));
 int h = (intptr_t)arg;

     for(;;)
     {
         prepare_poll_fds(h, pfds);
        int ret = poll(pfds, ts[h].poll_count, -1);
         if(ret == -1)
         {
             APPL_TRACE_ERROR("poll ret -1, exit the thread, errno:%d, err:%s", errno, strerror(errno));
 break;
 }
 if(ret != 0)
 {
 int need_process_data_fd = TRUE;
 if(pfds[0].revents) //cmd fd always is the first one
 {
                asrt(pfds[0].fd == ts[h].cmd_fdr);
 if(!process_cmd_sock(h))
 {
                    APPL_TRACE_DEBUG("h:%d, process_cmd_sock return false, exit...", h);
 break;
 }
 if(ret == 1)
                    need_process_data_fd = FALSE;
 else ret--; //exclude the cmd fd
 }
 if(need_process_data_fd)
                process_data_sock(h, pfds, ret);
 }
 else {APPL_TRACE_DEBUG("no data, select ret: %d", ret)};
 }
    ts[h].thread_id = -1;
    APPL_TRACE_DEBUG("socket poll thread exiting, h:%d", h);
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void onMessage(const omx_message &msg) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMXObserver::getInterfaceDescriptor());
        data.write(&msg, sizeof(msg));

        ALOGV("onMessage writing message %d, size %zu", msg.type, sizeof(msg));

        remote()->transact(OBSERVER_ON_MSG, data, &reply, IBinder::FLAG_ONEWAY);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_fill_num_mem_rec(void *pv_api_ip, void *pv_api_op)
{

 ih264d_fill_mem_rec_ip_t *ps_mem_q_ip;
 ih264d_fill_mem_rec_op_t *ps_mem_q_op;
    WORD32 level;
    UWORD32 num_reorder_frames;
    UWORD32 num_ref_frames;
    UWORD32 num_extra_disp_bufs;
    UWORD32 u4_dpb_size_num_frames;
 iv_mem_rec_t *memTab;

    UWORD32 chroma_format, u4_share_disp_buf;
    UWORD32 u4_total_num_mbs;
    UWORD32 luma_width, luma_width_in_mbs;
    UWORD32 luma_height, luma_height_in_mbs;
    UWORD32 max_dpb_size;

    ps_mem_q_ip = (ih264d_fill_mem_rec_ip_t *)pv_api_ip;
    ps_mem_q_op = (ih264d_fill_mem_rec_op_t *)pv_api_op;

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, i4_level))
 {
        level = ps_mem_q_ip->i4_level;
 }
 else
 {
        level = H264_LEVEL_3_1;
 }

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, u4_num_reorder_frames))
 {
        num_reorder_frames = ps_mem_q_ip->u4_num_reorder_frames;
 }
 else
 {
        num_reorder_frames = H264_MAX_REF_PICS;
 }

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, u4_num_ref_frames))
 {
        num_ref_frames = ps_mem_q_ip->u4_num_ref_frames;
 }
 else
 {
        num_ref_frames = H264_MAX_REF_PICS;
 }

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, u4_num_extra_disp_buf))
 {
        num_extra_disp_bufs = ps_mem_q_ip->u4_num_extra_disp_buf;
 }
 else
 {
        num_extra_disp_bufs = 0;
 }

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, u4_share_disp_buf))
 {
#ifndef LOGO_EN
        u4_share_disp_buf = ps_mem_q_ip->u4_share_disp_buf;
#else
        u4_share_disp_buf = 0;
#endif
 }
 else
 {
        u4_share_disp_buf = 0;
 }

 if(ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_size
 > offsetof(ih264d_fill_mem_rec_ip_t, e_output_format))
 {
        chroma_format = ps_mem_q_ip->e_output_format;
 }
 else
 {
        chroma_format = -1;
 }

 if((chroma_format != IV_YUV_420P) && (chroma_format != IV_YUV_420SP_UV)
 && (chroma_format != IV_YUV_420SP_VU))
 {
        u4_share_disp_buf = 0;
 }
 if(0 == u4_share_disp_buf)
        num_extra_disp_bufs = 0;

 {

        luma_height = ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht;
        luma_width = ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd;

        luma_height = ALIGN32(luma_height);
        luma_width = ALIGN16(luma_width);
        luma_width_in_mbs = luma_width >> 4;
        luma_height_in_mbs = luma_height >> 4;
        u4_total_num_mbs = (luma_height * luma_width) >> 8;
 }
 /*
     * If level is lesser than 31 and the resolution required is higher,
     * then make the level at least 31.
     */
 if(u4_total_num_mbs > MAX_MBS_LEVEL_30 && level < H264_LEVEL_3_1)
 {
        level = H264_LEVEL_3_1;
 }

 if((level < MIN_LEVEL_SUPPORTED) || (level > MAX_LEVEL_SUPPORTED))
 {
        ps_mem_q_op->s_ivd_fill_mem_rec_op_t.u4_error_code |=
                        ERROR_LEVEL_UNSUPPORTED;
 return (IV_FAIL);
 }

 if(num_ref_frames > H264_MAX_REF_PICS)
 {
        ps_mem_q_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= ERROR_NUM_REF;
        num_ref_frames = H264_MAX_REF_PICS;
 }

 if(num_reorder_frames > H264_MAX_REF_PICS)
 {
        ps_mem_q_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= ERROR_NUM_REF;
        num_reorder_frames = H264_MAX_REF_PICS;
 }
    memTab = ps_mem_q_ip->s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location;

    memTab[MEM_REC_IV_OBJ].u4_mem_size = sizeof(iv_obj_t);
    memTab[MEM_REC_IV_OBJ].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_IV_OBJ].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    H264_DEC_DEBUG_PRINT("MEM_REC_IV_OBJ MEM Size = %d\n",
                         memTab[MEM_REC_IV_OBJ].u4_mem_size);

    memTab[MEM_REC_CODEC].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_CODEC].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_CODEC].u4_mem_size = sizeof(dec_struct_t);

 {
        UWORD32 mvinfo_size, mv_info_size_pad;
        UWORD32 MVbank, MVbank_pad;
        UWORD32 Ysize;
        UWORD32 UVsize;
        UWORD32 one_frm_size;

        UWORD32 extra_mem = 0;

        UWORD32 pad_len_h, pad_len_v;

 /*
         * For low_delay, use num_buf as 2 -
         *      num_buf = (num_buf_ref) + 1;
         * where num_buf_ref is 1.
         */
        UWORD32 num_buf;

 {
            UWORD32 num_bufs_app, num_bufs_level;

            num_bufs_app = num_ref_frames + num_reorder_frames + 1;

 if(num_bufs_app <= 1)
                num_bufs_app = 2;

            num_bufs_level = ih264d_get_dpb_size_new(level, (luma_width >> 4),
 (luma_height >> 4));

            max_dpb_size = num_bufs_level;

            num_bufs_level = num_bufs_level * 2 + 1;

            num_buf = MIN(num_bufs_level, num_bufs_app);

            num_buf += num_extra_disp_bufs;

 }

        mvinfo_size = ((luma_width * (luma_height)) >> 4);

        mv_info_size_pad = ((luma_width * (PAD_MV_BANK_ROW)) >> 4);

 Ysize = ALIGN32((luma_width + (PAD_LEN_Y_H << 1)))
 * (luma_height + (PAD_LEN_Y_V << 2));


 UVsize = Ysize >> 2;
 if(u4_share_disp_buf == 1)
 {
 /* In case of buffers getting shared between application and library
             there is no need of reference memtabs. Instead of setting the i4_size
             to zero, it is reduced to a small i4_size to ensure that changes
             in the code are minimal */

 if((chroma_format == IV_YUV_420P)
 || (chroma_format == IV_YUV_420SP_UV)
 || (chroma_format == IV_YUV_420SP_VU))
 {
 Ysize = 64;
 }
 if(chroma_format == IV_YUV_420SP_UV)
 {
 UVsize = 64;
 }
 }

        one_frm_size = (((Ysize + 127) >> 7) << 7)
 + ((((UVsize << 1) + 127) >> 7) << 7);


 /*Add memory for colocated MB*/
 MVbank = sizeof(mv_pred_t) * mvinfo_size;
 MVbank_pad = sizeof(mv_pred_t) * mv_info_size_pad;

 MVbank = (((MVbank + 127) >> 7) << 7);

 MVbank_pad = (((MVbank_pad + 127) >> 7) << 7);

        memTab[MEM_REC_MVBANK].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_MVBANK].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_MVBANK].u4_mem_size = (MVbank + MVbank_pad)
 * (MIN(max_dpb_size, num_ref_frames) + 1);


        memTab[MEM_REC_REF_PIC].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_REF_PIC].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_REF_PIC].u4_mem_size = one_frm_size * num_buf;

 }

    memTab[MEM_REC_DEBLK_MB_INFO].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_DEBLK_MB_INFO].e_mem_type =
                    IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_DEBLK_MB_INFO].u4_mem_size = (((((u4_total_num_mbs
 + (luma_width >> 4)) * sizeof(deblk_mb_t)) + 127) >> 7) << 7);

    memTab[MEM_REC_NEIGHBOR_INFO].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_NEIGHBOR_INFO].e_mem_type =
                    IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_NEIGHBOR_INFO].u4_mem_size = sizeof(mb_neigbour_params_t)
 * ((luma_width + 16) >> 4) * 2 * 2;
 {
        WORD32 size;
        WORD32 num_entries;

        num_entries = MIN(MAX_FRAMES, num_ref_frames);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);
        size *= u4_total_num_mbs;
        size += sizeof(dec_slice_struct_t) * u4_total_num_mbs;
        memTab[MEM_REC_SLICE_HDR].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_SLICE_HDR].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_SLICE_HDR].u4_mem_size = size;
 }
 {

        UWORD32 u4_num_entries;

        u4_num_entries = u4_total_num_mbs;

        memTab[MEM_REC_MB_INFO].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_MB_INFO].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_MB_INFO].u4_mem_size = sizeof(dec_mb_info_t)
 * u4_num_entries;

        memTab[MEM_REC_PRED_INFO].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_PRED_INFO].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;

        memTab[MEM_REC_PRED_INFO].u4_mem_size = sizeof(pred_info_t) * 2*32;

        memTab[MEM_REC_COEFF_DATA].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_COEFF_DATA].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_COEFF_DATA].u4_mem_size = MB_LUM_SIZE * sizeof(WORD16);
 /*For I16x16 MBs, 16 4x4 AC coeffs and 1 4x4 DC coeff TU blocks will be sent
        For all MBs along with 8 4x4 AC coeffs 2 2x2 DC coeff TU blocks will be sent
        So use 17 4x4 TU blocks for luma and 9 4x4 TU blocks for chroma */
        memTab[MEM_REC_COEFF_DATA].u4_mem_size += u4_num_entries
 * (MAX(17 * sizeof(tu_sblk4x4_coeff_data_t),4 * sizeof(tu_blk8x8_coeff_data_t))
 + 9 * sizeof(tu_sblk4x4_coeff_data_t));
        memTab[MEM_REC_COEFF_DATA].u4_mem_size += u4_num_entries * 32;

 }

    memTab[MEM_REC_SPS].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_SPS].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_SPS].u4_mem_size = ((sizeof(dec_seq_params_t))
 * MAX_NUM_SEQ_PARAMS);

    memTab[MEM_REC_PPS].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_PPS].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_PPS].u4_mem_size = (sizeof(dec_pic_params_t))
 * MAX_NUM_PIC_PARAMS;

 {
        UWORD32 u4_mem_size;

        u4_mem_size = 0;
        u4_mem_size += (((sizeof(dec_err_status_t) + 127) >> 7) << 7);
        u4_mem_size += sizeof(sei);
        u4_mem_size += sizeof(dpb_commands_t);
        u4_mem_size += sizeof(dec_bit_stream_t);
        u4_mem_size += sizeof(dec_slice_params_t);
        u4_mem_size += MAX(sizeof(dec_seq_params_t), sizeof(dec_pic_params_t));

        memTab[MEM_REC_EXTRA_MEM].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_EXTRA_MEM].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_EXTRA_MEM].u4_mem_size = u4_mem_size;
 }

 {

        UWORD32 u4_mem_size;

        u4_mem_size = 0;
        u4_mem_size += ((TOTAL_LIST_ENTRIES + PAD_MAP_IDX_POC) * sizeof(void *));
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += (sizeof(bin_ctxt_model_t) * NUM_CABAC_CTXTS);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += sizeof(ctxt_inc_mb_info_t);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += sizeof(UWORD32) * (MAX_REF_BUFS * MAX_REF_BUFS);
        u4_mem_size = ALIGN64(u4_mem_size);

        u4_mem_size += MAX_REF_BUF_SIZE * 2;
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += ((sizeof(WORD16)) * PRED_BUFFER_WIDTH
 * PRED_BUFFER_HEIGHT * 2);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += sizeof(UWORD8) * (MB_LUM_SIZE);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += sizeof(parse_pmbarams_t) * luma_width_in_mbs; //Max recon mb group*/
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += (sizeof(parse_part_params_t) * luma_width_in_mbs) << 4; //Max recon mb group*/
        u4_mem_size = ALIGN64(u4_mem_size);

        u4_mem_size += 2 * MAX_REF_BUFS * sizeof(struct pic_buffer_t);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += 2 * MAX_REF_BUFS * sizeof(struct pic_buffer_t);
        u4_mem_size = ALIGN64(u4_mem_size);
        u4_mem_size += (sizeof(UWORD32) * 3 * (MAX_REF_BUFS * MAX_REF_BUFS)) << 3;
        u4_mem_size = ALIGN64(u4_mem_size);

        u4_mem_size += sizeof(UWORD32) * 2 * 3
 * ((MAX_FRAMES << 1) * (MAX_FRAMES << 1));
        u4_mem_size = ALIGN64(u4_mem_size);

        memTab[MEM_REC_INTERNAL_SCRATCH].u4_mem_alignment =
 (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_INTERNAL_SCRATCH].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_SCRATCH_MEM;
        memTab[MEM_REC_INTERNAL_SCRATCH].u4_mem_size = u4_mem_size;
 }

 {

        UWORD32 u4_mem_used;
        UWORD32 u4_numRows = MB_SIZE << 1;
        UWORD32 u4_blk_wd = ((luma_width_in_mbs << 4) >> 1) + 8;

        u4_mem_used = 0;
        u4_mem_used += ((luma_width_in_mbs * sizeof(deblkmb_neighbour_t)) << 1);
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += (sizeof(neighbouradd_t) << 2);
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += ((sizeof(ctxt_inc_mb_info_t))
 * (((luma_width_in_mbs + 1) << 1) + 1));
        u4_mem_used = ALIGN64(u4_mem_used);

        u4_mem_used += (sizeof(mv_pred_t) * luma_width_in_mbs * 16);
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += (sizeof(mv_pred_t) * luma_width_in_mbs * 16);
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += (sizeof(mv_pred_t) * luma_width_in_mbs * 4
 * MV_SCRATCH_BUFS);
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_numRows = BLK8x8SIZE << 1;

        u4_blk_wd = ((luma_width_in_mbs << 3) >> 1) + 8;

        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * u4_numRows * u4_blk_wd;
        u4_mem_used += 32;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * (luma_width + 16) * 2;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * (luma_width + 16) * 2;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(UWORD8) * (luma_width + 16) * 2;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += sizeof(mb_neigbour_params_t) * (luma_width_in_mbs + 1)
 * luma_height_in_mbs;
        u4_mem_used += luma_width;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += luma_width;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += luma_width;
        u4_mem_used = ALIGN64(u4_mem_used);

        u4_mem_used += ((MB_SIZE + 4) << 1) * PAD_LEN_Y_H;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += ((BLK8x8SIZE + 2) << 1) * PAD_LEN_UV_H;
        u4_mem_used = ALIGN64(u4_mem_used);
        u4_mem_used += ((BLK8x8SIZE + 2) << 1) * PAD_LEN_UV_H;
        u4_mem_used = ALIGN64(u4_mem_used);
        memTab[MEM_REC_INTERNAL_PERSIST].u4_mem_alignment =
 (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_INTERNAL_PERSIST].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_INTERNAL_PERSIST].u4_mem_size = u4_mem_used;
 }

    memTab[MEM_REC_BITSBUF].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_BITSBUF].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_BITSBUF].u4_mem_size = MAX(256000, (luma_width * luma_height * 3 / 2));

 {

        UWORD32 u4_thread_struct_size = ithread_get_handle_size();

        memTab[MEM_REC_THREAD_HANDLE].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_THREAD_HANDLE].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_THREAD_HANDLE].u4_mem_size = u4_thread_struct_size * 2;

 }

    memTab[MEM_REC_PARSE_MAP].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_PARSE_MAP].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_PARSE_MAP].u4_mem_size = u4_total_num_mbs;

    memTab[MEM_REC_PROC_MAP].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_PROC_MAP].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_PROC_MAP].u4_mem_size = u4_total_num_mbs;

    memTab[MEM_REC_SLICE_NUM_MAP].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_SLICE_NUM_MAP].e_mem_type =
                    IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_SLICE_NUM_MAP].u4_mem_size = u4_total_num_mbs
 * sizeof(UWORD16);

    memTab[MEM_REC_DPB_MGR].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_DPB_MGR].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_DPB_MGR].u4_mem_size = sizeof(dpb_manager_t);

    memTab[MEM_REC_BACKUP].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_BACKUP].e_mem_type = IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
    memTab[MEM_REC_BACKUP].u4_mem_size = sizeof(iv_mem_rec_t) * MEM_REC_CNT;

 {

        UWORD32 u4_mem_size;

        u4_mem_size = sizeof(disp_mgr_t);
        u4_mem_size += sizeof(buf_mgr_t) + ithread_get_mutex_lock_size();
        u4_mem_size += sizeof(struct pic_buffer_t) * (H264_MAX_REF_PICS * 2);

        memTab[MEM_REC_PIC_BUF_MGR].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_PIC_BUF_MGR].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_PIC_BUF_MGR].u4_mem_size = u4_mem_size;
 }

 {
        UWORD32 u4_mem_size;

        u4_mem_size  = sizeof(buf_mgr_t) + ithread_get_mutex_lock_size();
        u4_mem_size += sizeof(col_mv_buf_t) * (H264_MAX_REF_PICS * 2);
        u4_mem_size = ALIGN128(u4_mem_size);
        u4_mem_size += ((luma_width * luma_height) >> 4)
 * (MIN(max_dpb_size, num_ref_frames) + 1);
        memTab[MEM_REC_MV_BUF_MGR].u4_mem_alignment = (128 * 8) / CHAR_BIT;
        memTab[MEM_REC_MV_BUF_MGR].e_mem_type =
                        IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;
        memTab[MEM_REC_MV_BUF_MGR].u4_mem_size = u4_mem_size;
 }

    memTab[MEM_REC_PRED_INFO_PKD].u4_mem_alignment = (128 * 8) / CHAR_BIT;
    memTab[MEM_REC_PRED_INFO_PKD].e_mem_type =
                    IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM;

 {
        UWORD32 u4_num_entries;
        u4_num_entries = u4_total_num_mbs;

 if(1 == num_ref_frames)
            u4_num_entries *= 16;
 else
            u4_num_entries *= 16 * 2;

        memTab[MEM_REC_PRED_INFO_PKD].u4_mem_size = sizeof(pred_info_pkd_t)
 * u4_num_entries;
 }

    ps_mem_q_op->s_ivd_fill_mem_rec_op_t.u4_num_mem_rec_filled = MEM_REC_CNT;


 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: Segment::~Segment() {
 const long count = m_clusterCount + m_clusterPreloadCount;

 Cluster** i = m_clusters;
 Cluster** j = m_clusters + count;

 
   while (i != j) {
     Cluster* const p = *i++;
    assert(p);
     delete p;
   }
 
 delete[] m_clusters;

 delete m_pTracks;

   delete m_pInfo;
   delete m_pCues;
   delete m_pChapters;
   delete m_pSeekHead;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_cam_param_ext(dec_state_t *ps_dec)
{

    UWORD32 u4_bits_to_flush;

    u4_bits_to_flush = CAMERA_PARAMETER_EXTENSION_LEN;

 while(u4_bits_to_flush >= 32 )
 {
        impeg2d_bit_stream_flush(&ps_dec->s_bit_stream,32);
        u4_bits_to_flush = u4_bits_to_flush - 32;
 }

 if(u4_bits_to_flush > 0)
 {
        impeg2d_bit_stream_flush(&ps_dec->s_bit_stream,u4_bits_to_flush);
 }

  impeg2d_next_start_code(ps_dec);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Chapters::Atom::GetStopTime(const Chapters* pChapters) const
{
    return GetTime(pChapters, m_stop_timecode);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void internal_read_ready(void *context) {
  assert(context != NULL);

 socket_t *socket = (void *)context;
  socket->read_ready(socket, socket->context);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool is32bit(pid_t tid) {
 char* exeline;
 if (asprintf(&exeline, "/proc/%d/exe", tid) == -1) {
 return false;
 }
 int fd = TEMP_FAILURE_RETRY(open(exeline, O_RDONLY | O_CLOEXEC));
 int saved_errno = errno;
  free(exeline);
 if (fd == -1) {
    ALOGW("Failed to open /proc/%d/exe %s", tid, strerror(saved_errno));
 return false;
 }

 char ehdr[EI_NIDENT];
 ssize_t bytes = TEMP_FAILURE_RETRY(read(fd, &ehdr, sizeof(ehdr)));
  close(fd);
 if (bytes != (ssize_t) sizeof(ehdr) || memcmp(ELFMAG, ehdr, SELFMAG) != 0) {
 return false;
 }
 if (ehdr[EI_CLASS] == ELFCLASS32) {
 return true;
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int validation_ascii_to_fp(int count, int argc, char **argv)
{
 int    showall = 0;
 double max_error=2; /* As a percentage error-in-last-digit/.5 */
 double max_error_abs=17; /* Used when precision is DBL_DIG */
 double max = 0;
 double max_abs = 0;
 double test = 0; /* Important to test this. */
 int    precision = 5;
 int    nonfinite = 0;
 int    finite = 0;
 int    ok = 0;
 int    failcount = 0;
 int    minorarith = 0;

 while (--argc > 0)
 if (strcmp(*++argv, "-a") == 0)
         showall = 1;
 else if (strcmp(*argv, "-e") == 0 && argc > 0)
 {
 --argc;
         max_error = atof(*++argv);
 }
 else if (strcmp(*argv, "-E") == 0 && argc > 0)
 {
 --argc;
         max_error_abs = atof(*++argv);
 }
 else
 {
         fprintf(stderr, "unknown argument %s\n", *argv);
 return 1;
 }

 do
 {
 png_size_t index;
 int state, failed = 0;
 char buffer[64];

 if (isfinite(test))
 ++finite;
 else
 ++nonfinite;

 if (verbose)
         fprintf(stderr, "%.*g %d\n", DBL_DIG, test, precision);

 /* Check for overflow in the buffer by setting a marker. */
      memset(buffer, 71, sizeof buffer);

      png_ascii_from_fp(0, buffer, precision+10, test, precision);

 /* Allow for a three digit exponent, this stuff will fail if
       * the exponent is bigger than this!
       */
 if (buffer[precision+7] != 71)
 {
         fprintf(stderr, "%g[%d] -> '%s'[%lu] buffer overflow\n", test,
            precision, buffer, (unsigned long)strlen(buffer));
         failed = 1;
 }

 /* Following are used for the number parser below and must be
       * initialized to zero.
       */
      state = 0;
      index = 0;
 if (!isfinite(test))
 {
 /* Expect 'inf' */
 if (test >= 0 && strcmp(buffer, "inf") ||
             test < 0 && strcmp(buffer, "-inf"))
 {
            fprintf(stderr, "%g[%d] -> '%s' but expected 'inf'\n", test,
               precision, buffer);
            failed = 1;
 }
 }
 else if (!png_check_fp_number(buffer, precision+10, &state, &index) ||
          buffer[index] != 0)
 {
         fprintf(stderr, "%g[%d] -> '%s' but has bad format ('%c')\n", test,
         precision, buffer, buffer[index]);
         failed = 1;
 }
 else if (PNG_FP_IS_NEGATIVE(state) && !(test < 0))
 {
         fprintf(stderr, "%g[%d] -> '%s' but negative value not so reported\n",
            test, precision, buffer);
         failed = 1;
         assert(!PNG_FP_IS_ZERO(state));
         assert(!PNG_FP_IS_POSITIVE(state));
 }
 else if (PNG_FP_IS_ZERO(state) && !(test == 0))
 {
         fprintf(stderr, "%g[%d] -> '%s' but zero value not so reported\n",
            test, precision, buffer);
         failed = 1;
         assert(!PNG_FP_IS_NEGATIVE(state));
         assert(!PNG_FP_IS_POSITIVE(state));
 }
 else if (PNG_FP_IS_POSITIVE(state) && !(test > 0))
 {
         fprintf(stderr, "%g[%d] -> '%s' but postive value not so reported\n",
            test, precision, buffer);
         failed = 1;
         assert(!PNG_FP_IS_NEGATIVE(state));
         assert(!PNG_FP_IS_ZERO(state));
 }
 else
 {
 /* Check the result against the original. */
 double out = atof(buffer);
 double change = fabs((out - test)/test);
 double allow = .5/pow(10,
 (precision >= DBL_DIG) ? DBL_DIG-1 : precision-1);

 /* NOTE: if you hit this error case are you compiling with gcc
          * and -O0?  Try -O2 - the errors can accumulate if the FP
          * code above is not optimized and may drift outside the .5 in
          * DBL_DIG allowed.  In any case a small number of errors may
          * occur (very small ones - 1 or 2%) because of rounding in the
          * calculations, either in the conversion API or in atof.
          */
 if (change >= allow && (isfinite(out) ||
             fabs(test/DBL_MAX) <= 1-allow))
 {
 double percent = (precision >= DBL_DIG) ? max_error_abs : max_error;
 double allowp = (change-allow)*100/allow;

 if (precision >= DBL_DIG)
 {
 if (max_abs < allowp) max_abs = allowp;
 }

 else
 {
 if (max < allowp) max = allowp;
 }

 if (showall || allowp >= percent)
 {
               fprintf(stderr,
 "%.*g[%d] -> '%s' -> %.*g number changed (%g > %g (%d%%))\n",
                  DBL_DIG, test, precision, buffer, DBL_DIG, out, change, allow,
 (int)round(allowp));
               failed = 1;
 }
 else
 ++minorarith;
 }
 }

 if (failed)
 ++failcount;
 else
 ++ok;

skip:
 /* Generate a new number and precision. */
      precision = rand();
 if (precision & 1) test = -test;
      precision >>= 1;

 /* Generate random numbers. */
 if (test == 0 || !isfinite(test))
         test = precision+1;
 else
 {
 /* Derive the exponent from the previous rand() value. */
 int exponent = precision % (DBL_MAX_EXP - DBL_MIN_EXP) + DBL_MIN_EXP;
 int tmp;
         test = frexp(test * rand(), &tmp);
         test = ldexp(test, exponent);
         precision >>= 8; /* arbitrary */
 }

 /* This limits the precision to 32 digits, enough for standard
       * IEEE implementations which have at most 15 digits.
       */
      precision = (precision & 0x1f) + 1;
 }
 while (--count);

   printf("Tested %d finite values, %d non-finite, %d OK (%d failed) %d minor "
 "arithmetic errors\n", finite, nonfinite, ok, failcount, minorarith);
   printf(" Error with >=%d digit precision %.2f%%\n", DBL_DIG, max_abs);
   printf(" Error with < %d digit precision %.2f%%\n", DBL_DIG, max);

 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void encrypt_buffer(const uint8_t *src, uint8_t *dst, size_t size,
 ptrdiff_t offset) {
 for (size_t i = 0; i < size; ++i) {
    dst[i] = src[i] ^ test_key[(offset + i) & 15];
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int main(int argc __unused, char** argv)
 {
     signal(SIGPIPE, SIG_IGN);
     char value[PROPERTY_VALUE_MAX];
     bool doLog = (property_get("ro.test_harness", value, "0") > 0) && (atoi(value) == 1);
 pid_t childPid;
 if (doLog && (childPid = fork()) != 0) {
        strcpy(argv[0], "media.log");
        sp<ProcessState> proc(ProcessState::self());
 MediaLogService::instantiate();
 ProcessState::self()->startThreadPool();
 for (;;) {
 siginfo_t info;
 int ret = waitid(P_PID, childPid, &info, WEXITED | WSTOPPED | WCONTINUED);
 if (ret == EINTR) {
 continue;
 }
 if (ret < 0) {
 break;
 }
 char buffer[32];
 const char *code;
 switch (info.si_code) {
 case CLD_EXITED:
                code = "CLD_EXITED";
 break;
 case CLD_KILLED:
                code = "CLD_KILLED";
 break;
 case CLD_DUMPED:
                code = "CLD_DUMPED";
 break;
 case CLD_STOPPED:
                code = "CLD_STOPPED";
 break;
 case CLD_TRAPPED:
                code = "CLD_TRAPPED";
 break;
 case CLD_CONTINUED:
                code = "CLD_CONTINUED";
 break;
 default:
                snprintf(buffer, sizeof(buffer), "unknown (%d)", info.si_code);
                code = buffer;
 break;
 }
 struct rusage usage;
            getrusage(RUSAGE_CHILDREN, &usage);
            ALOG(LOG_ERROR, "media.log", "pid %d status %d code %s user %ld.%03lds sys %ld.%03lds",
                    info.si_pid, info.si_status, code,
                    usage.ru_utime.tv_sec, usage.ru_utime.tv_usec / 1000,
                    usage.ru_stime.tv_sec, usage.ru_stime.tv_usec / 1000);
            sp<IServiceManager> sm = defaultServiceManager();
            sp<IBinder> binder = sm->getService(String16("media.log"));
 if (binder != 0) {
 Vector<String16> args;
                binder->dump(-1, args);
 }
 switch (info.si_code) {
 case CLD_EXITED:
 case CLD_KILLED:
 case CLD_DUMPED: {
                ALOG(LOG_INFO, "media.log", "exiting");
                _exit(0);
 }
 default:
 break;
 }
 }
 } else {
 if (doLog) {
            prctl(PR_SET_PDEATHSIG, SIGKILL); // if parent media.log dies before me, kill me also
            setpgid(0, 0); // but if I die first, don't kill my parent
 }
 InitializeIcuOrDie();
        sp<ProcessState> proc(ProcessState::self());
        sp<IServiceManager> sm = defaultServiceManager();
        ALOGI("ServiceManager: %p", sm.get());
 AudioFlinger::instantiate();
 MediaPlayerService::instantiate();
 ResourceManagerService::instantiate();
 CameraService::instantiate();
 AudioPolicyService::instantiate();
 SoundTriggerHwService::instantiate();
 RadioService::instantiate();
        registerExtensions();
 ProcessState::self()->startThreadPool();
 IPCThreadState::self()->joinThreadPool();
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool effects_enabled()
{
 struct listnode *out_node;

    list_for_each(out_node, &active_outputs_list) {
 struct listnode *fx_node;
 output_context_t *out_ctxt = node_to_item(out_node,
 output_context_t,
                                                  outputs_list_node);

        list_for_each(fx_node, &out_ctxt->effects_list) {
 effect_context_t *fx_ctxt = node_to_item(fx_node,
 effect_context_t,
                                                     output_node);
 if ((fx_ctxt->state == EFFECT_STATE_ACTIVE) &&
 (fx_ctxt->ops.process != NULL))
 return true;
 }
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void reference2_16x16_idct_2d(double *input, double *output) {
 double x;
 for (int l = 0; l < 16; ++l) {
 for (int k = 0; k < 16; ++k) {
 double s = 0;
 for (int i = 0; i < 16; ++i) {
 for (int j = 0; j < 16; ++j) {
          x = cos(PI * j * (l + 0.5) / 16.0) *
              cos(PI * i * (k + 0.5) / 16.0) *
              input[i * 16 + j] / 256;
 if (i != 0)
            x *= sqrt(2.0);
 if (j != 0)
            x *= sqrt(2.0);
          s += x;
 }
 }
      output[k*16+l] = s;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_get_tile_pos(pps_t *ps_pps,
 sps_t *ps_sps,
                                   WORD32 ctb_x,
                                   WORD32 ctb_y,
                                   WORD32 *pi4_ctb_tile_x,
                                   WORD32 *pi4_ctb_tile_y,
                                   WORD32 *pi4_tile_idx)
{

 tile_t *ps_tile_tmp;
    WORD32 i;
    WORD32 tile_row, tile_col;

 if(ctb_x < 0 || ctb_y < 0)
 {
 *pi4_ctb_tile_x = 0;
 *pi4_ctb_tile_y = 0;
 *pi4_tile_idx = 0;

 return (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }

    tile_row = 0;
    tile_col = 0;
    ps_tile_tmp = ps_pps->ps_tile;
 if(0 == ps_pps->i1_tiles_enabled_flag)
 {
 *pi4_ctb_tile_x = ctb_x;
 *pi4_ctb_tile_y = ctb_y;
 *pi4_tile_idx = 0;
 }
 else
 {
 for(i = 0; i < ps_pps->i1_num_tile_columns; i++)
 {
            WORD16 next_tile_ctb_x;
            ps_tile_tmp = ps_pps->ps_tile + i; //* ps_pps->i1_num_tile_rows;
 if((ps_pps->i1_num_tile_columns - 1) == i)
 {
                next_tile_ctb_x = ps_sps->i2_pic_wd_in_ctb;
 }
 else
 {
 tile_t *ps_tile_next_tmp;
                ps_tile_next_tmp = ps_pps->ps_tile + i + 1;
                next_tile_ctb_x = ps_tile_next_tmp->u1_pos_x;
 }
 if((ctb_x >= ps_tile_tmp->u1_pos_x) && (ctb_x < next_tile_ctb_x))
 {
                tile_col = i;
 break;
 }
 }
 *pi4_ctb_tile_x = ctb_x - ps_tile_tmp->u1_pos_x;

 for(i = 0; i < ps_pps->i1_num_tile_rows; i++)
 {
            WORD16 next_tile_ctb_y;
            ps_tile_tmp = ps_pps->ps_tile + i * ps_pps->i1_num_tile_columns;
 if((ps_pps->i1_num_tile_rows - 1) == i)
 {
                next_tile_ctb_y = ps_sps->i2_pic_ht_in_ctb;
 }
 else
 {
 tile_t *ps_tile_next_tmp;
                ps_tile_next_tmp = ps_pps->ps_tile + ((i + 1) * ps_pps->i1_num_tile_columns);
                next_tile_ctb_y = ps_tile_next_tmp->u1_pos_y;
 }
 if((ctb_y >= ps_tile_tmp->u1_pos_y) && (ctb_y < next_tile_ctb_y))
 {
                tile_row = i;
 break;
 }

 }
 *pi4_ctb_tile_y = ctb_y - ps_tile_tmp->u1_pos_y;
 *pi4_tile_idx = tile_row * ps_pps->i1_num_tile_columns
 + tile_col;
 }
 return (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: log_error(struct file *file, int code, const char *what)
 /* Like emit_error but checks the global 'errors' flag */
{
 if (file->global->errors)
      emit_error(file, code, what);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long VideoTrack::Seek(long long time_ns, const BlockEntry*& pResult) const {
 const long status = GetFirst(pResult);

 if (status < 0) // buffer underflow, etc
 return status;

  assert(pResult);

 if (pResult->EOS())
 return 0;

 const Cluster* pCluster = pResult->GetCluster();
  assert(pCluster);
  assert(pCluster->GetIndex() >= 0);

 if (time_ns <= pResult->GetBlock()->GetTime(pCluster))
 return 0;

 Cluster** const clusters = m_pSegment->m_clusters;
  assert(clusters);

 const long count = m_pSegment->GetCount(); // loaded only, not pre-loaded
  assert(count > 0);

 Cluster** const i = clusters + pCluster->GetIndex();
  assert(i);
  assert(*i == pCluster);
  assert(pCluster->GetTime() <= time_ns);

 Cluster** const j = clusters + count;

 Cluster** lo = i;
 Cluster** hi = j;

 while (lo < hi) {

 Cluster** const mid = lo + (hi - lo) / 2;
    assert(mid < hi);

    pCluster = *mid;
    assert(pCluster);
    assert(pCluster->GetIndex() >= 0);
    assert(pCluster->GetIndex() == long(mid - m_pSegment->m_clusters));

 const long long t = pCluster->GetTime();

 if (t <= time_ns)
      lo = mid + 1;
 else
      hi = mid;

    assert(lo <= hi);
 }

  assert(lo == hi);
  assert(lo > i);
  assert(lo <= j);

  pCluster = *--lo;
  assert(pCluster);
  assert(pCluster->GetTime() <= time_ns);

  pResult = pCluster->GetEntry(this, time_ns);

 if ((pResult != 0) && !pResult->EOS()) // found a keyframe
 return 0;

 while (lo != i) {
    pCluster = *--lo;

     assert(pCluster);
     assert(pCluster->GetTime() <= time_ns);
 
#if 0
        pResult = pCluster->GetMaxKey(this);
#else
     pResult = pCluster->GetEntry(this, time_ns);
#endif
 
     if ((pResult != 0) && !pResult->EOS())
       return 0;
 }


  pResult = GetEOS();
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: Chapters::Atom::Atom()
{
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const flat_binder_object* Parcel::readObject(bool nullMetaData) const
{
 const size_t DPOS = mDataPos;
 if ((DPOS+sizeof(flat_binder_object)) <= mDataSize) {
 const flat_binder_object* obj
 = reinterpret_cast<const flat_binder_object*>(mData+DPOS);
        mDataPos = DPOS + sizeof(flat_binder_object);
 if (!nullMetaData && (obj->cookie == 0 && obj->binder == 0)) {
            ALOGV("readObject Setting data pos of %p to %zu", this, mDataPos);
 return obj;
 }

 binder_size_t* const OBJS = mObjects;
 const size_t N = mObjectsSize;
 size_t opos = mNextObjectHint;

 if (N > 0) {
            ALOGV("Parcel %p looking for obj at %zu, hint=%zu",
 this, DPOS, opos);

 if (opos < N) {
 while (opos < (N-1) && OBJS[opos] < DPOS) {
                    opos++;
 }
 } else {
                opos = N-1;
 }
 if (OBJS[opos] == DPOS) {
                ALOGV("Parcel %p found obj %zu at index %zu with forward search",
 this, DPOS, opos);
                mNextObjectHint = opos+1;
                ALOGV("readObject Setting data pos of %p to %zu", this, mDataPos);
 return obj;
 }

 while (opos > 0 && OBJS[opos] > DPOS) {
                opos--;
 }
 if (OBJS[opos] == DPOS) {
                ALOGV("Parcel %p found obj %zu at index %zu with backward search",
 this, DPOS, opos);
                mNextObjectHint = opos+1;
                ALOGV("readObject Setting data pos of %p to %zu", this, mDataPos);
 return obj;
 }
 }
        ALOGW("Attempt to read object from Parcel %p at offset %zu that is not in the object list",
 this, DPOS);
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void WT_MuteVoice (S_VOICE_MGR *pVoiceMgr, S_SYNTH *pSynth, S_SYNTH_VOICE *pVoice, EAS_I32 voiceNum)
{

#ifdef DLS_SYNTHESIZER
 if (pVoice->regionIndex & FLAG_RGN_IDX_DLS_SYNTH)
 {
        DLS_MuteVoice(pVoiceMgr, pSynth, pVoice, voiceNum);
 return;
 }
#endif

 /* clear deferred action flags */
    pVoice->voiceFlags &=
 ~(VOICE_FLAG_DEFER_MIDI_NOTE_OFF |
        VOICE_FLAG_SUSTAIN_PEDAL_DEFER_NOTE_OFF |
        VOICE_FLAG_DEFER_MUTE);

 /* set the envelope state */
    pVoiceMgr->wtVoices[voiceNum].eg1State = eEnvelopeStateMuted;
    pVoiceMgr->wtVoices[voiceNum].eg2State = eEnvelopeStateMuted;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline void init_cmd_fd(int h)
{
    asrt(ts[h].cmd_fdr == -1 && ts[h].cmd_fdw == -1);
 if(socketpair(AF_UNIX, SOCK_STREAM, 0, &ts[h].cmd_fdr) < 0)
 {
        APPL_TRACE_ERROR("socketpair failed: %s", strerror(errno));
 return;
 }
    APPL_TRACE_DEBUG("h:%d, cmd_fdr:%d, cmd_fdw:%d", h, ts[h].cmd_fdr, ts[h].cmd_fdw);
    add_poll(h, ts[h].cmd_fdr, 0, SOCK_THREAD_FD_RD, 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::parseSampleAuxiliaryInformationOffsets(
 off64_t offset, off64_t /* size */) {
    ALOGV("parseSampleAuxiliaryInformationOffsets");
 uint8_t version;
 if (mDataSource->readAt(offset, &version, sizeof(version)) != 1) {
 return ERROR_IO;
 }
    offset++;

 uint32_t flags;
 if (!mDataSource->getUInt24(offset, &flags)) {
 return ERROR_IO;
 }
    offset += 3;

 uint32_t entrycount;
 if (!mDataSource->getUInt32(offset, &entrycount)) {
 return ERROR_IO;
 }
    offset += 4;

 if (entrycount > mCurrentSampleInfoOffsetsAllocSize) {
        mCurrentSampleInfoOffsets = (uint64_t*) realloc(mCurrentSampleInfoOffsets, entrycount * 8);
        mCurrentSampleInfoOffsetsAllocSize = entrycount;
 }
    mCurrentSampleInfoOffsetCount = entrycount;

 for (size_t i = 0; i < entrycount; i++) {
 if (version == 0) {
 uint32_t tmp;
 if (!mDataSource->getUInt32(offset, &tmp)) {
 return ERROR_IO;
 }
            mCurrentSampleInfoOffsets[i] = tmp;
            offset += 4;
 } else {
 uint64_t tmp;
 if (!mDataSource->getUInt64(offset, &tmp)) {
 return ERROR_IO;
 }
            mCurrentSampleInfoOffsets[i] = tmp;
            offset += 8;
 }
 }


 off64_t drmoffset = mCurrentSampleInfoOffsets[0]; // from moof

    drmoffset += mCurrentMoofOffset;
 int ivlength;
    CHECK(mFormat->findInt32(kKeyCryptoDefaultIVSize, &ivlength));

 for (size_t i = 0; i < mCurrentSampleInfoCount; i++) {
 Sample *smpl = &mCurrentSamples.editItemAt(i);

        memset(smpl->iv, 0, 16);
 if (mDataSource->readAt(drmoffset, smpl->iv, ivlength) != ivlength) {
 return ERROR_IO;
 }

        drmoffset += ivlength;

 int32_t smplinfosize = mCurrentDefaultSampleInfoSize;
 if (smplinfosize == 0) {
            smplinfosize = mCurrentSampleInfoSizes[i];
 }
 if (smplinfosize > ivlength) {
 uint16_t numsubsamples;
 if (!mDataSource->getUInt16(drmoffset, &numsubsamples)) {
 return ERROR_IO;
 }
            drmoffset += 2;
 for (size_t j = 0; j < numsubsamples; j++) {
 uint16_t numclear;
 uint32_t numencrypted;
 if (!mDataSource->getUInt16(drmoffset, &numclear)) {
 return ERROR_IO;
 }
                drmoffset += 2;
 if (!mDataSource->getUInt32(drmoffset, &numencrypted)) {
 return ERROR_IO;
 }
                drmoffset += 4;
                smpl->clearsizes.add(numclear);
                smpl->encryptedsizes.add(numencrypted);
 }
 } else {
            smpl->clearsizes.add(0);
            smpl->encryptedsizes.add(smpl->size);
 }
 }


 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Tags::GetTagCount() const { return m_tags_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_error_resilience(OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE* error_resilience)
{
 bool status = true;
 struct venc_headerextension hec_cfg;
 struct venc_multiclicecfg multislice_cfg;
 int rc;
    OMX_U32 resynchMarkerSpacingBytes = 0;
 struct v4l2_control control;

    memset(&control, 0, sizeof(control));

 if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_MPEG4) {
 if (error_resilience->bEnableHEC) {
            hec_cfg.header_extension = 1;
 } else {
            hec_cfg.header_extension = 0;
 }

        hec.header_extension = error_resilience->bEnableHEC;
 }

 if (error_resilience->bEnableRVLC) {
        DEBUG_PRINT_ERROR("RVLC is not Supported");
 return false;
 }

 if (( m_sVenc_cfg.codectype != V4L2_PIX_FMT_H263) &&
 (error_resilience->bEnableDataPartitioning)) {
        DEBUG_PRINT_ERROR("DataPartioning are not Supported for MPEG4/H264");
 return false;
 }

 if (error_resilience->nResynchMarkerSpacing) {
        resynchMarkerSpacingBytes = error_resilience->nResynchMarkerSpacing;
        resynchMarkerSpacingBytes = ALIGN(resynchMarkerSpacingBytes, 8) >> 3;
 }
 if (( m_sVenc_cfg.codectype != V4L2_PIX_FMT_H263) &&
 (error_resilience->nResynchMarkerSpacing)) {
        multislice_cfg.mslice_mode = VEN_MSLICE_CNT_BYTE;
        multislice_cfg.mslice_size = resynchMarkerSpacingBytes;
        control.id = V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MODE;
        control.value = V4L2_MPEG_VIDEO_MULTI_SICE_MODE_MAX_BYTES;
 } else if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_H263 &&
            error_resilience->bEnableDataPartitioning) {
        multislice_cfg.mslice_mode = VEN_MSLICE_GOB;
        multislice_cfg.mslice_size = resynchMarkerSpacingBytes;
        control.id = V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MODE;
        control.value = V4L2_MPEG_VIDEO_MULTI_SLICE_GOB;
 } else {
        multislice_cfg.mslice_mode = VEN_MSLICE_OFF;
        multislice_cfg.mslice_size = 0;
        control.id = V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MODE;
        control.value =  V4L2_MPEG_VIDEO_MULTI_SLICE_MODE_SINGLE;
 }

    DEBUG_PRINT_LOW("%s(): mode = %lu, size = %lu", __func__,
            multislice_cfg.mslice_mode, multislice_cfg.mslice_size);
    DEBUG_PRINT_ERROR("Calling IOCTL set control for id=%x, val=%d", control.id, control.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
       DEBUG_PRINT_ERROR("Failed to set Slice mode control");
 return false;
 }

    DEBUG_PRINT_ERROR("Success IOCTL set control for id=%x, value=%d", control.id, control.value);
    multislice.mslice_mode=control.value;

    control.id = V4L2_CID_MPEG_VIDEO_MULTI_SLICE_MAX_BYTES;
    control.value = resynchMarkerSpacingBytes;
    DEBUG_PRINT_ERROR("Calling IOCTL set control for id=%x, val=%d", control.id, control.value);

    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
       DEBUG_PRINT_ERROR("Failed to set MAX MB control");
 return false;
 }

    DEBUG_PRINT_ERROR("Success IOCTL set control for id=%x, value=%d", control.id, control.value);
    multislice.mslice_mode = multislice_cfg.mslice_mode;
    multislice.mslice_size = multislice_cfg.mslice_size;
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline void dump_heaps() {
        gHeapCache->dump_heaps();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraClient::lock() {
 int callingPid = getCallingPid();
    LOG1("lock (pid %d)", callingPid);
 Mutex::Autolock lock(mLock);

 if (mClientPid == 0) {
        mClientPid = callingPid;
 return NO_ERROR;
 }

 return checkPid();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: row_copy(png_bytep toBuffer, png_const_bytep fromBuffer, unsigned int bitWidth)
 {
    memcpy(toBuffer, fromBuffer, bitWidth >> 3);
 
 if ((bitWidth & 7) != 0)
 {
 unsigned int mask;

 
       toBuffer += bitWidth >> 3;
       fromBuffer += bitWidth >> 3;
      /* The remaining bits are in the top of the byte, the mask is the bits to
       * retain.
       */
      mask = 0xff >> (bitWidth & 7);
       *toBuffer = (png_byte)((*toBuffer & mask) | (*fromBuffer & ~mask));
    }
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int32_t EqualizerGetBand(EffectContext *pContext, uint32_t targetFreq){
 int band = 0;

 if(targetFreq < bandFreqRange[0][0]){
 return -EINVAL;
 }else if(targetFreq == bandFreqRange[0][0]){
 return 0;
 }
 for(int i=0; i<FIVEBAND_NUMBANDS;i++){
 if((targetFreq > bandFreqRange[i][0])&&(targetFreq <= bandFreqRange[i][1])){
            band = i;
 }
 }
 return band;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ACodec::UninitializedState::UninitializedState(ACodec *codec)
 : BaseState(codec) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: UINT32 UIPC_Read(tUIPC_CH_ID ch_id, UINT16 *p_msg_evt, UINT8 *p_buf, UINT32 len)
{
 int n;
 int n_read = 0;
 int fd = uipc_main.ch[ch_id].fd;
 struct pollfd pfd;
    UNUSED(p_msg_evt);

 if (ch_id >= UIPC_CH_NUM)
 {
        BTIF_TRACE_ERROR("UIPC_Read : invalid ch id %d", ch_id);
 return 0;
 }

 if (fd == UIPC_DISCONNECTED)
 {
        BTIF_TRACE_ERROR("UIPC_Read : channel %d closed", ch_id);
 return 0;
 }


 while (n_read < (int)len)
 {
        pfd.fd = fd;
        pfd.events = POLLIN|POLLHUP;

 
         /* make sure there is data prior to attempting read to avoid blocking
            a read for more than poll timeout */
        if (poll(&pfd, 1, uipc_main.ch[ch_id].read_poll_tmo_ms) == 0)
         {
             BTIF_TRACE_EVENT("poll timeout (%d ms)", uipc_main.ch[ch_id].read_poll_tmo_ms);
             break;
 }


 if (pfd.revents & (POLLHUP|POLLNVAL) )
 {
            BTIF_TRACE_EVENT("poll : channel detached remotely");
            UIPC_LOCK();
            uipc_close_locked(ch_id);
            UIPC_UNLOCK();

             return 0;
         }
 
        n = recv(fd, p_buf+n_read, len-n_read, 0);
 
 
 if (n == 0)
 {
            BTIF_TRACE_EVENT("UIPC_Read : channel detached remotely");
            UIPC_LOCK();
            uipc_close_locked(ch_id);
            UIPC_UNLOCK();
 return 0;
 }

 if (n < 0)
 {
            BTIF_TRACE_EVENT("UIPC_Read : read failed (%s)", strerror(errno));
 return 0;
 }

        n_read+=n;

 }

 return n_read;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bdt_init(void)
{
    bdt_log("INIT BT ");
    status = sBtInterface->init(&bt_callbacks);

 if (status == BT_STATUS_SUCCESS) {
        status = sBtInterface->set_os_callouts(&callouts);
 }

    check_return_status(status);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::hasWindowHandleLocked(
 const sp<InputWindowHandle>& windowHandle) const {
 size_t numWindows = mWindowHandles.size();
 for (size_t i = 0; i < numWindows; i++) {
 if (mWindowHandles.itemAt(i) == windowHandle) {
 return true;
 }
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_dec_pic_ext_data(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    UWORD32     u4_start_code;
    IMPEG2D_ERROR_CODES_T e_error;

    e_error = (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;

    ps_stream      = &ps_dec->s_bit_stream;
    u4_start_code   = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);
 while ( (u4_start_code == EXTENSION_START_CODE ||
            u4_start_code == USER_DATA_START_CODE) &&
 (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE == e_error &&
 (ps_stream->u4_offset < ps_stream->u4_max_offset))
 {
 if(u4_start_code == USER_DATA_START_CODE)
 {
            impeg2d_dec_user_data(ps_dec);
 }
 else
 {
            impeg2d_bit_stream_flush(ps_stream,START_CODE_LEN);
            u4_start_code   = impeg2d_bit_stream_nxt(ps_stream,EXT_ID_LEN);
 switch(u4_start_code)
 {
 case QUANT_MATRIX_EXT_ID:
                impeg2d_dec_quant_matrix_ext(ps_dec);
 break;
 case COPYRIGHT_EXT_ID:
                impeg2d_dec_copyright_ext(ps_dec);
 break;
 case PIC_DISPLAY_EXT_ID:
                impeg2d_dec_pic_disp_ext(ps_dec);
 break;
 case CAMERA_PARAM_EXT_ID:
                impeg2d_dec_cam_param_ext(ps_dec);
 break;
 case ITU_T_EXT_ID:
                impeg2d_dec_itu_t_ext(ps_dec);
 break;
 case PIC_SPATIAL_SCALABLE_EXT_ID:
 case PIC_TEMPORAL_SCALABLE_EXT_ID:
                e_error = IMPEG2D_SCALABLITY_NOT_SUP;
 break;
 default:
 /* In case its a reserved extension code */
                impeg2d_bit_stream_flush(ps_stream,EXT_ID_LEN);
                impeg2d_next_start_code(ps_dec);
 break;
 }
 }
        u4_start_code = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);
 }
 return e_error;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Visualizer_command(effect_handle_t self, uint32_t cmdCode, uint32_t cmdSize,
 void *pCmdData, uint32_t *replySize, void *pReplyData) {

 VisualizerContext * pContext = (VisualizerContext *)self;
 int retsize;

 if (pContext == NULL || pContext->mState == VISUALIZER_STATE_UNINITIALIZED) {
 return -EINVAL;
 }


 
     switch (cmdCode) {
     case EFFECT_CMD_INIT:
        if (pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         *(int *) pReplyData = Visualizer_init(pContext);
         break;
     case EFFECT_CMD_SET_CONFIG:
         if (pCmdData == NULL || cmdSize != sizeof(effect_config_t)
                || pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         *(int *) pReplyData = Visualizer_setConfig(pContext,
                 (effect_config_t *) pCmdData);
         break;
     case EFFECT_CMD_GET_CONFIG:
        if (pReplyData == NULL ||
             *replySize != sizeof(effect_config_t)) {
             return -EINVAL;
         }
 Visualizer_getConfig(pContext, (effect_config_t *)pReplyData);
 break;
 case EFFECT_CMD_RESET:

         Visualizer_reset(pContext);
         break;
     case EFFECT_CMD_ENABLE:
        if (pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         if (pContext->mState != VISUALIZER_STATE_INITIALIZED) {
 return -ENOSYS;
 }
        pContext->mState = VISUALIZER_STATE_ACTIVE;
        ALOGV("EFFECT_CMD_ENABLE() OK");

         *(int *)pReplyData = 0;
         break;
     case EFFECT_CMD_DISABLE:
        if (pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         if (pContext->mState != VISUALIZER_STATE_ACTIVE) {
 return -ENOSYS;
 }
        pContext->mState = VISUALIZER_STATE_INITIALIZED;
        ALOGV("EFFECT_CMD_DISABLE() OK");
 *(int *)pReplyData = 0;
 break;

     case EFFECT_CMD_GET_PARAM: {
         if (pCmdData == NULL ||
             cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t)) ||
            pReplyData == NULL ||
             *replySize < (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t))) {
             return -EINVAL;
         }
        memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + sizeof(uint32_t));
 effect_param_t *p = (effect_param_t *)pReplyData;
        p->status = 0;
 *replySize = sizeof(effect_param_t) + sizeof(uint32_t);
 if (p->psize != sizeof(uint32_t)) {
            p->status = -EINVAL;
 break;
 }
 switch (*(uint32_t *)p->data) {
 case VISUALIZER_PARAM_CAPTURE_SIZE:
            ALOGV("get mCaptureSize = %" PRIu32, pContext->mCaptureSize);
 *((uint32_t *)p->data + 1) = pContext->mCaptureSize;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 case VISUALIZER_PARAM_SCALING_MODE:
            ALOGV("get mScalingMode = %" PRIu32, pContext->mScalingMode);
 *((uint32_t *)p->data + 1) = pContext->mScalingMode;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 case VISUALIZER_PARAM_MEASUREMENT_MODE:
            ALOGV("get mMeasurementMode = %" PRIu32, pContext->mMeasurementMode);
 *((uint32_t *)p->data + 1) = pContext->mMeasurementMode;
            p->vsize = sizeof(uint32_t);
 *replySize += sizeof(uint32_t);
 break;
 default:
            p->status = -EINVAL;
 }
 } break;

     case EFFECT_CMD_SET_PARAM: {
         if (pCmdData == NULL ||
             cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t)) ||
            pReplyData == NULL || *replySize != sizeof(int32_t)) {
             return -EINVAL;
         }
         *(int32_t *)pReplyData = 0;
 effect_param_t *p = (effect_param_t *)pCmdData;
 if (p->psize != sizeof(uint32_t) || p->vsize != sizeof(uint32_t)) {
 *(int32_t *)pReplyData = -EINVAL;
 break;
 }
 switch (*(uint32_t *)p->data) {
 case VISUALIZER_PARAM_CAPTURE_SIZE:
            pContext->mCaptureSize = *((uint32_t *)p->data + 1);
            ALOGV("set mCaptureSize = %" PRIu32, pContext->mCaptureSize);
 break;
 case VISUALIZER_PARAM_SCALING_MODE:
            pContext->mScalingMode = *((uint32_t *)p->data + 1);
            ALOGV("set mScalingMode = %" PRIu32, pContext->mScalingMode);
 break;
 case VISUALIZER_PARAM_LATENCY:
            pContext->mLatency = *((uint32_t *)p->data + 1);
            ALOGV("set mLatency = %" PRIu32, pContext->mLatency);
 break;
 case VISUALIZER_PARAM_MEASUREMENT_MODE:
            pContext->mMeasurementMode = *((uint32_t *)p->data + 1);
            ALOGV("set mMeasurementMode = %" PRIu32, pContext->mMeasurementMode);
 break;
 default:
 *(int32_t *)pReplyData = -EINVAL;
 }
 } break;
 case EFFECT_CMD_SET_DEVICE:
 case EFFECT_CMD_SET_VOLUME:
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;


 
     case VISUALIZER_CMD_CAPTURE: {
         uint32_t captureSize = pContext->mCaptureSize;
        if (pReplyData == NULL || *replySize != captureSize) {
             ALOGV("VISUALIZER_CMD_CAPTURE() error *replySize %" PRIu32 " captureSize %" PRIu32,
                     *replySize, captureSize);
             return -EINVAL;
 }
 if (pContext->mState == VISUALIZER_STATE_ACTIVE) {
 const uint32_t deltaMs = Visualizer_getDeltaTimeMsFromUpdatedTime(pContext);

 if ((pContext->mLastCaptureIdx == pContext->mCaptureIdx) &&
 (pContext->mBufferUpdateTime.tv_sec != 0) &&
 (deltaMs > MAX_STALL_TIME_MS)) {
                    ALOGV("capture going to idle");
                    pContext->mBufferUpdateTime.tv_sec = 0;
                    memset(pReplyData, 0x80, captureSize);
 } else {
 int32_t latencyMs = pContext->mLatency;
                latencyMs -= deltaMs;
 if (latencyMs < 0) {
                    latencyMs = 0;
 }
 const uint32_t deltaSmpl =
                    pContext->mConfig.inputCfg.samplingRate * latencyMs / 1000;
 int32_t capturePoint = pContext->mCaptureIdx - captureSize - deltaSmpl;

 if (capturePoint < 0) {
 uint32_t size = -capturePoint;
 if (size > captureSize) {
                        size = captureSize;
 }
                    memcpy(pReplyData,
                           pContext->mCaptureBuf + CAPTURE_BUF_SIZE + capturePoint,
                           size);
                    pReplyData = (char *)pReplyData + size;
                    captureSize -= size;
                    capturePoint = 0;
 }
                memcpy(pReplyData,
                       pContext->mCaptureBuf + capturePoint,
                       captureSize);
 }

            pContext->mLastCaptureIdx = pContext->mCaptureIdx;
 } else {
            memset(pReplyData, 0x80, captureSize);
 }

 } break;

 case VISUALIZER_CMD_MEASURE: {
 uint16_t peakU16 = 0;
 float sumRmsSquared = 0.0f;
 uint8_t nbValidMeasurements = 0;
 const int32_t delayMs = Visualizer_getDeltaTimeMsFromUpdatedTime(pContext);
 if (delayMs > DISCARD_MEASUREMENTS_TIME_MS) {
            ALOGV("Discarding measurements, last measurement is %" PRId32 "ms old", delayMs);
 for (uint32_t i=0 ; i<pContext->mMeasurementWindowSizeInBuffers ; i++) {
                pContext->mPastMeasurements[i].mIsValid = false;
                pContext->mPastMeasurements[i].mPeakU16 = 0;
                pContext->mPastMeasurements[i].mRmsSquared = 0;
 }
            pContext->mMeasurementBufferIdx = 0;
 } else {
 for (uint32_t i=0 ; i < pContext->mMeasurementWindowSizeInBuffers ; i++) {
 if (pContext->mPastMeasurements[i].mIsValid) {
 if (pContext->mPastMeasurements[i].mPeakU16 > peakU16) {
                        peakU16 = pContext->mPastMeasurements[i].mPeakU16;
 }
                    sumRmsSquared += pContext->mPastMeasurements[i].mRmsSquared;
                    nbValidMeasurements++;
 }
 }
 }
 float rms = nbValidMeasurements == 0 ? 0.0f : sqrtf(sumRmsSquared / nbValidMeasurements);
 int32_t* pIntReplyData = (int32_t*)pReplyData;
 if (rms < 0.000016f) {
            pIntReplyData[MEASUREMENT_IDX_RMS] = -9600; //-96dB
 } else {
            pIntReplyData[MEASUREMENT_IDX_RMS] = (int32_t) (2000 * log10(rms / 32767.0f));
 }
 if (peakU16 == 0) {
            pIntReplyData[MEASUREMENT_IDX_PEAK] = -9600; //-96dB
 } else {
            pIntReplyData[MEASUREMENT_IDX_PEAK] = (int32_t) (2000 * log10(peakU16 / 32767.0f));
 }
        ALOGV("VISUALIZER_CMD_MEASURE peak=%" PRIu16 " (%" PRId32 "mB), rms=%.1f (%" PRId32 "mB)",
                peakU16, pIntReplyData[MEASUREMENT_IDX_PEAK],
                rms, pIntReplyData[MEASUREMENT_IDX_RMS]);
 }
 break;

 default:
        ALOGW("Visualizer_command invalid command %" PRIu32, cmdCode);
 return -EINVAL;
 }

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void SoundChannel::setRate(float rate)
{
 Mutex::Autolock lock(&mLock);
 if (mAudioTrack != NULL && mSample != 0) {
 uint32_t sampleRate = uint32_t(float(mSample->sampleRate()) * rate + 0.5);
        mAudioTrack->setSampleRate(sampleRate);
        mRate = rate;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  get_unknown(display *d, png_infop info_ptr, int after_IDAT)
 {
 /* Create corresponding 'unknown' flags */
   png_uint_32 flags = 0;

   UNUSED(after_IDAT)

 {
      png_unknown_chunkp unknown;
 int num_unknown = png_get_unknown_chunks(d->png_ptr, info_ptr, &unknown);

 while (--num_unknown >= 0)
 {
 int chunk = findb(unknown[num_unknown].name);

 /* Chunks not known to pngunknown must be validated here; since they
          * must also be unknown to libpng the 'display->keep' behavior should
          * have been used.
          */
 if (chunk < 0) switch (d->keep)
 {
 default: /* impossible */
 case PNG_HANDLE_CHUNK_AS_DEFAULT:
 case PNG_HANDLE_CHUNK_NEVER:
               fprintf(stderr, "%s(%s): %s: %s: unknown chunk saved\n",
                  d->file, d->test, d->keep ? "discard" : "default",
                  unknown[num_unknown].name);
 ++(d->error_count);
 break;

 case PNG_HANDLE_CHUNK_IF_SAFE:
 if (!ancillaryb(unknown[num_unknown].name))
 {
                  fprintf(stderr,
 "%s(%s): if-safe: %s: unknown critical chunk saved\n",
                     d->file, d->test, unknown[num_unknown].name);
 ++(d->error_count);
 break;
 }
 /* FALL THROUGH (safe) */
 case PNG_HANDLE_CHUNK_ALWAYS:
 break;
 }

 else
            flags |= chunk_info[chunk].flag;
 }
 }

 return flags;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dispatchNVReadItem(Parcel &p, RequestInfo *pRI) {
    RIL_NV_ReadItem nvri;
 int32_t  t;
 status_t status;

    memset(&nvri, 0, sizeof(nvri));

    status = p.readInt32(&t);
    nvri.itemID = (RIL_NV_Item) t;

 if (status != NO_ERROR) {
 goto invalid;
 }

    startRequest;
    appendPrintBuf("%snvri.itemID=%d, ", printBuf, nvri.itemID);
    closeRequest;

    printRequest(pRI->token, pRI->pCI->requestNumber);

    CALL_ONREQUEST(pRI->pCI->requestNumber, &nvri, sizeof(nvri), pRI, pRI->socket_id);

#ifdef MEMSET_FREED
    memset(&nvri, 0, sizeof(nvri));
#endif

 return;

invalid:
    invalidCommandBlock(pRI);
 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::commandEnableFocusMoveMsgL(bool enable) {
 SharedParameters::Lock l(mParameters);
    l.mParameters.enableFocusMoveMessages = enable;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_hdr(void *pv_dec,impeg2d_video_decode_ip_t *ps_ip,
 impeg2d_video_decode_op_t *ps_op)
{

    UWORD32 u4_bits_read;
 dec_state_t *ps_dec;

    ps_dec = (dec_state_t *)pv_dec;
    ps_op->s_ivd_video_decode_op_t.u4_error_code = 0;

    impeg2d_bit_stream_init(&(ps_dec->s_bit_stream),ps_ip->s_ivd_video_decode_ip_t.pv_stream_buffer,
        ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes);

 {
 {
            IMPEG2D_ERROR_CODES_T e_error;
            e_error = impeg2d_process_video_header(ps_dec);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code    = e_error;

                u4_bits_read     = impeg2d_bit_stream_num_bits_read(&ps_dec->s_bit_stream);

                ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = u4_bits_read>> 3;
 if(ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed > ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes)
 {
                    ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes;
 }

                 if(ps_op->s_ivd_video_decode_op_t.u4_error_code == 0)
                     ps_op->s_ivd_video_decode_op_t.u4_error_code = e_error;
 
 
                 impeg2d_next_code(ps_dec, SEQUENCE_HEADER_CODE);
                 return;
             }
 }
        ps_op->s_ivd_video_decode_op_t.u4_pic_ht = ps_dec->u2_vertical_size;
        ps_op->s_ivd_video_decode_op_t.u4_pic_wd = ps_dec->u2_horizontal_size;

        ps_op->s_ivd_video_decode_op_t.e_pic_type            = IV_NA_FRAME;
        ps_op->s_ivd_video_decode_op_t.u4_error_code        = IV_SUCCESS;

        u4_bits_read     = impeg2d_bit_stream_num_bits_read(&ps_dec->s_bit_stream);
        ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = u4_bits_read>> 3;
 if(ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed > ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes)
 {
            ps_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes;
 }
        ps_op->s_ivd_video_decode_op_t.u4_frame_decoded_flag = 0;
 /* MOD */
        ps_dec->u2_header_done = 1;

 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void SetUp() {
    fwd_txfm_ = GET_PARAM(0);
    inv_txfm_ = GET_PARAM(1);

     tx_type_  = GET_PARAM(2);
     pitch_    = 8;
     fwd_txfm_ref = fdct8x8_ref;
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: tBTM_STATUS btm_sec_l2cap_access_req (BD_ADDR bd_addr, UINT16 psm, UINT16 handle,
                                      CONNECTION_TYPE conn_type,
                                      tBTM_SEC_CALLBACK *p_callback,
 void *p_ref_data)
{
    tBTM_SEC_DEV_REC  *p_dev_rec;
    tBTM_SEC_SERV_REC *p_serv_rec;
    UINT16         security_required;
    UINT16         old_security_required;
    BOOLEAN       old_is_originator;
    tBTM_STATUS   rc = BTM_SUCCESS;
    BOOLEAN       chk_acp_auth_done = FALSE;
    BOOLEAN is_originator;
    BOOLEAN     transport = FALSE; /* should check PSM range in LE connection oriented L2CAP connection */

#if (L2CAP_UCD_INCLUDED == TRUE)
 if (conn_type & CONNECTION_TYPE_ORIG_MASK)
        is_originator = TRUE;
 else
        is_originator = FALSE;

    BTM_TRACE_DEBUG ("btm_sec_l2cap_access_req conn_type:0x%x, 0x%x", conn_type, p_ref_data);
#else
    is_originator = conn_type;

    BTM_TRACE_DEBUG ("btm_sec_l2cap_access_req is_originator:%d, 0x%x", is_originator, p_ref_data);
#endif

 /* Find or get oldest record */
    p_dev_rec = btm_find_or_alloc_dev (bd_addr);

    p_dev_rec->hci_handle = handle;

 /* Find the service record for the PSM */
    p_serv_rec = btm_sec_find_first_serv (conn_type, psm);

 /* If there is no application registered with this PSM do not allow connection */
 if (!p_serv_rec)
 {
        BTM_TRACE_WARNING ("btm_sec_l2cap_access_req()  PSM:%d no application registerd", psm);

 (*p_callback) (bd_addr, transport, p_ref_data, BTM_MODE_UNSUPPORTED);

 return(BTM_MODE_UNSUPPORTED);
 }

 /* SDP connection we will always let through */
 if (BT_PSM_SDP == psm)
 {
 (*p_callback) (bd_addr,transport, p_ref_data, BTM_SUCCESS_NO_SECURITY);

 return(BTM_SUCCESS);
 }
#if (L2CAP_UCD_INCLUDED == TRUE)
 if ( conn_type & CONNECTION_TYPE_CONNLESS_MASK )
 {
        security_required = p_serv_rec->ucd_security_flags;

        rc = BTM_CMD_STARTED;
 if (is_originator)
 {
 if (((security_required & BTM_SEC_OUT_FLAGS) == 0) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == BTM_SEC_OUT_AUTHENTICATE) && (p_dev_rec->sec_flags & BTM_SEC_AUTHENTICATED))) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == (BTM_SEC_OUT_AUTHENTICATE | BTM_SEC_OUT_ENCRYPT)) && (p_dev_rec->sec_flags & BTM_SEC_ENCRYPTED))) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == BTM_SEC_OUT_FLAGS) && (p_dev_rec->sec_flags & BTM_SEC_AUTHORIZED))) )
 {
                rc = BTM_SUCCESS;
 }
 }
 else
 {
 if (((security_required & BTM_SEC_IN_FLAGS) == 0) ||
 ((((security_required & BTM_SEC_IN_FLAGS) == BTM_SEC_IN_AUTHENTICATE) && (p_dev_rec->sec_flags & BTM_SEC_AUTHENTICATED))) ||
 ((((security_required & BTM_SEC_IN_FLAGS) == (BTM_SEC_IN_AUTHENTICATE | BTM_SEC_IN_ENCRYPT)) && (p_dev_rec->sec_flags & BTM_SEC_ENCRYPTED))) ||
 ((((security_required & BTM_SEC_IN_FLAGS) == BTM_SEC_IN_FLAGS) && (p_dev_rec->sec_flags & BTM_SEC_AUTHORIZED))) )
 {
                rc = BTM_SUCCESS;
 }
 }

 if (rc == BTM_SUCCESS)
 {
 if (p_callback)
 (*p_callback) (bd_addr, transport, (void *)p_ref_data, BTM_SUCCESS);

 return(BTM_SUCCESS);
 }
 }
 else
#endif
 {
        security_required = p_serv_rec->security_flags;
 }

 /* there are some devices (moto KRZR) which connects to several services at the same time */
 /* we will process one after another */
 if ( (p_dev_rec->p_callback) || (btm_cb.pairing_state != BTM_PAIR_STATE_IDLE) )
 {
        BTM_TRACE_EVENT ("btm_sec_l2cap_access_req() - busy - PSM:%d delayed  state: %s mode:%d, sm4:0x%x",
                          psm, btm_pair_state_descr(btm_cb.pairing_state), btm_cb.security_mode, p_dev_rec->sm4);
        BTM_TRACE_EVENT ("security_flags:x%x, sec_flags:x%x", security_required, p_dev_rec->sec_flags);
        rc = BTM_CMD_STARTED;
 if ((BTM_SEC_MODE_SP != btm_cb.security_mode)
 || ((BTM_SEC_MODE_SP == btm_cb.security_mode) && (BTM_SM4_KNOWN == p_dev_rec->sm4))
 || (BTM_SEC_IS_SM4(p_dev_rec->sm4) && (btm_sec_is_upgrade_possible(p_dev_rec, is_originator) == FALSE))
 )
 {
 /* legacy mode - local is legacy or local is lisbon/peer is legacy
             * or SM4 with no possibility of link key upgrade */
 if (is_originator)
 {
 if (((security_required & BTM_SEC_OUT_FLAGS) == 0) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == BTM_SEC_OUT_AUTHENTICATE) && btm_dev_authenticated(p_dev_rec))) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == (BTM_SEC_OUT_AUTHENTICATE | BTM_SEC_OUT_ENCRYPT)) && btm_dev_encrypted(p_dev_rec))) ||
 ((((security_required & BTM_SEC_OUT_FLAGS) == BTM_SEC_OUT_FLAGS) && btm_dev_authorized(p_dev_rec) && btm_dev_encrypted(p_dev_rec))) )
 {
                    rc = BTM_SUCCESS;
 }
 }
 else
 {
 if (((security_required & BTM_SEC_IN_FLAGS) == 0) ||
 (((security_required & BTM_SEC_IN_FLAGS) == BTM_SEC_IN_AUTHENTICATE) && btm_dev_authenticated(p_dev_rec)) ||
 (((security_required & BTM_SEC_IN_FLAGS) == (BTM_SEC_IN_AUTHENTICATE | BTM_SEC_IN_ENCRYPT)) && btm_dev_encrypted(p_dev_rec)) ||
 (((security_required & BTM_SEC_IN_FLAGS) == BTM_SEC_IN_AUTHORIZE) && (btm_dev_authorized(p_dev_rec)||btm_serv_trusted(p_dev_rec, p_serv_rec))) ||
 (((security_required & BTM_SEC_IN_FLAGS) == (BTM_SEC_IN_AUTHENTICATE | BTM_SEC_IN_AUTHORIZE)) && ((btm_dev_authorized(p_dev_rec)||btm_serv_trusted(p_dev_rec, p_serv_rec)) && btm_dev_authenticated(p_dev_rec))) ||
 (((security_required & BTM_SEC_IN_FLAGS) == (BTM_SEC_IN_ENCRYPT | BTM_SEC_IN_AUTHORIZE)) && ((btm_dev_authorized(p_dev_rec)||btm_serv_trusted(p_dev_rec, p_serv_rec)) && btm_dev_encrypted(p_dev_rec))) ||
 (((security_required & BTM_SEC_IN_FLAGS) == BTM_SEC_IN_FLAGS) && btm_dev_encrypted(p_dev_rec) && (btm_dev_authorized(p_dev_rec)||btm_serv_trusted(p_dev_rec, p_serv_rec))))
 {
                    rc = BTM_SUCCESS;
 }
 }

 if (rc == BTM_SUCCESS)
 {
 if (p_callback)
 (*p_callback) (bd_addr, transport, (void *)p_ref_data, BTM_SUCCESS);

 return(BTM_SUCCESS);
 }
 }

        btm_cb.sec_req_pending = TRUE;
 return(BTM_CMD_STARTED);
 }

 /* Save pointer to service record */
    p_dev_rec->p_cur_service = p_serv_rec;


 /* mess /w security_required in btm_sec_l2cap_access_req for Lisbon */
 if (btm_cb.security_mode == BTM_SEC_MODE_SP)
 {
 if (is_originator)
 {
 if (BTM_SEC_IS_SM4(p_dev_rec->sm4))
 {
 /* SM4 to SM4 -> always authenticate & encrypt */
                security_required |= (BTM_SEC_OUT_AUTHENTICATE | BTM_SEC_OUT_ENCRYPT);
 }
 else
 {
 if ( !(BTM_SM4_KNOWN & p_dev_rec->sm4))
 {
                    BTM_TRACE_DEBUG ("remote features unknown!!sec_flags:0x%x", p_dev_rec->sec_flags);
 /* the remote features are not known yet */
                    p_dev_rec->sm4          |= BTM_SM4_REQ_PEND;

 return(BTM_CMD_STARTED);
 }
 }
 }
 else
 {
 /* responder */
 if (BTM_SEC_IS_SM4(p_dev_rec->sm4))
 {
 /* SM4 to SM4: the acceptor needs to make sure the authentication is already done */
                chk_acp_auth_done = TRUE;
 /* SM4 to SM4 -> always authenticate & encrypt */
                security_required |= (BTM_SEC_IN_AUTHENTICATE | BTM_SEC_IN_ENCRYPT);
 }
 else
 {
 if ( !(BTM_SM4_KNOWN & p_dev_rec->sm4))
 {
                    BTM_TRACE_DEBUG ("(rsp) remote features unknown!!sec_flags:0x%x", p_dev_rec->sec_flags);
 /* the remote features are not known yet */
                    p_dev_rec->sm4          |= BTM_SM4_REQ_PEND;

 return(BTM_CMD_STARTED);
 }
 }
 }
 }

    BTM_TRACE_DEBUG ("btm_sec_l2cap_access_req()  sm4:0x%x, sec_flags:0x%x, security_required:0x%x chk:%d",
                      p_dev_rec->sm4, p_dev_rec->sec_flags, security_required, chk_acp_auth_done);

    old_security_required        = p_dev_rec->security_required;
    old_is_originator            = p_dev_rec->is_originator;
    p_dev_rec->security_required = security_required;
    p_dev_rec->p_ref_data        = p_ref_data;
    p_dev_rec->is_originator     = is_originator;

#if (L2CAP_UCD_INCLUDED == TRUE)
 if ( conn_type & CONNECTION_TYPE_CONNLESS_MASK )
        p_dev_rec->is_ucd = TRUE;
 else
        p_dev_rec->is_ucd = FALSE;
#endif

 /* If there are multiple service records used through the same PSM */
 /* leave security decision for the multiplexor on the top */
#if (L2CAP_UCD_INCLUDED == TRUE)
 if (((btm_sec_find_next_serv (p_serv_rec)) != NULL)
 &&(!( conn_type & CONNECTION_TYPE_CONNLESS_MASK ))) /* if not UCD */
#else
 if ((btm_sec_find_next_serv (p_serv_rec)) != NULL)
#endif
 {
        BTM_TRACE_DEBUG ("no next_serv sm4:0x%x, chk:%d", p_dev_rec->sm4, chk_acp_auth_done);
 if (!BTM_SEC_IS_SM4(p_dev_rec->sm4))
 {
            BTM_TRACE_EVENT ("Security Manager: l2cap_access_req PSM:%d postponed for multiplexer", psm);
 /* pre-Lisbon: restore the old settings */
            p_dev_rec->security_required = old_security_required;
            p_dev_rec->is_originator     = old_is_originator;

 (*p_callback) (bd_addr, transport, p_ref_data, BTM_SUCCESS);

 return(BTM_SUCCESS);
 }
 }

 /* if the originator is using dynamic PSM in legacy mode, do not start any security process now.
     * The layer above L2CAP needs to carry out the security requirement after L2CAP connect response is received*/
 if (is_originator && (btm_cb.security_mode != BTM_SEC_MODE_SP || !BTM_SEC_IS_SM4(p_dev_rec->sm4)) && (psm >= 0x1001))
 {
        BTM_TRACE_EVENT ("dynamic PSM:0x%x in legacy mode - postponed for upper layer", psm);
 /* restore the old settings */
        p_dev_rec->security_required = old_security_required;
        p_dev_rec->is_originator     = old_is_originator;

 (*p_callback) (bd_addr, transport, p_ref_data, BTM_SUCCESS);

 return(BTM_SUCCESS);
 }

 if (chk_acp_auth_done)
 {
        BTM_TRACE_DEBUG ("(SM4 to SM4) btm_sec_l2cap_access_req rspd. authenticated: x%x, enc: x%x",
 (p_dev_rec->sec_flags & BTM_SEC_AUTHENTICATED), (p_dev_rec->sec_flags & BTM_SEC_ENCRYPTED));
 /* SM4, but we do not know for sure which level of security we need.
         * as long as we have a link key, it's OK */
 if ((0 == (p_dev_rec->sec_flags & BTM_SEC_AUTHENTICATED))
 ||(0 == (p_dev_rec->sec_flags & BTM_SEC_ENCRYPTED)))
 {
            rc = BTM_DELAY_CHECK;
 /*
            2046 may report HCI_Encryption_Change and L2C Connection Request out of sequence
            because of data path issues. Delay this disconnect a little bit
            */
            BTM_TRACE_ERROR ("peer should have initiated security process by now (SM4 to SM4)");
            p_dev_rec->p_callback        = p_callback;
            p_dev_rec->sec_state         = BTM_SEC_STATE_DELAY_FOR_ENC;
 (*p_callback) (bd_addr, transport, p_ref_data, rc);

 return(BTM_CMD_STARTED);
 }
 }

    p_dev_rec->p_callback        = p_callback;

 if (p_dev_rec->last_author_service_id == BTM_SEC_NO_LAST_SERVICE_ID
 || p_dev_rec->last_author_service_id != p_dev_rec->p_cur_service->service_id)
 {
 /* Although authentication and encryption are per connection
        ** authorization is per access request.  For example when serial connection
        ** is up and authorized and client requests to read file (access to other
        ** scn), we need to request user's permission again.
        */
        p_dev_rec->sec_flags &= ~BTM_SEC_AUTHORIZED;
 }

 if (BTM_SEC_IS_SM4(p_dev_rec->sm4))
 {
 /* If we already have a link key to the connected peer, is the link key secure enough ? */
        btm_sec_check_upgrade(p_dev_rec, is_originator);
 }

    BTM_TRACE_EVENT ("Security Manager: l2cap_access_req PSM:%d Handle:%d State:%d Flags:0x%x Required:0x%x Service ID:%d",
                      psm, handle, p_dev_rec->sec_state, p_dev_rec->sec_flags, p_dev_rec->security_required, p_dev_rec->p_cur_service->service_id);

 if ((rc = btm_sec_execute_procedure (p_dev_rec)) != BTM_CMD_STARTED)
 {
        p_dev_rec->p_callback = NULL;
 (*p_callback) (bd_addr, transport, p_dev_rec->p_ref_data, (UINT8)rc);
 }

 return(rc);
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void Tags::SimpleTag::ShallowCopy(SimpleTag& rhs) const {
  rhs.m_tag_name = m_tag_name;
  rhs.m_tag_string = m_tag_string;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void SetLeftUnavailable() {
    mbptr_->left_available = 0;
 for (int p = 0; p < num_planes_; p++)
 for (int i = -1; i < block_size_; ++i)
        data_ptr_[p][stride_ * i - 1] = 129;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Chapters::GetEditionCount() const
{
    return m_editions_count;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_image_row(PNG_CONST png_store* ps, png_const_structp pp, int nImage,
    png_uint_32 y)
 {
    png_size_t coffset = (nImage * ps->image_h + y) * (ps->cb_row + 5) + 2;

 if (ps->image == NULL)
      png_error(pp, "no allocated image");

 if (coffset + ps->cb_row + 3 > ps->cb_image)
      png_error(pp, "image too small");

 return ps->image + coffset;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int handle_mknod(struct fuse* fuse, struct fuse_handler* handler,
 const struct fuse_in_header* hdr, const struct fuse_mknod_in* req, const char* name)
{
 struct node* parent_node;
 char parent_path[PATH_MAX];
 char child_path[PATH_MAX];
 const char* actual_name;

    pthread_mutex_lock(&fuse->global->lock);
    parent_node = lookup_node_and_path_by_id_locked(fuse, hdr->nodeid,
            parent_path, sizeof(parent_path));
    TRACE("[%d] MKNOD %s 0%o @ %"PRIx64" (%s)\n", handler->token,
            name, req->mode, hdr->nodeid, parent_node ? parent_node->name : "?");
    pthread_mutex_unlock(&fuse->global->lock);

 if (!parent_node || !(actual_name = find_file_within(parent_path, name,
            child_path, sizeof(child_path), 1))) {
 return -ENOENT;
 }
 if (!check_caller_access_to_name(fuse, hdr, parent_node, name, W_OK)) {
 return -EACCES;
 }
    __u32 mode = (req->mode & (~0777)) | 0664;
 if (mknod(child_path, mode, req->rdev) < 0) {
 return -errno;
 }
 return fuse_reply_entry(fuse, hdr->unique, parent_node, name, actual_name, child_path);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_pixel_add_alpha(image_pixel *this, PNG_CONST standard_display *display)
 {
    if (this->colour_type == PNG_COLOR_TYPE_PALETTE)
       image_pixel_convert_PLTE(this);

 if ((this->colour_type & PNG_COLOR_MASK_ALPHA) == 0)

    {
       if (this->colour_type == PNG_COLOR_TYPE_GRAY)
       {
         if (this->bit_depth < 8)
            this->bit_depth = 8;
 
          if (this->have_tRNS)
          {
             this->have_tRNS = 0;
 
             /* Check the input, original, channel value here against the
             * original tRNS gray chunk valie.
             */
 if (this->red == display->transparent.red)
 this->alphaf = 0;
 else
 this->alphaf = 1;
 }
 else
 this->alphaf = 1;

 this->colour_type = PNG_COLOR_TYPE_GRAY_ALPHA;
 }

 else if (this->colour_type == PNG_COLOR_TYPE_RGB)
 {
 if (this->have_tRNS)
 {
 this->have_tRNS = 0;

 /* Again, check the exact input values, not the current transformed
             * value!
             */
 if (this->red == display->transparent.red &&
 this->green == display->transparent.green &&
 this->blue == display->transparent.blue)

                this->alphaf = 0;
             else
                this->alphaf = 1;
            this->colour_type = PNG_COLOR_TYPE_RGB_ALPHA;
          }
       }
 
       /* The error in the alpha is zero and the sBIT value comes from the
       * original sBIT data (actually it will always be the original bit depth).
       */
 this->alphae = 0;

       this->alpha_sBIT = display->alpha_sBIT;
    }
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int vol_prc_lib_release(effect_handle_t handle)
{

     struct listnode *node, *temp_node_next;
     vol_listener_context_t *context = NULL;
     vol_listener_context_t *recv_contex = (vol_listener_context_t *)handle;
    int status = -1;
     bool recompute_flag = false;
     int active_stream_count = 0;
     ALOGV("%s context %p", __func__, handle);
     pthread_mutex_lock(&vol_listner_init_lock);
 
     list_for_each_safe(node, temp_node_next, &vol_effect_list) {
         context = node_to_item(node, struct vol_listener_context_s, effect_list_node);
        if ((memcmp(&(context->desc->uuid), &(recv_contex->desc->uuid), sizeof(effect_uuid_t)) == 0)
            && (context->session_id == recv_contex->session_id)
            && (context->stream_type == recv_contex->stream_type)) {
             ALOGV("--- Found something to remove ---");
            list_remove(&context->effect_list_node);
             PRINT_STREAM_TYPE(context->stream_type);
             if (context->dev_id && AUDIO_DEVICE_OUT_SPEAKER) {
                 recompute_flag = true;
 }
            free(context);
            status = 0;
 } else {
 ++active_stream_count;
 }
 }

 
     if (status != 0) {
         ALOGE("something wrong ... <<<--- Found NOTHING to remove ... ???? --->>>>>");
     }
 
 if (active_stream_count == 0) {
        current_gain_dep_cal_level = -1;
        current_vol = 0.0;
 }

 if (recompute_flag) {
        check_and_set_gain_dep_cal();
 }

 if (dumping_enabled) {
        dump_list_l();
 }
    pthread_mutex_unlock(&vol_listner_init_lock);
 return status;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t FLACExtractor::countTracks()
{
 return mInitCheck == OK ? 1 : 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t IGraphicBufferConsumer::BufferItem::getFdCount() const {
 size_t c = 0;
 if (mGraphicBuffer != 0) {
        c += mGraphicBuffer->getFdCount();
 }
 if (mFence != 0) {
        c += mFence->getFdCount();
 }
 return c;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static double pcerr(PNG_CONST png_modifier *pm, int in_depth, int out_depth)
 {
    /* Percentage error permitted in the linear values.  Note that the specified
     * value is a percentage but this routine returns a simple number.
    */
 if (pm->assume_16_bit_calculations ||
 (pm->calculations_use_input_precision ? in_depth : out_depth) == 16)
 return pm->maxpc16 * .01;
 else
 return pm->maxpc8 * .01;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  BufferMeta(size_t size, OMX_U32 portIndex)
 : mSize(size),
          mCopyFromOmx(false),
          mCopyToOmx(false),
          mPortIndex(portIndex),
          mBackup(NULL) {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: double AudioTrack::GetSamplingRate() const { return m_rate; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long VideoTrack::GetWidth() const
{
    return m_width;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t HevcParameterSets::parsePps(
 const uint8_t* data __unused, size_t size __unused) {
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::use_output_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes,
        OMX_IN OMX_U8*                   buffer)
{
 (void)hComp, (void)port;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
    OMX_BUFFERHEADERTYPE       *bufHdr= NULL; // buffer header
 unsigned                         i= 0; // Temporary counter
 unsigned char *buf_addr = NULL;
#ifdef _MSM8974_
 int align_size;
#endif

    DEBUG_PRINT_HIGH("Inside use_output_buffer()");
 if (bytes != m_sOutPortDef.nBufferSize) {
        DEBUG_PRINT_ERROR("ERROR: use_output_buffer: Size Mismatch!! "
 "bytes[%u] != Port.nBufferSize[%u]", (unsigned int)bytes, (unsigned int)m_sOutPortDef.nBufferSize);
 return OMX_ErrorBadParameter;
 }

 if (!m_out_mem_ptr) {
        output_use_buffer = true;
 int nBufHdrSize        = 0;

        DEBUG_PRINT_LOW("Allocating First Output Buffer(%u)",(unsigned int)m_sOutPortDef.nBufferCountActual);
        nBufHdrSize        = m_sOutPortDef.nBufferCountActual * sizeof(OMX_BUFFERHEADERTYPE);
 /*
         * Memory for output side involves the following:
         * 1. Array of Buffer Headers
         * 2. Bitmask array to hold the buffer allocation details
         * In order to minimize the memory management entire allocation
         * is done in one step.
         */
        m_out_mem_ptr = (OMX_BUFFERHEADERTYPE  *)calloc(nBufHdrSize,1);
 if (m_out_mem_ptr == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_out_mem_ptr");
 return OMX_ErrorInsufficientResources;
 }

        m_pOutput_pmem = (struct pmem *) calloc(sizeof (struct pmem), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_pmem");
 return OMX_ErrorInsufficientResources;
 }
#ifdef USE_ION
        m_pOutput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif
 if (m_out_mem_ptr) {
            bufHdr          =  m_out_mem_ptr;
            DEBUG_PRINT_LOW("Memory Allocation Succeeded for OUT port%p",m_out_mem_ptr);
 for (i=0; i < m_sOutPortDef.nBufferCountActual ; i++) {
                bufHdr->nSize              = sizeof(OMX_BUFFERHEADERTYPE);
                bufHdr->nVersion.nVersion  = OMX_SPEC_VERSION;
                bufHdr->nAllocLen          = bytes;
                bufHdr->nFilledLen         = 0;
                bufHdr->pAppPrivate        = appData;
                bufHdr->nOutputPortIndex   = PORT_INDEX_OUT;
                bufHdr->pBuffer            = NULL;
                bufHdr++;
                m_pOutput_pmem[i].fd = -1;
#ifdef USE_ION
                m_pOutput_ion[i].ion_device_fd =-1;
                m_pOutput_ion[i].fd_ion_data.fd=-1;
                m_pOutput_ion[i].ion_alloc_data.handle = 0;
#endif
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: Output buf mem alloc failed[0x%p]",m_out_mem_ptr);
            eRet =  OMX_ErrorInsufficientResources;
 }
 }

 for (i=0; i< m_sOutPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_out_bm_count,i)) {
 break;
 }
 }

 if (eRet == OMX_ErrorNone) {
 if (i < m_sOutPortDef.nBufferCountActual) {

             *bufferHdr = (m_out_mem_ptr + i );
             (*bufferHdr)->pBuffer = (OMX_U8 *)buffer;
             (*bufferHdr)->pAppPrivate = appData;
            BITMASK_SET(&m_out_bm_count,i);
 
             if (!m_use_output_pmem) {
 #ifdef USE_ION
#ifdef _MSM8974_
                align_size = (m_sOutPortDef.nBufferSize + (SZ_4K - 1)) & ~(SZ_4K - 1);
                m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(align_size,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data,0);
#else
                m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(
                        m_sOutPortDef.nBufferSize,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pOutput_ion[i].ion_device_fd < 0) {
                    DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }
                m_pOutput_pmem[i].fd = m_pOutput_ion[i].fd_ion_data.fd;
#else
                m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);

 if (m_pOutput_pmem[i].fd == 0) {
                    m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pOutput_pmem[i].fd < 0) {
                    DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() Failed");
 return OMX_ErrorInsufficientResources;
 }
#endif
                m_pOutput_pmem[i].size = m_sOutPortDef.nBufferSize;
                m_pOutput_pmem[i].offset = 0;

                m_pOutput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
 if(!secure_session) {
#ifdef _MSM8974_
                    m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                        align_size,PROT_READ|PROT_WRITE,
                        MAP_SHARED,m_pOutput_pmem[i].fd,0);
#else
                    m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                        m_pOutput_pmem[i].size,PROT_READ|PROT_WRITE,
                        MAP_SHARED,m_pOutput_pmem[i].fd,0);
#endif
 if (m_pOutput_pmem[i].buffer == MAP_FAILED) {
                        DEBUG_PRINT_ERROR("ERROR: mmap() Failed");
                    close(m_pOutput_pmem[i].fd);
#ifdef USE_ION
                    free_ion_memory(&m_pOutput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 }
 } else {
                OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO *pParam = reinterpret_cast<OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO*>((*bufferHdr)->pAppPrivate);
                DEBUG_PRINT_LOW("Inside qcom_ext pParam: %p", pParam);

 if (pParam) {
                    DEBUG_PRINT_LOW("Inside qcom_ext with luma:(fd:%lu,offset:0x%x)", pParam->pmem_fd, (int)pParam->offset);
                    m_pOutput_pmem[i].fd = pParam->pmem_fd;
                    m_pOutput_pmem[i].offset = pParam->offset;
                    m_pOutput_pmem[i].size = m_sOutPortDef.nBufferSize;
                    m_pOutput_pmem[i].buffer = (unsigned char *)buffer;
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid AppData given for PMEM o/p UseBuffer case");
 return OMX_ErrorBadParameter;
 }
                buf_addr = (unsigned char *)buffer;
 }

            DEBUG_PRINT_LOW("use_out:: bufhdr = %p, pBuffer = %p, m_pOutput_pmem[i].buffer = %p",
 (*bufferHdr), (*bufferHdr)->pBuffer, m_pOutput_pmem[i].buffer);
 if (dev_use_buf(&m_pOutput_pmem[i],PORT_INDEX_OUT,i) != true) {

                 DEBUG_PRINT_ERROR("ERROR: dev_use_buf Failed for o/p buf");
                 return OMX_ErrorInsufficientResources;
             }
         } else {
             DEBUG_PRINT_ERROR("ERROR: All o/p Buffers have been Used, invalid use_buf call for "
                     "index = %u", i);
            eRet = OMX_ErrorInsufficientResources;
 }
 }
 return eRet;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: sp<MetaData> AMRSource::getFormat() {
 return mMeta;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool checkIfCover(const GifImageDesc& target, const GifImageDesc& covered) {
 return target.Left <= covered.Left
 && covered.Left + covered.Width <= target.Left + target.Width
 && target.Top <= covered.Top
 && covered.Top + covered.Height <= target.Top + target.Height;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool btif_av_state_opened_handler(btif_sm_event_t event, void* p_data) {
  tBTA_AV* p_av = (tBTA_AV*)p_data;

  BTIF_TRACE_DEBUG("%s: event=%s flags=0x%x", __func__,
                   dump_av_sm_event_name((btif_av_sm_event_t)event),
                   btif_av_cb.flags);

 if ((event == BTA_AV_REMOTE_CMD_EVT) &&
 (btif_av_cb.flags & BTIF_AV_FLAG_REMOTE_SUSPEND) &&
 (p_av->remote_cmd.rc_id == BTA_AV_RC_PLAY)) {
    BTIF_TRACE_EVENT("%s: Resetting remote suspend flag on RC PLAY", __func__);
    btif_av_cb.flags &= ~BTIF_AV_FLAG_REMOTE_SUSPEND;
 }

 switch (event) {
 case BTIF_SM_ENTER_EVT:
      btif_av_cb.flags &= ~BTIF_AV_FLAG_PENDING_STOP;
      btif_av_cb.flags &= ~BTIF_AV_FLAG_PENDING_START;
 break;

 case BTIF_SM_EXIT_EVT:
      btif_av_cb.flags &= ~BTIF_AV_FLAG_PENDING_START;
 break;

 case BTIF_AV_START_STREAM_REQ_EVT:
 if (btif_av_cb.peer_sep != AVDT_TSEP_SRC) btif_a2dp_source_setup_codec();
      BTA_AvStart();
      btif_av_cb.flags |= BTIF_AV_FLAG_PENDING_START;
 break;

 case BTA_AV_START_EVT: {
      BTIF_TRACE_WARNING(
 "%s: BTA_AV_START_EVT status=%d suspending=%d initiator=%d "
 "flags=0x%x",
          __func__, p_av->start.status, p_av->start.suspending,
          p_av->start.initiator, btif_av_cb.flags);

 if ((p_av->start.status == BTA_SUCCESS) &&
 (p_av->start.suspending == true))
 return true;

 /* if remote tries to start a2dp when DUT is a2dp source
       * then suspend. In case a2dp is sink and call is active
       * then disconnect the AVDTP channel
       */
 if (!(btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START)) {
 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK) {
          BTIF_TRACE_WARNING("%s: trigger suspend as remote initiated!!",
                             __func__);
          btif_dispatch_sm_event(BTIF_AV_SUSPEND_STREAM_REQ_EVT, NULL, 0);
 }
 }

 /*  In case peer is A2DP SRC we do not want to ack commands on UIPC*/
 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK) {
 if (btif_a2dp_on_started(
 &p_av->start,
 ((btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START) != 0))) {
 /* only clear pending flag after acknowledgement */
          btif_av_cb.flags &= ~BTIF_AV_FLAG_PENDING_START;
 }
 }

 /* remain in open state if status failed */
 if (p_av->start.status != BTA_AV_SUCCESS) return false;

 if (btif_av_cb.peer_sep == AVDT_TSEP_SRC) {
        btif_a2dp_sink_set_rx_flush(
 false); /*  remove flush state, ready for streaming*/
 }

 /* change state to started, send acknowledgement if start is pending */
 if (btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START) {
 if (btif_av_cb.peer_sep == AVDT_TSEP_SNK)
          btif_a2dp_on_started(NULL, true);
 /* pending start flag will be cleared when exit current state */
 }
      btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_STARTED);

 } break;

 case BTIF_AV_SOURCE_CONFIG_REQ_EVT:
      btif_update_source_codec(p_data);
 break;

 case BTIF_AV_SOURCE_CONFIG_UPDATED_EVT:
      btif_report_source_codec_state(p_data);
 break;

 case BTIF_AV_DISCONNECT_REQ_EVT:
      BTA_AvClose(btif_av_cb.bta_handle);
 if (btif_av_cb.peer_sep == AVDT_TSEP_SRC) {
        BTA_AvCloseRc(btif_av_cb.bta_handle);
 }

 /* inform the application that we are disconnecting */
      btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTING,
 &(btif_av_cb.peer_bda));
 break;

 case BTA_AV_CLOSE_EVT:
 /* avdtp link is closed */
      btif_a2dp_on_stopped(NULL);

 /* inform the application that we are disconnected */
      btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTED,
 &(btif_av_cb.peer_bda));

 /* change state to idle, send acknowledgement if start is pending */
 if (btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START) {
        btif_a2dp_command_ack(A2DP_CTRL_ACK_FAILURE);
 /* pending start flag will be cleared when exit current state */
 }
      btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_IDLE);
 break;

 case BTA_AV_RECONFIG_EVT:
 if ((btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START) &&
 (p_av->reconfig.status == BTA_AV_SUCCESS)) {
        APPL_TRACE_WARNING("reconfig done BTA_AVstart()");
        BTA_AvStart();
 } else if (btif_av_cb.flags & BTIF_AV_FLAG_PENDING_START) {
        btif_av_cb.flags &= ~BTIF_AV_FLAG_PENDING_START;
        btif_a2dp_command_ack(A2DP_CTRL_ACK_FAILURE);
 }
 break;

 case BTIF_AV_CONNECT_REQ_EVT: {
 btif_av_connect_req_t* connect_req_p = (btif_av_connect_req_t*)p_data;
 RawAddress& target_bda = *connect_req_p->target_bda;
 if (btif_av_cb.peer_bda == target_bda) {
        BTIF_TRACE_WARNING(
 "%s: Ignore BTIF_AV_CONNECT_REQ_EVT for same device: target_bda=%s",
            __func__, target_bda.ToString().c_str());
 } else {
        BTIF_TRACE_WARNING(
 "%s: Moved to opened by Other incoming Connect request: "
 "target_bda=%s",
            __func__, target_bda.ToString().c_str());
        btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTED,
 &target_bda);
 }
      btif_queue_advance();
 } break;

 case BTIF_AV_OFFLOAD_START_REQ_EVT:
      BTIF_TRACE_ERROR(
 "%s: BTIF_AV_OFFLOAD_START_REQ_EVT: Stream not Started Opened",
          __func__);
      btif_a2dp_on_offload_started(BTA_AV_FAIL);
 break;

      CHECK_RC_EVENT(event, (tBTA_AV*)p_data);

 default:
      BTIF_TRACE_WARNING("%s: unhandled event=%s", __func__,
                         dump_av_sm_event_name((btif_av_sm_event_t)event));
 return false;
 }
 return true;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Parcel::writeBlob(size_t len, bool mutableCopy, WritableBlob* outBlob)
{
 if (len > INT32_MAX) {
 return BAD_VALUE;
 }

 status_t status;
 if (!mAllowFds || len <= BLOB_INPLACE_LIMIT) {
        ALOGV("writeBlob: write in place");
        status = writeInt32(BLOB_INPLACE);
 if (status) return status;

 void* ptr = writeInplace(len);
 if (!ptr) return NO_MEMORY;

        outBlob->init(-1, ptr, len, false);
 return NO_ERROR;
 }

    ALOGV("writeBlob: write to ashmem");
 int fd = ashmem_create_region("Parcel Blob", len);
 if (fd < 0) return NO_MEMORY;

 int result = ashmem_set_prot_region(fd, PROT_READ | PROT_WRITE);
 if (result < 0) {
        status = result;
 } else {
 void* ptr = ::mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
 if (ptr == MAP_FAILED) {
            status = -errno;
 } else {
 if (!mutableCopy) {
                result = ashmem_set_prot_region(fd, PROT_READ);
 }
 if (result < 0) {
                status = result;
 } else {
                status = writeInt32(mutableCopy ? BLOB_ASHMEM_MUTABLE : BLOB_ASHMEM_IMMUTABLE);
 if (!status) {
                    status = writeFileDescriptor(fd, true /*takeOwnership*/);
 if (!status) {
                        outBlob->init(fd, ptr, len, mutableCopy);
 return NO_ERROR;
 }
 }
 }
 }
 ::munmap(ptr, len);
 }
 ::close(fd);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void EndPassHook() {
#if WRITE_COMPRESSED_STREAM
 if (outfile_) {
 if (!fseek(outfile_, 0, SEEK_SET))
        write_ivf_file_header(&cfg_, out_frames_, outfile_);
      fclose(outfile_);
      outfile_ = NULL;
 }
#endif
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long AudioTrack::GetChannels() const
{
    return m_channels;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static jboolean android_net_wifi_setScanningMacOui(JNIEnv *env, jclass cls,
        jint iface, jbyteArray param) {

 JNIHelper helper(env);
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);
    ALOGD("setting scan oui %p", handle);

 static const unsigned oui_len = 3; /* OUI is upper 3 bytes of mac_address */
 int len = helper.getArrayLength(param);
 if (len != oui_len) {
        ALOGE("invalid oui length %d", len);
 return false;
 }

 ScopedBytesRO paramBytes(env, param);
 const jbyte* bytes = paramBytes.get();
 if (bytes == NULL) {
        ALOGE("failed to get array");
 return false;
 }

 return hal_fn.wifi_set_scanning_mac_oui(handle, (byte *)bytes) == WIFI_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Parcel::allowFds() const
{
 return mAllowFds;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void remote_socket_shutdown(asocket* s) {
    D("entered remote_socket_shutdown RS(%d) CLOSE fd=%d peer->fd=%d", s->id, s->fd,
      s->peer ? s->peer->fd : -1);
    apacket* p = get_apacket();
    p->msg.command = A_CLSE;
 if (s->peer) {
        p->msg.arg0 = s->peer->id;
 }
    p->msg.arg1 = s->id;
    send_packet(p, s->transport);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Region_isComplex(JNIEnv* env, jobject region) {
 bool result = GetSkRegion(env, region)->isComplex();
 return boolTojboolean(result);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ATSParser::Stream::flush(SyncEvent *event) {
 if (mBuffer == NULL || mBuffer->size() == 0) {
 return OK;
 }

    ALOGV("flushing stream 0x%04x size = %zu", mElementaryPID, mBuffer->size());

 ABitReader br(mBuffer->data(), mBuffer->size());

 status_t err = parsePES(&br, event);

    mBuffer->setRange(0, 0);

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void write_ivf_file_header(FILE *outfile,
 const vpx_codec_enc_cfg_t *cfg,
 int frame_cnt) {
 char header[32];

 if(cfg->g_pass != VPX_RC_ONE_PASS && cfg->g_pass != VPX_RC_LAST_PASS)
 return;
    header[0] = 'D';
    header[1] = 'K';
    header[2] = 'I';
    header[3] = 'F';
    mem_put_le16(header+4, 0); /* version */
    mem_put_le16(header+6, 32); /* headersize */
    mem_put_le32(header+8,  fourcc); /* headersize */
    mem_put_le16(header+12, cfg->g_w); /* width */
    mem_put_le16(header+14, cfg->g_h); /* height */
    mem_put_le32(header+16, cfg->g_timebase.den); /* rate */
    mem_put_le32(header+20, cfg->g_timebase.num); /* scale */
    mem_put_le32(header+24, frame_cnt); /* length */
    mem_put_le32(header+28, 0); /* unused */

 (void) fwrite(header, 1, 32, outfile);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: AMediaCodec* AMediaCodec_createDecoderByType(const char *mime_type) {
 return createAMediaCodec(mime_type, true, false);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::FlushingState::onInputBufferFilled(const sp<AMessage> &msg) {
 BaseState::onInputBufferFilled(msg);

    changeStateIfWeOwnAllBuffers();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool OMXCodec::drainInputBuffer(IOMX::buffer_id buffer) {
 Vector<BufferInfo> *buffers = &mPortBuffers[kPortIndexInput];
 for (size_t i = 0; i < buffers->size(); ++i) {
 if ((*buffers)[i].mBuffer == buffer) {
 return drainInputBuffer(&buffers->editItemAt(i));
 }
 }

    CHECK(!"should not be here.");

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_vdec::ts_arr_list::reset_ts_list()
{
 bool ret = true;
 int idx = 0;

    DEBUG_PRINT_LOW("reset_ts_list(): Resetting timestamp array list");
 for ( ; idx < MAX_NUM_INPUT_OUTPUT_BUFFERS; idx++) {
        m_ts_arr_list[idx].valid = false;
 }
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Cues::DoneParsing() const
{
    const long long stop = m_start + m_size;
    return (m_pos >= stop);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: get_buffer(png_structp pp)
 /* Used from libpng callbacks to get the current buffer */
{

    return (struct buffer*)png_get_io_ptr(pp);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: EBMLHeader::~EBMLHeader()
{
     delete[] m_docType;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXCodec::isColorFormatSupported(
        OMX_COLOR_FORMATTYPE colorFormat, int portIndex) {
    ALOGV("isColorFormatSupported: %d", static_cast<int>(colorFormat));

    OMX_VIDEO_PARAM_PORTFORMATTYPE portFormat;
 InitOMXParams(&portFormat);
    portFormat.nPortIndex = portIndex;
    OMX_U32 index = 0;
    portFormat.nIndex = index;
 while (true) {
 if (OMX_ErrorNone != mOMX->getParameter(
                mNode, OMX_IndexParamVideoPortFormat,
 &portFormat, sizeof(portFormat))) {
 break;
 }
        CHECK_EQ(index, portFormat.nIndex);
 if (portFormat.eColorFormat == colorFormat) {
            CODEC_LOGV("Found supported color format: %d", portFormat.eColorFormat);
 return OK; // colorFormat is supported!
 }
 ++index;
        portFormat.nIndex = index;

 if (index >= kMaxColorFormatSupported) {
            CODEC_LOGE("More than %u color formats are supported???", index);
 break;
 }
 }

    CODEC_LOGE("color format %d is not supported", colorFormat);
 return UNKNOWN_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: btpan_conn_t* btpan_find_conn_addr(const BD_ADDR addr)
{
 for (int i = 0; i < MAX_PAN_CONNS; i++)
 {
 if (memcmp(btpan_cb.conns[i].peer, addr, sizeof(BD_ADDR)) == 0)
 return &btpan_cb.conns[i];
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void get_frame_stats(vpx_codec_ctx_t *ctx,
                            const vpx_image_t *img,
                            vpx_codec_pts_t pts,
                            unsigned int duration,
                            vpx_enc_frame_flags_t flags,
                            unsigned int deadline,
                            vpx_fixed_buf_t *stats) {
   vpx_codec_iter_t iter = NULL;
   const vpx_codec_cx_pkt_t *pkt = NULL;
   const vpx_codec_err_t res = vpx_codec_encode(ctx, img, pts, duration, flags,
                                               deadline);
 if (res != VPX_CODEC_OK)

     die_codec(ctx, "Failed to get frame stats.");
 
   while ((pkt = vpx_codec_get_cx_data(ctx, &iter)) != NULL) {
     if (pkt->kind == VPX_CODEC_STATS_PKT) {
       const uint8_t *const pkt_buf = pkt->data.twopass_stats.buf;
       const size_t pkt_size = pkt->data.twopass_stats.sz;
      stats->buf = realloc(stats->buf, stats->sz + pkt_size);
      memcpy((uint8_t *)stats->buf + stats->sz, pkt_buf, pkt_size);

       stats->sz += pkt_size;
     }
   }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::logOutboundKeyDetailsLocked(const char* prefix, const KeyEntry* entry) {
#if DEBUG_OUTBOUND_EVENT_DETAILS
    ALOGD("%seventTime=%lld, deviceId=%d, source=0x%x, policyFlags=0x%x, "
 "action=0x%x, flags=0x%x, keyCode=0x%x, scanCode=0x%x, metaState=0x%x, "
 "repeatCount=%d, downTime=%lld",
            prefix,
            entry->eventTime, entry->deviceId, entry->source, entry->policyFlags,
            entry->action, entry->flags, entry->keyCode, entry->scanCode, entry->metaState,
            entry->repeatCount, entry->downTime);
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btif_hl_find_avail_app_idx(UINT8 *p_idx){
    BOOLEAN found = FALSE;
    UINT8 i;

 for (i=0; i < BTA_HL_NUM_APPS ; i ++)
 {
 if (!btif_hl_cb.acb[i].in_use)
 {
            found = TRUE;
 *p_idx = i;
 break;
 }
 }

    BTIF_TRACE_DEBUG("%s found=%d app_idx=%d", __FUNCTION__, found, i);
 return found;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void DeleteAtEnd(Handle<JSObject> obj,
 Handle<BackingStore> backing_store, uint32_t entry) {
 uint32_t length = static_cast<uint32_t>(backing_store->length());
 Isolate* isolate = obj->GetIsolate();
 for (; entry > 0; entry--) {
 if (!backing_store->is_the_hole(isolate, entry - 1)) break;
 }
 if (entry == 0) {
 FixedArray* empty = isolate->heap()->empty_fixed_array();
 if (obj->GetElementsKind() == FAST_SLOPPY_ARGUMENTS_ELEMENTS) {
 FixedArray::cast(obj->elements())->set(1, empty);
 } else {
        obj->set_elements(empty);
 }
 return;
 }

    isolate->heap()->RightTrimFixedArray(*backing_store, length - entry);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_slice_partition(dec_struct_t * ps_dec,
 dec_bit_stream_t * ps_bitstrm)
{
    H264_DEC_DEBUG_PRINT("\nSlice partition not supported");
    UNUSED(ps_dec);
    UNUSED(ps_bitstrm);
 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void event_finish_startup(UNUSED_ATTR void *context) {
  LOG_INFO("%s", __func__);
  hal->open();
  vendor->send_async_command(VENDOR_CONFIGURE_FIRMWARE, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void release_node_locked(struct node* node)
{
    TRACE("RELEASE %p (%s) rc=%d\n", node, node->name, node->refcount);
 if (node->refcount > 0) {
        node->refcount--;
 if (!node->refcount) {
            TRACE("DESTROY %p (%s)\n", node, node->name);
            remove_node_from_parent_locked(node);

 /* TODO: remove debugging - poison memory */
            memset(node->name, 0xef, node->namelen);
            free(node->name);
            free(node->actual_name);
            memset(node, 0xfc, sizeof(*node));
            free(node);
 }
 } else {
        ERROR("Zero refcnt %p\n", node);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX::OMX()
 : mMaster(new OMXMaster),
      mNodeCounter(0) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BnDrm::onTransact(
 uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {
 switch (code) {
 case INIT_CHECK:
 {
            CHECK_INTERFACE(IDrm, data, reply);
            reply->writeInt32(initCheck());
 return OK;
 }

 case IS_CRYPTO_SUPPORTED:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 uint8_t uuid[16];
            data.read(uuid, sizeof(uuid));
 String8 mimeType = data.readString8();
            reply->writeInt32(isCryptoSchemeSupported(uuid, mimeType));

 return OK;
 }

 case CREATE_PLUGIN:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 uint8_t uuid[16];
            data.read(uuid, sizeof(uuid));
            reply->writeInt32(createPlugin(uuid));
 return OK;
 }

 case DESTROY_PLUGIN:
 {
            CHECK_INTERFACE(IDrm, data, reply);
            reply->writeInt32(destroyPlugin());
 return OK;
 }

 case OPEN_SESSION:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId;
 status_t result = openSession(sessionId);
            writeVector(reply, sessionId);
            reply->writeInt32(result);
 return OK;
 }

 case CLOSE_SESSION:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId;
            readVector(data, sessionId);
            reply->writeInt32(closeSession(sessionId));
 return OK;
 }

 case GET_KEY_REQUEST:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, initData;

            readVector(data, sessionId);
            readVector(data, initData);
 String8 mimeType = data.readString8();
 DrmPlugin::KeyType keyType = (DrmPlugin::KeyType)data.readInt32();

 KeyedVector<String8, String8> optionalParameters;
 uint32_t count = data.readInt32();
 for (size_t i = 0; i < count; ++i) {
 String8 key, value;
                key = data.readString8();
                value = data.readString8();
                optionalParameters.add(key, value);
 }

 
             Vector<uint8_t> request;
             String8 defaultUrl;
            DrmPlugin::KeyRequestType keyRequestType;
 
             status_t result = getKeyRequest(sessionId, initData, mimeType,
                     keyType, optionalParameters, request, defaultUrl,
 &keyRequestType);

            writeVector(reply, request);
            reply->writeString8(defaultUrl);
            reply->writeInt32(static_cast<int32_t>(keyRequestType));
            reply->writeInt32(result);
 return OK;
 }

 case PROVIDE_KEY_RESPONSE:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, response, keySetId;
            readVector(data, sessionId);
            readVector(data, response);
 uint32_t result = provideKeyResponse(sessionId, response, keySetId);
            writeVector(reply, keySetId);
            reply->writeInt32(result);
 return OK;
 }

 case REMOVE_KEYS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> keySetId;
            readVector(data, keySetId);
            reply->writeInt32(removeKeys(keySetId));
 return OK;
 }

 case RESTORE_KEYS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, keySetId;
            readVector(data, sessionId);
            readVector(data, keySetId);
            reply->writeInt32(restoreKeys(sessionId, keySetId));
 return OK;
 }

 case QUERY_KEY_STATUS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId;
            readVector(data, sessionId);
 KeyedVector<String8, String8> infoMap;
 status_t result = queryKeyStatus(sessionId, infoMap);
 size_t count = infoMap.size();
            reply->writeInt32(count);
 for (size_t i = 0; i < count; ++i) {
                reply->writeString8(infoMap.keyAt(i));
                reply->writeString8(infoMap.valueAt(i));
 }
            reply->writeInt32(result);
 return OK;
 }

 case GET_PROVISION_REQUEST:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 String8 certType = data.readString8();
 String8 certAuthority = data.readString8();

 Vector<uint8_t> request;
 String8 defaultUrl;
 status_t result = getProvisionRequest(certType, certAuthority,
                                                  request, defaultUrl);
            writeVector(reply, request);
            reply->writeString8(defaultUrl);
            reply->writeInt32(result);
 return OK;
 }

 case PROVIDE_PROVISION_RESPONSE:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> response;
 Vector<uint8_t> certificate;
 Vector<uint8_t> wrappedKey;
            readVector(data, response);
 status_t result = provideProvisionResponse(response, certificate, wrappedKey);
            writeVector(reply, certificate);
            writeVector(reply, wrappedKey);
            reply->writeInt32(result);
 return OK;
 }

 case UNPROVISION_DEVICE:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 status_t result = unprovisionDevice();
            reply->writeInt32(result);
 return OK;
 }

 case GET_SECURE_STOPS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 List<Vector<uint8_t> > secureStops;
 status_t result = getSecureStops(secureStops);
 size_t count = secureStops.size();
            reply->writeInt32(count);
 List<Vector<uint8_t> >::iterator iter = secureStops.begin();
 while(iter != secureStops.end()) {
 size_t size = iter->size();
                reply->writeInt32(size);
                reply->write(iter->array(), iter->size());
                iter++;
 }
            reply->writeInt32(result);
 return OK;
 }

 case GET_SECURE_STOP:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> ssid, secureStop;
            readVector(data, ssid);
 status_t result = getSecureStop(ssid, secureStop);
            writeVector(reply, secureStop);
            reply->writeInt32(result);
 return OK;
 }

 case RELEASE_SECURE_STOPS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> ssRelease;
            readVector(data, ssRelease);
            reply->writeInt32(releaseSecureStops(ssRelease));
 return OK;
 }

 case RELEASE_ALL_SECURE_STOPS:
 {
            CHECK_INTERFACE(IDrm, data, reply);
            reply->writeInt32(releaseAllSecureStops());
 return OK;
 }

 case GET_PROPERTY_STRING:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 String8 name = data.readString8();
 String8 value;
 status_t result = getPropertyString(name, value);
            reply->writeString8(value);
            reply->writeInt32(result);
 return OK;
 }

 case GET_PROPERTY_BYTE_ARRAY:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 String8 name = data.readString8();
 Vector<uint8_t> value;
 status_t result = getPropertyByteArray(name, value);
            writeVector(reply, value);
            reply->writeInt32(result);
 return OK;
 }

 case SET_PROPERTY_STRING:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 String8 name = data.readString8();
 String8 value = data.readString8();
            reply->writeInt32(setPropertyString(name, value));
 return OK;
 }

 case SET_PROPERTY_BYTE_ARRAY:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 String8 name = data.readString8();
 Vector<uint8_t> value;
            readVector(data, value);
            reply->writeInt32(setPropertyByteArray(name, value));
 return OK;
 }

 case SET_CIPHER_ALGORITHM:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId;
            readVector(data, sessionId);
 String8 algorithm = data.readString8();
            reply->writeInt32(setCipherAlgorithm(sessionId, algorithm));
 return OK;
 }

 case SET_MAC_ALGORITHM:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId;
            readVector(data, sessionId);
 String8 algorithm = data.readString8();
            reply->writeInt32(setMacAlgorithm(sessionId, algorithm));
 return OK;
 }

 case ENCRYPT:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, keyId, input, iv, output;
            readVector(data, sessionId);
            readVector(data, keyId);
            readVector(data, input);
            readVector(data, iv);
 uint32_t result = encrypt(sessionId, keyId, input, iv, output);
            writeVector(reply, output);
            reply->writeInt32(result);
 return OK;
 }

 case DECRYPT:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, keyId, input, iv, output;
            readVector(data, sessionId);
            readVector(data, keyId);
            readVector(data, input);
            readVector(data, iv);
 uint32_t result = decrypt(sessionId, keyId, input, iv, output);
            writeVector(reply, output);
            reply->writeInt32(result);
 return OK;
 }

 case SIGN:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, keyId, message, signature;
            readVector(data, sessionId);
            readVector(data, keyId);
            readVector(data, message);
 uint32_t result = sign(sessionId, keyId, message, signature);
            writeVector(reply, signature);
            reply->writeInt32(result);
 return OK;
 }

 case VERIFY:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, keyId, message, signature;
            readVector(data, sessionId);
            readVector(data, keyId);
            readVector(data, message);
            readVector(data, signature);
 bool match;
 uint32_t result = verify(sessionId, keyId, message, signature, match);
            reply->writeInt32(match);
            reply->writeInt32(result);
 return OK;
 }

 case SIGN_RSA:
 {
            CHECK_INTERFACE(IDrm, data, reply);
 Vector<uint8_t> sessionId, message, wrappedKey, signature;
            readVector(data, sessionId);
 String8 algorithm = data.readString8();
            readVector(data, message);
            readVector(data, wrappedKey);
 uint32_t result = signRSA(sessionId, algorithm, message, wrappedKey, signature);
            writeVector(reply, signature);
            reply->writeInt32(result);
 return OK;
 }

 case SET_LISTENER: {
        CHECK_INTERFACE(IDrm, data, reply);
        sp<IDrmClient> listener =
            interface_cast<IDrmClient>(data.readStrongBinder());
        reply->writeInt32(setListener(listener));
 return NO_ERROR;
 } break;

 default:
 return BBinder::onTransact(code, data, reply, flags);
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;
    UNUSED(u1_is_idr_slice);

 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
        ih264d_err_pic_dispbuf_mgr(ps_dec);
 return 0;
 }

 if(ps_dec->ps_cur_slice->u1_mbaff_frame_flag && (num_mb_skip & 1))
 {
        num_mb_skip++;
 }
    ps_dec->ps_dpb_cmds->u1_long_term_reference_flag = 0;
 if(prev_slice_err == 1)
 {
 /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;
 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = -1;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 {
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
 {
 if(ps_dec->ps_pps[i].ps_sps->u1_is_valid == TRUE)
 {
                           j = i;
 break;
 }
 }
 }

 if(j == -1)
 {
 return ERROR_INV_SLICE_HDR_T;
 }

 /* call ih264d_start_of_pic only if it was not called earlier*/
 if(ps_dec->u4_pic_buf_got == 0)
 {
                ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
                ps_dec->ps_cur_slice->u1_nal_ref_idc = 1;
                ps_dec->ps_cur_slice->u1_nal_unit_type = 1;
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;

                 }
             }
         }
        ps_dec->u4_first_slice_in_pic = 0;
     }
     else
     {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
 if((u1_mbaff) && (ps_dec->u4_num_mbs_cur_nmb & 1))
 {
                ps_dec->u4_num_mbs_cur_nmb = ps_dec->u4_num_mbs_cur_nmb - 1;
                ps_dec->u2_cur_mb_addr--;
 }

            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;
 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

 if(u1_num_mbs)
 {
                ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
                ps_dec->u2_cur_mb_addr--;
                ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

 /* Inserting new slice only if the current slice has atleast 1 MB*/
 if(ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice <
 (UWORD32)(ps_dec->u2_total_mbs_coded >> ps_slice->u1_mbaff_frame_flag))
 {
                ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
                ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
                ps_dec->u2_cur_slice_num++;
                ps_dec->ps_parse_cur_slice++;
 }

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_cur_slice->i1_slice_alpha_c0_offset = 0;
    ps_dec->ps_cur_slice->i1_slice_beta_offset = 0;

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;
    ps_dec->u2_mbx =
 (MOD(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby =
 (DIV(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby <<= u1_mbaff;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

    H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);


 /* incremented here only if first slice is inserted */
 if(ps_dec->u4_first_slice_in_pic != 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: const BlockEntry* Cluster::GetEntry(const Track* pTrack,
 long long time_ns) const {
  assert(pTrack);

 if (m_pSegment == NULL) // this is the special EOS cluster
 return pTrack->GetEOS();

 const BlockEntry* pResult = pTrack->GetEOS();

 long index = 0;

 for (;;) {
 if (index >= m_entries_count) {
 long long pos;
 long len;

 const long status = Parse(pos, len);
      assert(status >= 0);

 if (status > 0) // completely parsed, and no more entries
 return pResult;

 if (status < 0) // should never happen
 return 0;

      assert(m_entries);
      assert(index < m_entries_count);
 }

 const BlockEntry* const pEntry = m_entries[index];
    assert(pEntry);
    assert(!pEntry->EOS());

 const Block* const pBlock = pEntry->GetBlock();
    assert(pBlock);

 if (pBlock->GetTrackNumber() != pTrack->GetNumber()) {
 ++index;
 continue;
 }

 if (pTrack->VetEntry(pEntry)) {
 if (time_ns < 0) // just want first candidate block
 return pEntry;

 const long long ns = pBlock->GetTime(this);

 if (ns > time_ns)
 return pResult;

      pResult = pEntry; // have a candidate
 } else if (time_ns >= 0) {
 const long long ns = pBlock->GetTime(this);

 if (ns > time_ns)
 return pResult;
 }

 ++index;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Parcel::readAligned(T *pArg) const {
    COMPILE_TIME_ASSERT_FUNCTION_SCOPE(PAD_SIZE(sizeof(T)) == sizeof(T));

 if ((mDataPos+sizeof(T)) <= mDataSize) {
 const void* data = mData+mDataPos;
        mDataPos += sizeof(T);
 *pArg = *reinterpret_cast<const T*>(data);
 return NO_ERROR;
 } else {
 return NOT_ENOUGH_DATA;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_config_save(void) {

   assert(alarm_timer != NULL);
   assert(config != NULL);
 
  alarm_set(alarm_timer, CONFIG_SETTLE_PERIOD_MS, timer_config_save, NULL);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::prepareAsync_l()
{
 if ( (mPlayer != 0) && ( mCurrentState & (MEDIA_PLAYER_INITIALIZED | MEDIA_PLAYER_STOPPED) ) ) {
 if (mAudioAttributesParcel != NULL) {
            mPlayer->setParameter(KEY_PARAMETER_AUDIO_ATTRIBUTES, *mAudioAttributesParcel);
 } else {
            mPlayer->setAudioStreamType(mStreamType);
 }
        mCurrentState = MEDIA_PLAYER_PREPARING;
 return mPlayer->prepareAsync();
 }
    ALOGE("prepareAsync called in state %d", mCurrentState);
 return INVALID_OPERATION;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: tBTM_STATUS BTM_SecGetDeviceLinkKey (BD_ADDR bd_addr, LINK_KEY link_key)
{
    tBTM_SEC_DEV_REC *p_dev_rec;

 if (((p_dev_rec = btm_find_dev (bd_addr)) != NULL)
 && (p_dev_rec->sec_flags & BTM_SEC_LINK_KEY_KNOWN))
 {
        memcpy (link_key, p_dev_rec->link_key, LINK_KEY_LEN);
 return(BTM_SUCCESS);
 }
 return(BTM_UNKNOWN_ADDR);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline int bta_role_to_btpan(int bta_pan_role)
{
 int btpan_role = 0;
    BTIF_TRACE_DEBUG("bta_pan_role:0x%x", bta_pan_role);
 if (bta_pan_role & PAN_ROLE_NAP_SERVER)
        btpan_role |= BTPAN_ROLE_PANNAP;
 if (bta_pan_role & PAN_ROLE_CLIENT)
        btpan_role |= BTPAN_ROLE_PANU;
 return btpan_role;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char* find_and_open_tombstone(int* fd) {
 char path[128];
 int oldest = -1;
 struct stat oldest_sb;
 for (int i = 0; i < MAX_TOMBSTONES; i++) {
    snprintf(path, sizeof(path), TOMBSTONE_TEMPLATE, i);

 struct stat sb;
 if (!stat(path, &sb)) {
 if (oldest < 0 || sb.st_mtime < oldest_sb.st_mtime) {
        oldest = i;
        oldest_sb.st_mtime = sb.st_mtime;
 }
 continue;
 }
 if (errno != ENOENT)
 continue;

 *fd = open(path, O_CREAT | O_EXCL | O_WRONLY | O_NOFOLLOW | O_CLOEXEC, 0600);
 if (*fd < 0)
 continue; // raced ?

    fchown(*fd, AID_SYSTEM, AID_SYSTEM);
 return strdup(path);
 }

 if (oldest < 0) {
    ALOGE("Failed to find a valid tombstone, default to using tombstone 0.\n");
    oldest = 0;
 }

  snprintf(path, sizeof(path), TOMBSTONE_TEMPLATE, oldest);
 *fd = open(path, O_CREAT | O_TRUNC | O_WRONLY | O_NOFOLLOW | O_CLOEXEC, 0600);
 if (*fd < 0) {
    ALOGE("failed to open tombstone file '%s': %s\n", path, strerror(errno));
 return NULL;
 }
  fchown(*fd, AID_SYSTEM, AID_SYSTEM);
 return strdup(path);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_parse_slice_data(codec_t *ps_codec)
{

    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    WORD32 end_of_slice_flag;
 sps_t *ps_sps;
 pps_t *ps_pps;
 slice_header_t *ps_slice_hdr;
    WORD32 end_of_pic;
 tile_t *ps_tile, *ps_tile_prev;
    WORD32 i;
    WORD32 ctb_addr;
    WORD32 tile_idx;
    WORD32 cabac_init_idc;
    WORD32 ctb_size;
    WORD32 num_ctb_in_row;
    WORD32 num_min4x4_in_ctb;
    WORD32 slice_qp;
    WORD32 slice_start_ctb_idx;
    WORD32 tile_start_ctb_idx;


    ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr_base;
    ps_pps = ps_codec->s_parse.ps_pps_base;
    ps_sps = ps_codec->s_parse.ps_sps_base;

 /* Get current slice header, pps and sps */
    ps_slice_hdr += (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1));
    ps_pps  += ps_slice_hdr->i1_pps_id;
    ps_sps  += ps_pps->i1_sps_id;

 if(0 != ps_codec->s_parse.i4_cur_slice_idx)
 {
 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
            ps_codec->s_parse.i4_cur_independent_slice_idx =
                    ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1);
 }
 }


    ctb_size = 1 << ps_sps->i1_log2_ctb_size;
    num_min4x4_in_ctb = (ctb_size / 4) * (ctb_size / 4);
    num_ctb_in_row = ps_sps->i2_pic_wd_in_ctb;

 /* Update the parse context */
 if(0 == ps_codec->i4_slice_error)
 {
        ps_codec->s_parse.i4_ctb_x = ps_slice_hdr->i2_ctb_x;
        ps_codec->s_parse.i4_ctb_y = ps_slice_hdr->i2_ctb_y;
 }
    ps_codec->s_parse.ps_pps = ps_pps;
    ps_codec->s_parse.ps_sps = ps_sps;
    ps_codec->s_parse.ps_slice_hdr = ps_slice_hdr;

 /* Derive Tile positions for the current CTB */
 /* Change this to lookup if required */
    ihevcd_get_tile_pos(ps_pps, ps_sps, ps_codec->s_parse.i4_ctb_x,
                        ps_codec->s_parse.i4_ctb_y,
 &ps_codec->s_parse.i4_ctb_tile_x,
 &ps_codec->s_parse.i4_ctb_tile_y,
 &tile_idx);
    ps_codec->s_parse.ps_tile = ps_pps->ps_tile + tile_idx;
    ps_codec->s_parse.i4_cur_tile_idx = tile_idx;
    ps_tile = ps_codec->s_parse.ps_tile;
 if(tile_idx)
        ps_tile_prev = ps_tile - 1;
 else
        ps_tile_prev = ps_tile;

 /* If the present slice is dependent, then store the previous
     * independent slices' ctb x and y values for decoding process */
 if(0 == ps_codec->i4_slice_error)
 {
 if(1 == ps_slice_hdr->i1_dependent_slice_flag)
 {
 /*If slice is present at the start of a new tile*/
 if((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                ps_codec->s_parse.i4_ctb_slice_x = 0;
                ps_codec->s_parse.i4_ctb_slice_y = 0;
 }
 }

 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
            ps_codec->s_parse.i4_ctb_slice_x = 0;
            ps_codec->s_parse.i4_ctb_slice_y = 0;
 }
 }

 /* Frame level initializations */
 if((0 == ps_codec->s_parse.i4_ctb_y) &&
 (0 == ps_codec->s_parse.i4_ctb_x))
 {
        ret = ihevcd_parse_pic_init(ps_codec);
        RETURN_IF((ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS), ret);

        ps_codec->s_parse.pu4_pic_tu_idx[0] = 0;
        ps_codec->s_parse.pu4_pic_pu_idx[0] = 0;
        ps_codec->s_parse.i4_cur_independent_slice_idx = 0;
        ps_codec->s_parse.i4_ctb_tile_x = 0;
        ps_codec->s_parse.i4_ctb_tile_y = 0;
 }

 {
 /* Updating the poc list of current slice to ps_mv_buf */
 mv_buf_t *ps_mv_buf = ps_codec->s_parse.ps_cur_mv_buf;

 if(ps_slice_hdr->i1_num_ref_idx_l1_active != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                ps_mv_buf->ai4_l1_collocated_poc[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_pic_buf)->i4_abs_poc;
                ps_mv_buf->ai1_l1_collocated_poc_lt[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_pic_buf)->u1_used_as_ref;
 }
 }

 if(ps_slice_hdr->i1_num_ref_idx_l0_active != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
                ps_mv_buf->ai4_l0_collocated_poc[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_pic_buf)->i4_abs_poc;
                ps_mv_buf->ai1_l0_collocated_poc_lt[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_pic_buf)->u1_used_as_ref;
 }
 }
 }

 /*Initialize the low delay flag at the beginning of every slice*/
 if((0 == ps_codec->s_parse.i4_ctb_slice_x) || (0 == ps_codec->s_parse.i4_ctb_slice_y))
 {
 /* Lowdelay flag */
        WORD32 cur_poc, ref_list_poc, flag = 1;
        cur_poc = ps_slice_hdr->i4_abs_pic_order_cnt;
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
            ref_list_poc = ((mv_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_mv_buf)->i4_abs_poc;
 if(ref_list_poc > cur_poc)
 {
                flag = 0;
 break;
 }
 }
 if(flag && (ps_slice_hdr->i1_slice_type == BSLICE))
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                ref_list_poc = ((mv_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_mv_buf)->i4_abs_poc;
 if(ref_list_poc > cur_poc)
 {
                    flag = 0;
 break;
 }
 }
 }
        ps_slice_hdr->i1_low_delay_flag = flag;
 }

 /* initialize the cabac init idc based on slice type */
 if(ps_slice_hdr->i1_slice_type == ISLICE)
 {
        cabac_init_idc = 0;
 }
 else if(ps_slice_hdr->i1_slice_type == PSLICE)
 {
        cabac_init_idc = ps_slice_hdr->i1_cabac_init_flag ? 2 : 1;
 }
 else
 {
        cabac_init_idc = ps_slice_hdr->i1_cabac_init_flag ? 1 : 2;
 }

    slice_qp = ps_slice_hdr->i1_slice_qp_delta + ps_pps->i1_pic_init_qp;
    slice_qp = CLIP3(slice_qp, 0, 51);

 /*Update QP value for every indepndent slice or for every dependent slice that begins at the start of a new tile*/
 if((0 == ps_slice_hdr->i1_dependent_slice_flag) ||
 ((1 == ps_slice_hdr->i1_dependent_slice_flag) && ((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))))
 {
        ps_codec->s_parse.u4_qp = slice_qp;
 }

 /*Cabac init at the beginning of a slice*/
 if((1 == ps_slice_hdr->i1_dependent_slice_flag) && (!((ps_codec->s_parse.i4_ctb_tile_x == 0) && (ps_codec->s_parse.i4_ctb_tile_y == 0))))
 {
 if((0 == ps_pps->i1_entropy_coding_sync_enabled_flag) || (ps_pps->i1_entropy_coding_sync_enabled_flag && (0 != ps_codec->s_parse.i4_ctb_x)))
 {
            ihevcd_cabac_reset(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm);
 }

     }
     else if((0 == ps_pps->i1_entropy_coding_sync_enabled_flag) || (ps_pps->i1_entropy_coding_sync_enabled_flag && (0 != ps_codec->s_parse.i4_ctb_x)))
     {
        ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
                          &ps_codec->s_parse.s_bitstrm,
                          slice_qp,
                          cabac_init_idc,
                          &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);
     }
 
 
 do
 {

 {
            WORD32 cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
 if(1 == ps_codec->i4_num_cores && 0 == cur_ctb_idx % RESET_TU_BUF_NCTB)
 {
                ps_codec->s_parse.ps_tu = ps_codec->s_parse.ps_pic_tu;
                ps_codec->s_parse.i4_pic_tu_idx = 0;
 }
 }

        end_of_pic = 0;
 /* Section:7.3.7 Coding tree unit syntax */
 /* coding_tree_unit() inlined here */
 /* If number of cores is greater than 1, then add job to the queue */
 /* At the start of ctb row parsing in a tile, queue a job for processing the current tile row */
        ps_codec->s_parse.i4_ctb_num_pcm_blks = 0;


 /*At the beginning of each tile-which is not the beginning of a slice, cabac context must be initialized.
         * Hence, check for the tile beginning here */
 if(((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))
 && (!((ps_tile->u1_pos_x == 0) && (ps_tile->u1_pos_y == 0)))
 && (!((0 == ps_codec->s_parse.i4_ctb_slice_x) && (0 == ps_codec->s_parse.i4_ctb_slice_y))))
 {
            slice_qp = ps_slice_hdr->i1_slice_qp_delta + ps_pps->i1_pic_init_qp;
            slice_qp = CLIP3(slice_qp, 0, 51);
            ps_codec->s_parse.u4_qp = slice_qp;

            ihevcd_get_tile_pos(ps_pps, ps_sps, ps_codec->s_parse.i4_ctb_x,
                                ps_codec->s_parse.i4_ctb_y,
 &ps_codec->s_parse.i4_ctb_tile_x,
 &ps_codec->s_parse.i4_ctb_tile_y,
 &tile_idx);

            ps_codec->s_parse.ps_tile = ps_pps->ps_tile + tile_idx;
            ps_codec->s_parse.i4_cur_tile_idx = tile_idx;
            ps_tile_prev = ps_tile - 1;

            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 /*For slices that span across multiple tiles*/
 if(slice_start_ctb_idx < tile_start_ctb_idx)
 { /* 2 Cases
             * 1 - slice spans across frame-width- but does not start from 1st column
             * 2 - Slice spans across multiple tiles anywhere is a frame
             */
                ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y - ps_slice_hdr->i2_ctb_y;
 if(!(((ps_slice_hdr->i2_ctb_x + ps_tile_prev->u2_wd) % ps_sps->i2_pic_wd_in_ctb) == ps_tile->u1_pos_x)) //Case 2
 {
 if(ps_slice_hdr->i2_ctb_y <= ps_tile->u1_pos_y)
 {
 if(ps_slice_hdr->i2_ctb_x > ps_tile->u1_pos_x)
 {
                            ps_codec->s_parse.i4_ctb_slice_y -= 1;
 }
 }
 }
 /*ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y - ps_slice_hdr->i2_ctb_y;
                if (ps_slice_hdr->i2_ctb_y <= ps_tile->u1_pos_y)
                {
                    if (ps_slice_hdr->i2_ctb_x > ps_tile->u1_pos_x )
                    {
                        ps_codec->s_parse.i4_ctb_slice_y -= 1 ;
                    }
                }*/
 }


             /* Cabac init is done unconditionally at the start of the tile irrespective
              * of whether it is a dependent or an independent slice */
             {
                ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
                                  &ps_codec->s_parse.s_bitstrm,
                                  slice_qp,
                                  cabac_init_idc,
                                  &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);
 
             }
         }
 /* If number of cores is greater than 1, then add job to the queue */
 /* At the start of ctb row parsing in a tile, queue a job for processing the current tile row */

 if(0 == ps_codec->s_parse.i4_ctb_tile_x)
 {

 if(1 < ps_codec->i4_num_cores)
 {
 proc_job_t s_job;
                IHEVCD_ERROR_T ret;
                s_job.i4_cmd    = CMD_PROCESS;
                s_job.i2_ctb_cnt = (WORD16)ps_tile->u2_wd;
                s_job.i2_ctb_x = (WORD16)ps_codec->s_parse.i4_ctb_x;
                s_job.i2_ctb_y = (WORD16)ps_codec->s_parse.i4_ctb_y;
                s_job.i2_slice_idx = (WORD16)ps_codec->s_parse.i4_cur_slice_idx;
                s_job.i4_tu_coeff_data_ofst = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data -
 (UWORD8 *)ps_codec->s_parse.pv_pic_tu_coeff_data;
                ret = ihevcd_jobq_queue((jobq_t *)ps_codec->s_parse.pv_proc_jobq, &s_job, sizeof(proc_job_t), 1);

 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 return ret;
 }
 else
 {
 process_ctxt_t *ps_proc = &ps_codec->as_process[0];
                WORD32 tu_coeff_data_ofst = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data -
 (UWORD8 *)ps_codec->s_parse.pv_pic_tu_coeff_data;

 /* If the codec is running in single core mode,
                 * initialize zeroth process context
                 * TODO: Dual core mode might need a different implementation instead of jobq
                 */

                ps_proc->i4_ctb_cnt = ps_tile->u2_wd;
                ps_proc->i4_ctb_x   = ps_codec->s_parse.i4_ctb_x;
                ps_proc->i4_ctb_y   = ps_codec->s_parse.i4_ctb_y;
                ps_proc->i4_cur_slice_idx = ps_codec->s_parse.i4_cur_slice_idx;

                ihevcd_init_proc_ctxt(ps_proc, tu_coeff_data_ofst);
 }
 }


 /* Restore cabac context model from top right CTB if entropy sync is enabled */
 if(ps_pps->i1_entropy_coding_sync_enabled_flag)
 {
 /*TODO Handle single CTB and top-right belonging to a different slice */
 if(0 == ps_codec->s_parse.i4_ctb_x)
 {
                WORD32 default_ctxt = 0;

 if((0 == ps_codec->s_parse.i4_ctb_slice_y) && (!ps_slice_hdr->i1_dependent_slice_flag))
                    default_ctxt = 1;
 if(1 == ps_sps->i2_pic_wd_in_ctb)
                    default_ctxt = 1;

                ps_codec->s_parse.u4_qp = slice_qp;

                 if(default_ctxt)
                 {
                    ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
                                      &ps_codec->s_parse.s_bitstrm,
                                      slice_qp,
                                      cabac_init_idc,
                                      &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);
 
                 }
                 else
                 {
                    ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
                                      &ps_codec->s_parse.s_bitstrm,
                                      slice_qp,
                                      cabac_init_idc,
                                      (const UWORD8 *)&ps_codec->s_parse.s_cabac.au1_ctxt_models_sync);
 
                 }
             }
         }



 if(0 == ps_codec->i4_slice_error)
 {
 if(ps_slice_hdr->i1_slice_sao_luma_flag || ps_slice_hdr->i1_slice_sao_chroma_flag)
                ihevcd_parse_sao(ps_codec);
 }
 else
 {
 sao_t *ps_sao = ps_codec->s_parse.ps_pic_sao +
                            ps_codec->s_parse.i4_ctb_x +
                            ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 /* Default values */
            ps_sao->b3_y_type_idx = 0;
            ps_sao->b3_cb_type_idx = 0;
            ps_sao->b3_cr_type_idx = 0;
 }


 {
            WORD32 ctb_indx;
            ctb_indx = ps_codec->s_parse.i4_ctb_x + ps_sps->i2_pic_wd_in_ctb * ps_codec->s_parse.i4_ctb_y;
            ps_codec->s_parse.s_bs_ctxt.pu1_pic_qp_const_in_ctb[ctb_indx >> 3] |= (1 << (ctb_indx & 7));
 {
                UWORD16 *pu1_slice_idx = ps_codec->s_parse.pu1_slice_idx;
                pu1_slice_idx[ctb_indx] = ps_codec->s_parse.i4_cur_independent_slice_idx;
 }
 }

 if(0 == ps_codec->i4_slice_error)
 {
            ihevcd_parse_coding_quadtree(ps_codec,
 (ps_codec->s_parse.i4_ctb_x << ps_sps->i1_log2_ctb_size),
 (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size),
                                         ps_sps->i1_log2_ctb_size,
 0);
 }
 else
 {
 tu_t *ps_tu = ps_codec->s_parse.ps_tu;
 pu_t *ps_pu = ps_codec->s_parse.ps_pu;

            ps_tu->b1_cb_cbf = 0;
            ps_tu->b1_cr_cbf = 0;
            ps_tu->b1_y_cbf = 0;
            ps_tu->b4_pos_x = 0;
            ps_tu->b4_pos_y = 0;
            ps_tu->b1_transquant_bypass = 0;
            ps_tu->b3_size = (ps_sps->i1_log2_ctb_size - 2);
            ps_tu->b7_qp = ps_codec->s_parse.u4_qp;
            ps_tu->b3_chroma_intra_mode_idx = INTRA_PRED_CHROMA_IDX_NONE;
            ps_tu->b6_luma_intra_mode   = INTRA_PRED_NONE;
            ps_tu->b1_first_tu_in_cu = 1;

            ps_codec->s_parse.ps_tu++;
            ps_codec->s_parse.s_cu.i4_tu_cnt++;
            ps_codec->s_parse.i4_pic_tu_idx++;

            ps_codec->s_parse.s_cu.i4_pred_mode = PRED_MODE_SKIP;
            ps_codec->s_parse.s_cu.i4_part_mode = PART_2Nx2N;

            ps_pu->b2_part_idx = 0;
            ps_pu->b4_pos_x = 0;
            ps_pu->b4_pos_y = 0;
            ps_pu->b4_wd = (ctb_size >> 2) - 1;
            ps_pu->b4_ht = (ctb_size >> 2) - 1;
            ps_pu->b1_intra_flag = 0;
            ps_pu->b3_part_mode = ps_codec->s_parse.s_cu.i4_part_mode;
            ps_pu->b1_merge_flag = 1;
            ps_pu->b3_merge_idx = 0;

            ps_codec->s_parse.ps_pu++;
            ps_codec->s_parse.i4_pic_pu_idx++;

 }

 if(0 == ps_codec->i4_slice_error)
            end_of_slice_flag = ihevcd_cabac_decode_terminate(&ps_codec->s_parse.s_cabac, &ps_codec->s_parse.s_bitstrm);
 else
            end_of_slice_flag = 0;

        AEV_TRACE("end_of_slice_flag", end_of_slice_flag, ps_codec->s_parse.s_cabac.u4_range);


 /* In case of tiles or entropy sync, terminate cabac and copy cabac context backed up at the end of top-right CTB */
 if(ps_pps->i1_tiles_enabled_flag || ps_pps->i1_entropy_coding_sync_enabled_flag)
 {
            WORD32 end_of_tile = 0;
            WORD32 end_of_tile_row = 0;

 /* Take a back up of cabac context models if entropy sync is enabled */
 if(ps_pps->i1_entropy_coding_sync_enabled_flag || ps_pps->i1_tiles_enabled_flag)
 {
 if(1 == ps_codec->s_parse.i4_ctb_x)
 {
                    WORD32 size = sizeof(ps_codec->s_parse.s_cabac.au1_ctxt_models);
                    memcpy(&ps_codec->s_parse.s_cabac.au1_ctxt_models_sync, &ps_codec->s_parse.s_cabac.au1_ctxt_models, size);
 }
 }

 /* Since tiles and entropy sync are not enabled simultaneously, the following will not result in any problems */
 if((ps_codec->s_parse.i4_ctb_tile_x + 1) == (ps_tile->u2_wd))
 {
                end_of_tile_row = 1;
 if((ps_codec->s_parse.i4_ctb_tile_y + 1) == ps_tile->u2_ht)
                    end_of_tile = 1;
 }
 if((0 == end_of_slice_flag) &&
 ((ps_pps->i1_tiles_enabled_flag && end_of_tile) ||
 (ps_pps->i1_entropy_coding_sync_enabled_flag && end_of_tile_row)))
 {
                WORD32 end_of_sub_stream_one_bit;
                end_of_sub_stream_one_bit = ihevcd_cabac_decode_terminate(&ps_codec->s_parse.s_cabac, &ps_codec->s_parse.s_bitstrm);
                AEV_TRACE("end_of_sub_stream_one_bit", end_of_sub_stream_one_bit, ps_codec->s_parse.s_cabac.u4_range);

 /* TODO: Remove the check for offset when HM is updated to include a byte unconditionally even for aligned location */
 /* For Ittiam streams this check should not be there, for HM9.1 streams this should be there */
 if(ps_codec->s_parse.s_bitstrm.u4_bit_ofst % 8)
                    ihevcd_bits_flush_to_byte_boundary(&ps_codec->s_parse.s_bitstrm);

                UNUSED(end_of_sub_stream_one_bit);
 }
 }
 {
            WORD32 ctb_indx;

            ctb_addr = ps_codec->s_parse.i4_ctb_y * num_ctb_in_row + ps_codec->s_parse.i4_ctb_x;

            ctb_indx = ++ctb_addr;

 /* Store pu_idx for next CTB in frame level pu_idx array */

 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                        ctb_indx = ctb_addr; //Next continuous ctb address
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                        ctb_indx = ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }

            ps_codec->s_parse.pu4_pic_pu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_pu_idx;
            ps_codec->s_parse.i4_next_pu_ctb_cnt = ctb_indx;

            ps_codec->s_parse.pu1_pu_map += num_min4x4_in_ctb;

 /* Store tu_idx for next CTB in frame level tu_idx array */
 if(1 == ps_codec->i4_num_cores)
 {
                ctb_indx = (0 == ctb_addr % RESET_TU_BUF_NCTB) ?
                                RESET_TU_BUF_NCTB : ctb_addr % RESET_TU_BUF_NCTB;

 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                    ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                            ctb_indx = (0 == ctb_addr % RESET_TU_BUF_NCTB) ?
                                            RESET_TU_BUF_NCTB : ctb_addr % RESET_TU_BUF_NCTB;
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                            ctb_indx =  ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }
                ps_codec->s_parse.i4_next_tu_ctb_cnt = ctb_indx;
                ps_codec->s_parse.pu4_pic_tu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_tu_idx;
 }
 else
 {
                ctb_indx = ctb_addr;
 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                    ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                            ctb_indx = ctb_addr;
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                            ctb_indx =  ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }
                ps_codec->s_parse.i4_next_tu_ctb_cnt = ctb_indx;
                ps_codec->s_parse.pu4_pic_tu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_tu_idx;
 }
            ps_codec->s_parse.pu1_tu_map += num_min4x4_in_ctb;
 }

 /* QP array population has to be done if deblocking is enabled in the picture
         * but some of the slices in the pic have it disabled */
 if((0 != ps_codec->i4_disable_deblk_pic) &&
 (1 == ps_slice_hdr->i1_slice_disable_deblocking_filter_flag))
 {
 bs_ctxt_t *ps_bs_ctxt = &ps_codec->s_parse.s_bs_ctxt;
            WORD32 log2_ctb_size = ps_sps->i1_log2_ctb_size;
            UWORD8 *pu1_qp;
            WORD32 qp_strd;
            WORD32 u4_qp_const_in_ctb;
            WORD32 cur_ctb_idx;
            WORD32 next_ctb_idx;
            WORD32 cur_tu_idx;
            WORD32 i4_ctb_tu_cnt;
 tu_t *ps_tu;

            cur_ctb_idx = ps_codec->s_parse.i4_ctb_x + ps_sps->i2_pic_wd_in_ctb * ps_codec->s_parse.i4_ctb_y;
 /* ctb_size/8 elements per CTB */
            qp_strd = ps_sps->i2_pic_wd_in_ctb << (log2_ctb_size - 3);
            pu1_qp = ps_bs_ctxt->pu1_pic_qp + ((ps_codec->s_parse.i4_ctb_x + ps_codec->s_parse.i4_ctb_y * qp_strd) << (log2_ctb_size - 3));

            u4_qp_const_in_ctb = ps_bs_ctxt->pu1_pic_qp_const_in_ctb[cur_ctb_idx >> 3] & (1 << (cur_ctb_idx & 7));

            next_ctb_idx = ps_codec->s_parse.i4_next_tu_ctb_cnt;
 if(1 == ps_codec->i4_num_cores)
 {
                i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];

                cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];
 }
 else
 {
                i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];

                cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];
 }

            ps_tu = &ps_codec->s_parse.ps_pic_tu[cur_tu_idx];

 if(u4_qp_const_in_ctb)
 {
                pu1_qp[0] = ps_tu->b7_qp;
 }
 else
 {
 for(i = 0; i < i4_ctb_tu_cnt; i++, ps_tu++)
 {
                    WORD32 start_pos_x;
                    WORD32 start_pos_y;
                    WORD32 tu_size;

 /* start_pos_x and start_pos_y are in units of min TU size (4x4) */
                    start_pos_x = ps_tu->b4_pos_x;
                    start_pos_y = ps_tu->b4_pos_y;

                    tu_size = 1 << (ps_tu->b3_size + 2);
                    tu_size >>= 2; /* TU size divided by 4 */

 if(0 == (start_pos_x & 1) && 0 == (start_pos_y & 1))
 {
                        WORD32 row, col;
 for(row = start_pos_y; row < start_pos_y + tu_size; row += 2)
 {
 for(col = start_pos_x; col < start_pos_x + tu_size; col += 2)
 {
                                pu1_qp[(row >> 1) * qp_strd + (col >> 1)] = ps_tu->b7_qp;
 }
 }
 }
 }
 }
 }

 if(ps_codec->i4_num_cores <= MV_PRED_NUM_CORES_THRESHOLD)
 {
 /*************************************************/
 /****************   MV pred **********************/
 /*************************************************/
            WORD8 u1_top_ctb_avail = 1;
            WORD8 u1_left_ctb_avail = 1;
            WORD8 u1_top_lt_ctb_avail = 1;
            WORD8 u1_top_rt_ctb_avail = 1;
            WORD16 i2_wd_in_ctb;

            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 if((slice_start_ctb_idx < tile_start_ctb_idx))
 {
                i2_wd_in_ctb = ps_sps->i2_pic_wd_in_ctb;
 }
 else
 {
                i2_wd_in_ctb = ps_tile->u2_wd;
 }
 /* slice and tile boundaries */
 if((0 == ps_codec->s_parse.i4_ctb_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                u1_top_ctb_avail = 0;
                u1_top_lt_ctb_avail = 0;
                u1_top_rt_ctb_avail = 0;
 }

 if((0 == ps_codec->s_parse.i4_ctb_x) || (0 == ps_codec->s_parse.i4_ctb_tile_x))
 {
                u1_left_ctb_avail = 0;
                u1_top_lt_ctb_avail = 0;
 if((0 == ps_codec->s_parse.i4_ctb_slice_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                    u1_top_ctb_avail = 0;
 if((i2_wd_in_ctb - 1) != ps_codec->s_parse.i4_ctb_slice_x) //TODO: For tile, not implemented
 {
                        u1_top_rt_ctb_avail = 0;
 }
 }
 }
 /*For slices not beginning at start of a ctb row*/
 else if(ps_codec->s_parse.i4_ctb_x > 0)
 {
 if((0 == ps_codec->s_parse.i4_ctb_slice_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                    u1_top_ctb_avail = 0;
                    u1_top_lt_ctb_avail = 0;
 if(0 == ps_codec->s_parse.i4_ctb_slice_x)
 {
                        u1_left_ctb_avail = 0;
 }
 if((i2_wd_in_ctb - 1) != ps_codec->s_parse.i4_ctb_slice_x)
 {
                        u1_top_rt_ctb_avail = 0;
 }
 }
 else if((1 == ps_codec->s_parse.i4_ctb_slice_y) && (0 == ps_codec->s_parse.i4_ctb_slice_x))
 {
                    u1_top_lt_ctb_avail = 0;
 }
 }

 if(((ps_sps->i2_pic_wd_in_ctb - 1) == ps_codec->s_parse.i4_ctb_x) || ((ps_tile->u2_wd - 1) == ps_codec->s_parse.i4_ctb_tile_x))
 {
                u1_top_rt_ctb_avail = 0;
 }

 if(PSLICE == ps_slice_hdr->i1_slice_type
 || BSLICE == ps_slice_hdr->i1_slice_type)
 {
 mv_ctxt_t s_mv_ctxt;
 process_ctxt_t *ps_proc;
                UWORD32 *pu4_ctb_top_pu_idx;
                UWORD32 *pu4_ctb_left_pu_idx;
                UWORD32 *pu4_ctb_top_left_pu_idx;
                WORD32 i4_ctb_pu_cnt;
                WORD32 cur_ctb_idx;
                WORD32 next_ctb_idx;
                WORD32 cur_pu_idx;
                ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
                next_ctb_idx = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                i4_ctb_pu_cnt = ps_codec->s_parse.pu4_pic_pu_idx[next_ctb_idx]
 - ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];

                cur_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];

                pu4_ctb_top_pu_idx = ps_proc->pu4_pic_pu_idx_top
 + (ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE);
                pu4_ctb_left_pu_idx = ps_proc->pu4_pic_pu_idx_left;
                pu4_ctb_top_left_pu_idx = &ps_proc->u4_ctb_top_left_pu_idx;

 /* Initializing s_mv_ctxt */
 {
                    s_mv_ctxt.ps_pps = ps_pps;
                    s_mv_ctxt.ps_sps = ps_sps;
                    s_mv_ctxt.ps_slice_hdr = ps_slice_hdr;
                    s_mv_ctxt.i4_ctb_x = ps_codec->s_parse.i4_ctb_x;
                    s_mv_ctxt.i4_ctb_y = ps_codec->s_parse.i4_ctb_y;
                    s_mv_ctxt.ps_pu = &ps_codec->s_parse.ps_pic_pu[cur_pu_idx];
                    s_mv_ctxt.ps_pic_pu = ps_codec->s_parse.ps_pic_pu;
                    s_mv_ctxt.ps_tile = ps_tile;
                    s_mv_ctxt.pu4_pic_pu_idx_map = ps_proc->pu4_pic_pu_idx_map;
                    s_mv_ctxt.pu4_pic_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx;
                    s_mv_ctxt.pu1_pic_pu_map = ps_codec->s_parse.pu1_pic_pu_map;
                    s_mv_ctxt.i4_ctb_pu_cnt = i4_ctb_pu_cnt;
                    s_mv_ctxt.i4_ctb_start_pu_idx = cur_pu_idx;
                    s_mv_ctxt.u1_top_ctb_avail = u1_top_ctb_avail;
                    s_mv_ctxt.u1_top_rt_ctb_avail = u1_top_rt_ctb_avail;
                    s_mv_ctxt.u1_top_lt_ctb_avail = u1_top_lt_ctb_avail;
                    s_mv_ctxt.u1_left_ctb_avail = u1_left_ctb_avail;
 }

                ihevcd_get_mv_ctb(&s_mv_ctxt, pu4_ctb_top_pu_idx,
                                  pu4_ctb_left_pu_idx, pu4_ctb_top_left_pu_idx);

 }
 else
 {
                WORD32 num_minpu_in_ctb = (ctb_size / MIN_PU_SIZE) * (ctb_size / MIN_PU_SIZE);
                UWORD8 *pu1_pic_pu_map_ctb = ps_codec->s_parse.pu1_pic_pu_map +
 (ps_codec->s_parse.i4_ctb_x + ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb) * num_minpu_in_ctb;
 process_ctxt_t *ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                WORD32 row, col;
                WORD32 pu_cnt;
                WORD32 num_pu_per_ctb;
                WORD32 cur_ctb_idx;
                WORD32 next_ctb_idx;
                WORD32 ctb_start_pu_idx;
                UWORD32 *pu4_nbr_pu_idx = ps_proc->pu4_pic_pu_idx_map;
                WORD32 nbr_pu_idx_strd = MAX_CTB_SIZE / MIN_PU_SIZE + 2;
 pu_t *ps_pu;

 for(row = 0; row < ctb_size / MIN_PU_SIZE; row++)
 {
 for(col = 0; col < ctb_size / MIN_PU_SIZE; col++)
 {
                        pu1_pic_pu_map_ctb[row * ctb_size / MIN_PU_SIZE + col] = 0;
 }
 }


 /* Neighbor PU idx update inside CTB */
 /* 1byte per 4x4. Indicates the PU idx that 4x4 block belongs to */

                cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
                next_ctb_idx = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                num_pu_per_ctb = ps_codec->s_parse.pu4_pic_pu_idx[next_ctb_idx]
 - ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                ctb_start_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                ps_pu = &ps_codec->s_parse.ps_pic_pu[ctb_start_pu_idx];

 for(pu_cnt = 0; pu_cnt < num_pu_per_ctb; pu_cnt++, ps_pu++)
 {
                    UWORD32 cur_pu_idx;
                    WORD32 pu_ht = (ps_pu->b4_ht + 1) << 2;
                    WORD32 pu_wd = (ps_pu->b4_wd + 1) << 2;

                    cur_pu_idx = ctb_start_pu_idx + pu_cnt;

 for(row = 0; row < pu_ht / MIN_PU_SIZE; row++)
 for(col = 0; col < pu_wd / MIN_PU_SIZE; col++)
                            pu4_nbr_pu_idx[(1 + ps_pu->b4_pos_x + col)
 + (1 + ps_pu->b4_pos_y + row)
 * nbr_pu_idx_strd] =
                                            cur_pu_idx;
 }

 /* Updating Top and Left pointers */
 {
                    WORD32 rows_remaining = ps_sps->i2_pic_height_in_luma_samples
 - (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size);
                    WORD32 ctb_size_left = MIN(ctb_size, rows_remaining);

 /* Top Left */
 /* saving top left before updating top ptr, as updating top ptr will overwrite the top left for the next ctb */
                    ps_proc->u4_ctb_top_left_pu_idx = ps_proc->pu4_pic_pu_idx_top[(ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE) + ctb_size / MIN_PU_SIZE - 1];
 for(i = 0; i < ctb_size / MIN_PU_SIZE; i++)
 {
 /* Left */
 /* Last column of au4_nbr_pu_idx */
                        ps_proc->pu4_pic_pu_idx_left[i] = pu4_nbr_pu_idx[(ctb_size / MIN_PU_SIZE)
 + (i + 1) * nbr_pu_idx_strd];
 /* Top */
 /* Last row of au4_nbr_pu_idx */
                        ps_proc->pu4_pic_pu_idx_top[(ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE) + i] =
                                        pu4_nbr_pu_idx[(ctb_size_left / MIN_PU_SIZE) * nbr_pu_idx_strd + i + 1];

 }
 }
 }

 /*************************************************/
 /******************  BS, QP  *********************/
 /*************************************************/
 /* Check if deblock is disabled for the current slice or if it is disabled for the current picture
             * because of disable deblock api
             */
 if(0 == ps_codec->i4_disable_deblk_pic)
 {
 /* Boundary strength calculation is done irrespective of whether deblocking is disabled
                 * in the slice or not, to handle deblocking slice boundaries */
 if((0 == ps_codec->i4_slice_error))
 {
                    WORD32 i4_ctb_tu_cnt;
                    WORD32 cur_ctb_idx, next_ctb_idx;
                    WORD32 cur_pu_idx;
                    WORD32 cur_tu_idx;
 process_ctxt_t *ps_proc;

                    ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                    cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

                    cur_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                    next_ctb_idx = ps_codec->s_parse.i4_next_tu_ctb_cnt;
 if(1 == ps_codec->i4_num_cores)
 {
                        i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                        ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];

                        cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];
 }
 else
 {
                        i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                        ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];

                        cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];
 }

                    ps_codec->s_parse.s_bs_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
                    ps_codec->s_parse.s_bs_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
                    ps_codec->s_parse.s_bs_ctxt.ps_codec = ps_codec;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tu_cnt = i4_ctb_tu_cnt;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_x = ps_codec->s_parse.i4_ctb_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_y = ps_codec->s_parse.i4_ctb_y;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tile_x = ps_codec->s_parse.i4_ctb_tile_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tile_y = ps_codec->s_parse.i4_ctb_tile_y;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_slice_x = ps_codec->s_parse.i4_ctb_slice_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_slice_y = ps_codec->s_parse.i4_ctb_slice_y;
                    ps_codec->s_parse.s_bs_ctxt.ps_tu = &ps_codec->s_parse.ps_pic_tu[cur_tu_idx];
                    ps_codec->s_parse.s_bs_ctxt.ps_pu = &ps_codec->s_parse.ps_pic_pu[cur_pu_idx];
                    ps_codec->s_parse.s_bs_ctxt.pu4_pic_pu_idx_map = ps_proc->pu4_pic_pu_idx_map;
                    ps_codec->s_parse.s_bs_ctxt.i4_next_pu_ctb_cnt = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                    ps_codec->s_parse.s_bs_ctxt.i4_next_tu_ctb_cnt = ps_codec->s_parse.i4_next_tu_ctb_cnt;
                    ps_codec->s_parse.s_bs_ctxt.pu1_slice_idx = ps_codec->s_parse.pu1_slice_idx;
                    ps_codec->s_parse.s_bs_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;
                    ps_codec->s_parse.s_bs_ctxt.ps_tile = ps_codec->s_parse.ps_tile;

 if(ISLICE == ps_slice_hdr->i1_slice_type)
 {
                        ihevcd_ctb_boundary_strength_islice(&ps_codec->s_parse.s_bs_ctxt);
 }
 else
 {
                        ihevcd_ctb_boundary_strength_pbslice(&ps_codec->s_parse.s_bs_ctxt);
 }
 }

 /* Boundary strength is set to zero if deblocking is disabled for the current slice */
 if(0 != ps_slice_hdr->i1_slice_disable_deblocking_filter_flag)
 {
                    WORD32 bs_strd = (ps_sps->i2_pic_wd_in_ctb + 1) * (ctb_size * ctb_size / 8 / 16);

                    UWORD32 *pu4_vert_bs = (UWORD32 *)((UWORD8 *)ps_codec->s_parse.s_bs_ctxt.pu4_pic_vert_bs +
                                    ps_codec->s_parse.i4_ctb_x * (ctb_size * ctb_size / 8 / 16) +
                                    ps_codec->s_parse.i4_ctb_y * bs_strd);
                    UWORD32 *pu4_horz_bs = (UWORD32 *)((UWORD8 *)ps_codec->s_parse.s_bs_ctxt.pu4_pic_horz_bs +
                                    ps_codec->s_parse.i4_ctb_x * (ctb_size * ctb_size / 8 / 16) +
                                    ps_codec->s_parse.i4_ctb_y * bs_strd);

                    memset(pu4_vert_bs, 0, (ctb_size / 8) * (ctb_size / 4) / 8 * 2);
                    memset(pu4_horz_bs, 0, (ctb_size / 8) * (ctb_size / 4) / 8 * 2);
 }
 }

 }

        DATA_SYNC();

 /* Update the parse status map */
 {
 sps_t *ps_sps = ps_codec->s_parse.ps_sps;
            UWORD8 *pu1_buf;
            WORD32 idx;
            idx = (ps_codec->s_parse.i4_ctb_x);
            idx += ((ps_codec->s_parse.i4_ctb_y) * ps_sps->i2_pic_wd_in_ctb);
            pu1_buf = (ps_codec->pu1_parse_map + idx);
 *pu1_buf = 1;
 }

 /* Increment CTB x and y positions */
        ps_codec->s_parse.i4_ctb_tile_x++;
        ps_codec->s_parse.i4_ctb_x++;
        ps_codec->s_parse.i4_ctb_slice_x++;

 /*If tiles are enabled, handle the slice counters differently*/
 if(ps_pps->i1_tiles_enabled_flag)
 {
            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 if((slice_start_ctb_idx < tile_start_ctb_idx))
 {
 if(ps_codec->s_parse.i4_ctb_slice_x == (ps_tile->u1_pos_x + ps_tile->u2_wd))
 {
 /* Reached end of slice row within a tile /frame */
                    ps_codec->s_parse.i4_ctb_slice_y++;
                    ps_codec->s_parse.i4_ctb_slice_x = ps_tile->u1_pos_x; //todo:Check
 }
 }
 else if(ps_codec->s_parse.i4_ctb_slice_x == (ps_tile->u2_wd))
 {
                ps_codec->s_parse.i4_ctb_slice_y++;
                ps_codec->s_parse.i4_ctb_slice_x = 0;
 }
 }
 else
 {
 if(ps_codec->s_parse.i4_ctb_slice_x == ps_tile->u2_wd)
 {
 /* Reached end of slice row within a tile /frame */
                ps_codec->s_parse.i4_ctb_slice_y++;
                ps_codec->s_parse.i4_ctb_slice_x = 0;
 }
 }


 if(ps_codec->s_parse.i4_ctb_tile_x == (ps_tile->u2_wd))
 {
 /* Reached end of tile row */
            ps_codec->s_parse.i4_ctb_tile_x = 0;
            ps_codec->s_parse.i4_ctb_x = ps_tile->u1_pos_x;

            ps_codec->s_parse.i4_ctb_tile_y++;
            ps_codec->s_parse.i4_ctb_y++;

 if(ps_codec->s_parse.i4_ctb_tile_y == (ps_tile->u2_ht))
 {
 /* Reached End of Tile */
                ps_codec->s_parse.i4_ctb_tile_y = 0;
                ps_codec->s_parse.i4_ctb_tile_x = 0;
                ps_codec->s_parse.ps_tile++;

 if((ps_tile->u2_ht + ps_tile->u1_pos_y  ==  ps_sps->i2_pic_ht_in_ctb) && (ps_tile->u2_wd + ps_tile->u1_pos_x  ==  ps_sps->i2_pic_wd_in_ctb))
 {
 /* Reached end of frame */
                    end_of_pic = 1;
                    ps_codec->s_parse.i4_ctb_x = 0;
                    ps_codec->s_parse.i4_ctb_y = ps_sps->i2_pic_ht_in_ctb;
 }
 else
 {
 /* Initialize ctb_x and ctb_y to start of next tile */
                    ps_tile = ps_codec->s_parse.ps_tile;
                    ps_codec->s_parse.i4_ctb_x = ps_tile->u1_pos_x;
                    ps_codec->s_parse.i4_ctb_y = ps_tile->u1_pos_y;
                    ps_codec->s_parse.i4_ctb_tile_y = 0;
                    ps_codec->s_parse.i4_ctb_tile_x = 0;
                    ps_codec->s_parse.i4_ctb_slice_x = ps_tile->u1_pos_x;
                    ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y;

 }
 }

 }

        ps_codec->s_parse.i4_next_ctb_indx = ps_codec->s_parse.i4_ctb_x +
                        ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 /* If the current slice is in error, check if the next slice's address
         * is reached and mark the end_of_slice flag */
 if(ps_codec->i4_slice_error)
 {
 slice_header_t *ps_slice_hdr_next = ps_slice_hdr + 1;
            WORD32 next_slice_addr = ps_slice_hdr_next->i2_ctb_x +
                            ps_slice_hdr_next->i2_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 if(ps_codec->s_parse.i4_next_ctb_indx == next_slice_addr)
                end_of_slice_flag = 1;
 }

 /* If the codec is running in single core mode
         * then call process function for current CTB
         */
 if((1 == ps_codec->i4_num_cores) && (ps_codec->s_parse.i4_ctb_tile_x == 0))
 {
 process_ctxt_t *ps_proc = &ps_codec->as_process[0];
            ps_proc->i4_ctb_cnt = ps_proc->ps_tile->u2_wd;
            ihevcd_process(ps_proc);
 }

 /* If the bytes for the current slice are exhausted
         * set end_of_slice flag to 1
         * This slice will be treated as incomplete */
 if((UWORD8 *)ps_codec->s_parse.s_bitstrm.pu1_buf_max + BITSTRM_OFF_THRS <
 ((UWORD8 *)ps_codec->s_parse.s_bitstrm.pu4_buf + (ps_codec->s_parse.s_bitstrm.u4_bit_ofst / 8)))
 {

 if(0 == ps_codec->i4_slice_error)
                end_of_slice_flag = 1;
 }


 if(end_of_pic)

             break;
     } while(!end_of_slice_flag);
 
     /* Increment the slice index for parsing next slice */
     if(0 == end_of_pic)
     {
 while(1)
 {

            WORD32 parse_slice_idx;
            parse_slice_idx = ps_codec->s_parse.i4_cur_slice_idx;
            parse_slice_idx++;

 {
 /* If the next slice header is not initialized, update cur_slice_idx and break */
 if((1 == ps_codec->i4_num_cores) || (0 != (parse_slice_idx & (MAX_SLICE_HDR_CNT - 1))))
 {
                    ps_codec->s_parse.i4_cur_slice_idx = parse_slice_idx;
 break;
 }

 /* If the next slice header is initialised, wait for the parsed slices to be processed */
 else
 {
                    WORD32 ctb_indx = 0;

 while(ctb_indx != ps_sps->i4_pic_size_in_ctb)
 {
                        WORD32 parse_status = *(ps_codec->pu1_parse_map + ctb_indx);
 volatile WORD32 proc_status = *(ps_codec->pu1_proc_map + ctb_indx) & 1;

 if(parse_status == proc_status)
                            ctb_indx++;
 }
                    ps_codec->s_parse.i4_cur_slice_idx = parse_slice_idx;
 break;
 }

 }
 }

 }
 else
 {
#if FRAME_ILF_PAD
 if(FRAME_ILF_PAD && 1 == ps_codec->i4_num_cores)
 {
 if(ps_slice_hdr->i4_abs_pic_order_cnt == 0)
 {
                DUMP_PRE_ILF(ps_codec->as_process[0].pu1_cur_pic_luma,
                             ps_codec->as_process[0].pu1_cur_pic_chroma,
                             ps_sps->i2_pic_width_in_luma_samples,
                             ps_sps->i2_pic_height_in_luma_samples,
                             ps_codec->i4_strd);

                DUMP_BS(ps_codec->as_process[0].s_bs_ctxt.pu4_pic_vert_bs,
                        ps_codec->as_process[0].s_bs_ctxt.pu4_pic_horz_bs,
                        ps_sps->i2_pic_wd_in_ctb * (ctb_size * ctb_size / 8 / 16) * ps_sps->i2_pic_ht_in_ctb,
 (ps_sps->i2_pic_wd_in_ctb + 1) * (ctb_size * ctb_size / 8 / 16) * ps_sps->i2_pic_ht_in_ctb);

                DUMP_QP(ps_codec->as_process[0].s_bs_ctxt.pu1_pic_qp,
 (ps_sps->i2_pic_height_in_luma_samples * ps_sps->i2_pic_width_in_luma_samples) / (MIN_CU_SIZE * MIN_CU_SIZE));

                DUMP_QP_CONST_IN_CTB(ps_codec->as_process[0].s_bs_ctxt.pu1_pic_qp_const_in_ctb,
 (ps_sps->i2_pic_height_in_luma_samples * ps_sps->i2_pic_width_in_luma_samples) / (MIN_CTB_SIZE * MIN_CTB_SIZE) / 8);

                DUMP_NO_LOOP_FILTER(ps_codec->as_process[0].pu1_pic_no_loop_filter_flag,
 (ps_sps->i2_pic_width_in_luma_samples / MIN_CU_SIZE) * (ps_sps->i2_pic_height_in_luma_samples / MIN_CU_SIZE) / 8);

                DUMP_OFFSETS(ps_slice_hdr->i1_beta_offset_div2,
                             ps_slice_hdr->i1_tc_offset_div2,
                             ps_pps->i1_pic_cb_qp_offset,
                             ps_pps->i1_pic_cr_qp_offset);
 }
            ps_codec->s_parse.s_deblk_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
            ps_codec->s_parse.s_deblk_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
            ps_codec->s_parse.s_deblk_ctxt.ps_codec = ps_codec;
            ps_codec->s_parse.s_deblk_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;
            ps_codec->s_parse.s_deblk_ctxt.is_chroma_yuv420sp_vu = (ps_codec->e_ref_chroma_fmt == IV_YUV_420SP_VU);

            ps_codec->s_parse.s_sao_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
            ps_codec->s_parse.s_sao_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
            ps_codec->s_parse.s_sao_ctxt.ps_codec = ps_codec;
            ps_codec->s_parse.s_sao_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;

            ihevcd_ilf_pad_frame(&ps_codec->s_parse.s_deblk_ctxt, &ps_codec->s_parse.s_sao_ctxt);

 }
#endif
        ps_codec->s_parse.i4_end_of_frame = 1;
 }
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 impeg2d_dec_pnb_mb_params(dec_state_t *ps_dec)
{
 stream_t *ps_stream = &ps_dec->s_bit_stream;
    UWORD16 u2_mb_addr_incr;
    UWORD16 u2_total_len;
    UWORD16 u2_len;
    UWORD16 u2_mb_type;
    UWORD32 u4_next_word;
 const dec_mb_params_t *ps_dec_mb_params;
 if(impeg2d_bit_stream_nxt(ps_stream,1) == 1)
 {
        impeg2d_bit_stream_flush(ps_stream,1);

 }
 else
 {
        u2_mb_addr_incr = impeg2d_get_mb_addr_incr(ps_stream);

 if(ps_dec->u2_first_mb)
 {
 /****************************************************************/
 /* Section 6.3.17                                               */
 /* The first MB of a slice cannot be skipped                    */
 /* But the mb_addr_incr can be > 1, because at the beginning of */
 /* a slice, it indicates the offset from the last MB in the     */
 /* previous row. Hence for the first slice in a row, the        */
 /* mb_addr_incr needs to be 1.                                  */
 /****************************************************************/
 /* MB_x is set to zero whenever MB_y changes.                   */
            ps_dec->u2_mb_x = u2_mb_addr_incr - 1;
 /* For error resilience */
            ps_dec->u2_mb_x = MIN(ps_dec->u2_mb_x, (ps_dec->u2_num_horiz_mb - 1));

 /****************************************************************/
 /* mb_addr_incr is forced to 1 because in this decoder it is used */
 /* more as an indicator of the number of MBs skipped than the   */
 /* as defined by the standard (Section 6.3.17)                  */
 /****************************************************************/
            u2_mb_addr_incr = 1;
            ps_dec->u2_first_mb = 0;
 }
 else
 {
 /****************************************************************/
 /* In MPEG-2, the last MB of the row cannot be skipped and the  */
 /* mb_addr_incr cannot be such that it will take the current MB   */
 /* beyond the current row                                       */
 /* In MPEG-1, the slice could start and end anywhere and is not */
 /* restricted to a row like in MPEG-2. Hence this check should  */
 /* not be done for MPEG-1 streams.                              */
 /****************************************************************/
 if(ps_dec->u2_is_mpeg2 &&
 ((ps_dec->u2_mb_x + u2_mb_addr_incr) > ps_dec->u2_num_horiz_mb))
 {
                u2_mb_addr_incr    = ps_dec->u2_num_horiz_mb - ps_dec->u2_mb_x;
 }

 if ((u2_mb_addr_incr - 1) > ps_dec->u2_num_mbs_left)
 {
 /* If the number of skip MBs are more than the number of MBs
                 * left, indicate error.
                 */
 return IV_FAIL;
 }

            impeg2d_dec_skip_mbs(ps_dec, (UWORD16)(u2_mb_addr_incr - 1));
 }

 }
    u4_next_word = (UWORD16)impeg2d_bit_stream_nxt(ps_stream,16);
 /*-----------------------------------------------------------------------*/
 /* MB type                                                               */
 /*-----------------------------------------------------------------------*/
 {
        u2_mb_type   = ps_dec->pu2_mb_type[BITS((UWORD16)u4_next_word,15,10)];
        u2_len      = BITS(u2_mb_type,15,8);
        u2_total_len = u2_len;
        u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << u2_len);
 }
 /*-----------------------------------------------------------------------*/
 /* motion type                                                           */
 /*-----------------------------------------------------------------------*/
 {
        WORD32 i4_motion_type = ps_dec->u2_motion_type;

 if((u2_mb_type & MB_FORW_OR_BACK) &&  ps_dec->u2_read_motion_type)
 {
            ps_dec->u2_motion_type = BITS((UWORD16)u4_next_word,15,14);
            u2_total_len += MB_MOTION_TYPE_LEN;
            u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << MB_MOTION_TYPE_LEN);
            i4_motion_type     = ps_dec->u2_motion_type;

 }


 if ((u2_mb_type & MB_FORW_OR_BACK) &&
 ((i4_motion_type == 0) ||
 (i4_motion_type == 3) ||
 (i4_motion_type == 4) ||
 (i4_motion_type >= 7)))
 {
            i4_motion_type = 1;
 }

 }
 /*-----------------------------------------------------------------------*/
 /* dct type                                                              */
 /*-----------------------------------------------------------------------*/
 {
 if((u2_mb_type & MB_CODED) && ps_dec->u2_read_dct_type)
 {
            ps_dec->u2_field_dct = BIT((UWORD16)u4_next_word,15);
            u2_total_len += MB_DCT_TYPE_LEN;
            u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << MB_DCT_TYPE_LEN);
 }
 }
 /*-----------------------------------------------------------------------*/
 /* Quant scale code                                                      */
 /*-----------------------------------------------------------------------*/
 if(u2_mb_type & MB_QUANT)
 {
        UWORD16 u2_quant_scale_code;
        u2_quant_scale_code = BITS((UWORD16)u4_next_word,15,11);

        ps_dec->u1_quant_scale = (ps_dec->u2_q_scale_type) ?
            gau1_impeg2_non_linear_quant_scale[u2_quant_scale_code] : (u2_quant_scale_code << 1);
        u2_total_len += MB_QUANT_SCALE_CODE_LEN;
 }
    impeg2d_bit_stream_flush(ps_stream,u2_total_len);
 /*-----------------------------------------------------------------------*/
 /* Set the function pointers                                             */
 /*-----------------------------------------------------------------------*/
    ps_dec->u2_coded_mb    = (UWORD16)(u2_mb_type & MB_CODED);

 if(u2_mb_type & MB_BIDRECT)
 {
        UWORD16 u2_index       = (ps_dec->u2_motion_type);

        ps_dec->u2_prev_intra_mb    = 0;
        ps_dec->e_mb_pred         = BIDIRECT;
        ps_dec_mb_params = &ps_dec->ps_func_bi_direct[u2_index];
        ps_dec->s_mb_type = ps_dec_mb_params->s_mb_type;
 if(NULL == ps_dec_mb_params->pf_func_mb_params)
 return -1;
        ps_dec_mb_params->pf_func_mb_params(ps_dec);
 }
 else if(u2_mb_type & MB_FORW_OR_BACK)
 {

        UWORD16 u2_refPic      = !(u2_mb_type & MB_MV_FORW);
        UWORD16 u2_index       = (ps_dec->u2_motion_type);
        ps_dec->u2_prev_intra_mb    = 0;
        ps_dec->e_mb_pred         = (e_pred_direction_t)u2_refPic;
        ps_dec_mb_params = &ps_dec->ps_func_forw_or_back[u2_index];
        ps_dec->s_mb_type = ps_dec_mb_params->s_mb_type;
 if(NULL == ps_dec_mb_params->pf_func_mb_params)
 return -1;
        ps_dec_mb_params->pf_func_mb_params(ps_dec);

 }
 else if(u2_mb_type & MB_TYPE_INTRA)
 {
        ps_dec->u2_prev_intra_mb    = 1;
        impeg2d_dec_intra_mb(ps_dec);

 }
 else
 {
        ps_dec->u2_prev_intra_mb =0;
        ps_dec->e_mb_pred = FORW;
        ps_dec->u2_motion_type = 0;
        impeg2d_dec_0mv_coded_mb(ps_dec);
 }

 /*-----------------------------------------------------------------------*/
 /* decode cbp                                                            */
 /*-----------------------------------------------------------------------*/
 if((u2_mb_type & MB_TYPE_INTRA))
 {
        ps_dec->u2_cbp  = 0x3f;
        ps_dec->u2_prev_intra_mb    = 1;
 }
 else
 {
        ps_dec->u2_prev_intra_mb  = 0;
        ps_dec->u2_def_dc_pred[Y_LUMA] = 128 << ps_dec->u2_intra_dc_precision;
        ps_dec->u2_def_dc_pred[U_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
        ps_dec->u2_def_dc_pred[V_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
 if((ps_dec->u2_coded_mb))
 {
            UWORD16 cbpValue;
            cbpValue  = gau2_impeg2d_cbp_code[impeg2d_bit_stream_nxt(ps_stream,MB_CBP_LEN)];
            ps_dec->u2_cbp  = cbpValue & 0xFF;
            impeg2d_bit_stream_flush(ps_stream,(cbpValue >> 8) & 0x0FF);
 }
 else
 {
            ps_dec->u2_cbp  = 0;
 }
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void connect_to_remote(asocket* s, const char* destination) {
    D("Connect_to_remote call RS(%d) fd=%d", s->id, s->fd);
    apacket* p = get_apacket();
 size_t len = strlen(destination) + 1;

 if (len > (s->get_max_payload() - 1)) {
        fatal("destination oversized");
 }

    D("LS(%d): connect('%s')", s->id, destination);
    p->msg.command = A_OPEN;
    p->msg.arg0 = s->id;
    p->msg.data_length = len;
    strcpy((char*)p->data, destination);
    send_packet(p, s->transport);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   void RunFwdTxfm(int16_t *in, int16_t *out, int stride) {
     fwd_txfm_(in, out, stride);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t OMXNodeInstance::freeBuffer(
        OMX_U32 portIndex, OMX::buffer_id buffer) {
 Mutex::Autolock autoLock(mLock);
    CLOG_BUFFER(freeBuffer, "%s:%u %#x", portString(portIndex), portIndex, buffer);

    removeActiveBuffer(portIndex, buffer);

    OMX_BUFFERHEADERTYPE *header = findBufferHeader(buffer, portIndex);
 if (header == NULL) {
        ALOGE("b/25884056");
 return BAD_VALUE;
 }
 BufferMeta *buffer_meta = static_cast<BufferMeta *>(header->pAppPrivate);

    OMX_ERRORTYPE err = OMX_FreeBuffer(mHandle, portIndex, header);
    CLOG_IF_ERROR(freeBuffer, err, "%s:%u %#x", portString(portIndex), portIndex, buffer);

 delete buffer_meta;
    buffer_meta = NULL;
    invalidateBufferID(buffer);

 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btsock_rfc_cleanup(void) {
  pth = -1;

  pthread_mutex_lock(&slot_lock);
 for (size_t i = 0; i < ARRAY_SIZE(rfc_slots); ++i) {
 if (rfc_slots[i].id)
      cleanup_rfc_slot(&rfc_slots[i]);
    list_free(rfc_slots[i].incoming_queue);
 }
  pthread_mutex_unlock(&slot_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t ctrl_get_bit_depth(vpx_codec_alg_priv_t *ctx,
                                          va_list args) {
 unsigned int *const bit_depth = va_arg(args, unsigned int *);
 VPxWorker *const worker = &ctx->frame_workers[ctx->next_output_worker_id];

 if (bit_depth) {
 if (worker) {
 FrameWorkerData *const frame_worker_data =
 (FrameWorkerData *)worker->data1;
 const VP9_COMMON *const cm = &frame_worker_data->pbi->common;
 *bit_depth = cm->bit_depth;
 return VPX_CODEC_OK;
 } else {
 return VPX_CODEC_ERROR;
 }
 }

 return VPX_CODEC_INVALID_PARAM;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_av_del_rc(tBTA_AV_RCB* p_rcb) {
  tBTA_AV_SCB* p_scb;
 uint8_t rc_handle; /* connected AVRCP handle */

  p_scb = NULL;
 if (p_rcb->handle != BTA_AV_RC_HANDLE_NONE) {
 if (p_rcb->shdl) {
 /* Validate array index*/
 if ((p_rcb->shdl - 1) < BTA_AV_NUM_STRS) {
        p_scb = bta_av_cb.p_scb[p_rcb->shdl - 1];
 }
 if (p_scb) {
        APPL_TRACE_DEBUG("%s: shdl:%d, srch:%d rc_handle:%d", __func__,
                         p_rcb->shdl, p_scb->rc_handle, p_rcb->handle);
 if (p_scb->rc_handle == p_rcb->handle)
          p_scb->rc_handle = BTA_AV_RC_HANDLE_NONE;
 /* just in case the RC timer is active
        if (bta_av_cb.features & BTA_AV_FEAT_RCCT && p_scb->chnl ==
        BTA_AV_CHNL_AUDIO) */
        alarm_cancel(p_scb->avrc_ct_timer);
 }
 }

    APPL_TRACE_EVENT("%s: handle: %d status=0x%x, rc_acp_handle:%d, idx:%d",
                     __func__, p_rcb->handle, p_rcb->status,
                     bta_av_cb.rc_acp_handle, bta_av_cb.rc_acp_idx);
    rc_handle = p_rcb->handle;
 if (!(p_rcb->status & BTA_AV_RC_CONN_MASK) ||
 ((p_rcb->status & BTA_AV_RC_ROLE_MASK) == BTA_AV_RC_ROLE_INT)) {
      p_rcb->status = 0;
      p_rcb->handle = BTA_AV_RC_HANDLE_NONE;
      p_rcb->shdl = 0;
      p_rcb->lidx = 0;
 }
 /* else ACP && connected. do not clear the handle yet */
    AVRC_Close(rc_handle);
 if (rc_handle == bta_av_cb.rc_acp_handle)
      bta_av_cb.rc_acp_handle = BTA_AV_RC_HANDLE_NONE;
    APPL_TRACE_EVENT(
 "%s: end del_rc handle: %d status=0x%x, rc_acp_handle:%d, lidx:%d",
        __func__, p_rcb->handle, p_rcb->status, bta_av_cb.rc_acp_handle,
        p_rcb->lidx);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ihevcd_copy_slice_hdr(codec_t *ps_codec, WORD32 slice_idx, WORD32 slice_idx_ref)
{
 slice_header_t *ps_slice_hdr, *ps_slice_hdr_ref;
    WORD32 *pu4_entry_offset_backup;

    ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr_base + slice_idx;
    ps_slice_hdr_ref = ps_codec->s_parse.ps_slice_hdr_base + slice_idx_ref;

    pu4_entry_offset_backup = ps_slice_hdr->pu4_entry_point_offset;
    memcpy(ps_slice_hdr, ps_slice_hdr_ref, sizeof(slice_header_t));
    ps_slice_hdr->pu4_entry_point_offset = pu4_entry_offset_backup;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAACEncoder::onQueueFilled(OMX_U32 portIndex) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 if (!mSentCodecSpecificData) {

 if (outQueue.empty()) {
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
        outHeader->nFilledLen = sizeof(mAudioSpecificConfigData);
        outHeader->nFlags = OMX_BUFFERFLAG_CODECCONFIG;

 uint8_t *out = outHeader->pBuffer + outHeader->nOffset;
        memcpy(out, mAudioSpecificConfigData, sizeof(mAudioSpecificConfigData));

#if 0
        ALOGI("sending codec specific data.");
        hexdump(out, sizeof(mAudioSpecificConfigData));
#endif

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        mSentCodecSpecificData = true;
 }

 size_t numBytesPerInputFrame =
        mNumChannels * kNumSamplesPerFrame * sizeof(int16_t);

 for (;;) {

 while (mInputSize < numBytesPerInputFrame) {

 if (mSawInputEOS || inQueue.empty()) {
 return;
 }

 BufferInfo *inInfo = *inQueue.begin();
            OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 const void *inData = inHeader->pBuffer + inHeader->nOffset;

 size_t copy = numBytesPerInputFrame - mInputSize;
 if (copy > inHeader->nFilledLen) {
                copy = inHeader->nFilledLen;
 }

 if (mInputFrame == NULL) {
                mInputFrame = new int16_t[kNumSamplesPerFrame * mNumChannels];
 }

 if (mInputSize == 0) {
                mInputTimeUs = inHeader->nTimeStamp;
 }

            memcpy((uint8_t *)mInputFrame + mInputSize, inData, copy);
            mInputSize += copy;

            inHeader->nOffset += copy;
            inHeader->nFilledLen -= copy;

            inHeader->nTimeStamp +=
 (copy * 1000000ll / mSampleRate)
 / (mNumChannels * sizeof(int16_t));

 if (inHeader->nFilledLen == 0) {
 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                    ALOGV("saw input EOS");
                    mSawInputEOS = true;

                    memset((uint8_t *)mInputFrame + mInputSize,
 0,
                           numBytesPerInputFrame - mInputSize);

                    mInputSize = numBytesPerInputFrame;
 }

                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);

                inData = NULL;
                inHeader = NULL;
                inInfo = NULL;
 }
 }


 if (outQueue.empty()) {
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

        VO_CODECBUFFER inputData;
        memset(&inputData, 0, sizeof(inputData));
        inputData.Buffer = (unsigned char *)mInputFrame;
        inputData.Length = numBytesPerInputFrame;
        CHECK(VO_ERR_NONE ==
                mApiHandle->SetInputData(mEncoderHandle, &inputData));

        VO_CODECBUFFER outputData;
        memset(&outputData, 0, sizeof(outputData));
        VO_AUDIO_OUTPUTINFO outputInfo;
        memset(&outputInfo, 0, sizeof(outputInfo));

 uint8_t *outPtr = (uint8_t *)outHeader->pBuffer + outHeader->nOffset;
 size_t outAvailable = outHeader->nAllocLen - outHeader->nOffset;

        VO_U32 ret = VO_ERR_NONE;
 size_t nOutputBytes = 0;
 do {
            outputData.Buffer = outPtr;
            outputData.Length = outAvailable - nOutputBytes;
            ret = mApiHandle->GetOutputData(
                    mEncoderHandle, &outputData, &outputInfo);
 if (ret == VO_ERR_NONE) {
                outPtr += outputData.Length;
                nOutputBytes += outputData.Length;
 }
 } while (ret != VO_ERR_INPUT_BUFFER_SMALL);

        outHeader->nFilledLen = nOutputBytes;

        outHeader->nFlags = OMX_BUFFERFLAG_ENDOFFRAME;

 if (mSawInputEOS) {
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;
 }

        outHeader->nTimeStamp = mInputTimeUs;

#if 0
        ALOGI("sending %d bytes of data (time = %lld us, flags = 0x%08lx)",
              nOutputBytes, mInputTimeUs, outHeader->nFlags);

        hexdump(outHeader->pBuffer + outHeader->nOffset, outHeader->nFilledLen);
#endif

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        outHeader = NULL;
        outInfo = NULL;

        mInputSize = 0;

     }
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool Cues::PreloadCuePoint(long& cue_points_size, long long pos) const {
 if (m_count != 0)
 return false;

 if (m_preload_count >= cue_points_size) {
 const long n = (cue_points_size <= 0) ? 2048 : 2 * cue_points_size;

 CuePoint** const qq = new (std::nothrow) CuePoint*[n];
 if (qq == NULL)
 return false;

 CuePoint** q = qq; // beginning of target

 CuePoint** p = m_cue_points; // beginning of source
 CuePoint** const pp = p + m_preload_count; // end of source

 while (p != pp)
 *q++ = *p++;

 delete[] m_cue_points;

    m_cue_points = qq;
    cue_points_size = n;
 }

 CuePoint* const pCP = new (std::nothrow) CuePoint(m_preload_count, pos);
 if (pCP == NULL)
 return false;

  m_cue_points[m_preload_count++] = pCP;
 return true;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual void dump(String8& result, const char* prefix) const {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeString8(result);
        data.writeString8(String8(prefix ? prefix : ""));
        remote()->transact(DUMP, data, &reply);
        reply.readString8();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void omx_vdec::print_debug_extradata(OMX_OTHER_EXTRADATATYPE *extra)
{
 if (!m_debug_extradata || !extra)
 return;


    DEBUG_PRINT_HIGH(
 "============== Extra Data ==============\n"
 "           Size: %u\n"
 "        Version: %u\n"
 "      PortIndex: %u\n"
 "           Type: %x\n"
 "       DataSize: %u",
 (unsigned int)extra->nSize, (unsigned int)extra->nVersion.nVersion,
 (unsigned int)extra->nPortIndex, extra->eType, (unsigned int)extra->nDataSize);

 if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataInterlaceFormat) {
        OMX_STREAMINTERLACEFORMAT *intfmt = (OMX_STREAMINTERLACEFORMAT *)(void *)extra->data;
        DEBUG_PRINT_HIGH(
 "------ Interlace Format ------\n"
 "                Size: %u\n"
 "             Version: %u\n"
 "           PortIndex: %u\n"
 " Is Interlace Format: %d\n"
 "   Interlace Formats: %u\n"
 "=========== End of Interlace ===========",
 (unsigned int)intfmt->nSize, (unsigned int)intfmt->nVersion.nVersion, (unsigned int)intfmt->nPortIndex,
                intfmt->bInterlaceFormat, (unsigned int)intfmt->nInterlaceFormats);
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataFrameInfo) {
        OMX_QCOM_EXTRADATA_FRAMEINFO *fminfo = (OMX_QCOM_EXTRADATA_FRAMEINFO *)(void *)extra->data;

        DEBUG_PRINT_HIGH(
 "-------- Frame Format --------\n"
 "             Picture Type: %d\n"
 "           Interlace Type: %d\n"
 " Pan Scan Total Frame Num: %u\n"
 "   Concealed Macro Blocks: %u\n"
 "               frame rate: %u\n"
 "               Time Stamp: %llu\n"
 "           Aspect Ratio X: %u\n"
 "           Aspect Ratio Y: %u",
                fminfo->ePicType,
                fminfo->interlaceType,
 (unsigned int)fminfo->panScan.numWindows,
 (unsigned int)fminfo->nConcealedMacroblocks,
 (unsigned int)fminfo->nFrameRate,
                fminfo->nTimeStamp,
 (unsigned int)fminfo->aspectRatio.aspectRatioX,
 (unsigned int)fminfo->aspectRatio.aspectRatioY);

 for (OMX_U32 i = 0; i < fminfo->panScan.numWindows; i++) {
            DEBUG_PRINT_HIGH(
 "------------------------------"
 "     Pan Scan Frame Num: %u\n"
 "            Rectangle x: %d\n"
 "            Rectangle y: %d\n"
 "           Rectangle dx: %d\n"
 "           Rectangle dy: %d",
 (unsigned int)i, (unsigned int)fminfo->panScan.window[i].x, (unsigned int)fminfo->panScan.window[i].y,
 (unsigned int)fminfo->panScan.window[i].dx, (unsigned int)fminfo->panScan.window[i].dy);
 }

        DEBUG_PRINT_HIGH("========= End of Frame Format ==========");
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataFramePackingArrangement) {
        OMX_QCOM_FRAME_PACK_ARRANGEMENT *framepack = (OMX_QCOM_FRAME_PACK_ARRANGEMENT *)(void *)extra->data;
        DEBUG_PRINT_HIGH(
 "------------------ Framepack Format ----------\n"
 "                           id: %u \n"
 "                  cancel_flag: %u \n"
 "                         type: %u \n"
 " quincunx_sampling_flagFormat: %u \n"
 "  content_interpretation_type: %u \n"
 "        spatial_flipping_flag: %u \n"
 "          frame0_flipped_flag: %u \n"
 "             field_views_flag: %u \n"
 " current_frame_is_frame0_flag: %u \n"
 "   frame0_self_contained_flag: %u \n"
 "   frame1_self_contained_flag: %u \n"
 "       frame0_grid_position_x: %u \n"
 "       frame0_grid_position_y: %u \n"
 "       frame1_grid_position_x: %u \n"
 "       frame1_grid_position_y: %u \n"
 "                reserved_byte: %u \n"
 "            repetition_period: %u \n"
 "               extension_flag: %u \n"
 "================== End of Framepack ===========",
 (unsigned int)framepack->id,
 (unsigned int)framepack->cancel_flag,
 (unsigned int)framepack->type,
 (unsigned int)framepack->quincunx_sampling_flag,
 (unsigned int)framepack->content_interpretation_type,
 (unsigned int)framepack->spatial_flipping_flag,
 (unsigned int)framepack->frame0_flipped_flag,
 (unsigned int)framepack->field_views_flag,
 (unsigned int)framepack->current_frame_is_frame0_flag,
 (unsigned int)framepack->frame0_self_contained_flag,
 (unsigned int)framepack->frame1_self_contained_flag,
 (unsigned int)framepack->frame0_grid_position_x,
 (unsigned int)framepack->frame0_grid_position_y,
 (unsigned int)framepack->frame1_grid_position_x,
 (unsigned int)framepack->frame1_grid_position_y,
 (unsigned int)framepack->reserved_byte,
 (unsigned int)framepack->repetition_period,
 (unsigned int)framepack->extension_flag);
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataQP) {
        OMX_QCOM_EXTRADATA_QP * qp = (OMX_QCOM_EXTRADATA_QP *)(void *)extra->data;
        DEBUG_PRINT_HIGH(
 "---- QP (Frame quantization parameter) ----\n"
 "    Frame QP: %u \n"
 "================ End of QP ================\n",
 (unsigned int)qp->nQP);
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataInputBitsInfo) {
        OMX_QCOM_EXTRADATA_BITS_INFO * bits = (OMX_QCOM_EXTRADATA_BITS_INFO *)(void *)extra->data;
        DEBUG_PRINT_HIGH(
 "--------- Input bits information --------\n"
 "    Header bits: %u \n"
 "     Frame bits: %u \n"
 "===== End of Input bits information =====\n",
 (unsigned int)bits->header_bits, (unsigned int)bits->frame_bits);
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataMP2UserData) {
        OMX_QCOM_EXTRADATA_USERDATA *userdata = (OMX_QCOM_EXTRADATA_USERDATA *)(void *)extra->data;
        OMX_U8 *data_ptr = (OMX_U8 *)userdata->data;
        OMX_U32 userdata_size = extra->nDataSize - sizeof(userdata->type);
        OMX_U32 i = 0;
        DEBUG_PRINT_HIGH(
 "--------------  Userdata  -------------\n"
 "    Stream userdata type: %u\n"
 "          userdata size: %u\n"
 "    STREAM_USERDATA:",
 (unsigned int)userdata->type, (unsigned int)userdata_size);
 for (i = 0; i < userdata_size; i+=4) {
                    DEBUG_PRINT_HIGH("        %x %x %x %x",
                        data_ptr[i], data_ptr[i+1],
                        data_ptr[i+2], data_ptr[i+3]);
 }
        DEBUG_PRINT_HIGH(
 "=========== End of Userdata ===========");
 } else if (extra->eType == (OMX_EXTRADATATYPE)OMX_ExtraDataMpeg2SeqDisplay) {
        OMX_QCOM_EXTRADATA_MPEG2SEQDISPLAY *seq_display = (OMX_QCOM_EXTRADATA_MPEG2SEQDISPLAY*)(void*)extra->data;
        DEBUG_PRINT_HIGH(
 "------Mpeg2SeqDisplay ------\n"
 "     Frame Width: %d\n"
 "    Frame Height: %d\n"
 "=========== End of Mpeg2SeqDisplay ===========",
                seq_display->disp_width, seq_display->disp_height);
 } else if (extra->eType == OMX_ExtraDataNone) {
        DEBUG_PRINT_HIGH("========== End of Terminator ===========");
 } else {
        DEBUG_PRINT_HIGH("======= End of Driver Extradata ========");
 }
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: OMX_ERRORTYPE  omx_video::get_config(OMX_IN OMX_HANDLETYPE      hComp,
        OMX_IN OMX_INDEXTYPE configIndex,
        OMX_INOUT OMX_PTR     configData)
{
 (void)hComp;

 if (configData == NULL) {
        DEBUG_PRINT_ERROR("ERROR: param is null");
 return OMX_ErrorBadParameter;
 }

 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("ERROR: can't be in invalid state");
 return OMX_ErrorIncorrectStateOperation;
 }


     switch ((int)configIndex) {
         case OMX_IndexConfigVideoBitrate:
             {
                 OMX_VIDEO_CONFIG_BITRATETYPE* pParam = reinterpret_cast<OMX_VIDEO_CONFIG_BITRATETYPE*>(configData);
                 memcpy(pParam, &m_sConfigBitrate, sizeof(m_sConfigBitrate));
                 break;
             }
         case OMX_IndexConfigVideoFramerate:
             {
                 OMX_CONFIG_FRAMERATETYPE* pParam = reinterpret_cast<OMX_CONFIG_FRAMERATETYPE*>(configData);
                 memcpy(pParam, &m_sConfigFramerate, sizeof(m_sConfigFramerate));
                 break;
             }
         case OMX_IndexConfigCommonRotate:
             {
                 OMX_CONFIG_ROTATIONTYPE* pParam = reinterpret_cast<OMX_CONFIG_ROTATIONTYPE*>(configData);
                 memcpy(pParam, &m_sConfigFrameRotation, sizeof(m_sConfigFrameRotation));
                 break;
 }

         case QOMX_IndexConfigVideoIntraperiod:
             {
                 DEBUG_PRINT_LOW("get_config:QOMX_IndexConfigVideoIntraperiod");
                 QOMX_VIDEO_INTRAPERIODTYPE* pParam = reinterpret_cast<QOMX_VIDEO_INTRAPERIODTYPE*>(configData);
                 memcpy(pParam, &m_sIntraperiod, sizeof(m_sIntraperiod));
                 break;
             }
         case OMX_IndexConfigVideoAVCIntraPeriod:
             {
                 OMX_VIDEO_CONFIG_AVCINTRAPERIOD *pParam =
                     reinterpret_cast<OMX_VIDEO_CONFIG_AVCINTRAPERIOD*>(configData);
                 DEBUG_PRINT_LOW("get_config: OMX_IndexConfigVideoAVCIntraPeriod");
                memcpy(pParam, &m_sConfigAVCIDRPeriod, sizeof(m_sConfigAVCIDRPeriod));
 break;

             }
         case OMX_IndexConfigCommonDeinterlace:
             {
                 OMX_VIDEO_CONFIG_DEINTERLACE *pParam =
                     reinterpret_cast<OMX_VIDEO_CONFIG_DEINTERLACE*>(configData);
                 DEBUG_PRINT_LOW("get_config: OMX_IndexConfigCommonDeinterlace");
                memcpy(pParam, &m_sConfigDeinterlace, sizeof(m_sConfigDeinterlace));
 break;

             }
        case OMX_IndexConfigVideoVp8ReferenceFrame:
            {
                OMX_VIDEO_VP8REFERENCEFRAMETYPE* pParam =
                    reinterpret_cast<OMX_VIDEO_VP8REFERENCEFRAMETYPE*>(configData);
                DEBUG_PRINT_LOW("get_config: OMX_IndexConfigVideoVp8ReferenceFrame");
               memcpy(pParam, &m_sConfigVp8ReferenceFrame, sizeof(m_sConfigVp8ReferenceFrame));
 break;

            }
         case OMX_QcomIndexConfigPerfLevel:
             {
                 OMX_U32 perflevel;
                 OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *pParam =
                     reinterpret_cast<OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL*>(configData);
                DEBUG_PRINT_LOW("get_config: OMX_QcomIndexConfigPerfLevel");
 if (!dev_get_performance_level(&perflevel)) {
                    DEBUG_PRINT_ERROR("Invalid entry returned from get_performance_level %d",
                        pParam->ePerfLevel);
 } else {
                    pParam->ePerfLevel = (QOMX_VIDEO_PERF_LEVEL)perflevel;
 }
 break;
 }
 default:
            DEBUG_PRINT_ERROR("ERROR: unsupported index %d", (int) configIndex);
 return OMX_ErrorUnsupportedIndex;
 }
 return OMX_ErrorNone;

}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static bool getCoverageFormat12(vector<uint32_t>& coverage, const uint8_t* data, size_t size) {
 const size_t kNGroupsOffset = 12;
 const size_t kFirstGroupOffset = 16;
 const size_t kGroupSize = 12;
 const size_t kStartCharCodeOffset = 0;
 const size_t kEndCharCodeOffset = 4;
 const size_t kMaxNGroups = 0xfffffff0 / kGroupSize; // protection against overflow
 if (kFirstGroupOffset > size) {
 return false;

     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
     if (nGroups >= kMaxNGroups || kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
 uint32_t groupOffset = kFirstGroupOffset + i * kGroupSize;
 uint32_t start = readU32(data, groupOffset + kStartCharCodeOffset);

         uint32_t end = readU32(data, groupOffset + kEndCharCodeOffset);
         if (end < start) {
             return false;
         }
         addRange(coverage, start, end + 1);  // file is inclusive, vector is exclusive
 }
 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool CameraDeviceClient::enforceRequestPermissions(CameraMetadata& metadata) {

 const int pid = IPCThreadState::self()->getCallingPid();
 const int selfPid = getpid();
 camera_metadata_entry_t entry;

 /**
     * Mixin default important security values
     * - android.led.transmit = defaulted ON
     */
 CameraMetadata staticInfo = mDevice->info();
    entry = staticInfo.find(ANDROID_LED_AVAILABLE_LEDS);
 for(size_t i = 0; i < entry.count; ++i) {
 uint8_t led = entry.data.u8[i];

 switch(led) {
 case ANDROID_LED_AVAILABLE_LEDS_TRANSMIT: {
 uint8_t transmitDefault = ANDROID_LED_TRANSMIT_ON;
 if (!metadata.exists(ANDROID_LED_TRANSMIT)) {
                    metadata.update(ANDROID_LED_TRANSMIT,
 &transmitDefault, 1);
 }
 break;
 }
 }
 }

 if (pid == selfPid) {
 return true;
 }

 /**
     * Permission check special fields in the request
     * - android.led.transmit = android.permission.CAMERA_DISABLE_TRANSMIT
     */
    entry = metadata.find(ANDROID_LED_TRANSMIT);
 if (entry.count > 0 && entry.data.u8[0] != ANDROID_LED_TRANSMIT_ON) {
 String16 permissionString =
 String16("android.permission.CAMERA_DISABLE_TRANSMIT_LED");
 if (!checkCallingPermission(permissionString)) {
 const int uid = IPCThreadState::self()->getCallingUid();
            ALOGE("Permission Denial: "
 "can't disable transmit LED pid=%d, uid=%d", pid, uid);
 return false;
 }
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void session_set_fx_enabled(struct session_s *session, uint32_t id, bool enabled)
{
 if (enabled) {
 if(session->enabled_msk == 0) {
 /* do first enable here */
 }
        session->enabled_msk |= (1 << id);
 } else {
        session->enabled_msk &= ~(1 << id);
 if(session->enabled_msk == 0) {
 /* do last enable here */
 }
 }
    ALOGV("session_set_fx_enabled() id %d, enabled %d enabled_msk %08x",
         id, enabled, session->enabled_msk);
    session->processed_msk = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: parse_color(char *arg, unsigned int *colors)
{
 unsigned int ncolors = 0;

 while (*arg && ncolors < 4)
 {
 char *ep = arg;

 unsigned long ul = strtoul(arg, &ep, 0);

 if (ul > 65535)
 {
         fprintf(stderr, "makepng --color=...'%s': too big\n", arg);
         exit(1);
 }

 if (ep == arg)
 {
         fprintf(stderr, "makepng --color=...'%s': not a valid color\n", arg);
         exit(1);
 }

 if (*ep) ++ep; /* skip a separator */
      arg = ep;

      colors[++ncolors] = (unsigned int)ul; /* checked above */
 }

 if (*arg)
 {
      fprintf(stderr, "makepng --color=...'%s': too many values\n", arg);
      exit(1);
 }

 *colors = ncolors;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ESDS::getObjectTypeIndication(uint8_t *objectTypeIndication) const {
 if (mInitCheck != OK) {
 return mInitCheck;
 }

 *objectTypeIndication = mObjectTypeIndication;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void startup_timer_expired(UNUSED_ATTR void *context) {
  LOG_ERROR("%s", __func__);
  future_ready(startup_future, FUTURE_FAIL);
  startup_future = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SampleTable::CompositionDeltaLookup::CompositionDeltaLookup()
 : mDeltaEntries(NULL),
      mNumDeltaEntries(0),
      mCurrentDeltaEntry(0),
      mCurrentEntrySampleIndex(0) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundChannel::setVolume(float leftVolume, float rightVolume)
{
 Mutex::Autolock lock(&mLock);
    setVolume_l(leftVolume, rightVolume);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::set_config(OMX_IN OMX_HANDLETYPE      hComp,
        OMX_IN OMX_INDEXTYPE configIndex,
        OMX_IN OMX_PTR        configData)
{
 (void) hComp;
 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("Get Config in Invalid State");
 return OMX_ErrorInvalidState;
 }

    OMX_ERRORTYPE ret = OMX_ErrorNone;
    OMX_VIDEO_CONFIG_NALSIZE *pNal;

    DEBUG_PRINT_LOW("Set Config Called");

 if (configIndex == (OMX_INDEXTYPE)OMX_IndexVendorVideoExtraData) {
        OMX_VENDOR_EXTRADATATYPE *config = (OMX_VENDOR_EXTRADATATYPE *) configData;
        DEBUG_PRINT_LOW("Index OMX_IndexVendorVideoExtraData called");
 if (!strcmp(drv_ctx.kind, "OMX.qcom.video.decoder.avc") ||
 !strcmp(drv_ctx.kind, "OMX.qcom.video.decoder.mvc")) {
            DEBUG_PRINT_LOW("Index OMX_IndexVendorVideoExtraData AVC");
            OMX_U32 extra_size;

            nal_length = (config->pData[4] & 0x03) + 1;

            extra_size = 0;
 if (nal_length > 2) {
 /* Presently we assume that only one SPS and one PPS in AvC1 Atom */
                extra_size = (nal_length - 2) * 2;
 }

            OMX_U8 *pSrcBuf = (OMX_U8 *) (&config->pData[6]);
            OMX_U8 *pDestBuf;
            m_vendor_config.nPortIndex = config->nPortIndex;

            m_vendor_config.nDataSize = config->nDataSize - 6 - 1 + extra_size;
            m_vendor_config.pData = (OMX_U8 *) malloc(m_vendor_config.nDataSize);
            OMX_U32 len;
            OMX_U8 index = 0;
            pDestBuf = m_vendor_config.pData;

            DEBUG_PRINT_LOW("Rxd SPS+PPS nPortIndex[%u] len[%u] data[%p]",
 (unsigned int)m_vendor_config.nPortIndex,
 (unsigned int)m_vendor_config.nDataSize,
                    m_vendor_config.pData);
 while (index < 2) {
 uint8 *psize;
                len = *pSrcBuf;
                len = len << 8;
                len |= *(pSrcBuf + 1);
                psize = (uint8 *) & len;
                memcpy(pDestBuf + nal_length, pSrcBuf + 2,len);
 for (unsigned int i = 0; i < nal_length; i++) {
                    pDestBuf[i] = psize[nal_length - 1 - i];
 }
                pDestBuf += len + nal_length;
                pSrcBuf += len + 2;
                index++;
                pSrcBuf++; // skip picture param set
                len = 0;
 }
 } else if (!strcmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg4") ||
 !strcmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg2")) {
            m_vendor_config.nPortIndex = config->nPortIndex;
            m_vendor_config.nDataSize = config->nDataSize;
            m_vendor_config.pData = (OMX_U8 *) malloc((config->nDataSize));
            memcpy(m_vendor_config.pData, config->pData,config->nDataSize);
 } else if (!strcmp(drv_ctx.kind, "OMX.qcom.video.decoder.vc1")) {
 if (m_vendor_config.pData) {
                free(m_vendor_config.pData);
                m_vendor_config.pData = NULL;
                m_vendor_config.nDataSize = 0;
 }

 if (((*((OMX_U32 *) config->pData)) &
                        VC1_SP_MP_START_CODE_MASK) ==
                    VC1_SP_MP_START_CODE) {
                DEBUG_PRINT_LOW("set_config - VC1 simple/main profile");
                m_vendor_config.nPortIndex = config->nPortIndex;
                m_vendor_config.nDataSize = config->nDataSize;
                m_vendor_config.pData =
 (OMX_U8 *) malloc(config->nDataSize);
                memcpy(m_vendor_config.pData, config->pData,
                        config->nDataSize);
                m_vc1_profile = VC1_SP_MP_RCV;
 } else if (*((OMX_U32 *) config->pData) == VC1_AP_SEQ_START_CODE) {
                DEBUG_PRINT_LOW("set_config - VC1 Advance profile");
                m_vendor_config.nPortIndex = config->nPortIndex;
                m_vendor_config.nDataSize = config->nDataSize;
                m_vendor_config.pData =
 (OMX_U8 *) malloc((config->nDataSize));
                memcpy(m_vendor_config.pData, config->pData,
                        config->nDataSize);
                m_vc1_profile = VC1_AP;
 } else if ((config->nDataSize == VC1_STRUCT_C_LEN)) {
                DEBUG_PRINT_LOW("set_config - VC1 Simple/Main profile struct C only");
                m_vendor_config.nPortIndex = config->nPortIndex;
                m_vendor_config.nDataSize  = config->nDataSize;
                m_vendor_config.pData = (OMX_U8*)malloc(config->nDataSize);
                memcpy(m_vendor_config.pData,config->pData,config->nDataSize);
                m_vc1_profile = VC1_SP_MP_RCV;
 } else {
                DEBUG_PRINT_LOW("set_config - Error: Unknown VC1 profile");
 }
 }
 return ret;
 } else if (configIndex == OMX_IndexConfigVideoNalSize) {

         struct v4l2_control temp;
         temp.id = V4L2_CID_MPEG_VIDC_VIDEO_STREAM_FORMAT;
 
         pNal = reinterpret_cast < OMX_VIDEO_CONFIG_NALSIZE * >(configData);
         switch (pNal->nNaluBytes) {
             case 0:
                temp.value = V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_STARTCODES;
 break;
 case 2:
                temp.value = V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_TWO_BYTE_LENGTH;
 break;
 case 4:
                temp.value = V4L2_MPEG_VIDC_VIDEO_NAL_FORMAT_FOUR_BYTE_LENGTH;
 break;
 default:
 return OMX_ErrorUnsupportedSetting;
 }

 if (!arbitrary_bytes) {
 /* In arbitrary bytes mode, the assembler strips out nal size and replaces
             * with start code, so only need to notify driver in frame by frame mode */
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &temp)) {
                DEBUG_PRINT_ERROR("Failed to set V4L2_CID_MPEG_VIDC_VIDEO_STREAM_FORMAT");
 return OMX_ErrorHardware;
 }
 }

        nal_length = pNal->nNaluBytes;
        m_frame_parser.init_nal_length(nal_length);

        DEBUG_PRINT_LOW("OMX_IndexConfigVideoNalSize called with Size %d", nal_length);
 return ret;
 } else if ((int)configIndex == (int)OMX_IndexVendorVideoFrameRate) {
        OMX_VENDOR_VIDEOFRAMERATE *config = (OMX_VENDOR_VIDEOFRAMERATE *) configData;
        DEBUG_PRINT_HIGH("Index OMX_IndexVendorVideoFrameRate %u", (unsigned int)config->nFps);

 if (config->nPortIndex == OMX_CORE_INPUT_PORT_INDEX) {
 if (config->bEnabled) {
 if ((config->nFps >> 16) > 0) {
                    DEBUG_PRINT_HIGH("set_config: frame rate set by omx client : %u",
 (unsigned int)config->nFps >> 16);
                    Q16ToFraction(config->nFps, drv_ctx.frame_rate.fps_numerator,
                            drv_ctx.frame_rate.fps_denominator);

 if (!drv_ctx.frame_rate.fps_numerator) {
                        DEBUG_PRINT_ERROR("Numerator is zero setting to 30");
                        drv_ctx.frame_rate.fps_numerator = 30;
 }

 if (drv_ctx.frame_rate.fps_denominator) {
                        drv_ctx.frame_rate.fps_numerator = (int)
                            drv_ctx.frame_rate.fps_numerator / drv_ctx.frame_rate.fps_denominator;
 }

                    drv_ctx.frame_rate.fps_denominator = 1;
                    frm_int = drv_ctx.frame_rate.fps_denominator * 1e6 /
                        drv_ctx.frame_rate.fps_numerator;

 struct v4l2_outputparm oparm;
 /*XXX: we're providing timing info as seconds per frame rather than frames
                     * per second.*/
                    oparm.timeperframe.numerator = drv_ctx.frame_rate.fps_denominator;
                    oparm.timeperframe.denominator = drv_ctx.frame_rate.fps_numerator;

 struct v4l2_streamparm sparm;
                    sparm.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
                    sparm.parm.output = oparm;
 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_PARM, &sparm)) {
                        DEBUG_PRINT_ERROR("Unable to convey fps info to driver, \
                                performance might be affected");
                        ret = OMX_ErrorHardware;
 }
                    client_set_fps = true;
 } else {
                    DEBUG_PRINT_ERROR("Frame rate not supported.");
                    ret = OMX_ErrorUnsupportedSetting;
 }
 } else {
                DEBUG_PRINT_HIGH("set_config: Disabled client's frame rate");
                client_set_fps = false;
 }
 } else {
            DEBUG_PRINT_ERROR(" Set_config: Bad Port idx %d",
 (int)config->nPortIndex);
            ret = OMX_ErrorBadPortIndex;
 }

 return ret;
 } else if ((int)configIndex == (int)OMX_QcomIndexConfigPerfLevel) {
        OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *perf =
 (OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *)configData;
 struct v4l2_control control;

        DEBUG_PRINT_LOW("Set perf level: %d", perf->ePerfLevel);

        control.id = V4L2_CID_MPEG_VIDC_SET_PERF_LEVEL;

 switch (perf->ePerfLevel) {
 case OMX_QCOM_PerfLevelNominal:
                control.value = V4L2_CID_MPEG_VIDC_PERF_LEVEL_NOMINAL;
 break;
 case OMX_QCOM_PerfLevelTurbo:
                control.value = V4L2_CID_MPEG_VIDC_PERF_LEVEL_TURBO;
 break;
 default:
                ret = OMX_ErrorUnsupportedSetting;
 break;
 }

 if (ret == OMX_ErrorNone) {
            ret = (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control) < 0) ?
                OMX_ErrorUnsupportedSetting : OMX_ErrorNone;
 }

 return ret;
 } else if ((int)configIndex == (int)OMX_IndexConfigPriority) {
        OMX_PARAM_U32TYPE *priority = (OMX_PARAM_U32TYPE *)configData;
        DEBUG_PRINT_LOW("Set_config: priority %d", priority->nU32);

 struct v4l2_control control;

        control.id = V4L2_CID_MPEG_VIDC_VIDEO_PRIORITY;
 if (priority->nU32 == 0)
            control.value = V4L2_MPEG_VIDC_VIDEO_PRIORITY_REALTIME_ENABLE;
 else
            control.value = V4L2_MPEG_VIDC_VIDEO_PRIORITY_REALTIME_DISABLE;

 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control)) {
            DEBUG_PRINT_ERROR("Failed to set Priority");
            ret = OMX_ErrorUnsupportedSetting;
 }
 return ret;
 } else if ((int)configIndex == (int)OMX_IndexConfigOperatingRate) {
        OMX_PARAM_U32TYPE *rate = (OMX_PARAM_U32TYPE *)configData;
        DEBUG_PRINT_LOW("Set_config: operating-rate %u fps", rate->nU32 >> 16);

 struct v4l2_control control;

        control.id = V4L2_CID_MPEG_VIDC_VIDEO_OPERATING_RATE;
        control.value = rate->nU32;

 if (ioctl(drv_ctx.video_driver_fd, VIDIOC_S_CTRL, &control)) {
            ret = errno == -EBUSY ? OMX_ErrorInsufficientResources :
                    OMX_ErrorUnsupportedSetting;
            DEBUG_PRINT_ERROR("Failed to set operating rate %u fps (%s)",
                    rate->nU32 >> 16, errno == -EBUSY ? "HW Overload" : strerror(errno));
 }
 return ret;
 }

 return OMX_ErrorNotImplemented;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: make_transform_image(png_store* PNG_CONST ps, png_byte PNG_CONST colour_type,
    png_byte PNG_CONST bit_depth, unsigned int palette_number,
     int interlace_type, png_const_charp name)
 {
    context(ps, fault);

   check_interlace_type(interlace_type);

 Try

    {
       png_infop pi;
       png_structp pp = set_store_for_write(ps, &pi, name);
      png_uint_32 h;
 
       /* In the event of a problem return control to the Catch statement below
        * to do the clean up - it is not possible to 'return' directly from a Try
       * block.
       */

       if (pp == NULL)
          Throw ps;
 
       h = transform_height(pp, colour_type, bit_depth);
 
      png_set_IHDR(pp, pi, transform_width(pp, colour_type, bit_depth), h,
         bit_depth, colour_type, interlace_type,
          PNG_COMPRESSION_TYPE_BASE, PNG_FILTER_TYPE_BASE);
 
 #ifdef PNG_TEXT_SUPPORTED
#  if defined(PNG_READ_zTXt_SUPPORTED) && defined(PNG_WRITE_zTXt_SUPPORTED)
#     define TEXT_COMPRESSION PNG_TEXT_COMPRESSION_zTXt
#  else
#     define TEXT_COMPRESSION PNG_TEXT_COMPRESSION_NONE
#  endif
 {
 static char key[] = "image name"; /* must be writeable */
 size_t pos;
         png_text text;
 char copy[FILE_NAME_SIZE];

 /* Use a compressed text string to test the correct interaction of text
          * compression and IDAT compression.
          */
         text.compression = TEXT_COMPRESSION;
         text.key = key;
 /* Yuck: the text must be writable! */
         pos = safecat(copy, sizeof copy, 0, ps->wname);
         text.text = copy;
         text.text_length = pos;
         text.itxt_length = 0;
         text.lang = 0;
         text.lang_key = 0;

         png_set_text(pp, pi, &text, 1);
 }
#endif


       if (colour_type == 3) /* palette */
          init_standard_palette(ps, pp, pi, 1U << bit_depth, 1/*do tRNS*/);
 
       png_write_info(pp, pi);
 
       if (png_get_rowbytes(pp, pi) !=
           transform_rowsize(pp, colour_type, bit_depth))
         png_error(pp, "row size incorrect");
 
       else
       {
 /* Somewhat confusingly this must be called *after* png_write_info

           * because if it is called before, the information in *pp has not been
           * updated to reflect the interlaced image.
           */
         int npasses = png_set_interlace_handling(pp);
          int pass;
 
          if (npasses != npasses_from_interlace_type(pp, interlace_type))
            png_error(pp, "write: png_set_interlace_handling failed");

 for (pass=0; pass<npasses; ++pass)

          {
             png_uint_32 y;
 
             for (y=0; y<h; ++y)
             {
                png_byte buffer[TRANSFORM_ROWMAX];
 
                transform_row(pp, buffer, colour_type, bit_depth, y);
                png_write_row(pp, buffer);
             }
          }
 }

#ifdef PNG_TEXT_SUPPORTED
 {
 static char key[] = "end marker";
 static char comment[] = "end";
         png_text text;

 /* Use a compressed text string to test the correct interaction of text
          * compression and IDAT compression.
          */
         text.compression = TEXT_COMPRESSION;
         text.key = key;
         text.text = comment;
         text.text_length = (sizeof comment)-1;
         text.itxt_length = 0;
         text.lang = 0;
         text.lang_key = 0;

         png_set_text(pp, pi, &text, 1);
 }
#endif

      png_write_end(pp, pi);

 /* And store this under the appropriate id, then clean up. */
      store_storefile(ps, FILEID(colour_type, bit_depth, palette_number,
         interlace_type, 0, 0, 0));

      store_write_reset(ps);
 }

 Catch(fault)
 {
 /* Use the png_store returned by the exception. This may help the compiler
       * because 'ps' is not used in this branch of the setjmp.  Note that fault
       * and ps will always be the same value.
       */
      store_write_reset(fault);
 }

 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: omx_venc::omx_venc()
{
#ifdef _ANDROID_ICS_
    meta_mode_enable = false;
    memset(meta_buffer_hdr,0,sizeof(meta_buffer_hdr));
    memset(meta_buffers,0,sizeof(meta_buffers));
    memset(opaque_buffer_hdr,0,sizeof(opaque_buffer_hdr));
    mUseProxyColorFormat = false;
    get_syntaxhdr_enable = false;
#endif
    bframes = entropy = 0;
 char property_value[PROPERTY_VALUE_MAX] = {0};
    property_get("vidc.debug.level", property_value, "1");
    debug_level = atoi(property_value);
    property_value[0] = '\0';
    property_get("vidc.debug.bframes", property_value, "0");
    bframes = atoi(property_value);
    property_value[0] = '\0';
    property_get("vidc.debug.entropy", property_value, "1");
    entropy = !!atoi(property_value);
    property_value[0] = '\0';
    property_get("vidc.debug.perf.mode", property_value, "0");
    perfmode = atoi(property_value);
    property_value[0] = '\0';
    property_get("vidc.debug.hybrid.hierp", property_value, "0");
    hybrid_hp = atoi(property_value);
    property_value[0] = '\0';
    handle = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_vdec::execute_input_flush()
{
 unsigned       i =0;
 unsigned long p1 = 0; // Parameter - 1
 unsigned long p2 = 0; // Parameter - 2
 unsigned long ident = 0;
 bool bRet = true;

 /*Generate EBD for all Buffers in the ETBq*/
    DEBUG_PRINT_LOW("Initiate Input Flush");

    pthread_mutex_lock(&m_lock);
    DEBUG_PRINT_LOW("Check if the Queue is empty");
 while (m_etb_q.m_size) {
        m_etb_q.pop_entry(&p1,&p2,&ident);

 if (ident == OMX_COMPONENT_GENERATE_ETB_ARBITRARY) {
            DEBUG_PRINT_LOW("Flush Input Heap Buffer %p",(OMX_BUFFERHEADERTYPE *)p2);
            m_cb.EmptyBufferDone(&m_cmp ,m_app_data, (OMX_BUFFERHEADERTYPE *)p2);
 } else if (ident == OMX_COMPONENT_GENERATE_ETB) {
            pending_input_buffers++;
            DEBUG_PRINT_LOW("Flush Input OMX_COMPONENT_GENERATE_ETB %p, pending_input_buffers %d",
 (OMX_BUFFERHEADERTYPE *)p2, pending_input_buffers);
            empty_buffer_done(&m_cmp,(OMX_BUFFERHEADERTYPE *)p2);
 } else if (ident == OMX_COMPONENT_GENERATE_EBD) {
            DEBUG_PRINT_LOW("Flush Input OMX_COMPONENT_GENERATE_EBD %p",
 (OMX_BUFFERHEADERTYPE *)p1);
            empty_buffer_done(&m_cmp,(OMX_BUFFERHEADERTYPE *)p1);
 }
 }
    time_stamp_dts.flush_timestamp();
 /*Check if Heap Buffers are to be flushed*/
 if (arbitrary_bytes && !(codec_config_flag)) {
        DEBUG_PRINT_LOW("Reset all the variables before flusing");
        h264_scratch.nFilledLen = 0;
        nal_count = 0;
        look_ahead_nal = false;
        frame_count = 0;
        h264_last_au_ts = LLONG_MAX;
        h264_last_au_flags = 0;
        memset(m_demux_offsets, 0, ( sizeof(OMX_U32) * 8192) );
        m_demux_entries = 0;
        DEBUG_PRINT_LOW("Initialize parser");
 if (m_frame_parser.mutils) {
            m_frame_parser.mutils->initialize_frame_checking_environment();
 }

 while (m_input_pending_q.m_size) {
            m_input_pending_q.pop_entry(&p1,&p2,&ident);
            m_cb.EmptyBufferDone(&m_cmp ,m_app_data, (OMX_BUFFERHEADERTYPE *)p1);
 }

 if (psource_frame) {
            m_cb.EmptyBufferDone(&m_cmp ,m_app_data,psource_frame);
            psource_frame = NULL;
 }

 if (pdest_frame) {
            pdest_frame->nFilledLen = 0;
            m_input_free_q.insert_entry((unsigned long) pdest_frame, (unsigned int)NULL,
 (unsigned int)NULL);
            pdest_frame = NULL;
 }
        m_frame_parser.flush();
 } else if (codec_config_flag) {
        DEBUG_PRINT_HIGH("frame_parser flushing skipped due to codec config buffer "
 "is not sent to the driver yet");
 }
    pthread_mutex_unlock(&m_lock);
    input_flush_progress = false;
 if (!arbitrary_bytes) {
        prev_ts = LLONG_MAX;
        rst_prev_ts = true;
 }
#ifdef _ANDROID_
 if (m_debug_timestamp) {
        m_timestamp_list.reset_ts_list();
 }
#endif
    DEBUG_PRINT_HIGH("OMX flush i/p Port complete PenBuf(%d)", pending_input_buffers);
 return bRet;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  safecat_current_encoding(char *buffer, size_t bufsize, size_t pos,
   PNG_CONST png_modifier *pm)
 {
    pos = safecat_color_encoding(buffer, bufsize, pos, pm->current_encoding,
       pm->current_gamma);

 if (pm->encoding_ignored)
      pos = safecat(buffer, bufsize, pos, "[overridden]");

 
    return pos;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: netdutils::Status XfrmController::ipSecSetEncapSocketOwner(const android::base::unique_fd& socket,
 int newUid, uid_t callerUid) {
    ALOGD("XfrmController:%s, line=%d", __FUNCTION__, __LINE__);

 const int fd = socket.get();
 struct stat info;
 if (fstat(fd, &info)) {
 return netdutils::statusFromErrno(errno, "Failed to stat socket file descriptor");
 }
 if (info.st_uid != callerUid) {
 return netdutils::statusFromErrno(EPERM, "fchown disabled for non-owner calls");
 }
 if (S_ISSOCK(info.st_mode) == 0) {
 return netdutils::statusFromErrno(EINVAL, "File descriptor was not a socket");

     }
 
     int optval;
    socklen_t optlen;
     netdutils::Status status =
         getSyscallInstance().getsockopt(Fd(socket), IPPROTO_UDP, UDP_ENCAP, &optval, &optlen);
     if (status != netdutils::status::ok) {
 return status;
 }
 if (optval != UDP_ENCAP_ESPINUDP && optval != UDP_ENCAP_ESPINUDP_NON_IKE) {
 return netdutils::statusFromErrno(EINVAL, "Socket did not have UDP-encap sockopt set");
 }
 if (fchown(fd, newUid, -1)) {
 return netdutils::statusFromErrno(errno, "Failed to fchown socket file descriptor");
 }

 return netdutils::status::ok;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sRGB(double linear /*range 0.0 .. 1.0*/)
{
 return u8d(255 * sRGB_from_linear(linear));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: StatusOr<uint16_t> convertStringAddress(std::string addr, uint8_t* buffer) {
 if (inet_pton(AF_INET, addr.c_str(), buffer) == 1) {
 return AF_INET;
 } else if (inet_pton(AF_INET6, addr.c_str(), buffer) == 1) {
 return AF_INET6;
 } else {
 return Status(EAFNOSUPPORT);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_image_t *decoder_get_frame(vpx_codec_alg_priv_t *ctx,
 vpx_codec_iter_t *iter) {
 vpx_image_t *img = NULL;

 if (ctx->frame_parallel_decode && ctx->available_threads > 0 &&
 !ctx->flushed) {
 return NULL;
 }

 if (ctx->num_cache_frames > 0) {
    release_last_output_frame(ctx);
    ctx->last_show_frame  = ctx->frame_cache[ctx->frame_cache_read].fb_idx;
 if (ctx->need_resync)
 return NULL;
    img = &ctx->frame_cache[ctx->frame_cache_read].img;
    ctx->frame_cache_read = (ctx->frame_cache_read + 1) % FRAME_CACHE_SIZE;
 --ctx->num_cache_frames;
 return img;
 }

 if (*iter == NULL && ctx->frame_workers != NULL) {
 do {
      YV12_BUFFER_CONFIG sd;
 vp9_ppflags_t flags = {0, 0, 0};
 const VPxWorkerInterface *const winterface = vpx_get_worker_interface();
 VPxWorker *const worker =
 &ctx->frame_workers[ctx->next_output_worker_id];
 FrameWorkerData *const frame_worker_data =
 (FrameWorkerData *)worker->data1;
      ctx->next_output_worker_id =
 (ctx->next_output_worker_id + 1) % ctx->num_frame_workers;
 if (ctx->base.init_flags & VPX_CODEC_USE_POSTPROC)
        set_ppflags(ctx, &flags);
 if (winterface->sync(worker)) {
 if (frame_worker_data->received_frame == 1) {
 ++ctx->available_threads;
          frame_worker_data->received_frame = 0;
          check_resync(ctx, frame_worker_data->pbi);
 }
 if (vp9_get_raw_frame(frame_worker_data->pbi, &sd, &flags) == 0) {
          VP9_COMMON *const cm = &frame_worker_data->pbi->common;
 RefCntBuffer *const frame_bufs = cm->buffer_pool->frame_bufs;
          release_last_output_frame(ctx);
          ctx->last_show_frame = frame_worker_data->pbi->common.new_fb_idx;
 if (ctx->need_resync)
 return NULL;
          yuvconfig2image(&ctx->img, &sd, frame_worker_data->user_priv);
          ctx->img.fb_priv = frame_bufs[cm->new_fb_idx].raw_frame_buffer.priv;
          img = &ctx->img;
 return img;
 }
 } else {
        frame_worker_data->received_frame = 0;
 ++ctx->available_threads;
        ctx->need_resync = 1;
 if (ctx->flushed != 1)
 return NULL;
 }
 } while (ctx->next_output_worker_id != ctx->next_submit_worker_id);
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: cmppixel(Transform *transform, png_const_voidp in, png_const_voidp out,
   png_uint_32 x, png_uint_32 y/*or palette index*/)
{
 int maxerr;
   png_const_charp errmsg;
 Pixel pixel_in, pixel_calc, pixel_out;

   transform->in_gp(&pixel_in, in);

 if (transform->from_linear == NULL)
      transform->transform(&pixel_calc, &pixel_in, transform->background);

 else
 {
      transform->transform(&pixel_out, &pixel_in, transform->background);
      transform->from_linear(&pixel_calc, &pixel_out, NULL);
 }

   transform->out_gp(&pixel_out, out);

 /* Eliminate the case where the input and output values match exactly. */
 if (pixel_calc.a == pixel_out.a && pixel_calc.r == pixel_out.r &&
      pixel_calc.g == pixel_out.g && pixel_calc.b == pixel_out.b)
 return 1;

 /* Eliminate the case where the output pixel is transparent and the output
    * is 8-bit - any component values are valid.  Don't check the input alpha
    * here to also skip the 16-bit small alpha cases.
    */
 if (transform->output_8bit && pixel_calc.a == 0 && pixel_out.a == 0)
 return 1;

 /* Check for alpha errors first; an alpha error can damage the components too
    * so avoid spurious checks on components if one is found.
    */
   errmsg = NULL;
 {
 int err_a = abs(pixel_calc.a-pixel_out.a);

 if (err_a > transform->error[3])
 {
 /* If accumulating check the components too */
 if (transform->accumulate)
            transform->error[3] = (png_uint_16)err_a;

 else
            errmsg = "alpha";
 }
 }

 /* Now if *either* of the output alphas are 0 but alpha is within tolerance
    * eliminate the 8-bit component comparison.
    */
 if (errmsg == NULL && transform->output_8bit &&
 (pixel_calc.a == 0 || pixel_out.a == 0))
 return 1;

 if (errmsg == NULL) /* else just signal an alpha error */
 {
 int err_r = abs(pixel_calc.r - pixel_out.r);
 int err_g = abs(pixel_calc.g - pixel_out.g);
 int err_b = abs(pixel_calc.b - pixel_out.b);
 int limit;

 if ((err_r | err_g | err_b) == 0)
 return 1; /* exact match */

 /* Mismatch on a component, check the input alpha */
 if (pixel_in.a >= transform->in_opaque)
 {
         errmsg = "opaque component";
         limit = 2; /* opaque */
 }

 else if (pixel_in.a > 0)
 {
         errmsg = "alpha component";
         limit = 1; /* partially transparent */
 }

 else
 {
         errmsg = "transparent component (background)";
         limit = 0; /* transparent */
 }

      maxerr = err_r;
 if (maxerr < err_g) maxerr = err_g;
 if (maxerr < err_b) maxerr = err_b;

 if (maxerr <= transform->error[limit])
 return 1; /* within the error limits */

 /* Handle a component mis-match; log it, just return an error code, or
       * accumulate it.
       */
 if (transform->accumulate)
 {
         transform->error[limit] = (png_uint_16)maxerr;
 return 1; /* to cause the caller to keep going */
 }
 }

 /* Failure to match and not accumulating, so the error must be logged. */
 return logpixel(transform, x, y, &pixel_in, &pixel_calc, &pixel_out, errmsg);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: Parcel::~Parcel()
{
    freeDataNoInit();
    LOG_ALLOC("Parcel %p: destroyed", this);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void android_net_wifi_hal_cleaned_up_handler(wifi_handle handle) {
    ALOGD("In wifi cleaned up handler");

 JNIHelper helper(mVM);
    helper.setStaticLongField(mCls, WifiHandleVarName, 0);

    helper.deleteGlobalRef(mCls);
    mCls = NULL;
    mVM  = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char* adev_get_parameters(const struct audio_hw_device *dev,
 const char *keys)
{
 (void)dev;
 (void)keys;

 return strdup("");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlRecoverDoc(const xmlChar *cur) {
 return(xmlSAXParseDoc(NULL, cur, 1));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static WORD32 ihevcd_parse_hrd_parameters(bitstrm_t *ps_bitstrm,
 hrd_params_t *ps_hrd,
                                          WORD32 common_info_present_flag,
                                          WORD32 max_num_sub_layers_minus1)
{
    WORD32 ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    WORD32 i;

    ps_hrd->u1_nal_hrd_parameters_present_flag = 0;
    ps_hrd->u1_vcl_hrd_parameters_present_flag = 0;

    ps_hrd->u1_sub_pic_cpb_params_present_flag = 0;

    ps_hrd->u1_tick_divisor_minus2 = 0;
    ps_hrd->u1_du_cpb_removal_delay_increment_length_minus1 = 0;
    ps_hrd->u1_sub_pic_cpb_params_in_pic_timing_sei_flag = 0;
    ps_hrd->u1_dpb_output_delay_du_length_minus1 = 0;

    ps_hrd->u4_bit_rate_scale = 0;
    ps_hrd->u4_cpb_size_scale = 0;
    ps_hrd->u4_cpb_size_du_scale = 0;

    ps_hrd->u1_initial_cpb_removal_delay_length_minus1 = 23;
    ps_hrd->u1_au_cpb_removal_delay_length_minus1 = 23;
    ps_hrd->u1_dpb_output_delay_length_minus1 = 23;

 if(common_info_present_flag)
 {
        BITS_PARSE("nal_hrd_parameters_present_flag", ps_hrd->u1_nal_hrd_parameters_present_flag, ps_bitstrm, 1);
        BITS_PARSE("vcl_hrd_parameters_present_flag", ps_hrd->u1_vcl_hrd_parameters_present_flag, ps_bitstrm, 1);

 if(ps_hrd->u1_nal_hrd_parameters_present_flag  ||  ps_hrd->u1_vcl_hrd_parameters_present_flag)
 {
            BITS_PARSE("sub_pic_cpb_params_present_flag", ps_hrd->u1_sub_pic_cpb_params_present_flag, ps_bitstrm, 1);
 if(ps_hrd->u1_sub_pic_cpb_params_present_flag)
 {
                BITS_PARSE("tick_divisor_minus2", ps_hrd->u1_tick_divisor_minus2, ps_bitstrm, 8);
                BITS_PARSE("du_cpb_removal_delay_increment_length_minus1", ps_hrd->u1_du_cpb_removal_delay_increment_length_minus1, ps_bitstrm, 5);
                BITS_PARSE("sub_pic_cpb_params_in_pic_timing_sei_flag", ps_hrd->u1_sub_pic_cpb_params_in_pic_timing_sei_flag, ps_bitstrm, 1);
                BITS_PARSE("dpb_output_delay_du_length_minus1", ps_hrd->u1_dpb_output_delay_du_length_minus1, ps_bitstrm, 5);
 }

            BITS_PARSE("bit_rate_scale", ps_hrd->u4_bit_rate_scale, ps_bitstrm, 4);
            BITS_PARSE("cpb_size_scale", ps_hrd->u4_cpb_size_scale, ps_bitstrm, 4);
 if(ps_hrd->u1_sub_pic_cpb_params_present_flag)
                BITS_PARSE("cpb_size_du_scale", ps_hrd->u4_cpb_size_du_scale, ps_bitstrm, 4);

            BITS_PARSE("initial_cpb_removal_delay_length_minus1", ps_hrd->u1_initial_cpb_removal_delay_length_minus1, ps_bitstrm, 5);
            BITS_PARSE("au_cpb_removal_delay_length_minus1", ps_hrd->u1_au_cpb_removal_delay_length_minus1, ps_bitstrm, 5);
            BITS_PARSE("dpb_output_delay_length_minus1", ps_hrd->u1_dpb_output_delay_length_minus1, ps_bitstrm, 5);
 }
 }


 for(i = 0; i <= max_num_sub_layers_minus1; i++)
 {
        BITS_PARSE("fixed_pic_rate_general_flag[ i ]", ps_hrd->au1_fixed_pic_rate_general_flag[i], ps_bitstrm, 1);

        ps_hrd->au1_fixed_pic_rate_within_cvs_flag[i] = 1;
        ps_hrd->au1_elemental_duration_in_tc_minus1[i] = 0;
        ps_hrd->au1_low_delay_hrd_flag[i] = 0;
        ps_hrd->au1_cpb_cnt_minus1[i] = 0;

 if(!ps_hrd->au1_fixed_pic_rate_general_flag[i])
            BITS_PARSE("fixed_pic_rate_within_cvs_flag[ i ]", ps_hrd->au1_fixed_pic_rate_within_cvs_flag[i], ps_bitstrm, 1);

 if(ps_hrd->au1_fixed_pic_rate_within_cvs_flag[i])
 {
            UEV_PARSE("elemental_duration_in_tc_minus1[ i ]", ps_hrd->au1_elemental_duration_in_tc_minus1[i], ps_bitstrm);
 }
 else
 {
            BITS_PARSE("low_delay_hrd_flag[ i ]", ps_hrd->au1_low_delay_hrd_flag[i], ps_bitstrm, 1);
 }

 if(!ps_hrd->au1_low_delay_hrd_flag[i])
            UEV_PARSE("cpb_cnt_minus1[ i ]", ps_hrd->au1_cpb_cnt_minus1[i], ps_bitstrm);

 if(ps_hrd->u1_nal_hrd_parameters_present_flag)
            ihevcd_parse_sub_layer_hrd_parameters(ps_bitstrm,
 &ps_hrd->as_sub_layer_hrd_params[i],
                                                  ps_hrd->au1_cpb_cnt_minus1[i],
                                                  ps_hrd->u1_sub_pic_cpb_params_present_flag);

 if(ps_hrd->u1_vcl_hrd_parameters_present_flag)
            ihevcd_parse_sub_layer_hrd_parameters(ps_bitstrm,
 &ps_hrd->as_sub_layer_hrd_params[i],
                                                  ps_hrd->au1_cpb_cnt_minus1[i],
                                                  ps_hrd->u1_sub_pic_cpb_params_present_flag);
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: No.</s>


Instruction: 
Input: status_t writeByteVectorInternalPtr(Parcel* parcel,
 const std::unique_ptr<std::vector<T>>& val)
{
 if (!val) {
 return parcel->writeInt32(-1);
 }

 return writeByteVectorInternal(parcel, *val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool btif_config_get_bin(const char *section, const char *key, uint8_t *value, size_t *length) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);
  assert(value != NULL);
  assert(length != NULL);

  pthread_mutex_lock(&lock);
 const char *value_str = config_get_string(config, section, key, NULL);
  pthread_mutex_unlock(&lock);

 if (!value_str)
 return false;

 size_t value_len = strlen(value_str);
 if ((value_len % 2) != 0 || *length < (value_len / 2))
 return false;

 for (size_t i = 0; i < value_len; ++i)
 if (!isxdigit(value_str[i]))
 return false;

 for (*length = 0; *value_str; value_str += 2, *length += 1)
    sscanf(value_str, "%02hhx", &value[*length]);

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long VideoTrack::Seek(long long time_ns, const BlockEntry*& pResult) const {
 const long status = GetFirst(pResult);

 if (status < 0) // buffer underflow, etc
 return status;

  assert(pResult);

 if (pResult->EOS())
 return 0;

 const Cluster* pCluster = pResult->GetCluster();
  assert(pCluster);
  assert(pCluster->GetIndex() >= 0);

 if (time_ns <= pResult->GetBlock()->GetTime(pCluster))
 return 0;

 Cluster** const clusters = m_pSegment->m_clusters;
  assert(clusters);

 const long count = m_pSegment->GetCount(); // loaded only, not pre-loaded
  assert(count > 0);

 Cluster** const i = clusters + pCluster->GetIndex();
  assert(i);
  assert(*i == pCluster);
  assert(pCluster->GetTime() <= time_ns);

 Cluster** const j = clusters + count;

 Cluster** lo = i;
 Cluster** hi = j;

 while (lo < hi) {

 Cluster** const mid = lo + (hi - lo) / 2;
    assert(mid < hi);

    pCluster = *mid;
    assert(pCluster);
    assert(pCluster->GetIndex() >= 0);
    assert(pCluster->GetIndex() == long(mid - m_pSegment->m_clusters));

 const long long t = pCluster->GetTime();

 if (t <= time_ns)
      lo = mid + 1;
 else
      hi = mid;

    assert(lo <= hi);
 }

  assert(lo == hi);
  assert(lo > i);
  assert(lo <= j);

  pCluster = *--lo;
  assert(pCluster);
  assert(pCluster->GetTime() <= time_ns);

  pResult = pCluster->GetEntry(this, time_ns);

 if ((pResult != 0) && !pResult->EOS()) // found a keyframe
 return 0;

 while (lo != i) {
    pCluster = *--lo;
    assert(pCluster);
    assert(pCluster->GetTime() <= time_ns);

    pResult = pCluster->GetEntry(this, time_ns);

 if ((pResult != 0) && !pResult->EOS())
 return 0;
 }


  pResult = GetEOS();
 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void SetPicNums(dpbStorage_t *dpb, u32 currFrameNum)
{

/* Variables */

    u32 i;
    i32 frameNumWrap;

/* Code */

    ASSERT(dpb);
    ASSERT(currFrameNum < dpb->maxFrameNum);

 for (i = 0; i < dpb->numRefFrames; i++)
 if (IS_SHORT_TERM(dpb->buffer[i]))
 {
 if (dpb->buffer[i].frameNum > currFrameNum)
                frameNumWrap =
 (i32)dpb->buffer[i].frameNum - (i32)dpb->maxFrameNum;
 else
                frameNumWrap = (i32)dpb->buffer[i].frameNum;
            dpb->buffer[i].picNum = frameNumWrap;
 }

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Reverb_getParameter(ReverbContext *pContext,
 void *pParam,
 size_t *pValueSize,
 void *pValue){
 int status = 0;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;
 char *name;
    t_reverb_settings *pProperties;

 if (pContext->preset) {
 if (param != REVERB_PARAM_PRESET || *pValueSize < sizeof(uint16_t)) {
 return -EINVAL;
 }

 *(uint16_t *)pValue = pContext->nextPreset;
        ALOGV("get REVERB_PARAM_PRESET, preset %d", pContext->nextPreset);
 return 0;
 }

 switch (param){
 case REVERB_PARAM_ROOM_LEVEL:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize1 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_ROOM_HF_LEVEL:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize12 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_DECAY_TIME:
 if (*pValueSize != sizeof(uint32_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize3 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(uint32_t);
 break;
 case REVERB_PARAM_DECAY_HF_RATIO:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize4 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_REFLECTIONS_LEVEL:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize5 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_REFLECTIONS_DELAY:
 if (*pValueSize != sizeof(uint32_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize6 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(uint32_t);
 break;
 case REVERB_PARAM_REVERB_LEVEL:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize7 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_REVERB_DELAY:
 if (*pValueSize != sizeof(uint32_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize8 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(uint32_t);
 break;
 case REVERB_PARAM_DIFFUSION:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize9 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_DENSITY:
 if (*pValueSize != sizeof(int16_t)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize10 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(int16_t);
 break;
 case REVERB_PARAM_PROPERTIES:
 if (*pValueSize != sizeof(t_reverb_settings)){
                ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid pValueSize11 %d", *pValueSize);
 return -EINVAL;
 }
 *pValueSize = sizeof(t_reverb_settings);
 break;

 default:
            ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid param %d", param);
 return -EINVAL;
 }

    pProperties = (t_reverb_settings *) pValue;

 switch (param){
 case REVERB_PARAM_PROPERTIES:
            pProperties->roomLevel = ReverbGetRoomLevel(pContext);
            pProperties->roomHFLevel = ReverbGetRoomHfLevel(pContext);
            pProperties->decayTime = ReverbGetDecayTime(pContext);
            pProperties->decayHFRatio = ReverbGetDecayHfRatio(pContext);
            pProperties->reflectionsLevel = 0;
            pProperties->reflectionsDelay = 0;
            pProperties->reverbDelay = 0;
            pProperties->reverbLevel = ReverbGetReverbLevel(pContext);
            pProperties->diffusion = ReverbGetDiffusion(pContext);
            pProperties->density = ReverbGetDensity(pContext);

            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is roomLevel        %d",
                pProperties->roomLevel);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is roomHFLevel      %d",
                pProperties->roomHFLevel);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is decayTime        %d",
                pProperties->decayTime);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is decayHFRatio     %d",
                pProperties->decayHFRatio);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is reflectionsLevel %d",
                pProperties->reflectionsLevel);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is reflectionsDelay %d",
                pProperties->reflectionsDelay);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is reverbDelay      %d",
                pProperties->reverbDelay);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is reverbLevel      %d",
                pProperties->reverbLevel);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is diffusion        %d",
                pProperties->diffusion);
            ALOGV("\tReverb_getParameter() REVERB_PARAM_PROPERTIES Value is density          %d",
                pProperties->density);
 break;

 case REVERB_PARAM_ROOM_LEVEL:
 *(int16_t *)pValue = ReverbGetRoomLevel(pContext);

 break;
 case REVERB_PARAM_ROOM_HF_LEVEL:
 *(int16_t *)pValue = ReverbGetRoomHfLevel(pContext);

 break;
 case REVERB_PARAM_DECAY_TIME:
 *(uint32_t *)pValue = ReverbGetDecayTime(pContext);

 break;
 case REVERB_PARAM_DECAY_HF_RATIO:
 *(int16_t *)pValue = ReverbGetDecayHfRatio(pContext);

 break;
 case REVERB_PARAM_REVERB_LEVEL:
 *(int16_t *)pValue = ReverbGetReverbLevel(pContext);

 break;
 case REVERB_PARAM_DIFFUSION:
 *(int16_t *)pValue = ReverbGetDiffusion(pContext);

 break;
 case REVERB_PARAM_DENSITY:
 *(uint16_t *)pValue = 0;
 *(int16_t *)pValue = ReverbGetDensity(pContext);
 break;
 case REVERB_PARAM_REFLECTIONS_LEVEL:
 *(uint16_t *)pValue = 0;
 case REVERB_PARAM_REFLECTIONS_DELAY:
 *(uint32_t *)pValue = 0;
 case REVERB_PARAM_REVERB_DELAY:
 *(uint32_t *)pValue = 0;
 break;

 default:
            ALOGV("\tLVM_ERROR : Reverb_getParameter() invalid param %d", param);
            status = -EINVAL;
 break;
 }

 return status;
} /* end Reverb_getParameter */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static int parseExcludedChannels( UINT *excludedChnsMask,
                                  HANDLE_FDK_BITSTREAM bs )
{
  UINT excludeMask = 0;
  UINT i, j;
 int  bitCnt = 9;

 for (i = 0, j = 1; i < 7; i++, j<<=1) {
 if (FDKreadBits(bs,1)) {
      excludeMask |= j;
 }
 }

 /* additional_excluded_chns */
 while (FDKreadBits(bs,1)) {
 for (i = 0; i < 7; i++, j<<=1) {
 if (FDKreadBits(bs,1)) {
        excludeMask |= j;
 }
 }
    bitCnt += 9;
    FDK_ASSERT(j < (UINT)-1);
 }

 *excludedChnsMask = excludeMask;

 return (bitCnt);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {
#ifdef VERBOSE_DEBUG
    ALOGD("adding range %d-%d\n", start, end);
#endif
 if (coverage.empty() || coverage.back() < start) {
        coverage.push_back(start);
        coverage.push_back(end);
 } else {
        coverage.back() = end;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool OMXNodeInstance::handleMessage(omx_message &msg) {
 const sp<GraphicBufferSource>& bufferSource(getGraphicBufferSource());

 if (msg.type == omx_message::FILL_BUFFER_DONE) {
        OMX_BUFFERHEADERTYPE *buffer =
            findBufferHeader(msg.u.extended_buffer_data.buffer, kPortIndexOutput);
 if (buffer == NULL) {
            ALOGE("b/25884056");
 return false;
 }

 {
 Mutex::Autolock _l(mDebugLock);
            mOutputBuffersWithCodec.remove(buffer);

            CLOG_BUMPED_BUFFER(
                    FBD, WITH_STATS(FULL_BUFFER(
                            msg.u.extended_buffer_data.buffer, buffer, msg.fenceFd)));

            unbumpDebugLevel_l(kPortIndexOutput);
 }

 BufferMeta *buffer_meta =
 static_cast<BufferMeta *>(buffer->pAppPrivate);

 if (buffer->nOffset + buffer->nFilledLen < buffer->nOffset
 || buffer->nOffset + buffer->nFilledLen > buffer->nAllocLen) {
            CLOG_ERROR(onFillBufferDone, OMX_ErrorBadParameter,
                    FULL_BUFFER(NULL, buffer, msg.fenceFd));
 }
        buffer_meta->CopyFromOMX(buffer);

 if (bufferSource != NULL) {
            bufferSource->codecBufferFilled(buffer);

            msg.u.extended_buffer_data.timestamp = buffer->nTimeStamp;
 }
 } else if (msg.type == omx_message::EMPTY_BUFFER_DONE) {
        OMX_BUFFERHEADERTYPE *buffer =
            findBufferHeader(msg.u.buffer_data.buffer, kPortIndexInput);
 if (buffer == NULL) {
 return false;
 }

 {
 Mutex::Autolock _l(mDebugLock);
            mInputBuffersWithCodec.remove(buffer);

            CLOG_BUMPED_BUFFER(
                    EBD, WITH_STATS(EMPTY_BUFFER(msg.u.buffer_data.buffer, buffer, msg.fenceFd)));
 }

 if (bufferSource != NULL) {
            bufferSource->codecBufferEmptied(buffer, msg.fenceFd);
 return true;
 }
 }

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: component_loc(png_byte loc[4], png_uint_32 format)
{
 /* Given a format return the number of channels and the location of
    * each channel.
    *
    * The mask 'loc' contains the component offset of the channels in the
    * following order.  Note that if 'format' is grayscale the entries 1-3 must
    * all contain the location of the gray channel.
    *
    * 0: alpha
    * 1: red or gray
    * 2: green or gray
    * 3: blue or gray
    */
   png_byte channels;

 if (format & PNG_FORMAT_FLAG_COLOR)
 {
      channels = 3;

      loc[2] = 1;

#     ifdef PNG_FORMAT_BGR_SUPPORTED
 if (format & PNG_FORMAT_FLAG_BGR)
 {
            loc[1] = 2;
            loc[3] = 0;
 }

 else
#     endif
 {
         loc[1] = 0;
         loc[3] = 2;
 }
 }

 else
 {
      channels = 1;
      loc[1] = loc[2] = loc[3] = 0;
 }

 if (format & PNG_FORMAT_FLAG_ALPHA)
 {
#     ifdef PNG_FORMAT_AFIRST_SUPPORTED
 if (format & PNG_FORMAT_FLAG_AFIRST)
 {
            loc[0] = 0;
 ++loc[1];
 ++loc[2];
 ++loc[3];
 }

 else
#     endif
         loc[0] = channels;

 ++channels;
 }

 else
      loc[0] = 4; /* not present */

 return channels;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: unsigned Get32u(void * Long)
{
 return (unsigned)Get32s(Long) & 0xffffffff;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMXNodeInstance::~OMXNodeInstance() {
    free(mName);
    CHECK(mHandle == NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Chapters::Atom::ExpandDisplaysArray()
{
    if (m_displays_size > m_displays_count)
        return true;  // nothing else to do
    const int size = (m_displays_size == 0) ? 1 : 2 * m_displays_size;
    Display* const displays = new (std::nothrow) Display[size];
    if (displays == NULL)
        return false;
    for (int idx = 0; idx < m_displays_count; ++idx)
    {
        m_displays[idx].ShallowCopy(displays[idx]);
    }
    delete[] m_displays;
    m_displays = displays;
    m_displays_size = size;
    return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::traceInboundQueueLengthLocked() {
 if (ATRACE_ENABLED()) {
        ATRACE_INT("iq", mInboundQueue.count());
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int get_properties(int num_properties, bt_property_t *properties, jintArray *types,
                        jobjectArray *props) {
    jbyteArray propVal;
 for (int i = 0; i < num_properties; i++) {
        propVal = callbackEnv->NewByteArray(properties[i].len);
 if (propVal == NULL) goto Fail;

        callbackEnv->SetByteArrayRegion(propVal, 0, properties[i].len,
 (jbyte*)properties[i].val);
        callbackEnv->SetObjectArrayElement(*props, i, propVal);
        callbackEnv->DeleteLocalRef(propVal);
        callbackEnv->SetIntArrayRegion(*types, i, 1, (jint *)&properties[i].type);
 }
 return 0;
Fail:
 if (propVal) callbackEnv->DeleteLocalRef(propVal);
    ALOGE("Error while allocation of array in %s", __FUNCTION__);
 return -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OggSource::start(MetaData * /* params */) {
 if (mStarted) {
 return INVALID_OPERATION;
 }

    mStarted = true;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseCharDataComplex(xmlParserCtxtPtr ctxt, int cdata) {
    xmlChar buf[XML_PARSER_BIG_BUFFER_SIZE + 5];
 int nbchar = 0;
 int cur, l;
 int count = 0;

    SHRINK;
    GROW;
    cur = CUR_CHAR(l);
 while ((cur != '<') && /* checked */
 (cur != '&') &&
 (IS_CHAR(cur))) /* test also done in xmlCurrentChar() */ {
 if ((cur == ']') && (NXT(1) == ']') &&
 (NXT(2) == '>')) {
 if (cdata) break;
 else {
		xmlFatalErr(ctxt, XML_ERR_MISPLACED_CDATA_END, NULL);
 }
 }
	COPY_BUF(l,buf,nbchar,cur);
 if (nbchar >= XML_PARSER_BIG_BUFFER_SIZE) {
	    buf[nbchar] = 0;

 /*
	     * OK the segment is to be consumed as chars.
	     */
 if ((ctxt->sax != NULL) && (!ctxt->disableSAX)) {
 if (areBlanks(ctxt, buf, nbchar, 0)) {
 if (ctxt->sax->ignorableWhitespace != NULL)
			ctxt->sax->ignorableWhitespace(ctxt->userData,
			                               buf, nbchar);
 } else {
 if (ctxt->sax->characters != NULL)
			ctxt->sax->characters(ctxt->userData, buf, nbchar);
 if ((ctxt->sax->characters !=
		         ctxt->sax->ignorableWhitespace) &&
 (*ctxt->space == -1))
 *ctxt->space = -2;
 }
 }
	    nbchar = 0;
 /* something really bad happened in the SAX callback */
 if (ctxt->instate != XML_PARSER_CONTENT)
 return;
 }
	count++;
 if (count > 50) {
	    GROW;
	    count = 0;
 if (ctxt->instate == XML_PARSER_EOF)
 return;
 }
	NEXTL(l);
	cur = CUR_CHAR(l);
 }
 if (nbchar != 0) {
        buf[nbchar] = 0;
 /*
	 * OK the segment is to be consumed as chars.
	 */
 if ((ctxt->sax != NULL) && (!ctxt->disableSAX)) {
 if (areBlanks(ctxt, buf, nbchar, 0)) {
 if (ctxt->sax->ignorableWhitespace != NULL)
		    ctxt->sax->ignorableWhitespace(ctxt->userData, buf, nbchar);
 } else {
 if (ctxt->sax->characters != NULL)
		    ctxt->sax->characters(ctxt->userData, buf, nbchar);
 if ((ctxt->sax->characters != ctxt->sax->ignorableWhitespace) &&
 (*ctxt->space == -1))
 *ctxt->space = -2;
 }
 }
 }
 if ((cur != 0) && (!IS_CHAR(cur))) {
 /* Generate the error and skip the offending character */
        xmlFatalErrMsgInt(ctxt, XML_ERR_INVALID_CHAR,
 "PCDATA invalid Char value %d\n",
	                  cur);
	NEXTL(l);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void EqualizerSetPreset(EffectContext *pContext, int preset){

    pContext->pBundledContext->CurPreset = preset;

 for (int i=0; i<FIVEBAND_NUMBANDS; i++)
 {
        pContext->pBundledContext->bandGaindB[i] =
                EQNB_5BandSoftPresets[i + preset * FIVEBAND_NUMBANDS];
 }

 EqualizerLimitBandLevels(pContext);

 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::readBuffer(
        media_track_type trackType, int64_t seekTimeUs, int64_t *actualTimeUs, bool formatChange) {
 if (mStopRead) {
 return;
 }
 Track *track;
 size_t maxBuffers = 1;
 switch (trackType) {
 case MEDIA_TRACK_TYPE_VIDEO:
            track = &mVideoTrack;
 if (mIsWidevine) {
                maxBuffers = 2;
 }
 break;
 case MEDIA_TRACK_TYPE_AUDIO:
            track = &mAudioTrack;
 if (mIsWidevine) {
                maxBuffers = 8;
 } else {
                maxBuffers = 64;
 }
 break;
 case MEDIA_TRACK_TYPE_SUBTITLE:
            track = &mSubtitleTrack;
 break;
 case MEDIA_TRACK_TYPE_TIMEDTEXT:
            track = &mTimedTextTrack;
 break;
 default:
            TRESPASS();
 }

 if (track->mSource == NULL) {
 return;
 }

 if (actualTimeUs) {
 *actualTimeUs = seekTimeUs;
 }

 MediaSource::ReadOptions options;

 bool seeking = false;

 if (seekTimeUs >= 0) {
        options.setSeekTo(seekTimeUs, MediaSource::ReadOptions::SEEK_PREVIOUS_SYNC);
        seeking = true;
 }

 if (mIsWidevine && trackType != MEDIA_TRACK_TYPE_AUDIO) {
        options.setNonBlocking();
 }

 for (size_t numBuffers = 0; numBuffers < maxBuffers; ) {
 MediaBuffer *mbuf;
 status_t err = track->mSource->read(&mbuf, &options);

        options.clearSeekTo();

 if (err == OK) {
 int64_t timeUs;
            CHECK(mbuf->meta_data()->findInt64(kKeyTime, &timeUs));
 if (trackType == MEDIA_TRACK_TYPE_AUDIO) {
                mAudioTimeUs = timeUs;
 } else if (trackType == MEDIA_TRACK_TYPE_VIDEO) {
                mVideoTimeUs = timeUs;
 }

 if ((seeking || formatChange)
 && (trackType == MEDIA_TRACK_TYPE_AUDIO
 || trackType == MEDIA_TRACK_TYPE_VIDEO)) {
 ATSParser::DiscontinuityType type = formatChange
 ? (seeking
 ? ATSParser::DISCONTINUITY_FORMATCHANGE
 : ATSParser::DISCONTINUITY_NONE)
 : ATSParser::DISCONTINUITY_SEEK;
                track->mPackets->queueDiscontinuity( type, NULL, true /* discard */);
 }

            sp<ABuffer> buffer = mediaBufferToABuffer(mbuf, trackType, actualTimeUs);
            track->mPackets->queueAccessUnit(buffer);
            formatChange = false;
            seeking = false;
 ++numBuffers;
 } else if (err == WOULD_BLOCK) {
 break;
 } else if (err == INFO_FORMAT_CHANGED) {
#if 0
            track->mPackets->queueDiscontinuity(
 ATSParser::DISCONTINUITY_FORMATCHANGE,
                    NULL,
 false /* discard */);
#endif
 } else {
            track->mPackets->signalEOS(err);
 break;
 }
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  static Handle<JSArray> SliceImpl(Handle<JSObject> receiver,
 uint32_t start, uint32_t end) {
    UNREACHABLE();
 return Handle<JSArray>();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void CopySmiToDoubleElements(FixedArrayBase* from_base,
 uint32_t from_start,
 FixedArrayBase* to_base, uint32_t to_start,
 int raw_copy_size) {
 DisallowHeapAllocation no_allocation;
 int copy_size = raw_copy_size;
 if (raw_copy_size < 0) {
    DCHECK(raw_copy_size == ElementsAccessor::kCopyToEnd ||
           raw_copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole);
    copy_size = from_base->length() - from_start;
 if (raw_copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole) {
 for (int i = to_start + copy_size; i < to_base->length(); ++i) {
 FixedDoubleArray::cast(to_base)->set_the_hole(i);
 }
 }
 }
  DCHECK((copy_size + static_cast<int>(to_start)) <= to_base->length() &&
 (copy_size + static_cast<int>(from_start)) <= from_base->length());
 if (copy_size == 0) return;
 FixedArray* from = FixedArray::cast(from_base);
 FixedDoubleArray* to = FixedDoubleArray::cast(to_base);
 Object* the_hole = from->GetHeap()->the_hole_value();
 for (uint32_t from_end = from_start + static_cast<uint32_t>(copy_size);
       from_start < from_end; from_start++, to_start++) {
 Object* hole_or_smi = from->get(from_start);
 if (hole_or_smi == the_hole) {
      to->set_the_hole(to_start);
 } else {
      to->set(to_start, Smi::cast(hole_or_smi)->value());
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void h264bsdInitRefPicList(dpbStorage_t *dpb)
{

/* Variables */

    u32 i;

/* Code */

 for (i = 0; i < dpb->numRefFrames; i++)
        dpb->list[i] = &dpb->buffer[i];

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void WT_NoiseGenerator (S_WT_VOICE *pWTVoice, S_WT_INT_FRAME *pWTIntFrame)
 {
    EAS_PCM *pOutputBuffer;
    EAS_I32 phaseInc;
    EAS_I32 tmp0;
    EAS_I32 tmp1;
    EAS_I32 nInterpolatedSample;
    EAS_I32 numSamples;

 /* initialize some local variables */

     numSamples = pWTIntFrame->numSamples;
     if (numSamples <= 0) {
         ALOGE("b/26366256");
         return;
     }
     pOutputBuffer = pWTIntFrame->pAudioBuffer;
    phaseInc = pWTIntFrame->frame.phaseIncrement;

 /* get last two samples generated */
 /*lint -e{704} <avoid divide for performance>*/
    tmp0 = (EAS_I32) (pWTVoice->phaseAccum) >> 18;
 /*lint -e{704} <avoid divide for performance>*/
    tmp1 = (EAS_I32) (pWTVoice->loopEnd) >> 18;

 /* generate a buffer of noise */
 while (numSamples--) {
        nInterpolatedSample = MULT_AUDIO_COEF( tmp0, (PHASE_ONE - pWTVoice->phaseFrac));
        nInterpolatedSample += MULT_AUDIO_COEF( tmp1, pWTVoice->phaseFrac);
 *pOutputBuffer++ = (EAS_PCM) nInterpolatedSample;

 /* update PRNG */
        pWTVoice->phaseFrac += (EAS_U32) phaseInc;
 if (GET_PHASE_INT_PART(pWTVoice->phaseFrac)) {
            tmp0 = tmp1;
            pWTVoice->phaseAccum = pWTVoice->loopEnd;
            pWTVoice->loopEnd = (5 * pWTVoice->loopEnd + 1);
            tmp1 = (EAS_I32) (pWTVoice->loopEnd) >> 18;
            pWTVoice->phaseFrac = GET_PHASE_FRAC_PART(pWTVoice->phaseFrac);
 }

 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MPEG4Extractor::populateMetrics() {
    ALOGV("MPEG4Extractor::populateMetrics");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: summarize_gamma_errors(png_modifier *pm, png_const_charp who, int low_bit_depth,
 int indexed)
{
   fflush(stderr);

 if (who)
      printf("\nGamma correction with %s:\n", who);

 else
      printf("\nBasic gamma correction:\n");

 if (low_bit_depth)
 {
      print_one(" 2 bit gray: ", pm->error_gray_2);
      print_one(" 4 bit gray: ", pm->error_gray_4);
      print_one(" 8 bit gray: ", pm->error_gray_8);
      print_one(" 8 bit color:", pm->error_color_8);
 if (indexed)
         print_one(" indexed:    ", pm->error_indexed);
 }

   print_one("16 bit gray: ", pm->error_gray_16);
   print_one("16 bit color:", pm->error_color_16);

   fflush(stdout);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int32_t StreamingProcessor::getActiveRequestId() const {
 Mutex::Autolock m(mMutex);
 switch (mActiveRequest) {
 case NONE:
 return 0;
 case PREVIEW:
 return mPreviewRequestId;
 case RECORD:
 return mRecordingRequestId;
 default:
            ALOGE("%s: Unexpected mode %d", __FUNCTION__, mActiveRequest);
 return 0;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<Object> GetImpl(Isolate* isolate, FixedArrayBase* elements,
 uint32_t entry) {
    UNREACHABLE();
 return Handle<Object>();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void RilSapSocket::onRequestComplete(RIL_Token t, RIL_Errno e, void *response,
 size_t response_len) {
 SapSocketRequest* request= (SapSocketRequest*)t;
 MsgHeader *hdr = request->curr;

 MsgHeader rsp;
    rsp.token = request->curr->token;
    rsp.type = MsgType_RESPONSE;
    rsp.id = request->curr->id;
    rsp.error = (Error)e;
    rsp.payload = (pb_bytes_array_t *)calloc(1, sizeof(pb_bytes_array_t) + response_len);
 if (!rsp.payload) {
        RLOGE("onRequestComplete: OOM");
 } else {
 if (response && response_len > 0) {
            memcpy(rsp.payload->bytes, response, response_len);
            rsp.payload->size = response_len;
 } else {
            rsp.payload->size = 0;
 }

        RLOGE("Token:%d, MessageId:%d", hdr->token, hdr->id);

        sendResponse(&rsp);
        free(rsp.payload);
 }

 if(!pendingResponseQueue.checkAndDequeue(hdr->id, hdr->token)) {
        RLOGE("Token:%d, MessageId:%d", hdr->token, hdr->id);
        RLOGE ("RilSapSocket::onRequestComplete: invalid Token or Message Id");
 }

    free(hdr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual bool isCryptoSchemeSupported(const uint8_t uuid[16]) {
 Parcel data, reply;
        data.writeInterfaceToken(ICrypto::getInterfaceDescriptor());
        data.write(uuid, 16);
        remote()->transact(IS_CRYPTO_SUPPORTED, data, &reply);

 return reply.readInt32() != 0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::sendCommand(
        OMX_COMMANDTYPE cmd, OMX_S32 param) {
 const sp<GraphicBufferSource>& bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && cmd == OMX_CommandStateSet) {
 if (param == OMX_StateIdle) {
            bufferSource->omxIdle();
 } else if (param == OMX_StateLoaded) {
            bufferSource->omxLoaded();
            setGraphicBufferSource(NULL);
 }

 }

 Mutex::Autolock autoLock(mLock);

 {
 Mutex::Autolock _l(mDebugLock);
        bumpDebugLevel_l(2 /* numInputBuffers */, 2 /* numOutputBuffers */);
 }

 const char *paramString =
        cmd == OMX_CommandStateSet ? asString((OMX_STATETYPE)param) : portString(param);
    CLOG_STATE(sendCommand, "%s(%d), %s(%d)", asString(cmd), cmd, paramString, param);
    OMX_ERRORTYPE err = OMX_SendCommand(mHandle, cmd, param, NULL);
    CLOG_IF_ERROR(sendCommand, err, "%s(%d), %s(%d)", asString(cmd), cmd, paramString, param);
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void WT_Interpolate (S_WT_VOICE *pWTVoice, S_WT_INT_FRAME *pWTIntFrame)
{
    EAS_PCM *pOutputBuffer;
    EAS_I32 phaseInc;
    EAS_I32 phaseFrac;
    EAS_I32 acc0;
 const EAS_SAMPLE *pSamples;
 const EAS_SAMPLE *loopEnd;
    EAS_I32 samp1;
    EAS_I32 samp2;
    EAS_I32 numSamples;

 /* initialize some local variables */

     numSamples = pWTIntFrame->numSamples;
     if (numSamples <= 0) {
         ALOGE("b/26366256");
         return;
     }
     pOutputBuffer = pWTIntFrame->pAudioBuffer;

    loopEnd = (const EAS_SAMPLE*) pWTVoice->loopEnd + 1;
    pSamples = (const EAS_SAMPLE*) pWTVoice->phaseAccum;
 /*lint -e{713} truncation is OK */
    phaseFrac = pWTVoice->phaseFrac;
    phaseInc = pWTIntFrame->frame.phaseIncrement;

 /* fetch adjacent samples */
#if defined(_8_BIT_SAMPLES)
 /*lint -e{701} <avoid multiply for performance>*/
    samp1 = pSamples[0] << 8;
 /*lint -e{701} <avoid multiply for performance>*/
    samp2 = pSamples[1] << 8;
#else
    samp1 = pSamples[0];
    samp2 = pSamples[1];
#endif

 while (numSamples--) {

 /* linear interpolation */
        acc0 = samp2 - samp1;
        acc0 = acc0 * phaseFrac;
 /*lint -e{704} <avoid divide>*/
        acc0 = samp1 + (acc0 >> NUM_PHASE_FRAC_BITS);

 /* save new output sample in buffer */
 /*lint -e{704} <avoid divide>*/
 *pOutputBuffer++ = (EAS_I16)(acc0 >> 2);

 /* increment phase */
        phaseFrac += phaseInc;
 /*lint -e{704} <avoid divide>*/
        acc0 = phaseFrac >> NUM_PHASE_FRAC_BITS;

 /* next sample */
 if (acc0 > 0) {

 /* advance sample pointer */
            pSamples += acc0;
            phaseFrac = (EAS_I32)((EAS_U32)phaseFrac & PHASE_FRAC_MASK);

 /* check for loop end */
            acc0 = (EAS_I32) (pSamples - loopEnd);
 if (acc0 >= 0)
                pSamples = (const EAS_SAMPLE*) pWTVoice->loopStart + acc0;

 /* fetch new samples */
#if defined(_8_BIT_SAMPLES)
 /*lint -e{701} <avoid multiply for performance>*/
            samp1 = pSamples[0] << 8;
 /*lint -e{701} <avoid multiply for performance>*/
            samp2 = pSamples[1] << 8;
#else
            samp1 = pSamples[0];
            samp2 = pSamples[1];
#endif
 }
 }

 /* save pointer and phase */
    pWTVoice->phaseAccum = (EAS_U32) pSamples;
    pWTVoice->phaseFrac = (EAS_U32) phaseFrac;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: AudioFlinger::EffectModule::~EffectModule()
{
    ALOGV("Destructor %p", this);
 if (mEffectInterface != NULL) {
        remove_effect_from_hal_l();
 EffectRelease(mEffectInterface);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::empty_buffer_done(OMX_HANDLETYPE         hComp,
        OMX_BUFFERHEADERTYPE* buffer)
{

 if (buffer == NULL || ((buffer - m_inp_mem_ptr) > (int)drv_ctx.ip_buf.actualcount)) {
        DEBUG_PRINT_ERROR("empty_buffer_done: ERROR bufhdr = %p", buffer);
 return OMX_ErrorBadParameter;
 }

    DEBUG_PRINT_LOW("empty_buffer_done: bufhdr = %p, bufhdr->pBuffer = %p, bufhdr->nFlags = %x",
            buffer, buffer->pBuffer, buffer->nFlags);
    pending_input_buffers--;

 if (arbitrary_bytes) {
 if (pdest_frame == NULL && input_flush_progress == false) {
            DEBUG_PRINT_LOW("Push input from buffer done address of Buffer %p",buffer);
            pdest_frame = buffer;
            buffer->nFilledLen = 0;
            buffer->nTimeStamp = LLONG_MAX;
            push_input_buffer (hComp);
 } else {
            DEBUG_PRINT_LOW("Push buffer into freeq address of Buffer %p",buffer);
            buffer->nFilledLen = 0;
 if (!m_input_free_q.insert_entry((unsigned long)buffer,
 (unsigned)NULL, (unsigned)NULL)) {
                DEBUG_PRINT_ERROR("ERROR:i/p free Queue is FULL Error");
 }
 }
 } else if (m_cb.EmptyBufferDone) {
        buffer->nFilledLen = 0;
 if (input_use_buffer == true) {
            buffer = &m_inp_heap_ptr[buffer-m_inp_mem_ptr];
 }
        m_cb.EmptyBufferDone(hComp ,m_app_data, buffer);
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ATSParser::~ATSParser() {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setupH263EncoderParameters(const sp<AMessage> &msg) {
 int32_t bitrate, iFrameInterval;
 if (!msg->findInt32("bitrate", &bitrate)
 || !msg->findInt32("i-frame-interval", &iFrameInterval)) {
 return INVALID_OPERATION;
 }

    OMX_VIDEO_CONTROLRATETYPE bitrateMode = getBitrateMode(msg);

 float frameRate;
 if (!msg->findFloat("frame-rate", &frameRate)) {
 int32_t tmp;
 if (!msg->findInt32("frame-rate", &tmp)) {
 return INVALID_OPERATION;
 }
        frameRate = (float)tmp;
 }

    OMX_VIDEO_PARAM_H263TYPE h263type;
 InitOMXParams(&h263type);
    h263type.nPortIndex = kPortIndexOutput;

 status_t err = mOMX->getParameter(
            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));

 if (err != OK) {
 return err;
 }

    h263type.nAllowedPictureTypes =
        OMX_VIDEO_PictureTypeI | OMX_VIDEO_PictureTypeP;

    h263type.nPFrames = setPFramesSpacing(iFrameInterval, frameRate);
 if (h263type.nPFrames == 0) {
        h263type.nAllowedPictureTypes = OMX_VIDEO_PictureTypeI;
 }
    h263type.nBFrames = 0;

 int32_t profile;
 if (msg->findInt32("profile", &profile)) {
 int32_t level;
 if (!msg->findInt32("level", &level)) {
 return INVALID_OPERATION;
 }

        err = verifySupportForProfileAndLevel(profile, level);

 if (err != OK) {
 return err;
 }

        h263type.eProfile = static_cast<OMX_VIDEO_H263PROFILETYPE>(profile);
        h263type.eLevel = static_cast<OMX_VIDEO_H263LEVELTYPE>(level);
 }

    h263type.bPLUSPTYPEAllowed = OMX_FALSE;
    h263type.bForceRoundingTypeToZero = OMX_FALSE;
    h263type.nPictureHeaderRepetition = 0;
    h263type.nGOBHeaderInterval = 0;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamVideoH263, &h263type, sizeof(h263type));

 if (err != OK) {
 return err;
 }

    err = configureBitrate(bitrate, bitrateMode);

 if (err != OK) {
 return err;
 }

 return setupErrorCorrectionParameters();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t AudioFlinger::EffectModule::removeHandle(EffectHandle *handle)
{
 Mutex::Autolock _l(mLock);
 size_t size = mHandles.size();
 size_t i;
 for (i = 0; i < size; i++) {
 if (mHandles[i] == handle) {
 break;
 }
 }
 if (i == size) {
 return size;
 }
    ALOGV("removeHandle() %p removed handle %p in position %d", this, handle, i);

    mHandles.removeAt(i);
 if (i == 0) {
 EffectHandle *h = controlHandle_l();
 if (h != NULL) {
            h->setControl(true /*hasControl*/, true /*signal*/ , handle->enabled() /*enabled*/);
 }
 }

 if (mHandles.size() == 0 && !mPinned) {
        mState = DESTROYED;
 }

 return mHandles.size();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_reset(iv_obj_t *ps_dechdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 dec_state_t *ps_dec_state;
 dec_state_multi_core_t *ps_dec_state_multi_core;
    UNUSED(pv_api_ip);
 impeg2d_ctl_reset_op_t *s_ctl_reset_op = (impeg2d_ctl_reset_op_t *)pv_api_op;

    WORD32 i4_num_threads;

    ps_dec_state_multi_core = (dec_state_multi_core_t *) (ps_dechdl->pv_codec_handle);
    ps_dec_state = ps_dec_state_multi_core->ps_dec_state[0];

 if(ps_dec_state_multi_core != NULL)
 {
 if(ps_dec_state->aps_ref_pics[1] != NULL)
            impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->aps_ref_pics[1]->i4_buf_id, BUF_MGR_REF);
 if(ps_dec_state->aps_ref_pics[0] != NULL)
            impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->aps_ref_pics[0]->i4_buf_id, BUF_MGR_REF);
 while(1)
 {
 pic_buf_t *ps_disp_pic = impeg2_disp_mgr_get(&ps_dec_state->s_disp_mgr, &ps_dec_state->i4_disp_buf_id);
 if(NULL == ps_disp_pic)
 break;
 if(0 == ps_dec_state->u4_share_disp_buf)
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_disp_pic->i4_buf_id, BUF_MGR_DISP);

 }

 if((ps_dec_state->u4_deinterlace) && (NULL != ps_dec_state->ps_deint_pic))
 {
            impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg,
                                   ps_dec_state->ps_deint_pic->i4_buf_id,
                                   MPEG2_BUF_MGR_DEINT);
 }

 for(i4_num_threads = 0; i4_num_threads < MAX_THREADS; i4_num_threads++)
 {
            ps_dec_state = ps_dec_state_multi_core->ps_dec_state[i4_num_threads];


 /* --------------------------------------------------------------------- */
 /* Initializations */

            ps_dec_state->u2_header_done    = 0; /* Header decoding not done */
            ps_dec_state->u4_frm_buf_stride = 0;
            ps_dec_state->u2_is_mpeg2       = 0;
            ps_dec_state->aps_ref_pics[0] = NULL;
            ps_dec_state->aps_ref_pics[1] = NULL;
            ps_dec_state->ps_deint_pic = NULL;
 }
 }
 else
 {
        s_ctl_reset_op->s_ivd_ctl_reset_op_t.u4_error_code =
                        IMPEG2D_INIT_NOT_DONE;
 }

 return(IV_SUCCESS);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void HeapCache::free_heap(const sp<IBinder>& binder) {
    free_heap( wp<IBinder>(binder) );
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_storenew(png_store *ps)
{
   png_store_buffer *pb;

 if (ps->writepos != STORE_BUFFER_SIZE)
      png_error(ps->pwrite, "invalid store call");

   pb = voidcast(png_store_buffer*, malloc(sizeof *pb));

 if (pb == NULL)
      png_error(ps->pwrite, "store new: OOM");

 *pb = ps->new;
   ps->new.prev = pb;
   ps->writepos = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t NuPlayer::GenericSource::getSelectedTrack(media_track_type type) const {
    sp<AMessage> msg = new AMessage(kWhatGetSelectedTrack, id());
    msg->setInt32("type", type);

    sp<AMessage> response;
 int32_t index;
 status_t err = msg->postAndAwaitResponse(&response);
 if (err == OK && response != NULL) {
        CHECK(response->findInt32("index", &index));
 return index;
 } else {
 return -1;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void internal_write_ready(void *context) {
  assert(context != NULL);

 socket_t *socket = (void *)context;
  socket->write_ready(socket, socket->context);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: put_chunk(const unsigned char *chunk, uInt length)
{
   uLong crc;

   put_uLong(length-4); /* Exclude the tag */

   fwrite(chunk, length, 1, stdout);

   crc = crc32(0, Z_NULL, 0);
   put_uLong(crc32(crc, chunk, length));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectModule::setAudioSource(audio_source_t source)
{
 Mutex::Autolock _l(mLock);
 if (mStatus != NO_ERROR) {
 return mStatus;
 }
 status_t status = NO_ERROR;
 if ((mDescriptor.flags & EFFECT_FLAG_AUDIO_SOURCE_MASK) == EFFECT_FLAG_AUDIO_SOURCE_IND) {
 uint32_t size = 0;
        status = (*mEffectInterface)->command(mEffectInterface,
                                              EFFECT_CMD_SET_AUDIO_SOURCE,
 sizeof(audio_source_t),
 &source,
 &size,
                                              NULL);
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::ExecutingToIdleState::onInputBufferFilled(
 const sp<AMessage> &msg) {
 BaseState::onInputBufferFilled(msg);

    changeStateIfWeOwnAllBuffers();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseSegmentIndex(off64_t offset, size_t size) {
  ALOGV("MPEG4Extractor::parseSegmentIndex");

 if (size < 12) {
 return -EINVAL;
 }

 uint32_t flags;
 if (!mDataSource->getUInt32(offset, &flags)) {
 return ERROR_MALFORMED;
 }

 uint32_t version = flags >> 24;
    flags &= 0xffffff;

    ALOGV("sidx version %d", version);

 uint32_t referenceId;
 if (!mDataSource->getUInt32(offset + 4, &referenceId)) {
 return ERROR_MALFORMED;
 }

 uint32_t timeScale;
 if (!mDataSource->getUInt32(offset + 8, &timeScale)) {
 return ERROR_MALFORMED;
 }
    ALOGV("sidx refid/timescale: %d/%d", referenceId, timeScale);
 if (timeScale == 0)
 return ERROR_MALFORMED;

 uint64_t earliestPresentationTime;
 uint64_t firstOffset;

    offset += 12;
    size -= 12;

 if (version == 0) {
 if (size < 8) {
 return -EINVAL;
 }
 uint32_t tmp;
 if (!mDataSource->getUInt32(offset, &tmp)) {
 return ERROR_MALFORMED;
 }
        earliestPresentationTime = tmp;
 if (!mDataSource->getUInt32(offset + 4, &tmp)) {
 return ERROR_MALFORMED;
 }
        firstOffset = tmp;
        offset += 8;
        size -= 8;
 } else {
 if (size < 16) {
 return -EINVAL;
 }
 if (!mDataSource->getUInt64(offset, &earliestPresentationTime)) {
 return ERROR_MALFORMED;
 }
 if (!mDataSource->getUInt64(offset + 8, &firstOffset)) {
 return ERROR_MALFORMED;
 }
        offset += 16;
        size -= 16;
 }
    ALOGV("sidx pres/off: %" PRIu64 "/%" PRIu64, earliestPresentationTime, firstOffset);

 if (size < 4) {
 return -EINVAL;
 }

 uint16_t referenceCount;
 if (!mDataSource->getUInt16(offset + 2, &referenceCount)) {
 return ERROR_MALFORMED;
 }
    offset += 4;
    size -= 4;
    ALOGV("refcount: %d", referenceCount);

 if (size < referenceCount * 12) {
 return -EINVAL;
 }

 uint64_t total_duration = 0;
 for (unsigned int i = 0; i < referenceCount; i++) {
 uint32_t d1, d2, d3;

 if (!mDataSource->getUInt32(offset, &d1) || // size
 !mDataSource->getUInt32(offset + 4, &d2) || // duration
 !mDataSource->getUInt32(offset + 8, &d3)) { // flags
 return ERROR_MALFORMED;
 }

 if (d1 & 0x80000000) {
            ALOGW("sub-sidx boxes not supported yet");
 }
 bool sap = d3 & 0x80000000;
 uint32_t saptype = (d3 >> 28) & 7;
 if (!sap || (saptype != 1 && saptype != 2)) {
            ALOGW("not a stream access point, or unsupported type: %08x", d3);
 }
        total_duration += d2;
        offset += 12;
        ALOGV(" item %d, %08x %08x %08x", i, d1, d2, d3);
 SidxEntry se;
        se.mSize = d1 & 0x7fffffff;
        se.mDurationUs = 1000000LL * d2 / timeScale;
        mSidxEntries.add(se);
 }

 uint64_t sidxDuration = total_duration * 1000000 / timeScale;

 if (mLastTrack == NULL)
 return ERROR_MALFORMED;

 int64_t metaDuration;
 if (!mLastTrack->meta->findInt64(kKeyDuration, &metaDuration) || metaDuration == 0) {
        mLastTrack->meta->setInt64(kKeyDuration, sidxDuration);
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ATSParser::PSISection::isComplete() const {
 if (mBuffer == NULL || mBuffer->size() < 3) {
 return false;
 }

 unsigned sectionLength = U16_AT(mBuffer->data() + 1) & 0xfff;
 return mBuffer->size() >= sectionLength + 3;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<Object> RemoveElement(Handle<JSArray> receiver,
 Where remove_position) {
 Isolate* isolate = receiver->GetIsolate();
 ElementsKind kind = KindTraits::Kind;
 if (IsFastSmiOrObjectElementsKind(kind)) {
 HandleScope scope(isolate);
 JSObject::EnsureWritableFastElements(receiver);
 }
 Handle<FixedArrayBase> backing_store(receiver->elements(), isolate);
 uint32_t length =
 static_cast<uint32_t>(Smi::cast(receiver->length())->value());
    DCHECK(length > 0);
 int new_length = length - 1;
 int remove_index = remove_position == AT_START ? 0 : new_length;
 Handle<Object> result =
 Subclass::GetImpl(isolate, *backing_store, remove_index);
 if (remove_position == AT_START) {
 Subclass::MoveElements(isolate, receiver, backing_store, 0, 1, new_length,
 0, 0);
 }
 Subclass::SetLengthImpl(isolate, receiver, new_length, backing_store);

 if (IsHoleyElementsKind(kind) && result->IsTheHole(isolate)) {
 return isolate->factory()->undefined_value();
 }
 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftVideoDecoderOMXComponent::getConfig(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexConfigCommonOutputCrop:

         {
             OMX_CONFIG_RECTTYPE *rectParams = (OMX_CONFIG_RECTTYPE *)params;
 
             if (rectParams->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorUndefined;
             }

            rectParams->nLeft = mCropLeft;
            rectParams->nTop = mCropTop;
            rectParams->nWidth = mCropWidth;
            rectParams->nHeight = mCropHeight;

 return OMX_ErrorNone;
 }

 default:
 return OMX_ErrorUnsupportedIndex;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_write_palette(png_store *ps, int npalette)
{
 if (ps->pwrite == NULL)
      store_log(ps, NULL, "attempt to write palette without write stream", 1);

 if (ps->palette != NULL)
      png_error(ps->pwrite, "multiple store_write_palette calls");

 /* This function can only return NULL if called with '0'! */
 if (npalette > 0)
 {
      ps->palette = voidcast(store_palette_entry*, malloc(npalette *
 sizeof *ps->palette));

 if (ps->palette == NULL)
         png_error(ps->pwrite, "store new palette: OOM");

      ps->npalette = npalette;
 }

 return ps->palette;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Downmix_GetDescriptor(effect_handle_t self, effect_descriptor_t *pDescriptor)
{
 downmix_module_t *pDwnmxModule = (downmix_module_t *) self;

 if (pDwnmxModule == NULL ||
            pDwnmxModule->context.state == DOWNMIX_STATE_UNINITIALIZED) {
 return -EINVAL;
 }

    memcpy(pDescriptor, &gDownmixDescriptor, sizeof(effect_descriptor_t));

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_perf_mode(OMX_U32 mode)
{
 struct v4l2_control control;
 if (mode && mode <= V4L2_MPEG_VIDC_VIDEO_PERF_POWER_SAVE) {
        control.id = V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE;
        control.value = mode;
        DEBUG_PRINT_LOW("Going to set V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE");
 if (ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control)) {
            DEBUG_PRINT_ERROR("Failed to set V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE");
 return false;
 }
 return true;
 } else {
        DEBUG_PRINT_ERROR("Invalid mode set for V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE: %d", mode);
 return false;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: perform_gamma_composition_tests(png_modifier *pm, int do_background,
 int expand_16)
{
   png_byte colour_type = 0;
   png_byte bit_depth = 0;
 unsigned int palette_number = 0;

 
    /* Skip the non-alpha cases - there is no setting of a transparency colour at
     * present.
     */
   while (next_format(&colour_type, &bit_depth, &palette_number, 1/*gamma*/))
      if ((colour_type & PNG_COLOR_MASK_ALPHA) != 0)
    {
       unsigned int i, j;
 
 /* Don't skip the i==j case here - it's relevant. */
 for (i=0; i<pm->ngamma_tests; ++i) for (j=0; j<pm->ngamma_tests; ++j)
 {
         gamma_composition_test(pm, colour_type, bit_depth, palette_number,
            pm->interlace_type, 1/pm->gammas[i], pm->gammas[j],
            pm->use_input_precision, do_background, expand_16);

 if (fail(pm))
 return;
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: xmlSAXParseFile(xmlSAXHandlerPtr sax, const char *filename,
 int recovery) {
 return(xmlSAXParseFileWithData(sax,filename,recovery,NULL));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  explicit TypedElementsAccessor(const char* name)
 : ElementsAccessorBase<AccessorClass,
 ElementsKindTraits<Kind> >(name) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::getAudioStreamType(audio_stream_type_t *type)
{
    ALOGV("getAudioStreamType");
 Mutex::Autolock _l(mLock);
 *type = mStreamType;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: CameraSource *CameraSource::Create(const String16 &clientName) {
 Size size;
    size.width = -1;
    size.height = -1;

    sp<ICamera> camera;
 return new CameraSource(camera, NULL, 0, clientName, -1,
            size, -1, NULL, false);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::allocateBuffer(
        OMX_U32 portIndex, size_t size, OMX::buffer_id *buffer,

         void **buffer_data) {
     Mutex::Autolock autoLock(mLock);
 
    BufferMeta *buffer_meta = new BufferMeta(size);
 
     OMX_BUFFERHEADERTYPE *header;
 
    OMX_ERRORTYPE err = OMX_AllocateBuffer(
            mHandle, &header, portIndex, buffer_meta, size);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(allocateBuffer, err, BUFFER_FMT(portIndex, "%zu@", size));
 delete buffer_meta;
        buffer_meta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, buffer_meta);

 *buffer = makeBufferID(header);
 *buffer_data = header->pBuffer;

    addActiveBuffer(portIndex, *buffer);

    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && portIndex == kPortIndexInput) {
        bufferSource->addCodecBuffer(header);
 }
    CLOG_BUFFER(allocateBuffer, NEW_BUFFER_FMT(*buffer, portIndex, "%zu@%p", size, *buffer_data));

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline void set_socket_blocking(int s, int blocking)
 {
     int opts;
    opts = fcntl(s, F_GETFL);
     if (opts<0) APPL_TRACE_ERROR("set blocking (%s)", strerror(errno));
     if(blocking)
         opts &= ~O_NONBLOCK;
     else opts |= O_NONBLOCK;
    if (fcntl(s, F_SETFL, opts) < 0)
         APPL_TRACE_ERROR("set blocking (%s)", strerror(errno));
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool btif_config_set_str(const char *section, const char *key, const char *value) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);
  assert(value != NULL);

  pthread_mutex_lock(&lock);
  config_set_string(config, section, key, value);
  pthread_mutex_unlock(&lock);

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint32_t in_get_channels(const struct audio_stream *stream)
{
 struct a2dp_stream_in *in = (struct a2dp_stream_in *)stream;

    FNLOG();
 return in->common.cfg.channel_flags;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::Parse(long long& pos, long& len) const
{
    long status = Load(pos, len);
    if (status < 0)
        return status;
    assert(m_pos >= m_element_start);
    assert(m_timecode >= 0);
    const long long cluster_stop =
        (m_element_size < 0) ? -1 : m_element_start + m_element_size;
    if ((cluster_stop >= 0) && (m_pos >= cluster_stop))
        return 1;  //nothing else to do
    IMkvReader* const pReader = m_pSegment->m_pReader;
    long long total, avail;
    status = pReader->Length(&total, &avail);
    if (status < 0)  //error
        return status;
    assert((total < 0) || (avail <= total));
    pos = m_pos;
    for (;;)
    {
        if ((cluster_stop >= 0) && (pos >= cluster_stop))
            break;
        if ((total >= 0) && (pos >= total))
        {
            if (m_element_size < 0)
                m_element_size = pos - m_element_start;
            break;
        }
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        long long result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error
            return static_cast<long>(result);
        if (result > 0)  //weird
            return E_BUFFER_NOT_FULL;
        if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long id = ReadUInt(pReader, pos, len);
        if (id < 0) //error
            return static_cast<long>(id);
        if (id == 0)  //weird
            return E_FILE_FORMAT_INVALID;
        if ((id == 0x0F43B675) || (id == 0x0C53BB6B)) //Cluster or Cues ID
        {
            if (m_element_size < 0)
                m_element_size = pos - m_element_start;
            break;
        }
        pos += len;  //consume ID field
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error
            return static_cast<long>(result);
        if (result > 0)  //weird
            return E_BUFFER_NOT_FULL;
        if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long size = ReadUInt(pReader, pos, len);
        if (size < 0)  //error
            return static_cast<long>(size);
        const long long unknown_size = (1LL << (7 * len)) - 1;
        if (size == unknown_size)
            return E_FILE_FORMAT_INVALID;
        pos += len;  //consume size field
        if ((cluster_stop >= 0) && (pos > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if (size == 0)  //weird
            continue;
        const long long block_stop = pos + size;
        if (cluster_stop >= 0)
        {
            if (block_stop > cluster_stop)
            {
                if ((id == 0x20) || (id == 0x23))
                    return E_FILE_FORMAT_INVALID;
                pos = cluster_stop;
                break;
            }
        }
        else if ((total >= 0) && (block_stop > total))
        {
            m_element_size = total - m_element_start;
            pos = total;
            break;
        }
        else if (block_stop > avail)
        {
            len = static_cast<long>(size);
            return E_BUFFER_NOT_FULL;
        }
        Cluster* const this_ = const_cast<Cluster*>(this);
        if (id == 0x20)  //BlockGroup
            return this_->ParseBlockGroup(size, pos, len);
        if (id == 0x23)  //SimpleBlock
            return this_->ParseSimpleBlock(size, pos, len);
        pos += size;  //consume payload
        assert((cluster_stop < 0) || (pos <= cluster_stop));
    }
    assert(m_element_size > 0);
    m_pos = pos;
    assert((cluster_stop < 0) || (m_pos <= cluster_stop));
    if (m_entries_count > 0)
    {
        const long idx = m_entries_count - 1;
        const BlockEntry* const pLast = m_entries[idx];
        assert(pLast);
        const Block* const pBlock = pLast->GetBlock();
        assert(pBlock);
        const long long start = pBlock->m_start;
        if ((total >= 0) && (start > total))
            return -1;  //defend against trucated stream
        const long long size = pBlock->m_size;
        const long long stop = start + size;
        assert((cluster_stop < 0) || (stop <= cluster_stop));
        if ((total >= 0) && (stop > total))
            return -1;  //defend against trucated stream
    }
    return 1;  //no more entries
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: long long BlockGroup::GetPrevTimeCode() const { return m_prev; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long long Segment::GetDuration() const {
  assert(m_pInfo);
 return m_pInfo->GetDuration();
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void SoundPool::setVolume(int channelID, float leftVolume, float rightVolume)
{
 Mutex::Autolock lock(&mLock);
 SoundChannel* channel = findChannel(channelID);
 if (channel) {
        channel->setVolume(leftVolume, rightVolume);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jint Bitmap_getGenerationId(JNIEnv* env, jobject, jlong bitmapHandle) {
 SkBitmap* bitmap = reinterpret_cast<SkBitmap*>(bitmapHandle);
 return static_cast<jint>(bitmap->getGenerationID());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraService::connectPro(
 const sp<IProCameraCallbacks>& cameraCb,
 int cameraId,
 const String16& clientPackageName,
 int clientUid,
 /*out*/
                                        sp<IProCameraUser>& device)
{
 String8 clientName8(clientPackageName);
 int callingPid = getCallingPid();

    LOG1("CameraService::connectPro E (pid %d \"%s\", id %d)", callingPid,
            clientName8.string(), cameraId);
 status_t status = validateConnect(cameraId, /*inout*/clientUid);
 if (status != OK) {
 return status;
 }

    sp<ProClient> client;
 {
 Mutex::Autolock lock(mServiceLock);
 {
            sp<BasicClient> client;
 if (!canConnectUnsafe(cameraId, clientPackageName,
                                  cameraCb->asBinder(),
 /*out*/client)) {
 return -EBUSY;
 }
 }

 int facing = -1;
 int deviceVersion = getDeviceVersion(cameraId, &facing);

 switch(deviceVersion) {
 case CAMERA_DEVICE_API_VERSION_1_0:
            ALOGE("Camera id %d uses HALv1, doesn't support ProCamera",
                  cameraId);
 return -EOPNOTSUPP;
 break;
 case CAMERA_DEVICE_API_VERSION_2_0:
 case CAMERA_DEVICE_API_VERSION_2_1:
 case CAMERA_DEVICE_API_VERSION_3_0:
            client = new ProCamera2Client(this, cameraCb, clientPackageName,
                    cameraId, facing, callingPid, clientUid, getpid());
 break;
 case -1:
            ALOGE("Invalid camera id %d", cameraId);
 return BAD_VALUE;
 default:
            ALOGE("Unknown camera device HAL version: %d", deviceVersion);
 return INVALID_OPERATION;
 }

 status_t status = connectFinishUnsafe(client, client->getRemote());
 if (status != OK) {
 return status;
 }

        mProClientList[cameraId].push(client);

        LOG1("CameraService::connectPro X (id %d, this pid is %d)", cameraId,
                getpid());
 }
    device = client;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundPool::resume(int channelID)
{
    ALOGV("resume(%d)", channelID);
 Mutex::Autolock lock(&mLock);
 SoundChannel* channel = findChannel(channelID);
 if (channel) {
        channel->resume();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int32_t SampleTable::CompositionDeltaLookup::getCompositionTimeOffset(
 uint32_t sampleIndex) {
 Mutex::Autolock autolock(mLock);

 if (mDeltaEntries == NULL) {
 return 0;
 }

 if (sampleIndex < mCurrentEntrySampleIndex) {
        mCurrentDeltaEntry = 0;
        mCurrentEntrySampleIndex = 0;
 }

 while (mCurrentDeltaEntry < mNumDeltaEntries) {
 uint32_t sampleCount = mDeltaEntries[2 * mCurrentDeltaEntry];
 if (sampleIndex < mCurrentEntrySampleIndex + sampleCount) {
 return mDeltaEntries[2 * mCurrentDeltaEntry + 1];
 }

        mCurrentEntrySampleIndex += sampleCount;
 ++mCurrentDeltaEntry;
 }

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<FixedArrayBase> ConvertElementsWithCapacity(
 Handle<JSObject> object, Handle<FixedArrayBase> old_elements,
 ElementsKind from_kind, uint32_t capacity) {
 return ConvertElementsWithCapacity(
        object, old_elements, from_kind, capacity, 0, 0,
 ElementsAccessor::kCopyToEndAndInitializeToHole);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static EAS_RESULT Parse_insh (SDLS_SYNTHESIZER_DATA *pDLSData, EAS_I32 pos, EAS_U32 *pRgnCount, EAS_U32 *pLocale)
{
    EAS_RESULT result;
    EAS_U32 bank;
    EAS_U32 program;

 /* seek to start of chunk */
 if ((result = EAS_HWFileSeek(pDLSData->hwInstData, pDLSData->fileHandle, pos)) != EAS_SUCCESS)
 return result;

 /* get the region count and locale */
 if ((result = EAS_HWGetDWord(pDLSData->hwInstData, pDLSData->fileHandle, pRgnCount, EAS_FALSE)) != EAS_SUCCESS)
 return result;
 if ((result = EAS_HWGetDWord(pDLSData->hwInstData, pDLSData->fileHandle, &bank, EAS_FALSE)) != EAS_SUCCESS)
 return result;
 if ((result = EAS_HWGetDWord(pDLSData->hwInstData, pDLSData->fileHandle, &program, EAS_FALSE)) != EAS_SUCCESS)
 return result;

 /* verify the parameters are valid */
 if (bank & 0x7fff8080)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_WARNING, "DLS bank number is out of range: %08lx\n", bank); */ }
        bank &= 0xff7f;
 }
 if (program > 127)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_WARNING, "DLS program number is out of range: %08lx\n", program); */ }
        program &= 0x7f;
 }

 /* save the program number */
 *pLocale = (bank << 8) | program;
 return EAS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual ~ExternalFrameBufferMD5Test() {
 if (md5_file_ != NULL)
      fclose(md5_file_);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlFatalErrMsgStrIntStr(xmlParserCtxtPtr ctxt, xmlParserErrors error,
 const char *msg, const xmlChar *str1, int val,
 const xmlChar *str2)
{
 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 if (ctxt != NULL)
	ctxt->errNo = error;
    __xmlRaiseError(NULL, NULL, NULL,
                    ctxt, NULL, XML_FROM_PARSER, error, XML_ERR_FATAL,
                    NULL, 0, (const char *) str1, (const char *) str2,
		    NULL, val, 0, msg, str1, val, str2);
 if (ctxt != NULL) {
	ctxt->wellFormed = 0;
 if (ctxt->recovery == 0)
	    ctxt->disableSAX = 1;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::isAppSwitchPendingLocked() {
 return mAppSwitchDueTime != LONG_LONG_MAX;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int main(int argc, char **argv) {
 FILE *infile = NULL;
 vpx_codec_ctx_t codec;
 vpx_codec_enc_cfg_t cfg;
 int frame_count = 0;
 vpx_image_t raw;
 vpx_codec_err_t res;
 VpxVideoInfo info = {0};
 VpxVideoWriter *writer = NULL;
 const VpxInterface *encoder = NULL;
 const int fps = 30; // TODO(dkovalev) add command line argument
 const int bitrate = 200; // kbit/s TODO(dkovalev) add command line argument
 int keyframe_interval = 0;

 const char *codec_arg = NULL;
 const char *width_arg = NULL;
 const char *height_arg = NULL;
 const char *infile_arg = NULL;
 const char *outfile_arg = NULL;
 const char *keyframe_interval_arg = NULL;

  exec_name = argv[0];

 if (argc < 7)
    die("Invalid number of arguments");

  codec_arg = argv[1];
  width_arg = argv[2];
  height_arg = argv[3];
  infile_arg = argv[4];
  outfile_arg = argv[5];
  keyframe_interval_arg = argv[6];

  encoder = get_vpx_encoder_by_name(codec_arg);
 if (!encoder)
     die("Unsupported codec.");

  info.codec_fourcc = encoder->fourcc;
  info.frame_width = strtol(width_arg, NULL, 0);
  info.frame_height = strtol(height_arg, NULL, 0);
  info.time_base.numerator = 1;
  info.time_base.denominator = fps;

 if (info.frame_width <= 0 ||
      info.frame_height <= 0 ||
 (info.frame_width % 2) != 0 ||
 (info.frame_height % 2) != 0) {
    die("Invalid frame size: %dx%d", info.frame_width, info.frame_height);
 }

 if (!vpx_img_alloc(&raw, VPX_IMG_FMT_I420, info.frame_width,
                                             info.frame_height, 1)) {
    die("Failed to allocate image.");
 }

  keyframe_interval = strtol(keyframe_interval_arg, NULL, 0);

   if (keyframe_interval < 0)
     die("Invalid keyframe interval value.");
 
  printf("Using %s\n", vpx_codec_iface_name(encoder->interface()));
 
  res = vpx_codec_enc_config_default(encoder->interface(), &cfg, 0);
   if (res)
     die_codec(&codec, "Failed to get default codec config.");
 
  cfg.g_w = info.frame_width;
  cfg.g_h = info.frame_height;
  cfg.g_timebase.num = info.time_base.numerator;
  cfg.g_timebase.den = info.time_base.denominator;
  cfg.rc_target_bitrate = bitrate;
  cfg.g_error_resilient = argc > 7 ? strtol(argv[7], NULL, 0) : 0;

  writer = vpx_video_writer_open(outfile_arg, kContainerIVF, &info);
 if (!writer)
    die("Failed to open %s for writing.", outfile_arg);


   if (!(infile = fopen(infile_arg, "rb")))
     die("Failed to open %s for reading.", infile_arg);
 
  if (vpx_codec_enc_init(&codec, encoder->interface(), &cfg, 0))
     die_codec(&codec, "Failed to initialize encoder");
 
   while (vpx_img_read(&raw, infile)) {
     int flags = 0;
     if (keyframe_interval > 0 && frame_count % keyframe_interval == 0)
       flags |= VPX_EFLAG_FORCE_KF;
     encode_frame(&codec, &raw, frame_count++, flags, writer);
   }
  encode_frame(&codec, NULL, -1, 0, writer);  // flush the encoder
 
   printf("\n");
   fclose(infile);
  printf("Processed %d frames.\n", frame_count);

  vpx_img_free(&raw);
 if (vpx_codec_destroy(&codec))
    die_codec(&codec, "Failed to destroy codec.");

  vpx_video_writer_close(writer);

 return EXIT_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: omx_vdec::omx_vdec(): m_error_propogated(false),
    m_state(OMX_StateInvalid),
    m_app_data(NULL),
    m_inp_mem_ptr(NULL),
    m_out_mem_ptr(NULL),
    input_flush_progress (false),
    output_flush_progress (false),
    input_use_buffer (false),
    output_use_buffer (false),
    ouput_egl_buffers(false),
    m_use_output_pmem(OMX_FALSE),
    m_out_mem_region_smi(OMX_FALSE),
    m_out_pvt_entry_pmem(OMX_FALSE),
    pending_input_buffers(0),
    pending_output_buffers(0),
    m_out_bm_count(0),
    m_inp_bm_count(0),
    m_inp_bPopulated(OMX_FALSE),
    m_out_bPopulated(OMX_FALSE),
    m_flags(0),
#ifdef _ANDROID_
    m_heap_ptr(NULL),
#endif
    m_inp_bEnabled(OMX_TRUE),
    m_out_bEnabled(OMX_TRUE),
    m_in_alloc_cnt(0),
    m_platform_list(NULL),
    m_platform_entry(NULL),
    m_pmem_info(NULL),
    h264_parser(NULL),
    arbitrary_bytes (true),
    psource_frame (NULL),
    pdest_frame (NULL),
    m_inp_heap_ptr (NULL),
    m_phdr_pmem_ptr(NULL),
    m_heap_inp_bm_count (0),
    codec_type_parse ((codec_type)0),
    first_frame_meta (true),
    frame_count (0),
    nal_count (0),
    nal_length(0),
    look_ahead_nal (false),
    first_frame(0),
    first_buffer(NULL),
    first_frame_size (0),
    m_device_file_ptr(NULL),
    m_vc1_profile((vc1_profile_type)0),
    h264_last_au_ts(LLONG_MAX),
    h264_last_au_flags(0),
    m_disp_hor_size(0),
    m_disp_vert_size(0),
    prev_ts(LLONG_MAX),
    rst_prev_ts(true),
    frm_int(0),
    in_reconfig(false),
    m_display_id(NULL),
    client_extradata(0),
    m_reject_avc_1080p_mp (0),
#ifdef _ANDROID_
    m_enable_android_native_buffers(OMX_FALSE),
    m_use_android_native_buffers(OMX_FALSE),
    iDivXDrmDecrypt(NULL),
#endif
    m_desc_buffer_ptr(NULL),
    secure_mode(false),
    m_other_extradata(NULL),
    m_profile(0),
    client_set_fps(false),
    m_last_rendered_TS(-1),
    m_queued_codec_config_count(0),
    secure_scaling_to_non_secure_opb(false)
{
 /* Assumption is that , to begin with , we have all the frames with decoder */
    DEBUG_PRINT_HIGH("In %u bit OMX vdec Constructor", (unsigned int)sizeof(long) * 8);
    memset(&m_debug,0,sizeof(m_debug));
#ifdef _ANDROID_
 char property_value[PROPERTY_VALUE_MAX] = {0};
    property_get("vidc.debug.level", property_value, "1");
    debug_level = atoi(property_value);
    property_value[0] = '\0';

    DEBUG_PRINT_HIGH("In OMX vdec Constructor");

    property_get("vidc.dec.debug.perf", property_value, "0");
    perf_flag = atoi(property_value);
 if (perf_flag) {
        DEBUG_PRINT_HIGH("vidc.dec.debug.perf is %d", perf_flag);
        dec_time.start();
        proc_frms = latency = 0;
 }
    prev_n_filled_len = 0;
    property_value[0] = '\0';
    property_get("vidc.dec.debug.ts", property_value, "0");
    m_debug_timestamp = atoi(property_value);
    DEBUG_PRINT_HIGH("vidc.dec.debug.ts value is %d",m_debug_timestamp);
 if (m_debug_timestamp) {
        time_stamp_dts.set_timestamp_reorder_mode(true);
        time_stamp_dts.enable_debug_print(true);
 }

    property_value[0] = '\0';
    property_get("vidc.dec.debug.concealedmb", property_value, "0");
    m_debug_concealedmb = atoi(property_value);
    DEBUG_PRINT_HIGH("vidc.dec.debug.concealedmb value is %d",m_debug_concealedmb);

    property_value[0] = '\0';
    property_get("vidc.dec.profile.check", property_value, "0");
    m_reject_avc_1080p_mp = atoi(property_value);
    DEBUG_PRINT_HIGH("vidc.dec.profile.check value is %d",m_reject_avc_1080p_mp);

    property_value[0] = '\0';
    property_get("vidc.dec.log.in", property_value, "0");
    m_debug.in_buffer_log = atoi(property_value);

    property_value[0] = '\0';
    property_get("vidc.dec.log.out", property_value, "0");
    m_debug.out_buffer_log = atoi(property_value);
    sprintf(m_debug.log_loc, "%s", BUFFER_LOG_LOC);

    property_value[0] = '\0';
    property_get("vidc.log.loc", property_value, "");
 if (*property_value)
        strlcpy(m_debug.log_loc, property_value, PROPERTY_VALUE_MAX);

    property_value[0] = '\0';
    property_get("vidc.dec.120fps.enabled", property_value, "0");

 if(atoi(property_value)) {
        DEBUG_PRINT_LOW("feature 120 FPS decode enabled");
        m_last_rendered_TS = 0;
 }

    property_value[0] = '\0';
    property_get("vidc.dec.debug.dyn.disabled", property_value, "0");
    m_disable_dynamic_buf_mode = atoi(property_value);
    DEBUG_PRINT_HIGH("vidc.dec.debug.dyn.disabled value is %d",m_disable_dynamic_buf_mode);

#endif
    memset(&m_cmp,0,sizeof(m_cmp));
    memset(&m_cb,0,sizeof(m_cb));
    memset (&drv_ctx,0,sizeof(drv_ctx));
    memset (&h264_scratch,0,sizeof (OMX_BUFFERHEADERTYPE));
    memset (m_hwdevice_name,0,sizeof(m_hwdevice_name));
    memset(m_demux_offsets, 0, ( sizeof(OMX_U32) * 8192) );
    memset(&m_custom_buffersize, 0, sizeof(m_custom_buffersize));
    m_demux_entries = 0;
    msg_thread_id = 0;
    async_thread_id = 0;
    msg_thread_created = false;
    async_thread_created = false;
#ifdef _ANDROID_ICS_
    memset(&native_buffer, 0 ,(sizeof(struct nativebuffer) * MAX_NUM_INPUT_OUTPUT_BUFFERS));
#endif
    memset(&drv_ctx.extradata_info, 0, sizeof(drv_ctx.extradata_info));

 /* invalidate m_frame_pack_arrangement */
    memset(&m_frame_pack_arrangement, 0, sizeof(OMX_QCOM_FRAME_PACK_ARRANGEMENT));
    m_frame_pack_arrangement.cancel_flag = 1;

    drv_ctx.timestamp_adjust = false;
    drv_ctx.video_driver_fd = -1;

     m_vendor_config.pData = NULL;
     pthread_mutex_init(&m_lock, NULL);
     pthread_mutex_init(&c_lock, NULL);
     sem_init(&m_cmd_lock,0,0);
     sem_init(&m_safe_flush, 0, 0);
     streaming[CAPTURE_PORT] =
        streaming[OUTPUT_PORT] = false;
#ifdef _ANDROID_
 char extradata_value[PROPERTY_VALUE_MAX] = {0};
    property_get("vidc.dec.debug.extradata", extradata_value, "0");
    m_debug_extradata = atoi(extradata_value);
    DEBUG_PRINT_HIGH("vidc.dec.debug.extradata value is %d",m_debug_extradata);
#endif
    m_fill_output_msg = OMX_COMPONENT_GENERATE_FTB;
    client_buffers.set_vdec_client(this);
    dynamic_buf_mode = false;
    out_dynamic_list = NULL;
    is_down_scalar_enabled = false;
    m_smoothstreaming_mode = false;
    m_smoothstreaming_width = 0;
    m_smoothstreaming_height = 0;
    is_q6_platform = false;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: unsigned venc_dev::venc_flush( unsigned port)
{
 struct v4l2_encoder_cmd enc;
    DEBUG_PRINT_LOW("in %s", __func__);

    enc.cmd = V4L2_ENC_QCOM_CMD_FLUSH;
    enc.flags = V4L2_QCOM_CMD_FLUSH_OUTPUT | V4L2_QCOM_CMD_FLUSH_CAPTURE;

 if (ioctl(m_nDriver_fd, VIDIOC_ENCODER_CMD, &enc)) {
        DEBUG_PRINT_ERROR("Flush Port (%d) Failed ", port);
 return -1;
 }

 return 0;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static rfc_slot_t *find_rfc_slot_by_id(uint32_t id) {
  assert(id != 0);

 for (size_t i = 0; i < ARRAY_SIZE(rfc_slots); ++i)
 if (rfc_slots[i].id == id)
 return &rfc_slots[i];

  LOG_ERROR("%s unable to find RFCOMM slot id: %d", __func__, id);
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftAMRWBEncoder::~SoftAMRWBEncoder() {
 if (mEncoderHandle != NULL) {
        CHECK_EQ(VO_ERR_NONE, mApiHandle->Uninit(mEncoderHandle));
        mEncoderHandle = NULL;
 }

 delete mApiHandle;
    mApiHandle = NULL;

 delete mMemOperator;
    mMemOperator = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t NuPlayer::GenericSource::selectTrack(size_t trackIndex, bool select) {
    ALOGV("%s track: %zu", select ? "select" : "deselect", trackIndex);
    sp<AMessage> msg = new AMessage(kWhatSelectTrack, id());
    msg->setInt32("trackIndex", trackIndex);
    msg->setInt32("select", select);

    sp<AMessage> response;
 status_t err = msg->postAndAwaitResponse(&response);
 if (err == OK && response != NULL) {
        CHECK(response->findInt32("err", &err));
 }

 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const BlockEntry* Segment::GetBlock(const CuePoint& cp,
 const CuePoint::TrackPosition& tp) {
 Cluster** const ii = m_clusters;
 Cluster** i = ii;

 const long count = m_clusterCount + m_clusterPreloadCount;

 Cluster** const jj = ii + count;
 Cluster** j = jj;

 while (i < j) {

 Cluster** const k = i + (j - i) / 2;
    assert(k < jj);

 Cluster* const pCluster = *k;
    assert(pCluster);


 const long long pos = pCluster->GetPosition();
    assert(pos >= 0);

 if (pos < tp.m_pos)
      i = k + 1;
 else if (pos > tp.m_pos)
      j = k;
 else
 return pCluster->GetEntry(cp, tp);
 }

  assert(i == j);

 Cluster* const pCluster = Cluster::Create(this, -1, tp.m_pos); //, -1);
 if (pCluster == NULL)
 return NULL;

 const ptrdiff_t idx = i - m_clusters;

 if (!PreloadCluster(pCluster, idx)) {
 delete pCluster;
 return NULL;
 }
  assert(m_clusters);
  assert(m_clusterPreloadCount > 0);
  assert(m_clusters[idx] == pCluster);

 return pCluster->GetEntry(cp, tp);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void EncoderTest::SetMode(TestMode mode) {
 switch (mode) {
 case kRealTime:
      deadline_ = VPX_DL_REALTIME;
 break;

 case kOnePassGood:
 case kTwoPassGood:
      deadline_ = VPX_DL_GOOD_QUALITY;
 break;

 case kOnePassBest:
 case kTwoPassBest:
      deadline_ = VPX_DL_BEST_QUALITY;
 break;

 default:
      ASSERT_TRUE(false) << "Unexpected mode " << mode;
 }

 if (mode == kTwoPassGood || mode == kTwoPassBest)
    passes_ = 2;
 else
    passes_ = 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void CopyDictionaryToDoubleElements(FixedArrayBase* from_base,
 uint32_t from_start,
 FixedArrayBase* to_base,
 uint32_t to_start,
 int raw_copy_size) {
 DisallowHeapAllocation no_allocation;
 SeededNumberDictionary* from = SeededNumberDictionary::cast(from_base);
 int copy_size = raw_copy_size;
 if (copy_size < 0) {
    DCHECK(copy_size == ElementsAccessor::kCopyToEnd ||
           copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole);
    copy_size = from->max_number_key() + 1 - from_start;
 if (raw_copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole) {
 for (int i = to_start + copy_size; i < to_base->length(); ++i) {
 FixedDoubleArray::cast(to_base)->set_the_hole(i);
 }
 }
 }
 if (copy_size == 0) return;
 FixedDoubleArray* to = FixedDoubleArray::cast(to_base);
 uint32_t to_length = to->length();
 if (to_start + copy_size > to_length) {
    copy_size = to_length - to_start;
 }
 Isolate* isolate = from->GetIsolate();
 for (int i = 0; i < copy_size; i++) {
 int entry = from->FindEntry(isolate, i + from_start);
 if (entry != SeededNumberDictionary::kNotFound) {
      to->set(i + to_start, from->ValueAt(entry)->Number());
 } else {
      to->set_the_hole(i + to_start);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool is_init_done(void) {
 return pth != -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  double VideoTrack::GetFrameRate() const { return m_rate; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftVPXEncoder::internalSetRoleParams(
 const OMX_PARAM_COMPONENTROLETYPE* role) {
 const char* roleText = (const char*)role->cRole;
 const size_t roleTextMaxSize = OMX_MAX_STRINGNAME_SIZE - 1;

 if (strncmp(roleText, "video_encoder.vp8", roleTextMaxSize)) {
        ALOGE("Unsupported component role");
 return OMX_ErrorBadParameter;
 }

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BufferQueueConsumer::detachBuffer(int slot) {
    ATRACE_CALL();
    ATRACE_BUFFER_INDEX(slot);
    BQ_LOGV("detachBuffer(C): slot %d", slot);
 Mutex::Autolock lock(mCore->mMutex);

 if (mCore->mIsAbandoned) {
        BQ_LOGE("detachBuffer(C): BufferQueue has been abandoned");
 return NO_INIT;
 }

 if (slot < 0 || slot >= BufferQueueDefs::NUM_BUFFER_SLOTS) {
        BQ_LOGE("detachBuffer(C): slot index %d out of range [0, %d)",
                slot, BufferQueueDefs::NUM_BUFFER_SLOTS);
 return BAD_VALUE;
 } else if (mSlots[slot].mBufferState != BufferSlot::ACQUIRED) {
        BQ_LOGE("detachBuffer(C): slot %d is not owned by the consumer "
 "(state = %d)", slot, mSlots[slot].mBufferState);
 return BAD_VALUE;
 }

    mCore->freeBufferLocked(slot);
    mCore->mDequeueCondition.broadcast();

 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint8_t rfc_parse_data(tRFC_MCB* p_mcb, MX_FRAME* p_frame, BT_HDR* p_buf) {
 uint8_t ead, eal, fcs;
 uint8_t* p_data = (uint8_t*)(p_buf + 1) + p_buf->offset;
 uint8_t* p_start = p_data;
 uint16_t len;

 if (p_buf->len < RFCOMM_CTRL_FRAME_LEN) {
    RFCOMM_TRACE_ERROR("Bad Length1: %d", p_buf->len);
 return (RFC_EVENT_BAD_FRAME);
 }

  RFCOMM_PARSE_CTRL_FIELD(ead, p_frame->cr, p_frame->dlci, p_data);
 if (!ead) {
    RFCOMM_TRACE_ERROR("Bad Address(EA must be 1)");

     return (RFC_EVENT_BAD_FRAME);
   }
   RFCOMM_PARSE_TYPE_FIELD(p_frame->type, p_frame->pf, p_data);
  RFCOMM_PARSE_LEN_FIELD(eal, len, p_data);
 
   p_buf->len -= (3 + !ead + !eal + 1); /* Additional 1 for FCS */
   p_buf->offset += (3 + !ead + !eal);

 /* handle credit if credit based flow control */
 if ((p_mcb->flow == PORT_FC_CREDIT) && (p_frame->type == RFCOMM_UIH) &&
 (p_frame->dlci != RFCOMM_MX_DLCI) && (p_frame->pf == 1)) {
    p_frame->credit = *p_data++;
    p_buf->len--;
    p_buf->offset++;
 } else
    p_frame->credit = 0;

 if (p_buf->len != len) {
    RFCOMM_TRACE_ERROR("Bad Length2 %d %d", p_buf->len, len);
 return (RFC_EVENT_BAD_FRAME);
 }

  fcs = *(p_data + len);

 /* All control frames that we are sending are sent with P=1, expect */
 /* reply with F=1 */
 /* According to TS 07.10 spec ivalid frames are discarded without */
 /* notification to the sender */
 switch (p_frame->type) {
 case RFCOMM_SABME:
 if (RFCOMM_FRAME_IS_RSP(p_mcb->is_initiator, p_frame->cr) ||
 !p_frame->pf || len || !RFCOMM_VALID_DLCI(p_frame->dlci) ||
 !rfc_check_fcs(RFCOMM_CTRL_FRAME_LEN, p_start, fcs)) {
        RFCOMM_TRACE_ERROR("Bad SABME");
 return (RFC_EVENT_BAD_FRAME);
 } else
 return (RFC_EVENT_SABME);

 case RFCOMM_UA:
 if (RFCOMM_FRAME_IS_CMD(p_mcb->is_initiator, p_frame->cr) ||
 !p_frame->pf || len || !RFCOMM_VALID_DLCI(p_frame->dlci) ||
 !rfc_check_fcs(RFCOMM_CTRL_FRAME_LEN, p_start, fcs)) {
        RFCOMM_TRACE_ERROR("Bad UA");
 return (RFC_EVENT_BAD_FRAME);
 } else
 return (RFC_EVENT_UA);

 case RFCOMM_DM:
 if (RFCOMM_FRAME_IS_CMD(p_mcb->is_initiator, p_frame->cr) || len ||
 !RFCOMM_VALID_DLCI(p_frame->dlci) ||
 !rfc_check_fcs(RFCOMM_CTRL_FRAME_LEN, p_start, fcs)) {
        RFCOMM_TRACE_ERROR("Bad DM");
 return (RFC_EVENT_BAD_FRAME);
 } else
 return (RFC_EVENT_DM);

 case RFCOMM_DISC:
 if (RFCOMM_FRAME_IS_RSP(p_mcb->is_initiator, p_frame->cr) ||
 !p_frame->pf || len || !RFCOMM_VALID_DLCI(p_frame->dlci) ||
 !rfc_check_fcs(RFCOMM_CTRL_FRAME_LEN, p_start, fcs)) {
        RFCOMM_TRACE_ERROR("Bad DISC");
 return (RFC_EVENT_BAD_FRAME);
 } else
 return (RFC_EVENT_DISC);

 case RFCOMM_UIH:
 if (!RFCOMM_VALID_DLCI(p_frame->dlci)) {
        RFCOMM_TRACE_ERROR("Bad UIH - invalid DLCI");
 return (RFC_EVENT_BAD_FRAME);
 } else if (!rfc_check_fcs(2, p_start, fcs)) {
        RFCOMM_TRACE_ERROR("Bad UIH - FCS");
 return (RFC_EVENT_BAD_FRAME);
 } else if (RFCOMM_FRAME_IS_RSP(p_mcb->is_initiator, p_frame->cr)) {
 /* we assume that this is ok to allow bad implementations to work */
        RFCOMM_TRACE_ERROR("Bad UIH - response");
 return (RFC_EVENT_UIH);
 } else
 return (RFC_EVENT_UIH);
 }

 return (RFC_EVENT_BAD_FRAME);
}

Labels: Yes
----------------lora model----------------
Response: /*junk*/</s>


Instruction: 
Input: int Downmix_Configure(downmix_module_t *pDwmModule, effect_config_t *pConfig, bool init) {

 downmix_object_t *pDownmixer = &pDwmModule->context;

 if (pConfig->inputCfg.samplingRate != pConfig->outputCfg.samplingRate
 || pConfig->outputCfg.channels != DOWNMIX_OUTPUT_CHANNELS
 || pConfig->inputCfg.format != AUDIO_FORMAT_PCM_16_BIT
 || pConfig->outputCfg.format != AUDIO_FORMAT_PCM_16_BIT) {
        ALOGE("Downmix_Configure error: invalid config");
 return -EINVAL;
 }

 if (&pDwmModule->config != pConfig) {
        memcpy(&pDwmModule->config, pConfig, sizeof(effect_config_t));
 }

 if (init) {
        pDownmixer->type = DOWNMIX_TYPE_FOLD;
        pDownmixer->apply_volume_correction = false;
        pDownmixer->input_channel_count = 8; // matches default input of AUDIO_CHANNEL_OUT_7POINT1
 } else {
 if (pConfig->inputCfg.channels == 0) {
            ALOGE("Downmix_Configure error: input channel mask can't be 0");
 return -EINVAL;
 }
        pDownmixer->input_channel_count =
                audio_channel_count_from_out_mask(pConfig->inputCfg.channels);
 }

 Downmix_Reset(pDownmixer, init);

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int equalizer_get_parameter(effect_context_t *context, effect_param_t *p,
 uint32_t *size)
{
 equalizer_context_t *eq_ctxt = (equalizer_context_t *)context;
 int voffset = ((p->psize - 1) / sizeof(int32_t) + 1) * sizeof(int32_t);
 int32_t *param_tmp = (int32_t *)p->data;
 int32_t param = *param_tmp++;
 int32_t param2;
 char *name;
 void *value = p->data + voffset;
 int i;

    ALOGV("%s", __func__);

    p->status = 0;

 switch (param) {
 case EQ_PARAM_NUM_BANDS:
 case EQ_PARAM_CUR_PRESET:
 case EQ_PARAM_GET_NUM_OF_PRESETS:
 case EQ_PARAM_BAND_LEVEL:
 case EQ_PARAM_GET_BAND:
 if (p->vsize < sizeof(int16_t))
           p->status = -EINVAL;
        p->vsize = sizeof(int16_t);
 break;

 case EQ_PARAM_LEVEL_RANGE:
 if (p->vsize < 2 * sizeof(int16_t))
            p->status = -EINVAL;
        p->vsize = 2 * sizeof(int16_t);
 break;
 case EQ_PARAM_BAND_FREQ_RANGE:
 if (p->vsize < 2 * sizeof(int32_t))
            p->status = -EINVAL;
        p->vsize = 2 * sizeof(int32_t);
 break;

 case EQ_PARAM_CENTER_FREQ:
 if (p->vsize < sizeof(int32_t))
            p->status = -EINVAL;
        p->vsize = sizeof(int32_t);
 break;

 case EQ_PARAM_GET_PRESET_NAME:
 break;

 case EQ_PARAM_PROPERTIES:
 if (p->vsize < (2 + NUM_EQ_BANDS) * sizeof(uint16_t))
            p->status = -EINVAL;
        p->vsize = (2 + NUM_EQ_BANDS) * sizeof(uint16_t);
 break;

 default:
        p->status = -EINVAL;
 }

 *size = sizeof(effect_param_t) + voffset + p->vsize;

 if (p->status != 0)
 return 0;

 switch (param) {
 case EQ_PARAM_NUM_BANDS:
	ALOGV("%s: EQ_PARAM_NUM_BANDS", __func__);
 *(uint16_t *)value = (uint16_t)NUM_EQ_BANDS;
 break;

 case EQ_PARAM_LEVEL_RANGE:
	ALOGV("%s: EQ_PARAM_LEVEL_RANGE", __func__);
 *(int16_t *)value = -1500;
 *((int16_t *)value + 1) = 1500;
 break;


     case EQ_PARAM_BAND_LEVEL:
 	ALOGV("%s: EQ_PARAM_BAND_LEVEL", __func__);
         param2 = *param_tmp;
        if (param2 >= NUM_EQ_BANDS) {
             p->status = -EINVAL;
             break;
         }
         *(int16_t *)value = (int16_t)equalizer_get_band_level(eq_ctxt, param2);
 break;


     case EQ_PARAM_CENTER_FREQ:
 	ALOGV("%s: EQ_PARAM_CENTER_FREQ", __func__);
         param2 = *param_tmp;
        if (param2 >= NUM_EQ_BANDS) {
           p->status = -EINVAL;
             break;
         }
         *(int32_t *)value = equalizer_get_center_frequency(eq_ctxt, param2);
 break;


     case EQ_PARAM_BAND_FREQ_RANGE:
 	ALOGV("%s: EQ_PARAM_BAND_FREQ_RANGE", __func__);
         param2 = *param_tmp;
        if (param2 >= NUM_EQ_BANDS) {
             p->status = -EINVAL;
            break;
         }
        equalizer_get_band_freq_range(eq_ctxt, param2, (uint32_t *)value,
 ((uint32_t *)value + 1));
 break;

 case EQ_PARAM_GET_BAND:
	ALOGV("%s: EQ_PARAM_GET_BAND", __func__);
        param2 = *param_tmp;
 *(uint16_t *)value = (uint16_t)equalizer_get_band(eq_ctxt, param2);
 break;

 case EQ_PARAM_CUR_PRESET:
	ALOGV("%s: EQ_PARAM_CUR_PRESET", __func__);
 *(uint16_t *)value = (uint16_t)equalizer_get_preset(eq_ctxt);
 break;

 case EQ_PARAM_GET_NUM_OF_PRESETS:
	ALOGV("%s: EQ_PARAM_GET_NUM_OF_PRESETS", __func__);
 *(uint16_t *)value = (uint16_t)equalizer_get_num_presets(eq_ctxt);
 break;

 case EQ_PARAM_GET_PRESET_NAME:
	ALOGV("%s: EQ_PARAM_GET_PRESET_NAME", __func__);
        param2 = *param_tmp;
	ALOGV("param2: %d", param2);
 if (param2 >= equalizer_get_num_presets(eq_ctxt)) {
            p->status = -EINVAL;
 break;
 }
        name = (char *)value;
        strlcpy(name, equalizer_get_preset_name(eq_ctxt, param2), p->vsize - 1);
        name[p->vsize - 1] = 0;
        p->vsize = strlen(name) + 1;
 break;

 case EQ_PARAM_PROPERTIES: {
	ALOGV("%s: EQ_PARAM_PROPERTIES", __func__);
 int16_t *prop = (int16_t *)value;
        prop[0] = (int16_t)equalizer_get_preset(eq_ctxt);
        prop[1] = (int16_t)NUM_EQ_BANDS;
 for (i = 0; i < NUM_EQ_BANDS; i++) {
            prop[2 + i] = (int16_t)equalizer_get_band_level(eq_ctxt, i);
 }
 } break;

 default:
        p->status = -EINVAL;
 break;
 }

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int uinput_create(char *name)
{
 struct uinput_dev dev;
 int fd, x = 0;

 
     for(x=0; x < MAX_UINPUT_PATHS; x++)
     {
        fd = open(uinput_dev_path[x], O_RDWR);
         if (fd < 0)
             continue;
         break;
 }
 if (x == MAX_UINPUT_PATHS) {
        BTIF_TRACE_ERROR("%s ERROR: uinput device open failed", __FUNCTION__);
 return -1;
 }
    memset(&dev, 0, sizeof(dev));
 if (name)
        strncpy(dev.name, name, UINPUT_MAX_NAME_SIZE-1);

    dev.id.bustype = BUS_BLUETOOTH;
    dev.id.vendor  = 0x0000;

     dev.id.product = 0x0000;
     dev.id.version = 0x0000;
 
    if (write(fd, &dev, sizeof(dev)) < 0) {
         BTIF_TRACE_ERROR("%s Unable to write device information", __FUNCTION__);
         close(fd);
         return -1;
     }
 
    ioctl(fd, UI_SET_EVBIT, EV_KEY);
    ioctl(fd, UI_SET_EVBIT, EV_REL);
    ioctl(fd, UI_SET_EVBIT, EV_SYN);
 
     for (x = 0; key_map[x].name != NULL; x++)
        ioctl(fd, UI_SET_KEYBIT, key_map[x].mapped_id);
 
    if (ioctl(fd, UI_DEV_CREATE, NULL) < 0) {
         BTIF_TRACE_ERROR("%s Unable to create uinput device", __FUNCTION__);
         close(fd);
         return -1;
 }
 return fd;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Track::GetLacing() const
{
    return m_info.lacing;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int vp8dx_get_raw_frame(VP8D_COMP *pbi, YV12_BUFFER_CONFIG *sd, int64_t *time_stamp, int64_t *time_end_stamp, vp8_ppflags_t *flags)
{
 int ret = -1;

 if (pbi->ready_for_new_data == 1)
 return ret;

 /* ie no raw frame to show!!! */
 if (pbi->common.show_frame == 0)
 return ret;

    pbi->ready_for_new_data = 1;
 *time_stamp = pbi->last_time_stamp;
 *time_end_stamp = 0;

#if CONFIG_POSTPROC
    ret = vp8_post_proc_frame(&pbi->common, sd, flags);
#else
 (void)flags;

 if (pbi->common.frame_to_show)
 {
 *sd = *pbi->common.frame_to_show;
        sd->y_width = pbi->common.Width;
        sd->y_height = pbi->common.Height;
        sd->uv_height = pbi->common.Height / 2;
        ret = 0;
 }
 else
 {
        ret = -1;
 }

#endif /*!CONFIG_POSTPROC*/
    vp8_clear_system_state();
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dump(int fd)
{
    btif_debug_dump(fd);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:      void CopyToOMX(const OMX_BUFFERHEADERTYPE *header) {
        if (!mIsBackup) {
             return;
         }
 
        memcpy(header->pBuffer + header->nOffset,
 (const OMX_U8 *)mMem->pointer() + header->nOffset,
                header->nFilledLen);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void CameraSource::ProxyListener::dataCallbackTimestamp(
 nsecs_t timestamp, int32_t msgType, const sp<IMemory>& dataPtr) {
    mSource->dataCallbackTimestamp(timestamp / 1000, msgType, dataPtr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_parse_part_mode_amp(cab_ctxt_t *ps_cabac, bitstrm_t *ps_bitstrm)
{
    WORD32 ctxt_idx = IHEVC_CAB_PART_MODE;
    WORD32 part_mode_idx;
    WORD32 part_mode;
    WORD32 bin;

    part_mode = 0;
    TRACE_CABAC_CTXT("part_mode", ps_cabac->u4_range, ctxt_idx);
    bin = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx++);

 if(!bin)
 {
        bin = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx++);
        part_mode_idx = bin;
        part_mode_idx <<= 1;

 /* Following takes of handling context increment for 3rd bin in part_mode */
 /* When AMP is enabled and the current is not min CB */
 /* Context for 3rd bin is 3 and not 2 */
        ctxt_idx += 1;

        bin = ihevcd_cabac_decode_bin(ps_cabac, ps_bitstrm, ctxt_idx);
        part_mode_idx |= bin;

        part_mode_idx <<= 1;
 if(!bin)
 {

            bin = ihevcd_cabac_decode_bypass_bin(ps_cabac, ps_bitstrm);
            part_mode_idx |= bin;
 }
        part_mode = gau1_part_mode_amp[part_mode_idx];
 }
 return part_mode;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ContentEncoding::GetEncryptionByIndex(unsigned long idx) const {
   const ptrdiff_t count = encryption_entries_end_ - encryption_entries_;
   assert(count >= 0);
 
 if (idx >= static_cast<unsigned long>(count))
 return NULL;

 return encryption_entries_[idx];
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::setDataSize(size_t size)
{
 status_t err;
    err = continueWrite(size);
 if (err == NO_ERROR) {
        mDataSize = size;
        ALOGV("setDataSize Setting data size of %p to %zu", this, mDataSize);
 }
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long VideoTrack::GetHeight() const { return m_height; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t allocateBuffer(
            node_id node, OMX_U32 port_index, size_t size,
            buffer_id *buffer, void **buffer_data) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt64(size);
        remote()->transact(ALLOC_BUFFER, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();
 *buffer_data = (void *)reply.readInt64();

 return err;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaRecorder::init()
{
    ALOGV("init");
 if (mMediaRecorder == NULL) {
        ALOGE("media recorder is not initialized yet");
 return INVALID_OPERATION;
 }
 if (!(mCurrentState & MEDIA_RECORDER_IDLE)) {
        ALOGE("init called in an invalid state(%d)", mCurrentState);
 return INVALID_OPERATION;
 }

 status_t ret = mMediaRecorder->init();
 if (OK != ret) {
        ALOGV("init failed: %d", ret);
        mCurrentState = MEDIA_RECORDER_ERROR;
 return ret;
 }

    ret = mMediaRecorder->setListener(this);
 if (OK != ret) {
        ALOGV("setListener failed: %d", ret);
        mCurrentState = MEDIA_RECORDER_ERROR;
 return ret;
 }

    mCurrentState = MEDIA_RECORDER_INITIALIZED;
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: write_lease(const struct interface *iface, const struct dhcp_message *dhcp)
{
 int fd;
 ssize_t bytes = sizeof(*dhcp);
 const uint8_t *p = dhcp->options;
 const uint8_t *e = p + sizeof(dhcp->options);
 uint8_t l;
 uint8_t o = 0;

 /* We don't write BOOTP leases */
 if (is_bootp(dhcp)) {
		unlink(iface->leasefile);
 return 0;
 }

	syslog(LOG_DEBUG, "%s: writing lease `%s'",
	    iface->name, iface->leasefile);

	fd = open(iface->leasefile, O_WRONLY | O_CREAT | O_TRUNC, 0444);
#ifdef ANDROID
 if (fd == -1 && errno == EACCES) {
 /* the lease file might have been created when dhcpcd was running as root */
		unlink(iface->leasefile);
		fd = open(iface->leasefile, O_WRONLY | O_CREAT | O_TRUNC, 0444);
 }
#endif
 if (fd == -1) {
		syslog(LOG_ERR, "%s: open: %m", iface->name);
 return -1;
 }

 /* Only write as much as we need */
 while (p < e) {
		o = *p;
 if (o == DHO_END) {
			bytes = p - (const uint8_t *)dhcp;
 break;
 }
		p++;
 if (o != DHO_PAD) {
			l = *p++;
			p += l;
 }
 }
	bytes = write(fd, dhcp, bytes);
	close(fd);
 return bytes;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static double digitize(double value, int depth, int do_round)
{
 /* 'value' is in the range 0 to 1, the result is the same value rounded to a
    * multiple of the digitization factor - 8 or 16 bits depending on both the
    * sample depth and the 'assume' setting.  Digitization is normally by

     * rounding and 'do_round' should be 1, if it is 0 the digitized value will
     * be truncated.
     */
   PNG_CONST unsigned int digitization_factor = (1U << depth) -1;
 
    /* Limiting the range is done as a convenience to the caller - it's easier to
     * do it once here than every time at the call site.
    */
 if (value <= 0)
      value = 0;

 else if (value >= 1)
      value = 1;

   value *= digitization_factor;
 if (do_round) value += .5;
 return floor(value)/digitization_factor;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: standard_height(png_const_structp pp, png_uint_32 id)
{
   png_uint_32 height = HEIGHT_FROM_ID(id);

 if (height == 0)
      height = transform_height(pp, COL_FROM_ID(id), DEPTH_FROM_ID(id));

 return height;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: UWORD32 ih264d_map_error(UWORD32 i4_err_status)
{
    UWORD32 temp = 0;

 switch(i4_err_status)
 {
 case ERROR_MEM_ALLOC_ISRAM_T:
 case ERROR_MEM_ALLOC_SDRAM_T:
 case ERROR_BUF_MGR:
 case ERROR_MB_GROUP_ASSGN_T:
 case ERROR_FRAME_LIMIT_OVER:
 case ERROR_ACTUAL_RESOLUTION_GREATER_THAN_INIT:
 case ERROR_PROFILE_NOT_SUPPORTED:
 case ERROR_INIT_NOT_DONE:
 case IVD_MEM_ALLOC_FAILED:
            temp = 1 << IVD_FATALERROR;
            H264_DEC_DEBUG_PRINT("\nFatal Error\n");
 break;

 case ERROR_DBP_MANAGER_T:
 case ERROR_GAPS_IN_FRM_NUM:
 case ERROR_UNKNOWN_NAL:
 case ERROR_INV_MB_SLC_GRP_T:
 case ERROR_MULTIPLE_SLC_GRP_T:
 case ERROR_UNKNOWN_LEVEL:
 case ERROR_UNAVAIL_PICBUF_T:
 case ERROR_UNAVAIL_MVBUF_T:
 case ERROR_UNAVAIL_DISPBUF_T:
 case ERROR_NUM_REF:
 case ERROR_REFIDX_ORDER_T:
 case ERROR_PIC0_NOT_FOUND_T:
 case ERROR_MB_TYPE:
 case ERROR_SUB_MB_TYPE:
 case ERROR_CBP:
 case ERROR_REF_IDX:
 case ERROR_NUM_MV:
 case ERROR_CHROMA_PRED_MODE:
 case ERROR_INTRAPRED:
 case ERROR_NEXT_MB_ADDRESS_T:
 case ERROR_MB_ADDRESS_T:
 case ERROR_PIC1_NOT_FOUND_T:
 case ERROR_CAVLC_NUM_COEFF_T:
 case ERROR_CAVLC_SCAN_POS_T:
 case ERROR_PRED_WEIGHT_TABLE_T:
 case ERROR_CORRUPTED_SLICE:
            temp = 1 << IVD_CORRUPTEDDATA;
 break;

 case ERROR_NOT_SUPP_RESOLUTION:
 case ERROR_FEATURE_UNAVAIL:
 case ERROR_ACTUAL_LEVEL_GREATER_THAN_INIT:
            temp = 1 << IVD_UNSUPPORTEDINPUT;
 break;

 case ERROR_INVALID_PIC_PARAM:
 case ERROR_INVALID_SEQ_PARAM:
 case ERROR_EGC_EXCEED_32_1_T:
 case ERROR_EGC_EXCEED_32_2_T:
 case ERROR_INV_RANGE_TEV_T:
 case ERROR_INV_SLC_TYPE_T:
 case ERROR_INV_POC_TYPE_T:
 case ERROR_INV_RANGE_QP_T:
 case ERROR_INV_SPS_PPS_T:
 case ERROR_INV_SLICE_HDR_T:
            temp = 1 << IVD_CORRUPTEDHEADER;
 break;

 case ERROR_EOB_FLUSHBITS_T:
 case ERROR_EOB_GETBITS_T:
 case ERROR_EOB_GETBIT_T:
 case ERROR_EOB_BYPASS_T:
 case ERROR_EOB_DECISION_T:
 case ERROR_EOB_TERMINATE_T:
 case ERROR_EOB_READCOEFF4X4CAB_T:
            temp = 1 << IVD_INSUFFICIENTDATA;
 break;
 case ERROR_DYNAMIC_RESOLUTION_NOT_SUPPORTED:
 case ERROR_DISP_WIDTH_RESET_TO_PIC_WIDTH:
            temp = 1 << IVD_UNSUPPORTEDPARAM | 1 << IVD_FATALERROR;
 break;

 case ERROR_DANGLING_FIELD_IN_PIC:
            temp = 1 << IVD_APPLIEDCONCEALMENT;
 break;

 }

 return temp;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_sei_payload(dec_bit_stream_t *ps_bitstrm,
                                UWORD32 ui4_payload_type,
                                UWORD32 ui4_payload_size,
 dec_struct_t *ps_dec)
{
    sei *ps_sei;
    WORD32 i4_status = 0;
    ps_sei = (sei *)ps_dec->ps_sei;
 switch(ui4_payload_type)
 {
 case SEI_BUF_PERIOD:

            i4_status = ih264d_parse_buffering_period(&ps_sei->s_buf_period,
                                                      ps_bitstrm, ps_dec);
 /*if(i4_status != OK)
                return i4_status;*/
 break;
 case SEI_PIC_TIMING:
 if(NULL == ps_dec->ps_cur_sps)
                ih264d_flush_bits_h264(ps_bitstrm, (ui4_payload_size << 3));
 else
                ih264d_parse_pic_timing(ps_bitstrm, ps_dec,
                                        ui4_payload_size);
 break;
 case SEI_RECOVERY_PT:
            ih264d_parse_recovery_point(ps_bitstrm, ps_dec,
                                        ui4_payload_size);
 break;
 default:
            ih264d_flush_bits_h264(ps_bitstrm, (ui4_payload_size << 3));
 break;
 }
 return (i4_status);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void SetTopUnavailable() {
    mbptr_->up_available = 0;
 for (int p = 0; p < num_planes_; p++)
      memset(&data_ptr_[p][-1 - stride_], 127, block_size_ + 2);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::fill_buffer_done(OMX_HANDLETYPE hComp,
        OMX_BUFFERHEADERTYPE * buffer)
{
    OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO *pPMEMInfo = NULL;
 if (!buffer || (buffer - m_out_mem_ptr) >= (int)drv_ctx.op_buf.actualcount) {
        DEBUG_PRINT_ERROR("[FBD] ERROR in ptr(%p)", buffer);
 return OMX_ErrorBadParameter;
 } else if (output_flush_progress) {
        DEBUG_PRINT_LOW("FBD: Buffer (%p) flushed", buffer);
        buffer->nFilledLen = 0;
        buffer->nTimeStamp = 0;
        buffer->nFlags &= ~OMX_BUFFERFLAG_EXTRADATA;
        buffer->nFlags &= ~QOMX_VIDEO_BUFFERFLAG_EOSEQ;
        buffer->nFlags &= ~OMX_BUFFERFLAG_DATACORRUPT;
 }

 if (m_debug_extradata) {
 if (buffer->nFlags & QOMX_VIDEO_BUFFERFLAG_EOSEQ) {
            DEBUG_PRINT_HIGH("***************************************************");
            DEBUG_PRINT_HIGH("FillBufferDone: End Of Sequence Received");
            DEBUG_PRINT_HIGH("***************************************************");
 }

 if (buffer->nFlags & OMX_BUFFERFLAG_DATACORRUPT) {
            DEBUG_PRINT_HIGH("***************************************************");
            DEBUG_PRINT_HIGH("FillBufferDone: OMX_BUFFERFLAG_DATACORRUPT Received");
            DEBUG_PRINT_HIGH("***************************************************");
 }
 }


    DEBUG_PRINT_LOW("fill_buffer_done: bufhdr = %p, bufhdr->pBuffer = %p",
            buffer, buffer->pBuffer);
    pending_output_buffers --;

 if (buffer->nFlags & OMX_BUFFERFLAG_EOS) {
        DEBUG_PRINT_HIGH("Output EOS has been reached");
 if (!output_flush_progress)
            post_event((unsigned)NULL, (unsigned)NULL,
                    OMX_COMPONENT_GENERATE_EOS_DONE);

 if (psource_frame) {
            m_cb.EmptyBufferDone(&m_cmp, m_app_data, psource_frame);
            psource_frame = NULL;
 }
 if (pdest_frame) {
            pdest_frame->nFilledLen = 0;
            m_input_free_q.insert_entry((unsigned long) pdest_frame,(unsigned)NULL,
 (unsigned)NULL);
            pdest_frame = NULL;
 }
 }

 if (!output_flush_progress && (buffer->nFilledLen > 0)) {
        DEBUG_PRINT_LOW("Processing extradata");
        handle_extradata(buffer);
 }

#ifdef OUTPUT_EXTRADATA_LOG
 if (outputExtradataFile) {
 int buf_index = buffer - m_out_mem_ptr;
        OMX_U8 *pBuffer = (OMX_U8 *)(drv_ctx.ptr_outputbuffer[buf_index].bufferaddr);

        OMX_OTHER_EXTRADATATYPE *p_extra = NULL;
        p_extra = (OMX_OTHER_EXTRADATATYPE *)
 ((unsigned long)(pBuffer + buffer->nOffset + buffer->nFilledLen + 3)&(~3));

 while (p_extra && (OMX_U8*)p_extra < (pBuffer + buffer->nAllocLen) ) {
            DEBUG_PRINT_LOW("WRITING extradata, size=%d,type=%x",
                                    p_extra->nSize, p_extra->eType);
            fwrite (p_extra,1,p_extra->nSize,outputExtradataFile);

 if (p_extra->eType == OMX_ExtraDataNone) {
 break;
 }
            p_extra = (OMX_OTHER_EXTRADATATYPE *) (((OMX_U8 *) p_extra) + p_extra->nSize);
 }
 }
#endif

 /* For use buffer we need to copy the data */
 if (!output_flush_progress) {
 /* This is the error check for non-recoverable errros */
 bool is_duplicate_ts_valid = true;
 bool is_interlaced = (drv_ctx.interlace != VDEC_InterlaceFrameProgressive);

 if (output_capability == V4L2_PIX_FMT_MPEG4 ||
                output_capability == V4L2_PIX_FMT_MPEG2 ||
                output_capability == V4L2_PIX_FMT_DIVX ||
                output_capability == V4L2_PIX_FMT_DIVX_311)
            is_duplicate_ts_valid = false;

 if ((output_capability == V4L2_PIX_FMT_H264 ||
                output_capability == V4L2_PIX_FMT_H264_MVC) &&
                is_interlaced) {
 if (buffer->nFlags & QOMX_VIDEO_BUFFERFLAG_MBAFF) {
                is_interlaced = false;
 }
 }

 if (buffer->nFilledLen > 0) {
            time_stamp_dts.get_next_timestamp(buffer,
                    is_interlaced && is_duplicate_ts_valid);
 if (m_debug_timestamp) {
 {
                    OMX_TICKS expected_ts = 0;
                    m_timestamp_list.pop_min_ts(expected_ts);
 if (is_interlaced && is_duplicate_ts_valid) {
                        m_timestamp_list.pop_min_ts(expected_ts);
 }
                    DEBUG_PRINT_LOW("Current timestamp (%lld),Popped TIMESTAMP (%lld) from list",
                            buffer->nTimeStamp, expected_ts);

 if (buffer->nTimeStamp != expected_ts) {
                        DEBUG_PRINT_ERROR("ERROR in omx_vdec::async_message_process timestamp Check");
 }
 }
 }
 }
 }

 /* Since we're passing around handles, adjust nFilledLen and nAllocLen
     * to size of the handle.  Do it _after_ handle_extradata() which
     * requires the respective sizes to be accurate. */
 if (dynamic_buf_mode) {
        buffer->nAllocLen = sizeof(struct VideoDecoderOutputMetaData);
        buffer->nFilledLen = buffer->nFilledLen ?
 sizeof(struct VideoDecoderOutputMetaData) : 0;
 }
 if (m_cb.FillBufferDone) {
 if (buffer->nFilledLen > 0) {
 if (arbitrary_bytes)
                adjust_timestamp(buffer->nTimeStamp);
 else
                set_frame_rate(buffer->nTimeStamp);

 if (perf_flag) {
 if (!proc_frms) {
                    dec_time.stop();
                    latency = dec_time.processing_time_us() - latency;
                    DEBUG_PRINT_HIGH(">>> FBD Metrics: Latency(%.2f)mS", latency / 1e3);
                    dec_time.start();
                    fps_metrics.start();
 }
                proc_frms++;
 if (buffer->nFlags & OMX_BUFFERFLAG_EOS) {
                    OMX_U64 proc_time = 0;
                    fps_metrics.stop();
                    proc_time = fps_metrics.processing_time_us();
                    DEBUG_PRINT_HIGH(">>> FBD Metrics: proc_frms(%u) proc_time(%.2f)S fps(%.2f)",
 (unsigned int)proc_frms, (float)proc_time / 1e6,
 (float)(1e6 * proc_frms) / proc_time);
                    proc_frms = 0;
 }
 }
 }
 if (buffer->nFlags & OMX_BUFFERFLAG_EOS) {
            prev_ts = LLONG_MAX;
            rst_prev_ts = true;
 }

        pPMEMInfo = (OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO *)
 ((OMX_QCOM_PLATFORM_PRIVATE_LIST *)
             buffer->pPlatformPrivate)->entryList->entry;
        DEBUG_PRINT_LOW("Before FBD callback Accessed Pmeminfo %lu",pPMEMInfo->pmem_fd);
        OMX_BUFFERHEADERTYPE *il_buffer;
        il_buffer = client_buffers.get_il_buf_hdr(buffer);

 if (il_buffer && m_last_rendered_TS >= 0) {
 int current_framerate = (int)(drv_ctx.frame_rate.fps_numerator /drv_ctx.frame_rate.fps_denominator);
            OMX_TICKS ts_delta = (OMX_TICKS)llabs(il_buffer->nTimeStamp - m_last_rendered_TS);


 if(current_framerate <= 60 || m_last_rendered_TS == 0 ||
               il_buffer->nTimeStamp == 0 || ts_delta >= 16000 ||
               ts_delta == 0 || (il_buffer->nFlags & OMX_BUFFERFLAG_EOS)) {
               m_last_rendered_TS = il_buffer->nTimeStamp;
 } else {
               buffer->nFilledLen = 0;
 }

            DEBUG_PRINT_LOW(" -- %s Frame -- info:: fps(%d) lastRenderTime(%lld) bufferTs(%lld) ts_delta(%lld)",
                              buffer->nFilledLen? "Rendering":"Dropping",current_framerate,m_last_rendered_TS,
                              il_buffer->nTimeStamp,ts_delta);
 }

 if (il_buffer) {
            log_output_buffers(il_buffer);
 if (dynamic_buf_mode) {
 unsigned int nPortIndex = 0;
                nPortIndex = buffer-((OMX_BUFFERHEADERTYPE *)client_buffers.get_il_buf_hdr());

 if (!secure_mode) {
                    munmap(drv_ctx.ptr_outputbuffer[nPortIndex].bufferaddr,
                        drv_ctx.ptr_outputbuffer[nPortIndex].mmaped_size);
 }

                native_buffer[nPortIndex].privatehandle = NULL;
                native_buffer[nPortIndex].nativehandle = NULL;
 }
            m_cb.FillBufferDone (hComp,m_app_data,il_buffer);
 } else {
            DEBUG_PRINT_ERROR("Invalid buffer address from get_il_buf_hdr");
 return OMX_ErrorBadParameter;
 }
        DEBUG_PRINT_LOW("After Fill Buffer Done callback %lu",pPMEMInfo->pmem_fd);
 } else {
 return OMX_ErrorBadParameter;
 }

#ifdef ADAPTIVE_PLAYBACK_SUPPORTED
 if (m_smoothstreaming_mode && m_out_mem_ptr) {
        OMX_U32 buf_index = buffer - m_out_mem_ptr;
 BufferDim_t dim;
 private_handle_t *private_handle = NULL;
        dim.sliceWidth = framesize.nWidth;
        dim.sliceHeight = framesize.nHeight;
 if (native_buffer[buf_index].privatehandle)
            private_handle = native_buffer[buf_index].privatehandle;
 if (private_handle) {
            DEBUG_PRINT_LOW("set metadata: update buf-geometry with stride %d slice %d",
                dim.sliceWidth, dim.sliceHeight);
            setMetaData(private_handle, UPDATE_BUFFER_GEOMETRY, (void*)&dim);
 }
 }
#endif

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: int readpng2_decode_data(mainprog_info *mainprog_ptr, uch *rawbuf, ulg length)
{
    png_structp png_ptr = (png_structp)mainprog_ptr->png_ptr;
    png_infop info_ptr = (png_infop)mainprog_ptr->info_ptr;


 /* setjmp() must be called in every function that calls a PNG-reading
     * libpng function */

 if (setjmp(mainprog_ptr->jmpbuf)) {
        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);
        mainprog_ptr->png_ptr = NULL;
        mainprog_ptr->info_ptr = NULL;
 return 2;
 }


 /* hand off the next chunk of input data to libpng for decoding */

    png_process_data(png_ptr, info_ptr, rawbuf, length);

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtReset(xmlParserCtxtPtr ctxt)
{
    xmlParserInputPtr input;
    xmlDictPtr dict;

 if (ctxt == NULL)
 return;

    dict = ctxt->dict;

 while ((input = inputPop(ctxt)) != NULL) { /* Non consuming */
        xmlFreeInputStream(input);
 }
    ctxt->inputNr = 0;
    ctxt->input = NULL;

    ctxt->spaceNr = 0;
 if (ctxt->spaceTab != NULL) {
	ctxt->spaceTab[0] = -1;
	ctxt->space = &ctxt->spaceTab[0];
 } else {
        ctxt->space = NULL;
 }


    ctxt->nodeNr = 0;
    ctxt->node = NULL;

    ctxt->nameNr = 0;
    ctxt->name = NULL;

    DICT_FREE(ctxt->version);
    ctxt->version = NULL;
    DICT_FREE(ctxt->encoding);
    ctxt->encoding = NULL;
    DICT_FREE(ctxt->directory);
    ctxt->directory = NULL;
    DICT_FREE(ctxt->extSubURI);
    ctxt->extSubURI = NULL;
    DICT_FREE(ctxt->extSubSystem);
    ctxt->extSubSystem = NULL;
 if (ctxt->myDoc != NULL)
        xmlFreeDoc(ctxt->myDoc);
    ctxt->myDoc = NULL;

    ctxt->standalone = -1;
    ctxt->hasExternalSubset = 0;
    ctxt->hasPErefs = 0;
    ctxt->html = 0;
    ctxt->external = 0;
    ctxt->instate = XML_PARSER_START;
    ctxt->token = 0;

    ctxt->wellFormed = 1;
    ctxt->nsWellFormed = 1;
    ctxt->disableSAX = 0;
    ctxt->valid = 1;
#if 0
    ctxt->vctxt.userData = ctxt;
    ctxt->vctxt.error = xmlParserValidityError;
    ctxt->vctxt.warning = xmlParserValidityWarning;
#endif
    ctxt->record_info = 0;
    ctxt->nbChars = 0;
    ctxt->checkIndex = 0;
    ctxt->inSubset = 0;
    ctxt->errNo = XML_ERR_OK;
    ctxt->depth = 0;
    ctxt->charset = XML_CHAR_ENCODING_UTF8;
    ctxt->catalogs = NULL;
    ctxt->nbentities = 0;
    ctxt->sizeentities = 0;
    ctxt->sizeentcopy = 0;
    xmlInitNodeInfoSeq(&ctxt->node_seq);

 if (ctxt->attsDefault != NULL) {
        xmlHashFree(ctxt->attsDefault, (xmlHashDeallocator) xmlFree);
        ctxt->attsDefault = NULL;
 }
 if (ctxt->attsSpecial != NULL) {
        xmlHashFree(ctxt->attsSpecial, NULL);
        ctxt->attsSpecial = NULL;
 }

#ifdef LIBXML_CATALOG_ENABLED
 if (ctxt->catalogs != NULL)
	xmlCatalogFreeLocal(ctxt->catalogs);
#endif
 if (ctxt->lastError.code != XML_ERR_OK)
        xmlResetError(&ctxt->lastError);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dut_mode_cback( tBTM_VSC_CMPL *p )
{
    UNUSED(p);
 /* For now nothing to be done. */
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SimpleSoftOMXComponent::getParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 Mutex::Autolock autoLock(mLock);
 return internalGetParameter(index, params);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<JSArray> SpliceImpl(Handle<JSArray> receiver,
 uint32_t start, uint32_t delete_count,
 Arguments* args, uint32_t add_count) {
 Isolate* isolate = receiver->GetIsolate();
 Heap* heap = isolate->heap();
 uint32_t length = Smi::cast(receiver->length())->value();
 uint32_t new_length = length - delete_count + add_count;

 ElementsKind kind = KindTraits::Kind;
 if (new_length <= static_cast<uint32_t>(receiver->elements()->length()) &&
 IsFastSmiOrObjectElementsKind(kind)) {
 HandleScope scope(isolate);
 JSObject::EnsureWritableFastElements(receiver);
 }

 Handle<FixedArrayBase> backing_store(receiver->elements(), isolate);

 if (new_length == 0) {
      receiver->set_elements(heap->empty_fixed_array());
      receiver->set_length(Smi::kZero);
 return isolate->factory()->NewJSArrayWithElements(
          backing_store, KindTraits::Kind, delete_count);
 }

 Handle<JSArray> deleted_elements = isolate->factory()->NewJSArray(
 KindTraits::Kind, delete_count, delete_count);
 if (delete_count > 0) {
 DisallowHeapAllocation no_gc;
 Subclass::CopyElementsImpl(*backing_store, start,
                                 deleted_elements->elements(), KindTraits::Kind,
 0, kPackedSizeNotKnown, delete_count);
 }

 if (add_count < delete_count) {
 Subclass::SpliceShrinkStep(isolate, receiver, backing_store, start,
                                 delete_count, add_count, length, new_length);
 } else if (add_count > delete_count) {
      backing_store =
 Subclass::SpliceGrowStep(isolate, receiver, backing_store, start,
                                   delete_count, add_count, length, new_length);
 }

 Subclass::CopyArguments(args, backing_store, add_count, 3, start);

    receiver->set_length(Smi::FromInt(new_length));
 Subclass::TryTransitionResultArrayToPacked(deleted_elements);
 return deleted_elements;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MediaPlayer::clear_l()
{
    mCurrentPosition = -1;
    mSeekPosition = -1;
    mVideoWidth = mVideoHeight = 0;
    mRetransmitEndpointValid = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t vp8_get_si(vpx_codec_alg_priv_t *ctx,
 vpx_codec_stream_info_t *si)
{

 unsigned int sz;

 if (si->sz >= sizeof(vp8_stream_info_t))
        sz = sizeof(vp8_stream_info_t);
 else
        sz = sizeof(vpx_codec_stream_info_t);

    memcpy(si, &ctx->si, sz);
    si->sz = sz;

 return VPX_CODEC_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: get_option_addr(struct in_addr *a, const struct dhcp_message *dhcp,
 uint8_t option)
{
 const uint8_t *p = get_option_raw(dhcp, option);

 if (!p)
 return -1;
	memcpy(&a->s_addr, p, sizeof(a->s_addr));
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: camera_metadata_t* copy_camera_metadata(void *dst, size_t dst_size,
 const camera_metadata_t *src) {
 size_t memory_needed = get_camera_metadata_compact_size(src);

 if (dst == NULL) return NULL;
 if (dst_size < memory_needed) return NULL;

 camera_metadata_t *metadata =
        place_camera_metadata(dst, dst_size, src->entry_count, src->data_count);

    metadata->flags = src->flags;
    metadata->entry_count = src->entry_count;
    metadata->data_count = src->data_count;

    memcpy(get_entries(metadata), get_entries(src),
 sizeof(camera_metadata_buffer_entry_t[metadata->entry_count]));
    memcpy(get_data(metadata), get_data(src),
 sizeof(uint8_t[metadata->data_count]));

    assert(validate_camera_metadata_structure(metadata, NULL) == OK);
 return metadata;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::InjectionState::release() {
    refCount -= 1;
 if (refCount == 0) {
 delete this;
 } else {
        ALOG_ASSERT(refCount > 0);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static IV_API_CALL_STATUS_T api_check_struct_sanity(iv_obj_t *ps_handle,
 void *pv_api_ip,
 void *pv_api_op)
{
    IVD_API_COMMAND_TYPE_T e_cmd;
    UWORD32 *pu4_api_ip;
    UWORD32 *pu4_api_op;
    WORD32 i;

 if(NULL == pv_api_op)
 return (IV_FAIL);

 if(NULL == pv_api_ip)
 return (IV_FAIL);

    pu4_api_ip = (UWORD32 *)pv_api_ip;
    pu4_api_op = (UWORD32 *)pv_api_op;
    e_cmd = (IVD_API_COMMAND_TYPE_T)*(pu4_api_ip + 1);

 *(pu4_api_op + 1) = 0;
 /* error checks on handle */
 switch((WORD32)e_cmd)
 {
 case IVD_CMD_CREATE:
 break;

 case IVD_CMD_REL_DISPLAY_FRAME:
 case IVD_CMD_SET_DISPLAY_FRAME:
 case IVD_CMD_GET_DISPLAY_FRAME:
 case IVD_CMD_VIDEO_DECODE:
 case IVD_CMD_DELETE:
 case IVD_CMD_VIDEO_CTL:
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }


 if(ps_handle->pv_codec_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }
 break;
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_API_CMD;
 return IV_FAIL;
 }

 switch((WORD32)e_cmd)
 {
 case IVD_CMD_CREATE:
 {
 ihevcd_cxa_create_ip_t *ps_ip = (ihevcd_cxa_create_ip_t *)pv_api_ip;
 ihevcd_cxa_create_op_t *ps_op = (ihevcd_cxa_create_op_t *)pv_api_op;


            ps_op->s_ivd_create_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_create_ip_t.u4_size > sizeof(ihevcd_cxa_create_ip_t))
 || (ps_ip->s_ivd_create_ip_t.u4_size
 < sizeof(ivd_create_ip_t)))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;

 return (IV_FAIL);
 }

 if((ps_op->s_ivd_create_op_t.u4_size != sizeof(ihevcd_cxa_create_op_t))
 && (ps_op->s_ivd_create_op_t.u4_size
 != sizeof(ivd_create_op_t)))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;

 return (IV_FAIL);
 }


 if((ps_ip->s_ivd_create_ip_t.e_output_format != IV_YUV_420P)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_422ILE)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_RGB_565)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_420SP_UV)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_420SP_VU))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_INIT_DEC_COL_FMT_NOT_SUPPORTED;

 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_GET_DISPLAY_FRAME:
 {
 ihevcd_cxa_get_display_frame_ip_t *ps_ip =
 (ihevcd_cxa_get_display_frame_ip_t *)pv_api_ip;
 ihevcd_cxa_get_display_frame_op_t *ps_op =
 (ihevcd_cxa_get_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_get_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ihevcd_cxa_get_display_frame_ip_t))
 && (ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ivd_get_display_frame_ip_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ihevcd_cxa_get_display_frame_op_t))
 && (ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ivd_get_display_frame_op_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_REL_DISPLAY_FRAME:
 {
 ihevcd_cxa_rel_display_frame_ip_t *ps_ip =
 (ihevcd_cxa_rel_display_frame_ip_t *)pv_api_ip;
 ihevcd_cxa_rel_display_frame_op_t *ps_op =
 (ihevcd_cxa_rel_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_rel_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ihevcd_cxa_rel_display_frame_ip_t))
 && (ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ivd_rel_display_frame_ip_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ihevcd_cxa_rel_display_frame_op_t))
 && (ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ivd_rel_display_frame_op_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_SET_DISPLAY_FRAME:
 {
 ihevcd_cxa_set_display_frame_ip_t *ps_ip =
 (ihevcd_cxa_set_display_frame_ip_t *)pv_api_ip;
 ihevcd_cxa_set_display_frame_op_t *ps_op =
 (ihevcd_cxa_set_display_frame_op_t *)pv_api_op;
            UWORD32 j;

            ps_op->s_ivd_set_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ihevcd_cxa_set_display_frame_ip_t))
 && (ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ivd_set_display_frame_ip_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ihevcd_cxa_set_display_frame_op_t))
 && (ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ivd_set_display_frame_op_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs == 0)
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(j = 0; j < ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs;
                            j++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs
 == 0)
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                    IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0;
                                i
 < (WORD32)ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs;
                                i++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].pu1_bufs[i]
 == NULL)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_min_out_buf_size[i]
 == 0)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_DECODE:
 {
 ihevcd_cxa_video_decode_ip_t *ps_ip =
 (ihevcd_cxa_video_decode_ip_t *)pv_api_ip;
 ihevcd_cxa_video_decode_op_t *ps_op =
 (ihevcd_cxa_video_decode_op_t *)pv_api_op;

            DEBUG("The input bytes is: %d",
                            ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes);
            ps_op->s_ivd_video_decode_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_video_decode_ip_t.u4_size
 != sizeof(ihevcd_cxa_video_decode_ip_t)
 && ps_ip->s_ivd_video_decode_ip_t.u4_size
 != offsetof(ivd_video_decode_ip_t,
                                                        s_out_buffer))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_video_decode_op_t.u4_size
 != sizeof(ihevcd_cxa_video_decode_op_t)
 && ps_op->s_ivd_video_decode_op_t.u4_size
 != offsetof(ivd_video_decode_op_t,
                                                        u4_output_present))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_DELETE:
 {
 ihevcd_cxa_delete_ip_t *ps_ip =
 (ihevcd_cxa_delete_ip_t *)pv_api_ip;
 ihevcd_cxa_delete_op_t *ps_op =
 (ihevcd_cxa_delete_op_t *)pv_api_op;

            ps_op->s_ivd_delete_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_delete_ip_t.u4_size
 != sizeof(ihevcd_cxa_delete_ip_t))
 {
                ps_op->s_ivd_delete_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_delete_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_delete_op_t.u4_size
 != sizeof(ihevcd_cxa_delete_op_t))
 {
                ps_op->s_ivd_delete_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_delete_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_VIDEO_CTL:
 {
            UWORD32 *pu4_ptr_cmd;
            UWORD32 sub_command;

            pu4_ptr_cmd = (UWORD32 *)pv_api_ip;
            pu4_ptr_cmd += 2;
            sub_command = *pu4_ptr_cmd;

 switch(sub_command)
 {
 case IVD_CMD_CTL_SETPARAMS:
 {
 ihevcd_cxa_ctl_set_config_ip_t *ps_ip;
 ihevcd_cxa_ctl_set_config_op_t *ps_op;
                    ps_ip = (ihevcd_cxa_ctl_set_config_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_set_config_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_set_config_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_set_config_ip_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 case IVD_CMD_CTL_SETDEFAULT:
 {
 ihevcd_cxa_ctl_set_config_op_t *ps_op;
                    ps_op = (ihevcd_cxa_ctl_set_config_op_t *)pv_api_op;
 if(ps_op->s_ivd_ctl_set_config_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_set_config_op_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETPARAMS:
 {
 ihevcd_cxa_ctl_getstatus_ip_t *ps_ip;
 ihevcd_cxa_ctl_getstatus_op_t *ps_op;

                    ps_ip = (ihevcd_cxa_ctl_getstatus_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_getstatus_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getstatus_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getstatus_ip_t))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if((ps_op->s_ivd_ctl_getstatus_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getstatus_op_t)) &&
 (ps_op->s_ivd_ctl_getstatus_op_t.u4_size
 != sizeof(ivd_ctl_getstatus_op_t)))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETBUFINFO:
 {
 ihevcd_cxa_ctl_getbufinfo_ip_t *ps_ip;
 ihevcd_cxa_ctl_getbufinfo_op_t *ps_op;
                    ps_ip = (ihevcd_cxa_ctl_getbufinfo_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_getbufinfo_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_getbufinfo_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getbufinfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getbufinfo_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getbufinfo_op_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETVERSION:
 {
 ihevcd_cxa_ctl_getversioninfo_ip_t *ps_ip;
 ihevcd_cxa_ctl_getversioninfo_op_t *ps_op;
                    ps_ip = (ihevcd_cxa_ctl_getversioninfo_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_getversioninfo_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getversioninfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getversioninfo_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_getversioninfo_op_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_FLUSH:
 {
 ihevcd_cxa_ctl_flush_ip_t *ps_ip;
 ihevcd_cxa_ctl_flush_op_t *ps_op;
                    ps_ip = (ihevcd_cxa_ctl_flush_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_flush_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_flush_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_flush_ip_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_flush_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_flush_op_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_RESET:
 {
 ihevcd_cxa_ctl_reset_ip_t *ps_ip;
 ihevcd_cxa_ctl_reset_op_t *ps_op;
                    ps_ip = (ihevcd_cxa_ctl_reset_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_reset_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_reset_ip_t.u4_size
 != sizeof(ihevcd_cxa_ctl_reset_ip_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_reset_op_t.u4_size
 != sizeof(ihevcd_cxa_ctl_reset_op_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;
 case IHEVCD_CXA_CMD_CTL_DEGRADE:
 {
 ihevcd_cxa_ctl_degrade_ip_t *ps_ip;
 ihevcd_cxa_ctl_degrade_op_t *ps_op;

                    ps_ip = (ihevcd_cxa_ctl_degrade_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_degrade_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_degrade_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_degrade_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if((ps_ip->i4_degrade_pics < 0) ||
 (ps_ip->i4_degrade_pics > 4) ||
 (ps_ip->i4_nondegrade_interval < 0) ||
 (ps_ip->i4_degrade_type < 0) ||
 (ps_ip->i4_degrade_type > 15))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }

 break;
 }

 case IHEVCD_CXA_CMD_CTL_GET_BUFFER_DIMENSIONS:
 {
 ihevcd_cxa_ctl_get_frame_dimensions_ip_t *ps_ip;
 ihevcd_cxa_ctl_get_frame_dimensions_op_t *ps_op;

                    ps_ip =
 (ihevcd_cxa_ctl_get_frame_dimensions_ip_t *)pv_api_ip;
                    ps_op =
 (ihevcd_cxa_ctl_get_frame_dimensions_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_get_frame_dimensions_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_get_frame_dimensions_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }

 case IHEVCD_CXA_CMD_CTL_GET_VUI_PARAMS:
 {
 ihevcd_cxa_ctl_get_vui_params_ip_t *ps_ip;
 ihevcd_cxa_ctl_get_vui_params_op_t *ps_op;

                    ps_ip =
 (ihevcd_cxa_ctl_get_vui_params_ip_t *)pv_api_ip;
                    ps_op =
 (ihevcd_cxa_ctl_get_vui_params_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_get_vui_params_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_get_vui_params_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 case IHEVCD_CXA_CMD_CTL_GET_SEI_MASTERING_PARAMS:
 {
 ihevcd_cxa_ctl_get_sei_mastering_params_ip_t *ps_ip;
 ihevcd_cxa_ctl_get_sei_mastering_params_op_t *ps_op;

                    ps_ip = (ihevcd_cxa_ctl_get_sei_mastering_params_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_get_sei_mastering_params_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_get_sei_mastering_params_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_get_sei_mastering_params_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 case IHEVCD_CXA_CMD_CTL_SET_NUM_CORES:
 {
 ihevcd_cxa_ctl_set_num_cores_ip_t *ps_ip;
 ihevcd_cxa_ctl_set_num_cores_op_t *ps_op;

                    ps_ip = (ihevcd_cxa_ctl_set_num_cores_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_set_num_cores_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_set_num_cores_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_set_num_cores_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

#ifdef MULTICORE
 if((ps_ip->u4_num_cores < 1) || (ps_ip->u4_num_cores > MAX_NUM_CORES))
#else
 if(ps_ip->u4_num_cores != 1)
#endif
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }
 break;
 }
 case IHEVCD_CXA_CMD_CTL_SET_PROCESSOR:
 {
 ihevcd_cxa_ctl_set_processor_ip_t *ps_ip;
 ihevcd_cxa_ctl_set_processor_op_t *ps_op;

                    ps_ip = (ihevcd_cxa_ctl_set_processor_ip_t *)pv_api_ip;
                    ps_op = (ihevcd_cxa_ctl_set_processor_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ihevcd_cxa_ctl_set_processor_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ihevcd_cxa_ctl_set_processor_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_UNSUPPORTED_API_CMD;
 return IV_FAIL;
 }
 }
 break;
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_UNSUPPORTED_API_CMD;
 return IV_FAIL;
 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Parcel::readInt32Vector(std::vector<int32_t>* val) const {
 return readTypedVector(val, &Parcel::readInt32);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlWarningMsg(xmlParserCtxtPtr ctxt, xmlParserErrors error,
 const char *msg, const xmlChar *str1, const xmlChar *str2)
{
    xmlStructuredErrorFunc schannel = NULL;

 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 if ((ctxt != NULL) && (ctxt->sax != NULL) &&
 (ctxt->sax->initialized == XML_SAX2_MAGIC))
        schannel = ctxt->sax->serror;
 if (ctxt != NULL) {
        __xmlRaiseError(schannel,
 (ctxt->sax) ? ctxt->sax->warning : NULL,
                    ctxt->userData,
                    ctxt, NULL, XML_FROM_PARSER, error,
                    XML_ERR_WARNING, NULL, 0,
 (const char *) str1, (const char *) str2, NULL, 0, 0,
		    msg, (const char *) str1, (const char *) str2);
 } else {
        __xmlRaiseError(schannel, NULL, NULL,
                    ctxt, NULL, XML_FROM_PARSER, error,
                    XML_ERR_WARNING, NULL, 0,
 (const char *) str1, (const char *) str2, NULL, 0, 0,
		    msg, (const char *) str1, (const char *) str2);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: clean_display(display *d)
{
   png_destroy_read_struct(&d->png_ptr, &d->info_ptr, &d->end_ptr);

 /* This must not happen - it might cause an app crash */
 if (d->png_ptr != NULL || d->info_ptr != NULL || d->end_ptr != NULL)
 {
      fprintf(stderr, "%s(%s): png_destroy_read_struct error\n", d->file,
         d->test);
      exit(1);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaMetadataRetriever::setDataSource(
 const sp<IMediaHTTPService> &httpService,
 const char *srcUrl,
 const KeyedVector<String8, String8> *headers)
{
    ALOGV("setDataSource");
 Mutex::Autolock _l(mLock);
 if (mRetriever == 0) {
        ALOGE("retriever is not initialized");
 return INVALID_OPERATION;
 }
 if (srcUrl == NULL) {
        ALOGE("data source is a null pointer");
 return UNKNOWN_ERROR;
 }
    ALOGV("data source (%s)", srcUrl);
 return mRetriever->setDataSource(httpService, srcUrl, headers);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void SoftHEVC::onPortFlushCompleted(OMX_U32 portIndex) {
     /* Once the output buffers are flushed, ignore any buffers that are held in decoder */
 if (kOutputPortIndex == portIndex) {
        setFlushMode();

 /* Allocate a picture buffer to flushed data */
 uint32_t displayStride = outputBufferWidth();
 uint32_t displayHeight = outputBufferHeight();

 uint32_t bufferSize = displayStride * displayHeight * 3 / 2;
        mFlushOutBuffer = (uint8_t *)memalign(128, bufferSize);
 if (NULL == mFlushOutBuffer) {
            ALOGE("Could not allocate flushOutputBuffer of size %zu", bufferSize);
 return;
 }

 while (true) {
 ivd_video_decode_ip_t s_dec_ip;
 ivd_video_decode_op_t s_dec_op;
            IV_API_CALL_STATUS_T status;
 size_t sizeY, sizeUV;

            setDecodeArgs(&s_dec_ip, &s_dec_op, NULL, NULL, 0);

            status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip,
 (void *)&s_dec_op);
 if (0 == s_dec_op.u4_output_present) {
                resetPlugin();
 break;
 }
 }

 if (mFlushOutBuffer) {
            free(mFlushOutBuffer);
            mFlushOutBuffer = NULL;
 }

 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_cavlc_parse_8x8block_left_available(WORD16 *pi2_coeff_block,
                                                  UWORD32 u4_sub_block_strd,
                                                  UWORD32 u4_isdc,
 dec_struct_t * ps_dec,
                                                  UWORD8 *pu1_top_nnz,
                                                  UWORD8 *pu1_left_nnz,
                                                  UWORD8 u1_tran_form8x8,
                                                  UWORD8 u1_mb_field_decodingflag,
                                                  UWORD32 *pu4_csbp)
{
    UWORD32 u4_num_coeff, u4_n, u4_subblock_coded;
    UWORD32 u4_top0, u4_top1;
    UWORD32 *pu4_dummy;
    WORD32 (**pf_cavlc_parse4x4coeff)(WORD16 *pi2_coeff_block,
                                      UWORD32 u4_isdc,
                                      WORD32 u4_n,
 struct _DecStruct *ps_dec,
                                      UWORD32 *pu4_dummy) =
                                      ps_dec->pf_cavlc_parse4x4coeff;
    UWORD32 u4_idx = 0;
    UWORD8 *puc_temp;
    WORD32 ret;

 *pu4_csbp = 0;
    puc_temp = ps_dec->pu1_inv_scan;

 /*------------------------------------------------------*/
 /* Residual 4x4 decoding: SubBlock 0                    */
 /*------------------------------------------------------*/
 if(u1_tran_form8x8)
 {
 if(!u1_mb_field_decodingflag)
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[0];
 }
 else
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[0];
 }
 }
    u4_n = pu1_left_nnz[0];
    ret = pf_cavlc_parse4x4coeff[(u4_n > 7)](pi2_coeff_block, u4_isdc,
                                             u4_n, ps_dec, &u4_num_coeff);
 if(ret != OK)
 return ret;

    u4_top0 = u4_num_coeff;
    u4_subblock_coded = (u4_num_coeff != 0);
    INSERT_BIT(*pu4_csbp, u4_idx, u4_subblock_coded);

 /*------------------------------------------------------*/
 /* Residual 4x4 decoding: SubBlock 1                    */
 /*------------------------------------------------------*/
    u4_idx++;
 if(u1_tran_form8x8)
 {
 if(!u1_mb_field_decodingflag)
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[1];
 }
 else
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[1];
 }
 }
 else
 {
        pi2_coeff_block += NUM_COEFFS_IN_4x4BLK;
 }
    u4_n = u4_num_coeff;
    ret = pf_cavlc_parse4x4coeff[(u4_n > 7)](pi2_coeff_block, u4_isdc,
                                             u4_n, ps_dec, &u4_num_coeff);
 if(ret != OK)
 return ret;

    u4_top1 = pu1_left_nnz[0] = u4_num_coeff;
    u4_subblock_coded = (u4_num_coeff != 0);
    INSERT_BIT(*pu4_csbp, u4_idx, u4_subblock_coded);

 /*------------------------------------------------------*/
 /* Residual 4x4 decoding: SubBlock 2                    */
 /*------------------------------------------------------*/
    u4_idx += (u4_sub_block_strd - 1);
 if(u1_tran_form8x8)
 {
 if(!u1_mb_field_decodingflag)
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[2];
 }
 else
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[2];
 }
 }
 else
 {
        pi2_coeff_block += ((u4_sub_block_strd - 1) * NUM_COEFFS_IN_4x4BLK);
 }
    u4_n = (u4_top0 + pu1_left_nnz[1] + 1) >> 1;
    ret = pf_cavlc_parse4x4coeff[(u4_n > 7)](pi2_coeff_block, u4_isdc,
                                             u4_n, ps_dec, &u4_num_coeff);
 if(ret != OK)
 return ret;

    pu1_top_nnz[0] = u4_num_coeff;
    u4_subblock_coded = (u4_num_coeff != 0);
    INSERT_BIT(*pu4_csbp, u4_idx, u4_subblock_coded);

 /*------------------------------------------------------*/
 /* Residual 4x4 decoding: SubBlock 3                    */
 /*------------------------------------------------------*/
    u4_idx++;
 if(u1_tran_form8x8)
 {
 if(!u1_mb_field_decodingflag)
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_prog8x8_cavlc[3];
 }
 else
 {
            ps_dec->pu1_inv_scan =
 (UWORD8*)gau1_ih264d_inv_scan_int8x8_cavlc[3];
 }
 }
 else
 {
        pi2_coeff_block += NUM_COEFFS_IN_4x4BLK;
 }
    u4_n = (u4_top1 + u4_num_coeff + 1) >> 1;
    ret = pf_cavlc_parse4x4coeff[(u4_n > 7)](pi2_coeff_block, u4_isdc,
                                             u4_n, ps_dec, &u4_num_coeff);
 if(ret != OK)
 return ret;

    pu1_top_nnz[1] = pu1_left_nnz[1] = u4_num_coeff;
    u4_subblock_coded = (u4_num_coeff != 0);
    INSERT_BIT(*pu4_csbp, u4_idx, u4_subblock_coded);

    ps_dec->pu1_inv_scan = puc_temp;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXCodec::allocateBuffersOnPort(OMX_U32 portIndex) {
 if (mNativeWindow != NULL && portIndex == kPortIndexOutput) {
 return allocateOutputBuffersFromNativeWindow();
 }

 if ((mFlags & kEnableGrallocUsageProtected) && portIndex == kPortIndexOutput) {
        ALOGE("protected output buffers must be stent to an ANativeWindow");
 return PERMISSION_DENIED;
 }

 status_t err = OK;
 if ((mFlags & kStoreMetaDataInVideoBuffers)
 && portIndex == kPortIndexInput) {
        err = mOMX->storeMetaDataInBuffers(mNode, kPortIndexInput, OMX_TRUE);
 if (err != OK) {
            ALOGE("Storing meta data in video buffers is not supported");
 return err;
 }
 }

    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

 if (err != OK) {
 return err;
 }

    CODEC_LOGV("allocating %u buffers of size %u on %s port",
            def.nBufferCountActual, def.nBufferSize,
            portIndex == kPortIndexInput ? "input" : "output");

 if (def.nBufferSize != 0 && def.nBufferCountActual > SIZE_MAX / def.nBufferSize) {
 return BAD_VALUE;
 }
 size_t totalSize = def.nBufferCountActual * def.nBufferSize;
    mDealer[portIndex] = new MemoryDealer(totalSize, "OMXCodec");

 for (OMX_U32 i = 0; i < def.nBufferCountActual; ++i) {
        sp<IMemory> mem = mDealer[portIndex]->allocate(def.nBufferSize);
        CHECK(mem.get() != NULL);

 BufferInfo info;
        info.mData = NULL;
        info.mSize = def.nBufferSize;

        IOMX::buffer_id buffer;
 if (portIndex == kPortIndexInput
 && ((mQuirks & kRequiresAllocateBufferOnInputPorts)
 || (mFlags & kUseSecureInputBuffers))) {
 if (mOMXLivesLocally) {
                mem.clear();

                err = mOMX->allocateBuffer(
                        mNode, portIndex, def.nBufferSize, &buffer,
 &info.mData);
 } else {
                err = mOMX->allocateBufferWithBackup(
                        mNode, portIndex, mem, &buffer, mem->size());
 }
 } else if (portIndex == kPortIndexOutput
 && (mQuirks & kRequiresAllocateBufferOnOutputPorts)) {
 if (mOMXLivesLocally) {
                mem.clear();

                err = mOMX->allocateBuffer(
                        mNode, portIndex, def.nBufferSize, &buffer,
 &info.mData);
 } else {
                err = mOMX->allocateBufferWithBackup(
                        mNode, portIndex, mem, &buffer, mem->size());
 }
 } else {
            err = mOMX->useBuffer(mNode, portIndex, mem, &buffer, mem->size());
 }

 if (err != OK) {
            ALOGE("allocate_buffer_with_backup failed");
 return err;
 }

 if (mem != NULL) {
            info.mData = mem->pointer();
 }

        info.mBuffer = buffer;
        info.mStatus = OWNED_BY_US;
        info.mMem = mem;
        info.mMediaBuffer = NULL;

 if (portIndex == kPortIndexOutput) {
            LOG_ALWAYS_FATAL_IF((mOMXLivesLocally
 && (mQuirks & kRequiresAllocateBufferOnOutputPorts)
 && (mQuirks & kDefersOutputBufferAllocation)),
 "allocateBuffersOnPort cannot defer buffer allocation");

            info.mMediaBuffer = new MediaBuffer(info.mData, info.mSize);
            info.mMediaBuffer->setObserver(this);
 }

        mPortBuffers[portIndex].push(info);

        CODEC_LOGV("allocated buffer %u on %s port", buffer,
             portIndex == kPortIndexInput ? "input" : "output");
 }

 if (portIndex == kPortIndexOutput) {

        sp<MetaData> meta = mSource->getFormat();
 int32_t delay = 0;
 if (!meta->findInt32(kKeyEncoderDelay, &delay)) {
            delay = 0;
 }
 int32_t padding = 0;
 if (!meta->findInt32(kKeyEncoderPadding, &padding)) {
            padding = 0;
 }
 int32_t numchannels = 0;
 if (delay + padding) {
 if (mOutputFormat->findInt32(kKeyChannelCount, &numchannels)) {
 size_t frameSize = numchannels * sizeof(int16_t);
 if (mSkipCutBuffer != NULL) {
 size_t prevbuffersize = mSkipCutBuffer->size();
 if (prevbuffersize != 0) {
                        ALOGW("Replacing SkipCutBuffer holding %zu bytes", prevbuffersize);
 }
 }
                mSkipCutBuffer = new SkipCutBuffer(delay * frameSize, padding * frameSize);
 }
 }
 }


 if (portIndex == kPortIndexInput && (mFlags & kUseSecureInputBuffers)) {
 Vector<MediaBuffer *> buffers;
 for (size_t i = 0; i < def.nBufferCountActual; ++i) {
 const BufferInfo &info = mPortBuffers[kPortIndexInput].itemAt(i);

 MediaBuffer *mbuf = new MediaBuffer(info.mData, info.mSize);
            buffers.push(mbuf);
 }

 status_t err = mSource->setBuffers(buffers);

 if (err != OK) {
 for (size_t i = 0; i < def.nBufferCountActual; ++i) {
                buffers.editItemAt(i)->release();
 }
            buffers.clear();

            CODEC_LOGE(
 "Codec requested to use secure input buffers but "
 "upstream source didn't support that.");

 return err;
 }
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: transform_info_imp(transform_display *dp, png_structp pp, png_infop pi)
{
 /* Reuse the standard stuff as appropriate. */
   standard_info_part1(&dp->this, pp, pi);

 /* Now set the list of transforms. */
   dp->transform_list->set(dp->transform_list, dp, pp, pi);

 /* Update the info structure for these transforms: */
 {
 int i = dp->this.use_update_info;
 /* Always do one call, even if use_update_info is 0. */
 do
         png_read_update_info(pp, pi);
 while (--i > 0);
 }

 /* And get the output information into the standard_display */
   standard_info_part2(&dp->this, pp, pi, 1/*images*/);

 /* Plus the extra stuff we need for the transform tests: */

    dp->output_colour_type = png_get_color_type(pp, pi);
    dp->output_bit_depth = png_get_bit_depth(pp, pi);
 
    /* Validate the combination of colour type and bit depth that we are getting
     * out of libpng; the semantics of something not in the PNG spec are, at
     * best, unclear.
    */
 switch (dp->output_colour_type)
 {
 case PNG_COLOR_TYPE_PALETTE:
 if (dp->output_bit_depth > 8) goto error;
 /*FALL THROUGH*/
 case PNG_COLOR_TYPE_GRAY:
 if (dp->output_bit_depth == 1 || dp->output_bit_depth == 2 ||
         dp->output_bit_depth == 4)
 break;
 /*FALL THROUGH*/
 default:
 if (dp->output_bit_depth == 8 || dp->output_bit_depth == 16)
 break;
 /*FALL THROUGH*/
   error:
 {
 char message[128];
 size_t pos;

         pos = safecat(message, sizeof message, 0,
 "invalid final bit depth: colour type(");
         pos = safecatn(message, sizeof message, pos, dp->output_colour_type);
         pos = safecat(message, sizeof message, pos, ") with bit depth: ");
         pos = safecatn(message, sizeof message, pos, dp->output_bit_depth);

         png_error(pp, message);
 }

    }
 
    /* Use a test pixel to check that the output agrees with what we expect -
    * this avoids running the whole test if the output is unexpected.
     */
    {
       image_pixel test_pixel;

      memset(&test_pixel, 0, sizeof test_pixel);
      test_pixel.colour_type = dp->this.colour_type; /* input */
      test_pixel.bit_depth = dp->this.bit_depth;
 if (test_pixel.colour_type == PNG_COLOR_TYPE_PALETTE)
         test_pixel.sample_depth = 8;
 else
         test_pixel.sample_depth = test_pixel.bit_depth;

       /* Don't need sBIT here, but it must be set to non-zero to avoid
        * arithmetic overflows.
        */
      test_pixel.have_tRNS = dp->this.is_transparent;
       test_pixel.red_sBIT = test_pixel.green_sBIT = test_pixel.blue_sBIT =
          test_pixel.alpha_sBIT = test_pixel.sample_depth;
 
      dp->transform_list->mod(dp->transform_list, &test_pixel, pp, dp);

 if (test_pixel.colour_type != dp->output_colour_type)
 {
 char message[128];
 size_t pos = safecat(message, sizeof message, 0, "colour type ");

         pos = safecatn(message, sizeof message, pos, dp->output_colour_type);
         pos = safecat(message, sizeof message, pos, " expected ");
         pos = safecatn(message, sizeof message, pos, test_pixel.colour_type);

         png_error(pp, message);
 }

 if (test_pixel.bit_depth != dp->output_bit_depth)
 {
 char message[128];
 size_t pos = safecat(message, sizeof message, 0, "bit depth ");

         pos = safecatn(message, sizeof message, pos, dp->output_bit_depth);
         pos = safecat(message, sizeof message, pos, " expected ");
         pos = safecatn(message, sizeof message, pos, test_pixel.bit_depth);

         png_error(pp, message);

       }
 
       /* If both bit depth and colour type are correct check the sample depth.
       * I believe these are both internal errors.
        */
      if (test_pixel.colour_type == PNG_COLOR_TYPE_PALETTE)
      {
         if (test_pixel.sample_depth != 8) /* oops - internal error! */
            png_error(pp, "pngvalid: internal: palette sample depth not 8");
      }
      else if (test_pixel.sample_depth != dp->output_bit_depth)
       {
          char message[128];
          size_t pos = safecat(message, sizeof message, 0,
             "internal: sample depth ");
 
          pos = safecatn(message, sizeof message, pos, dp->output_bit_depth);
          pos = safecat(message, sizeof message, pos, " expected ");
         pos = safecatn(message, sizeof message, pos, test_pixel.sample_depth);
 
          png_error(pp, message);
       }
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: char* String8::lockBuffer(size_t size)
{
 SharedBuffer* buf = SharedBuffer::bufferFromData(mString)
 ->editResize(size+1);
 if (buf) {
 char* str = (char*)buf->data();
        mString = str;
 return str;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static sent_status_t send_data_to_app(int fd, BT_HDR *p_buf) {

   if (p_buf->len == 0)
     return SENT_ALL;
 
  ssize_t sent = send(fd, p_buf->data + p_buf->offset, p_buf->len, MSG_DONTWAIT);
 
   if (sent == -1) {
     if (errno == EAGAIN || errno == EWOULDBLOCK || errno == EINTR)
 return SENT_NONE;
    LOG_ERROR("%s error writing RFCOMM data back to app: %s", __func__, strerror(errno));
 return SENT_FAILED;
 }

 if (sent == 0)
 return SENT_FAILED;

 if (sent == p_buf->len)
 return SENT_ALL;

  p_buf->offset += sent;
  p_buf->len -= sent;
 return SENT_PARTIAL;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int main(int argc, char **argv) {
 int frame_cnt = 0;
 FILE *outfile = NULL;
 vpx_codec_ctx_t codec;
 vpx_codec_err_t res;
 VpxVideoReader *reader = NULL;
 const VpxInterface *decoder = NULL;
 const VpxVideoInfo *info = NULL;

  exec_name = argv[0];

 if (argc != 3)
    die("Invalid number of arguments.");

  reader = vpx_video_reader_open(argv[1]);
 if (!reader)
    die("Failed to open %s for reading.", argv[1]);

 if (!(outfile = fopen(argv[2], "wb")))
    die("Failed to open %s for writing", argv[2]);

  info = vpx_video_reader_get_info(reader);

  decoder = get_vpx_decoder_by_fourcc(info->codec_fourcc);

   if (!decoder)
     die("Unknown input codec.");
 
  printf("Using %s\n", vpx_codec_iface_name(decoder->interface()));
 
  res = vpx_codec_dec_init(&codec, decoder->interface(), NULL,
                            VPX_CODEC_USE_POSTPROC);
   if (res == VPX_CODEC_INCAPABLE)
     die_codec(&codec, "Postproc not supported by this decoder.");

 if (res)
    die_codec(&codec, "Failed to initialize decoder.");

 while (vpx_video_reader_read_frame(reader)) {
 vpx_codec_iter_t iter = NULL;
 vpx_image_t *img = NULL;
 size_t frame_size = 0;
 const unsigned char *frame = vpx_video_reader_get_frame(reader,
 &frame_size);

 ++frame_cnt;

 if (frame_cnt % 30 == 1) {
 vp8_postproc_cfg_t pp = {0, 0, 0};

 if (vpx_codec_control(&codec, VP8_SET_POSTPROC, &pp))
      die_codec(&codec, "Failed to turn off postproc.");
 } else if (frame_cnt % 30 == 16) {
 vp8_postproc_cfg_t pp = {VP8_DEBLOCK | VP8_DEMACROBLOCK | VP8_MFQE,
 4, 0};
 if (vpx_codec_control(&codec, VP8_SET_POSTPROC, &pp))
        die_codec(&codec, "Failed to turn on postproc.");
 };

 if (vpx_codec_decode(&codec, frame, (unsigned int)frame_size, NULL, 15000))
      die_codec(&codec, "Failed to decode frame");

 while ((img = vpx_codec_get_frame(&codec, &iter)) != NULL) {
      vpx_img_write(img, outfile);
 }
 }

  printf("Processed %d frames.\n", frame_cnt);
 if (vpx_codec_destroy(&codec))
    die_codec(&codec, "Failed to destroy codec");

  printf("Play: ffplay -f rawvideo -pix_fmt yuv420p -s %dx%d %s\n",
         info->frame_width, info->frame_height, argv[2]);

  vpx_video_reader_close(reader);

  fclose(outfile);
 return EXIT_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool SniffAMR(
 const sp<DataSource> &source, String8 *mimeType, float *confidence,
        sp<AMessage> *) {
 char header[9];

 if (source->readAt(0, header, sizeof(header)) != sizeof(header)) {
 return false;
 }

 if (!memcmp(header, "#!AMR\n", 6)) {
 *mimeType = MEDIA_MIMETYPE_AUDIO_AMR_NB;
 *confidence = 0.5;

 return true;
 } else if (!memcmp(header, "#!AMR-WB\n", 9)) {
 *mimeType = MEDIA_MIMETYPE_AUDIO_AMR_WB;
 *confidence = 0.5;

 return true;
 }

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void smart_socket_ready(asocket* s) {
    D("SS(%d): ready", s->id);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static size_t consumeDigits(const char16_t* start, const char16_t* end) {
 const char16_t* c = start;
 for (; c != end && *c >= u'0' && *c <= u'9'; c++) {}
 return static_cast<size_t>(c - start);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<FixedArray> DirectCollectElementIndicesImpl(
 Isolate* isolate, Handle<JSObject> object,
 Handle<FixedArrayBase> backing_store, GetKeysConversion convert,
 PropertyFilter filter, Handle<FixedArray> list, uint32_t* nof_indices,
 uint32_t insertion_index = 0) {
 uint32_t length = Subclass::GetMaxIndex(*object, *backing_store);
 for (uint32_t i = 0; i < length; i++) {
 if (Subclass::HasElementImpl(isolate, object, i, backing_store, filter)) {
 if (convert == GetKeysConversion::kConvertToString) {
 Handle<String> index_string = isolate->factory()->Uint32ToString(i);
 list->set(insertion_index, *index_string);
 } else {
 list->set(insertion_index, Smi::FromInt(i), SKIP_WRITE_BARRIER);
 }
        insertion_index++;
 }
 }
 *nof_indices = insertion_index;
 return list;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int lib_init()
{
    pthread_once(&once, init_once);
 return init_status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::initiateShutdown(bool keepComponentAllocated) {
    sp<AMessage> msg = new AMessage(kWhatShutdown, this);
    msg->setInt32("keepComponentAllocated", keepComponentAllocated);
    msg->post();
 if (!keepComponentAllocated) {
 (new AMessage(kWhatReleaseCodecInstance, this))->post(3000000);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Chapters::Edition::Clear()
{
    while (m_atoms_count > 0)
    {
        Atom& a = m_atoms[--m_atoms_count];
        a.Clear();
     }
 
    delete[] m_atoms;
    m_atoms = NULL;
 
    m_atoms_size = 0;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::ipSecUpdateSecurityPolicy(int32_t transformId, int32_t direction,
 const std::string& localAddress,
 const std::string& remoteAddress,
 int32_t spi, int32_t markValue,
 int32_t markMask) {
 return processSecurityPolicy(transformId, direction, localAddress, remoteAddress, spi,
                                 markValue, markMask, XFRM_MSG_UPDPOLICY);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Track* Tracks::GetTrackByIndex(unsigned long idx) const {
 const ptrdiff_t count = m_trackEntriesEnd - m_trackEntries;

 if (idx >= static_cast<unsigned long>(count))
 return NULL;


   return m_trackEntries[idx];
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Maybe<int64_t> IndexOfValueImpl(Isolate* isolate,
 Handle<JSObject> receiver,
 Handle<Object> value,
 uint32_t start_from, uint32_t length) {
 return IndexOfValueSlowPath(isolate, receiver, value, start_from, length);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMPEG4Encoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamVideoBitrate:
 {
            OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
 (OMX_VIDEO_PARAM_BITRATETYPE *) params;

 if (!isValidOMXParam(bitRate)) {
 return OMX_ErrorBadParameter;
 }

 if (bitRate->nPortIndex != 1 ||
                bitRate->eControlRate != OMX_Video_ControlRateVariable) {
 return OMX_ErrorUndefined;
 }

            mBitrate = bitRate->nTargetBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoH263:
 {
            OMX_VIDEO_PARAM_H263TYPE *h263type =
 (OMX_VIDEO_PARAM_H263TYPE *)params;

 if (!isValidOMXParam(h263type)) {
 return OMX_ErrorBadParameter;
 }

 if (h263type->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

 if (h263type->eProfile != OMX_VIDEO_H263ProfileBaseline ||
                h263type->eLevel != OMX_VIDEO_H263Level45 ||
 (h263type->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) ||
                h263type->bPLUSPTYPEAllowed != OMX_FALSE ||
                h263type->bForceRoundingTypeToZero != OMX_FALSE ||
                h263type->nPictureHeaderRepetition != 0 ||
                h263type->nGOBHeaderInterval != 0) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoMpeg4:
 {
            OMX_VIDEO_PARAM_MPEG4TYPE *mpeg4type =
 (OMX_VIDEO_PARAM_MPEG4TYPE *)params;

 if (!isValidOMXParam(mpeg4type)) {
 return OMX_ErrorBadParameter;
 }

 if (mpeg4type->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

 if (mpeg4type->eProfile != OMX_VIDEO_MPEG4ProfileCore ||
                mpeg4type->eLevel != OMX_VIDEO_MPEG4Level2 ||
 (mpeg4type->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) ||
                mpeg4type->nBFrames != 0 ||
                mpeg4type->nIDCVLCThreshold != 0 ||
                mpeg4type->bACPred != OMX_TRUE ||
                mpeg4type->nMaxPacketSize != 256 ||
                mpeg4type->nTimeIncRes != 1000 ||
                mpeg4type->nHeaderExtension != 0 ||
                mpeg4type->bReversibleVLC != OMX_FALSE) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalSetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t SoundTriggerHwService::Module::unloadSoundModel(sound_model_handle_t handle)
{
    ALOGV("unloadSoundModel() model handle %d", handle);
 if (!captureHotwordAllowed()) {
 return PERMISSION_DENIED;
 }

 AutoMutex lock(mLock);
 return unloadSoundModel_l(handle);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void get_config(effect_context_t *context, effect_config_t *config)
{
 *config = context->config;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual void SetUp() {
     source_stride_ = (width_ + 31) & ~31;
     reference_stride_ = width_ * 2;
     rnd_.Reset(ACMRandom::DeterministicSeed());
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int set_user(struct cred *new)
{
 struct user_struct *new_user;

	new_user = alloc_uid(current_user_ns(), new->uid);
 if (!new_user)
 return -EAGAIN;

 /*
	 * We don't fail in case of NPROC limit excess here because too many
	 * poorly written programs don't check set*uid() return code, assuming
	 * it never fails if called by root.  We may still enforce NPROC limit
	 * for programs doing set*uid()+execve() by harmlessly deferring the
	 * failure to the execve() stage.
	 */
 if (atomic_read(&new_user->processes) >= rlimit(RLIMIT_NPROC) &&
			new_user != INIT_USER)
		current->flags |= PF_NPROC_EXCEEDED;
 else
		current->flags &= ~PF_NPROC_EXCEEDED;

	free_uid(new->user);
 new->user = new_user;
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_av_handle_event(uint16_t event, char* p_param) {
  BTIF_TRACE_EVENT("%s: event=%s", __func__,
                   dump_av_sm_event_name((btif_av_sm_event_t)event));
 switch (event) {
 case BTIF_AV_CLEANUP_REQ_EVT:
      btif_a2dp_source_shutdown();
      btif_a2dp_sink_shutdown();
 break;

 case BTA_AV_REGISTER_EVT:
 if (btif_av_cb.sm_handle == NULL) {
        btif_av_cb.bta_handle = ((tBTA_AV*)p_param)->registr.hndl;
        BTIF_TRACE_DEBUG("%s: BTA AV Handle updated", __func__);
 }
 /* FALLTHROUGH */
 default:
      btif_sm_dispatch(btif_av_cb.sm_handle, event, (void*)p_param);
      btif_av_event_free_data(event, p_param);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtReadFile(xmlParserCtxtPtr ctxt, const char *filename,
 const char *encoding, int options)
{
    xmlParserInputPtr stream;

 if (filename == NULL)
 return (NULL);
 if (ctxt == NULL)
 return (NULL);
    xmlInitParser();

    xmlCtxtReset(ctxt);

    stream = xmlLoadExternalEntity(filename, NULL, ctxt);
 if (stream == NULL) {
 return (NULL);
 }
    inputPush(ctxt, stream);
 return (xmlDoRead(ctxt, NULL, encoding, options, 1));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputWindowHandle::releaseInfo() {
 if (mInfo) {
 delete mInfo;
        mInfo = NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: struct mixer_card *adev_get_mixer_for_card(struct audio_device *adev, int card)
{
 struct mixer_card *mixer_card;
 struct listnode *node;

    list_for_each(node, &adev->mixer_list) {
        mixer_card = node_to_item(node, struct mixer_card, adev_list_node);
 if (mixer_card->card == card)
 return mixer_card;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MetaData> CameraSource::getFormat() {
 return mMeta;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean android_net_wifi_cancelRange(
 JNIEnv *env, jclass cls, jint iface, jint id, jobject params) {

 JNIHelper helper(env);
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);
    ALOGD("cancelling rtt request [%d] = %p", id, handle);

    mac_addr addrs[MaxRttConfigs];
    memset(&addrs, 0, sizeof(addrs));

 int len = helper.getArrayLength((jobjectArray)params);
 if (len > MaxRttConfigs) {
 return false;
 }

 for (int i = 0; i < len; i++) {

 JNIObject<jobject> param = helper.getObjectArrayElement(params, i);
 if (param == NULL) {
            ALOGD("could not get element %d", i);
 continue;
 }

        parseMacAddress(env, param, addrs[i]);
 }

 return hal_fn.wifi_rtt_range_cancel(id, handle, len, addrs) == WIFI_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t NuPlayer::GenericSource::setDataSource(const sp<DataSource>& source) {
    resetDataSource();
    mDataSource = source;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void mca_ccb_cong(tMCA_CCB* p_ccb, tMCA_CCB_EVT* p_data) {
  MCA_TRACE_DEBUG("mca_ccb_cong cong=%d/%d", p_ccb->cong, p_data->llcong);
  p_ccb->cong = p_data->llcong;
 if (!p_ccb->cong) {
 /* if there's a held packet, send it now */
 if (p_ccb->p_tx_req && !p_ccb->p_tx_req->hdr.layer_specific) {
      p_data = (tMCA_CCB_EVT*)p_ccb->p_tx_req;
      p_ccb->p_tx_req = NULL;
      mca_ccb_snd_req(p_ccb, p_data);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_U32 omx_venc::dev_start_done(void)
{
 return handle->venc_start_done();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void Bitmap_getPixels(JNIEnv* env, jobject, jlong bitmapHandle,
        jintArray pixelArray, jint offset, jint stride,
        jint x, jint y, jint width, jint height) {
 const SkBitmap* bitmap = reinterpret_cast<SkBitmap*>(bitmapHandle);
 SkAutoLockPixels alp(*bitmap);

 ToColorProc proc = ChooseToColorProc(*bitmap);
 if (NULL == proc) {
 return;
 }
 const void* src = bitmap->getAddr(x, y);
 if (NULL == src) {
 return;
 }

 SkColorTable* ctable = bitmap->getColorTable();
    jint* dst = env->GetIntArrayElements(pixelArray, NULL);
 SkColor* d = (SkColor*)dst + offset;
 while (--height >= 0) {
        proc(d, src, width, ctable);
        d += stride;
        src = (void*)((const char*)src + bitmap->rowBytes());
 }
    env->ReleaseIntArrayElements(pixelArray, dst, 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_create(iv_obj_t *dec_hdl, void *pv_api_ip, void *pv_api_op)
{
 ih264d_create_op_t *ps_create_op;

    WORD32 ret;

    ps_create_op = (ih264d_create_op_t *)pv_api_op;

    ps_create_op->s_ivd_create_op_t.u4_error_code = 0;

    ret = ih264d_allocate_static_bufs(&dec_hdl, pv_api_ip, pv_api_op);

 /* If allocation of some buffer fails, then free buffers allocated till then */
 if((IV_FAIL == ret) && (NULL != dec_hdl))
 {
        ih264d_free_static_bufs(dec_hdl);
        ps_create_op->s_ivd_create_op_t.u4_error_code = IVD_MEM_ALLOC_FAILED;
        ps_create_op->s_ivd_create_op_t.u4_error_code = 1 << IVD_FATALERROR;

 return IV_FAIL;
 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual ~CodecObserver() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_create(iv_obj_t *ps_codec_obj,

                            void *pv_api_ip,
                            void *pv_api_op)
 {
     ihevcd_cxa_create_op_t *ps_create_op;
 
     WORD32 ret;
     codec_t *ps_codec;
     ps_create_op = (ihevcd_cxa_create_op_t *)pv_api_op;
 
     ps_create_op->s_ivd_create_op_t.u4_error_code = 0;
     ret = ihevcd_allocate_static_bufs(&ps_codec_obj, pv_api_ip, pv_api_op);
 
     /* If allocation of some buffer fails, then free buffers allocated till then */
    if((IV_FAIL == ret) && (NULL != ps_codec_obj))
     {
        ihevcd_free_static_bufs(ps_codec_obj);
         ps_create_op->s_ivd_create_op_t.u4_error_code = IVD_MEM_ALLOC_FAILED;
         ps_create_op->s_ivd_create_op_t.u4_error_code = 1 << IVD_FATALERROR;
 
 return IV_FAIL;
 }
    ps_codec = (codec_t *)ps_codec_obj->pv_codec_handle;
    ret = ihevcd_init(ps_codec);

    TRACE_INIT(NULL);
    STATS_INIT();

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void SetUp() {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_get_version(iv_obj_t *ps_dechdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 char au1_version_string[512];

 impeg2d_ctl_getversioninfo_ip_t *ps_ip;
 impeg2d_ctl_getversioninfo_op_t *ps_op;

    UNUSED(ps_dechdl);

    ps_ip = (impeg2d_ctl_getversioninfo_ip_t *)pv_api_ip;
    ps_op = (impeg2d_ctl_getversioninfo_op_t *)pv_api_op;

    ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code = IV_SUCCESS;

    VERSION(au1_version_string, CODEC_NAME, CODEC_RELEASE_TYPE, CODEC_RELEASE_VER,
            CODEC_VENDOR);

 if((WORD32)ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_version_buffer_size <= 0)
 {
        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code = IV_FAIL;
 return (IV_FAIL);
 }

 if(ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_version_buffer_size
 >= (strlen(au1_version_string) + 1))
 {
        memcpy(ps_ip->s_ivd_ctl_getversioninfo_ip_t.pv_version_buffer,
               au1_version_string, (strlen(au1_version_string) + 1));
        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code = IV_SUCCESS;
 }
 else
 {
        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code = IV_FAIL;
 }

 return (IV_SUCCESS);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void terminate_string8()
{
 SharedBuffer::bufferFromData(gEmptyString)->release();
    gEmptyStringBuf = NULL;
    gEmptyString = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual void TearDown() {
    libvpx_test::ClearSystemState();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::verifySupportForProfileAndLevel(
 int32_t profile, int32_t level) {
    OMX_VIDEO_PARAM_PROFILELEVELTYPE params;
 InitOMXParams(&params);
    params.nPortIndex = kPortIndexOutput;

 for (params.nProfileIndex = 0;; ++params.nProfileIndex) {
 status_t err = mOMX->getParameter(
                mNode,
                OMX_IndexParamVideoProfileLevelQuerySupported,
 &params,
 sizeof(params));

 if (err != OK) {
 return err;
 }

 int32_t supportedProfile = static_cast<int32_t>(params.eProfile);
 int32_t supportedLevel = static_cast<int32_t>(params.eLevel);

 if (profile == supportedProfile && level <= supportedLevel) {
 return OK;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MediaPlayerService::Client::ServiceDeathNotifier::~ServiceDeathNotifier() {
    mService->unlinkToDeath(this);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::use_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes,
        OMX_IN OMX_U8*                   buffer)
{
    OMX_ERRORTYPE error = OMX_ErrorNone;
 struct vdec_setbuffer_cmd setbuffers;

 if (bufferHdr == NULL || bytes == 0 || (!secure_mode && buffer == NULL)) {
            DEBUG_PRINT_ERROR("bad param 0x%p %u 0x%p",bufferHdr, (unsigned int)bytes, buffer);
 return OMX_ErrorBadParameter;
 }
 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("Use Buffer in Invalid State");
 return OMX_ErrorInvalidState;
 }
 if (port == OMX_CORE_INPUT_PORT_INDEX)
        error = use_input_heap_buffers(hComp, bufferHdr, port, appData, bytes, buffer);
 else if (port == OMX_CORE_OUTPUT_PORT_INDEX)
        error = use_output_buffer(hComp,bufferHdr,port,appData,bytes,buffer); //not tested
 else {
        DEBUG_PRINT_ERROR("Error: Invalid Port Index received %d",(int)port);
        error = OMX_ErrorBadPortIndex;
 }
    DEBUG_PRINT_LOW("Use Buffer: port %u, buffer %p, eRet %d", (unsigned int)port, *bufferHdr, error);
 if (error == OMX_ErrorNone) {
 if (allocate_done() && BITMASK_PRESENT(&m_flags,OMX_COMPONENT_IDLE_PENDING)) {
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_IDLE_PENDING);
            post_event(OMX_CommandStateSet,OMX_StateIdle,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 if (port == OMX_CORE_INPUT_PORT_INDEX && m_inp_bPopulated &&
                BITMASK_PRESENT(&m_flags,OMX_COMPONENT_INPUT_ENABLE_PENDING)) {
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_INPUT_ENABLE_PENDING);
            post_event(OMX_CommandPortEnable,
                    OMX_CORE_INPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 } else if (port == OMX_CORE_OUTPUT_PORT_INDEX && m_out_bPopulated &&
                BITMASK_PRESENT(&m_flags,OMX_COMPONENT_OUTPUT_ENABLE_PENDING)) {
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_OUTPUT_ENABLE_PENDING);
            post_event(OMX_CommandPortEnable,
                    OMX_CORE_OUTPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 }
 return error;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Parcel::readUniqueFileDescriptorVector(std::unique_ptr<std::vector<ScopedFd>>* val) const {
 return readNullableTypedVector(val, &Parcel::readUniqueFileDescriptor);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8::String8(const String16& o)
 : mString(allocFromUTF16(o.string(), o.size()))
{
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void cleanup_sink(void) {
  BTIF_TRACE_EVENT("%s", __func__);

  btif_queue_cleanup(UUID_SERVCLASS_AUDIO_SINK);
 if (bt_av_sink_callbacks) {
    bt_av_sink_callbacks = NULL;
 if (bt_av_src_callbacks == NULL) cleanup(BTA_A2DP_SINK_SERVICE_ID);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_read_local_oob_complete (UINT8 *p)
{
    tBTM_SP_LOC_OOB evt_data;
    UINT8           status = *p++;

    BTM_TRACE_EVENT ("btm_read_local_oob_complete:%d", status);
 if (status == HCI_SUCCESS)
 {
        evt_data.status = BTM_SUCCESS;
        STREAM_TO_ARRAY16(evt_data.c, p);
        STREAM_TO_ARRAY16(evt_data.r, p);
 }
 else
        evt_data.status = BTM_ERR_PROCESSING;

 if (btm_cb.api.p_sp_callback)
 (*btm_cb.api.p_sp_callback) (BTM_SP_LOC_OOB_EVT, (tBTM_SP_EVT_DATA *)&evt_data);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::createInputSurface(
        OMX_U32 portIndex, sp<IGraphicBufferProducer> *bufferProducer, MetadataBufferType *type) {
 Mutex::Autolock autolock(mLock);
 status_t err = createGraphicBufferSource(portIndex, NULL /* bufferConsumer */, type);

 if (err != OK) {
 return err;
 }

 *bufferProducer = mGraphicBufferSource->getIGraphicBufferProducer();
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ihevcd_parse_sei_payload(codec_t *ps_codec,
                              UWORD32 u4_payload_type,
                              UWORD32 u4_payload_size,
                              WORD8 i1_nal_type)
{
 parse_ctxt_t *ps_parse = &ps_codec->s_parse;
 bitstrm_t *ps_bitstrm = &ps_parse->s_bitstrm;
    WORD32 payload_bits_remaining = 0;
 sps_t *ps_sps;

    UWORD32 i;

 for(i = 0; i < MAX_SPS_CNT; i++)
 {
        ps_sps = ps_codec->ps_sps_base + i;
 if(ps_sps->i1_sps_valid)
 {
 break;
 }
 }
 if(NULL == ps_sps)
 {
 return;
 }

 if(NAL_PREFIX_SEI == i1_nal_type)
 {
 switch(u4_payload_type)
 {
 case SEI_BUFFERING_PERIOD:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_buffering_period_sei(ps_codec, ps_sps);
 break;

 case SEI_PICTURE_TIMING:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_pic_timing_sei(ps_codec, ps_sps);
 break;

 case SEI_TIME_CODE:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_time_code_sei(ps_codec);
 break;

 case SEI_MASTERING_DISPLAY_COLOUR_VOLUME:
                ps_parse->s_sei_params.i4_sei_mastering_disp_colour_vol_params_present_flags = 1;
                ihevcd_parse_mastering_disp_params_sei(ps_codec);
 break;

 case SEI_USER_DATA_REGISTERED_ITU_T_T35:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_user_data_registered_itu_t_t35(ps_codec,
                                                            u4_payload_size);
 break;

 default:
 for(i = 0; i < u4_payload_size; i++)
 {
                    ihevcd_bits_flush(ps_bitstrm, 8);
 }
 break;
 }
 }
 else /* NAL_SUFFIX_SEI */
 {
 switch(u4_payload_type)
 {
 case SEI_USER_DATA_REGISTERED_ITU_T_T35:
                ps_parse->s_sei_params.i1_sei_parameters_present_flag = 1;
                ihevcd_parse_user_data_registered_itu_t_t35(ps_codec,
                                                            u4_payload_size);
 break;

 default:
 for(i = 0; i < u4_payload_size; i++)
 {
                    ihevcd_bits_flush(ps_bitstrm, 8);
 }
 break;
 }
 }

 /**
     * By definition the underlying bitstream terminates in a byte-aligned manner.
     * 1. Extract all bar the last MIN(bitsremaining,nine) bits as reserved_payload_extension_data
     * 2. Examine the final 8 bits to determine the payload_bit_equal_to_one marker
     * 3. Extract the remainingreserved_payload_extension_data bits.
     *
     * If there are fewer than 9 bits available, extract them.
     */

    payload_bits_remaining = ihevcd_bits_num_bits_remaining(ps_bitstrm);
 if(payload_bits_remaining) /* more_data_in_payload() */
 {
        WORD32 final_bits;
        WORD32 final_payload_bits = 0;
        WORD32 mask = 0xFF;
        UWORD32 u4_dummy;
        UWORD32 u4_reserved_payload_extension_data;
        UNUSED(u4_dummy);
        UNUSED(u4_reserved_payload_extension_data);

 while(payload_bits_remaining > 9)
 {
            BITS_PARSE("reserved_payload_extension_data",
                       u4_reserved_payload_extension_data, ps_bitstrm, 1);
            payload_bits_remaining--;
 }

        final_bits = ihevcd_bits_nxt(ps_bitstrm, payload_bits_remaining);

 while(final_bits & (mask >> final_payload_bits))
 {
            final_payload_bits++;
 continue;
 }

 while(payload_bits_remaining > (9 - final_payload_bits))
 {
            BITS_PARSE("reserved_payload_extension_data",
                       u4_reserved_payload_extension_data, ps_bitstrm, 1);
            payload_bits_remaining--;
 }

        BITS_PARSE("payload_bit_equal_to_one", u4_dummy, ps_bitstrm, 1);
        payload_bits_remaining--;
 while(payload_bits_remaining)
 {
            BITS_PARSE("payload_bit_equal_to_zero", u4_dummy, ps_bitstrm, 1);
            payload_bits_remaining--;
 }
 }

 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BnMemoryHeap::BnMemoryHeap() {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_venc::set_parameter(OMX_IN OMX_HANDLETYPE     hComp,
        OMX_IN OMX_INDEXTYPE paramIndex,
        OMX_IN OMX_PTR        paramData)
{
 (void)hComp;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;


 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("ERROR: Set Param in Invalid State");
 return OMX_ErrorInvalidState;
 }
 if (paramData == NULL) {
        DEBUG_PRINT_ERROR("ERROR: Get Param in Invalid paramData");
 return OMX_ErrorBadParameter;
 }

 /*set_parameter can be called in loaded state
      or disabled port */
 if (m_state == OMX_StateLoaded
 || m_sInPortDef.bEnabled == OMX_FALSE
 || m_sOutPortDef.bEnabled == OMX_FALSE) {
        DEBUG_PRINT_LOW("Set Parameter called in valid state");
 } else {
        DEBUG_PRINT_ERROR("ERROR: Set Parameter called in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }

 switch ((int)paramIndex) {
 case OMX_IndexParamPortDefinition:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_PORTDEFINITIONTYPE);
                OMX_PARAM_PORTDEFINITIONTYPE *portDefn;
                portDefn = (OMX_PARAM_PORTDEFINITIONTYPE *) paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPortDefinition H= %d, W = %d",
 (int)portDefn->format.video.nFrameHeight,
 (int)portDefn->format.video.nFrameWidth);

 if (PORT_INDEX_IN == portDefn->nPortIndex) {
 if (!dev_is_video_session_supported(portDefn->format.video.nFrameWidth,
                                portDefn->format.video.nFrameHeight)) {
                        DEBUG_PRINT_ERROR("video session not supported");
                        omx_report_unsupported_setting();
 return OMX_ErrorUnsupportedSetting;
 }
                    DEBUG_PRINT_LOW("i/p actual cnt requested = %u", (unsigned int)portDefn->nBufferCountActual);
                    DEBUG_PRINT_LOW("i/p min cnt requested = %u", (unsigned int)portDefn->nBufferCountMin);
                    DEBUG_PRINT_LOW("i/p buffersize requested = %u", (unsigned int)portDefn->nBufferSize);
 if (portDefn->nBufferCountActual > MAX_NUM_INPUT_BUFFERS) {
                        DEBUG_PRINT_ERROR("ERROR: (In_PORT) actual count (%u) exceeds max(%u)",
 (unsigned int)portDefn->nBufferCountActual, (unsigned int)MAX_NUM_INPUT_BUFFERS);
 return OMX_ErrorUnsupportedSetting;
 }
 if (portDefn->nBufferCountMin > portDefn->nBufferCountActual) {
                        DEBUG_PRINT_ERROR("ERROR: (In_PORT) Min buffers (%u) > actual count (%u)",
 (unsigned int)portDefn->nBufferCountMin, (unsigned int)portDefn->nBufferCountActual);
 return OMX_ErrorUnsupportedSetting;
 }
 if (handle->venc_set_param(paramData,OMX_IndexParamPortDefinition) != true) {
                        DEBUG_PRINT_ERROR("ERROR: venc_set_param input failed");
 return handle->hw_overload ? OMX_ErrorInsufficientResources :
                                OMX_ErrorUnsupportedSetting;
 }

                    DEBUG_PRINT_LOW("i/p previous actual cnt = %u", (unsigned int)m_sInPortDef.nBufferCountActual);
                    DEBUG_PRINT_LOW("i/p previous min cnt = %u", (unsigned int)m_sInPortDef.nBufferCountMin);
                    memcpy(&m_sInPortDef, portDefn,sizeof(OMX_PARAM_PORTDEFINITIONTYPE));

#ifdef _ANDROID_ICS_
 if (portDefn->format.video.eColorFormat ==
 (OMX_COLOR_FORMATTYPE)QOMX_COLOR_FormatAndroidOpaque) {
                        m_sInPortDef.format.video.eColorFormat = (OMX_COLOR_FORMATTYPE)
                            QOMX_COLOR_FORMATYUV420PackedSemiPlanar32m;
 if (!mUseProxyColorFormat) {
 if (!c2d_conv.init()) {
                                DEBUG_PRINT_ERROR("C2D init failed");
 return OMX_ErrorUnsupportedSetting;
 }
                            DEBUG_PRINT_HIGH("C2D init is successful");
 }
                        mUseProxyColorFormat = true;
                        m_input_msg_id = OMX_COMPONENT_GENERATE_ETB_OPQ;
 } else
                        mUseProxyColorFormat = false;
#endif
 /*Query Input Buffer Requirements*/
                    dev_get_buf_req   (&m_sInPortDef.nBufferCountMin,
 &m_sInPortDef.nBufferCountActual,
 &m_sInPortDef.nBufferSize,
                            m_sInPortDef.nPortIndex);

 /*Query ouput Buffer Requirements*/
                    dev_get_buf_req   (&m_sOutPortDef.nBufferCountMin,
 &m_sOutPortDef.nBufferCountActual,
 &m_sOutPortDef.nBufferSize,
                            m_sOutPortDef.nPortIndex);
                    m_sInPortDef.nBufferCountActual = portDefn->nBufferCountActual;
 } else if (PORT_INDEX_OUT == portDefn->nPortIndex) {
                    DEBUG_PRINT_LOW("o/p actual cnt requested = %u", (unsigned int)portDefn->nBufferCountActual);
                    DEBUG_PRINT_LOW("o/p min cnt requested = %u", (unsigned int)portDefn->nBufferCountMin);
                    DEBUG_PRINT_LOW("o/p buffersize requested = %u", (unsigned int)portDefn->nBufferSize);
 if (portDefn->nBufferCountActual > MAX_NUM_OUTPUT_BUFFERS) {
                        DEBUG_PRINT_ERROR("ERROR: (Out_PORT) actual count (%u) exceeds max(%u)",
 (unsigned int)portDefn->nBufferCountActual, (unsigned int)MAX_NUM_OUTPUT_BUFFERS);
 return OMX_ErrorUnsupportedSetting;
 }
 if (portDefn->nBufferCountMin > portDefn->nBufferCountActual) {
                        DEBUG_PRINT_ERROR("ERROR: (Out_PORT) Min buffers (%u) > actual count (%u)",
 (unsigned int)portDefn->nBufferCountMin, (unsigned int)portDefn->nBufferCountActual);
 return OMX_ErrorUnsupportedSetting;
 }
 if (handle->venc_set_param(paramData,OMX_IndexParamPortDefinition) != true) {
                        DEBUG_PRINT_ERROR("ERROR: venc_set_param output failed");
 return OMX_ErrorUnsupportedSetting;
 }
#ifdef _MSM8974_
 /*Query ouput Buffer Requirements*/
                    dev_get_buf_req(&m_sOutPortDef.nBufferCountMin,
 &m_sOutPortDef.nBufferCountActual,
 &m_sOutPortDef.nBufferSize,
                            m_sOutPortDef.nPortIndex);
#endif
                    memcpy(&m_sOutPortDef,portDefn,sizeof(struct OMX_PARAM_PORTDEFINITIONTYPE));
                    update_profile_level(); //framerate , bitrate

                    DEBUG_PRINT_LOW("o/p previous actual cnt = %u", (unsigned int)m_sOutPortDef.nBufferCountActual);
                    DEBUG_PRINT_LOW("o/p previous min cnt = %u", (unsigned int)m_sOutPortDef.nBufferCountMin);
                    m_sOutPortDef.nBufferCountActual = portDefn->nBufferCountActual;
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Set_parameter: Bad Port idx %d",
 (int)portDefn->nPortIndex);
                    eRet = OMX_ErrorBadPortIndex;
 }
                m_sConfigFramerate.xEncodeFramerate = portDefn->format.video.xFramerate;
                m_sConfigBitrate.nEncodeBitrate = portDefn->format.video.nBitrate;
                m_sParamBitrate.nTargetBitrate = portDefn->format.video.nBitrate;
 }
 break;

 case OMX_IndexParamVideoPortFormat:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_PORTFORMATTYPE);
                OMX_VIDEO_PARAM_PORTFORMATTYPE *portFmt =
 (OMX_VIDEO_PARAM_PORTFORMATTYPE *)paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoPortFormat %d",
                        portFmt->eColorFormat);
 if (PORT_INDEX_IN == portFmt->nPortIndex) {
 if (handle->venc_set_param(paramData,OMX_IndexParamVideoPortFormat) != true) {
 return OMX_ErrorUnsupportedSetting;
 }

                    DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoPortFormat %d",
                            portFmt->eColorFormat);
                    update_profile_level(); //framerate

#ifdef _ANDROID_ICS_
 if (portFmt->eColorFormat ==
 (OMX_COLOR_FORMATTYPE)QOMX_COLOR_FormatAndroidOpaque) {
                        m_sInPortFormat.eColorFormat = (OMX_COLOR_FORMATTYPE)
                            QOMX_COLOR_FORMATYUV420PackedSemiPlanar32m;
 if (!mUseProxyColorFormat) {
 if (!c2d_conv.init()) {
                                DEBUG_PRINT_ERROR("C2D init failed");
 return OMX_ErrorUnsupportedSetting;
 }
                            DEBUG_PRINT_HIGH("C2D init is successful");
 }
                        mUseProxyColorFormat = true;
                        m_input_msg_id = OMX_COMPONENT_GENERATE_ETB_OPQ;
 } else
#endif
 {
                        m_sInPortFormat.eColorFormat = portFmt->eColorFormat;
                        m_sInPortDef.format.video.eColorFormat = portFmt->eColorFormat;
                        m_input_msg_id = OMX_COMPONENT_GENERATE_ETB;
                        mUseProxyColorFormat = false;
 }
                    m_sInPortFormat.xFramerate = portFmt->xFramerate;
 }
 }
 break;
 case OMX_IndexParamVideoInit:
 { //TODO, do we need this index set param
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_PORT_PARAM_TYPE);
                OMX_PORT_PARAM_TYPE* pParam = (OMX_PORT_PARAM_TYPE*)(paramData);
                DEBUG_PRINT_LOW("Set OMX_IndexParamVideoInit called");
 break;
 }

 case OMX_IndexParamVideoBitrate:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_BITRATETYPE);
                OMX_VIDEO_PARAM_BITRATETYPE* pParam = (OMX_VIDEO_PARAM_BITRATETYPE*)paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoBitrate");
 if (handle->venc_set_param(paramData,OMX_IndexParamVideoBitrate) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                m_sParamBitrate.nTargetBitrate = pParam->nTargetBitrate;
                m_sParamBitrate.eControlRate = pParam->eControlRate;
                update_profile_level(); //bitrate
                m_sConfigBitrate.nEncodeBitrate = pParam->nTargetBitrate;
                m_sInPortDef.format.video.nBitrate = pParam->nTargetBitrate;
                m_sOutPortDef.format.video.nBitrate = pParam->nTargetBitrate;
                DEBUG_PRINT_LOW("bitrate = %u", (unsigned int)m_sOutPortDef.format.video.nBitrate);
 break;
 }
 case OMX_IndexParamVideoMpeg4:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_MPEG4TYPE);
                OMX_VIDEO_PARAM_MPEG4TYPE* pParam = (OMX_VIDEO_PARAM_MPEG4TYPE*)paramData;
                OMX_VIDEO_PARAM_MPEG4TYPE mp4_param;
                memcpy(&mp4_param, pParam, sizeof(struct OMX_VIDEO_PARAM_MPEG4TYPE));
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoMpeg4");
 if (pParam->eProfile == OMX_VIDEO_MPEG4ProfileAdvancedSimple) {
#ifdef MAX_RES_1080P
 if (pParam->nBFrames) {
                        DEBUG_PRINT_HIGH("INFO: Only 1 Bframe is supported");
                        mp4_param.nBFrames = 1;
 }
#else
 if (pParam->nBFrames) {
                        DEBUG_PRINT_ERROR("Warning: B frames not supported");
                        mp4_param.nBFrames = 0;
 }
#endif
#ifdef _MSM8974_
 if (pParam->nBFrames || bframes)
                        mp4_param.nBFrames = (pParam->nBFrames > (unsigned int) bframes)? pParam->nBFrames : bframes;
                    DEBUG_PRINT_HIGH("MPEG4: %u BFrames are being set", (unsigned int)mp4_param.nBFrames);
#endif

 } else {
 if (pParam->nBFrames) {
                        DEBUG_PRINT_ERROR("Warning: B frames not supported");
                        mp4_param.nBFrames = 0;
 }
 }
 if (handle->venc_set_param(&mp4_param,OMX_IndexParamVideoMpeg4) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamMPEG4,pParam, sizeof(struct OMX_VIDEO_PARAM_MPEG4TYPE));
                m_sIntraperiod.nPFrames = m_sParamMPEG4.nPFrames;
 if (pParam->nBFrames || bframes)
                    m_sIntraperiod.nBFrames = m_sParamMPEG4.nBFrames = mp4_param.nBFrames;
 else
                m_sIntraperiod.nBFrames = m_sParamMPEG4.nBFrames;
 break;
 }
 case OMX_IndexParamVideoH263:
 {
                OMX_VIDEO_PARAM_H263TYPE* pParam = (OMX_VIDEO_PARAM_H263TYPE*)paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoH263");
 if (handle->venc_set_param(paramData,OMX_IndexParamVideoH263) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamH263,pParam, sizeof(struct OMX_VIDEO_PARAM_H263TYPE));
                m_sIntraperiod.nPFrames = m_sParamH263.nPFrames;
                m_sIntraperiod.nBFrames = m_sParamH263.nBFrames;
 break;
 }
 case OMX_IndexParamVideoAvc:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_AVCTYPE);
                OMX_VIDEO_PARAM_AVCTYPE* pParam = (OMX_VIDEO_PARAM_AVCTYPE*)paramData;
                OMX_VIDEO_PARAM_AVCTYPE avc_param;
                memcpy(&avc_param, pParam, sizeof( struct OMX_VIDEO_PARAM_AVCTYPE));
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoAvc");

 if ((pParam->eProfile == OMX_VIDEO_AVCProfileHigh)||
 (pParam->eProfile == OMX_VIDEO_AVCProfileMain)) {
#ifdef MAX_RES_1080P
 if (pParam->nBFrames) {
                        DEBUG_PRINT_HIGH("INFO: Only 1 Bframe is supported");
                        avc_param.nBFrames = 1;
 }
 if (pParam->nRefFrames != 2) {
                        DEBUG_PRINT_ERROR("Warning: 2 RefFrames are needed, changing RefFrames from %u to 2", (unsigned int)pParam->nRefFrames);
                        avc_param.nRefFrames = 2;
 }
#else
 if (pParam->nBFrames) {
                        DEBUG_PRINT_ERROR("Warning: B frames not supported");
                        avc_param.nBFrames = 0;
 }
 if (pParam->nRefFrames != 1) {
                        DEBUG_PRINT_ERROR("Warning: Only 1 RefFrame is supported, changing RefFrame from %u to 1)", (unsigned int)pParam->nRefFrames);
                        avc_param.nRefFrames = 1;
 }
#endif
#ifdef _MSM8974_
 if (pParam->nBFrames || bframes) {
                        avc_param.nBFrames = (pParam->nBFrames > (unsigned int) bframes)? pParam->nBFrames : bframes;
                        avc_param.nRefFrames = (avc_param.nBFrames < 4)? avc_param.nBFrames + 1 : 4;
 }
                    DEBUG_PRINT_HIGH("AVC: RefFrames: %u, BFrames: %u", (unsigned int)avc_param.nRefFrames, (unsigned int)avc_param.nBFrames);

                    avc_param.bEntropyCodingCABAC = (OMX_BOOL)(avc_param.bEntropyCodingCABAC && entropy);
                    avc_param.nCabacInitIdc = entropy ? avc_param.nCabacInitIdc : 0;
#endif
 } else {
 if (pParam->nRefFrames != 1) {
                        DEBUG_PRINT_ERROR("Warning: Only 1 RefFrame is supported, changing RefFrame from %u to 1)", (unsigned int)pParam->nRefFrames);
                        avc_param.nRefFrames = 1;
 }
 if (pParam->nBFrames) {
                        DEBUG_PRINT_ERROR("Warning: B frames not supported");
                        avc_param.nBFrames = 0;
 }
 }
 if (handle->venc_set_param(&avc_param,OMX_IndexParamVideoAvc) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamAVC,pParam, sizeof(struct OMX_VIDEO_PARAM_AVCTYPE));
                m_sIntraperiod.nPFrames = m_sParamAVC.nPFrames;
 if (pParam->nBFrames || bframes)
                    m_sIntraperiod.nBFrames = m_sParamAVC.nBFrames = avc_param.nBFrames;
 else
                m_sIntraperiod.nBFrames = m_sParamAVC.nBFrames;
 break;
 }
 case (OMX_INDEXTYPE)OMX_IndexParamVideoVp8:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_VP8TYPE);
                OMX_VIDEO_PARAM_VP8TYPE* pParam = (OMX_VIDEO_PARAM_VP8TYPE*)paramData;
                OMX_VIDEO_PARAM_VP8TYPE vp8_param;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoVp8");
 if (pParam->nDCTPartitions != m_sParamVP8.nDCTPartitions ||
                    pParam->bErrorResilientMode != m_sParamVP8.bErrorResilientMode) {
                    DEBUG_PRINT_ERROR("VP8 doesn't support nDCTPartitions or bErrorResilientMode");
 }
                memcpy(&vp8_param, pParam, sizeof( struct OMX_VIDEO_PARAM_VP8TYPE));
 if (handle->venc_set_param(&vp8_param, (OMX_INDEXTYPE)OMX_IndexParamVideoVp8) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamVP8,pParam, sizeof(struct OMX_VIDEO_PARAM_VP8TYPE));
 break;
 }
 case (OMX_INDEXTYPE)OMX_IndexParamVideoHevc:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_HEVCTYPE);
                OMX_VIDEO_PARAM_HEVCTYPE* pParam = (OMX_VIDEO_PARAM_HEVCTYPE*)paramData;
                OMX_VIDEO_PARAM_HEVCTYPE hevc_param;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoHevc");
                memcpy(&hevc_param, pParam, sizeof( struct OMX_VIDEO_PARAM_HEVCTYPE));
 if (handle->venc_set_param(&hevc_param, (OMX_INDEXTYPE)OMX_IndexParamVideoHevc) != true) {
                    DEBUG_PRINT_ERROR("Failed : set_parameter: OMX_IndexParamVideoHevc");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamHEVC, pParam, sizeof(struct OMX_VIDEO_PARAM_HEVCTYPE));
 break;
 }
 case OMX_IndexParamVideoProfileLevelCurrent:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_PROFILELEVELTYPE);
                OMX_VIDEO_PARAM_PROFILELEVELTYPE* pParam = (OMX_VIDEO_PARAM_PROFILELEVELTYPE*)paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoProfileLevelCurrent");
 if (handle->venc_set_param(pParam,OMX_IndexParamVideoProfileLevelCurrent) != true) {
                    DEBUG_PRINT_ERROR("set_parameter: OMX_IndexParamVideoProfileLevelCurrent failed for Profile: %u "
 "Level :%u", (unsigned int)pParam->eProfile, (unsigned int)pParam->eLevel);
 return OMX_ErrorUnsupportedSetting;
 }
                m_sParamProfileLevel.eProfile = pParam->eProfile;
                m_sParamProfileLevel.eLevel = pParam->eLevel;

 if (!strncmp((char *)m_nkind, "OMX.qcom.video.encoder.mpeg4",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamMPEG4.eProfile = (OMX_VIDEO_MPEG4PROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamMPEG4.eLevel = (OMX_VIDEO_MPEG4LEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("MPEG4 profile = %d, level = %d", m_sParamMPEG4.eProfile,
                            m_sParamMPEG4.eLevel);
 } else if (!strncmp((char *)m_nkind, "OMX.qcom.video.encoder.h263",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamH263.eProfile = (OMX_VIDEO_H263PROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamH263.eLevel = (OMX_VIDEO_H263LEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("H263 profile = %d, level = %d", m_sParamH263.eProfile,
                            m_sParamH263.eLevel);
 } else if (!strncmp((char *)m_nkind, "OMX.qcom.video.encoder.avc",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamAVC.eProfile = (OMX_VIDEO_AVCPROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamAVC.eLevel = (OMX_VIDEO_AVCLEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("AVC profile = %d, level = %d", m_sParamAVC.eProfile,
                            m_sParamAVC.eLevel);
 } else if (!strncmp((char *)m_nkind, "OMX.qcom.video.encoder.avc.secure",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamAVC.eProfile = (OMX_VIDEO_AVCPROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamAVC.eLevel = (OMX_VIDEO_AVCLEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("\n AVC profile = %d, level = %d", m_sParamAVC.eProfile,
                            m_sParamAVC.eLevel);
 }
 else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.vp8",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamVP8.eProfile = (OMX_VIDEO_VP8PROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamVP8.eLevel = (OMX_VIDEO_VP8LEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("VP8 profile = %d, level = %d", m_sParamVP8.eProfile,
                            m_sParamVP8.eLevel);
 }
 else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.hevc",\
                            OMX_MAX_STRINGNAME_SIZE)) {
                    m_sParamHEVC.eProfile = (OMX_VIDEO_HEVCPROFILETYPE)m_sParamProfileLevel.eProfile;
                    m_sParamHEVC.eLevel = (OMX_VIDEO_HEVCLEVELTYPE)m_sParamProfileLevel.eLevel;
                    DEBUG_PRINT_LOW("HEVC profile = %d, level = %d", m_sParamHEVC.eProfile,
                            m_sParamHEVC.eLevel);
 }

 break;
 }
 case OMX_IndexParamStandardComponentRole:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_COMPONENTROLETYPE);
                OMX_PARAM_COMPONENTROLETYPE *comp_role;
                comp_role = (OMX_PARAM_COMPONENTROLETYPE *) paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamStandardComponentRole %s",
                        comp_role->cRole);

 if ((m_state == OMX_StateLoaded)&&
 !BITMASK_PRESENT(&m_flags,OMX_COMPONENT_IDLE_PENDING)) {
                    DEBUG_PRINT_LOW("Set Parameter called in valid state");
 } else {
                    DEBUG_PRINT_ERROR("Set Parameter called in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }

 if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((char*)comp_role->cRole,"video_encoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.avc",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s", comp_role->cRole);
                        eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.avc.secure",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((char*)comp_role->cRole,"video_encoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.avc",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s\n", comp_role->cRole);
                        eRet =OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_encoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.mpeg4",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s", comp_role->cRole);
                        eRet = OMX_ErrorUnsupportedSetting;
 }
 } else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.h263",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_encoder.h263",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.h263",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s", comp_role->cRole);
                        eRet =OMX_ErrorUnsupportedSetting;
 }
 }
#ifdef _MSM8974_
 else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.vp8",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_encoder.vp8",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.vp8",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s", comp_role->cRole);
                        eRet =OMX_ErrorUnsupportedSetting;
 }
 }
#endif
 else if (!strncmp((char*)m_nkind, "OMX.qcom.video.encoder.hevc",OMX_MAX_STRINGNAME_SIZE)) {
 if (!strncmp((const char*)comp_role->cRole,"video_encoder.hevc",OMX_MAX_STRINGNAME_SIZE)) {
                        strlcpy((char*)m_cRole,"video_encoder.hevc",OMX_MAX_STRINGNAME_SIZE);
 } else {
                        DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown Index %s", comp_role->cRole);
                        eRet = OMX_ErrorUnsupportedSetting;
 }
 }

 else {
                    DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown param %s", m_nkind);
                    eRet = OMX_ErrorInvalidComponentName;
 }
 break;
 }

 case OMX_IndexParamPriorityMgmt:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_PRIORITYMGMTTYPE);
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPriorityMgmt");
 if (m_state != OMX_StateLoaded) {
                    DEBUG_PRINT_ERROR("ERROR: Set Parameter called in Invalid State");
 return OMX_ErrorIncorrectStateOperation;
 }
                OMX_PRIORITYMGMTTYPE *priorityMgmtype = (OMX_PRIORITYMGMTTYPE*) paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamPriorityMgmt %u",
 (unsigned int)priorityMgmtype->nGroupID);

                DEBUG_PRINT_LOW("set_parameter: priorityMgmtype %u",
 (unsigned int)priorityMgmtype->nGroupPriority);

                m_sPriorityMgmt.nGroupID = priorityMgmtype->nGroupID;
                m_sPriorityMgmt.nGroupPriority = priorityMgmtype->nGroupPriority;

 break;
 }

 case OMX_IndexParamCompBufferSupplier:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_PARAM_BUFFERSUPPLIERTYPE);
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamCompBufferSupplier");
                OMX_PARAM_BUFFERSUPPLIERTYPE *bufferSupplierType = (OMX_PARAM_BUFFERSUPPLIERTYPE*) paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamCompBufferSupplier %d",
                        bufferSupplierType->eBufferSupplier);
 if (bufferSupplierType->nPortIndex == 0 || bufferSupplierType->nPortIndex ==1)
                    m_sInBufSupplier.eBufferSupplier = bufferSupplierType->eBufferSupplier;

 else

                    eRet = OMX_ErrorBadPortIndex;

 break;

 }
 case OMX_IndexParamVideoQuantization:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_QUANTIZATIONTYPE);
                DEBUG_PRINT_LOW("set_parameter: OMX_IndexParamVideoQuantization");
                OMX_VIDEO_PARAM_QUANTIZATIONTYPE *session_qp = (OMX_VIDEO_PARAM_QUANTIZATIONTYPE*) paramData;
 if (session_qp->nPortIndex == PORT_INDEX_OUT) {
 if (handle->venc_set_param(paramData, OMX_IndexParamVideoQuantization) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                    m_sSessionQuantization.nQpI = session_qp->nQpI;
                    m_sSessionQuantization.nQpP = session_qp->nQpP;
                    m_sSessionQuantization.nQpB = session_qp->nQpB;
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Unsupported port Index for Session QP setting");
                    eRet = OMX_ErrorBadPortIndex;
 }
 break;
 }

 case OMX_QcomIndexParamVideoQPRange:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_VIDEO_PARAM_QPRANGETYPE);
                DEBUG_PRINT_LOW("set_parameter: OMX_QcomIndexParamVideoQPRange");
                OMX_QCOM_VIDEO_PARAM_QPRANGETYPE *qp_range = (OMX_QCOM_VIDEO_PARAM_QPRANGETYPE*) paramData;
 if (qp_range->nPortIndex == PORT_INDEX_OUT) {
 if (handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexParamVideoQPRange) != true) {
 return OMX_ErrorUnsupportedSetting;
 }
                    m_sSessionQPRange.minQP= qp_range->minQP;
                    m_sSessionQPRange.maxQP= qp_range->maxQP;
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Unsupported port Index for QP range setting");
                    eRet = OMX_ErrorBadPortIndex;
 }
 break;
 }

 case OMX_QcomIndexPortDefn:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_PARAM_PORTDEFINITIONTYPE);
                OMX_QCOM_PARAM_PORTDEFINITIONTYPE* pParam =
 (OMX_QCOM_PARAM_PORTDEFINITIONTYPE*)paramData;
                DEBUG_PRINT_LOW("set_parameter: OMX_QcomIndexPortDefn");
 if (pParam->nPortIndex == (OMX_U32)PORT_INDEX_IN) {
 if (pParam->nMemRegion > OMX_QCOM_MemRegionInvalid &&
                            pParam->nMemRegion < OMX_QCOM_MemRegionMax) {
                        m_use_input_pmem = OMX_TRUE;
 } else {
                        m_use_input_pmem = OMX_FALSE;
 }
 } else if (pParam->nPortIndex == (OMX_U32)PORT_INDEX_OUT) {
 if (pParam->nMemRegion > OMX_QCOM_MemRegionInvalid &&
                            pParam->nMemRegion < OMX_QCOM_MemRegionMax) {
                        m_use_output_pmem = OMX_TRUE;
 } else {
                        m_use_output_pmem = OMX_FALSE;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: SetParameter called on unsupported Port Index for QcomPortDefn");
 return OMX_ErrorBadPortIndex;
 }
 break;
 }

 case OMX_IndexParamVideoErrorCorrection:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE);
                DEBUG_PRINT_LOW("OMX_IndexParamVideoErrorCorrection");
                OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE* pParam =
 (OMX_VIDEO_PARAM_ERRORCORRECTIONTYPE*)paramData;
 if (!handle->venc_set_param(paramData, OMX_IndexParamVideoErrorCorrection)) {
                    DEBUG_PRINT_ERROR("ERROR: Request for setting Error Resilience failed");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sErrorCorrection,pParam, sizeof(m_sErrorCorrection));
 break;
 }
 case OMX_IndexParamVideoIntraRefresh:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_VIDEO_PARAM_INTRAREFRESHTYPE);
                DEBUG_PRINT_LOW("set_param:OMX_IndexParamVideoIntraRefresh");
                OMX_VIDEO_PARAM_INTRAREFRESHTYPE* pParam =
 (OMX_VIDEO_PARAM_INTRAREFRESHTYPE*)paramData;
 if (!handle->venc_set_param(paramData,OMX_IndexParamVideoIntraRefresh)) {
                    DEBUG_PRINT_ERROR("ERROR: Request for setting intra refresh failed");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sIntraRefresh, pParam, sizeof(m_sIntraRefresh));
 break;
 }
#ifdef _ANDROID_ICS_
 case OMX_QcomIndexParamVideoMetaBufferMode:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, StoreMetaDataInBuffersParams);
 StoreMetaDataInBuffersParams *pParam =
 (StoreMetaDataInBuffersParams*)paramData;
                DEBUG_PRINT_HIGH("set_parameter:OMX_QcomIndexParamVideoMetaBufferMode: "
 "port_index = %u, meta_mode = %d", (unsigned int)pParam->nPortIndex, pParam->bStoreMetaData);
 if (pParam->nPortIndex == PORT_INDEX_IN) {
 if (pParam->bStoreMetaData != meta_mode_enable) {
 if (!handle->venc_set_meta_mode(pParam->bStoreMetaData)) {
                            DEBUG_PRINT_ERROR("ERROR: set Metabuffer mode %d fail",
                                    pParam->bStoreMetaData);
 return OMX_ErrorUnsupportedSetting;
 }
                        meta_mode_enable = pParam->bStoreMetaData;
 if (meta_mode_enable) {
                            m_sInPortDef.nBufferCountActual = m_sInPortDef.nBufferCountMin;
 if (handle->venc_set_param(&m_sInPortDef,OMX_IndexParamPortDefinition) != true) {
                                DEBUG_PRINT_ERROR("ERROR: venc_set_param input failed");
 return OMX_ErrorUnsupportedSetting;
 }
 } else {
 /*TODO: reset encoder driver Meta mode*/
                            dev_get_buf_req   (&m_sOutPortDef.nBufferCountMin,
 &m_sOutPortDef.nBufferCountActual,
 &m_sOutPortDef.nBufferSize,
                                    m_sOutPortDef.nPortIndex);
 }
 }
 } else if (pParam->nPortIndex == PORT_INDEX_OUT && secure_session) {
 if (pParam->bStoreMetaData != meta_mode_enable) {
 if (!handle->venc_set_meta_mode(pParam->bStoreMetaData)) {
                            DEBUG_PRINT_ERROR("\nERROR: set Metabuffer mode %d fail",
                                    pParam->bStoreMetaData);
 return OMX_ErrorUnsupportedSetting;
 }
                        meta_mode_enable = pParam->bStoreMetaData;
 }
 } else {
                    DEBUG_PRINT_ERROR("set_parameter: metamode is "
 "valid for input port only");
                    eRet = OMX_ErrorUnsupportedIndex;
 }
 }
 break;
#endif
#if !defined(MAX_RES_720P) || defined(_MSM8974_)
 case OMX_QcomIndexParamIndexExtraDataType:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_INDEXEXTRADATATYPE);
                DEBUG_PRINT_HIGH("set_parameter: OMX_QcomIndexParamIndexExtraDataType");
                QOMX_INDEXEXTRADATATYPE *pParam = (QOMX_INDEXEXTRADATATYPE *)paramData;
 bool enable = false;
                OMX_U32 mask = 0;

 if (pParam->nIndex == (OMX_INDEXTYPE)OMX_ExtraDataVideoEncoderSliceInfo) {
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
                        mask = VEN_EXTRADATA_SLICEINFO;

                        DEBUG_PRINT_HIGH("SliceInfo extradata %s",
 ((pParam->bEnabled == OMX_TRUE) ? "enabled" : "disabled"));
 } else {
                        DEBUG_PRINT_ERROR("set_parameter: Slice information is "
 "valid for output port only");
                        eRet = OMX_ErrorUnsupportedIndex;
 break;
 }
 } else if (pParam->nIndex == (OMX_INDEXTYPE)OMX_ExtraDataVideoEncoderMBInfo) {
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
                        mask = VEN_EXTRADATA_MBINFO;

                        DEBUG_PRINT_HIGH("MBInfo extradata %s",
 ((pParam->bEnabled == OMX_TRUE) ? "enabled" : "disabled"));
 } else {
                        DEBUG_PRINT_ERROR("set_parameter: MB information is "
 "valid for output port only");
                        eRet = OMX_ErrorUnsupportedIndex;
 break;
 }
 }
#ifndef _MSM8974_
 else if (pParam->nIndex == (OMX_INDEXTYPE)OMX_ExtraDataVideoLTRInfo) {
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
 if (pParam->bEnabled == OMX_TRUE)
                            mask = VEN_EXTRADATA_LTRINFO;

                        DEBUG_PRINT_HIGH("LTRInfo extradata %s",
 ((pParam->bEnabled == OMX_TRUE) ? "enabled" : "disabled"));
 } else {
                        DEBUG_PRINT_ERROR("set_parameter: LTR information is "
 "valid for output port only");
                        eRet = OMX_ErrorUnsupportedIndex;
 break;
 }
 }
#endif
 else {
                    DEBUG_PRINT_ERROR("set_parameter: unsupported extrdata index (%x)",
                            pParam->nIndex);
                    eRet = OMX_ErrorUnsupportedIndex;
 break;
 }


 if (pParam->bEnabled == OMX_TRUE)
                    m_sExtraData |= mask;
 else
                    m_sExtraData &= ~mask;

                enable = !!(m_sExtraData & mask);
 if (handle->venc_set_param(&enable,
 (OMX_INDEXTYPE)pParam->nIndex) != true) {
                    DEBUG_PRINT_ERROR("ERROR: Setting Extradata (%x) failed", pParam->nIndex);
 return OMX_ErrorUnsupportedSetting;
 } else {
                    m_sOutPortDef.nPortIndex = PORT_INDEX_OUT;
                    dev_get_buf_req(&m_sOutPortDef.nBufferCountMin,
 &m_sOutPortDef.nBufferCountActual,
 &m_sOutPortDef.nBufferSize,
                            m_sOutPortDef.nPortIndex);
                    DEBUG_PRINT_HIGH("updated out_buf_req: buffer cnt=%u, "
 "count min=%u, buffer size=%u",
 (unsigned int)m_sOutPortDef.nBufferCountActual,
 (unsigned int)m_sOutPortDef.nBufferCountMin,
 (unsigned int)m_sOutPortDef.nBufferSize);
 }
 break;
 }
 case QOMX_IndexParamVideoLTRMode:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_VIDEO_PARAM_LTRMODE_TYPE);
                QOMX_VIDEO_PARAM_LTRMODE_TYPE* pParam =
 (QOMX_VIDEO_PARAM_LTRMODE_TYPE*)paramData;
 if (!handle->venc_set_param(paramData, (OMX_INDEXTYPE)QOMX_IndexParamVideoLTRMode)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting LTR mode failed");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamLTRMode, pParam, sizeof(m_sParamLTRMode));
 break;
 }
 case QOMX_IndexParamVideoLTRCount:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_VIDEO_PARAM_LTRCOUNT_TYPE);
                QOMX_VIDEO_PARAM_LTRCOUNT_TYPE* pParam =
 (QOMX_VIDEO_PARAM_LTRCOUNT_TYPE*)paramData;
 if (!handle->venc_set_param(paramData, (OMX_INDEXTYPE)QOMX_IndexParamVideoLTRCount)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting LTR count failed");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamLTRCount, pParam, sizeof(m_sParamLTRCount));
 break;
 }
#endif
 case OMX_QcomIndexParamVideoMaxAllowedBitrateCheck:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_EXTNINDEX_PARAMTYPE);
                QOMX_EXTNINDEX_PARAMTYPE* pParam =
 (QOMX_EXTNINDEX_PARAMTYPE*)paramData;
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
                    handle->m_max_allowed_bitrate_check =
 ((pParam->bEnable == OMX_TRUE) ? true : false);
                    DEBUG_PRINT_HIGH("set_parameter: max allowed bitrate check %s",
 ((pParam->bEnable == OMX_TRUE) ? "enabled" : "disabled"));
 } else {
                    DEBUG_PRINT_ERROR("ERROR: OMX_QcomIndexParamVideoMaxAllowedBitrateCheck "
 " called on wrong port(%u)", (unsigned int)pParam->nPortIndex);
 return OMX_ErrorBadPortIndex;
 }
 break;
 }
#ifdef MAX_RES_1080P
 case OMX_QcomIndexEnableSliceDeliveryMode:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_EXTNINDEX_PARAMTYPE);
                QOMX_EXTNINDEX_PARAMTYPE* pParam =
 (QOMX_EXTNINDEX_PARAMTYPE*)paramData;
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexEnableSliceDeliveryMode)) {
                        DEBUG_PRINT_ERROR("ERROR: Request for setting slice delivery mode failed");
 return OMX_ErrorUnsupportedSetting;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: OMX_QcomIndexEnableSliceDeliveryMode "
 "called on wrong port(%u)", (unsigned int)pParam->nPortIndex);
 return OMX_ErrorBadPortIndex;
 }
 break;
 }
#endif
 case OMX_QcomIndexEnableH263PlusPType:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_EXTNINDEX_PARAMTYPE);
                QOMX_EXTNINDEX_PARAMTYPE* pParam =
 (QOMX_EXTNINDEX_PARAMTYPE*)paramData;
                DEBUG_PRINT_LOW("OMX_QcomIndexEnableH263PlusPType");
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexEnableH263PlusPType)) {
                        DEBUG_PRINT_ERROR("ERROR: Request for setting PlusPType failed");
 return OMX_ErrorUnsupportedSetting;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: OMX_QcomIndexEnableH263PlusPType "
 "called on wrong port(%u)", (unsigned int)pParam->nPortIndex);
 return OMX_ErrorBadPortIndex;
 }
 break;
 }
 case OMX_QcomIndexParamSequenceHeaderWithIDR:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, PrependSPSPPSToIDRFramesParams);
 if(!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexParamSequenceHeaderWithIDR)) {
                    DEBUG_PRINT_ERROR("%s: %s",
 "OMX_QComIndexParamSequenceHeaderWithIDR:",
 "request for inband sps/pps failed.");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexParamH264AUDelimiter:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_VIDEO_CONFIG_H264_AUD);
 if(!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexParamH264AUDelimiter)) {
                    DEBUG_PRINT_ERROR("%s: %s",
 "OMX_QComIndexParamh264AUDelimiter:",
 "request for AU Delimiters failed.");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexHierarchicalStructure:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_VIDEO_HIERARCHICALLAYERS);
                QOMX_VIDEO_HIERARCHICALLAYERS* pParam =
 (QOMX_VIDEO_HIERARCHICALLAYERS*)paramData;
                DEBUG_PRINT_LOW("OMX_QcomIndexHierarchicalStructure");
 if (pParam->nPortIndex == PORT_INDEX_OUT) {
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexHierarchicalStructure)) {
                        DEBUG_PRINT_ERROR("ERROR: Request for setting PlusPType failed");
 return OMX_ErrorUnsupportedSetting;
 }
 if((pParam->eHierarchicalCodingType == QOMX_HIERARCHICALCODING_B) && pParam->nNumLayers)
                    hier_b_enabled = true;
                    m_sHierLayers.nNumLayers = pParam->nNumLayers;
                    m_sHierLayers.eHierarchicalCodingType = pParam->eHierarchicalCodingType;
 } else {
                    DEBUG_PRINT_ERROR("ERROR: OMX_QcomIndexHierarchicalStructure called on wrong port(%u)",
 (unsigned int)pParam->nPortIndex);
 return OMX_ErrorBadPortIndex;
 }
 break;

 }
 case OMX_QcomIndexParamPerfLevel:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_VIDEO_PARAM_PERF_LEVEL);
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE) OMX_QcomIndexParamPerfLevel)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting performance level");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexParamH264VUITimingInfo:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_VIDEO_PARAM_VUI_TIMING_INFO);
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE) OMX_QcomIndexParamH264VUITimingInfo)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting VUI timing info");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexParamPeakBitrate:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, OMX_QCOM_VIDEO_PARAM_PEAK_BITRATE);
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE) OMX_QcomIndexParamPeakBitrate)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting peak bitrate");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case QOMX_IndexParamVideoInitialQp:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_EXTNINDEX_VIDEO_INITIALQP);
 if(!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)QOMX_IndexParamVideoInitialQp)) {
                    DEBUG_PRINT_ERROR("Request to Enable initial QP failed");
 return OMX_ErrorUnsupportedSetting;
 }
                memcpy(&m_sParamInitqp, paramData, sizeof(m_sParamInitqp));
 break;
 }
 case OMX_QcomIndexParamSetMVSearchrange:
 {
 if (!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE) OMX_QcomIndexParamSetMVSearchrange)) {
                    DEBUG_PRINT_ERROR("ERROR: Setting Searchrange");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_QcomIndexParamVideoHybridHierpMode:
 {
                VALIDATE_OMX_PARAM_DATA(paramData, QOMX_EXTNINDEX_VIDEO_HYBRID_HP_MODE);
 if(!handle->venc_set_param(paramData,
 (OMX_INDEXTYPE)OMX_QcomIndexParamVideoHybridHierpMode)) {
                   DEBUG_PRINT_ERROR("Request to Enable Hybrid Hier-P failed");
 return OMX_ErrorUnsupportedSetting;
 }
 break;
 }
 case OMX_IndexParamVideoSliceFMO:
 default:
 {
                DEBUG_PRINT_ERROR("ERROR: Setparameter: unknown param %d", paramIndex);
                eRet = OMX_ErrorUnsupportedIndex;
 break;
 }
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: int send_event (int fd, uint16_t type, uint16_t code, int32_t value)
{
 struct uinput_event event;
    BTIF_TRACE_DEBUG("%s type:%u code:%u value:%d", __FUNCTION__,
        type, code, value);
    memset(&event, 0, sizeof(event));
    event.type  = type;

     event.code  = code;
     event.value = value;
 
    return write(fd, &event, sizeof(event));
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Edition::~Edition()
{
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SparseBitSet::initFromRanges(const uint32_t* ranges, size_t nRanges) {
 if (nRanges == 0) {
        mMaxVal = 0;
        mIndices.reset();
        mBitmaps.reset();
 return;
 }
    mMaxVal = ranges[nRanges * 2 - 1];
 size_t indexSize = (mMaxVal + kPageMask) >> kLogValuesPerPage;
    mIndices.reset(new uint32_t[indexSize]);
 uint32_t nPages = calcNumPages(ranges, nRanges);
    mBitmaps.reset(new element[nPages << (kLogValuesPerPage - kLogBitsPerEl)]);
    memset(mBitmaps.get(), 0, nPages << (kLogValuesPerPage - 3));
    mZeroPageIndex = noZeroPage;
 uint32_t nonzeroPageEnd = 0;
 uint32_t currentPage = 0;

     for (size_t i = 0; i < nRanges; i++) {
         uint32_t start = ranges[i * 2];
         uint32_t end = ranges[i * 2 + 1];
         uint32_t startPage = start >> kLogValuesPerPage;
         uint32_t endPage = (end - 1) >> kLogValuesPerPage;
         if (startPage >= nonzeroPageEnd) {
 if (startPage > nonzeroPageEnd) {
 if (mZeroPageIndex == noZeroPage) {
                    mZeroPageIndex = (currentPage++) << (kLogValuesPerPage - kLogBitsPerEl);
 }
 for (uint32_t j = nonzeroPageEnd; j < startPage; j++) {
                    mIndices[j] = mZeroPageIndex;
 }
 }
            mIndices[startPage] = (currentPage++) << (kLogValuesPerPage - kLogBitsPerEl);
 }

 size_t index = ((currentPage - 1) << (kLogValuesPerPage - kLogBitsPerEl)) +
 ((start & kPageMask) >> kLogBitsPerEl);
 size_t nElements = (end - (start & ~kElMask) + kElMask) >> kLogBitsPerEl;
 if (nElements == 1) {
            mBitmaps[index] |= (kElAllOnes >> (start & kElMask)) &
 (kElAllOnes << ((-end) & kElMask));
 } else {
            mBitmaps[index] |= kElAllOnes >> (start & kElMask);
 for (size_t j = 1; j < nElements - 1; j++) {
                mBitmaps[index + j] = kElAllOnes;
 }
            mBitmaps[index + nElements - 1] |= kElAllOnes << ((-end) & kElMask);
 }
 for (size_t j = startPage + 1; j < endPage + 1; j++) {
            mIndices[j] = (currentPage++) << (kLogValuesPerPage - kLogBitsPerEl);
 }
        nonzeroPageEnd = endPage + 1;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int get_signed_int(char **p, int DefaultValue)
{
 int Value = 0;
 unsigned char UseDefault;
 unsigned char NegativeNum = 0;

 UseDefault = 1;
  skip_blanks(p);

 if ( (**p) == '-')
 {
 NegativeNum = 1;
 (*p)++;
 }
 while ( ((**p)<= '9' && (**p)>= '0') )
 {
 Value = Value * 10 + (**p) - '0';
 UseDefault = 0;
 (*p)++;
 }

 if (UseDefault)
 return DefaultValue;
 else
 return ((NegativeNum == 0)? Value : -Value);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_pic_timing(dec_bit_stream_t *ps_bitstrm,
 dec_struct_t *ps_dec,
                               UWORD32 ui4_payload_size)
{
    sei *ps_sei;
 vui_t *ps_vu4;
    UWORD8 u1_cpb_dpb_present;
    UWORD8 u1_pic_struct_present_flag;
    UWORD32 u4_start_offset, u4_bits_consumed;
    UWORD8 u1_cpb_removal_delay_length, u1_dpb_output_delay_length;

    ps_sei = (sei *)ps_dec->ps_sei;
    ps_vu4 = &ps_dec->ps_cur_sps->s_vui;

    u1_cpb_dpb_present = ps_vu4->u1_vcl_hrd_params_present
 + ps_vu4->u1_nal_hrd_params_present;

 if(ps_vu4->u1_vcl_hrd_params_present)
 {
        u1_cpb_removal_delay_length =
                        ps_vu4->s_vcl_hrd.u1_cpb_removal_delay_length;
        u1_dpb_output_delay_length =
                        ps_vu4->s_vcl_hrd.u1_dpb_output_delay_length;
 }
 else if(ps_vu4->u1_nal_hrd_params_present)
 {
        u1_cpb_removal_delay_length =
                        ps_vu4->s_nal_hrd.u1_cpb_removal_delay_length;
        u1_dpb_output_delay_length =
                        ps_vu4->s_nal_hrd.u1_dpb_output_delay_length;
 }
 else
 {
        u1_cpb_removal_delay_length = 24;
        u1_dpb_output_delay_length = 24;

 }

    u4_start_offset = ps_bitstrm->u4_ofst;
 if(u1_cpb_dpb_present)
 {
        ih264d_get_bits_h264(ps_bitstrm, u1_cpb_removal_delay_length);
        ih264d_get_bits_h264(ps_bitstrm, u1_dpb_output_delay_length);
 }

    u1_pic_struct_present_flag = ps_vu4->u1_pic_struct_present_flag;
 if(u1_pic_struct_present_flag)
 {
        ps_sei->u1_pic_struct = ih264d_get_bits_h264(ps_bitstrm, 4);
        ps_dec->u1_pic_struct_copy = ps_sei->u1_pic_struct;
        ps_sei->u1_is_valid = 1;
 }
    u4_bits_consumed = ps_bitstrm->u4_ofst - u4_start_offset;
    ih264d_flush_bits_h264(ps_bitstrm,
 (ui4_payload_size << 3) - u4_bits_consumed);

 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ACodec::BaseState::onOMXEvent(
        OMX_EVENTTYPE event, OMX_U32 data1, OMX_U32 data2) {
 if (event != OMX_EventError) {
        ALOGV("[%s] EVENT(%d, 0x%08x, 0x%08x)",
             mCodec->mComponentName.c_str(), event, data1, data2);

 return false;
 }

    ALOGE("[%s] ERROR(0x%08x)", mCodec->mComponentName.c_str(), data1);

    OMX_ERRORTYPE omxError = (OMX_ERRORTYPE)data1;
 if (!isOMXError(omxError)) {
        ALOGW("Invalid OMX error %#x", omxError);
        omxError = OMX_ErrorUndefined;
 }
    mCodec->signalError(omxError);

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void on_srv_l2cap_le_connect_l(tBTA_JV_L2CAP_LE_OPEN *p_open, l2cap_socket *sock)
{
    l2cap_socket *accept_rs;
 uint32_t new_listen_id;

    accept_rs = btsock_l2cap_alloc_l(sock->name, (const bt_bdaddr_t*)p_open->rem_bda, FALSE, 0);
 if (accept_rs) {

        new_listen_id = accept_rs->id;
        accept_rs->id = sock->id;
        sock->id = new_listen_id;

        accept_rs->handle = p_open->handle;
        accept_rs->connected = TRUE;
        accept_rs->security = sock->security;
        accept_rs->fixed_chan = sock->fixed_chan;
        accept_rs->channel = sock->channel;

 *(p_open->p_p_cback) = (void*)btsock_l2cap_cbk;
 *(p_open->p_user_data) = (void*)accept_rs->id;

        btsock_thread_add_fd(pth, sock->our_fd, BTSOCK_L2CAP, SOCK_THREAD_FD_EXCEPTION, sock->id);
        btsock_thread_add_fd(pth, accept_rs->our_fd, BTSOCK_L2CAP, SOCK_THREAD_FD_RD,
                accept_rs->id);
        APPL_TRACE_DEBUG("sending connect signal & app fd:%dto app server to accept() the"
 " connection", accept_rs->app_fd);
        APPL_TRACE_DEBUG("server fd:%d, scn:%d", sock->our_fd, sock->channel);
        send_app_connect_signal(sock->our_fd, &accept_rs->addr, sock->channel, 0,
                accept_rs->app_fd, p_open->tx_mtu);
        accept_rs->app_fd = -1; //the fd is closed after sent to app
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline int btif_hl_select_close_connected(void){
     char sig_on = btif_hl_signal_select_close_connected;
     BTIF_TRACE_DEBUG("btif_hl_select_close_connected");
    return send(signal_fds[1], &sig_on, sizeof(sig_on), 0);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<IMediaSource> FLACExtractor::getTrack(size_t index)
{
 if (mInitCheck != OK || index > 0) {
 return NULL;
 }
 return new FLACSource(mDataSource, mTrackMetadata);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SoftAVC::deInitDecoder() {
 size_t i;
    IV_API_CALL_STATUS_T status;

 if (mCodecCtx) {
 ivdext_delete_ip_t s_delete_ip;
 ivdext_delete_op_t s_delete_op;

        s_delete_ip.s_ivd_delete_ip_t.u4_size = sizeof(ivdext_delete_ip_t);
        s_delete_ip.s_ivd_delete_ip_t.e_cmd = IVD_CMD_DELETE;

        s_delete_op.s_ivd_delete_op_t.u4_size = sizeof(ivdext_delete_op_t);

        status = ivdec_api_function(mCodecCtx, (void *)&s_delete_ip, (void *)&s_delete_op);
 if (status != IV_SUCCESS) {
            ALOGE("Error in delete: 0x%x",
                    s_delete_op.s_ivd_delete_op_t.u4_error_code);
 return UNKNOWN_ERROR;
 }
 }


    mChangingResolution = false;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Track::GetType() const
{
    return m_info.type;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void InputDispatcher::releaseInboundEventLocked(EventEntry* entry) {
 InjectionState* injectionState = entry->injectionState;
 if (injectionState && injectionState->injectionResult == INPUT_EVENT_INJECTION_PENDING) {
#if DEBUG_DISPATCH_CYCLE
        ALOGD("Injected inbound event was dropped.");
#endif
        setInjectionResultLocked(entry, INPUT_EVENT_INJECTION_FAILED);
 }
 if (entry == mNextUnblockedEvent) {
        mNextUnblockedEvent = NULL;
 }
    addRecentEventLocked(entry);
    entry->release();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;


 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
        ih264d_err_pic_dispbuf_mgr(ps_dec);
 return 0;
 }

 if(ps_dec->ps_cur_slice->u1_mbaff_frame_flag && (num_mb_skip & 1))
 {
        num_mb_skip++;
 }
    ps_dec->ps_dpb_cmds->u1_long_term_reference_flag = 0;
 if(prev_slice_err == 1)
 {
 /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;


 if(!ps_dec->u1_first_slice_in_stream)
 {
            ih264d_end_of_pic(ps_dec, u1_is_idr_slice,
                ps_dec->ps_cur_slice->u2_frame_num);
            ps_dec->s_cur_pic_poc.u2_frame_num =
                ps_dec->ps_cur_slice->u2_frame_num;
 }

 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = -1;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 {
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
 {
 if(ps_dec->ps_pps[i].ps_sps->u1_is_valid == TRUE)
 {
                           j = i;
 break;
 }
 }
 }

 if(j == -1)
 {
 return ERROR_INV_SPS_PPS_T;
 }

 /* call ih264d_start_of_pic only if it was not called earlier*/
 if(ps_dec->u4_pic_buf_got == 0)
 {
                ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
                ps_dec->ps_cur_slice->u1_nal_ref_idc = 1;
                ps_dec->ps_cur_slice->u1_nal_unit_type = 1;
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }
 }
        ps_dec->u4_first_slice_in_pic = 0;
 }
 else
 {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
 if((u1_mbaff) && (ps_dec->u4_num_mbs_cur_nmb & 1))
 {
                ps_dec->u4_num_mbs_cur_nmb = ps_dec->u4_num_mbs_cur_nmb - 1;
                ps_dec->u2_cur_mb_addr--;
 }

            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;
 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

 if(u1_num_mbs)
 {
                ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
                ps_dec->u2_cur_mb_addr--;
                ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

 /* Inserting new slice only if the current slice has atleast 1 MB*/
 if(ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice <
 (UWORD32)(ps_dec->u2_total_mbs_coded >> ps_slice->u1_mbaff_frame_flag))
 {
                ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
                ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
                ps_dec->u2_cur_slice_num++;
                ps_dec->ps_parse_cur_slice++;
 }

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_cur_slice->i1_slice_alpha_c0_offset = 0;
    ps_dec->ps_cur_slice->i1_slice_beta_offset = 0;

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;
    ps_dec->u2_mbx =
 (MOD(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby =
 (DIV(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby <<= u1_mbaff;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

    H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);


 /* incremented here only if first slice is inserted */
 if(ps_dec->u4_first_slice_in_pic != 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: Tags::SimpleTag::SimpleTag() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtUseOptions(xmlParserCtxtPtr ctxt, int options)
{
 return(xmlCtxtUseOptionsInternal(ctxt, options, NULL));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: decode_rfc3442_rt(int dl, const uint8_t *data)
{
 const uint8_t *p = data;
 const uint8_t *e;
 uint8_t cidr;
 size_t ocets;
 struct rt *routes = NULL;
 struct rt *rt = NULL;

 /* Minimum is 5 -first is CIDR and a router length of 4 */
 if (dl < 5)
 return NULL;

	e = p + dl;
 while (p < e) {
		cidr = *p++;
 if (cidr > 32) {
			free_routes(routes);
			errno = EINVAL;
 return NULL;
 }

 if (rt) {
			rt->next = xzalloc(sizeof(*rt));
			rt = rt->next;
 } else {
			routes = rt = xzalloc(sizeof(*routes));
 }
		rt->next = NULL;

		ocets = (cidr + 7) / 8;
 /* If we have ocets then we have a destination and netmask */
 if (ocets > 0) {
			memcpy(&rt->dest.s_addr, p, ocets);
			p += ocets;
			rt->net.s_addr = htonl(~0U << (32 - cidr));
 }

 /* Finally, snag the router */
		memcpy(&rt->gate.s_addr, p, 4);
		p += 4;
 }
 return routes;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftOpus::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.opus",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidOpus:
 {

             const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *opusParams =
                 (const OMX_AUDIO_PARAM_ANDROID_OPUSTYPE *)params;
 
             if (opusParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParse3986DecOctet(const char **str) {
 const char *cur = *str;

 if (!(ISA_DIGIT(cur)))
 return(1);
 if (!ISA_DIGIT(cur+1))
	cur++;
 else if ((*cur != '0') && (ISA_DIGIT(cur + 1)) && (!ISA_DIGIT(cur+2)))
	cur += 2;
 else if ((*cur == '1') && (ISA_DIGIT(cur + 1)) && (ISA_DIGIT(cur + 2)))
	cur += 3;
 else if ((*cur == '2') && (*(cur + 1) >= '0') &&
 (*(cur + 1) <= '4') && (ISA_DIGIT(cur + 2)))
	cur += 3;
 else if ((*cur == '2') && (*(cur + 1) == '5') &&
 (*(cur + 2) >= '0') && (*(cur + 1) <= '5'))
	cur += 3;
 else
 return(1);
 *str = cur;
 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void GraphicBuffer::dumpAllocationsToSystemLog()
{
 GraphicBufferAllocator::dumpToSystemLog();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bt_status_t src_connect_sink(RawAddress* bd_addr) {
  BTIF_TRACE_EVENT("%s", __func__);
  CHECK_BTAV_INIT();

 return btif_queue_connect(UUID_SERVCLASS_AUDIO_SOURCE, bd_addr, connect_int);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int LvmBundle_process(LVM_INT16        *pIn,
                      LVM_INT16        *pOut,
 int              frameCount,
 EffectContext *pContext){

 LVM_ControlParams_t ActiveParams; /* Current control Parameters */
    LVM_ReturnStatus_en     LvmStatus = LVM_SUCCESS; /* Function call status */
    LVM_INT16               *pOutTmp;

 if (pContext->config.outputCfg.accessMode == EFFECT_BUFFER_ACCESS_WRITE){
        pOutTmp = pOut;
 } else if (pContext->config.outputCfg.accessMode == EFFECT_BUFFER_ACCESS_ACCUMULATE){
 if (pContext->pBundledContext->frameCount != frameCount) {
 if (pContext->pBundledContext->workBuffer != NULL) {
                free(pContext->pBundledContext->workBuffer);
 }
            pContext->pBundledContext->workBuffer =
 (LVM_INT16 *)calloc(frameCount, sizeof(LVM_INT16) * 2);
 if (pContext->pBundledContext->workBuffer == NULL) {
 return -ENOMEM;
 }
            pContext->pBundledContext->frameCount = frameCount;
 }
        pOutTmp = pContext->pBundledContext->workBuffer;
 } else {
        ALOGV("LVM_ERROR : LvmBundle_process invalid access mode");
 return -EINVAL;
 }

 #ifdef LVM_PCM
    fwrite(pIn, frameCount*sizeof(LVM_INT16)*2, 1, pContext->pBundledContext->PcmInPtr);
    fflush(pContext->pBundledContext->PcmInPtr);
 #endif


 /* Process the samples */
 LvmStatus = LVM_Process(pContext->pBundledContext->hInstance, /* Instance handle */
                            pIn, /* Input buffer */
                            pOutTmp, /* Output buffer */
 (LVM_UINT16)frameCount, /* Number of samples to read */
 0); /* Audo Time */

    LVM_ERROR_CHECK(LvmStatus, "LVM_Process", "LvmBundle_process")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

 #ifdef LVM_PCM
    fwrite(pOutTmp, frameCount*sizeof(LVM_INT16)*2, 1, pContext->pBundledContext->PcmOutPtr);
    fflush(pContext->pBundledContext->PcmOutPtr);
 #endif

 if (pContext->config.outputCfg.accessMode == EFFECT_BUFFER_ACCESS_ACCUMULATE){
 for (int i=0; i<frameCount*2; i++){
            pOut[i] = clamp16((LVM_INT32)pOut[i] + (LVM_INT32)pOutTmp[i]);
 }
 }
 return 0;
} /* end LvmBundle_process */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<IRemoteDisplay> MediaPlayerService::listenForRemoteDisplay(
 const String16 &opPackageName,
 const sp<IRemoteDisplayClient>& client, const String8& iface) {
 if (!checkPermission("android.permission.CONTROL_WIFI_DISPLAY")) {
 return NULL;
 }

 return new RemoteDisplay(opPackageName, client, iface.string());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectModule::stop()
{
 Mutex::Autolock _l(mLock);
 return stop_l();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::afterKeyEventLockedInterruptible(const sp<Connection>& connection,
 DispatchEntry* dispatchEntry, KeyEntry* keyEntry, bool handled) {
 if (!(keyEntry->flags & AKEY_EVENT_FLAG_FALLBACK)) {
 int32_t originalKeyCode = keyEntry->keyCode;
 int32_t fallbackKeyCode = connection->inputState.getFallbackKey(originalKeyCode);
 if (keyEntry->action == AKEY_EVENT_ACTION_UP) {
            connection->inputState.removeFallbackKey(originalKeyCode);
 }

 if (handled || !dispatchEntry->hasForegroundTarget()) {
 if (fallbackKeyCode != -1) {
#if DEBUG_OUTBOUND_EVENT_DETAILS
                ALOGD("Unhandled key event: Asking policy to cancel fallback action.  "
 "keyCode=%d, action=%d, repeatCount=%d, policyFlags=0x%08x",
                        keyEntry->keyCode, keyEntry->action, keyEntry->repeatCount,
                        keyEntry->policyFlags);
#endif
 KeyEvent event;
                initializeKeyEvent(&event, keyEntry);
                event.setFlags(event.getFlags() | AKEY_EVENT_FLAG_CANCELED);

                mLock.unlock();

                mPolicy->dispatchUnhandledKey(connection->inputWindowHandle,
 &event, keyEntry->policyFlags, &event);

                mLock.lock();

 if (fallbackKeyCode != AKEYCODE_UNKNOWN) {
 CancelationOptions options(CancelationOptions::CANCEL_FALLBACK_EVENTS,
 "application handled the original non-fallback key "
 "or is no longer a foreground target, "
 "canceling previously dispatched fallback key");
                    options.keyCode = fallbackKeyCode;
                    synthesizeCancelationEventsForConnectionLocked(connection, options);
 }
                connection->inputState.removeFallbackKey(originalKeyCode);
 }
 } else {
 bool initialDown = keyEntry->action == AKEY_EVENT_ACTION_DOWN
 && keyEntry->repeatCount == 0;
 if (fallbackKeyCode == -1 && !initialDown) {
#if DEBUG_OUTBOUND_EVENT_DETAILS
                ALOGD("Unhandled key event: Skipping unhandled key event processing "
 "since this is not an initial down.  "
 "keyCode=%d, action=%d, repeatCount=%d, policyFlags=0x%08x",
                        originalKeyCode, keyEntry->action, keyEntry->repeatCount,
                        keyEntry->policyFlags);
#endif
 return false;
 }

#if DEBUG_OUTBOUND_EVENT_DETAILS
            ALOGD("Unhandled key event: Asking policy to perform fallback action.  "
 "keyCode=%d, action=%d, repeatCount=%d, policyFlags=0x%08x",
                    keyEntry->keyCode, keyEntry->action, keyEntry->repeatCount,
                    keyEntry->policyFlags);
#endif
 KeyEvent event;
            initializeKeyEvent(&event, keyEntry);

            mLock.unlock();

 bool fallback = mPolicy->dispatchUnhandledKey(connection->inputWindowHandle,
 &event, keyEntry->policyFlags, &event);

            mLock.lock();

 if (connection->status != Connection::STATUS_NORMAL) {
                connection->inputState.removeFallbackKey(originalKeyCode);
 return false;
 }

 if (initialDown) {
 if (fallback) {
                    fallbackKeyCode = event.getKeyCode();
 } else {
                    fallbackKeyCode = AKEYCODE_UNKNOWN;
 }
                connection->inputState.setFallbackKey(originalKeyCode, fallbackKeyCode);
 }

            ALOG_ASSERT(fallbackKeyCode != -1);

 if (fallbackKeyCode != AKEYCODE_UNKNOWN
 && (!fallback || fallbackKeyCode != event.getKeyCode())) {
#if DEBUG_OUTBOUND_EVENT_DETAILS
 if (fallback) {
                    ALOGD("Unhandled key event: Policy requested to send key %d"
 "as a fallback for %d, but on the DOWN it had requested "
 "to send %d instead.  Fallback canceled.",
                            event.getKeyCode(), originalKeyCode, fallbackKeyCode);
 } else {
                    ALOGD("Unhandled key event: Policy did not request fallback for %d, "
 "but on the DOWN it had requested to send %d.  "
 "Fallback canceled.",
                            originalKeyCode, fallbackKeyCode);
 }
#endif

 CancelationOptions options(CancelationOptions::CANCEL_FALLBACK_EVENTS,
 "canceling fallback, policy no longer desires it");
                options.keyCode = fallbackKeyCode;
                synthesizeCancelationEventsForConnectionLocked(connection, options);

                fallback = false;
                fallbackKeyCode = AKEYCODE_UNKNOWN;
 if (keyEntry->action != AKEY_EVENT_ACTION_UP) {
                    connection->inputState.setFallbackKey(originalKeyCode,
                            fallbackKeyCode);
 }
 }

#if DEBUG_OUTBOUND_EVENT_DETAILS
 {
 String8 msg;
 const KeyedVector<int32_t, int32_t>& fallbackKeys =
                        connection->inputState.getFallbackKeys();
 for (size_t i = 0; i < fallbackKeys.size(); i++) {
                    msg.appendFormat(", %d->%d", fallbackKeys.keyAt(i),
                            fallbackKeys.valueAt(i));
 }
                ALOGD("Unhandled key event: %d currently tracked fallback keys%s.",
                        fallbackKeys.size(), msg.string());
 }
#endif

 if (fallback) {
                keyEntry->eventTime = event.getEventTime();
                keyEntry->deviceId = event.getDeviceId();
                keyEntry->source = event.getSource();
                keyEntry->flags = event.getFlags() | AKEY_EVENT_FLAG_FALLBACK;
                keyEntry->keyCode = fallbackKeyCode;
                keyEntry->scanCode = event.getScanCode();
                keyEntry->metaState = event.getMetaState();
                keyEntry->repeatCount = event.getRepeatCount();
                keyEntry->downTime = event.getDownTime();
                keyEntry->syntheticRepeat = false;

#if DEBUG_OUTBOUND_EVENT_DETAILS
                ALOGD("Unhandled key event: Dispatching fallback key.  "
 "originalKeyCode=%d, fallbackKeyCode=%d, fallbackMetaState=%08x",
                        originalKeyCode, fallbackKeyCode, keyEntry->metaState);
#endif
 return true; // restart the event
 } else {
#if DEBUG_OUTBOUND_EVENT_DETAILS
                ALOGD("Unhandled key event: No fallback key.");
#endif
 }
 }
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Chapters* Segment::GetChapters() const { return m_pChapters; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t vp8_set_reference(vpx_codec_alg_priv_t *ctx,
                                         va_list args)
{

 vpx_ref_frame_t *data = va_arg(args, vpx_ref_frame_t *);

 if (data && !ctx->yv12_frame_buffers.use_frame_threads)
 {
 vpx_ref_frame_t *frame = (vpx_ref_frame_t *)data;
        YV12_BUFFER_CONFIG sd;

        image2yuvconfig(&frame->img, &sd);

 return vp8dx_set_reference(ctx->yv12_frame_buffers.pbi[0],
                                   frame->frame_type, &sd);
 }
 else
 return VPX_CODEC_INVALID_PARAM;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftHEVC::onQueueFilled(OMX_U32 portIndex) {
    UNUSED(portIndex);

 if (mSignalledError) {
 return;
 }
 if (mOutputPortSettingsChange != NONE) {
 return;
 }

 
     if (NULL == mCodecCtx) {
         if (OK != initDecoder()) {
             return;
         }
     }
 if (outputBufferWidth() != mStride) {
 /* Set the run-time (dynamic) parameters */
        mStride = outputBufferWidth();
        setParams(mStride);
 }

 List<BufferInfo *> &inQueue = getPortQueue(kInputPortIndex);
 List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);

 /* If input EOS is seen and decoder is not in flush mode,
     * set the decoder in flush mode.
     * There can be a case where EOS is sent along with last picture data
     * In that case, only after decoding that input data, decoder has to be
     * put in flush. This case is handled here  */

 if (mReceivedEOS && !mIsInFlush) {
        setFlushMode();
 }

 while (!outQueue.empty()) {
 BufferInfo *inInfo;
        OMX_BUFFERHEADERTYPE *inHeader;

 BufferInfo *outInfo;
        OMX_BUFFERHEADERTYPE *outHeader;
 size_t timeStampIx;

        inInfo = NULL;
        inHeader = NULL;

 if (!mIsInFlush) {
 if (!inQueue.empty()) {
                inInfo = *inQueue.begin();
                inHeader = inInfo->mHeader;
 } else {
 break;
 }
 }

        outInfo = *outQueue.begin();
        outHeader = outInfo->mHeader;
        outHeader->nFlags = 0;
        outHeader->nTimeStamp = 0;
        outHeader->nOffset = 0;

 if (inHeader != NULL && (inHeader->nFlags & OMX_BUFFERFLAG_EOS)) {
            mReceivedEOS = true;
 if (inHeader->nFilledLen == 0) {
                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;
                setFlushMode();
 }
 }

 /* Get a free slot in timestamp array to hold input timestamp */
 {
 size_t i;
            timeStampIx = 0;
 for (i = 0; i < MAX_TIME_STAMPS; i++) {
 if (!mTimeStampsValid[i]) {
                    timeStampIx = i;
 break;
 }
 }
 if (inHeader != NULL) {
                mTimeStampsValid[timeStampIx] = true;
                mTimeStamps[timeStampIx] = inHeader->nTimeStamp;
 }
 }

 {
 ivd_video_decode_ip_t s_dec_ip;
 ivd_video_decode_op_t s_dec_op;
            WORD32 timeDelay, timeTaken;
 size_t sizeY, sizeUV;

 if (!setDecodeArgs(&s_dec_ip, &s_dec_op, inHeader, outHeader, timeStampIx)) {
                ALOGE("Decoder arg setup failed");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
                mSignalledError = true;
 return;
 }

            GETTIME(&mTimeStart, NULL);
 /* Compute time elapsed between end of previous decode()
             * to start of current decode() */
            TIME_DIFF(mTimeEnd, mTimeStart, timeDelay);


             IV_API_CALL_STATUS_T status;
             status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);
 
             bool resChanged = (IVD_RES_CHANGED == (s_dec_op.u4_error_code & 0xFF));
 
             GETTIME(&mTimeEnd, NULL);
 /* Compute time taken for decode() */
            TIME_DIFF(mTimeStart, mTimeEnd, timeTaken);

            ALOGV("timeTaken=%6d delay=%6d numBytes=%6d", timeTaken, timeDelay,
                   s_dec_op.u4_num_bytes_consumed);
 if (s_dec_op.u4_frame_decoded_flag && !mFlushNeeded) {
                mFlushNeeded = true;
 }

 if ((inHeader != NULL) && (1 != s_dec_op.u4_frame_decoded_flag)) {
 /* If the input did not contain picture data, then ignore
                 * the associated timestamp */
                mTimeStampsValid[timeStampIx] = false;
 }

 if (mChangingResolution && !s_dec_op.u4_output_present) {
                mChangingResolution = false;
                resetDecoder();
                resetPlugin();
 continue;
 }

 if (resChanged) {
                mChangingResolution = true;
 if (mFlushNeeded) {
                    setFlushMode();
 }
 continue;
 }

 if ((0 < s_dec_op.u4_pic_wd) && (0 < s_dec_op.u4_pic_ht)) {
 uint32_t width = s_dec_op.u4_pic_wd;
 uint32_t height = s_dec_op.u4_pic_ht;
 bool portWillReset = false;
                handlePortSettingsChange(&portWillReset, width, height);

 if (portWillReset) {
                    resetDecoder();
 return;
 }
 }

 if (s_dec_op.u4_output_present) {
                outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;

                outHeader->nTimeStamp = mTimeStamps[s_dec_op.u4_ts];
                mTimeStampsValid[s_dec_op.u4_ts] = false;

                outInfo->mOwnedByUs = false;
                outQueue.erase(outQueue.begin());
                outInfo = NULL;
                notifyFillBufferDone(outHeader);
                outHeader = NULL;
 } else {
 /* If in flush mode and no output is returned by the codec,
                 * then come out of flush mode */
                mIsInFlush = false;

 /* If EOS was recieved on input port and there is no output
                 * from the codec, then signal EOS on output port */
 if (mReceivedEOS) {
                    outHeader->nFilledLen = 0;
                    outHeader->nFlags |= OMX_BUFFERFLAG_EOS;

                    outInfo->mOwnedByUs = false;
                    outQueue.erase(outQueue.begin());
                    outInfo = NULL;
                    notifyFillBufferDone(outHeader);
                    outHeader = NULL;
                    resetPlugin();
 }
 }
 }

 if (inHeader != NULL) {
            inInfo->mOwnedByUs = false;
            inQueue.erase(inQueue.begin());
            inInfo = NULL;
            notifyEmptyBufferDone(inHeader);
            inHeader = NULL;
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftVideoDecoderOMXComponent::CropSettingsMode SoftAVC::handleCropParams(
 const H264SwDecInfo& decInfo) {
 if (!decInfo.croppingFlag) {
 return kCropUnSet;
 }

 const CropParams& crop = decInfo.cropParams;
 if (mCropLeft == crop.cropLeftOffset &&
        mCropTop == crop.cropTopOffset &&
        mCropWidth == crop.cropOutWidth &&
        mCropHeight == crop.cropOutHeight) {
 return kCropSet;
 }

    mCropLeft = crop.cropLeftOffset;
    mCropTop = crop.cropTopOffset;
    mCropWidth = crop.cropOutWidth;
    mCropHeight = crop.cropOutHeight;
 return kCropChanged;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: main(void)
{

    fwrite(signature, sizeof signature, 1, stdout);
    put_chunk(IHDR, sizeof IHDR);
 
   for(;;)
       put_chunk(unknown, sizeof unknown);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::notifyBufferingUpdate(int32_t percentage) {
 if (percentage < mPrevBufferPercentage) {
        percentage = mPrevBufferPercentage;
 } else if (percentage > 100) {
        percentage = 100;
 }

    mPrevBufferPercentage = percentage;

    ALOGV("notifyBufferingUpdate: buffering %d%%", percentage);

    sp<AMessage> msg = dupNotify();
    msg->setInt32("what", kWhatBufferingUpdate);
    msg->setInt32("percentage", percentage);
    msg->post();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long CuePoint::GetTime(const Segment* pSegment) const {
  assert(pSegment);
  assert(m_timecode >= 0);

 const SegmentInfo* const pInfo = pSegment->GetInfo();
  assert(pInfo);

 const long long scale = pInfo->GetTimeCodeScale();
  assert(scale >= 1);

 const long long time = scale * m_timecode;

 return time;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  static void parseMacAddress(const char *str, mac_addr addr) {
    addr[0] = parseHexByte(str);
    addr[1] = parseHexByte(str);
    addr[2] = parseHexByte(str);
    addr[3] = parseHexByte(str);
    addr[4] = parseHexByte(str);
    addr[5] = parseHexByte(str);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundTriggerHwService::CallbackThread::exit()
{
 Mutex::Autolock _l(mCallbackLock);
    requestExit();
    mCallbackCond.broadcast();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int read_package_list(struct fuse_global* global) {
    pthread_mutex_lock(&global->lock);

    hashmapForEach(global->package_to_appid, remove_str_to_int, global->package_to_appid);

 FILE* file = fopen(kPackagesListFile, "r");
 if (!file) {
        ERROR("failed to open package list: %s\n", strerror(errno));
        pthread_mutex_unlock(&global->lock);
 return -1;
 }

 char buf[512];
 while (fgets(buf, sizeof(buf), file) != NULL) {
 char package_name[512];
 int appid;
 char gids[512];

 if (sscanf(buf, "%s %d %*d %*s %*s %s", package_name, &appid, gids) == 3) {
 char* package_name_dup = strdup(package_name);
            hashmapPut(global->package_to_appid, package_name_dup, (void*) (uintptr_t) appid);
 }
 }

    TRACE("read_package_list: found %zu packages\n",
            hashmapSize(global->package_to_appid));
    fclose(file);

 /* Regenerate ownership details using newly loaded mapping */
    derive_permissions_recursive_locked(global->fuse_default, &global->root);

    pthread_mutex_unlock(&global->lock);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_pic_data_thread(dec_state_t *ps_dec)
{
    WORD32 i4_continue_decode;

    WORD32 i4_cur_row, temp;
    UWORD32 u4_bits_read;
    WORD32 i4_dequeue_job;
    IMPEG2D_ERROR_CODES_T e_error;

    i4_cur_row = ps_dec->u2_mb_y + 1;

    i4_continue_decode = 1;

    i4_dequeue_job = 1;
 do
 {
 if(i4_cur_row > ps_dec->u2_num_vert_mb)
 {
            i4_continue_decode = 0;
 break;
 }

 {
 if((ps_dec->i4_num_cores> 1) && (i4_dequeue_job))
 {
 job_t s_job;
                IV_API_CALL_STATUS_T e_ret;
                UWORD8 *pu1_buf;

                e_ret = impeg2_jobq_dequeue(ps_dec->pv_jobq, &s_job, sizeof(s_job), 1, 1);
 if(e_ret != IV_SUCCESS)
 break;

 if(CMD_PROCESS == s_job.i4_cmd)
 {
                    pu1_buf = ps_dec->pu1_inp_bits_buf + s_job.i4_bistream_ofst;
                    impeg2d_bit_stream_init(&(ps_dec->s_bit_stream), pu1_buf,
 (ps_dec->u4_num_inp_bytes - s_job.i4_bistream_ofst));
                    i4_cur_row      = s_job.i2_start_mb_y;
                    ps_dec->i4_start_mb_y = s_job.i2_start_mb_y;
                    ps_dec->i4_end_mb_y = s_job.i2_end_mb_y;
                    ps_dec->u2_mb_x = 0;
                    ps_dec->u2_mb_y = ps_dec->i4_start_mb_y;
                    ps_dec->u2_num_mbs_left = (ps_dec->i4_end_mb_y - ps_dec->i4_start_mb_y) * ps_dec->u2_num_horiz_mb;

 }
 else
 {
                    WORD32 start_row;
                    WORD32 num_rows;
                    start_row = s_job.i2_start_mb_y << 4;
                    num_rows = MIN((s_job.i2_end_mb_y << 4), ps_dec->u2_vertical_size);
                    num_rows -= start_row;

 if(ps_dec->u4_deinterlace && (0 == ps_dec->u2_progressive_frame))
 {
                        impeg2d_deinterlace(ps_dec,
                                            ps_dec->ps_disp_pic,
                                            ps_dec->ps_disp_frm_buf,
                                            start_row,
                                            num_rows);

 }
 else
 {
                        impeg2d_format_convert(ps_dec, ps_dec->ps_disp_pic,
                                               ps_dec->ps_disp_frm_buf,
                                               start_row, num_rows);
 }
 break;

 }

 }
            e_error = impeg2d_dec_slice(ps_dec);

 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
                impeg2d_next_start_code(ps_dec);
 if(ps_dec->s_bit_stream.u4_offset >= ps_dec->s_bit_stream.u4_max_offset)
 {
                    ps_dec->u4_error_code = IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;
 return;
 }
 }
 }

 /* Detecting next slice start code */
 while(1)
 {
            u4_bits_read = impeg2d_bit_stream_nxt(&ps_dec->s_bit_stream,START_CODE_LEN);
            temp = u4_bits_read & 0xFF;
            i4_continue_decode = (((u4_bits_read >> 8) == 0x01) && (temp) && (temp <= 0xAF));

 if (1 == ps_dec->i4_num_cores && 0 == ps_dec->u2_num_mbs_left)
 {
                i4_continue_decode = 0;
#ifdef __ANDROID__
                android_errorWriteLog(0x534e4554, "26070014");
#endif
 }

 if(i4_continue_decode)
 {
 if (0 != ps_dec->u2_num_mbs_left)
 {
 /* If the slice is from the same row, then continue decoding without dequeue */
 if((temp - 1) == i4_cur_row)
 {
                        i4_dequeue_job = 0;
 }
 else
 {
 if(temp < ps_dec->i4_end_mb_y)
 {
                            i4_cur_row = ps_dec->u2_mb_y;
 }
 else
 {
                            i4_dequeue_job = 1;
 }
 }
 }
 else
 {
                    i4_dequeue_job = 1;
 }
 break;
 }
 else
 break;
 }

 }while(i4_continue_decode);
 if(ps_dec->i4_num_cores > 1)
 {
 while(1)
 {
 job_t s_job;
            IV_API_CALL_STATUS_T e_ret;

            e_ret = impeg2_jobq_dequeue(ps_dec->pv_jobq, &s_job, sizeof(s_job), 1, 1);
 if(e_ret != IV_SUCCESS)
 break;
 if(CMD_FMTCONV == s_job.i4_cmd)
 {
                WORD32 start_row;
                WORD32 num_rows;
                start_row = s_job.i2_start_mb_y << 4;
                num_rows = MIN((s_job.i2_end_mb_y << 4), ps_dec->u2_vertical_size);
                num_rows -= start_row;
 if(ps_dec->u4_deinterlace && (0 == ps_dec->u2_progressive_frame))
 {
                    impeg2d_deinterlace(ps_dec,
                                        ps_dec->ps_disp_pic,
                                        ps_dec->ps_disp_frm_buf,
                                        start_row,
                                        num_rows);

 }
 else
 {
                    impeg2d_format_convert(ps_dec,
                                           ps_dec->ps_disp_pic,
                                           ps_dec->ps_disp_frm_buf,
                                           start_row,
                                           num_rows);
 }
 }
 }
 }
 else
 {
 if((NULL != ps_dec->ps_disp_pic) && ((0 == ps_dec->u4_share_disp_buf) || (IV_YUV_420P != ps_dec->i4_chromaFormat)))
 {
 if(ps_dec->u4_deinterlace && (0 == ps_dec->u2_progressive_frame))
 {
                impeg2d_deinterlace(ps_dec,
                                    ps_dec->ps_disp_pic,
                                    ps_dec->ps_disp_frm_buf,
 0,
                                    ps_dec->u2_vertical_size);

 }
 else
 {
                impeg2d_format_convert(ps_dec, ps_dec->ps_disp_pic,
                                        ps_dec->ps_disp_frm_buf,
 0, ps_dec->u2_vertical_size);
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void NuPlayer::NuPlayerStreamListener::issueCommand(
 Command cmd, bool synchronous, const sp<AMessage> &extra) {
    CHECK(!synchronous);

 QueueEntry entry;
    entry.mIsCommand = true;
    entry.mCommand = cmd;
    entry.mExtra = extra;

 Mutex::Autolock autoLock(mLock);
    mQueue.push_back(entry);

 if (mSendDataNotification) {
        mSendDataNotification = false;

 if (mTargetHandler != NULL) {
 (new AMessage(kWhatMoreDataQueued, mTargetHandler))->post();
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char * EqualizerGetPresetName(int32_t preset){
 if (preset == PRESET_CUSTOM) {
 return "Custom";
 } else {
 return gEqualizerPresets[preset].name;
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  random_32(void)
 {
 
   for(;;)
    {
       png_byte mark[4];
       png_uint_32 result;

      store_pool_mark(mark);
      result = png_get_uint_32(mark);

 if (result != 0)
 return result;
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: SYSCALL_DEFINE3(setresgid, gid_t, rgid, gid_t, egid, gid_t, sgid)
{
 const struct cred *old;
 struct cred *new;
 int retval;

 new = prepare_creds();
 if (!new)
 return -ENOMEM;
	old = current_cred();

	retval = -EPERM;
 if (!nsown_capable(CAP_SETGID)) {
 if (rgid != (gid_t) -1 && rgid != old->gid &&
		    rgid != old->egid  && rgid != old->sgid)
 goto error;
 if (egid != (gid_t) -1 && egid != old->gid &&
		    egid != old->egid  && egid != old->sgid)
 goto error;
 if (sgid != (gid_t) -1 && sgid != old->gid &&
		    sgid != old->egid  && sgid != old->sgid)
 goto error;
 }

 if (rgid != (gid_t) -1)
 new->gid = rgid;
 if (egid != (gid_t) -1)
 new->egid = egid;
 if (sgid != (gid_t) -1)
 new->sgid = sgid;
 new->fsgid = new->egid;

 return commit_creds(new);

error:
	abort_creds(new);
 return retval;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_decode_slice(UWORD8 u1_is_idr_slice,
                                 UWORD8 u1_nal_ref_idc,
 dec_struct_t *ps_dec /* Decoder parameters */
 )
{
 dec_bit_stream_t * ps_bitstrm = ps_dec->ps_bitstrm;
 dec_pic_params_t *ps_pps;
 dec_seq_params_t *ps_seq;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 pocstruct_t s_tmp_poc;
    WORD32 i_delta_poc[2];
    WORD32 i4_poc = 0;
    UWORD16 u2_first_mb_in_slice, u2_frame_num;
    UWORD8 u1_field_pic_flag, u1_redundant_pic_cnt = 0, u1_slice_type;
    UWORD32 u4_idr_pic_id = 0;
    UWORD8 u1_bottom_field_flag, u1_pic_order_cnt_type;

    UWORD8 u1_nal_unit_type;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    WORD8 i1_is_end_of_poc;

    WORD32 ret, end_of_frame;
    WORD32 prev_slice_err, num_mb_skipped;
    UWORD8 u1_mbaff;
 pocstruct_t *ps_cur_poc;

    UWORD32 u4_temp;
    WORD32 i_temp;
    UWORD32 u4_call_end_of_pic = 0;

 /* read FirstMbInSlice  and slice type*/
    ps_dec->ps_dpb_cmds->u1_dpb_commands_read_slc = 0;
    u2_first_mb_in_slice = ih264d_uev(pu4_bitstrm_ofst,
                                     pu4_bitstrm_buf);
 if(u2_first_mb_in_slice
 > (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs))
 {

 return ERROR_CORRUPTED_SLICE;
 }

 /*we currently don not support ASO*/
 if(((u2_first_mb_in_slice << ps_cur_slice->u1_mbaff_frame_flag)
 <= ps_dec->u2_cur_mb_addr) && (ps_dec->u4_first_slice_in_pic == 0))
 {
 return ERROR_CORRUPTED_SLICE;
 }

    COPYTHECONTEXT("SH: first_mb_in_slice",u2_first_mb_in_slice);

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);

 if(u4_temp > 9)
 return ERROR_INV_SLC_TYPE_T;

    u1_slice_type = u4_temp;
    COPYTHECONTEXT("SH: slice_type",(u1_slice_type));
    ps_dec->u1_sl_typ_5_9 = 0;
 /* Find Out the Slice Type is 5 to 9 or not then Set the Flag   */
 /* u1_sl_typ_5_9 = 1 .Which tells that all the slices in the Pic*/
 /* will be of same type of current                            */
 if(u1_slice_type > 4)
 {
        u1_slice_type -= 5;
        ps_dec->u1_sl_typ_5_9 = 1;
 }

 {
        UWORD32 skip;

 if((ps_dec->i4_app_skip_mode == IVD_SKIP_PB)
 || (ps_dec->i4_dec_skip_mode == IVD_SKIP_PB))
 {
            UWORD32 u4_bit_stream_offset = 0;

 if(ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else if((I_SLICE == u1_slice_type)
 && (1 >= ps_dec->ps_cur_sps->u1_num_ref_frames))
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else
 {
                skip = 1;
 }

 /* If one frame worth of data is already skipped, do not skip the next one */
 if((0 == u2_first_mb_in_slice) && (1 == ps_dec->u4_prev_nal_skipped))
 {
                skip = 0;
 }

 if(skip)
 {
                ps_dec->u4_prev_nal_skipped = 1;
                ps_dec->i4_dec_skip_mode = IVD_SKIP_PB;
 return 0;
 }
 else
 {
 /* If the previous NAL was skipped, then
                 do not process that buffer in this call.
                 Return to app and process it in the next call.
                 This is necessary to handle cases where I/IDR is not complete in
                 the current buffer and application intends to fill the remaining part of the bitstream
                 later. This ensures we process only frame worth of data in every call */
 if(1 == ps_dec->u4_prev_nal_skipped)
 {
                    ps_dec->u4_return_to_app = 1;
 return 0;
 }
 }
 }

 }

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp & MASK_ERR_PIC_SET_ID)
 return ERROR_INV_SLICE_HDR_T;
 /* discard slice if pic param is invalid */
    COPYTHECONTEXT("SH: pic_parameter_set_id", u4_temp);
    ps_pps = &ps_dec->ps_pps[u4_temp];
 if(FALSE == ps_pps->u1_is_valid)
 {
 return ERROR_INV_SLICE_HDR_T;
 }
    ps_seq = ps_pps->ps_sps;
 if(!ps_seq)
 return ERROR_INV_SLICE_HDR_T;
 if(FALSE == ps_seq->u1_is_valid)
 return ERROR_INV_SLICE_HDR_T;

 /* Get the frame num */
    u2_frame_num = ih264d_get_bits_h264(ps_bitstrm,
                                         ps_seq->u1_bits_in_frm_num);

 
     COPYTHECONTEXT("SH: frame_num", u2_frame_num);
 
     /* Get the field related flags  */
     if(!ps_seq->u1_frame_mbs_only_flag)
     {

        u1_field_pic_flag = ih264d_get_bit_h264(ps_bitstrm);
        COPYTHECONTEXT("SH: field_pic_flag", u1_field_pic_flag);
        u1_bottom_field_flag = 0;

 if(u1_field_pic_flag)
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan_fld;
            u1_bottom_field_flag = ih264d_get_bit_h264(ps_bitstrm);
            COPYTHECONTEXT("SH: bottom_field_flag", u1_bottom_field_flag);

 }
 else
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }
 }
 else
 {
        u1_field_pic_flag = 0;
        u1_bottom_field_flag = 0;

        ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }

    u1_nal_unit_type = SLICE_NAL;
 if(u1_is_idr_slice)
 {
 if(0 == u1_field_pic_flag)
 {
            ps_dec->u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY;
 }
        u1_nal_unit_type = IDR_SLICE_NAL;
        u4_idr_pic_id = ih264d_uev(pu4_bitstrm_ofst,
                                   pu4_bitstrm_buf);
 if(u4_idr_pic_id > 65535)
 return ERROR_INV_SLICE_HDR_T;
        COPYTHECONTEXT("SH:  ", u4_idr_pic_id);
 }

 /* read delta pic order count information*/
    i_delta_poc[0] = i_delta_poc[1] = 0;
    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    u1_pic_order_cnt_type = ps_seq->u1_pic_order_cnt_type;
 if(u1_pic_order_cnt_type == 0)
 {
        i_temp = ih264d_get_bits_h264(
                        ps_bitstrm,
                        ps_seq->u1_log2_max_pic_order_cnt_lsb_minus);
 if(i_temp < 0 || i_temp >= ps_seq->i4_max_pic_order_cntLsb)
 return ERROR_INV_SLICE_HDR_T;
        s_tmp_poc.i4_pic_order_cnt_lsb = i_temp;
        COPYTHECONTEXT("SH: pic_order_cnt_lsb", s_tmp_poc.i4_pic_order_cnt_lsb);

 if((ps_pps->u1_pic_order_present_flag == 1) && (!u1_field_pic_flag))
 {
            s_tmp_poc.i4_delta_pic_order_cnt_bottom = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt_bottom",
                            s_tmp_poc.i4_delta_pic_order_cnt_bottom);
 }
 }

    s_tmp_poc.i4_delta_pic_order_cnt[0] = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[1] = 0;
 if(u1_pic_order_cnt_type == 1
 && (!ps_seq->u1_delta_pic_order_always_zero_flag))
 {
        s_tmp_poc.i4_delta_pic_order_cnt[0] = ih264d_sev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
        COPYTHECONTEXT("SH: delta_pic_order_cnt[0]",
                        s_tmp_poc.i4_delta_pic_order_cnt[0]);

 if(ps_pps->u1_pic_order_present_flag && !u1_field_pic_flag)
 {
            s_tmp_poc.i4_delta_pic_order_cnt[1] = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt[1]",
                            s_tmp_poc.i4_delta_pic_order_cnt[1]);
 }
 }

 if(ps_pps->u1_redundant_pic_cnt_present_flag)
 {
        u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp > MAX_REDUNDANT_PIC_CNT)
 return ERROR_INV_SLICE_HDR_T;
        u1_redundant_pic_cnt = u4_temp;
        COPYTHECONTEXT("SH: redundant_pic_cnt", u1_redundant_pic_cnt);
 }

 /*--------------------------------------------------------------------*/
 /* Check if the slice is part of new picture                          */
 /*--------------------------------------------------------------------*/
 /* First slice of a picture is always considered as part of new picture */
    i1_is_end_of_poc = 1;
    ps_dec->ps_dec_err_status->u1_err_flag &= MASK_REJECT_CUR_PIC;

 if(ps_dec->u4_first_slice_in_pic != 2)
 {
        i1_is_end_of_poc = ih264d_is_end_of_pic(u2_frame_num, u1_nal_ref_idc,
 &s_tmp_poc, &ps_dec->s_cur_pic_poc,
                                            ps_cur_slice, u1_pic_order_cnt_type,

                                             u1_nal_unit_type, u4_idr_pic_id,
                                             u1_field_pic_flag,
                                             u1_bottom_field_flag);
     }
 
     /*--------------------------------------------------------------------*/
 /* Check for error in slice and parse the missing/corrupted MB's      */
 /* as skip-MB's in an inserted P-slice                                */
 /*--------------------------------------------------------------------*/
    u1_mbaff = ps_seq->u1_mb_aff_flag && (!u1_field_pic_flag);
    prev_slice_err = 0;

 if(i1_is_end_of_poc || ps_dec->u1_first_slice_in_stream)
 {
 if(u2_frame_num != ps_dec->u2_prv_frame_num
 && ps_dec->u1_top_bottom_decoded != 0
 && ps_dec->u1_top_bottom_decoded
 != (TOP_FIELD_ONLY | BOT_FIELD_ONLY))
 {
            ps_dec->u1_dangling_field = 1;
 if(ps_dec->u4_first_slice_in_pic)
 {
                prev_slice_err = 1;
 }
 else
 {
                prev_slice_err = 2;
 }

 if(ps_dec->u1_top_bottom_decoded ==TOP_FIELD_ONLY)
                ps_cur_slice->u1_bottom_field_flag = 1;
 else
                ps_cur_slice->u1_bottom_field_flag = 0;

            num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &ps_dec->s_cur_pic_poc;

            u1_is_idr_slice = ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL;
 }
 else if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice > 0)
 {
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
                ps_cur_poc = &s_tmp_poc;

                ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
                ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
                ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
                ps_cur_slice->i4_pic_order_cnt_lsb =
                        s_tmp_poc.i4_pic_order_cnt_lsb;
                ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
                ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
                ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
                ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;
                ps_cur_slice->u1_mbaff_frame_flag = ps_seq->u1_mb_aff_flag
 && (!u1_field_pic_flag);
 }
 }
 else
 {

 if(ps_dec->u4_first_slice_in_pic)
 {
 /* if valid slice header is not decoded do start of pic processing
                 * since in the current process call, frame num is not updated in the slice structure yet
                 * ih264d_is_end_of_pic is checked with valid frame num of previous process call,
                 * although i1_is_end_of_poc is set there could be  more slices in the frame,
                 * so conceal only till cur slice */
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
 }
 else
 {
 /* since i1_is_end_of_poc is set ,means new frame num is encountered. so conceal the current frame
                 * completely */
                prev_slice_err = 2;
                num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
 }
            ps_cur_poc = &s_tmp_poc;
 }
 }
 else
 {
 if((u2_first_mb_in_slice << u1_mbaff) > ps_dec->u2_total_mbs_coded)
 {
            prev_slice_err = 2;
            num_mb_skipped = (u2_first_mb_in_slice << u1_mbaff)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &s_tmp_poc;
 }
 else if((u2_first_mb_in_slice << u1_mbaff) < ps_dec->u2_total_mbs_coded)
 {
 return ERROR_CORRUPTED_SLICE;
 }
 }

 if(prev_slice_err)
 {
        ret = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, u1_is_idr_slice, u2_frame_num, ps_cur_poc, prev_slice_err);

 if(ps_dec->u1_dangling_field == 1)
 {
            ps_dec->u1_second_field = 1 - ps_dec->u1_second_field;
            ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
            ps_dec->u2_prv_frame_num = u2_frame_num;
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_DANGLING_FIELD_IN_PIC;
 }

 if(prev_slice_err == 2)
 {
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_INCOMPLETE_FRAME;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
 /* return if all MBs in frame are parsed*/
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_IN_LAST_SLICE_OF_PIC;
 }

 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
            ih264d_err_pic_dispbuf_mgr(ps_dec);
 return ERROR_NEW_FRAME_EXPECTED;
 }

 if(ret != OK)
 return ret;

        i1_is_end_of_poc = 0;
 }

 if (ps_dec->u4_first_slice_in_pic == 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

 if((ps_dec->u1_separate_parse == 0) && (ps_dec->u4_first_slice_in_pic == 0))
 {
        ps_dec->ps_decode_cur_slice++;

     }
     ps_dec->u1_slice_header_done = 0;
 
    /*--------------------------------------------------------------------*/
    /* If the slice is part of new picture, do End of Pic processing.     */
    /*--------------------------------------------------------------------*/
    if(!ps_dec->u1_first_slice_in_stream)
    {
        UWORD8 uc_mbs_exceed = 0;
        if(ps_dec->u2_total_mbs_coded
                        == (ps_dec->ps_cur_sps->u2_max_mb_addr + 1))
        {
            /*u2_total_mbs_coded is forced  to u2_max_mb_addr+ 1 at the end of decode ,so
             ,if it is first slice in pic dont consider u2_total_mbs_coded to detect new picture */
            if(ps_dec->u4_first_slice_in_pic == 0)
                uc_mbs_exceed = 1;
        }
        if(i1_is_end_of_poc || uc_mbs_exceed)
        {
            if(1 == ps_dec->u1_last_pic_not_decoded)
            {
                ret = ih264d_end_of_pic_dispbuf_mgr(ps_dec);
                if(ret != OK)
                    return ret;
                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
                if(ret != OK)
                    return ret;
#if WIN32
                H264_DEC_DEBUG_PRINT(" ------ PIC SKIPPED ------\n");
#endif
                return RET_LAST_SKIP;
            }
            else
            {
                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
                if(ret != OK)
                    return ret;
            }
        }
    }
 
     if(u1_field_pic_flag)
     {
        ps_dec->u2_prv_frame_num = u2_frame_num;
 }

 if(ps_cur_slice->u1_mmco_equalto5)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;

 if(!ps_cur_slice->u1_field_pic_flag) // or a complementary field pair
 {
            i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
            i4_bot_field_order_poc =
                            ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
            i4_temp_poc = MIN(i4_top_field_order_poc,
                                     i4_bot_field_order_poc);
 }
 else if(!ps_cur_slice->u1_bottom_field_flag)
            i4_temp_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
 else
            i4_temp_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;

        ps_dec->ps_cur_pic->i4_top_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        ps_dec->ps_cur_pic->i4_bottom_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
        ps_dec->ps_cur_pic->i4_poc = i4_temp_poc;
        ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
 }
 if(ps_dec->u4_first_slice_in_pic == 2)
 {
        ret = ih264d_decode_pic_order_cnt(u1_is_idr_slice, u2_frame_num,
 &ps_dec->s_prev_pic_poc,
 &s_tmp_poc, ps_cur_slice, ps_pps,
                                          u1_nal_ref_idc,
                                          u1_bottom_field_flag,
                                          u1_field_pic_flag, &i4_poc);
 if(ret != OK)
 return ret;
 /* Display seq no calculations */
 if(i4_poc >= ps_dec->i4_max_poc)
            ps_dec->i4_max_poc = i4_poc;
 /* IDR Picture or POC wrap around */
 if(i4_poc == 0)
 {
            ps_dec->i4_prev_max_display_seq = ps_dec->i4_prev_max_display_seq
 + ps_dec->i4_max_poc
 + ps_dec->u1_max_dec_frame_buffering + 1;
            ps_dec->i4_max_poc = 0;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Copy the values read from the bitstream to the slice header and then*/
 /* If the slice is first slice in picture, then do Start of Picture   */
 /* processing.                                                        */
 /*--------------------------------------------------------------------*/
    ps_cur_slice->i4_delta_pic_order_cnt[0] = i_delta_poc[0];
    ps_cur_slice->i4_delta_pic_order_cnt[1] = i_delta_poc[1];
    ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
    ps_cur_slice->u2_first_mb_in_slice = u2_first_mb_in_slice;
    ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
    ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
    ps_cur_slice->u1_slice_type = u1_slice_type;
    ps_cur_slice->i4_pic_order_cnt_lsb = s_tmp_poc.i4_pic_order_cnt_lsb;

    ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
    ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
    ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
    ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;

 if(ps_seq->u1_frame_mbs_only_flag)
        ps_cur_slice->u1_direct_8x8_inference_flag =
                        ps_seq->u1_direct_8x8_inference_flag;
 else
        ps_cur_slice->u1_direct_8x8_inference_flag = 1;

 if(u1_slice_type == B_SLICE)
 {
        ps_cur_slice->u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264(
                        ps_bitstrm);
        COPYTHECONTEXT("SH: direct_spatial_mv_pred_flag",
                        ps_cur_slice->u1_direct_spatial_mv_pred_flag);

 if(ps_cur_slice->u1_direct_spatial_mv_pred_flag)
            ps_cur_slice->pf_decodeDirect = ih264d_decode_spatial_direct;
 else
            ps_cur_slice->pf_decodeDirect = ih264d_decode_temporal_direct;
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaffB;
 }
 else
 {
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
 }

 if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice == 0)
 {
            ret = ih264d_start_of_pic(ps_dec, i4_poc, &s_tmp_poc, u2_frame_num, ps_pps);
 if(ret != OK)
 return ret;
 }

        ps_dec->u4_output_present = 0;

 {
            ih264d_get_next_display_field(ps_dec,
                                          ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
             hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                ps_dec->u4_output_present = 1;
 }
 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                ps_dec->u4_start_recon_deblk = 0;
                ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }

 }

 /* INITIALIZATION of fn ptrs for MC and formMbPartInfo functions */
 {
        UWORD8 uc_nofield_nombaff;



        uc_nofield_nombaff = ((ps_dec->ps_cur_slice->u1_field_pic_flag == 0)
 && (ps_dec->ps_cur_slice->u1_mbaff_frame_flag == 0)
 && (u1_slice_type != B_SLICE)
 && (ps_dec->ps_cur_pps->u1_wted_pred_flag == 0));

 /* Initialise MC and formMbPartInfo fn ptrs one time based on profile_idc */

 if(uc_nofield_nombaff)
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;
 }
 else
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_mp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_mp;
 }


 }

 /*
     * Decide whether to decode the current picture or not
     */
 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if(ps_err->u4_frm_sei_sync == u2_frame_num)
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
            ps_err->u4_frm_sei_sync = SYNC_FRM_DEFAULT;
 }
        ps_err->u4_cur_frm = u2_frame_num;
 }

 /* Decision for decoding if the picture is to be skipped */
 {
        WORD32 i4_skip_b_pic, i4_skip_p_pic;

        i4_skip_b_pic = (ps_dec->u4_skip_frm_mask & B_SLC_BIT)
 && (B_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

        i4_skip_p_pic = (ps_dec->u4_skip_frm_mask & P_SLC_BIT)
 && (P_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

 /**************************************************************/
 /* Skip the B picture if skip mask is set for B picture and   */
 /* Current B picture is a non reference B picture or there is */
 /* no user for reference B picture                            */
 /**************************************************************/
 if(i4_skip_b_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
 /* Don't decode the picture in SKIP-B mode if that picture is B */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 /**************************************************************/
 /* Skip the P picture if skip mask is set for P picture and   */
 /* Current P picture is a non reference P picture or there is */
 /* no user for reference P picture                            */
 /**************************************************************/
 if(i4_skip_p_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
 /* Don't decode the picture in SKIP-P mode if that picture is P */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 }

 {
        UWORD16 u2_mb_x, u2_mb_y;

        ps_dec->i4_submb_ofst = ((u2_first_mb_in_slice
 << ps_cur_slice->u1_mbaff_frame_flag) * SUB_BLK_SIZE)
 - SUB_BLK_SIZE;
 if(u2_first_mb_in_slice)
 {
            UWORD8 u1_mb_aff;
            UWORD8 u1_field_pic;
            UWORD16 u2_frm_wd_in_mbs;
            u2_frm_wd_in_mbs = ps_seq->u2_frm_wd_in_mbs;
            u1_mb_aff = ps_cur_slice->u1_mbaff_frame_flag;
            u1_field_pic = ps_cur_slice->u1_field_pic_flag;

 {
                UWORD32 x_offset;
                UWORD32 y_offset;
                UWORD32 u4_frame_stride;
 tfr_ctxt_t *ps_trns_addr; // = &ps_dec->s_tran_addrecon_parse;

 if(ps_dec->u1_separate_parse)
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon;
 }
                u2_mb_x = MOD(u2_first_mb_in_slice, u2_frm_wd_in_mbs);
                u2_mb_y = DIV(u2_first_mb_in_slice, u2_frm_wd_in_mbs);

                u2_mb_y <<= u1_mb_aff;

 if((u2_mb_x > u2_frm_wd_in_mbs - 1)
 || (u2_mb_y > ps_dec->u2_frm_ht_in_mbs - 1))
 {
 return ERROR_CORRUPTED_SLICE;
 }

                u4_frame_stride = ps_dec->u2_frm_wd_y << u1_field_pic;
                x_offset = u2_mb_x << 4;
                y_offset = (u2_mb_y * u4_frame_stride) << 4;

                ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1 + x_offset
 + y_offset;

                u4_frame_stride = ps_dec->u2_frm_wd_uv << u1_field_pic;
                x_offset >>= 1;
                y_offset = (u2_mb_y * u4_frame_stride) << 3;

                x_offset *= YUV420SP_FACTOR;

                ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2 + x_offset
 + y_offset;
                ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3 + x_offset
 + y_offset;

                ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
                ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
                ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;


 if(ps_dec->u1_separate_parse == 1)
 {
                    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }
 else
 {
                        ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }

                ps_dec->u2_cur_mb_addr = (u2_first_mb_in_slice << u1_mb_aff);

                ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv
 + ((u2_first_mb_in_slice << u1_mb_aff) << 4);
 }
 }
 else
 {
 tfr_ctxt_t *ps_trns_addr;

 if(ps_dec->u1_separate_parse)
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon;
 }

            u2_mb_x = 0xffff;
            u2_mb_y = 0;
            ps_dec->u2_cur_mb_addr = 0;
            ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
            ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
            ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
            ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
            ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

            ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
            ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
            ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;

 }

        ps_dec->ps_part = ps_dec->ps_parse_part_params;

        ps_dec->u2_mbx =
 (MOD(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby =
 (DIV(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby <<= ps_cur_slice->u1_mbaff_frame_flag;
        ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
        ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
 }

 /* RBSP stop bit is used for CABAC decoding*/
    ps_bitstrm->u4_max_ofst += ps_dec->ps_cur_pps->u1_entropy_coding_mode;

    ps_dec->u1_B = (u1_slice_type == B_SLICE);
    ps_dec->u4_next_mb_skip = 0;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice =
                    ps_dec->ps_cur_slice->u2_first_mb_in_slice;
    ps_dec->ps_parse_cur_slice->slice_type =
                    ps_dec->ps_cur_slice->u1_slice_type;


    ps_dec->u4_start_recon_deblk = 1;
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = ( void *)pu1_buf;
 }

 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 if(u1_slice_type == I_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= I_SLC_BIT;

        ret = ih264d_parse_islice(ps_dec, u2_first_mb_in_slice);

 if(ps_dec->i4_pic_type != B_SLICE && ps_dec->i4_pic_type != P_SLICE)
            ps_dec->i4_pic_type = I_SLICE;

 }
 else if(u1_slice_type == P_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
        ret = ih264d_parse_pslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
 if(ps_dec->i4_pic_type != B_SLICE)
            ps_dec->i4_pic_type = P_SLICE;
 }
 else if(u1_slice_type == B_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
        ret = ih264d_parse_bslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
        ps_dec->i4_pic_type = B_SLICE;
 }
 else
 return ERROR_INV_SLC_TYPE_T;

 if(ps_dec->u1_slice_header_done)
 {
 /* set to zero to indicate a valid slice has been decoded */
 /* first slice header successfully decoded */
        ps_dec->u4_first_slice_in_pic = 0;
        ps_dec->u1_first_slice_in_stream = 0;
 }

 if(ret != OK)
 return ret;

 /* storing last Mb X and MbY of the slice */
    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 /* End of Picture detection */

 if(ps_dec->u2_total_mbs_coded >= (ps_seq->u2_max_mb_addr + 1))
 {
        ps_dec->u1_pic_decode_done = 1;

 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if((ps_err->u1_err_flag & REJECT_PB_PICS)
 && (ps_err->u1_cur_pic_type == PIC_TYPE_I))
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

    PRINT_BIN_BIT_RATIO(ps_dec)

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: xmlParseEnumeratedType(xmlParserCtxtPtr ctxt, xmlEnumerationPtr *tree) {
 if (CMP8(CUR_PTR, 'N', 'O', 'T', 'A', 'T', 'I', 'O', 'N')) {
	SKIP(8);
 if (!IS_BLANK_CH(CUR)) {
	    xmlFatalErrMsg(ctxt, XML_ERR_SPACE_REQUIRED,
 "Space required after 'NOTATION'\n");
 return(0);
 }
        SKIP_BLANKS;
 *tree = xmlParseNotationType(ctxt);
 if (*tree == NULL) return(0);
 return(XML_ATTRIBUTE_NOTATION);
 }
 *tree = xmlParseEnumerationType(ctxt);
 if (*tree == NULL) return(0);
 return(XML_ATTRIBUTE_ENUMERATION);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void init_once()
{
 int i = 0;
 if (initialized) {
        ALOGV("%s : already init .. do nothing", __func__);
 return;
 }

    ALOGD("%s Called ", __func__);
    pthread_mutex_init(&vol_listner_init_lock, NULL);

 if (access(PRIMARY_HAL_PATH, R_OK) == 0) {
 void *hal_lib_pointer = dlopen(PRIMARY_HAL_PATH, RTLD_NOW);
 if (hal_lib_pointer == NULL) {
            ALOGE("%s: DLOPEN failed for %s", __func__, PRIMARY_HAL_PATH);
            send_gain_dep_cal = NULL;
 } else {
            ALOGV("%s: DLOPEN of %s Succes .. next get HAL entry function", __func__, PRIMARY_HAL_PATH);
            send_gain_dep_cal = (bool (*)(int))dlsym(hal_lib_pointer, AHAL_GAIN_DEPENDENT_INTERFACE_FUNCTION);
 if (send_gain_dep_cal == NULL) {
                ALOGE("Couldnt able to get the function symbol");
 }
 }
 } else {
        ALOGE("%s: not able to acces lib %s ", __func__, PRIMARY_HAL_PATH);
        send_gain_dep_cal = NULL;
 }

 char check_dump_val[PROPERTY_VALUE_MAX];
    property_get("audio.volume.listener.dump", check_dump_val, "0");
 if (atoi(check_dump_val)) {
        dumping_enabled = true;
 }

    init_status = 0;
    list_init(&vol_effect_list);
    initialized = true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SampleTable::SampleTable(const sp<DataSource> &source)
 : mDataSource(source),
      mChunkOffsetOffset(-1),
      mChunkOffsetType(0),
      mNumChunkOffsets(0),
      mSampleToChunkOffset(-1),
      mNumSampleToChunkOffsets(0),
      mSampleSizeOffset(-1),
      mSampleSizeFieldSize(0),
      mDefaultSampleSize(0),
      mNumSampleSizes(0),
      mHasTimeToSample(false),
      mTimeToSampleCount(0),
      mTimeToSample(NULL),
      mSampleTimeEntries(NULL),
      mCompositionTimeDeltaEntries(NULL),
      mNumCompositionTimeDeltaEntries(0),
      mCompositionDeltaLookup(new CompositionDeltaLookup),
      mSyncSampleOffset(-1),
      mNumSyncSamples(0),
      mSyncSamples(NULL),
      mLastSyncSampleIndex(0),
      mSampleToChunkEntries(NULL),
      mTotalSize(0) {
    mSampleIterator = new SampleIterator(this);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Cues::Cues(Segment* pSegment, long long start_, long long size_,
 long long element_start, long long element_size)
 : m_pSegment(pSegment),
      m_start(start_),
      m_size(size_),
      m_element_start(element_start),
      m_element_size(element_size),
      m_cue_points(NULL),
      m_count(0),
      m_preload_count(0),
      m_pos(start_) {}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: sp<MetaData> MPEG4Source::getFormat() {
 Mutex::Autolock autoLock(mLock);

 return mFormat;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int XfrmController::fillUserPolicyId(const XfrmSaInfo& record, XfrmDirection direction,
                                     xfrm_userpolicy_id* usersp) {
    fillXfrmSelector(record, &usersp->sel);
    usersp->dir = static_cast<uint8_t>(direction);
 return sizeof(*usersp);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char* Track::GetNameAsUTF8() const
{
    return m_info.nameAsUTF8;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: get_option_uint32(uint32_t *i, const struct dhcp_message *dhcp, uint8_t option)
{
 const uint8_t *p = get_option_raw(dhcp, option);
 uint32_t d;

 if (!p)
 return -1;
	memcpy(&d, p, sizeof(d));
 *i = ntohl(d);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Cues::Find(
    long long time_ns,
    const Track* pTrack,
    const CuePoint*& pCP,
    const CuePoint::TrackPosition*& pTP) const
{
    assert(time_ns >= 0);
    assert(pTrack);
 
 #if 0
     LoadCuePoint();  //establish invariant

    assert(m_cue_points);
    assert(m_count > 0);

 CuePoint** const ii = m_cue_points;
 CuePoint** i = ii;

 CuePoint** const jj = ii + m_count + m_preload_count;
 CuePoint** j = jj;

    pCP = *i;
    assert(pCP);

 if (time_ns <= pCP->GetTime(m_pSegment))
 {
        pTP = pCP->Find(pTrack);
 return (pTP != NULL);
 }

 IMkvReader* const pReader = m_pSegment->m_pReader;

 while (i < j)
 {

 CuePoint** const k = i + (j - i) / 2;
        assert(k < jj);

 CuePoint* const pCP = *k;
        assert(pCP);

        pCP->Load(pReader);

 const long long t = pCP->GetTime(m_pSegment);

 if (t <= time_ns)
            i = k + 1;
 else
            j = k;

        assert(i <= j);
 }

    assert(i == j);
    assert(i <= jj);
    assert(i > ii);

    pCP = *--i;

     assert(pCP);
     assert(pCP->GetTime(m_pSegment) <= time_ns);
 #else
    if (m_cue_points == NULL)
        return false;
 
    if (m_count == 0)
        return false;
 
    CuePoint** const ii = m_cue_points;
    CuePoint** i = ii;
 
    CuePoint** const jj = ii + m_count;
    CuePoint** j = jj;
 
    pCP = *i;
    assert(pCP);
 
    if (time_ns <= pCP->GetTime(m_pSegment))
    {
        pTP = pCP->Find(pTrack);
        return (pTP != NULL);
    }
    while (i < j)
    {
        CuePoint** const k = i + (j - i) / 2;
        assert(k < jj);
        CuePoint* const pCP = *k;
        assert(pCP);
        const long long t = pCP->GetTime(m_pSegment);
        if (t <= time_ns)
            i = k + 1;
        else
            j = k;
        assert(i <= j);
    }
    assert(i == j);
    assert(i <= jj);
    assert(i > ii);
    pCP = *--i;
    assert(pCP);
    assert(pCP->GetTime(m_pSegment) <= time_ns);
#endif
     pTP = pCP->Find(pTrack);
     return (pTP != NULL);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual void SetUp() {

     fwd_txfm_ = GET_PARAM(0);
     inv_txfm_ = GET_PARAM(1);
     tx_type_  = GET_PARAM(2);
     pitch_    = 16;
     fwd_txfm_ref = fht16x16_ref;
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: const CuePoint* Cues::GetFirst() const
{
    if (m_cue_points == NULL)
        return NULL;
    if (m_count == 0)
        return NULL;
 
 #if 0
     LoadCuePoint();  //init cues

 const size_t count = m_count + m_preload_count;

 if (count == 0) //weird

         return NULL;
 #endif
 
    CuePoint* const* const pp = m_cue_points;
    assert(pp);
 
    CuePoint* const pCP = pp[0];
    assert(pCP);
    assert(pCP->GetTimeCode() >= 0);
 
    return pCP;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void CameraClient::dataCallbackTimestamp(nsecs_t timestamp,
 int32_t msgType, const sp<IMemory>& dataPtr, void* user) {
    LOG2("dataCallbackTimestamp(%d)", msgType);

 Mutex* lock = getClientLockFromCookie(user);
 if (lock == NULL) return;
 Mutex::Autolock alock(*lock);

 CameraClient* client =
 static_cast<CameraClient*>(getClientFromCookie(user));
 if (client == NULL) return;

 if (!client->lockIfMessageWanted(msgType)) return;

 if (dataPtr == 0) {
        ALOGE("Null data returned in data with timestamp callback");
        client->handleGenericNotify(CAMERA_MSG_ERROR, UNKNOWN_ERROR, 0);
 return;
 }

    client->handleGenericDataTimestamp(timestamp, msgType, dataPtr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool remove_str_to_int(void *key, void *value, void *context) {
 Hashmap* map = context;
    hashmapRemove(map, key);
    free(key);
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_ssp_cfm_req_evt(tBTA_DM_SP_CFM_REQ *p_ssp_cfm_req)
{
 bt_bdaddr_t bd_addr;
 bt_bdname_t bd_name;
    UINT32 cod;
    BOOLEAN is_incoming = !(pairing_cb.state == BT_BOND_STATE_BONDING);
 int dev_type;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

 /* Remote properties update */
 if (!btif_get_device_type(p_ssp_cfm_req->bd_addr, &dev_type))
 {
        dev_type = BT_DEVICE_TYPE_BREDR;
 }
    btif_update_remote_properties(p_ssp_cfm_req->bd_addr, p_ssp_cfm_req->bd_name,
                                  p_ssp_cfm_req->dev_class, (tBT_DEVICE_TYPE) dev_type);

    bdcpy(bd_addr.address, p_ssp_cfm_req->bd_addr);
    memcpy(bd_name.name, p_ssp_cfm_req->bd_name, BD_NAME_LEN);

 /* Set the pairing_cb based on the local & remote authentication requirements */
    bond_state_changed(BT_STATUS_SUCCESS, &bd_addr, BT_BOND_STATE_BONDING);

 /* if just_works and bonding bit is not set treat this as temporary */
 if (p_ssp_cfm_req->just_works && !(p_ssp_cfm_req->loc_auth_req & BTM_AUTH_BONDS) &&
 !(p_ssp_cfm_req->rmt_auth_req & BTM_AUTH_BONDS) &&
 !(check_cod((bt_bdaddr_t*)&p_ssp_cfm_req->bd_addr, COD_HID_POINTING)))
        pairing_cb.bond_type = BOND_TYPE_TEMPORARY;
 else
        pairing_cb.bond_type = BOND_TYPE_PERSISTENT;

    btm_set_bond_type_dev(p_ssp_cfm_req->bd_addr, pairing_cb.bond_type);

    pairing_cb.is_ssp = TRUE;

 /* If JustWorks auto-accept */
 if (p_ssp_cfm_req->just_works)
 {
 /* Pairing consent for JustWorks needed if:
         * 1. Incoming (non-temporary) pairing is detected AND
         * 2. local IO capabilities are DisplayYesNo AND
         * 3. remote IO capabiltiies are DisplayOnly or NoInputNoOutput;
         */
 if (is_incoming && pairing_cb.bond_type != BOND_TYPE_TEMPORARY &&
 ((p_ssp_cfm_req->loc_io_caps == HCI_IO_CAP_DISPLAY_YESNO) &&
 (p_ssp_cfm_req->rmt_io_caps == HCI_IO_CAP_DISPLAY_ONLY ||
                 p_ssp_cfm_req->rmt_io_caps == HCI_IO_CAP_NO_IO)))
 {
            BTIF_TRACE_EVENT("%s: User consent needed for incoming pairing request. loc_io_caps: %d, rmt_io_caps: %d",
                __FUNCTION__, p_ssp_cfm_req->loc_io_caps, p_ssp_cfm_req->rmt_io_caps);
 }
 else
 {
            BTIF_TRACE_EVENT("%s: Auto-accept JustWorks pairing", __FUNCTION__);
            btif_dm_ssp_reply(&bd_addr, BT_SSP_VARIANT_CONSENT, TRUE, 0);
 return;
 }
 }

    cod = devclass2uint(p_ssp_cfm_req->dev_class);

 if (cod == 0) {
        LOG_DEBUG("%s cod is 0, set as unclassified", __func__);
        cod = COD_UNCLASSIFIED;
 }

    pairing_cb.sdp_attempts = 0;
    HAL_CBACK(bt_hal_cbacks, ssp_request_cb, &bd_addr, &bd_name, cod,
 (p_ssp_cfm_req->just_works ? BT_SSP_VARIANT_CONSENT : BT_SSP_VARIANT_PASSKEY_CONFIRMATION),
                     p_ssp_cfm_req->num_val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftG711::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPcm:
 {

             OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 0 && pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (pcmParams->nChannels < 1 || pcmParams->nChannels > 2) {
 return OMX_ErrorUndefined;
 }

 if(pcmParams->nPortIndex == 0) {
                mNumChannels = pcmParams->nChannels;
 }

            mSamplingRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (mIsMLaw) {
                 if (strncmp((const char *)roleParams->cRole,
                             "audio_decoder.g711mlaw",
                            OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }
 } else {
 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.g711alaw",
                            OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }
 }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cluster* BlockEntry::GetCluster() const { return m_pCluster; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool CameraSource::isMetaDataStoredInVideoBuffers() const {
    ALOGV("isMetaDataStoredInVideoBuffers");

     return mIsMetaDataStoredInVideoBuffers;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t NuMediaExtractor::unselectTrack(size_t index) {
 Mutex::Autolock autoLock(mLock);

 if (mImpl == NULL) {
 return -EINVAL;
 }

 if (index >= mImpl->countTracks()) {
 return -ERANGE;
 }

 size_t i;
 for (i = 0; i < mSelectedTracks.size(); ++i) {
 TrackInfo *info = &mSelectedTracks.editItemAt(i);

 if (info->mTrackIndex == index) {
 break;
 }
 }

 if (i == mSelectedTracks.size()) {
 return OK;
 }

 TrackInfo *info = &mSelectedTracks.editItemAt(i);

 if (info->mSample != NULL) {
        info->mSample->release();
        info->mSample = NULL;

        info->mSampleTimeUs = -1ll;
 }

    CHECK_EQ((status_t)OK, info->mSource->stop());

    mSelectedTracks.removeAt(i);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   void RunFwdTxfm(int16_t *in, int16_t *out, int stride) {
     fwd_txfm_(in, out, stride, tx_type_);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void smp_match_dhkey_checks(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {

  SMP_TRACE_DEBUG("%s", __func__);

 if (memcmp(p_data->key.p_data, p_cb->remote_dhkey_check, BT_OCTET16_LEN)) {
    SMP_TRACE_WARNING("dhkey chcks do no match");
    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = SMP_DHKEY_CHK_FAIL;
    p_cb->failure = SMP_DHKEY_CHK_FAIL;
    smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &smp_int_data);
 return;
 }

  SMP_TRACE_EVENT("dhkey chcks match");

 /* compare the max encryption key size, and save the smaller one for the link
   */
 if (p_cb->peer_enc_size < p_cb->loc_enc_size)
    p_cb->loc_enc_size = p_cb->peer_enc_size;

 if (p_cb->role == HCI_ROLE_SLAVE) {
    smp_sm_event(p_cb, SMP_PAIR_DHKEY_CHCK_EVT, NULL);
 } else {
 /* master device always use received i/r key as keys to distribute */
    p_cb->local_i_key = p_cb->peer_i_key;
    p_cb->local_r_key = p_cb->peer_r_key;
    smp_sm_event(p_cb, SMP_ENC_REQ_EVT, NULL);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraDeviceClient::getCameraInfo(/*out*/CameraMetadata* info)
{
    ATRACE_CALL();
    ALOGV("%s", __FUNCTION__);

 status_t res = OK;

 if ( (res = checkPid(__FUNCTION__) ) != OK) return res;

 Mutex::Autolock icl(mBinderSerializationLock);

 if (!mDevice.get()) return DEAD_OBJECT;

 if (info != NULL) {
 *info = mDevice->info(); // static camera metadata
 }

 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: perform_error_test(png_modifier *pm)
{
#ifdef PNG_WARNINGS_SUPPORTED /* else there are no cases that work! */
 /* Need to do this here because we just write in this test. */
   safecat(pm->this.test, sizeof pm->this.test, 0, "error test");

 if (!make_errors(pm, 0, 0, WRITE_BDHI))
 return;

 if (!make_errors(pm, 2, 3, WRITE_BDHI))
 return;

 if (!make_errors(pm, 3, 0, 3))
 return;

 if (!make_errors(pm, 4, 3, WRITE_BDHI))
 return;

 if (!make_errors(pm, 6, 3, WRITE_BDHI))
 return;
#else
   UNUSED(pm)
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void a2dp_stream_common_init(struct a2dp_stream_common *common)
{
 pthread_mutexattr_t lock_attr;

    FNLOG();

    pthread_mutexattr_init(&lock_attr);
    pthread_mutexattr_settype(&lock_attr, PTHREAD_MUTEX_RECURSIVE);
    pthread_mutex_init(&common->lock, &lock_attr);

    common->ctrl_fd = AUDIO_SKT_DISCONNECTED;
    common->audio_fd = AUDIO_SKT_DISCONNECTED;
    common->state = AUDIO_A2DP_STATE_STOPPED;

 /* manages max capacity of socket pipe */
    common->buffer_sz = AUDIO_STREAM_OUTPUT_BUFFER_SZ;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline void uipc_wakeup_locked(void)

 {
     char sig_on = 1;
     BTIF_TRACE_EVENT("UIPC SEND WAKE UP");
    send(uipc_main.signal_fds[1], &sig_on, sizeof(sig_on), 0);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::MotionEntry::~MotionEntry() {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void copyStereo16(
         short *dst,
        const int *const *src,
         unsigned nSamples,
         unsigned /* nChannels */) {
     for (unsigned i = 0; i < nSamples; ++i) {
 *dst++ = src[0][i];
 *dst++ = src[1][i];

     }
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void WT_VoiceFilter (S_FILTER_CONTROL *pFilter, S_WT_INT_FRAME *pWTIntFrame)
{
    EAS_PCM *pAudioBuffer;
    EAS_I32 k;
    EAS_I32 b1;
    EAS_I32 b2;
    EAS_I32 z1;
    EAS_I32 z2;
    EAS_I32 acc0;
    EAS_I32 acc1;
    EAS_I32 numSamples;

 /* initialize some local variables */

     numSamples = pWTIntFrame->numSamples;
     if (numSamples <= 0) {
         ALOGE("b/26366256");
         return;
     }
     pAudioBuffer = pWTIntFrame->pAudioBuffer;

    z1 = pFilter->z1;
    z2 = pFilter->z2;
    b1 = -pWTIntFrame->frame.b1;

 /*lint -e{702} <avoid divide> */
    b2 = -pWTIntFrame->frame.b2 >> 1;

 /*lint -e{702} <avoid divide> */
    k = pWTIntFrame->frame.k >> 1;

 while (numSamples--)
 {

 /* do filter calculations */
        acc0 = *pAudioBuffer;
        acc1 = z1 * b1;
        acc1 += z2 * b2;
        acc0 = acc1 + k * acc0;
        z2 = z1;

 /*lint -e{702} <avoid divide> */
        z1 = acc0 >> 14;
 *pAudioBuffer++ = (EAS_I16) z1;
 }

 /* save delay values     */
    pFilter->z1 = (EAS_I16) z1;
    pFilter->z2 = (EAS_I16) z2;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool btif_config_remove(const char *section, const char *key) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);

  pthread_mutex_lock(&lock);
 bool ret = config_remove_key(config, section, key);
  pthread_mutex_unlock(&lock);

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int adev_open_output_stream(struct audio_hw_device *dev,
 audio_io_handle_t handle,
 audio_devices_t devices,
 audio_output_flags_t flags,
 struct audio_config *config,
 struct audio_stream_out **stream_out,
 const char *address __unused)
{
 struct audio_device *adev = (struct audio_device *)dev;
 struct stream_out *out;
 int i, ret;
 struct pcm_device_profile *pcm_profile;

    ALOGV("%s: enter: sample_rate(%d) channel_mask(%#x) devices(%#x) flags(%#x)",
          __func__, config->sample_rate, config->channel_mask, devices, flags);
 *stream_out = NULL;
    out = (struct stream_out *)calloc(1, sizeof(struct stream_out));

 if (devices == AUDIO_DEVICE_NONE)
        devices = AUDIO_DEVICE_OUT_SPEAKER;

    out->flags = flags;
    out->devices = devices;
    out->dev = adev;
    out->format = config->format;
    out->sample_rate = config->sample_rate;
    out->channel_mask = AUDIO_CHANNEL_OUT_STEREO;
    out->supported_channel_masks[0] = AUDIO_CHANNEL_OUT_STEREO;
    out->handle = handle;

    pcm_profile = get_pcm_device(PCM_PLAYBACK, devices);
 if (pcm_profile == NULL) {
        ret = -EINVAL;
 goto error_open;
 }
    out->config = pcm_profile->config;

 /* Init use case and pcm_config */
 if (out->flags & (AUDIO_OUTPUT_FLAG_DEEP_BUFFER)) {
        out->usecase = USECASE_AUDIO_PLAYBACK_DEEP_BUFFER;
        out->config = pcm_config_deep_buffer;
        out->sample_rate = out->config.rate;
        ALOGV("%s: use AUDIO_PLAYBACK_DEEP_BUFFER",__func__);
 } else {
        out->usecase = USECASE_AUDIO_PLAYBACK;
        out->sample_rate = out->config.rate;
 }

 if (flags & AUDIO_OUTPUT_FLAG_PRIMARY) {
 if (adev->primary_output == NULL)
            adev->primary_output = out;
 else {
            ALOGE("%s: Primary output is already opened", __func__);
            ret = -EEXIST;
 goto error_open;
 }
 }

 /* Check if this usecase is already existing */
    pthread_mutex_lock(&adev->lock);
 if (get_usecase_from_id(adev, out->usecase) != NULL) {
        ALOGE("%s: Usecase (%d) is already present", __func__, out->usecase);
        pthread_mutex_unlock(&adev->lock);
        ret = -EEXIST;
 goto error_open;
 }
    pthread_mutex_unlock(&adev->lock);

    out->stream.common.get_sample_rate = out_get_sample_rate;
    out->stream.common.set_sample_rate = out_set_sample_rate;
    out->stream.common.get_buffer_size = out_get_buffer_size;
    out->stream.common.get_channels = out_get_channels;
    out->stream.common.get_format = out_get_format;
    out->stream.common.set_format = out_set_format;
    out->stream.common.standby = out_standby;
    out->stream.common.dump = out_dump;
    out->stream.common.set_parameters = out_set_parameters;
    out->stream.common.get_parameters = out_get_parameters;
    out->stream.common.add_audio_effect = out_add_audio_effect;
    out->stream.common.remove_audio_effect = out_remove_audio_effect;
    out->stream.get_latency = out_get_latency;
    out->stream.set_volume = out_set_volume;
    out->stream.write = out_write;
    out->stream.get_render_position = out_get_render_position;
    out->stream.get_next_write_timestamp = out_get_next_write_timestamp;
    out->stream.get_presentation_position = out_get_presentation_position;

    out->standby = 1;
 /* out->muted = false; by calloc() */
 /* out->written = 0; by calloc() */

    pthread_mutex_init(&out->lock, (const pthread_mutexattr_t *) NULL);
    pthread_mutex_init(&out->pre_lock, (const pthread_mutexattr_t *) NULL);
    pthread_cond_init(&out->cond, (const pthread_condattr_t *) NULL);

    config->format = out->stream.common.get_format(&out->stream.common);
    config->channel_mask = out->stream.common.get_channels(&out->stream.common);
    config->sample_rate = out->stream.common.get_sample_rate(&out->stream.common);

 *stream_out = &out->stream;
    ALOGV("%s: exit", __func__);
 return 0;

error_open:
    free(out);
 *stream_out = NULL;
    ALOGV("%s: exit: ret %d", __func__, ret);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::updateGraphicBufferInMeta(

         OMX_U32 portIndex, const sp<GraphicBuffer>& graphicBuffer,
         OMX::buffer_id buffer) {
     Mutex::Autolock autoLock(mLock);
    OMX_BUFFERHEADERTYPE *header = findBufferHeader(buffer);
     return updateGraphicBufferInMeta_l(portIndex, graphicBuffer, buffer, header);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Maybe<bool> CollectValuesOrEntriesImpl(

       Isolate* isolate, Handle<JSObject> object,
       Handle<FixedArray> values_or_entries, bool get_entries, int* nof_items,
       PropertyFilter filter) {
    int count = 0;
     KeyAccumulator accumulator(isolate, KeyCollectionMode::kOwnOnly,
                                ALL_PROPERTIES);
     Subclass::CollectElementIndicesImpl(
         object, handle(object->elements(), isolate), &accumulator);
     Handle<FixedArray> keys = accumulator.GetKeys();
 
    for (int i = 0; i < keys->length(); ++i) {
       Handle<Object> key(keys->get(i), isolate);
      Handle<Object> value;
       uint32_t index;
       if (!key->ToUint32(&index)) continue;
 
       uint32_t entry = Subclass::GetEntryForIndexImpl(
           isolate, *object, object->elements(), index, filter);
       if (entry == kMaxUInt32) continue;
 
       PropertyDetails details = Subclass::GetDetailsImpl(*object, entry);
 
       if (details.kind() == kData) {
         value = Subclass::GetImpl(isolate, object->elements(), entry);
       } else {
         LookupIterator it(isolate, object, index, LookupIterator::OWN);
         ASSIGN_RETURN_ON_EXCEPTION_VALUE(
             isolate, value, Object::GetProperty(&it), Nothing<bool>());
       }
      if (get_entries) {
        value = MakeEntryPair(isolate, index, value);
       }
       values_or_entries->set(count++, *value);
     }
 
 *nof_items = count;
 return Just(true);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void ih264d_init_decoder(void * ps_dec_params)
{

     dec_struct_t * ps_dec = (dec_struct_t *)ps_dec_params;
     dec_slice_params_t *ps_cur_slice;
     pocstruct_t *ps_prev_poc, *ps_cur_poc;
 
     /* Free any dynamic buffers that are allocated */
     ih264d_free_dynamic_bufs(ps_dec);

    ps_cur_slice = ps_dec->ps_cur_slice;
    ps_dec->init_done = 0;

    ps_dec->u4_num_cores = 1;

    ps_dec->u2_pic_ht = ps_dec->u2_pic_wd = 0;

    ps_dec->u1_separate_parse = DEFAULT_SEPARATE_PARSE;
    ps_dec->u4_app_disable_deblk_frm = 0;
    ps_dec->i4_degrade_type = 0;
    ps_dec->i4_degrade_pics = 0;

    ps_dec->i4_app_skip_mode = IVD_SKIP_NONE;
    ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;

    memset(ps_dec->ps_pps, 0,
 ((sizeof(dec_pic_params_t)) * MAX_NUM_PIC_PARAMS));
    memset(ps_dec->ps_sps, 0,
 ((sizeof(dec_seq_params_t)) * MAX_NUM_SEQ_PARAMS));

 /* Initialization of function pointers ih264d_deblock_picture function*/

    ps_dec->p_DeblockPicture[0] = ih264d_deblock_picture_non_mbaff;
    ps_dec->p_DeblockPicture[1] = ih264d_deblock_picture_mbaff;

    ps_dec->s_cab_dec_env.pv_codec_handle = ps_dec;

    ps_dec->u4_num_fld_in_frm = 0;

    ps_dec->ps_dpb_mgr->pv_codec_handle = ps_dec;

 /* Initialize the sei validity u4_flag with zero indiacting sei is not valid*/
    ps_dec->ps_sei->u1_is_valid = 0;

 /* decParams Initializations */
    ps_dec->ps_cur_pps = NULL;
    ps_dec->ps_cur_sps = NULL;
    ps_dec->u1_init_dec_flag = 0;
    ps_dec->u1_first_slice_in_stream = 1;
    ps_dec->u1_first_pb_nal_in_pic = 1;
    ps_dec->u1_last_pic_not_decoded = 0;
    ps_dec->u4_app_disp_width = 0;
    ps_dec->i4_header_decoded = 0;
    ps_dec->u4_total_frames_decoded = 0;

    ps_dec->i4_error_code = 0;
    ps_dec->i4_content_type = -1;
    ps_dec->ps_cur_slice->u1_mbaff_frame_flag = 0;

    ps_dec->ps_dec_err_status->u1_err_flag = ACCEPT_ALL_PICS; //REJECT_PB_PICS;
    ps_dec->ps_dec_err_status->u1_cur_pic_type = PIC_TYPE_UNKNOWN;
    ps_dec->ps_dec_err_status->u4_frm_sei_sync = SYNC_FRM_DEFAULT;
    ps_dec->ps_dec_err_status->u4_cur_frm = INIT_FRAME;
    ps_dec->ps_dec_err_status->u1_pic_aud_i = PIC_TYPE_UNKNOWN;

    ps_dec->u1_pr_sl_type = 0xFF;
    ps_dec->u2_mbx = 0xffff;
    ps_dec->u2_mby = 0;
    ps_dec->u2_total_mbs_coded = 0;

 /* POC initializations */
    ps_prev_poc = &ps_dec->s_prev_pic_poc;
    ps_cur_poc = &ps_dec->s_cur_pic_poc;
    ps_prev_poc->i4_pic_order_cnt_lsb = ps_cur_poc->i4_pic_order_cnt_lsb = 0;
    ps_prev_poc->i4_pic_order_cnt_msb = ps_cur_poc->i4_pic_order_cnt_msb = 0;
    ps_prev_poc->i4_delta_pic_order_cnt_bottom =
                    ps_cur_poc->i4_delta_pic_order_cnt_bottom = 0;
    ps_prev_poc->i4_delta_pic_order_cnt[0] =
                    ps_cur_poc->i4_delta_pic_order_cnt[0] = 0;
    ps_prev_poc->i4_delta_pic_order_cnt[1] =
                    ps_cur_poc->i4_delta_pic_order_cnt[1] = 0;
    ps_prev_poc->u1_mmco_equalto5 = ps_cur_poc->u1_mmco_equalto5 = 0;
    ps_prev_poc->i4_top_field_order_count = ps_cur_poc->i4_top_field_order_count =
 0;
    ps_prev_poc->i4_bottom_field_order_count =
                    ps_cur_poc->i4_bottom_field_order_count = 0;
    ps_prev_poc->u1_bot_field = ps_cur_poc->u1_bot_field = 0;
    ps_prev_poc->u1_mmco_equalto5 = ps_cur_poc->u1_mmco_equalto5 = 0;
    ps_prev_poc->i4_prev_frame_num_ofst = ps_cur_poc->i4_prev_frame_num_ofst = 0;
    ps_cur_slice->u1_mmco_equalto5 = 0;
    ps_cur_slice->u2_frame_num = 0;

    ps_dec->i4_max_poc = 0;
    ps_dec->i4_prev_max_display_seq = 0;
    ps_dec->u1_recon_mb_grp = 4;

 /* Field PIC initializations */
    ps_dec->u1_second_field = 0;
    ps_dec->s_prev_seq_params.u1_eoseq_pending = 0;

 /* Set the cropping parameters as zero */
    ps_dec->u2_crop_offset_y = 0;
    ps_dec->u2_crop_offset_uv = 0;

 /* The Initial Frame Rate Info is not Present */
    ps_dec->i4_vui_frame_rate = -1;
    ps_dec->i4_pic_type = -1;
    ps_dec->i4_frametype = -1;
    ps_dec->i4_content_type = -1;

    ps_dec->u1_res_changed = 0;


    ps_dec->u1_frame_decoded_flag = 0;

 /* Set the default frame seek mask mode */
    ps_dec->u4_skip_frm_mask = SKIP_NONE;

 /********************************************************/
 /* Initialize CAVLC residual decoding function pointers */
 /********************************************************/
    ps_dec->pf_cavlc_4x4res_block[0] = ih264d_cavlc_4x4res_block_totalcoeff_1;
    ps_dec->pf_cavlc_4x4res_block[1] =
                    ih264d_cavlc_4x4res_block_totalcoeff_2to10;
    ps_dec->pf_cavlc_4x4res_block[2] =
                    ih264d_cavlc_4x4res_block_totalcoeff_11to16;

    ps_dec->pf_cavlc_parse4x4coeff[0] = ih264d_cavlc_parse4x4coeff_n0to7;
    ps_dec->pf_cavlc_parse4x4coeff[1] = ih264d_cavlc_parse4x4coeff_n8;

    ps_dec->pf_cavlc_parse_8x8block[0] =
                    ih264d_cavlc_parse_8x8block_none_available;
    ps_dec->pf_cavlc_parse_8x8block[1] =
                    ih264d_cavlc_parse_8x8block_left_available;
    ps_dec->pf_cavlc_parse_8x8block[2] =
                    ih264d_cavlc_parse_8x8block_top_available;
    ps_dec->pf_cavlc_parse_8x8block[3] =
                    ih264d_cavlc_parse_8x8block_both_available;

 /***************************************************************************/
 /* Initialize Bs calculation function pointers for P and B, 16x16/non16x16 */
 /***************************************************************************/
    ps_dec->pf_fill_bs1[0][0] = ih264d_fill_bs1_16x16mb_pslice;
    ps_dec->pf_fill_bs1[0][1] = ih264d_fill_bs1_non16x16mb_pslice;

    ps_dec->pf_fill_bs1[1][0] = ih264d_fill_bs1_16x16mb_bslice;
    ps_dec->pf_fill_bs1[1][1] = ih264d_fill_bs1_non16x16mb_bslice;

    ps_dec->pf_fill_bs_xtra_left_edge[0] =
                    ih264d_fill_bs_xtra_left_edge_cur_frm;
    ps_dec->pf_fill_bs_xtra_left_edge[1] =
                    ih264d_fill_bs_xtra_left_edge_cur_fld;

 /* Initialize Reference Pic Buffers */
    ih264d_init_ref_bufs(ps_dec->ps_dpb_mgr);

    ps_dec->u2_prv_frame_num = 0;
    ps_dec->u1_top_bottom_decoded = 0;
    ps_dec->u1_dangling_field = 0;

    ps_dec->s_cab_dec_env.cabac_table = gau4_ih264d_cabac_table;

    ps_dec->pu1_left_mv_ctxt_inc = ps_dec->u1_left_mv_ctxt_inc_arr[0];
    ps_dec->pi1_left_ref_idx_ctxt_inc =
 &ps_dec->i1_left_ref_idx_ctx_inc_arr[0][0];
    ps_dec->pu1_left_yuv_dc_csbp = &ps_dec->u1_yuv_dc_csbp_topmb;

 /* ! */
 /* Initializing flush frame u4_flag */
    ps_dec->u1_flushfrm = 0;

 {
        ps_dec->s_cab_dec_env.pv_codec_handle = (void*)ps_dec;
        ps_dec->ps_bitstrm->pv_codec_handle = (void*)ps_dec;
        ps_dec->ps_cur_slice->pv_codec_handle = (void*)ps_dec;
        ps_dec->ps_dpb_mgr->pv_codec_handle = (void*)ps_dec;
 }

    memset(ps_dec->disp_bufs, 0, (MAX_DISP_BUFS_NEW) * sizeof(disp_buf_t));
    memset(ps_dec->u4_disp_buf_mapping, 0,
 (MAX_DISP_BUFS_NEW) * sizeof(UWORD32));
    memset(ps_dec->u4_disp_buf_to_be_freed, 0,
 (MAX_DISP_BUFS_NEW) * sizeof(UWORD32));

    ih264d_init_arch(ps_dec);
    ih264d_init_function_ptr(ps_dec);
    ps_dec->e_frm_out_mode = IVD_DISPLAY_FRAME_OUT;
    ps_dec->init_done = 1;

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 ih264d_do_mmco_buffer(dpb_commands_t *ps_dpb_cmds,
 dpb_manager_t *ps_dpb_mgr,
                          UWORD8 u1_numRef_frames_for_seq, /*!< num_ref_frames from active SeqParSet*/
                          UWORD32 u4_cur_pic_num,
                          UWORD32 u2_u4_max_pic_num_minus1,
                          UWORD8 u1_nal_unit_type,
 struct pic_buffer_t *ps_pic_buf,
                          UWORD8 u1_buf_id,
                          UWORD8 u1_fld_pic_flag,
                          UWORD8 u1_curr_pic_in_err)
{
    WORD32 i;
    UWORD8 u1_buf_mode, u1_marked_lt;
 struct dpb_info_t *ps_next_dpb;
    UWORD8 u1_num_gaps;
    UWORD8 u1_del_node = 1;
    UWORD8 u1_insert_st_pic = 1;
    WORD32 ret;
    UNUSED(u1_nal_unit_type);
    UNUSED(u2_u4_max_pic_num_minus1);
    u1_buf_mode = ps_dpb_cmds->u1_buf_mode; //0 - sliding window; 1 - Adaptive
    u1_marked_lt = 0;
    u1_num_gaps = ps_dpb_mgr->u1_num_gaps;

 if(!u1_buf_mode)
 {
 if((ps_dpb_mgr->u1_num_st_ref_bufs
 + ps_dpb_mgr->u1_num_lt_ref_bufs + u1_num_gaps)
 == u1_numRef_frames_for_seq)
 {
            UWORD8 u1_new_node_flag = 1;
 if((0 == ps_dpb_mgr->u1_num_st_ref_bufs) && (0 == u1_num_gaps))
 {
                UWORD32 i4_error_code;
                i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }

            ps_next_dpb = ps_dpb_mgr->ps_dpb_st_head;

 if(ps_dpb_mgr->u1_num_st_ref_bufs > 1)
 {
 if(ps_next_dpb->i4_frame_num == (WORD32)u4_cur_pic_num)
 {
 /* Incase of  filed pictures top_field has been allocated   */
 /* picture buffer and complementary bottom field pair comes */
 /* then the sliding window mechanism should not allocate a  */
 /* new node                                                 */
                    u1_new_node_flag = 0;
 }

 for(i = 1; i < (ps_dpb_mgr->u1_num_st_ref_bufs - 1); i++)
 {
 if(ps_next_dpb == NULL)
 {
                        UWORD32 i4_error_code;
                        i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }
 if(ps_next_dpb->i4_frame_num == (WORD32)u4_cur_pic_num)
 {
 /* Incase of  field pictures top_field has been allocated   */
 /* picture buffer and complementary bottom field pair comes */
 /* then the sliding window mechanism should not allocate a  */
 /* new node                                                 */
                        u1_new_node_flag = 0;
 }
                    ps_next_dpb = ps_next_dpb->ps_prev_short;
 }

 if(ps_next_dpb->ps_prev_short->ps_prev_short != NULL)
 {
                    UWORD32 i4_error_code;
                    i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }

 if(u1_new_node_flag)
 {
 if(u1_num_gaps)
 {
                        ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                            ps_next_dpb->ps_prev_short->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 }

 if(u1_del_node)
 {
                        ps_dpb_mgr->u1_num_st_ref_bufs--;
                        ps_next_dpb->ps_prev_short->u1_used_as_ref =
                                        UNUSED_FOR_REF;
                        ps_next_dpb->ps_prev_short->s_top_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ps_next_dpb->ps_prev_short->s_bot_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                    ps_next_dpb->ps_prev_short->u1_buf_id);
                        ps_next_dpb->ps_prev_short->ps_pic_buf = NULL;
                        ps_next_dpb->ps_prev_short = NULL;
 }
 }
 }
 else
 {
 if(ps_dpb_mgr->u1_num_st_ref_bufs)
 {
                    ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                       ps_next_dpb->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 if((ps_next_dpb->i4_frame_num != (WORD32)u4_cur_pic_num)
 && u1_del_node)
 {
                        ps_dpb_mgr->u1_num_st_ref_bufs--;
                        ps_next_dpb->u1_used_as_ref = FALSE;
                        ps_next_dpb->s_top_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ps_next_dpb->s_bot_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                    ps_next_dpb->u1_buf_id);
                        ps_next_dpb->ps_pic_buf = NULL;
                        ps_next_dpb->ps_prev_short = NULL;
                        ps_dpb_mgr->ps_dpb_st_head = NULL;
                        ps_next_dpb = NULL;
 }
 else if(ps_next_dpb->i4_frame_num == (WORD32)u4_cur_pic_num)
 {
 if(u1_curr_pic_in_err)
 {
                            u1_insert_st_pic = 0;
 }
 else if(ps_dpb_mgr->u1_num_st_ref_bufs > 0)
 {
                            ps_dpb_mgr->u1_num_st_ref_bufs--;
                            ps_next_dpb->u1_used_as_ref = FALSE;
                            ps_next_dpb->s_top_field.u1_reference_info =
                                            UNUSED_FOR_REF;
                            ps_next_dpb->s_bot_field.u1_reference_info =
                                            UNUSED_FOR_REF;
                            ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                        ps_next_dpb->u1_buf_id);
                            ps_next_dpb->ps_pic_buf = NULL;
                            ps_next_dpb = NULL;
 }
 }
 }
 else
 {
                    ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                        INVALID_FRAME_NUM,
 &u1_del_node);
 if(ret != OK)
 return ret;
 if(u1_del_node)
 {
                        UWORD32 i4_error_code;
                        i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }
 }
 }
 }
 }
 else
 {
        UWORD32 u4_mmco;
        UWORD32 u4_diff_pic_num;
        WORD32 i4_pic_num;
        UWORD32 u4_lt_idx;
        WORD32 j;
 struct MMCParams *ps_mmc_params;

 for(j = 0; j < ps_dpb_cmds->u1_num_of_commands; j++)
 {
            ps_mmc_params = &ps_dpb_cmds->as_mmc_params[j];
            u4_mmco = ps_mmc_params->u4_mmco; //Get MMCO

 switch(u4_mmco)
 {
 case MARK_ST_PICNUM_AS_NONREF:
 {

 {
                        UWORD32 i4_cur_pic_num = u4_cur_pic_num;
                        u4_diff_pic_num = ps_mmc_params->u4_diff_pic_num; //Get absDiffPicnumMinus1
 if(u1_fld_pic_flag)
                            i4_cur_pic_num = i4_cur_pic_num * 2 + 1;
                        i4_pic_num = i4_cur_pic_num - (u4_diff_pic_num + 1);
 }

 if(ps_dpb_mgr->u1_num_st_ref_bufs > 0)
 {
                        ret = ih264d_delete_st_node_or_make_lt(ps_dpb_mgr,
                                                               i4_pic_num,
                                                               MAX_REF_BUFS + 1,
                                                               u1_fld_pic_flag);
 if(ret != OK)
 return ret;
 }
 else
 {
                        UWORD8 u1_dummy;
                        ret = ih264d_delete_gap_frm_mmco(ps_dpb_mgr, i4_pic_num, &u1_dummy);
 if(ret != OK)
 return ret;
 }
 break;
 }
 case MARK_LT_INDEX_AS_NONREF:
 {
                    WORD32 i4_status;
                    u4_lt_idx = ps_mmc_params->u4_lt_idx; //Get long term index
                    ret = ih264d_delete_lt_node(ps_dpb_mgr,
                                                u4_lt_idx,
                                                u1_fld_pic_flag,
 0, &i4_status);
 if(ret != OK)
 return ret;
 if(i4_status)
 {
                        UWORD32 i4_error_code;
                        i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }
 break;
 }

 case MARK_ST_PICNUM_AS_LT_INDEX:
 {
 {
                        UWORD32 i4_cur_pic_num = u4_cur_pic_num;
                        u4_diff_pic_num = ps_mmc_params->u4_diff_pic_num; //Get absDiffPicnumMinus1
 if(u1_fld_pic_flag)
                            i4_cur_pic_num = i4_cur_pic_num * 2 + 1;

                        i4_pic_num = i4_cur_pic_num - (u4_diff_pic_num + 1);
 }

                    u4_lt_idx = ps_mmc_params->u4_lt_idx; //Get long term index
 if(ps_dpb_mgr->u1_num_st_ref_bufs > 0)
 {
                        ret = ih264d_delete_st_node_or_make_lt(ps_dpb_mgr,
                                                               i4_pic_num, u4_lt_idx,
                                                               u1_fld_pic_flag);
 if(ret != OK)
 return ret;
 }
 break;
 }
 case SET_MAX_LT_INDEX:
 {
                    UWORD8 uc_numLT = ps_dpb_mgr->u1_num_lt_ref_bufs;
                    u4_lt_idx = ps_mmc_params->u4_max_lt_idx_plus1; //Get Max_long_term_index_plus1
 if(u4_lt_idx < ps_dpb_mgr->u1_max_lt_pic_idx_plus1
 && uc_numLT > 0)
 {
 struct dpb_info_t *ps_nxtDPB;
                        ps_nxtDPB = ps_dpb_mgr->ps_dpb_ht_head;
                        ps_next_dpb = ps_nxtDPB->ps_prev_long;
 if(ps_nxtDPB->u1_lt_idx >= u4_lt_idx)
 {
                            i = 0;
                            ps_dpb_mgr->ps_dpb_ht_head = NULL;
 }
 else
 {
 for(i = 1; i < uc_numLT; i++)
 {
 if(ps_next_dpb->u1_lt_idx >= u4_lt_idx)
 break;
                                ps_nxtDPB = ps_next_dpb;
                                ps_next_dpb = ps_next_dpb->ps_prev_long;
 }
                            ps_nxtDPB->ps_prev_long = NULL; //Terminate the link of the closest LTIndex that is <=Max
 }
                        ps_dpb_mgr->u1_num_lt_ref_bufs = i;
 if(i == 0)
                            ps_next_dpb = ps_nxtDPB;

 for(; i < uc_numLT; i++)
 {
                            ps_nxtDPB = ps_next_dpb;
                            ps_nxtDPB->u1_lt_idx = MAX_REF_BUFS + 1;
                            ps_nxtDPB->u1_used_as_ref = UNUSED_FOR_REF;
                            ps_nxtDPB->s_top_field.u1_reference_info =
                                            UNUSED_FOR_REF;
                            ps_nxtDPB->s_bot_field.u1_reference_info =
                                            UNUSED_FOR_REF;

                            ps_nxtDPB->ps_pic_buf = NULL;
                            ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                        ps_nxtDPB->u1_buf_id);
                            ps_next_dpb = ps_nxtDPB->ps_prev_long;
                            ps_nxtDPB->ps_prev_long = NULL;
 }
 }
                    ps_dpb_mgr->u1_max_lt_pic_idx_plus1 = u4_lt_idx;

 break;
 }
 case SET_LT_INDEX:
 {
                    u4_lt_idx = ps_mmc_params->u4_lt_idx; //Get long term index
                    ret = ih264d_insert_st_node(ps_dpb_mgr, ps_pic_buf, u1_buf_id,
                                          u4_cur_pic_num);
 if(ret != OK)
 return ret;
                    ret = ih264d_delete_st_node_or_make_lt(ps_dpb_mgr,
                                                     u4_cur_pic_num, u4_lt_idx,
                                                     u1_fld_pic_flag);
 if(ret != OK)
 return ret;
                    u1_marked_lt = 1;
 break;
 }

 default:
 break;
 }
 if(u4_mmco == RESET_REF_PICTURES || u4_mmco == RESET_ALL_PICTURES)
 {
                ih264d_reset_ref_bufs(ps_dpb_mgr);
                u4_cur_pic_num = 0;
 }
 }
 }
 if(!u1_marked_lt && u1_insert_st_pic)
 {
        ret = ih264d_insert_st_node(ps_dpb_mgr, ps_pic_buf, u1_buf_id,
                              u4_cur_pic_num);
 if(ret != OK)
 return ret;
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: Camera2Client::~Camera2Client() {
    ATRACE_CALL();
    ALOGV("~Camera2Client");

    mDestructionStarted = true;

    disconnect();

    ALOGI("Camera %d: Closed", mCameraId);

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8 String8::getPathDir(void) const
{
 const char* cp;
 const char*const str = mString;

    cp = strrchr(str, OS_PATH_SEPARATOR);
 if (cp == NULL)
 return String8("");
 else
 return String8(str, cp - str);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ATSParser::hasSource(SourceType type) const {
 for (size_t i = 0; i < mPrograms.size(); ++i) {
 const sp<Program> &program = mPrograms.itemAt(i);
 if (program->hasSource(type)) {
 return true;
 }
 }

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const btif_config_section_iter_t *btif_config_section_end(void) {
  assert(config != NULL);
 return (const btif_config_section_iter_t *)config_section_end(config);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::parseTrackFragmentRun(off64_t offset, off64_t size) {

    ALOGV("MPEG4Extractor::parseTrackFragmentRun");
 if (size < 8) {
 return -EINVAL;
 }

 enum {
        kDataOffsetPresent                  = 0x01,
        kFirstSampleFlagsPresent            = 0x04,
        kSampleDurationPresent              = 0x100,
        kSampleSizePresent                  = 0x200,
        kSampleFlagsPresent                 = 0x400,
        kSampleCompositionTimeOffsetPresent = 0x800,
 };

 uint32_t flags;
 if (!mDataSource->getUInt32(offset, &flags)) {
 return ERROR_MALFORMED;
 }
    ALOGV("fragment run flags: %08x", flags);

 if (flags & 0xff000000) {
 return -EINVAL;
 }

 if ((flags & kFirstSampleFlagsPresent) && (flags & kSampleFlagsPresent)) {
 return -EINVAL;
 }

 uint32_t sampleCount;
 if (!mDataSource->getUInt32(offset + 4, &sampleCount)) {
 return ERROR_MALFORMED;
 }
    offset += 8;
    size -= 8;

 uint64_t dataOffset = mTrackFragmentHeaderInfo.mDataOffset;

 uint32_t firstSampleFlags = 0;

 if (flags & kDataOffsetPresent) {
 if (size < 4) {
 return -EINVAL;
 }

 int32_t dataOffsetDelta;
 if (!mDataSource->getUInt32(offset, (uint32_t*)&dataOffsetDelta)) {
 return ERROR_MALFORMED;
 }

        dataOffset = mTrackFragmentHeaderInfo.mBaseDataOffset + dataOffsetDelta;

        offset += 4;
        size -= 4;
 }

 if (flags & kFirstSampleFlagsPresent) {
 if (size < 4) {
 return -EINVAL;
 }

 if (!mDataSource->getUInt32(offset, &firstSampleFlags)) {
 return ERROR_MALFORMED;
 }
        offset += 4;
        size -= 4;
 }

 uint32_t sampleDuration = 0, sampleSize = 0, sampleFlags = 0,
             sampleCtsOffset = 0;

 size_t bytesPerSample = 0;
 if (flags & kSampleDurationPresent) {
        bytesPerSample += 4;
 } else if (mTrackFragmentHeaderInfo.mFlags
 & TrackFragmentHeaderInfo::kDefaultSampleDurationPresent) {
        sampleDuration = mTrackFragmentHeaderInfo.mDefaultSampleDuration;
 } else {
        sampleDuration = mTrackFragmentHeaderInfo.mDefaultSampleDuration;
 }

 if (flags & kSampleSizePresent) {
        bytesPerSample += 4;
 } else if (mTrackFragmentHeaderInfo.mFlags
 & TrackFragmentHeaderInfo::kDefaultSampleSizePresent) {
        sampleSize = mTrackFragmentHeaderInfo.mDefaultSampleSize;
 } else {
        sampleSize = mTrackFragmentHeaderInfo.mDefaultSampleSize;
 }

 if (flags & kSampleFlagsPresent) {
        bytesPerSample += 4;
 } else if (mTrackFragmentHeaderInfo.mFlags
 & TrackFragmentHeaderInfo::kDefaultSampleFlagsPresent) {
        sampleFlags = mTrackFragmentHeaderInfo.mDefaultSampleFlags;
 } else {
        sampleFlags = mTrackFragmentHeaderInfo.mDefaultSampleFlags;
 }

 if (flags & kSampleCompositionTimeOffsetPresent) {
        bytesPerSample += 4;
 } else {
        sampleCtsOffset = 0;
 }

 if (size < sampleCount * bytesPerSample) {
 return -EINVAL;
 }

 Sample tmp;
 for (uint32_t i = 0; i < sampleCount; ++i) {
 if (flags & kSampleDurationPresent) {
 if (!mDataSource->getUInt32(offset, &sampleDuration)) {
 return ERROR_MALFORMED;
 }
            offset += 4;
 }

 if (flags & kSampleSizePresent) {
 if (!mDataSource->getUInt32(offset, &sampleSize)) {
 return ERROR_MALFORMED;
 }
            offset += 4;
 }

 if (flags & kSampleFlagsPresent) {
 if (!mDataSource->getUInt32(offset, &sampleFlags)) {
 return ERROR_MALFORMED;
 }
            offset += 4;
 }

 if (flags & kSampleCompositionTimeOffsetPresent) {
 if (!mDataSource->getUInt32(offset, &sampleCtsOffset)) {
 return ERROR_MALFORMED;
 }
            offset += 4;
 }

        ALOGV("adding sample %d at offset 0x%08llx, size %u, duration %u, "
 " flags 0x%08x", i + 1,
                dataOffset, sampleSize, sampleDuration,
 (flags & kFirstSampleFlagsPresent) && i == 0
 ? firstSampleFlags : sampleFlags);
        tmp.offset = dataOffset;
        tmp.size = sampleSize;
        tmp.duration = sampleDuration;
        mCurrentSamples.add(tmp);

        dataOffset += sampleSize;
 }

    mTrackFragmentHeaderInfo.mDataOffset = dataOffset;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void SoftVPX::onQueueFilled(OMX_U32 /* portIndex */) {
     if (mOutputPortSettingsChange != NONE || mEOSStatus == OUTPUT_FRAMES_FLUSHED) {
         return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);
 bool EOSseen = false;
 bool portWillReset = false;

 while ((mEOSStatus == INPUT_EOS_SEEN || !inQueue.empty())
 && !outQueue.empty()) {
 if (mEOSStatus == INPUT_EOS_SEEN || mImg != NULL) {
 if (!outputBuffers(
                     mEOSStatus == INPUT_EOS_SEEN, true /* display */,
                     mEOSStatus == INPUT_EOS_SEEN, &portWillReset)) {
                ALOGE("on2 decoder failed to output frame.");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 if (portWillReset || mEOSStatus == OUTPUT_FRAMES_FLUSHED ||
                    mEOSStatus == INPUT_EOS_SEEN) {
 return;
 }
 continue;
 }

 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
 if (mMode == MODE_VP9) {
                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);
 continue;
 } else {
                ALOGW("WARNING: Got CSD buffer for VP8.");
 }
 }

        mTimeStamps[mTimeStampIdx] = inHeader->nTimeStamp;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            mEOSStatus = INPUT_EOS_SEEN;
 EOSseen = true;
 }

 if (inHeader->nFilledLen > 0) {
 vpx_codec_err_t err = vpx_codec_decode(
 (vpx_codec_ctx_t *)mCtx, inHeader->pBuffer + inHeader->nOffset,
                    inHeader->nFilledLen, &mTimeStamps[mTimeStampIdx], 0);
 if (err == VPX_CODEC_OK) {
                inInfo->mOwnedByUs = false;
                inQueue.erase(inQueue.begin());
                inInfo = NULL;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;
 } else {
                ALOGE("on2 decoder failed to decode frame. err: %d", err);
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 }

        mTimeStampIdx = (mTimeStampIdx + 1) % kNumBuffers;

 if (!outputBuffers(
 EOSseen /* flushDecoder */, true /* display */, EOSseen, &portWillReset)) {
            ALOGE("on2 decoder failed to output frame.");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 if (portWillReset) {
 return;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: png_col_from_pass_col(png_uint_32 xIn, int pass)
{
 /* By examination of the array: */
 switch (pass)
 {
case 0: return xIn * 8;
case 1: return xIn * 8 + 4;
case 2: return xIn * 4;
case 3: return xIn * 4 + 2;
case 4: return xIn * 2;
case 5: return xIn * 2 + 1;
case 6: return xIn;
default: break;
 }

 return 0xff; /* bad pass number */
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_venc::dev_color_align(OMX_BUFFERHEADERTYPE *buffer,
                OMX_U32 width, OMX_U32 height)
{
 if(secure_session) {
        DEBUG_PRINT_ERROR("Cannot align colors in secure session.");
 return OMX_FALSE;
 }
 return handle->venc_color_align(buffer, width,height);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_peek_next_start_code(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    ps_stream = &ps_dec->s_bit_stream;

     impeg2d_bit_stream_flush_to_byte_boundary(ps_stream);
 
     while ((impeg2d_bit_stream_nxt(ps_stream,START_CODE_PREFIX_LEN) != START_CODE_PREFIX)
        && (ps_dec->s_bit_stream.u4_offset <= ps_dec->s_bit_stream.u4_max_offset))
     {
         impeg2d_bit_stream_get(ps_stream,8);
     }
 return;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void RilSapSocket::sendResponse(MsgHeader* hdr) {
 size_t encoded_size = 0;
 uint32_t written_size;
 size_t buffer_size = 0;
 pb_ostream_t ostream;
 bool success = false;

    pthread_mutex_lock(&write_lock);


     if ((success = pb_get_encoded_size(&encoded_size, MsgHeader_fields,
         hdr)) && encoded_size <= INT32_MAX && commandFd != -1) {
         buffer_size = encoded_size + sizeof(uint32_t);
        uint8_t buffer[buffer_size];
         written_size = htonl((uint32_t) encoded_size);
         ostream = pb_ostream_from_buffer(buffer, buffer_size);
         pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));
        success = pb_encode(&ostream, MsgHeader_fields, hdr);

 if (success) {
            RLOGD("Size: %d (0x%x) Size as written: 0x%x", encoded_size, encoded_size,
        written_size);
            log_hex("onRequestComplete", &buffer[sizeof(written_size)], encoded_size);
            RLOGI("[%d] < SAP RESPONSE type: %d. id: %d. error: %d",
        hdr->token, hdr->type, hdr->id,hdr->error );

 if ( 0 != blockingWrite_helper(commandFd, buffer, buffer_size)) {
                RLOGE("Error %d while writing to fd", errno);
 } else {
                RLOGD("Write successful");
 }
 } else {

             RLOGE("Error while encoding response of type %d id %d buffer_size: %d: %s.",
             hdr->type, hdr->id, buffer_size, PB_GET_ERROR(&ostream));
         }
     } else {
     RLOGE("Not sending response type %d: encoded_size: %u. commandFd: %d. encoded size result: %d",
         hdr->type, encoded_size, commandFd, success);
 }

    pthread_mutex_unlock(&write_lock);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void reference_16x16_dct_2d(int16_t input[256], double output[256]) {
 for (int i = 0; i < 16; ++i) {
 double temp_in[16], temp_out[16];
 for (int j = 0; j < 16; ++j)
      temp_in[j] = input[j * 16 + i];
    butterfly_16x16_dct_1d(temp_in, temp_out);
 for (int j = 0; j < 16; ++j)
      output[j * 16 + i] = temp_out[j];
 }
 for (int i = 0; i < 16; ++i) {
 double temp_in[16], temp_out[16];
 for (int j = 0; j < 16; ++j)
      temp_in[j] = output[j + i * 16];
    butterfly_16x16_dct_1d(temp_in, temp_out);
 for (int j = 0; j < 16; ++j)
      output[j + i * 16] = temp_out[j]/2;

   }
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static jlong Region_createFromParcel(JNIEnv* env, jobject clazz, jobject parcel)
{
 if (parcel == NULL) {
 return NULL;
 }

 
     android::Parcel* p = android::parcelForJavaObject(env, parcel);
 
     SkRegion* region = new SkRegion;
    size_t size = p->readInt32();
    region->readFromMemory(p->readInplace(size), size);
 
     return reinterpret_cast<jlong>(region);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::cancelAutoFocus() {
    ATRACE_CALL();
 Mutex::Autolock icl(mBinderSerializationLock);
    ALOGV("%s: Camera %d", __FUNCTION__, mCameraId);
 status_t res;
 if ( (res = checkPid(__FUNCTION__) ) != OK) return res;

 int triggerId;
 {
 SharedParameters::Lock l(mParameters);
 if (l.mParameters.focusMode == Parameters::FOCUS_MODE_FIXED ||
                l.mParameters.focusMode == Parameters::FOCUS_MODE_INFINITY) {
 return OK;
 }

 if (l.mParameters.afTriggerCounter == l.mParameters.currentAfTriggerId) {
            ATRACE_ASYNC_END(kAutofocusLabel, l.mParameters.currentAfTriggerId);
 }

        triggerId = ++l.mParameters.afTriggerCounter;

 if (l.mParameters.shadowFocusMode != Parameters::FOCUS_MODE_INVALID) {
            ALOGV("%s: Quirk: Restoring focus mode to %d", __FUNCTION__,
                    l.mParameters.shadowFocusMode);
            l.mParameters.focusMode = l.mParameters.shadowFocusMode;
            l.mParameters.shadowFocusMode = Parameters::FOCUS_MODE_INVALID;
            updateRequests(l.mParameters);

 return OK;
 }
 }
    syncWithDevice();

    mDevice->triggerCancelAutofocus(triggerId);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::empty_this_buffer(OMX_IN OMX_HANDLETYPE         hComp,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
    OMX_ERRORTYPE ret1 = OMX_ErrorNone;

     unsigned int nBufferIndex ;
 
     DEBUG_PRINT_LOW("ETB: buffer = %p, buffer->pBuffer[%p]", buffer, buffer->pBuffer);
    if (m_state == OMX_StateInvalid) {
         DEBUG_PRINT_ERROR("ERROR: Empty this buffer in Invalid State");
         return OMX_ErrorInvalidState;
     }

 if (buffer == NULL || (buffer->nSize != sizeof(OMX_BUFFERHEADERTYPE))) {
        DEBUG_PRINT_ERROR("ERROR: omx_video::etb--> buffer is null or buffer size is invalid");
 return OMX_ErrorBadParameter;
 }

 if (buffer->nVersion.nVersion != OMX_SPEC_VERSION) {
        DEBUG_PRINT_ERROR("ERROR: omx_video::etb--> OMX Version Invalid");
 return OMX_ErrorVersionMismatch;
 }

 if (buffer->nInputPortIndex != (OMX_U32)PORT_INDEX_IN) {
        DEBUG_PRINT_ERROR("ERROR: Bad port index to call empty_this_buffer");
 return OMX_ErrorBadPortIndex;
 }
 if (!m_sInPortDef.bEnabled) {
        DEBUG_PRINT_ERROR("ERROR: Cannot call empty_this_buffer while I/P port is disabled");
 return OMX_ErrorIncorrectStateOperation;
 }

    nBufferIndex = buffer - ((!meta_mode_enable)?m_inp_mem_ptr:meta_buffer_hdr);

 if (nBufferIndex > m_sInPortDef.nBufferCountActual ) {
        DEBUG_PRINT_ERROR("ERROR: ETB: Invalid buffer index[%d]", nBufferIndex);
 return OMX_ErrorBadParameter;
 }

    m_etb_count++;
    DEBUG_PRINT_LOW("DBG: i/p nTimestamp = %u", (unsigned)buffer->nTimeStamp);
    post_event ((unsigned long)hComp,(unsigned long)buffer,m_input_msg_id);
 return OMX_ErrorNone;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BOOLEAN btif_hl_load_mdl_config (UINT8 app_id, UINT8 buffer_size,
                                 tBTA_HL_MDL_CFG *p_mdl_buf ){
    UINT8 app_idx;
    BOOLEAN result = FALSE;
 btif_hl_app_cb_t *p_acb;
    tBTA_HL_MDL_CFG *p;
 int i;
    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

 if (btif_hl_find_app_idx(app_id, &app_idx))
 {
        p_acb  = BTIF_HL_GET_APP_CB_PTR(app_idx);
 for (i=0, p=p_mdl_buf; i<buffer_size; i++, p++)
 {
            memcpy(p, &p_acb->mdl_cfg[i].base, sizeof(tBTA_HL_MDL_CFG));
 }
        result = TRUE;
 }

    BTIF_TRACE_DEBUG("result=%d", result);
 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BnSoundTriggerHwService::onTransact(
 uint32_t code, const Parcel& data, Parcel* reply, uint32_t flags)
{
 switch(code) {

         case LIST_MODULES: {
             CHECK_INTERFACE(ISoundTriggerHwService, data, reply);
             unsigned int numModulesReq = data.readInt32();
             unsigned int numModules = numModulesReq;
             struct sound_trigger_module_descriptor *modules =
                     (struct sound_trigger_module_descriptor *)calloc(numModulesReq,
                                                    sizeof(struct sound_trigger_module_descriptor));
             status_t status = listModules(modules, &numModules);
             reply->writeInt32(status);
             reply->writeInt32(numModules);
            ALOGV("LIST_MODULES status %d got numModules %d", status, numModules);

 if (status == NO_ERROR) {
 if (numModulesReq > numModules) {
                    numModulesReq = numModules;
 }
                reply->write(modules,
                             numModulesReq * sizeof(struct sound_trigger_module_descriptor));
 }
            free(modules);
 return NO_ERROR;
 }

 case ATTACH: {
            CHECK_INTERFACE(ISoundTriggerHwService, data, reply);
 sound_trigger_module_handle_t handle;
            data.read(&handle, sizeof(sound_trigger_module_handle_t));
            sp<ISoundTriggerClient> client =
                    interface_cast<ISoundTriggerClient>(data.readStrongBinder());
            sp<ISoundTrigger> module;
 status_t status = attach(handle, client, module);
            reply->writeInt32(status);
 if (module != 0) {
                reply->writeInt32(1);
                reply->writeStrongBinder(IInterface::asBinder(module));
 } else {
                reply->writeInt32(0);
 }
 return NO_ERROR;
 } break;

 case SET_CAPTURE_STATE: {
            CHECK_INTERFACE(ISoundTriggerHwService, data, reply);
            reply->writeInt32(setCaptureState((bool)data.readInt32()));
 return NO_ERROR;
 } break;

 default:
 return BBinder::onTransact(code, data, reply, flags);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readString16(String16* pArg) const
{
 size_t len;
 const char16_t* str = readString16Inplace(&len);
 if (str) {
        pArg->setTo(str, len);
 return 0;
 } else {
 *pArg = String16();
 return UNEXPECTED_NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char* in_get_parameters(const struct audio_stream *stream,
 const char *keys)
{
 (void)stream;
 (void)keys;

 return strdup("");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: unsigned long ContentEncoding::GetCompressionCount() const {
 const ptrdiff_t count = compression_entries_end_ - compression_entries_;
  assert(count >= 0);

 return static_cast<unsigned long>(count);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean android_net_wifi_resetHotlist(JNIEnv *env, jclass cls, jint iface, jint id) {

 JNIHelper helper(env);
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);
    ALOGD("resetting hotlist on interface[%d] = %p", iface, handle);

 return hal_fn.wifi_reset_bssid_hotlist(id, handle) == WIFI_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundChannel::autoPause()
{
 Mutex::Autolock lock(&mLock);
 if (mState == PLAYING) {
        ALOGV("pause track");
        mState = PAUSED;
        mAutoPaused = true;
        mAudioTrack->pause();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void DumpDLS (S_EAS *pEAS)
{
    S_DLS_ARTICULATION *pArt;
    S_DLS_REGION *pRegion;
    EAS_INT i;
    EAS_INT j;

    EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000022 , pEAS->numPrograms);
    EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000023 , pEAS->numWTRegions);
    EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000024 , pEAS->numDLSArticulations);
    EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000025 , pEAS->numSamples);

 /* dump the instruments */
 for (i = 0; i < pEAS->numPrograms; i++)
 {
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000026 ,
                pEAS->pPrograms[i].locale >> 16,
 (pEAS->pPrograms[i].locale >> 8) & 0x7f,
                pEAS->pPrograms[i].locale & 0x7f);

 for (j = pEAS->pPrograms[i].regionIndex; ; j++)
 {
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000027 , j);
            pRegion = &pEAS->pWTRegions[j];
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000028 , pRegion->gain);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000029 , pRegion->region.rangeLow, pRegion->region.rangeHigh);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002a , pRegion->region.keyGroupAndFlags);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002b , pRegion->loopStart);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002c , pRegion->loopEnd);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002d , pRegion->tuning);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002e , pRegion->artIndex);
            EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000002f , pRegion->waveIndex);

 if (pRegion->region.keyGroupAndFlags & REGION_FLAG_LAST_REGION)
 break;
 }

 }

 /* dump the articulation data */
 for (i = 0; i < pEAS->numDLSArticulations; i++)
 {
 /* articulation data */
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000030 , i);
        pArt = &pEAS->pDLSArticulations[i];
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000031 , pArt->m_nEG2toFilterDepth);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000032 , pArt->m_nEG2toPitchDepth);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000033 , pArt->m_nFilterCutoffFrequency);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000034 , pArt->m_nFilterResonance);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000035 , pArt->m_nLFOAmplitudeDepth);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000036 , pArt->m_nLFODelayTime);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000037 , pArt->m_nLFOFrequency);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000038 , pArt->m_nLFOPitchDepth);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000039 , pArt->m_nPan);

 /* EG1 data */
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003a , pArt->m_sEG1.m_nAttack);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003b , pArt->m_sEG1.m_nDecay);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003c , pArt->m_sEG1.m_nSustain);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003d , pArt->m_sEG1.m_nRelease);

 /* EG2 data */
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003e , pArt->m_sEG2.m_nAttack);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x0000003f , pArt->m_sEG2.m_nDecay);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000040 , pArt->m_sEG2.m_nSustain);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000041 , pArt->m_sEG2.m_nRelease);

 }

 /* dump the waves */
 for (i = 0; i < pEAS->numSamples; i++)
 {
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000042 , i);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000043 , pEAS->pSampleLen[i]);
        EAS_ReportEx(_EAS_SEVERITY_NOFILTER, 0x19299ed4, 0x00000044 , pEAS->ppSamples[i]);
 }

}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: gpc_Glin(Pixel *out, const Pixel *in, const Background *back)
{
 (void)back;

 if (in->r == in->g && in->g == in->b)
      out->r = out->g = out->b = ilinear_g22(in->g);

 else
      out->r = out->g = out->b = u16d(65535 *
 YfromRGB(g22_to_d[in->r], g22_to_d[in->g], g22_to_d[in->b]));

   out->a = 65535;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int GetFreeFrameBuffer(size_t min_size, vpx_codec_frame_buffer_t *fb) {
    EXPECT_TRUE(fb != NULL);
 const int idx = FindFreeBufferIndex();
 if (idx == num_buffers_)
 return -1;


     if (ext_fb_list_[idx].size < min_size) {
       delete [] ext_fb_list_[idx].data;
       ext_fb_list_[idx].data = new uint8_t[min_size];
       ext_fb_list_[idx].size = min_size;
     }
 
 SetFrameBuffer(idx, fb);
 return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void usage()
{
  fprintf (stderr, "PNM2PNG\n");
  fprintf (stderr, "   by Willem van Schaik, 1999\n");
#ifdef __TURBOC__
  fprintf (stderr, "   for Turbo-C and Borland-C compilers\n");
#else
  fprintf (stderr, "   for Linux (and Unix) compilers\n");
#endif
  fprintf (stderr, "Usage:  pnm2png [options] <file>.<pnm> [<file>.png]\n");

   fprintf (stderr, "   or:  ... | pnm2png [options]\n");
   fprintf (stderr, "Options:\n");
   fprintf (stderr, "   -i[nterlace]   write png-file with interlacing on\n");
  fprintf (stderr, "   -a[lpha] <file>.pgm read PNG alpha channel as pgm-file\n");
   fprintf (stderr, "   -h | -?  print this help-information\n");
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: ssize_t NuPlayer::GenericSource::getSelectedTrack(media_track_type type) const {
    sp<AMessage> msg = new AMessage(kWhatGetSelectedTrack, this);
    msg->setInt32("type", type);

    sp<AMessage> response;
 int32_t index;
 status_t err = msg->postAndAwaitResponse(&response);
 if (err == OK && response != NULL) {
        CHECK(response->findInt32("index", &index));
 return index;
 } else {
 return -1;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ProCamera2Client::ProCamera2Client(const sp<CameraService>& cameraService,
 const sp<IProCameraCallbacks>& remoteCallback,
 const String16& clientPackageName,
 int cameraId,
 int cameraFacing,
 int clientPid,
 uid_t clientUid,
 int servicePid) :
 Camera2ClientBase(cameraService, remoteCallback, clientPackageName,
                cameraId, cameraFacing, clientPid, clientUid, servicePid)
{
    ATRACE_CALL();
    ALOGI("ProCamera %d: Opened", cameraId);

    mExclusiveLock = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_get_frame_dimensions(iv_obj_t *dec_hdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 ih264d_ctl_get_frame_dimensions_ip_t *ps_ip;
 ih264d_ctl_get_frame_dimensions_op_t *ps_op;
 dec_struct_t *ps_dec = dec_hdl->pv_codec_handle;
    UWORD32 disp_wd, disp_ht, buffer_wd, buffer_ht, x_offset, y_offset;

    ps_ip = (ih264d_ctl_get_frame_dimensions_ip_t *)pv_api_ip;

    ps_op = (ih264d_ctl_get_frame_dimensions_op_t *)pv_api_op;
    UNUSED(ps_ip);
 if((NULL != ps_dec->ps_cur_sps) && (1 == (ps_dec->ps_cur_sps->u1_is_valid)))
 {
        disp_wd = ps_dec->u2_disp_width;
        disp_ht = ps_dec->u2_disp_height;

 if(0 == ps_dec->u4_share_disp_buf)
 {
            buffer_wd = disp_wd;
            buffer_ht = disp_ht;
 }
 else
 {
            buffer_wd = ps_dec->u2_frm_wd_y;
            buffer_ht = ps_dec->u2_frm_ht_y;
 }
 }
 else
 {
        disp_wd = 0;
        disp_ht = 0;

 if(0 == ps_dec->u4_share_disp_buf)
 {
            buffer_wd = disp_wd;
            buffer_ht = disp_ht;
 }
 else
 {
            buffer_wd = ALIGN16(disp_wd) + (PAD_LEN_Y_H << 1);
            buffer_ht = ALIGN16(disp_ht) + (PAD_LEN_Y_V << 2);
 }
 }
 if(ps_dec->u4_app_disp_width > buffer_wd)
        buffer_wd = ps_dec->u4_app_disp_width;

 if(0 == ps_dec->u4_share_disp_buf)
 {
        x_offset = 0;
        y_offset = 0;
 }
 else
 {
        y_offset = (PAD_LEN_Y_V << 1);
        x_offset = PAD_LEN_Y_H;

 if((NULL != ps_dec->ps_sps) && (1 == (ps_dec->ps_sps->u1_is_valid))
 && (0 != ps_dec->u2_crop_offset_y))
 {
            y_offset += ps_dec->u2_crop_offset_y / ps_dec->u2_frm_wd_y;
            x_offset += ps_dec->u2_crop_offset_y % ps_dec->u2_frm_wd_y;
 }
 }

    ps_op->u4_disp_wd[0] = disp_wd;
    ps_op->u4_disp_ht[0] = disp_ht;
    ps_op->u4_buffer_wd[0] = buffer_wd;
    ps_op->u4_buffer_ht[0] = buffer_ht;
    ps_op->u4_x_offset[0] = x_offset;
    ps_op->u4_y_offset[0] = y_offset;

    ps_op->u4_disp_wd[1] = ps_op->u4_disp_wd[2] = ((ps_op->u4_disp_wd[0] + 1)
 >> 1);
    ps_op->u4_disp_ht[1] = ps_op->u4_disp_ht[2] = ((ps_op->u4_disp_ht[0] + 1)
 >> 1);
    ps_op->u4_buffer_wd[1] = ps_op->u4_buffer_wd[2] = (ps_op->u4_buffer_wd[0]
 >> 1);
    ps_op->u4_buffer_ht[1] = ps_op->u4_buffer_ht[2] = (ps_op->u4_buffer_ht[0]
 >> 1);
    ps_op->u4_x_offset[1] = ps_op->u4_x_offset[2] =
 (ps_op->u4_x_offset[0] >> 1);
    ps_op->u4_y_offset[1] = ps_op->u4_y_offset[2] =
 (ps_op->u4_y_offset[0] >> 1);

 if((ps_dec->u1_chroma_format == IV_YUV_420SP_UV)
 || (ps_dec->u1_chroma_format == IV_YUV_420SP_VU))
 {
        ps_op->u4_disp_wd[2] = 0;
        ps_op->u4_disp_ht[2] = 0;
        ps_op->u4_buffer_wd[2] = 0;
        ps_op->u4_buffer_ht[2] = 0;
        ps_op->u4_x_offset[2] = 0;
        ps_op->u4_y_offset[2] = 0;

        ps_op->u4_disp_wd[1] <<= 1;
        ps_op->u4_buffer_wd[1] <<= 1;
        ps_op->u4_x_offset[1] <<= 1;
 }

 return IV_SUCCESS;

}

Labels: No
----------------lora model----------------
Response: No.</s>


Instruction: 
Input:  int getId() {
 return mId;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_av_init(int service_id) {
 if (btif_av_cb.sm_handle == NULL) {
    alarm_free(av_open_on_rc_timer);
    av_open_on_rc_timer = alarm_new("btif_av.av_open_on_rc_timer");

 switch (service_id) {
 case BTA_A2DP_SOURCE_SERVICE_ID:
 if (!btif_a2dp_source_startup())
 return BT_STATUS_FAIL; // Already running
 break;
 case BTA_A2DP_SINK_SERVICE_ID:
 if (!btif_a2dp_sink_startup())
 return BT_STATUS_FAIL; // Already running
 break;
 default:
 break;
 }

    btif_enable_service(service_id);

 /* Also initialize the AV state machine */
    btif_av_cb.sm_handle = btif_sm_init(
 (const btif_sm_handler_t*)btif_av_state_handlers, BTIF_AV_STATE_IDLE);
 }

 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Virtualizer_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int status = 0;
 int16_t strength;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param){
 case VIRTUALIZER_PARAM_STRENGTH:
            strength = *(int16_t *)pValue;
 VirtualizerSetStrength(pContext, (int32_t)strength);
 break;
 default:
            ALOGV("\tLVM_ERROR : Virtualizer_setParameter() invalid param %d", param);
 break;
 }

 return status;
} /* end Virtualizer_setParameter */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:     FLAC__uint64 getTotalSamples() const {
 return mStreamInfo.total_samples;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: EAS_RESULT DLSParser (EAS_HW_DATA_HANDLE hwInstData, EAS_FILE_HANDLE fileHandle, EAS_I32 offset, EAS_DLSLIB_HANDLE *ppDLS)
{
    EAS_RESULT result;
    SDLS_SYNTHESIZER_DATA dls;
    EAS_U32 temp;
    EAS_I32 pos;
    EAS_I32 chunkPos;
    EAS_I32 size;
    EAS_I32 instSize;
    EAS_I32 rgnPoolSize;
    EAS_I32 artPoolSize;
    EAS_I32 waveLenSize;
    EAS_I32 endDLS;
    EAS_I32 wvplPos;
    EAS_I32 wvplSize;
    EAS_I32 linsPos;
    EAS_I32 linsSize;
    EAS_I32 ptblPos;
    EAS_I32 ptblSize;
 void *p;

 /* zero counts and pointers */
    EAS_HWMemSet(&dls, 0, sizeof(dls));

 /* save file handle and hwInstData to save copying pointers around */
    dls.hwInstData = hwInstData;
    dls.fileHandle = fileHandle;

 /* NULL return value in case of error */
 *ppDLS = NULL;

 /* seek to start of DLS and read in RIFF tag and set processor endian flag */
 if ((result = EAS_HWFileSeek(dls.hwInstData, dls.fileHandle, offset)) != EAS_SUCCESS)
 return result;
 if ((result = EAS_HWReadFile(dls.hwInstData, dls.fileHandle, &temp, sizeof(temp), &size)) != EAS_SUCCESS)
 return result;

 /* check for processor endian-ness */
    dls.bigEndian = (temp == CHUNK_RIFF);

 /* first chunk should be DLS */
    pos = offset;
 if ((result = NextChunk(&dls, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;
 if (temp != CHUNK_DLS)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "Expected DLS chunk, got %08lx\n", temp); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* no instrument or wavepool chunks */
    linsSize = wvplSize = ptblSize = linsPos = wvplPos = ptblPos = 0;

 /* scan the chunks in the DLS list */
    endDLS = offset + size;
    pos = offset + 12;
 while (pos < endDLS)
 {
        chunkPos = pos;

 /* get the next chunk type */
 if ((result = NextChunk(&dls, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 /* parse useful chunks */
 switch (temp)
 {
 case CHUNK_CDL:
 if ((result = Parse_cdl(&dls, size, &temp)) != EAS_SUCCESS)
 return result;
 if (!temp)
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 break;

 case CHUNK_LINS:
                linsPos = chunkPos + 12;
                linsSize = size - 4;
 break;

 case CHUNK_WVPL:
                wvplPos = chunkPos + 12;
                wvplSize = size - 4;
 break;

 case CHUNK_PTBL:
                ptblPos = chunkPos + 8;
                ptblSize = size - 4;
 break;

 default:
 break;
 }
 }

 /* must have a lins chunk */
 if (linsSize == 0)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "No lins chunk found"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* must have a wvpl chunk */
 if (wvplSize == 0)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "No wvpl chunk found"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* must have a ptbl chunk */
 if ((ptblSize == 0) || (ptblSize > DLS_MAX_WAVE_COUNT * sizeof(POOLCUE) + sizeof(POOLTABLE)))
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "No ptbl chunk found"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* pre-parse the wave pool chunk */
 if ((result = Parse_ptbl(&dls, ptblPos, wvplPos, wvplSize)) != EAS_SUCCESS)
 return result;

 /* limit check  */
 if ((dls.waveCount == 0) || (dls.waveCount > DLS_MAX_WAVE_COUNT))
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS file contains invalid #waves [%u]\n", dls.waveCount); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* allocate memory for wsmp data */
    dls.wsmpData = EAS_HWMalloc(dls.hwInstData, (EAS_I32) (sizeof(S_WSMP_DATA) * dls.waveCount));
 if (dls.wsmpData == NULL)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "EAS_HWMalloc for wsmp data failed\n"); */ }
 return EAS_ERROR_MALLOC_FAILED;
 }
    EAS_HWMemSet(dls.wsmpData, 0, (EAS_I32) (sizeof(S_WSMP_DATA) * dls.waveCount));

 /* pre-parse the lins chunk */
    result = Parse_lins(&dls, linsPos, linsSize);
 if (result == EAS_SUCCESS)
 {

 /* limit check  */
 if ((dls.regionCount == 0) || (dls.regionCount > DLS_MAX_REGION_COUNT))
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS file contains invalid #regions [%u]\n", dls.regionCount); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* limit check  */
 if ((dls.artCount == 0) || (dls.artCount > DLS_MAX_ART_COUNT))
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS file contains invalid #articulations [%u]\n", dls.regionCount); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* limit check  */
 if ((dls.instCount == 0) || (dls.instCount > DLS_MAX_INST_COUNT))
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS file contains invalid #instruments [%u]\n", dls.instCount); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* Allocate memory for the converted DLS data */
 /* calculate size of instrument data */
        instSize = (EAS_I32) (sizeof(S_PROGRAM) * dls.instCount);

 /* calculate size of region pool */
        rgnPoolSize = (EAS_I32) (sizeof(S_DLS_REGION) * dls.regionCount);

 /* calculate size of articulation pool, add one for default articulation */
        dls.artCount++;
        artPoolSize = (EAS_I32) (sizeof(S_DLS_ARTICULATION) * dls.artCount);

 /* calculate size of wave length and offset arrays */
        waveLenSize = (EAS_I32) (dls.waveCount * sizeof(EAS_U32));

 /* calculate final memory size */
        size = (EAS_I32) sizeof(S_EAS) + instSize + rgnPoolSize + artPoolSize + (2 * waveLenSize) + (EAS_I32) dls.wavePoolSize;
 if (size <= 0) {
 return EAS_ERROR_FILE_FORMAT;
 }

 /* allocate the main EAS chunk */
        dls.pDLS = EAS_HWMalloc(dls.hwInstData, size);
 if (dls.pDLS == NULL)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "EAS_HWMalloc failed for DLS memory allocation size %ld\n", size); */ }
 return EAS_ERROR_MALLOC_FAILED;
 }
        EAS_HWMemSet(dls.pDLS, 0, size);
        dls.pDLS->refCount = 1;
        p = PtrOfs(dls.pDLS, sizeof(S_EAS));

 /* setup pointer to programs */
        dls.pDLS->numDLSPrograms = (EAS_U16) dls.instCount;
        dls.pDLS->pDLSPrograms = p;
        p = PtrOfs(p, instSize);

 /* setup pointer to regions */
        dls.pDLS->pDLSRegions = p;
        dls.pDLS->numDLSRegions = (EAS_U16) dls.regionCount;
        p = PtrOfs(p, rgnPoolSize);

 /* setup pointer to articulations */
        dls.pDLS->numDLSArticulations = (EAS_U16) dls.artCount;
        dls.pDLS->pDLSArticulations = p;
        p = PtrOfs(p, artPoolSize);

 /* setup pointer to wave length table */
        dls.pDLS->numDLSSamples = (EAS_U16) dls.waveCount;
        dls.pDLS->pDLSSampleLen = p;
        p = PtrOfs(p, waveLenSize);

 /* setup pointer to wave offsets table */
        dls.pDLS->pDLSSampleOffsets = p;
        p = PtrOfs(p, waveLenSize);

 /* setup pointer to wave pool */
        dls.pDLS->pDLSSamples = p;

 /* clear filter flag */
        dls.filterUsed = EAS_FALSE;

 /* parse the wave pool and load samples */
        result = Parse_ptbl(&dls, ptblPos, wvplPos, wvplSize);

     }
 
     /* create the default articulation */
    Convert_art(&dls, &defaultArt, 0);
    dls.artCount = 1;
 
     /* parse the lins chunk and load instruments */
     dls.regionCount = dls.instCount = 0;
 if (result == EAS_SUCCESS)
        result = Parse_lins(&dls, linsPos, linsSize);

 /* clean up any temporary objects that were allocated */
 if (dls.wsmpData)
        EAS_HWFree(dls.hwInstData, dls.wsmpData);

 /* if successful, return a pointer to the EAS collection */
 if (result == EAS_SUCCESS)
 {
 *ppDLS = dls.pDLS;
#ifdef _DEBUG_DLS
 DumpDLS(dls.pDLS);
#endif
 }

 /* something went wrong, deallocate the EAS collection */
 else
 DLSCleanup(dls.hwInstData, dls.pDLS);

 return result;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  int btsock_thread_exit(int h)
 {
 if(h < 0 || h >= MAX_THREAD)
 {
        APPL_TRACE_ERROR("invalid bt thread handle:%d", h);
 return FALSE;
 }
 if(ts[h].cmd_fdw == -1)
 {
        APPL_TRACE_ERROR("cmd socket is not created");

         return FALSE;
     }
     sock_cmd_t cmd = {CMD_EXIT, 0, 0, 0, 0};
    if(send(ts[h].cmd_fdw, &cmd, sizeof(cmd), 0) == sizeof(cmd))
     {
         pthread_join(ts[h].thread_id, 0);
         pthread_mutex_lock(&thread_slot_lock);
        free_thread_slot(h);
        pthread_mutex_unlock(&thread_slot_lock);
 return TRUE;
 }
 return FALSE;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void BnDrm::writeVector(Parcel *reply, Vector<uint8_t> const &vector) const {
    reply->writeInt32(vector.size());
    reply->write(vector.array(), vector.size());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void kernel_shutdown_prepare(enum system_states state)
{
	blocking_notifier_call_chain(&reboot_notifier_list,
 (state == SYSTEM_HALT)?SYS_HALT:SYS_POWER_OFF, NULL);
	system_state = state;
	usermodehelper_disable();
	device_shutdown();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Reverb_getDescriptor(effect_handle_t   self,
 effect_descriptor_t *pDescriptor)
{
    android::ReverbContext * pContext = (android::ReverbContext *)self;
 const effect_descriptor_t *desc;

 if (pContext == NULL || pDescriptor == NULL) {
        ALOGV("Reverb_getDescriptor() invalid param");
 return -EINVAL;
 }

 if (pContext->auxiliary) {
 if (pContext->preset) {
            desc = &android::gAuxPresetReverbDescriptor;
 } else {
            desc = &android::gAuxEnvReverbDescriptor;
 }
 } else {
 if (pContext->preset) {
            desc = &android::gInsertPresetReverbDescriptor;
 } else {
            desc = &android::gInsertEnvReverbDescriptor;
 }
 }

 *pDescriptor = *desc;

 return 0;
} /* end Reverb_getDescriptor */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  OMX_ERRORTYPE  omx_vdec::fill_this_buffer(OMX_IN OMX_HANDLETYPE  hComp,
         OMX_IN OMX_BUFFERHEADERTYPE* buffer)
 {
     unsigned nPortIndex = 0;
     if (dynamic_buf_mode) {
         private_handle_t *handle = NULL;
 struct VideoDecoderOutputMetaData *meta;
 unsigned int nPortIndex = 0;

 if (!buffer || !buffer->pBuffer) {
            DEBUG_PRINT_ERROR("%s: invalid params: %p", __FUNCTION__, buffer);
 return OMX_ErrorBadParameter;
 }

        meta = (struct VideoDecoderOutputMetaData *)buffer->pBuffer;
        handle = (private_handle_t *)meta->pHandle;
        DEBUG_PRINT_LOW("FTB: metabuf: %p buftype: %d bufhndl: %p ", meta, meta->eType, meta->pHandle);

 if (!handle) {
            DEBUG_PRINT_ERROR("FTB: Error: IL client passed an invalid buf handle - %p", handle);
 return OMX_ErrorBadParameter;
 }

        nPortIndex = buffer-((OMX_BUFFERHEADERTYPE *)client_buffers.get_il_buf_hdr());
        drv_ctx.ptr_outputbuffer[nPortIndex].pmem_fd = handle->fd;
        drv_ctx.ptr_outputbuffer[nPortIndex].bufferaddr = (OMX_U8*) buffer;

        native_buffer[nPortIndex].privatehandle = handle;
        native_buffer[nPortIndex].nativehandle = handle;

        buffer->nFilledLen = 0;

         buffer->nAllocLen = handle->size;
     }
 
    if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("FTB in Invalid State");
        return OMX_ErrorInvalidState;
    }
    if (!m_out_bEnabled) {
        DEBUG_PRINT_ERROR("ERROR:FTB incorrect state operation, output port is disabled.");
        return OMX_ErrorIncorrectStateOperation;
    }
     nPortIndex = buffer - client_buffers.get_il_buf_hdr();
     if (buffer == NULL ||
             (nPortIndex >= drv_ctx.op_buf.actualcount)) {
        DEBUG_PRINT_ERROR("FTB: ERROR: invalid buffer index, nPortIndex %u bufCount %u",
            nPortIndex, drv_ctx.op_buf.actualcount);
 return OMX_ErrorBadParameter;
 }

 if (buffer->nOutputPortIndex != OMX_CORE_OUTPUT_PORT_INDEX) {
        DEBUG_PRINT_ERROR("ERROR:FTB invalid port in header %u", (unsigned int)buffer->nOutputPortIndex);
 return OMX_ErrorBadPortIndex;
 }

    DEBUG_PRINT_LOW("[FTB] bufhdr = %p, bufhdr->pBuffer = %p", buffer, buffer->pBuffer);
    post_event((unsigned long) hComp, (unsigned long)buffer, m_fill_output_msg);
 return OMX_ErrorNone;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void OMXCodec::setVideoInputFormat(
 const char *mime, const sp<MetaData>& meta) {

 int32_t width, height, frameRate, bitRate, stride, sliceHeight;
 bool success = meta->findInt32(kKeyWidth, &width);
    success = success && meta->findInt32(kKeyHeight, &height);
    success = success && meta->findInt32(kKeyFrameRate, &frameRate);
    success = success && meta->findInt32(kKeyBitRate, &bitRate);
    success = success && meta->findInt32(kKeyStride, &stride);
    success = success && meta->findInt32(kKeySliceHeight, &sliceHeight);
    CHECK(success);
    CHECK(stride != 0);

    OMX_VIDEO_CODINGTYPE compressionFormat = OMX_VIDEO_CodingUnused;
 if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_AVC, mime)) {
        compressionFormat = OMX_VIDEO_CodingAVC;
 } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_HEVC, mime)) {
        compressionFormat = OMX_VIDEO_CodingHEVC;
 } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_MPEG4, mime)) {
        compressionFormat = OMX_VIDEO_CodingMPEG4;
 } else if (!strcasecmp(MEDIA_MIMETYPE_VIDEO_H263, mime)) {
        compressionFormat = OMX_VIDEO_CodingH263;
 } else {
        ALOGE("Not a supported video mime type: %s", mime);
        CHECK(!"Should not be here. Not a supported video mime type.");
 }

    OMX_COLOR_FORMATTYPE colorFormat;
    CHECK_EQ((status_t)OK, findTargetColorFormat(meta, &colorFormat));

 status_t err;
    OMX_PARAM_PORTDEFINITIONTYPE def;
    OMX_VIDEO_PORTDEFINITIONTYPE *video_def = &def.format.video;

    CHECK_EQ(setVideoPortFormatType(
            kPortIndexInput, OMX_VIDEO_CodingUnused,
            colorFormat), (status_t)OK);

 InitOMXParams(&def);
    def.nPortIndex = kPortIndexInput;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
    CHECK_EQ(err, (status_t)OK);

    def.nBufferSize = getFrameSize(colorFormat,
            stride > 0? stride: -stride, sliceHeight);

    CHECK_EQ((int)def.eDomain, (int)OMX_PortDomainVideo);

    video_def->nFrameWidth = width;
    video_def->nFrameHeight = height;
    video_def->nStride = stride;
    video_def->nSliceHeight = sliceHeight;
    video_def->xFramerate = (frameRate << 16); // Q16 format
    video_def->eCompressionFormat = OMX_VIDEO_CodingUnused;
    video_def->eColorFormat = colorFormat;

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
    CHECK_EQ(err, (status_t)OK);

    CHECK_EQ(setVideoPortFormatType(
            kPortIndexOutput, compressionFormat, OMX_COLOR_FormatUnused),
 (status_t)OK);
 InitOMXParams(&def);
    def.nPortIndex = kPortIndexOutput;

    err = mOMX->getParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));

    CHECK_EQ(err, (status_t)OK);
    CHECK_EQ((int)def.eDomain, (int)OMX_PortDomainVideo);

    video_def->nFrameWidth = width;
    video_def->nFrameHeight = height;
    video_def->xFramerate = 0; // No need for output port
    video_def->nBitrate = bitRate; // Q16 format
    video_def->eCompressionFormat = compressionFormat;
    video_def->eColorFormat = OMX_COLOR_FormatUnused;
 if (mQuirks & kRequiresLargerEncoderOutputBuffer) {
        def.nBufferSize = ((def.nBufferSize * 3) >> 1);
 }

    err = mOMX->setParameter(
            mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
    CHECK_EQ(err, (status_t)OK);

 switch (compressionFormat) {
 case OMX_VIDEO_CodingMPEG4:
 {
            CHECK_EQ(setupMPEG4EncoderParameters(meta), (status_t)OK);
 break;
 }

 case OMX_VIDEO_CodingH263:
            CHECK_EQ(setupH263EncoderParameters(meta), (status_t)OK);
 break;

 case OMX_VIDEO_CodingAVC:
 {
            CHECK_EQ(setupAVCEncoderParameters(meta), (status_t)OK);
 break;
 }

 default:
            CHECK(!"Support for this compressionFormat to be implemented.");
 break;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: omx_vdec::perf_control::perf_control ()
{
    m_perf_lib = NULL;
    m_perf_handle = -1;
    m_perf_lock_acquire = NULL;
    m_perf_lock_release = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t FLACSource::read(
 MediaBuffer **outBuffer, const ReadOptions *options)
{
 MediaBuffer *buffer;
 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if ((NULL != options) && options->getSeekTo(&seekTimeUs, &mode)) {
        FLAC__uint64 sample;
 if (seekTimeUs <= 0LL) {
            sample = 0LL;
 } else {
            sample = (seekTimeUs * mParser->getSampleRate()) / 1000000LL;
 if (sample >= mParser->getTotalSamples()) {
                sample = mParser->getTotalSamples();
 }
 }
        buffer = mParser->readBuffer(sample);
 } else {
        buffer = mParser->readBuffer();
 }
 *outBuffer = buffer;
 return buffer != NULL ? (status_t) OK : (status_t) ERROR_END_OF_STREAM;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: dpbOutPicture_t* h264bsdDpbOutputPicture(dpbStorage_t *dpb)
{

/* Variables */

/* Code */

    ASSERT(dpb);

 if (dpb->outIndex < dpb->numOut)
 return(dpb->outBuf + dpb->outIndex++);
 else
 return(NULL);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool getCoverageFormat12(vector<uint32_t>& coverage, const uint8_t* data, size_t size) {
 const size_t kNGroupsOffset = 12;
 const size_t kFirstGroupOffset = 16;

     const size_t kGroupSize = 12;
     const size_t kStartCharCodeOffset = 0;
     const size_t kEndCharCodeOffset = 4;
     if (kFirstGroupOffset > size) {
         return false;
     }
     uint32_t nGroups = readU32(data, kNGroupsOffset);
    if (kFirstGroupOffset + nGroups * kGroupSize > size) {
         return false;
     }
     for (uint32_t i = 0; i < nGroups; i++) {
 uint32_t groupOffset = kFirstGroupOffset + i * kGroupSize;
 uint32_t start = readU32(data, groupOffset + kStartCharCodeOffset);
 uint32_t end = readU32(data, groupOffset + kEndCharCodeOffset);
        addRange(coverage, start, end + 1); // file is inclusive, vector is exclusive
 }
 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_init_video_state(dec_state_t *ps_dec, e_video_type_t e_video_type)
{
 /*-----------------------------------------------------------------------*/
 /* Bit Stream  that conforms to MPEG-1 <ISO/IEC 11172-2> standard        */
 /*-----------------------------------------------------------------------*/
 if(e_video_type == MPEG_1_VIDEO)
 {
        ps_dec->u2_is_mpeg2 = 0;

 /*-------------------------------------------------------------------*/
 /* force MPEG-1 parameters for proper decoder behavior               */
 /* see ISO/IEC 13818-2 section D.9.14                                */
 /*-------------------------------------------------------------------*/
        ps_dec->u2_progressive_sequence         = 1;
        ps_dec->u2_intra_dc_precision           = 0;
        ps_dec->u2_picture_structure            = FRAME_PICTURE;
        ps_dec->u2_frame_pred_frame_dct         = 1;
        ps_dec->u2_concealment_motion_vectors   = 0;
        ps_dec->u2_q_scale_type                 = 0;
        ps_dec->u2_intra_vlc_format             = 0;
        ps_dec->u2_alternate_scan               = 0;
        ps_dec->u2_repeat_first_field           = 0;

         ps_dec->u2_progressive_frame            = 1;
         ps_dec->u2_frame_rate_extension_n       = 0;
         ps_dec->u2_frame_rate_extension_d       = 0;
 
         ps_dec->pf_vld_inv_quant                  = impeg2d_vld_inv_quant_mpeg1;
         /*-------------------------------------------------------------------*/
 /* Setting of parameters other than those mentioned in MPEG2 standard*/
 /* but used in decoding process.                                     */
 /*-------------------------------------------------------------------*/
 }
 /*-----------------------------------------------------------------------*/
 /* Bit Stream  that conforms to MPEG-2                                   */
 /*-----------------------------------------------------------------------*/
 else
 {
        ps_dec->u2_is_mpeg2                  = 1;
        ps_dec->u2_full_pel_forw_vector   = 0;
        ps_dec->u2_forw_f_code            = 7;
        ps_dec->u2_full_pel_back_vector   = 0;
        ps_dec->u2_back_f_code            = 7;
        ps_dec->pf_vld_inv_quant       = impeg2d_vld_inv_quant_mpeg2;


 }


    impeg2d_init_function_ptr(ps_dec);

 /* Set the frame Width and frame Height */
    ps_dec->u2_frame_height        = ALIGN16(ps_dec->u2_vertical_size);
    ps_dec->u2_frame_width         = ALIGN16(ps_dec->u2_horizontal_size);
    ps_dec->u2_num_horiz_mb         = (ps_dec->u2_horizontal_size + 15) >> 4;
 if (ps_dec->u2_frame_height > ps_dec->u2_create_max_height || ps_dec->u2_frame_width > ps_dec->u2_create_max_width)
 {
 return IMPEG2D_PIC_SIZE_NOT_SUPPORTED;
 }

    ps_dec->u2_num_flds_decoded = 0;

 /* Calculate the frame period */
 {
        UWORD32 numer;
        UWORD32 denom;
        numer = (UWORD32)gau2_impeg2_frm_rate_code[ps_dec->u2_frame_rate_code][1] *
 (UWORD32)(ps_dec->u2_frame_rate_extension_d + 1);

        denom = (UWORD32)gau2_impeg2_frm_rate_code[ps_dec->u2_frame_rate_code][0] *
 (UWORD32)(ps_dec->u2_frame_rate_extension_n + 1);
        ps_dec->u2_framePeriod = (numer * 1000 * 100) / denom;
 }


 if(VERTICAL_SCAN == ps_dec->u2_alternate_scan)
 {
    ps_dec->pu1_inv_scan_matrix = (UWORD8 *)gau1_impeg2_inv_scan_vertical;
 }
 else
 {
    ps_dec->pu1_inv_scan_matrix = (UWORD8 *)gau1_impeg2_inv_scan_zig_zag;
 }
 return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXCodec::fillOutputBuffer(IOMX::buffer_id buffer) {
 Vector<BufferInfo> *buffers = &mPortBuffers[kPortIndexOutput];
 for (size_t i = 0; i < buffers->size(); ++i) {
 if ((*buffers)[i].mBuffer == buffer) {
            fillOutputBuffer(&buffers->editItemAt(i));
 return;
 }
 }

    CHECK(!"should not be here.");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMX::sendCommand(
        node_id node, OMX_COMMANDTYPE cmd, OMX_S32 param) {
 return findInstance(node)->sendCommand(cmd, param);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint32_t out_get_latency(const struct audio_stream_out *stream)
{
 int latency_us;

 struct a2dp_stream_out *out = (struct a2dp_stream_out *)stream;

    FNLOG();

    latency_us = ((out->common.buffer_sz * 1000 ) /
                    audio_stream_out_frame_size(&out->stream) /
                    out->common.cfg.rate) * 1000;


 return (latency_us / 1000) + 200;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static size_t get_input_buffer_size(uint32_t sample_rate,
 audio_format_t format,
 int channel_count,
 usecase_type_t usecase_type,
 audio_devices_t devices)
{
 size_t size = 0;
 struct pcm_device_profile *pcm_profile;

 if (check_input_parameters(sample_rate, format, channel_count) != 0)
 return 0;

    pcm_profile = get_pcm_device(usecase_type, devices);
 if (pcm_profile == NULL)
 return 0;

 /*
     * take resampling into account and return the closest majoring
     * multiple of 16 frames, as audioflinger expects audio buffers to
     * be a multiple of 16 frames
     */
    size = (pcm_profile->config.period_size * sample_rate) / pcm_profile->config.rate;
    size = ((size + 15) / 16) * 16;

 return (size * channel_count * audio_bytes_per_sample(format));

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t setConfig(
            node_id node, OMX_INDEXTYPE index,
 const void *params, size_t size) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(index);
        data.writeInt64(size);
        data.write(params, size);
        remote()->transact(SET_CONFIG, data, &reply);

 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gpc_Gprq(Pixel *out, const Pixel *in, const Background *back)
{
 (void)back;

 if (in->r == in->g && in->g == in->b)
      out->r = out->g = out->b = ilineara_g22(in->g, in->a);

 else
      out->r = out->g = out->b = u16d(in->a * 257 *
 YfromRGB(g22_to_d[in->r], g22_to_d[in->g], g22_to_d[in->b]));

   out->a = 65535;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: decode_rfc3397(char *out, ssize_t len, int pl, const uint8_t *p)
{
 const uint8_t *r, *q = p;
 int count = 0, l, hops;
 uint8_t ltype;

 while (q - p < pl) {
		r = NULL;
		hops = 0;
 /* We check we are inside our length again incase
		 * the data is NOT terminated correctly. */
 while ((l = *q++) && q - p < pl) {
			ltype = l & 0xc0;
 if (ltype == 0x80 || ltype == 0x40)
 return 0;
 else if (ltype == 0xc0) { /* pointer */
				l = (l & 0x3f) << 8;
				l |= *q++;
 /* save source of first jump. */
 if (!r)
					r = q;
				hops++;
 if (hops > 255)
 return 0;
				q = p + l;
 if (q - p >= pl)
 return 0;
 } else {
 /* straightforward name segment, add with '.' */
				count += l + 1;
 if (out) {
 if ((ssize_t)l + 1 > len) {
						errno = ENOBUFS;
 return -1;
 }
					memcpy(out, q, l);
					out += l;
 *out++ = '.';
					len -= l;
					len--;
 }
				q += l;
 }
 }
 /* change last dot to space */
 if (out)
 *(out - 1) = ' ';
 if (r)
			q = r;
 }

 /* change last space to zero terminator */
 if (out)
 *(out - 1) = 0;

 return count; 
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Cluster::GetLastTime() const
{
    const BlockEntry* pEntry;
    const long status = GetLast(pEntry);
    if (status < 0)  //error
        return status;
    if (pEntry == NULL)  //empty cluster
        return GetTime();
    const Block* const pBlock = pEntry->GetBlock();
    assert(pBlock);
    return pBlock->GetTime(this);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int Effect_command(effect_handle_t  self,
 uint32_t            cmdCode,
 uint32_t            cmdSize,
 void *pCmdData,
 uint32_t *replySize,
 void *pReplyData){
 EffectContext * pContext = (EffectContext *) self;
 int retsize;


 if(pContext->EffectType == LVM_BASS_BOOST){
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){
 }
 if(pContext->EffectType == LVM_EQUALIZER){
 }
 if(pContext->EffectType == LVM_VOLUME){
 }

 if (pContext == NULL){
        ALOGV("\tLVM_ERROR : Effect_command ERROR pContext == NULL");
 return -EINVAL;
 }




 switch (cmdCode){
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)){
                ALOGV("\tLVM_ERROR, EFFECT_CMD_INIT: ERROR for effect type %d",
                        pContext->EffectType);
 return -EINVAL;
 }
 *(int *) pReplyData = 0;
 if(pContext->EffectType == LVM_BASS_BOOST){
                android::BassSetStrength(pContext, 0);
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){
                android::VirtualizerSetStrength(pContext, 0);
 }
 if(pContext->EffectType == LVM_EQUALIZER){
                android::EqualizerSetPreset(pContext, 0);
 }
 if(pContext->EffectType == LVM_VOLUME){
 *(int *) pReplyData = android::VolumeSetVolumeLevel(pContext, 0);
 }
 break;

 case EFFECT_CMD_SET_CONFIG:
 if (pCmdData    == NULL || cmdSize     != sizeof(effect_config_t) ||
                    pReplyData  == NULL || replySize == NULL || *replySize  != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_SET_CONFIG: ERROR");
 return -EINVAL;
 }
 *(int *) pReplyData = android::Effect_setConfig(pContext, (effect_config_t *) pCmdData);
 break;

 case EFFECT_CMD_GET_CONFIG:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(effect_config_t)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_GET_CONFIG: ERROR");
 return -EINVAL;
 }

            android::Effect_getConfig(pContext, (effect_config_t *)pReplyData);
 break;

 case EFFECT_CMD_RESET:
            android::Effect_setConfig(pContext, &pContext->config);
 break;

 case EFFECT_CMD_GET_PARAM:{

 
             effect_param_t *p = (effect_param_t *)pCmdData;
             if (pCmdData == NULL || cmdSize < sizeof(effect_param_t) ||
                     cmdSize < (sizeof(effect_param_t) + p->psize) ||
                     pReplyData == NULL || replySize == NULL ||
 *replySize < (sizeof(effect_param_t) + p->psize)) {
                ALOGV("\tLVM_ERROR : EFFECT_CMD_GET_PARAM: ERROR");
 return -EINVAL;
 }

            memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + p->psize);

            p = (effect_param_t *)pReplyData;

 int voffset = ((p->psize - 1) / sizeof(int32_t) + 1) * sizeof(int32_t);

 if(pContext->EffectType == LVM_BASS_BOOST){
                p->status = android::BassBoost_getParameter(pContext,
                                                            p->data,
 (size_t *)&p->vsize,
                                                            p->data + voffset);
 }

 if(pContext->EffectType == LVM_VIRTUALIZER){
                p->status = android::Virtualizer_getParameter(pContext,
 (void *)p->data,
 (size_t *)&p->vsize,
                                                              p->data + voffset);

 }
 if(pContext->EffectType == LVM_EQUALIZER){
                p->status = android::Equalizer_getParameter(pContext,
                                                            p->data,
 &p->vsize,
                                                            p->data + voffset);

 }
 if(pContext->EffectType == LVM_VOLUME){
                p->status = android::Volume_getParameter(pContext,
 (void *)p->data,
 (size_t *)&p->vsize,
                                                         p->data + voffset);

 }
 *replySize = sizeof(effect_param_t) + voffset + p->vsize;

 } break;
 case EFFECT_CMD_SET_PARAM:{
 if(pContext->EffectType == LVM_BASS_BOOST){

 if (pCmdData   == NULL ||
                        cmdSize    != (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int16_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : BassBoost_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 if (p->psize != sizeof(int32_t)){
                    ALOGV("\tLVM_ERROR : BassBoost_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR, psize is not sizeof(int32_t)");
 return -EINVAL;
 }


 *(int *)pReplyData = android::BassBoost_setParameter(pContext,
 (void *)p->data,
                                                                    p->data + p->psize);
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){

 if (pCmdData   == NULL ||
                        cmdSize    > (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int32_t)) ||
                        cmdSize    < (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int16_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Virtualizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 if (p->psize != sizeof(int32_t)){
                    ALOGV("\tLVM_ERROR : Virtualizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR, psize is not sizeof(int32_t)");
 return -EINVAL;
 }


 *(int *)pReplyData = android::Virtualizer_setParameter(pContext,
 (void *)p->data,
                                                                       p->data + p->psize);
 }
 if(pContext->EffectType == LVM_EQUALIZER){

 if (pCmdData == NULL || cmdSize < (sizeof(effect_param_t) + sizeof(int32_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Equalizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 *(int *)pReplyData = android::Equalizer_setParameter(pContext,
 (void *)p->data,
                                                                     p->data + p->psize);
 }
 if(pContext->EffectType == LVM_VOLUME){

 if (pCmdData   == NULL ||
                        cmdSize    < (sizeof(effect_param_t) + sizeof(int32_t)) ||
                        pReplyData == NULL || replySize == NULL ||
 *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Volume_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 *(int *)pReplyData = android::Volume_setParameter(pContext,
 (void *)p->data,
                                                                 p->data + p->psize);
 }
 } break;

 case EFFECT_CMD_ENABLE:
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_ENABLE start");
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_ENABLE: ERROR");
 return -EINVAL;
 }

 *(int *)pReplyData = android::Effect_setEnabled(pContext, LVM_TRUE);
 break;

 case EFFECT_CMD_DISABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_DISABLE: ERROR");
 return -EINVAL;
 }
 *(int *)pReplyData = android::Effect_setEnabled(pContext, LVM_FALSE);
 break;

 case EFFECT_CMD_SET_DEVICE:
 {
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_SET_DEVICE start");
 if (pCmdData   == NULL){
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_SET_DEVICE: ERROR");
 return -EINVAL;
 }

 uint32_t device = *(uint32_t *)pCmdData;

 if (pContext->EffectType == LVM_BASS_BOOST) {
 if((device == AUDIO_DEVICE_OUT_SPEAKER) ||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_SCO_CARKIT) ||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_SPEAKER)){
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is invalid for LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                    ALOGV("\tEFFECT_CMD_SET_DEVICE temporary disable LVM_BAS_BOOST");


 if (pContext->pBundledContext->bBassEnabled == LVM_TRUE) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE disable LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_disable(pContext);
 }
                    pContext->pBundledContext->bBassTempDisabled = LVM_TRUE;
 } else {
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is valid for LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);


 if (pContext->pBundledContext->bBassEnabled == LVM_TRUE) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE re-enable LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_enable(pContext);
 }
                    pContext->pBundledContext->bBassTempDisabled = LVM_FALSE;
 }
 }
 if (pContext->EffectType == LVM_VIRTUALIZER) {
 if((device == AUDIO_DEVICE_OUT_SPEAKER)||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_SCO_CARKIT)||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_SPEAKER)){
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is invalid for LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                    ALOGV("\tEFFECT_CMD_SET_DEVICE temporary disable LVM_VIRTUALIZER");


 if (pContext->pBundledContext->bVirtualizerEnabled == LVM_TRUE) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE disable LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_disable(pContext);
 }
                    pContext->pBundledContext->bVirtualizerTempDisabled = LVM_TRUE;
 } else {
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is valid for LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);


 if(pContext->pBundledContext->bVirtualizerEnabled == LVM_TRUE){
                        ALOGV("\tEFFECT_CMD_SET_DEVICE re-enable LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_enable(pContext);
 }
                    pContext->pBundledContext->bVirtualizerTempDisabled = LVM_FALSE;
 }
 }
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_SET_DEVICE end");
 break;
 }
 case EFFECT_CMD_SET_VOLUME:
 {
 uint32_t leftVolume, rightVolume;
 int16_t  leftdB, rightdB;
 int16_t  maxdB, pandB;
 int32_t  vol_ret[2] = {1<<24,1<<24}; // Apply no volume
 int      status = 0;
 LVM_ControlParams_t ActiveParams; /* Current control Parameters */
            LVM_ReturnStatus_en     LvmStatus=LVM_SUCCESS; /* Function call status */

 if(pReplyData == LVM_NULL){
 break;
 }

 if (pCmdData == NULL || cmdSize != 2 * sizeof(uint32_t) || pReplyData == NULL ||
                    replySize == NULL || *replySize < 2*sizeof(int32_t)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_SET_VOLUME: ERROR");
 return -EINVAL;
 }

            leftVolume  = ((*(uint32_t *)pCmdData));
            rightVolume = ((*((uint32_t *)pCmdData + 1)));

 if(leftVolume == 0x1000000){
                leftVolume -= 1;
 }
 if(rightVolume == 0x1000000){
                rightVolume -= 1;
 }

            leftdB  = android::LVC_Convert_VolToDb(leftVolume);
            rightdB = android::LVC_Convert_VolToDb(rightVolume);

            pandB = rightdB - leftdB;

            maxdB = leftdB;
 if(rightdB > maxdB){
                maxdB = rightdB;
 }

            memcpy(pReplyData, vol_ret, sizeof(int32_t)*2);
            android::VolumeSetVolumeLevel(pContext, (int16_t)(maxdB*100));

 /* Get the current settings */
 LvmStatus =LVM_GetControlParameters(pContext->pBundledContext->hInstance,&ActiveParams);
            LVM_ERROR_CHECK(LvmStatus, "LVM_GetControlParameters", "VolumeSetStereoPosition")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

 /* Volume parameters */
 ActiveParams.VC_Balance  = pandB;
            ALOGV("\t\tVolumeSetStereoPosition() (-96dB -> +96dB)-> %d\n", ActiveParams.VC_Balance );

 /* Activate the initial settings */
 LvmStatus =LVM_SetControlParameters(pContext->pBundledContext->hInstance,&ActiveParams);
            LVM_ERROR_CHECK(LvmStatus, "LVM_SetControlParameters", "VolumeSetStereoPosition")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;
 break;
 }
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;
 default:
 return -EINVAL;
 }

 return 0;
} /* end Effect_command */

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void NuPlayer::GenericSource::readBuffer(
        media_track_type trackType, int64_t seekTimeUs, int64_t *actualTimeUs, bool formatChange) {
 if (mStopRead) {
 return;
 }
 Track *track;
 size_t maxBuffers = 1;
 switch (trackType) {
 case MEDIA_TRACK_TYPE_VIDEO:
            track = &mVideoTrack;
 if (mIsWidevine) {
                maxBuffers = 2;
 } else {
                maxBuffers = 4;
 }
 break;
 case MEDIA_TRACK_TYPE_AUDIO:
            track = &mAudioTrack;
 if (mIsWidevine) {
                maxBuffers = 8;
 } else {
                maxBuffers = 64;
 }
 break;
 case MEDIA_TRACK_TYPE_SUBTITLE:
            track = &mSubtitleTrack;
 break;
 case MEDIA_TRACK_TYPE_TIMEDTEXT:
            track = &mTimedTextTrack;
 break;
 default:
            TRESPASS();
 }

 if (track->mSource == NULL) {
 return;
 }

 if (actualTimeUs) {
 *actualTimeUs = seekTimeUs;
 }

 MediaSource::ReadOptions options;

 bool seeking = false;

 if (seekTimeUs >= 0) {
        options.setSeekTo(seekTimeUs, MediaSource::ReadOptions::SEEK_PREVIOUS_SYNC);
        seeking = true;
 }

 if (mIsWidevine) {
        options.setNonBlocking();
 }

 for (size_t numBuffers = 0; numBuffers < maxBuffers; ) {
 MediaBuffer *mbuf;
 status_t err = track->mSource->read(&mbuf, &options);

        options.clearSeekTo();

 if (err == OK) {
 int64_t timeUs;
            CHECK(mbuf->meta_data()->findInt64(kKeyTime, &timeUs));
 if (trackType == MEDIA_TRACK_TYPE_AUDIO) {
                mAudioTimeUs = timeUs;
 } else if (trackType == MEDIA_TRACK_TYPE_VIDEO) {
                mVideoTimeUs = timeUs;
 }

            queueDiscontinuityIfNeeded(seeking, formatChange, trackType, track);

            sp<ABuffer> buffer = mediaBufferToABuffer(
                    mbuf, trackType, seekTimeUs, actualTimeUs);
            track->mPackets->queueAccessUnit(buffer);
            formatChange = false;
            seeking = false;
 ++numBuffers;
 } else if (err == WOULD_BLOCK) {
 break;
 } else if (err == INFO_FORMAT_CHANGED) {
#if 0
            track->mPackets->queueDiscontinuity(
 ATSParser::DISCONTINUITY_FORMATCHANGE,
                    NULL,
 false /* discard */);
#endif
 } else {
            queueDiscontinuityIfNeeded(seeking, formatChange, trackType, track);
            track->mPackets->signalEOS(err);
 break;
 }
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int get_vp9_one_less_byte_frame_buffer(void *user_priv, size_t min_size,
 vpx_codec_frame_buffer_t *fb) {
 ExternalFrameBufferList *const fb_list =
 reinterpret_cast<ExternalFrameBufferList*>(user_priv);
 return fb_list->GetFreeFrameBuffer(min_size - 1, fb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void setGraphicBuffer(const sp<GraphicBuffer> &graphicBuffer) {

         mGraphicBuffer = graphicBuffer;
     }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Camera2Client::lock() {
    ATRACE_CALL();
    ALOGV("%s: E", __FUNCTION__);
 Mutex::Autolock icl(mBinderSerializationLock);
    ALOGV("%s: Camera %d: Lock call from pid %d; current client pid %d",
            __FUNCTION__, mCameraId, getCallingPid(), mClientPid);

 if (mClientPid == 0) {
        mClientPid = getCallingPid();
 return OK;
 }

 if (mClientPid != getCallingPid()) {
        ALOGE("%s: Camera %d: Lock call from pid %d; currently locked to pid %d",
                __FUNCTION__, mCameraId, getCallingPid(), mClientPid);
 return EBUSY;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  const CuePoint* Cues::GetFirst() const {
  if (m_cue_points == NULL)
     return NULL;
 
  if (m_count == 0)
    return NULL;
#if 0
    LoadCuePoint();  //init cues
    const size_t count = m_count + m_preload_count;
    if (count == 0)  //weird
        return NULL;
#endif
   CuePoint* const* const pp = m_cue_points;
  assert(pp);
 
   CuePoint* const pCP = pp[0];
  assert(pCP);
  assert(pCP->GetTimeCode() >= 0);
 
   return pCP;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int LvmEffect_enable(EffectContext *pContext){

 LVM_ControlParams_t ActiveParams; /* Current control Parameters */
    LVM_ReturnStatus_en     LvmStatus = LVM_SUCCESS; /* Function call status */

 /* Get the current settings */
 LvmStatus = LVM_GetControlParameters(pContext->pBundledContext->hInstance,
 &ActiveParams);

    LVM_ERROR_CHECK(LvmStatus, "LVM_GetControlParameters", "LvmEffect_enable")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

 if(pContext->EffectType == LVM_BASS_BOOST) {
        ALOGV("\tLvmEffect_enable : Enabling LVM_BASS_BOOST");
 ActiveParams.BE_OperatingMode       = LVM_BE_ON;
 }
 if(pContext->EffectType == LVM_VIRTUALIZER) {
        ALOGV("\tLvmEffect_enable : Enabling LVM_VIRTUALIZER");
 ActiveParams.VirtualizerOperatingMode = LVM_MODE_ON;
 }
 if(pContext->EffectType == LVM_EQUALIZER) {
        ALOGV("\tLvmEffect_enable : Enabling LVM_EQUALIZER");
 ActiveParams.EQNB_OperatingMode     = LVM_EQNB_ON;
 }
 if(pContext->EffectType == LVM_VOLUME) {
        ALOGV("\tLvmEffect_enable : Enabling LVM_VOLUME");
 }

 LvmStatus = LVM_SetControlParameters(pContext->pBundledContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVM_SetControlParameters", "LvmEffect_enable")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

 LvmEffect_limitLevel(pContext);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraService::Client::disconnect() {
    ALOGV("Client::disconnect");
 BasicClient::disconnect();
    mCameraService->setCameraFree(mCameraId);

 StatusVector rejectSourceStates;
    rejectSourceStates.push_back(ICameraServiceListener::STATUS_NOT_PRESENT);
    rejectSourceStates.push_back(ICameraServiceListener::STATUS_ENUMERATING);

    mCameraService->updateStatus(ICameraServiceListener::STATUS_PRESENT,
                                 mCameraId,
 &rejectSourceStates);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlNormalizeURIPath(char *path) {
 char *cur, *out;

 if (path == NULL)
 return(-1);

 /* Skip all initial "/" chars.  We want to get to the beginning of the
     * first non-empty segment.
     */
    cur = path;
 while (cur[0] == '/')
 ++cur;
 if (cur[0] == '\0')
 return(0);

 /* Keep everything we've seen so far.  */
    out = cur;

 /*
     * Analyze each segment in sequence for cases (c) and (d).
     */
 while (cur[0] != '\0') {
 /*
	 * c) All occurrences of "./", where "." is a complete path segment,
	 *    are removed from the buffer string.
	 */
 if ((cur[0] == '.') && (cur[1] == '/')) {
	    cur += 2;
 /* '//' normalization should be done at this point too */
 while (cur[0] == '/')
		cur++;
 continue;
 }

 /*
	 * d) If the buffer string ends with "." as a complete path segment,
	 *    that "." is removed.
	 */
 if ((cur[0] == '.') && (cur[1] == '\0'))
 break;

 /* Otherwise keep the segment.  */
 while (cur[0] != '/') {
 if (cur[0] == '\0')
 goto done_cd;
 (out++)[0] = (cur++)[0];
 }
 /* nomalize // */
 while ((cur[0] == '/') && (cur[1] == '/'))
	    cur++;

 (out++)[0] = (cur++)[0];
 }
 done_cd:
    out[0] = '\0';

 /* Reset to the beginning of the first segment for the next sequence.  */
    cur = path;
 while (cur[0] == '/')
 ++cur;
 if (cur[0] == '\0')
 return(0);

 /*
     * Analyze each segment in sequence for cases (e) and (f).
     *
     * e) All occurrences of "<segment>/../", where <segment> is a
     *    complete path segment not equal to "..", are removed from the
     *    buffer string.  Removal of these path segments is performed
     *    iteratively, removing the leftmost matching pattern on each
     *    iteration, until no matching pattern remains.
     *
     * f) If the buffer string ends with "<segment>/..", where <segment>
     *    is a complete path segment not equal to "..", that
     *    "<segment>/.." is removed.
     *
     * To satisfy the "iterative" clause in (e), we need to collapse the
     * string every time we find something that needs to be removed.  Thus,
     * we don't need to keep two pointers into the string: we only need a
     * "current position" pointer.
     */
 while (1) {
 char *segp, *tmp;

 /* At the beginning of each iteration of this loop, "cur" points to
         * the first character of the segment we want to examine.
         */

 /* Find the end of the current segment.  */
        segp = cur;
 while ((segp[0] != '/') && (segp[0] != '\0'))
 ++segp;

 /* If this is the last segment, we're done (we need at least two
         * segments to meet the criteria for the (e) and (f) cases).
         */
 if (segp[0] == '\0')
 break;

 /* If the first segment is "..", or if the next segment _isn't_ "..",
         * keep this segment and try the next one.
         */
 ++segp;
 if (((cur[0] == '.') && (cur[1] == '.') && (segp == cur+3))
 || ((segp[0] != '.') || (segp[1] != '.')
 || ((segp[2] != '/') && (segp[2] != '\0')))) {
          cur = segp;
 continue;
 }

 /* If we get here, remove this segment and the next one and back up
         * to the previous segment (if there is one), to implement the
         * "iteratively" clause.  It's pretty much impossible to back up
         * while maintaining two pointers into the buffer, so just compact
         * the whole buffer now.
         */

 /* If this is the end of the buffer, we're done.  */
 if (segp[2] == '\0') {
          cur[0] = '\0';
 break;
 }
 /* Valgrind complained, strcpy(cur, segp + 3); */
 /* string will overlap, do not use strcpy */
        tmp = cur;
        segp += 3;
 while ((*tmp++ = *segp++) != 0)
 ;

 /* If there are no previous segments, then keep going from here.  */
        segp = cur;
 while ((segp > path) && ((--segp)[0] == '/'))
 ;
 if (segp == path)
 continue;

 /* "segp" is pointing to the end of a previous segment; find it's
         * start.  We need to back up to the previous segment and start
         * over with that to handle things like "foo/bar/../..".  If we
         * don't do this, then on the first pass we'll remove the "bar/..",
         * but be pointing at the second ".." so we won't realize we can also
         * remove the "foo/..".
         */
        cur = segp;
 while ((cur > path) && (cur[-1] != '/'))
 --cur;
 }
    out[0] = '\0';

 /*
     * g) If the resulting buffer string still begins with one or more
     *    complete path segments of "..", then the reference is
     *    considered to be in error. Implementations may handle this
     *    error by retaining these components in the resolved path (i.e.,
     *    treating them as part of the final URI), by removing them from
     *    the resolved path (i.e., discarding relative levels above the
     *    root), or by avoiding traversal of the reference.
     *
     * We discard them from the final path.
     */
 if (path[0] == '/') {
      cur = path;
 while ((cur[0] == '/') && (cur[1] == '.') && (cur[2] == '.')
 && ((cur[3] == '/') || (cur[3] == '\0')))
	cur += 3;

 if (cur != path) {
	out = path;
 while (cur[0] != '\0')
 (out++)[0] = (cur++)[0];
	out[0] = 0;
 }
 }

 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Camera3Device::RequestThread::waitIfPaused() {
 status_t res;
 Mutex::Autolock l(mPauseLock);
 while (mDoPause) {
 if (mPaused == false) {
            mPaused = true;
            ALOGV("%s: RequestThread: Paused", __FUNCTION__);
            sp<StatusTracker> statusTracker = mStatusTracker.promote();
 if (statusTracker != 0) {
                statusTracker->markComponentIdle(mStatusId, Fence::NO_FENCE);
 }
 }

        res = mDoPauseSignal.waitRelative(mPauseLock, kRequestTimeout);
 if (res == TIMED_OUT || exitPending()) {
 return true;
 }
 }
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ATSParser::signalEOS(status_t finalResult) {
 if (finalResult == (status_t) OK) {
        ALOGE("finalResult not OK");
 return;
 }

 for (size_t i = 0; i < mPrograms.size(); ++i) {
        mPrograms.editItemAt(i)->signalEOS(finalResult);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Cluster::GetPosition() const
{
    const long long pos = m_element_start - m_pSegment->m_start;
    assert(pos >= 0);
 
    return pos;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: INLINE void impeg2d_bit_stream_flush(void* pv_ctxt, UWORD32 u4_no_of_bits)

 {
     stream_t *ps_stream = (stream_t *)pv_ctxt;
 
    FLUSH_BITS(ps_stream->u4_offset,ps_stream->u4_buf,ps_stream->u4_buf_nxt,u4_no_of_bits,ps_stream->pu4_buf_aligned)
     return;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Track::Info::~Info() { Clear(); }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraClient::checkPidAndHardware() const {
 status_t result = checkPid();
 if (result != NO_ERROR) return result;
 if (mHardware == 0) {
        ALOGE("attempt to use a camera after disconnect() (pid %d)", getCallingPid());
 return INVALID_OPERATION;
 }
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static const char *FourCC2MIME(uint32_t fourcc) {
 switch (fourcc) {
 case FOURCC('m', 'p', '4', 'a'):
 return MEDIA_MIMETYPE_AUDIO_AAC;

 case FOURCC('s', 'a', 'm', 'r'):
 return MEDIA_MIMETYPE_AUDIO_AMR_NB;

 case FOURCC('s', 'a', 'w', 'b'):
 return MEDIA_MIMETYPE_AUDIO_AMR_WB;

 case FOURCC('m', 'p', '4', 'v'):
 return MEDIA_MIMETYPE_VIDEO_MPEG4;

 case FOURCC('s', '2', '6', '3'):
 case FOURCC('h', '2', '6', '3'):
 case FOURCC('H', '2', '6', '3'):
 return MEDIA_MIMETYPE_VIDEO_H263;

 case FOURCC('a', 'v', 'c', '1'):
 return MEDIA_MIMETYPE_VIDEO_AVC;

 default:
            CHECK(!"should not be here.");
 return NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Camera2Client::Camera2Client(const sp<CameraService>& cameraService,
 const sp<ICameraClient>& cameraClient,
 const String16& clientPackageName,
 int cameraId,
 int cameraFacing,
 int clientPid,
 uid_t clientUid,
 int servicePid,
 int deviceVersion):
 Camera2ClientBase(cameraService, cameraClient, clientPackageName,
                cameraId, cameraFacing, clientPid, clientUid, servicePid),
        mParameters(cameraId, cameraFacing),
        mDeviceVersion(deviceVersion)
{
    ATRACE_CALL();

 SharedParameters::Lock l(mParameters);
    l.mParameters.state = Parameters::DISCONNECTED;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t Parcel::dataSize() const
{
 return (mDataSize > mDataPos ? mDataSize : mDataPos);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftVPXEncoder::internalGetParameter(OMX_INDEXTYPE index,
                                                   OMX_PTR param) {
 const int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamVideoBitrate: {

             OMX_VIDEO_PARAM_BITRATETYPE *bitrate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *)param;
 
                if (bitrate->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }
 
                bitrate->nTargetBitrate = mBitrate;
 
                if (mBitrateControlMode == VPX_VBR) {
                    bitrate->eControlRate = OMX_Video_ControlRateVariable;
                } else if (mBitrateControlMode == VPX_CBR) {
                    bitrate->eControlRate = OMX_Video_ControlRateConstant;
                } else {
                    return OMX_ErrorUnsupportedSetting;
                }
                return OMX_ErrorNone;
         }
 
 case OMX_IndexParamVideoVp8: {

             OMX_VIDEO_PARAM_VP8TYPE *vp8Params =
                 (OMX_VIDEO_PARAM_VP8TYPE *)param;
 
                if (vp8Params->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }
 
                vp8Params->eProfile = OMX_VIDEO_VP8ProfileMain;
                vp8Params->eLevel = mLevel;
                vp8Params->nDCTPartitions = mDCTPartitions;
                vp8Params->bErrorResilientMode = mErrorResilience;
                return OMX_ErrorNone;
         }
 
         case OMX_IndexParamVideoAndroidVp8Encoder: {
             OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE *vp8AndroidParams =
                 (OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE *)param;
 
                if (vp8AndroidParams->nPortIndex != kOutputPortIndex) {
                    return OMX_ErrorUnsupportedIndex;
                }
 
                vp8AndroidParams->nKeyFrameInterval = mKeyFrameInterval;
                vp8AndroidParams->eTemporalPattern = mTemporalPatternType;
                vp8AndroidParams->nTemporalLayerCount = mTemporalLayers;
                vp8AndroidParams->nMinQuantizer = mMinQuantizer;
                vp8AndroidParams->nMaxQuantizer = mMaxQuantizer;
                memcpy(vp8AndroidParams->nTemporalLayerBitrateRatio,
                       mTemporalLayerBitrateRatio, sizeof(mTemporalLayerBitrateRatio));
                return OMX_ErrorNone;
         }
 
         default:
 return SoftVideoEncoderOMXComponent::internalGetParameter(index, param);
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: FLAC_API FLAC__bool FLAC__stream_decoder_seek_absolute(FLAC__StreamDecoder *decoder, FLAC__uint64 sample)
{
	FLAC__uint64 length;

	FLAC__ASSERT(0 != decoder);

 if(
		decoder->protected_->state != FLAC__STREAM_DECODER_SEARCH_FOR_METADATA &&
		decoder->protected_->state != FLAC__STREAM_DECODER_READ_METADATA &&
		decoder->protected_->state != FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC &&
		decoder->protected_->state != FLAC__STREAM_DECODER_READ_FRAME &&
		decoder->protected_->state != FLAC__STREAM_DECODER_END_OF_STREAM
 )
 return false;

 if(0 == decoder->private_->seek_callback)
 return false;

	FLAC__ASSERT(decoder->private_->seek_callback);
	FLAC__ASSERT(decoder->private_->tell_callback);
	FLAC__ASSERT(decoder->private_->length_callback);
	FLAC__ASSERT(decoder->private_->eof_callback);

 if(FLAC__stream_decoder_get_total_samples(decoder) > 0 && sample >= FLAC__stream_decoder_get_total_samples(decoder))
 return false;

	decoder->private_->is_seeking = true;

 /* turn off md5 checking if a seek is attempted */
	decoder->private_->do_md5_checking = false;

 /* get the file length (currently our algorithm needs to know the length so it's also an error to get FLAC__STREAM_DECODER_LENGTH_STATUS_UNSUPPORTED) */
 if(decoder->private_->length_callback(decoder, &length, decoder->private_->client_data) != FLAC__STREAM_DECODER_LENGTH_STATUS_OK) {
		decoder->private_->is_seeking = false;
 return false;
 }

 /* if we haven't finished processing the metadata yet, do that so we have the STREAMINFO, SEEK_TABLE, and first_frame_offset */
 if(
		decoder->protected_->state == FLAC__STREAM_DECODER_SEARCH_FOR_METADATA ||
		decoder->protected_->state == FLAC__STREAM_DECODER_READ_METADATA
 ) {
 if(!FLAC__stream_decoder_process_until_end_of_metadata(decoder)) {
 /* above call sets the state for us */
			decoder->private_->is_seeking = false;
 return false;
 }
 /* check this again in case we didn't know total_samples the first time */
 if(FLAC__stream_decoder_get_total_samples(decoder) > 0 && sample >= FLAC__stream_decoder_get_total_samples(decoder)) {
			decoder->private_->is_seeking = false;
 return false;
 }
 }

 {
 const FLAC__bool ok =
#if FLAC__HAS_OGG
			decoder->private_->is_ogg?
			seek_to_absolute_sample_ogg_(decoder, length, sample) :
#endif
			seek_to_absolute_sample_(decoder, length, sample)
 ;
		decoder->private_->is_seeking = false;
 return ok;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void smp_br_send_pair_response(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);

  p_cb->local_i_key &= p_cb->peer_i_key;
  p_cb->local_r_key &= p_cb->peer_r_key;

  smp_send_cmd(SMP_OPCODE_PAIRING_RSP, p_cb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long SegmentInfo::GetDuration() const
{
    if (m_duration < 0)
        return -1;
    assert(m_timecodeScale >= 1);
    const double dd = double(m_duration) * double(m_timecodeScale);
    const long long d = static_cast<long long>(dd);
    return d;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: Chapters::Chapters(
    Segment* pSegment,
    long long payload_start,
    long long payload_size,
    long long element_start,
    long long element_size) :
    m_pSegment(pSegment),
    m_start(payload_start),
    m_size(payload_size),
    m_element_start(element_start),
    m_element_size(element_size),
    m_editions(NULL),
    m_editions_size(0),
    m_editions_count(0)
{
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void SoftMP3::onReset() {
    pvmp3_InitDecoder(mConfig, mDecoderBuf);
    mIsFirst = true;
    mSignalledError = false;
    mSawInputEos = false;
    mSignalledOutputEos = false;
    mOutputPortSettingsChange = NONE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraService::dump(int fd, const Vector<String16>& args) {
 String8 result;
 if (checkCallingPermission(String16("android.permission.DUMP")) == false) {
        result.appendFormat("Permission Denial: "
 "can't dump CameraService from pid=%d, uid=%d\n",
                getCallingPid(),
                getCallingUid());
        write(fd, result.string(), result.size());
 } else {
 bool locked = tryLock(mServiceLock);
 if (!locked) {
            result.append("CameraService may be deadlocked\n");
            write(fd, result.string(), result.size());
 }

 bool hasClient = false;
 if (!mModule) {
            result = String8::format("No camera module available!\n");
            write(fd, result.string(), result.size());
 return NO_ERROR;
 }

        result = String8::format("Camera module HAL API version: 0x%x\n",
                mModule->common.hal_api_version);
        result.appendFormat("Camera module API version: 0x%x\n",
                mModule->common.module_api_version);
        result.appendFormat("Camera module name: %s\n",
                mModule->common.name);
        result.appendFormat("Camera module author: %s\n",
                mModule->common.author);
        result.appendFormat("Number of camera devices: %d\n\n", mNumberOfCameras);
        write(fd, result.string(), result.size());
 for (int i = 0; i < mNumberOfCameras; i++) {
            result = String8::format("Camera %d static information:\n", i);
            camera_info info;

 status_t rc = mModule->get_camera_info(i, &info);
 if (rc != OK) {
                result.appendFormat("  Error reading static information!\n");
                write(fd, result.string(), result.size());
 } else {
                result.appendFormat("  Facing: %s\n",
                        info.facing == CAMERA_FACING_BACK ? "BACK" : "FRONT");
                result.appendFormat("  Orientation: %d\n", info.orientation);
 int deviceVersion;
 if (mModule->common.module_api_version <
                        CAMERA_MODULE_API_VERSION_2_0) {
                    deviceVersion = CAMERA_DEVICE_API_VERSION_1_0;
 } else {
                    deviceVersion = info.device_version;
 }
                result.appendFormat("  Device version: 0x%x\n", deviceVersion);
 if (deviceVersion >= CAMERA_DEVICE_API_VERSION_2_0) {
                    result.appendFormat("  Device static metadata:\n");
                    write(fd, result.string(), result.size());
                    dump_indented_camera_metadata(info.static_camera_characteristics,
                            fd, 2, 4);
 } else {
                    write(fd, result.string(), result.size());
 }
 }

            sp<BasicClient> client = mClient[i].promote();
 if (client == 0) {
                result = String8::format("  Device is closed, no client instance\n");
                write(fd, result.string(), result.size());
 continue;
 }

             hasClient = true;
             result = String8::format("  Device is open. Client instance dump:\n");
             write(fd, result.string(), result.size());
            client->dump(fd, args);
         }
         if (!hasClient) {
             result = String8::format("\nNo active camera clients yet.\n");
            write(fd, result.string(), result.size());
 }

 if (locked) mServiceLock.unlock();

        write(fd, "\n", 1);
        camera3::CameraTraces::dump(fd, args);

 int n = args.size();
 for (int i = 0; i + 1 < n; i++) {
 String16 verboseOption("-v");
 if (args[i] == verboseOption) {
 String8 levelStr(args[i+1]);
 int level = atoi(levelStr.string());
                result = String8::format("\nSetting log level to %d.\n", level);
                setLogLevel(level);
                write(fd, result.string(), result.size());
 }
 }

 }
 return NO_ERROR;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  fix(double d)
{
   d = floor(d * PNG_FP_1 + .5);
 return (png_fixed_point)d;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::free_buffer(OMX_IN OMX_HANDLETYPE         hComp,
        OMX_IN OMX_U32                 port,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
 (void)hComp;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned int nPortIndex;

    DEBUG_PRINT_LOW("In for encoder free_buffer");

 if (m_state == OMX_StateIdle &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
        DEBUG_PRINT_LOW(" free buffer while Component in Loading pending");
 } else if ((m_sInPortDef.bEnabled == OMX_FALSE && port == PORT_INDEX_IN)||
 (m_sOutPortDef.bEnabled == OMX_FALSE && port == PORT_INDEX_OUT)) {
        DEBUG_PRINT_LOW("Free Buffer while port %u disabled", (unsigned int)port);
 } else if (m_state == OMX_StateExecuting || m_state == OMX_StatePause) {
        DEBUG_PRINT_ERROR("ERROR: Invalid state to free buffer,ports need to be disabled");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);
 return eRet;
 } else {
        DEBUG_PRINT_ERROR("ERROR: Invalid state to free buffer,port lost Buffers");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);
 }

 if (port == PORT_INDEX_IN) {
        nPortIndex = buffer - ((!meta_mode_enable)?m_inp_mem_ptr:meta_buffer_hdr);

        DEBUG_PRINT_LOW("free_buffer on i/p port - Port idx %u, actual cnt %u",
                nPortIndex, (unsigned int)m_sInPortDef.nBufferCountActual);
 if (nPortIndex < m_sInPortDef.nBufferCountActual &&
                BITMASK_PRESENT(&m_inp_bm_count, nPortIndex)) {
            BITMASK_CLEAR(&m_inp_bm_count,nPortIndex);
            free_input_buffer (buffer);
            m_sInPortDef.bPopulated = OMX_FALSE;

 /*Free the Buffer Header*/
 if (release_input_done()
#ifdef _ANDROID_ICS_
 && !meta_mode_enable
#endif
 ) {
                input_use_buffer = false;
 if (m_inp_mem_ptr) {
                    DEBUG_PRINT_LOW("Freeing m_inp_mem_ptr");
                    free (m_inp_mem_ptr);
                    m_inp_mem_ptr = NULL;
 }
 if (m_pInput_pmem) {
                    DEBUG_PRINT_LOW("Freeing m_pInput_pmem");
                    free(m_pInput_pmem);
                    m_pInput_pmem = NULL;
 }
#ifdef USE_ION
 if (m_pInput_ion) {
                    DEBUG_PRINT_LOW("Freeing m_pInput_ion");
                    free(m_pInput_ion);
                    m_pInput_ion = NULL;
 }
#endif
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: free_buffer ,Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }

 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING)
 && release_input_done()) {
            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING);
            post_event(OMX_CommandPortDisable,
                    PORT_INDEX_IN,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 } else if (port == PORT_INDEX_OUT) {
        nPortIndex = buffer - (OMX_BUFFERHEADERTYPE*)m_out_mem_ptr;

        DEBUG_PRINT_LOW("free_buffer on o/p port - Port idx %u, actual cnt %u",
                nPortIndex, (unsigned int)m_sOutPortDef.nBufferCountActual);
 if (nPortIndex < m_sOutPortDef.nBufferCountActual &&
                BITMASK_PRESENT(&m_out_bm_count, nPortIndex)) {
            BITMASK_CLEAR(&m_out_bm_count,nPortIndex);
            m_sOutPortDef.bPopulated = OMX_FALSE;
            free_output_buffer (buffer);

 if (release_output_done()) {
                output_use_buffer = false;
 if (m_out_mem_ptr) {
                    DEBUG_PRINT_LOW("Freeing m_out_mem_ptr");
                    free (m_out_mem_ptr);
                    m_out_mem_ptr = NULL;
 }
 if (m_pOutput_pmem) {
                    DEBUG_PRINT_LOW("Freeing m_pOutput_pmem");
                    free(m_pOutput_pmem);
                    m_pOutput_pmem = NULL;
 }
#ifdef USE_ION
 if (m_pOutput_ion) {
                    DEBUG_PRINT_LOW("Freeing m_pOutput_ion");
                    free(m_pOutput_ion);
                    m_pOutput_ion = NULL;
 }
#endif
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: free_buffer , Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }
 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING)
 && release_output_done() ) {
            DEBUG_PRINT_LOW("FreeBuffer : If any Disable event pending,post it");

            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING);
            post_event(OMX_CommandPortDisable,
                    PORT_INDEX_OUT,
                    OMX_COMPONENT_GENERATE_EVENT);

 }
 } else {
        eRet = OMX_ErrorBadPortIndex;
 }
 if ((eRet == OMX_ErrorNone) &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
 if (release_done()) {
 if (dev_stop() != 0) {
                DEBUG_PRINT_ERROR("ERROR: dev_stop() FAILED");
                eRet = OMX_ErrorHardware;
 }
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_LOADING_PENDING);
            post_event(OMX_CommandStateSet, OMX_StateLoaded,
                    OMX_COMPONENT_GENERATE_EVENT);
 } else {
            DEBUG_PRINT_HIGH("in free buffer, release not done, need to free more buffers input %" PRIx64" output %" PRIx64,
                    m_out_bm_count, m_inp_bm_count);
 }
 }

 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_decode_pic_order_cnt(UWORD8 u1_is_idr_slice,
                                   UWORD32 u2_frame_num,
 pocstruct_t *ps_prev_poc,
 pocstruct_t *ps_cur_poc,
 dec_slice_params_t *ps_cur_slice, /*!< Pointer to current slice Params*/
 dec_pic_params_t * ps_pps,
                                   UWORD8 u1_nal_ref_idc,
                                   UWORD8 u1_bottom_field_flag,
                                   UWORD8 u1_field_pic_flag,
                                   WORD32 *pi4_poc)
{
    WORD16 i1_pic_msb;
    WORD32 i4_top_field_order_cnt = 0, i4_bottom_field_order_cnt = 0;
 dec_seq_params_t *ps_seq = ps_pps->ps_sps;
    WORD32 i4_prev_frame_num_ofst;

 switch(ps_seq->u1_pic_order_cnt_type)
 {
 case 0:
 /* POC TYPE 0 */
 if(u1_is_idr_slice)
 {
                ps_prev_poc->i4_pic_order_cnt_msb = 0;
                ps_prev_poc->i4_pic_order_cnt_lsb = 0;
 }
 if(ps_prev_poc->u1_mmco_equalto5)
 {
 if(ps_prev_poc->u1_bot_field != 1)
 {
                    ps_prev_poc->i4_pic_order_cnt_msb = 0;
                    ps_prev_poc->i4_pic_order_cnt_lsb =
                                    ps_prev_poc->i4_top_field_order_count;
 }
 else
 {
                    ps_prev_poc->i4_pic_order_cnt_msb = 0;
                    ps_prev_poc->i4_pic_order_cnt_lsb = 0;
 }
 }

 if((ps_cur_poc->i4_pic_order_cnt_lsb
 < ps_prev_poc->i4_pic_order_cnt_lsb)
 && ((ps_prev_poc->i4_pic_order_cnt_lsb
 - ps_cur_poc->i4_pic_order_cnt_lsb)
 >= (ps_seq->i4_max_pic_order_cntLsb
 >> 1)))
 {
                i1_pic_msb = ps_prev_poc->i4_pic_order_cnt_msb
 + ps_seq->i4_max_pic_order_cntLsb;
 }
 else if((ps_cur_poc->i4_pic_order_cnt_lsb
 > ps_prev_poc->i4_pic_order_cnt_lsb)
 && ((ps_cur_poc->i4_pic_order_cnt_lsb
 - ps_prev_poc->i4_pic_order_cnt_lsb)
 >= (ps_seq->i4_max_pic_order_cntLsb
 >> 1)))
 {
                i1_pic_msb = ps_prev_poc->i4_pic_order_cnt_msb
 - ps_seq->i4_max_pic_order_cntLsb;
 }
 else
 {
                i1_pic_msb = ps_prev_poc->i4_pic_order_cnt_msb;
 }

 if(!u1_field_pic_flag || !u1_bottom_field_flag)
                i4_top_field_order_cnt = i1_pic_msb
 + ps_cur_poc->i4_pic_order_cnt_lsb;

 if(!u1_field_pic_flag)
 {
                i4_bottom_field_order_cnt = i4_top_field_order_cnt
 + ps_cur_poc->i4_delta_pic_order_cnt_bottom;
 }
 else if(u1_bottom_field_flag)
 {
                i4_bottom_field_order_cnt = i1_pic_msb
 + ps_cur_poc->i4_pic_order_cnt_lsb;
 }
            ps_cur_poc->i4_pic_order_cnt_msb = i1_pic_msb;
 break;

 case 1:
 {
 /* POC TYPE 1 */
            UWORD8 i;
            WORD32 prev_frame_num;
            WORD32 frame_num_ofst;
            WORD32 abs_frm_num;
            WORD32 poc_cycle_cnt, frame_num_in_poc_cycle;
            WORD32 expected_delta_poc_cycle;
            WORD32 expected_poc;

            prev_frame_num = (WORD32)ps_cur_slice->u2_frame_num;
 if(!u1_is_idr_slice)
 {
 if(ps_cur_slice->u1_mmco_equalto5)
 {
                    prev_frame_num = 0;
                    i4_prev_frame_num_ofst = 0;
 }
 else
 {
                    i4_prev_frame_num_ofst = ps_prev_poc->i4_prev_frame_num_ofst;
 }
 }
 else
                i4_prev_frame_num_ofst = 0;

 /* 1. Derivation for FrameNumOffset */
 if(u1_is_idr_slice)
 {
                frame_num_ofst = 0;
                ps_cur_poc->i4_delta_pic_order_cnt[0] = 0;
                ps_cur_poc->i4_delta_pic_order_cnt[1] = 0;
 }
 else if(prev_frame_num > ((WORD32)u2_frame_num))
 {
                frame_num_ofst = i4_prev_frame_num_ofst
 + ps_seq->u2_u4_max_pic_num_minus1 + 1;
 }
 else
                frame_num_ofst = i4_prev_frame_num_ofst;

 /* 2. Derivation for absFrameNum */
 if(0 != ps_seq->u1_num_ref_frames_in_pic_order_cnt_cycle)
                abs_frm_num = frame_num_ofst + u2_frame_num;
 else
                abs_frm_num = 0;
 if((u1_nal_ref_idc == 0) && (abs_frm_num > 0))
                abs_frm_num = abs_frm_num - 1;

 /* 4. expectedDeltaPerPicOrderCntCycle is derived as */
            expected_delta_poc_cycle = 0;
 for(i = 0; i < ps_seq->u1_num_ref_frames_in_pic_order_cnt_cycle;
                            i++)
 {
                expected_delta_poc_cycle +=
                                ps_seq->i4_ofst_for_ref_frame[i];
 }

 /* 3. When absFrameNum > 0, picOrderCntCycleCnt and
             frame_num_in_poc_cycle are derived as : */
 /* 5. expectedPicOrderCnt is derived as : */
 if(abs_frm_num > 0)
 {
                poc_cycle_cnt =
                                DIV((abs_frm_num - 1),
                                    ps_seq->u1_num_ref_frames_in_pic_order_cnt_cycle);
                frame_num_in_poc_cycle =
                                MOD((abs_frm_num - 1),
                                    ps_seq->u1_num_ref_frames_in_pic_order_cnt_cycle);

                expected_poc = poc_cycle_cnt
 * expected_delta_poc_cycle;
 for(i = 0; i <= frame_num_in_poc_cycle; i++)
 {
                    expected_poc = expected_poc
 + ps_seq->i4_ofst_for_ref_frame[i];
 }
 }
 else
                expected_poc = 0;

 if(u1_nal_ref_idc == 0)
 {
                expected_poc = expected_poc
 + ps_seq->i4_ofst_for_non_ref_pic;
 }

 /* 6. TopFieldOrderCnt or BottomFieldOrderCnt are derived as */
 if(!u1_field_pic_flag)
 {
                i4_top_field_order_cnt = expected_poc
 + ps_cur_poc->i4_delta_pic_order_cnt[0];
                i4_bottom_field_order_cnt = i4_top_field_order_cnt
 + ps_seq->i4_ofst_for_top_to_bottom_field
 + ps_cur_poc->i4_delta_pic_order_cnt[1];
 }
 else if(!u1_bottom_field_flag)
 {
                i4_top_field_order_cnt = expected_poc
 + ps_cur_poc->i4_delta_pic_order_cnt[0];
 }
 else
 {
                i4_bottom_field_order_cnt = expected_poc
 + ps_seq->i4_ofst_for_top_to_bottom_field
 + ps_cur_poc->i4_delta_pic_order_cnt[0];
 }
 /* Copy the current POC info into Previous POC structure */
            ps_cur_poc->i4_prev_frame_num_ofst = frame_num_ofst;
 }

 break;
 case 2:
 {
 /* POC TYPE 2 */
            WORD32 prev_frame_num;
            WORD32 frame_num_ofst;
            WORD32 tmp_poc;

            prev_frame_num = (WORD32)ps_cur_slice->u2_frame_num;
 if(!u1_is_idr_slice)
 {
 if(ps_cur_slice->u1_mmco_equalto5)
 {
                    prev_frame_num = 0;
                    i4_prev_frame_num_ofst = 0;
 }
 else
                    i4_prev_frame_num_ofst = ps_prev_poc->i4_prev_frame_num_ofst;
 }
 else
                i4_prev_frame_num_ofst = 0;

 /* 1. Derivation for FrameNumOffset */
 if(u1_is_idr_slice)
 {
                frame_num_ofst = 0;
                ps_cur_poc->i4_delta_pic_order_cnt[0] = 0;
                ps_cur_poc->i4_delta_pic_order_cnt[1] = 0;
 }
 else if(prev_frame_num > ((WORD32)u2_frame_num))
 {
                frame_num_ofst = i4_prev_frame_num_ofst
 + ps_seq->u2_u4_max_pic_num_minus1 + 1;
 }
 else
                frame_num_ofst = i4_prev_frame_num_ofst;

 /* 2. Derivation for tempPicOrderCnt */
 if(u1_is_idr_slice)
                tmp_poc = 0;
 else if(u1_nal_ref_idc == 0)
                tmp_poc = ((frame_num_ofst + u2_frame_num) << 1)
 - 1;
 else
                tmp_poc = ((frame_num_ofst + u2_frame_num) << 1);

 /* 6. TopFieldOrderCnt or BottomFieldOrderCnt are derived as */
 if(!u1_field_pic_flag)
 {
                i4_top_field_order_cnt = tmp_poc;
                i4_bottom_field_order_cnt = tmp_poc;
 }
 else if(!u1_bottom_field_flag)
                i4_top_field_order_cnt = tmp_poc;
 else
                i4_bottom_field_order_cnt = tmp_poc;

 /* Copy the current POC info into Previous POC structure */
            ps_prev_poc->i4_prev_frame_num_ofst = frame_num_ofst;
            ps_cur_poc->i4_prev_frame_num_ofst = frame_num_ofst;
 }
 break;
 default:
 return ERROR_INV_POC_TYPE_T;
 break;
 }

 if(!u1_field_pic_flag) // or a complementary field pair
 {
 *pi4_poc = MIN(i4_top_field_order_cnt, i4_bottom_field_order_cnt);
        ps_pps->i4_top_field_order_cnt = i4_top_field_order_cnt;
        ps_pps->i4_bottom_field_order_cnt = i4_bottom_field_order_cnt;
 }
 else if(!u1_bottom_field_flag)
 {
 *pi4_poc = i4_top_field_order_cnt;
        ps_pps->i4_top_field_order_cnt = i4_top_field_order_cnt;
 }
 else
 {
 *pi4_poc = i4_bottom_field_order_cnt;
        ps_pps->i4_bottom_field_order_cnt = i4_bottom_field_order_cnt;
 }

    ps_pps->i4_avg_poc = *pi4_poc;

 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: long long EBMLHeader::Parse(IMkvReader* pReader, long long& pos) {
 if (!pReader)
 return E_FILE_FORMAT_INVALID;

 long long total, available;

 long status = pReader->Length(&total, &available);

 if (status < 0) // error
 return status;

  pos = 0;
 long long end = (available >= 1024) ? 1024 : available;

 for (;;) {
 unsigned char b = 0;

 while (pos < end) {
      status = pReader->Read(pos, 1, &b);

 if (status < 0) // error
 return status;

 if (b == 0x1A)
 break;

 ++pos;
 }

 if (b != 0x1A) {
 if (pos >= 1024)
 return E_FILE_FORMAT_INVALID; // don't bother looking anymore

 if ((total >= 0) && ((total - available) < 5))
 return E_FILE_FORMAT_INVALID;

 return available + 5; // 5 = 4-byte ID + 1st byte of size
 }

 if ((total >= 0) && ((total - pos) < 5))
 return E_FILE_FORMAT_INVALID;

 if ((available - pos) < 5)
 return pos + 5; // try again later

 long len;

 const long long result = ReadUInt(pReader, pos, len);

 if (result < 0) // error
 return result;

 if (result == 0x0A45DFA3) { // EBML Header ID
      pos += len; // consume ID
 break;
 }

 ++pos; // throw away just the 0x1A byte, and try again
 }



 long len;
 long long result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error
 return result;

 if (result > 0) // need more data
 return result;

 if (len < 1 || len > 8)
 return E_FILE_FORMAT_INVALID;

 if ((total >= 0) && ((total - pos) < len))
 return E_FILE_FORMAT_INVALID;

 if ((available - pos) < len)
 return pos + len; // try again later


  result = ReadUInt(pReader, pos, len);

 if (result < 0) // error
 return result;

  pos += len; // consume size field


 if ((total >= 0) && ((total - pos) < result))
 return E_FILE_FORMAT_INVALID;

 if ((available - pos) < result)
 return pos + result;

  end = pos + result;

 Init();

 while (pos < end) {
 long long id, size;

    status = ParseElementHeader(pReader, pos, end, id, size);

 if (status < 0) // error
 return status;

 if (size == 0) // weird
 return E_FILE_FORMAT_INVALID;

 if (id == 0x0286) { // version
      m_version = UnserializeUInt(pReader, pos, size);

 if (m_version <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F7) { // read version
      m_readVersion = UnserializeUInt(pReader, pos, size);

 if (m_readVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F2) { // max id length
      m_maxIdLength = UnserializeUInt(pReader, pos, size);

 if (m_maxIdLength <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x02F3) { // max size length
      m_maxSizeLength = UnserializeUInt(pReader, pos, size);

 if (m_maxSizeLength <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x0282) { // doctype
 if (m_docType)
 return E_FILE_FORMAT_INVALID;

      status = UnserializeString(pReader, pos, size, m_docType);

 if (status) // error
 return status;
 } else if (id == 0x0287) { // doctype version
      m_docTypeVersion = UnserializeUInt(pReader, pos, size);

 if (m_docTypeVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 } else if (id == 0x0285) { // doctype read version
      m_docTypeReadVersion = UnserializeUInt(pReader, pos, size);

 if (m_docTypeReadVersion <= 0)
 return E_FILE_FORMAT_INVALID;
 }

    pos += size;
 }

 if (pos != end)
 return E_FILE_FORMAT_INVALID;

 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void smp_wait_for_both_public_keys(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);

 if ((p_cb->flags & SMP_PAIR_FLAG_HAVE_PEER_PUBL_KEY) &&
 (p_cb->flags & SMP_PAIR_FLAG_HAVE_LOCAL_PUBL_KEY)) {
 if ((p_cb->role == HCI_ROLE_SLAVE) &&
 ((p_cb->req_oob_type == SMP_OOB_LOCAL) ||
 (p_cb->req_oob_type == SMP_OOB_BOTH))) {
      smp_set_state(SMP_STATE_PUBLIC_KEY_EXCH);
 }
    smp_sm_event(p_cb, SMP_BOTH_PUBL_KEYS_RCVD_EVT, NULL);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void acquire_object(const sp<ProcessState>& proc,
 const flat_binder_object& obj, const void* who, size_t* outAshmemSize)
{
 switch (obj.type) {
 case BINDER_TYPE_BINDER:
 if (obj.binder) {
                LOG_REFS("Parcel %p acquiring reference on local %p", who, obj.cookie);
 reinterpret_cast<IBinder*>(obj.cookie)->incStrong(who);
 }
 return;
 case BINDER_TYPE_WEAK_BINDER:
 if (obj.binder)
 reinterpret_cast<RefBase::weakref_type*>(obj.binder)->incWeak(who);
 return;
 case BINDER_TYPE_HANDLE: {
 const sp<IBinder> b = proc->getStrongProxyForHandle(obj.handle);
 if (b != NULL) {
                LOG_REFS("Parcel %p acquiring reference on remote %p", who, b.get());
                b->incStrong(who);
 }
 return;
 }
 case BINDER_TYPE_WEAK_HANDLE: {
 const wp<IBinder> b = proc->getWeakProxyForHandle(obj.handle);
 if (b != NULL) b.get_refs()->incWeak(who);
 return;
 }
 case BINDER_TYPE_FD: {
 if ((obj.cookie != 0) && (outAshmemSize != NULL)) {
 struct stat st;
 int ret = fstat(obj.handle, &st);
 if (!ret && S_ISCHR(st.st_mode) && (st.st_rdev == ashmem_rdev())) {
 int size = ashmem_get_size_region(obj.handle);
 if (size > 0) {
 *outAshmemSize += size;
 }
 }
 }
 return;
 }
 }

    ALOGD("Invalid object type 0x%08x", obj.type);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ATSParser::PSISection::append(const void *data, size_t size) {
 if (mBuffer == NULL || mBuffer->size() + size > mBuffer->capacity()) {
 size_t newCapacity =
 (mBuffer == NULL) ? size : mBuffer->capacity() + size;

        newCapacity = (newCapacity + 1023) & ~1023;

        sp<ABuffer> newBuffer = new ABuffer(newCapacity);

 if (mBuffer != NULL) {
            memcpy(newBuffer->data(), mBuffer->data(), mBuffer->size());
            newBuffer->setRange(0, mBuffer->size());
 } else {
            newBuffer->setRange(0, 0);
 }

        mBuffer = newBuffer;
 }

    memcpy(mBuffer->data() + mBuffer->size(), data, size);
    mBuffer->setRange(0, mBuffer->size() + size);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static inline void SetImpl(FixedArrayBase* backing_store, uint32_t entry,
 Object* value, WriteBarrierMode mode) {
 BackingStore::cast(backing_store)->SetValue(entry, value);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftAACEncoder::SoftAACEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mEncoderHandle(NULL),
      mApiHandle(NULL),
      mMemOperator(NULL),
      mNumChannels(1),
      mSampleRate(44100),
      mBitRate(0),
      mSentCodecSpecificData(false),
      mInputSize(0),
      mInputFrame(NULL),
      mInputTimeUs(-1ll),
      mSawInputEOS(false),
      mSignalledError(false) {
    initPorts();
    CHECK_EQ(initEncoder(), (status_t)OK);

    setAudioParams();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SimpleSoftOMXComponent::onSendCommand(
        OMX_COMMANDTYPE cmd, OMX_U32 param) {
 switch (cmd) {
 case OMX_CommandStateSet:
 {
            onChangeState((OMX_STATETYPE)param);
 break;
 }

 case OMX_CommandPortEnable:
 case OMX_CommandPortDisable:
 {
            onPortEnable(param, cmd == OMX_CommandPortEnable);
 break;
 }

 case OMX_CommandFlush:
 {
            onPortFlush(param, true /* sendFlushComplete */);
 break;
 }

 default:
            TRESPASS();
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: main(int argc, char **argv)
{
 int i;
 int extracted = 0;

 for (i=1; i<argc; ++i)
 {
 if (strcmp(argv[i], "-q") == 0)
         verbose = 0;

 else if (extract_one_file(argv[i]))
         extracted = 1;
 }


    /* Exit code is true if any extract succeeds */
    return extracted == 0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void VirtualizerGetSpeakerAngles(audio_channel_mask_t channelMask __unused,
 audio_devices_t deviceType __unused, int32_t *pSpeakerAngles) {
 *pSpeakerAngles++ = (int32_t) AUDIO_CHANNEL_OUT_FRONT_LEFT;
 *pSpeakerAngles++ = -90; // azimuth
 *pSpeakerAngles++ = 0; // elevation
 *pSpeakerAngles++ = (int32_t) AUDIO_CHANNEL_OUT_FRONT_RIGHT;
 *pSpeakerAngles++ = 90; // azimuth
 *pSpeakerAngles   = 0; // elevation
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char * adev_get_parameters(const struct audio_hw_device *dev,
 const char *keys)
{
 struct str_parms *parms;
    UNUSED(dev);

    FNLOG();

    parms = str_parms_create_str(keys);

    str_parms_dump(parms);

    str_parms_destroy(parms);

 return strdup("");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t InputDispatcher::InputState::findKeyMemento(const KeyEntry* entry) const {
 for (size_t i = 0; i < mKeyMementos.size(); i++) {
 const KeyMemento& memento = mKeyMementos.itemAt(i);
 if (memento.deviceId == entry->deviceId
 && memento.source == entry->source
 && memento.keyCode == entry->keyCode
 && memento.scanCode == entry->scanCode) {
 return i;
 }
 }
 return -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static OMX_U32 setPFramesSpacing(int32_t iFramesInterval, int32_t frameRate) {
 if (iFramesInterval < 0) {
 return 0xFFFFFFFF;
 } else if (iFramesInterval == 0) {
 return 0;
 }
    OMX_U32 ret = frameRate * iFramesInterval;
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline unsigned int flags2pevents(int flags)
{
 unsigned int pevents = 0;
 if(flags & SOCK_THREAD_FD_WR)
        pevents |= POLLOUT;
 if(flags & SOCK_THREAD_FD_RD)
        pevents |= POLLIN;
    pevents |= POLL_EXCEPTION_EVENTS;
 return pevents;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bt_status_t unregister_application(int app_id){
    UINT8               app_idx;
 int                 len;
 bt_status_t         status = BT_STATUS_SUCCESS;
 btif_hl_evt_cb_t    evt_param;

    CHECK_BTHL_INIT();
    BTIF_TRACE_EVENT("%s app_id=%d", __FUNCTION__, app_id);
    btif_hl_display_calling_process_name();

 if (btif_hl_find_app_idx(((UINT8)app_id), &app_idx))
 {
        evt_param.unreg.app_idx = app_idx;
        BTIF_HL_GET_APP_CB_PTR(app_idx);
        reg_counter --;
        len = sizeof(btif_hl_unreg_t);
        status = btif_transfer_context (btif_hl_proc_cb_evt, BTIF_HL_UNREG_APP,
 (char*) &evt_param, len, NULL);
        ASSERTC(status == BT_STATUS_SUCCESS, "context transfer failed", status);
 }
 else
 {
        status  = BT_STATUS_FAIL;
 }

    BTIF_TRACE_DEBUG("de-reg return status=%d", status);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_vdec::is_component_secure()
{
 return secure_mode;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_get_buf_req(OMX_U32 *min_buff_count,
        OMX_U32 *actual_buff_count,
        OMX_U32 *buff_size,
        OMX_U32 port)
{
 struct v4l2_format fmt;
 struct v4l2_requestbuffers bufreq;
 unsigned int buf_size = 0, extra_data_size = 0, client_extra_data_size = 0;
 int ret;

 if (port == 0) {
        fmt.type = V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
        fmt.fmt.pix_mp.height = m_sVenc_cfg.input_height;
        fmt.fmt.pix_mp.width = m_sVenc_cfg.input_width;
        fmt.fmt.pix_mp.pixelformat = V4L2_PIX_FMT_NV12;
        fmt.fmt.pix_mp.colorspace = V4L2_COLORSPACE_BT878;
        ret = ioctl(m_nDriver_fd, VIDIOC_G_FMT, &fmt);
        m_sInput_buff_property.datasize=fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
        bufreq.memory = V4L2_MEMORY_USERPTR;

 if (*actual_buff_count)
            bufreq.count = *actual_buff_count;
 else
            bufreq.count = 2;

 if (metadatamode && (bufreq.count < 9)) {
            DEBUG_PRINT_LOW("FW returned buffer count = %d , overwriting with 9",
                bufreq.count);
            bufreq.count = 9;
 }
 if (m_sVenc_cfg.input_height * m_sVenc_cfg.input_width >= 3840*2160) {
            DEBUG_PRINT_LOW("Increasing buffer count = %d to 11", bufreq.count);
            bufreq.count = 11;
 } else {
            bufreq.count = 12;
 }

        bufreq.type=V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
        ret = ioctl(m_nDriver_fd,VIDIOC_REQBUFS, &bufreq);

 if (ret) {
            DEBUG_PRINT_ERROR("VIDIOC_REQBUFS OUTPUT_MPLANE Failed");
 return false;
 }

        m_sInput_buff_property.mincount = m_sInput_buff_property.actualcount = bufreq.count;
 *min_buff_count = m_sInput_buff_property.mincount;
 *actual_buff_count = m_sInput_buff_property.actualcount;
#ifdef USE_ION
        m_sInput_buff_property.datasize = ALIGN(m_sInput_buff_property.datasize, SZ_4K);
#endif
 *buff_size = m_sInput_buff_property.datasize;
 } else {
 unsigned int extra_idx = 0;
        fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
        fmt.fmt.pix_mp.height = m_sVenc_cfg.dvs_height;
        fmt.fmt.pix_mp.width = m_sVenc_cfg.dvs_width;
        fmt.fmt.pix_mp.pixelformat = m_sVenc_cfg.codectype;

        ret = ioctl(m_nDriver_fd, VIDIOC_S_FMT, &fmt);
        m_sOutput_buff_property.datasize=fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
        fmt.type = V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
        fmt.fmt.pix_mp.height = m_sVenc_cfg.dvs_height;
        fmt.fmt.pix_mp.width = m_sVenc_cfg.dvs_width;
        fmt.fmt.pix_mp.pixelformat = m_sVenc_cfg.codectype;

        ret = ioctl(m_nDriver_fd, VIDIOC_G_FMT, &fmt);
        m_sOutput_buff_property.datasize=fmt.fmt.pix_mp.plane_fmt[0].sizeimage;
        bufreq.memory = V4L2_MEMORY_USERPTR;

 if (*actual_buff_count)
            bufreq.count = *actual_buff_count;
 else
            bufreq.count = 2;

        bufreq.type=V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
        ret = ioctl(m_nDriver_fd,VIDIOC_REQBUFS, &bufreq);

 if (ret) {
            DEBUG_PRINT_ERROR("VIDIOC_REQBUFS CAPTURE_MPLANE Failed");
 return false;
 }

        m_sOutput_buff_property.mincount = m_sOutput_buff_property.actualcount = bufreq.count;
 *min_buff_count = m_sOutput_buff_property.mincount;
 *actual_buff_count = m_sOutput_buff_property.actualcount;
 *buff_size = m_sOutput_buff_property.datasize;
        num_planes = fmt.fmt.pix_mp.num_planes;
        extra_idx = EXTRADATA_IDX(num_planes);

 if (extra_idx && (extra_idx < VIDEO_MAX_PLANES)) {
            extra_data_size =  fmt.fmt.pix_mp.plane_fmt[extra_idx].sizeimage;
 } else if (extra_idx >= VIDEO_MAX_PLANES) {
            DEBUG_PRINT_ERROR("Extradata index is more than allowed: %d", extra_idx);
 return OMX_ErrorBadParameter;
 }

        extradata_info.buffer_size = extra_data_size;
        extradata_info.count = m_sOutput_buff_property.actualcount;
        extradata_info.size = extradata_info.buffer_size * extradata_info.count;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t StreamingProcessor::incrementStreamingIds() {
    ATRACE_CALL();
 Mutex::Autolock m(mMutex);

    mPreviewRequestId++;
 if (mPreviewRequestId >= Camera2Client::kPreviewRequestIdEnd) {
        mPreviewRequestId = Camera2Client::kPreviewRequestIdStart;
 }
    mRecordingRequestId++;
 if (mRecordingRequestId >= Camera2Client::kRecordingRequestIdEnd) {
        mRecordingRequestId = Camera2Client::kRecordingRequestIdStart;
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftGSM(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_cavlc_parse4x4coeff_n8(WORD16 *pi2_coeff_block,
                                     UWORD32 u4_isdc, /* is it a DC block */
                                     WORD32 u4_n,
 dec_struct_t *ps_dec,
                                     UWORD32 *pu4_total_coeff)
{

 dec_bit_stream_t *ps_bitstrm = ps_dec->ps_bitstrm;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 u4_bitstream_offset = ps_bitstrm->u4_ofst;
    UWORD32 u4_code;
    UNUSED(u4_n);
    UNUSED(pi2_coeff_block);
    GETBITS(u4_code, u4_bitstream_offset, pu4_bitstrm_buf, 6);
    ps_bitstrm->u4_ofst = u4_bitstream_offset;
 *pu4_total_coeff = 0;

 if(u4_code != 3)
 {
        UWORD8 *pu1_offset = (UWORD8 *)gau1_ih264d_total_coeff_fn_ptr_offset;
        UWORD32 u4_trailing_ones, u4_offset, u4_total_coeff_tone;

 *pu4_total_coeff = (u4_code >> 2) + 1;
        u4_trailing_ones = u4_code & 0x03;
        u4_offset = pu1_offset[*pu4_total_coeff - 1];
        u4_total_coeff_tone = (*pu4_total_coeff << 16) | u4_trailing_ones;

        ps_dec->pf_cavlc_4x4res_block[u4_offset](u4_isdc,
                                                 u4_total_coeff_tone,
                                                 ps_bitstrm);
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseName(xmlParserCtxtPtr ctxt) {
 const xmlChar *in;
 const xmlChar *ret;
 int count = 0;

    GROW;

#ifdef DEBUG
    nbParseName++;
#endif

 /*
     * Accelerator for simple ASCII names
     */
    in = ctxt->input->cur;
 if (((*in >= 0x61) && (*in <= 0x7A)) ||
 ((*in >= 0x41) && (*in <= 0x5A)) ||
 (*in == '_') || (*in == ':')) {
	in++;
 while (((*in >= 0x61) && (*in <= 0x7A)) ||
 ((*in >= 0x41) && (*in <= 0x5A)) ||
 ((*in >= 0x30) && (*in <= 0x39)) ||
 (*in == '_') || (*in == '-') ||
 (*in == ':') || (*in == '.'))
	    in++;
 if ((*in > 0) && (*in < 0x80)) {
	    count = in - ctxt->input->cur;
 if ((count > XML_MAX_NAME_LENGTH) &&
 ((ctxt->options & XML_PARSE_HUGE) == 0)) {
                xmlFatalErr(ctxt, XML_ERR_NAME_TOO_LONG, "Name");
 return(NULL);
 }
	    ret = xmlDictLookup(ctxt->dict, ctxt->input->cur, count);
	    ctxt->input->cur = in;
	    ctxt->nbChars += count;
	    ctxt->input->col += count;
 if (ret == NULL)
	        xmlErrMemory(ctxt, NULL);
 return(ret);
 }
 }
 /* accelerator for special cases */
 return(xmlParseNameComplex(ctxt));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static struct VP8D_COMP * create_decompressor(VP8D_CONFIG *oxcf)
{
    VP8D_COMP *pbi = vpx_memalign(32, sizeof(VP8D_COMP));

 if (!pbi)
 return NULL;

    memset(pbi, 0, sizeof(VP8D_COMP));

 if (setjmp(pbi->common.error.jmp))
 {
        pbi->common.error.setjmp = 0;
        remove_decompressor(pbi);
 return 0;
 }

    pbi->common.error.setjmp = 1;

    vp8_create_common(&pbi->common);

    pbi->common.current_video_frame = 0;
    pbi->ready_for_new_data = 1;

 /* vp8cx_init_de_quantizer() is first called here. Add check in frame_init_dequantizer() to avoid
     *  unnecessary calling of vp8cx_init_de_quantizer() for every frame.
     */
    vp8cx_init_de_quantizer(pbi);

    vp8_loop_filter_init(&pbi->common);

    pbi->common.error.setjmp = 0;

#if CONFIG_ERROR_CONCEALMENT
    pbi->ec_enabled = oxcf->error_concealment;
    pbi->overlaps = NULL;
#else
 (void)oxcf;
    pbi->ec_enabled = 0;
#endif
 /* Error concealment is activated after a key frame has been
     * decoded without errors when error concealment is enabled.
     */
    pbi->ec_active = 0;

    pbi->decoded_key_frame = 0;

 /* Independent partitions is activated when a frame updates the
     * token probability table to have equal probabilities over the
     * PREV_COEF context.
     */
    pbi->independent_partitions = 0;

    vp8_setup_block_dptrs(&pbi->mb);

    once(initialize_dec);

 return pbi;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_transform_png_set_@_add(image_transform *this,
    PNG_CONST image_transform **that, char *name, size_t sizeof_name,
    size_t *pos, png_byte colour_type, png_byte bit_depth)
{
   this->next = *that;
   *that = this;
   *pos = safecat(name, sizeof_name, *pos, " +@");
   return 1;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t SampleTable::setSyncSampleParams(off64_t data_offset, size_t data_size) {
 if (mSyncSampleOffset >= 0 || data_size < 8) {
 return ERROR_MALFORMED;
 }

    mSyncSampleOffset = data_offset;

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;
 }

    mNumSyncSamples = U32_AT(&header[4]);

 if (mNumSyncSamples < 2) {

         ALOGV("Table of sync samples is empty or has only a single entry!");
     }
 
    uint64_t allocSize = mNumSyncSamples * sizeof(uint32_t);
     if (allocSize > SIZE_MAX) {
         return ERROR_OUT_OF_RANGE;
     }

    mSyncSamples = new uint32_t[mNumSyncSamples];
 size_t size = mNumSyncSamples * sizeof(uint32_t);
 if (mDataSource->readAt(mSyncSampleOffset + 8, mSyncSamples, size)
 != (ssize_t)size) {
 return ERROR_IO;
 }

 for (size_t i = 0; i < mNumSyncSamples; ++i) {
        mSyncSamples[i] = ntohl(mSyncSamples[i]) - 1;
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Parcel::remove(size_t /*start*/, size_t /*amt*/)
{
    LOG_ALWAYS_FATAL("Parcel::remove() not yet implemented!");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int arg_parse_enum_or_int(const struct arg *arg) {
 if (arg->def->enums)
 return arg_parse_enum(arg);
 return arg_parse_int(arg);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::CreateBlockGroup(long long start_offset, long long size,
 long long discard_padding) {
  assert(m_entries);
  assert(m_entries_size > 0);
  assert(m_entries_count >= 0);
  assert(m_entries_count < m_entries_size);

 IMkvReader* const pReader = m_pSegment->m_pReader;

 long long pos = start_offset;
 const long long stop = start_offset + size;


 long long prev = 1; // nonce
 long long next = 0; // nonce
 long long duration = -1; // really, this is unsigned

 long long bpos = -1;
 long long bsize = -1;

 
   while (pos < stop) {
     long len;
    const long long id = ReadUInt(pReader, pos, len);
    assert(id >= 0);  // TODO
    assert((pos + len) <= stop);
 
     pos += len;  // consume ID
 
 const long long size = ReadUInt(pReader, pos, len);
    assert(size >= 0); // TODO
    assert((pos + len) <= stop);

    pos += len; // consume size

 if (id == 0x21) { // Block ID
 if (bpos < 0) { // Block ID
        bpos = pos;

         bsize = size;
       }
     } else if (id == 0x1B) {  // Duration ID
      assert(size <= 8);
 
       duration = UnserializeUInt(pReader, pos, size);
      assert(duration >= 0);  // TODO
     } else if (id == 0x7B) {  // ReferenceBlock
      assert(size <= 8);
       const long size_ = static_cast<long>(size);
 
       long long time;

 long status = UnserializeInt(pReader, pos, size_, time);
      assert(status == 0);
 if (status != 0)
 return -1;

 if (time <= 0) // see note above
        prev = time;
 else // weird
        next = time;

     }
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
  assert(pos == stop);
  assert(bpos >= 0);
   assert(bsize >= 0);
 
   const long idx = m_entries_count;

 BlockEntry** const ppEntry = m_entries + idx;
 BlockEntry*& pEntry = *ppEntry;

  pEntry = new (std::nothrow)
 BlockGroup(this, idx, bpos, bsize, prev, next, duration, discard_padding);

 if (pEntry == NULL)
 return -1; // generic error

 BlockGroup* const p = static_cast<BlockGroup*>(pEntry);

 const long status = p->Parse();

 if (status == 0) { // success
 ++m_entries_count;
 return 0;
 }

 delete pEntry;
  pEntry = 0;

 return status;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int Effect_command(effect_handle_t  self,
 uint32_t            cmdCode,
 uint32_t            cmdSize,
 void *pCmdData,
 uint32_t *replySize,
 void *pReplyData){
 EffectContext * pContext = (EffectContext *) self;
 int retsize;


 if(pContext->EffectType == LVM_BASS_BOOST){
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){
 }
 if(pContext->EffectType == LVM_EQUALIZER){
 }
 if(pContext->EffectType == LVM_VOLUME){
 }

 if (pContext == NULL){
        ALOGV("\tLVM_ERROR : Effect_command ERROR pContext == NULL");
 return -EINVAL;
 }




 switch (cmdCode){
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)){
                ALOGV("\tLVM_ERROR, EFFECT_CMD_INIT: ERROR for effect type %d",
                        pContext->EffectType);
 return -EINVAL;
 }
 *(int *) pReplyData = 0;
 if(pContext->EffectType == LVM_BASS_BOOST){
                android::BassSetStrength(pContext, 0);
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){
                android::VirtualizerSetStrength(pContext, 0);
 }
 if(pContext->EffectType == LVM_EQUALIZER){
                android::EqualizerSetPreset(pContext, 0);
 }
 if(pContext->EffectType == LVM_VOLUME){
 *(int *) pReplyData = android::VolumeSetVolumeLevel(pContext, 0);
 }
 break;

 case EFFECT_CMD_SET_CONFIG:
 if (pCmdData    == NULL || cmdSize     != sizeof(effect_config_t) ||
                    pReplyData  == NULL || replySize == NULL || *replySize  != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_SET_CONFIG: ERROR");
 return -EINVAL;
 }
 *(int *) pReplyData = android::Effect_setConfig(pContext, (effect_config_t *) pCmdData);
 break;

 case EFFECT_CMD_GET_CONFIG:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(effect_config_t)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_GET_CONFIG: ERROR");
 return -EINVAL;
 }

            android::Effect_getConfig(pContext, (effect_config_t *)pReplyData);
 break;

 case EFFECT_CMD_RESET:
            android::Effect_setConfig(pContext, &pContext->config);
 break;

 case EFFECT_CMD_GET_PARAM:{

 effect_param_t *p = (effect_param_t *)pCmdData;
 if (SIZE_MAX - sizeof(effect_param_t) < (size_t)p->psize) {
                android_errorWriteLog(0x534e4554, "26347509");
 return -EINVAL;
 }
 if (pCmdData == NULL || cmdSize < sizeof(effect_param_t) ||
                    cmdSize < (sizeof(effect_param_t) + p->psize) ||
                    pReplyData == NULL || replySize == NULL ||
 *replySize < (sizeof(effect_param_t) + p->psize)) {
                ALOGV("\tLVM_ERROR : EFFECT_CMD_GET_PARAM: ERROR");
 return -EINVAL;
 }

            memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + p->psize);

            p = (effect_param_t *)pReplyData;

 int voffset = ((p->psize - 1) / sizeof(int32_t) + 1) * sizeof(int32_t);

 if(pContext->EffectType == LVM_BASS_BOOST){
                p->status = android::BassBoost_getParameter(pContext,
                                                            p->data,
 &p->vsize,
                                                            p->data + voffset);
 }

 if(pContext->EffectType == LVM_VIRTUALIZER){
                p->status = android::Virtualizer_getParameter(pContext,
 (void *)p->data,
 &p->vsize,
                                                              p->data + voffset);

 }
 if(pContext->EffectType == LVM_EQUALIZER){
                p->status = android::Equalizer_getParameter(pContext,
                                                            p->data,
 &p->vsize,
                                                            p->data + voffset);

 }
 if(pContext->EffectType == LVM_VOLUME){
                p->status = android::Volume_getParameter(pContext,
 (void *)p->data,
 &p->vsize,
                                                         p->data + voffset);

 }
 *replySize = sizeof(effect_param_t) + voffset + p->vsize;

 } break;
 case EFFECT_CMD_SET_PARAM:{
 if(pContext->EffectType == LVM_BASS_BOOST){

 if (pCmdData   == NULL ||
                        cmdSize    != (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int16_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : BassBoost_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 if (p->psize != sizeof(int32_t)){
                    ALOGV("\tLVM_ERROR : BassBoost_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR, psize is not sizeof(int32_t)");
 return -EINVAL;
 }


 *(int *)pReplyData = android::BassBoost_setParameter(pContext,
 (void *)p->data,
                                                                    p->data + p->psize);
 }
 if(pContext->EffectType == LVM_VIRTUALIZER){

 if (pCmdData   == NULL ||
                        cmdSize    > (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int32_t)) ||
                        cmdSize    < (sizeof(effect_param_t) + sizeof(int32_t) +sizeof(int16_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Virtualizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 if (p->psize != sizeof(int32_t)){
                    ALOGV("\tLVM_ERROR : Virtualizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR, psize is not sizeof(int32_t)");
 return -EINVAL;
 }


 *(int *)pReplyData = android::Virtualizer_setParameter(pContext,
 (void *)p->data,
                                                                       p->data + p->psize);
 }
 if(pContext->EffectType == LVM_EQUALIZER){

 if (pCmdData == NULL || cmdSize < (sizeof(effect_param_t) + sizeof(int32_t)) ||
                        pReplyData == NULL || replySize == NULL || *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Equalizer_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 *(int *)pReplyData = android::Equalizer_setParameter(pContext,
 (void *)p->data,
                                                                     p->data + p->psize);
 }
 if(pContext->EffectType == LVM_VOLUME){

 if (pCmdData   == NULL ||
                        cmdSize    < (sizeof(effect_param_t) + sizeof(int32_t)) ||
                        pReplyData == NULL || replySize == NULL ||
 *replySize != sizeof(int32_t)) {
                    ALOGV("\tLVM_ERROR : Volume_command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 *(int *)pReplyData = android::Volume_setParameter(pContext,
 (void *)p->data,
                                                                 p->data + p->psize);
 }
 } break;

 case EFFECT_CMD_ENABLE:
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_ENABLE start");
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_ENABLE: ERROR");
 return -EINVAL;
 }

 *(int *)pReplyData = android::Effect_setEnabled(pContext, LVM_TRUE);
 break;

 case EFFECT_CMD_DISABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_DISABLE: ERROR");
 return -EINVAL;
 }
 *(int *)pReplyData = android::Effect_setEnabled(pContext, LVM_FALSE);
 break;

 case EFFECT_CMD_SET_DEVICE:
 {
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_SET_DEVICE start");
 if (pCmdData   == NULL){
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: EFFECT_CMD_SET_DEVICE: ERROR");
 return -EINVAL;
 }

 uint32_t device = *(uint32_t *)pCmdData;
            pContext->pBundledContext->nOutputDevice = (audio_devices_t) device;

 if (pContext->EffectType == LVM_BASS_BOOST) {
 if((device == AUDIO_DEVICE_OUT_SPEAKER) ||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_SCO_CARKIT) ||
 (device == AUDIO_DEVICE_OUT_BLUETOOTH_A2DP_SPEAKER)){
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is invalid for LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                    ALOGV("\tEFFECT_CMD_SET_DEVICE temporary disable LVM_BAS_BOOST");


 if (pContext->pBundledContext->bBassEnabled == LVM_TRUE) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE disable LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_disable(pContext);
 }
                    pContext->pBundledContext->bBassTempDisabled = LVM_TRUE;
 } else {
                    ALOGV("\tEFFECT_CMD_SET_DEVICE device is valid for LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);


 if (pContext->pBundledContext->bBassEnabled == LVM_TRUE) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE re-enable LVM_BASS_BOOST %d",
 *(int32_t *)pCmdData);
                        android::LvmEffect_enable(pContext);
 }
                    pContext->pBundledContext->bBassTempDisabled = LVM_FALSE;
 }
 }
 if (pContext->EffectType == LVM_VIRTUALIZER) {
 if (pContext->pBundledContext->nVirtualizerForcedDevice == AUDIO_DEVICE_NONE) {
 if (android::VirtualizerIsDeviceSupported(device) != 0) {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE device is invalid for LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                        ALOGV("\tEFFECT_CMD_SET_DEVICE temporary disable LVM_VIRTUALIZER");


 if (pContext->pBundledContext->bVirtualizerEnabled == LVM_TRUE) {
                            ALOGV("\tEFFECT_CMD_SET_DEVICE disable LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                            android::LvmEffect_disable(pContext);
 }
                        pContext->pBundledContext->bVirtualizerTempDisabled = LVM_TRUE;
 } else {
                        ALOGV("\tEFFECT_CMD_SET_DEVICE device is valid for LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);


 if(pContext->pBundledContext->bVirtualizerEnabled == LVM_TRUE){
                            ALOGV("\tEFFECT_CMD_SET_DEVICE re-enable LVM_VIRTUALIZER %d",
 *(int32_t *)pCmdData);
                            android::LvmEffect_enable(pContext);
 }
                        pContext->pBundledContext->bVirtualizerTempDisabled = LVM_FALSE;
 }
 } // else virtualization mode is forced to a certain device, nothing to do
 }
            ALOGV("\tEffect_command cmdCode Case: EFFECT_CMD_SET_DEVICE end");
 break;
 }
 case EFFECT_CMD_SET_VOLUME:
 {
 uint32_t leftVolume, rightVolume;
 int16_t  leftdB, rightdB;
 int16_t  maxdB, pandB;
 int32_t  vol_ret[2] = {1<<24,1<<24}; // Apply no volume
 int      status = 0;
 LVM_ControlParams_t ActiveParams; /* Current control Parameters */
            LVM_ReturnStatus_en     LvmStatus=LVM_SUCCESS; /* Function call status */

 if(pReplyData == LVM_NULL){
 break;
 }

 if (pCmdData == NULL || cmdSize != 2 * sizeof(uint32_t) || pReplyData == NULL ||
                    replySize == NULL || *replySize < 2*sizeof(int32_t)) {
                ALOGV("\tLVM_ERROR : Effect_command cmdCode Case: "
 "EFFECT_CMD_SET_VOLUME: ERROR");
 return -EINVAL;
 }

            leftVolume  = ((*(uint32_t *)pCmdData));
            rightVolume = ((*((uint32_t *)pCmdData + 1)));

 if(leftVolume == 0x1000000){
                leftVolume -= 1;
 }
 if(rightVolume == 0x1000000){
                rightVolume -= 1;
 }

            leftdB  = android::LVC_Convert_VolToDb(leftVolume);
            rightdB = android::LVC_Convert_VolToDb(rightVolume);

            pandB = rightdB - leftdB;

            maxdB = leftdB;
 if(rightdB > maxdB){
                maxdB = rightdB;
 }

            memcpy(pReplyData, vol_ret, sizeof(int32_t)*2);
            android::VolumeSetVolumeLevel(pContext, (int16_t)(maxdB*100));

 /* Get the current settings */
 LvmStatus =LVM_GetControlParameters(pContext->pBundledContext->hInstance,&ActiveParams);
            LVM_ERROR_CHECK(LvmStatus, "LVM_GetControlParameters", "VolumeSetStereoPosition")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;

 /* Volume parameters */
 ActiveParams.VC_Balance  = pandB;
            ALOGV("\t\tVolumeSetStereoPosition() (-96dB -> +96dB)-> %d\n", ActiveParams.VC_Balance );

 /* Activate the initial settings */
 LvmStatus =LVM_SetControlParameters(pContext->pBundledContext->hInstance,&ActiveParams);
            LVM_ERROR_CHECK(LvmStatus, "LVM_SetControlParameters", "VolumeSetStereoPosition")
 if(LvmStatus != LVM_SUCCESS) return -EINVAL;
 break;
 }
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;
 default:
 return -EINVAL;
 }

 return 0;
} /* end Effect_command */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static int in_remove_audio_effect(const struct audio_stream *stream,
 effect_handle_t effect)
{
    ALOGV("%s: effect %p", __func__, effect);
 return add_remove_audio_effect(stream, effect, false /* disabled */);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ASessionDescription::getDimensions(
 size_t index, unsigned long PT,
 int32_t *width, int32_t *height) const {

     *width = 0;
     *height = 0;
 
    char key[20];
    sprintf(key, "a=framesize:%lu", PT);
     AString value;
     if (!findAttribute(index, key, &value)) {
         return false;
 }

 const char *s = value.c_str();
 char *end;
 *width = strtoul(s, &end, 10);
    CHECK_GT(end, s);
    CHECK_EQ(*end, '-');

    s = end + 1;
 *height = strtoul(s, &end, 10);
    CHECK_GT(end, s);
    CHECK_EQ(*end, '\0');

 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void do_le_test_mode(char *p)
{
    bdt_le_test_mode(p);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera2Client::notifyAutoFocus(uint8_t newState, int triggerId) {
    ALOGV("%s: Autofocus state now %d, last trigger %d",
            __FUNCTION__, newState, triggerId);
 bool sendCompletedMessage = false;
 bool sendMovingMessage = false;

 bool success = false;
 bool afInMotion = false;
 {
 SharedParameters::Lock l(mParameters);
 char tmp[32];
 if (l.mParameters.afStateCounter > 0) {
            camera_metadata_enum_snprint(
                ANDROID_CONTROL_AF_STATE, l.mParameters.focusState, tmp, sizeof(tmp));
            ATRACE_ASYNC_END(tmp, l.mParameters.afStateCounter);
 }

        l.mParameters.focusState = newState;
        l.mParameters.afStateCounter++;


        camera_metadata_enum_snprint(
            ANDROID_CONTROL_AF_STATE, l.mParameters.focusState, tmp, sizeof(tmp));
        ATRACE_ASYNC_BEGIN(tmp, l.mParameters.afStateCounter);

 switch (l.mParameters.focusMode) {
 case Parameters::FOCUS_MODE_AUTO:
 case Parameters::FOCUS_MODE_MACRO:
 if (triggerId != l.mParameters.currentAfTriggerId) break;
 switch (newState) {
 case ANDROID_CONTROL_AF_STATE_FOCUSED_LOCKED:
                        success = true;
 case ANDROID_CONTROL_AF_STATE_NOT_FOCUSED_LOCKED:
                        sendCompletedMessage = true;
                        l.mParameters.currentAfTriggerId = -1;
 break;
 case ANDROID_CONTROL_AF_STATE_ACTIVE_SCAN:
 break;
 case ANDROID_CONTROL_AF_STATE_INACTIVE:
 case ANDROID_CONTROL_AF_STATE_PASSIVE_SCAN:
 case ANDROID_CONTROL_AF_STATE_PASSIVE_FOCUSED:
 case ANDROID_CONTROL_AF_STATE_PASSIVE_UNFOCUSED:
 default:
                        ALOGE("%s: Unexpected AF state transition in AUTO/MACRO mode: %d",
                                __FUNCTION__, newState);
 break;
 }
 break;
 case Parameters::FOCUS_MODE_CONTINUOUS_VIDEO:
 case Parameters::FOCUS_MODE_CONTINUOUS_PICTURE:
 switch (newState) {
 case ANDROID_CONTROL_AF_STATE_FOCUSED_LOCKED:
                        success = true;
 case ANDROID_CONTROL_AF_STATE_NOT_FOCUSED_LOCKED:
 if (triggerId != l.mParameters.currentAfTriggerId) break;
                        sendCompletedMessage = true;
                        afInMotion = false;
 if (l.mParameters.enableFocusMoveMessages &&
                                l.mParameters.afInMotion) {
                            sendMovingMessage = true;
 }
                        l.mParameters.currentAfTriggerId = -1;
 break;
 case ANDROID_CONTROL_AF_STATE_INACTIVE:
                        afInMotion = false;
 if (l.mParameters.enableFocusMoveMessages &&
                                l.mParameters.afInMotion) {
                            sendMovingMessage = true;
 }
 break;
 case ANDROID_CONTROL_AF_STATE_PASSIVE_SCAN:
                        afInMotion = true;
 case ANDROID_CONTROL_AF_STATE_PASSIVE_FOCUSED:
 case ANDROID_CONTROL_AF_STATE_PASSIVE_UNFOCUSED:
 if (l.mParameters.enableFocusMoveMessages) {
                            sendMovingMessage = true;
 }
 break;
 }
                l.mParameters.afInMotion = afInMotion;
 break;
 case Parameters::FOCUS_MODE_EDOF:
 case Parameters::FOCUS_MODE_INFINITY:
 case Parameters::FOCUS_MODE_FIXED:
 default:
 if (newState != ANDROID_CONTROL_AF_STATE_INACTIVE) {
                    ALOGE("%s: Unexpected AF state change %d "
 "(ID %d) in focus mode %d",
                          __FUNCTION__, newState, triggerId,
                            l.mParameters.focusMode);
 }
 }
 }
 if (sendMovingMessage) {
 SharedCameraCallbacks::Lock l(mSharedCameraCallbacks);
 if (l.mRemoteCallback != 0) {
            l.mRemoteCallback->notifyCallback(CAMERA_MSG_FOCUS_MOVE,
                    afInMotion ? 1 : 0, 0);
 }
 }
 if (sendCompletedMessage) {
        ATRACE_ASYNC_END(kAutofocusLabel, triggerId);
 SharedCameraCallbacks::Lock l(mSharedCameraCallbacks);
 if (l.mRemoteCallback != 0) {
            l.mRemoteCallback->notifyCallback(CAMERA_MSG_FOCUS,
                    success ? 1 : 0, 0);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::waitUntilDrainedLocked() {
 switch (mStatus) {
 case STATUS_UNINITIALIZED:
 case STATUS_UNCONFIGURED:
            ALOGV("%s: Already idle", __FUNCTION__);
 return OK;
 case STATUS_CONFIGURED:
 case STATUS_ERROR:
 case STATUS_ACTIVE:
 break;
 default:
            SET_ERR_L("Unexpected status: %d",mStatus);
 return INVALID_OPERATION;
 }

    ALOGV("%s: Camera %d: Waiting until idle", __FUNCTION__, mId);
 status_t res = waitUntilStateThenRelock(/*active*/ false, kShutdownTimeout);
 if (res != OK) {
        SET_ERR_L("Error waiting for HAL to drain: %s (%d)", strerror(-res),
                res);
 }
 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  explicit BpCrypto(const sp<IBinder> &impl)
 : BpInterface<ICrypto>(impl) {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int sysMapFD(int fd, MemMapping* pMap)
{
 off_t start;
 size_t length;
 void* memPtr;

    assert(pMap != NULL);

 if (getFileStartAndLength(fd, &start, &length) < 0)
 return -1;

    memPtr = mmap(NULL, length, PROT_READ, MAP_PRIVATE, fd, start);
 if (memPtr == MAP_FAILED) {
        LOGW("mmap(%d, R, PRIVATE, %d, %d) failed: %s\n", (int) length,
            fd, (int) start, strerror(errno));
 return -1;
 }

    pMap->addr = memPtr;

     pMap->length = length;
     pMap->range_count = 1;
     pMap->ranges = malloc(sizeof(MappedRange));
     pMap->ranges[0].addr = memPtr;
     pMap->ranges[0].length = length;
 
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: btpan_conn_t * btpan_find_conn_handle(UINT16 handle)
{
 for (int i = 0; i < MAX_PAN_CONNS; i++)
 {
 if (btpan_cb.conns[i].handle == handle)
 return &btpan_cb.conns[i];
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: display_init(struct display *dp)
 /* Call this only once right at the start to initialize the control
    * structure, the (struct buffer) lists are maintained across calls - the
    * memory is not freed.
    */
{
   memset(dp, 0, sizeof *dp);
   dp->options = WARNINGS; /* default to !verbose, !quiet */
   dp->filename = NULL;
   dp->operation = NULL;
   dp->original_pp = NULL;
   dp->original_ip = NULL;
   dp->original_rows = NULL;
   dp->read_pp = NULL;
   dp->read_ip = NULL;
   buffer_init(&dp->original_file);

#  ifdef PNG_WRITE_SUPPORTED
      dp->write_pp = NULL;
      buffer_init(&dp->written_file);
#  endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t StreamingProcessor::processRecordingFrame() {
    ATRACE_CALL();
 status_t res;
    sp<Camera2Heap> recordingHeap;
 size_t heapIdx = 0;
 nsecs_t timestamp;

    sp<Camera2Client> client = mClient.promote();
 if (client == 0) {
 BufferItem imgBuffer;
        res = mRecordingConsumer->acquireBuffer(&imgBuffer, 0);
 if (res != OK) {
 if (res != BufferItemConsumer::NO_BUFFER_AVAILABLE) {
                ALOGE("%s: Camera %d: Can't acquire recording buffer: %s (%d)",
                        __FUNCTION__, mId, strerror(-res), res);
 }
 return res;
 }
        mRecordingConsumer->releaseBuffer(imgBuffer);
 return OK;
 }

 {
 /* acquire SharedParameters before mMutex so we don't dead lock
            with Camera2Client code calling into StreamingProcessor */
 SharedParameters::Lock l(client->getParameters());
 Mutex::Autolock m(mMutex);
 BufferItem imgBuffer;
        res = mRecordingConsumer->acquireBuffer(&imgBuffer, 0);
 if (res != OK) {
 if (res != BufferItemConsumer::NO_BUFFER_AVAILABLE) {
                ALOGE("%s: Camera %d: Can't acquire recording buffer: %s (%d)",
                        __FUNCTION__, mId, strerror(-res), res);
 }
 return res;
 }
        timestamp = imgBuffer.mTimestamp;

        mRecordingFrameCount++;
        ALOGVV("OnRecordingFrame: Frame %d", mRecordingFrameCount);

 if (l.mParameters.state != Parameters::RECORD &&
                l.mParameters.state != Parameters::VIDEO_SNAPSHOT) {
            ALOGV("%s: Camera %d: Discarding recording image buffers "
 "received after recording done", __FUNCTION__,
                    mId);
            mRecordingConsumer->releaseBuffer(imgBuffer);
 return INVALID_OPERATION;
 }

 if (mRecordingHeap == 0) {
 size_t payloadSize = sizeof(VideoNativeMetadata);
            ALOGV("%s: Camera %d: Creating recording heap with %zu buffers of "
 "size %zu bytes", __FUNCTION__, mId,
                    mRecordingHeapCount, payloadSize);

            mRecordingHeap = new Camera2Heap(payloadSize, mRecordingHeapCount,
 "Camera2Client::RecordingHeap");
 if (mRecordingHeap->mHeap->getSize() == 0) {
                ALOGE("%s: Camera %d: Unable to allocate memory for recording",
                        __FUNCTION__, mId);
                mRecordingConsumer->releaseBuffer(imgBuffer);
 return NO_MEMORY;
 }
 for (size_t i = 0; i < mRecordingBuffers.size(); i++) {
 if (mRecordingBuffers[i].mBuf !=
 BufferItemConsumer::INVALID_BUFFER_SLOT) {
                    ALOGE("%s: Camera %d: Non-empty recording buffers list!",
                            __FUNCTION__, mId);
 }
 }
            mRecordingBuffers.clear();
            mRecordingBuffers.setCapacity(mRecordingHeapCount);
            mRecordingBuffers.insertAt(0, mRecordingHeapCount);

            mRecordingHeapHead = 0;
            mRecordingHeapFree = mRecordingHeapCount;
 }

 if (mRecordingHeapFree == 0) {
            ALOGE("%s: Camera %d: No free recording buffers, dropping frame",
                    __FUNCTION__, mId);
            mRecordingConsumer->releaseBuffer(imgBuffer);
 return NO_MEMORY;
 }

        heapIdx = mRecordingHeapHead;
        mRecordingHeapHead = (mRecordingHeapHead + 1) % mRecordingHeapCount;
        mRecordingHeapFree--;

        ALOGVV("%s: Camera %d: Timestamp %lld",
                __FUNCTION__, mId, timestamp);

 ssize_t offset;
 size_t size;
        sp<IMemoryHeap> heap =
                mRecordingHeap->mBuffers[heapIdx]->getMemory(&offset,
 &size);

 VideoNativeMetadata *payload = reinterpret_cast<VideoNativeMetadata*>(

             (uint8_t*)heap->getBase() + offset);
         payload->eType = kMetadataBufferTypeANWBuffer;
         payload->pBuffer = imgBuffer.mGraphicBuffer->getNativeBuffer();
         payload->nFenceFd = -1;
 
         ALOGVV("%s: Camera %d: Sending out ANWBuffer %p",
                __FUNCTION__, mId, payload->pBuffer);

        mRecordingBuffers.replaceAt(imgBuffer, heapIdx);
        recordingHeap = mRecordingHeap;
 }

 Camera2Client::SharedCameraCallbacks::Lock l(client->mSharedCameraCallbacks);
 if (l.mRemoteCallback != 0) {
        l.mRemoteCallback->dataCallbackTimestamp(timestamp,
                CAMERA_MSG_VIDEO_FRAME,
                recordingHeap->mBuffers[heapIdx]);
 } else {
        ALOGW("%s: Camera %d: Remote callback gone", __FUNCTION__, mId);
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: unsigned int arg_parse_uint(const struct arg *arg) {
 long int   rawval;
 char *endptr;

  rawval = strtol(arg->val, &endptr, 10);

 if (arg->val[0] != '\0' && endptr[0] == '\0') {
 if (rawval >= 0 && rawval <= UINT_MAX)
 return rawval;

    die("Option %s: Value %ld out of range for unsigned int\n",
        arg->name, rawval);
 }

  die("Option %s: Invalid character '%c'\n", arg->name, *endptr);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  transform_range_check(png_const_structp pp, unsigned int r, unsigned int g,
    unsigned int b, unsigned int a, unsigned int in_digitized, double in,
    unsigned int out, png_byte sample_depth, double err, double limit,
   PNG_CONST char *name, double digitization_error)
 {
    /* Compare the scaled, digitzed, values of our local calculation (in+-err)
     * with the digitized values libpng produced;  'sample_depth' is the actual
    * digitization depth of the libpng output colors (the bit depth except for
    * palette images where it is always 8.)  The check on 'err' is to detect
    * internal errors in pngvalid itself.
    */
 unsigned int max = (1U<<sample_depth)-1;
 double in_min = ceil((in-err)*max - digitization_error);
 double in_max = floor((in+err)*max + digitization_error);
 if (err > limit || !(out >= in_min && out <= in_max))
 {
 char message[256];
 size_t pos;

      pos = safecat(message, sizeof message, 0, name);
      pos = safecat(message, sizeof message, pos, " output value error: rgba(");
      pos = safecatn(message, sizeof message, pos, r);
      pos = safecat(message, sizeof message, pos, ",");
      pos = safecatn(message, sizeof message, pos, g);
      pos = safecat(message, sizeof message, pos, ",");
      pos = safecatn(message, sizeof message, pos, b);
      pos = safecat(message, sizeof message, pos, ",");
      pos = safecatn(message, sizeof message, pos, a);
      pos = safecat(message, sizeof message, pos, "): ");
      pos = safecatn(message, sizeof message, pos, out);
      pos = safecat(message, sizeof message, pos, " expected: ");
      pos = safecatn(message, sizeof message, pos, in_digitized);
      pos = safecat(message, sizeof message, pos, " (");
      pos = safecatd(message, sizeof message, pos, (in-err)*max, 3);
      pos = safecat(message, sizeof message, pos, "..");
      pos = safecatd(message, sizeof message, pos, (in+err)*max, 3);
      pos = safecat(message, sizeof message, pos, ")");

      png_error(pp, message);
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual status_t setDefaultMaxBufferCount(int bufferCount) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeInt32(bufferCount);
 status_t result = remote()->transact(SET_DEFAULT_MAX_BUFFER_COUNT, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ElementsAccessor::InitializeOncePerProcess() {
 static ElementsAccessor* accessor_array[] = {
#define ACCESSOR_ARRAY(Class, Kind, Store) new Class(#Kind),
      ELEMENTS_LIST(ACCESSOR_ARRAY)
#undef ACCESSOR_ARRAY
 };

  STATIC_ASSERT((sizeof(accessor_array) / sizeof(*accessor_array)) ==
                kElementsKindCount);

  elements_accessors_ = accessor_array;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setPriority(int32_t priority) {
 if (priority < 0) {
 return BAD_VALUE;
 }
    OMX_PARAM_U32TYPE config;
 InitOMXParams(&config);
    config.nU32 = (OMX_U32)priority;
 status_t temp = mOMX->setConfig(
            mNode, (OMX_INDEXTYPE)OMX_IndexConfigPriority,
 &config, sizeof(config));
 if (temp != OK) {
        ALOGI("codec does not support config priority (err %d)", temp);
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::~Chapters()
{
    while (m_editions_count > 0)
    {
        Edition& e = m_editions[--m_editions_count];
        e.Clear();
    }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual void BeginPassHook(unsigned int /*pass*/) {
     psnr_ = kMaxPsnr;
     nframes_ = 0;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: FLACExtractor::FLACExtractor(
 const sp<DataSource> &dataSource)
 : mDataSource(dataSource),
      mInitCheck(false)
{
    ALOGV("FLACExtractor::FLACExtractor");
    mInitCheck = init();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t getMIMEType(String8 *mimeType) {
 *mimeType = String8("");

 Parcel data, reply;
        data.writeInterfaceToken(
 IMediaHTTPConnection::getInterfaceDescriptor());

        remote()->transact(GET_MIME_TYPE, data, &reply);

 int32_t exceptionCode = reply.readExceptionCode();

 if (exceptionCode) {
 return UNKNOWN_ERROR;
 }

 *mimeType = String8(reply.readString16());

 return OK;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_pnb_mb_params(dec_state_t *ps_dec)
 {
     stream_t *ps_stream = &ps_dec->s_bit_stream;
     UWORD16 u2_mb_addr_incr;
    UWORD16 u2_total_len;
    UWORD16 u2_len;
    UWORD16 u2_mb_type;
    UWORD32 u4_next_word;
 const dec_mb_params_t *ps_dec_mb_params;
 if(impeg2d_bit_stream_nxt(ps_stream,1) == 1)
 {
        impeg2d_bit_stream_flush(ps_stream,1);

 }
 else
 {
        u2_mb_addr_incr = impeg2d_get_mb_addr_incr(ps_stream);

 if(ps_dec->u2_first_mb)
 {
 /****************************************************************/
 /* Section 6.3.17                                               */
 /* The first MB of a slice cannot be skipped                    */
 /* But the mb_addr_incr can be > 1, because at the beginning of */
 /* a slice, it indicates the offset from the last MB in the     */
 /* previous row. Hence for the first slice in a row, the        */
 /* mb_addr_incr needs to be 1.                                  */
 /****************************************************************/
 /* MB_x is set to zero whenever MB_y changes.                   */
            ps_dec->u2_mb_x = u2_mb_addr_incr - 1;
 /* For error resilience */
            ps_dec->u2_mb_x = MIN(ps_dec->u2_mb_x, (ps_dec->u2_num_horiz_mb - 1));

 /****************************************************************/
 /* mb_addr_incr is forced to 1 because in this decoder it is used */
 /* more as an indicator of the number of MBs skipped than the   */
 /* as defined by the standard (Section 6.3.17)                  */
 /****************************************************************/
            u2_mb_addr_incr = 1;
            ps_dec->u2_first_mb = 0;
 }
 else
 {
 /****************************************************************/
 /* In MPEG-2, the last MB of the row cannot be skipped and the  */
 /* mb_addr_incr cannot be such that it will take the current MB   */
 /* beyond the current row                                       */
 /* In MPEG-1, the slice could start and end anywhere and is not */
 /* restricted to a row like in MPEG-2. Hence this check should  */
 /* not be done for MPEG-1 streams.                              */
 /****************************************************************/
 if(ps_dec->u2_is_mpeg2 &&
 ((ps_dec->u2_mb_x + u2_mb_addr_incr) > ps_dec->u2_num_horiz_mb))
 {
                u2_mb_addr_incr    = ps_dec->u2_num_horiz_mb - ps_dec->u2_mb_x;
 }


            impeg2d_dec_skip_mbs(ps_dec, (UWORD16)(u2_mb_addr_incr - 1));
 }

 }
    u4_next_word = (UWORD16)impeg2d_bit_stream_nxt(ps_stream,16);
 /*-----------------------------------------------------------------------*/
 /* MB type                                                               */
 /*-----------------------------------------------------------------------*/
 {
        u2_mb_type   = ps_dec->pu2_mb_type[BITS((UWORD16)u4_next_word,15,10)];
        u2_len      = BITS(u2_mb_type,15,8);
        u2_total_len = u2_len;
        u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << u2_len);
 }
 /*-----------------------------------------------------------------------*/
 /* motion type                                                           */
 /*-----------------------------------------------------------------------*/
 {
        WORD32 i4_motion_type = ps_dec->u2_motion_type;

 if((u2_mb_type & MB_FORW_OR_BACK) &&  ps_dec->u2_read_motion_type)
 {
            ps_dec->u2_motion_type = BITS((UWORD16)u4_next_word,15,14);
            u2_total_len += MB_MOTION_TYPE_LEN;
            u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << MB_MOTION_TYPE_LEN);
            i4_motion_type     = ps_dec->u2_motion_type;

 }


 if ((u2_mb_type & MB_FORW_OR_BACK) &&
 ((i4_motion_type == 0) ||
 (i4_motion_type == 3) ||
 (i4_motion_type == 4) ||
 (i4_motion_type >= 7)))
 {
            i4_motion_type = 1;
 }

 }
 /*-----------------------------------------------------------------------*/
 /* dct type                                                              */
 /*-----------------------------------------------------------------------*/
 {
 if((u2_mb_type & MB_CODED) && ps_dec->u2_read_dct_type)
 {
            ps_dec->u2_field_dct = BIT((UWORD16)u4_next_word,15);
            u2_total_len += MB_DCT_TYPE_LEN;
            u4_next_word = (UWORD16)LSW((UWORD16)u4_next_word << MB_DCT_TYPE_LEN);
 }
 }
 /*-----------------------------------------------------------------------*/
 /* Quant scale code                                                      */
 /*-----------------------------------------------------------------------*/
 if(u2_mb_type & MB_QUANT)
 {
        UWORD16 u2_quant_scale_code;
        u2_quant_scale_code = BITS((UWORD16)u4_next_word,15,11);

        ps_dec->u1_quant_scale = (ps_dec->u2_q_scale_type) ?
            gau1_impeg2_non_linear_quant_scale[u2_quant_scale_code] : (u2_quant_scale_code << 1);
        u2_total_len += MB_QUANT_SCALE_CODE_LEN;
 }
    impeg2d_bit_stream_flush(ps_stream,u2_total_len);
 /*-----------------------------------------------------------------------*/
 /* Set the function pointers                                             */
 /*-----------------------------------------------------------------------*/
    ps_dec->u2_coded_mb    = (UWORD16)(u2_mb_type & MB_CODED);

 if(u2_mb_type & MB_BIDRECT)
 {
        UWORD16 u2_index       = (ps_dec->u2_motion_type);

        ps_dec->u2_prev_intra_mb    = 0;

         ps_dec->e_mb_pred         = BIDIRECT;
         ps_dec_mb_params = &ps_dec->ps_func_bi_direct[u2_index];
         ps_dec->s_mb_type = ps_dec_mb_params->s_mb_type;
         ps_dec_mb_params->pf_func_mb_params(ps_dec);
     }
     else if(u2_mb_type & MB_FORW_OR_BACK)
 {

        UWORD16 u2_refPic      = !(u2_mb_type & MB_MV_FORW);
        UWORD16 u2_index       = (ps_dec->u2_motion_type);
        ps_dec->u2_prev_intra_mb    = 0;

         ps_dec->e_mb_pred         = (e_pred_direction_t)u2_refPic;
         ps_dec_mb_params = &ps_dec->ps_func_forw_or_back[u2_index];
         ps_dec->s_mb_type = ps_dec_mb_params->s_mb_type;
         ps_dec_mb_params->pf_func_mb_params(ps_dec);
 
     }
 else if(u2_mb_type & MB_TYPE_INTRA)
 {
        ps_dec->u2_prev_intra_mb    = 1;
        impeg2d_dec_intra_mb(ps_dec);

 }
 else
 {
        ps_dec->u2_prev_intra_mb =0;
        ps_dec->e_mb_pred = FORW;
        ps_dec->u2_motion_type = 0;
        impeg2d_dec_0mv_coded_mb(ps_dec);
 }

 /*-----------------------------------------------------------------------*/
 /* decode cbp                                                            */
 /*-----------------------------------------------------------------------*/
 if((u2_mb_type & MB_TYPE_INTRA))
 {
        ps_dec->u2_cbp  = 0x3f;
        ps_dec->u2_prev_intra_mb    = 1;
 }
 else
 {
        ps_dec->u2_prev_intra_mb  = 0;
        ps_dec->u2_def_dc_pred[Y_LUMA] = 128 << ps_dec->u2_intra_dc_precision;
        ps_dec->u2_def_dc_pred[U_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
        ps_dec->u2_def_dc_pred[V_CHROMA] = 128 << ps_dec->u2_intra_dc_precision;
 if((ps_dec->u2_coded_mb))
 {
            UWORD16 cbpValue;
            cbpValue  = gau2_impeg2d_cbp_code[impeg2d_bit_stream_nxt(ps_stream,MB_CBP_LEN)];
            ps_dec->u2_cbp  = cbpValue & 0xFF;
            impeg2d_bit_stream_flush(ps_stream,(cbpValue >> 8) & 0x0FF);
 }
 else
 {

             ps_dec->u2_cbp  = 0;
         }
     }
 }

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: bool OMXNodeInstance::handleMessage(omx_message &msg) {
 const sp<GraphicBufferSource>& bufferSource(getGraphicBufferSource());

 
     if (msg.type == omx_message::FILL_BUFFER_DONE) {
         OMX_BUFFERHEADERTYPE *buffer =
            findBufferHeader(msg.u.extended_buffer_data.buffer);
 
         {
             Mutex::Autolock _l(mDebugLock);
            mOutputBuffersWithCodec.remove(buffer);

            CLOG_BUMPED_BUFFER(
                    FBD, WITH_STATS(FULL_BUFFER(
                            msg.u.extended_buffer_data.buffer, buffer, msg.fenceFd)));

            unbumpDebugLevel_l(kPortIndexOutput);
 }

 BufferMeta *buffer_meta =
 static_cast<BufferMeta *>(buffer->pAppPrivate);

 if (buffer->nOffset + buffer->nFilledLen < buffer->nOffset
 || buffer->nOffset + buffer->nFilledLen > buffer->nAllocLen) {
            CLOG_ERROR(onFillBufferDone, OMX_ErrorBadParameter,
                    FULL_BUFFER(NULL, buffer, msg.fenceFd));
 }
        buffer_meta->CopyFromOMX(buffer);

 if (bufferSource != NULL) {
            bufferSource->codecBufferFilled(buffer);

            msg.u.extended_buffer_data.timestamp = buffer->nTimeStamp;

         }
     } else if (msg.type == omx_message::EMPTY_BUFFER_DONE) {
         OMX_BUFFERHEADERTYPE *buffer =
            findBufferHeader(msg.u.buffer_data.buffer);
 
         {
             Mutex::Autolock _l(mDebugLock);
            mInputBuffersWithCodec.remove(buffer);

            CLOG_BUMPED_BUFFER(
                    EBD, WITH_STATS(EMPTY_BUFFER(msg.u.buffer_data.buffer, buffer, msg.fenceFd)));
 }

 if (bufferSource != NULL) {
            bufferSource->codecBufferEmptied(buffer, msg.fenceFd);
 return true;
 }
 }

 return false;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BufferQueueConsumer::attachBuffer(int* outSlot,
 const sp<android::GraphicBuffer>& buffer) {
    ATRACE_CALL();

 if (outSlot == NULL) {
        BQ_LOGE("attachBuffer(P): outSlot must not be NULL");
 return BAD_VALUE;
 } else if (buffer == NULL) {
        BQ_LOGE("attachBuffer(P): cannot attach NULL buffer");
 return BAD_VALUE;
 }

 Mutex::Autolock lock(mCore->mMutex);

 int numAcquiredBuffers = 0;
 int found = BufferQueueCore::INVALID_BUFFER_SLOT;
 for (int s = 0; s < BufferQueueDefs::NUM_BUFFER_SLOTS; ++s) {
 if (mSlots[s].mBufferState == BufferSlot::ACQUIRED) {
 ++numAcquiredBuffers;
 } else if (mSlots[s].mBufferState == BufferSlot::FREE) {
 if (found == BufferQueueCore::INVALID_BUFFER_SLOT ||
                    mSlots[s].mFrameNumber < mSlots[found].mFrameNumber) {
                found = s;
 }
 }
 }

 if (numAcquiredBuffers >= mCore->mMaxAcquiredBufferCount + 1) {
        BQ_LOGE("attachBuffer(P): max acquired buffer count reached: %d "
 "(max %d)", numAcquiredBuffers,
                mCore->mMaxAcquiredBufferCount);
 return INVALID_OPERATION;
 }
 if (found == BufferQueueCore::INVALID_BUFFER_SLOT) {
        BQ_LOGE("attachBuffer(P): could not find free buffer slot");
 return NO_MEMORY;
 }

 *outSlot = found;
    ATRACE_BUFFER_INDEX(*outSlot);
    BQ_LOGV("attachBuffer(C): returning slot %d", *outSlot);

    mSlots[*outSlot].mGraphicBuffer = buffer;
    mSlots[*outSlot].mBufferState = BufferSlot::ACQUIRED;
    mSlots[*outSlot].mAttachedByConsumer = true;
    mSlots[*outSlot].mNeedsCleanupOnRelease = false;
    mSlots[*outSlot].mFence = Fence::NO_FENCE;
    mSlots[*outSlot].mFrameNumber = 0;

    mSlots[*outSlot].mAcquireCalled = false;

 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SYSCALL_DEFINE3(getcpu, unsigned __user *, cpup, unsigned __user *, nodep,
 struct getcpu_cache __user *, unused)
{
 int err = 0;
 int cpu = raw_smp_processor_id();
 if (cpup)
		err |= put_user(cpu, cpup);
 if (nodep)
		err |= put_user(cpu_to_node(cpu), nodep);
 return err ? -EFAULT : 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::setAudioStreamType(audio_stream_type_t type)
{
    ALOGV("MediaPlayer::setAudioStreamType");
 Mutex::Autolock _l(mLock);
 if (mStreamType == type) return NO_ERROR;
 if (mCurrentState & ( MEDIA_PLAYER_PREPARED | MEDIA_PLAYER_STARTED |
                MEDIA_PLAYER_PAUSED | MEDIA_PLAYER_PLAYBACK_COMPLETE ) ) {
        ALOGE("setAudioStream called in state %d", mCurrentState);
 return INVALID_OPERATION;
 }
    mStreamType = type;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SimpleSoftOMXComponent::onMessageReceived(const sp<AMessage> &msg) {
 Mutex::Autolock autoLock(mLock);
 uint32_t msgType = msg->what();
    ALOGV("msgType = %d", msgType);
 switch (msgType) {
 case kWhatSendCommand:
 {
 int32_t cmd, param;
            CHECK(msg->findInt32("cmd", &cmd));
            CHECK(msg->findInt32("param", &param));

            onSendCommand((OMX_COMMANDTYPE)cmd, (OMX_U32)param);
 break;
 }

 case kWhatEmptyThisBuffer:
 case kWhatFillThisBuffer:
 {
            OMX_BUFFERHEADERTYPE *header;
            CHECK(msg->findPointer("header", (void **)&header));

            CHECK(mState == OMX_StateExecuting && mTargetState == mState);

 bool found = false;
 size_t portIndex = (kWhatEmptyThisBuffer == msgType)?
                    header->nInputPortIndex: header->nOutputPortIndex;
 PortInfo *port = &mPorts.editItemAt(portIndex);

 for (size_t j = 0; j < port->mBuffers.size(); ++j) {
 BufferInfo *buffer = &port->mBuffers.editItemAt(j);

 if (buffer->mHeader == header) {
                    CHECK(!buffer->mOwnedByUs);

                    buffer->mOwnedByUs = true;

                    CHECK((msgType == kWhatEmptyThisBuffer
 && port->mDef.eDir == OMX_DirInput)
 || (port->mDef.eDir == OMX_DirOutput));

                    port->mQueue.push_back(buffer);
                    onQueueFilled(portIndex);

                    found = true;
 break;
 }
 }

            CHECK(found);
 break;
 }

 default:
            TRESPASS();
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_access_unit_delimiter_rbsp(dec_struct_t * ps_dec)
{
    UWORD8 u1_primary_pic_type;
    u1_primary_pic_type = ih264d_get_bits_h264(ps_dec->ps_bitstrm, 3);
 switch(u1_primary_pic_type)
 {
 case I_PIC:
 case SI_PIC:
 case ISI_PIC:
            ps_dec->ps_dec_err_status->u1_pic_aud_i = PIC_TYPE_I;
 break;
 default:
            ps_dec->ps_dec_err_status->u1_pic_aud_i = PIC_TYPE_UNKNOWN;
 }
 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  ResizeInternalTest()
 : ResizeTest(),
        frame0_psnr_(0.0),
        outfile_(NULL),
        out_frames_(0) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int is_number(char *p)
{
 while (*p) {
 if (!isdigit(*p))
 return FALSE;
 ++p;
 }
 return TRUE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual ~FwdTrans8x8TestBase() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::emptyGraphicBuffer(
        OMX_BUFFERHEADERTYPE *header, const sp<GraphicBuffer> &graphicBuffer,
        OMX_U32 flags, OMX_TICKS timestamp, int fenceFd) {
 if (header == NULL) {
        ALOGE("b/25884056");
 return BAD_VALUE;
 }

 Mutex::Autolock autoLock(mLock);
    OMX::buffer_id buffer = findBufferID(header);
 status_t err = updateGraphicBufferInMeta_l(
            kPortIndexInput, graphicBuffer, buffer, header,
 true /* updateCodecBuffer */);
 if (err != OK) {
        CLOG_ERROR(emptyGraphicBuffer, err, FULL_BUFFER(
 (intptr_t)header->pBuffer, header, fenceFd));
 return err;
 }

    header->nOffset = 0;
 if (graphicBuffer == NULL) {
        header->nFilledLen = 0;
 } else if (mMetadataType[kPortIndexInput] == kMetadataBufferTypeGrallocSource) {
        header->nFilledLen = sizeof(VideoGrallocMetadata);
 } else {
        header->nFilledLen = sizeof(VideoNativeMetadata);
 }
 return emptyBuffer_l(header, flags, timestamp, (intptr_t)header->pBuffer, fenceFd);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_video_decode(iv_obj_t *dec_hdl, void *pv_api_ip, void *pv_api_op)
{
 /* ! */

 dec_struct_t * ps_dec = (dec_struct_t *)(dec_hdl->pv_codec_handle);

    WORD32 i4_err_status = 0;
    UWORD8 *pu1_buf = NULL;
    WORD32 buflen;
    UWORD32 u4_max_ofst, u4_length_of_start_code = 0;

    UWORD32 bytes_consumed = 0;
    UWORD32 cur_slice_is_nonref = 0;
    UWORD32 u4_next_is_aud;
    UWORD32 u4_first_start_code_found = 0;
    WORD32 ret = 0,api_ret_value = IV_SUCCESS;
    WORD32 header_data_left = 0,frame_data_left = 0;
    UWORD8 *pu1_bitstrm_buf;
 ivd_video_decode_ip_t *ps_dec_ip;
 ivd_video_decode_op_t *ps_dec_op;

    ithread_set_name((void*)"Parse_thread");

    ps_dec_ip = (ivd_video_decode_ip_t *)pv_api_ip;
    ps_dec_op = (ivd_video_decode_op_t *)pv_api_op;

 {
        UWORD32 u4_size;
        u4_size = ps_dec_op->u4_size;
        memset(ps_dec_op, 0, sizeof(ivd_video_decode_op_t));
        ps_dec_op->u4_size = u4_size;
 }

    ps_dec->pv_dec_out = ps_dec_op;
 if(ps_dec->init_done != 1)
 {
 return IV_FAIL;
 }

 /*Data memory barries instruction,so that bitstream write by the application is complete*/
    DATA_SYNC();

 if(0 == ps_dec->u1_flushfrm)
 {
 if(ps_dec_ip->pv_stream_buffer == NULL)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_FRM_BS_BUF_NULL;
 return IV_FAIL;
 }
 if(ps_dec_ip->u4_num_Bytes <= 0)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_NUMBYTES_INV;
 return IV_FAIL;

 }
 }
    ps_dec->u1_pic_decode_done = 0;

    ps_dec_op->u4_num_bytes_consumed = 0;

    ps_dec->ps_out_buffer = NULL;

 if(ps_dec_ip->u4_size
 >= offsetof(ivd_video_decode_ip_t, s_out_buffer))
        ps_dec->ps_out_buffer = &ps_dec_ip->s_out_buffer;

    ps_dec->u4_fmt_conv_cur_row = 0;

    ps_dec->u4_output_present = 0;
    ps_dec->s_disp_op.u4_error_code = 1;
    ps_dec->u4_fmt_conv_num_rows = FMT_CONV_NUM_ROWS;
 if(0 == ps_dec->u4_share_disp_buf
 && ps_dec->i4_decode_header == 0)
 {
        UWORD32 i;
 if((ps_dec->ps_out_buffer->u4_num_bufs == 0) ||
 (ps_dec->ps_out_buffer->u4_num_bufs > IVD_VIDDEC_MAX_IO_BUFFERS))
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0; i < ps_dec->ps_out_buffer->u4_num_bufs; i++)
 {
 if(ps_dec->ps_out_buffer->pu1_bufs[i] == NULL)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_dec->ps_out_buffer->u4_min_out_buf_size[i] == 0)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |=
                                IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }

 if(ps_dec->u4_total_frames_decoded >= NUM_FRAMES_LIMIT)
 {
        ps_dec_op->u4_error_code = ERROR_FRAME_LIMIT_OVER;
 return IV_FAIL;
 }

 /* ! */
    ps_dec->u4_ts = ps_dec_ip->u4_ts;

    ps_dec_op->u4_error_code = 0;
    ps_dec_op->e_pic_type = -1;
    ps_dec_op->u4_output_present = 0;
    ps_dec_op->u4_frame_decoded_flag = 0;

    ps_dec->i4_frametype = -1;
    ps_dec->i4_content_type = -1;

    ps_dec->u4_slice_start_code_found = 0;

 /* In case the deocder is not in flush mode(in shared mode),
     then decoder has to pick up a buffer to write current frame.
     Check if a frame is available in such cases */

 if(ps_dec->u1_init_dec_flag == 1 && ps_dec->u4_share_disp_buf == 1
 && ps_dec->u1_flushfrm == 0)
 {
        UWORD32 i;

        WORD32 disp_avail = 0, free_id;

 /* Check if at least one buffer is available with the codec */
 /* If not then return to application with error */
 for(i = 0; i < ps_dec->u1_pic_bufs; i++)
 {
 if(0 == ps_dec->u4_disp_buf_mapping[i]
 || 1 == ps_dec->u4_disp_buf_to_be_freed[i])
 {
                disp_avail = 1;
 break;
 }

 }

 if(0 == disp_avail)
 {
 /* If something is queued for display wait for that buffer to be returned */

            ps_dec_op->u4_error_code = IVD_DEC_REF_BUF_NULL;
            ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
 return (IV_FAIL);
 }

 while(1)
 {
 pic_buffer_t *ps_pic_buf;
            ps_pic_buf = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr, &free_id);

 if(ps_pic_buf == NULL)
 {
                UWORD32 i, display_queued = 0;

 /* check if any buffer was given for display which is not returned yet */
 for(i = 0; i < (MAX_DISP_BUFS_NEW); i++)
 {
 if(0 != ps_dec->u4_disp_buf_mapping[i])
 {
                        display_queued = 1;
 break;
 }
 }
 /* If some buffer is queued for display, then codec has to singal an error and wait
                 for that buffer to be returned.
                 If nothing is queued for display then codec has ownership of all display buffers
                 and it can reuse any of the existing buffers and continue decoding */

 if(1 == display_queued)
 {
 /* If something is queued for display wait for that buffer to be returned */
                    ps_dec_op->u4_error_code = IVD_DEC_REF_BUF_NULL;
                    ps_dec_op->u4_error_code |= (1
 << IVD_UNSUPPORTEDPARAM);
 return (IV_FAIL);
 }
 }
 else
 {
 /* If the buffer is with display, then mark it as in use and then look for a buffer again */
 if(1 == ps_dec->u4_disp_buf_mapping[free_id])
 {
                    ih264_buf_mgr_set_status(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                    free_id,
                                    BUF_MGR_IO);
 }
 else
 {
 /**
                     *  Found a free buffer for present call. Release it now.
                     *  Will be again obtained later.
                     */
                    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                          free_id,
                                          BUF_MGR_IO);
 break;
 }
 }
 }

 }

 if(ps_dec->u1_flushfrm)
 {
 if(ps_dec->u1_init_dec_flag == 0)
 {
 /*Come out of flush mode and return*/
            ps_dec->u1_flushfrm = 0;
 return (IV_FAIL);
 }



        ih264d_get_next_display_field(ps_dec, ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
 /* check output buffer size given by the application */
 if(check_app_out_buf_size(ps_dec) != IV_SUCCESS)
 {
                ps_dec_op->u4_error_code= IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return (IV_FAIL);
 }

            ps_dec->u4_fmt_conv_cur_row = 0;
            ps_dec->u4_fmt_conv_num_rows = ps_dec->s_disp_frame_info.u4_y_ht;
            ih264d_format_convert(ps_dec, &(ps_dec->s_disp_op),
                                  ps_dec->u4_fmt_conv_cur_row,
                                  ps_dec->u4_fmt_conv_num_rows);
            ps_dec->u4_fmt_conv_cur_row += ps_dec->u4_fmt_conv_num_rows;
            ps_dec->u4_output_present = 1;

 }
        ih264d_release_display_field(ps_dec, &(ps_dec->s_disp_op));

        ps_dec_op->u4_pic_wd = (UWORD32)ps_dec->u2_disp_width;
        ps_dec_op->u4_pic_ht = (UWORD32)ps_dec->u2_disp_height;

        ps_dec_op->u4_new_seq = 0;

        ps_dec_op->u4_output_present = ps_dec->u4_output_present;
        ps_dec_op->u4_progressive_frame_flag =
                        ps_dec->s_disp_op.u4_progressive_frame_flag;
        ps_dec_op->e_output_format =
                        ps_dec->s_disp_op.e_output_format;
        ps_dec_op->s_disp_frm_buf = ps_dec->s_disp_op.s_disp_frm_buf;
        ps_dec_op->e4_fld_type = ps_dec->s_disp_op.e4_fld_type;
        ps_dec_op->u4_ts = ps_dec->s_disp_op.u4_ts;
        ps_dec_op->u4_disp_buf_id = ps_dec->s_disp_op.u4_disp_buf_id;

 /*In the case of flush ,since no frame is decoded set pic type as invalid*/
        ps_dec_op->u4_is_ref_flag = -1;
        ps_dec_op->e_pic_type = IV_NA_FRAME;
        ps_dec_op->u4_frame_decoded_flag = 0;

 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
 return (IV_SUCCESS);
 }
 else
 return (IV_FAIL);

 }
 if(ps_dec->u1_res_changed == 1)
 {
 /*if resolution has changed and all buffers have been flushed, reset decoder*/
        ih264d_init_decoder(ps_dec);
 }

    ps_dec->u4_prev_nal_skipped = 0;

    ps_dec->u2_cur_mb_addr = 0;
    ps_dec->u2_total_mbs_coded = 0;
    ps_dec->u2_cur_slice_num = 0;
    ps_dec->cur_dec_mb_num = 0;
    ps_dec->cur_recon_mb_num = 0;
    ps_dec->u4_first_slice_in_pic = 1;
    ps_dec->u1_slice_header_done = 0;
    ps_dec->u1_dangling_field = 0;

    ps_dec->u4_dec_thread_created = 0;
    ps_dec->u4_bs_deblk_thread_created = 0;
    ps_dec->u4_cur_bs_mb_num = 0;
    ps_dec->u4_start_recon_deblk  = 0;
    ps_dec->u4_sps_cnt_in_process = 0;

    DEBUG_THREADS_PRINTF(" Starting process call\n");


    ps_dec->u4_pic_buf_got = 0;

 do
 {
        WORD32 buf_size;

        pu1_buf = (UWORD8*)ps_dec_ip->pv_stream_buffer
 + ps_dec_op->u4_num_bytes_consumed;

        u4_max_ofst = ps_dec_ip->u4_num_Bytes
 - ps_dec_op->u4_num_bytes_consumed;

 /* If dynamic bitstream buffer is not allocated and
         * header decode is done, then allocate dynamic bitstream buffer
         */
 if((NULL == ps_dec->pu1_bits_buf_dynamic) &&
 (ps_dec->i4_header_decoded & 1))
 {
            WORD32 size;


             void *pv_buf;
             void *pv_mem_ctxt = ps_dec->pv_mem_ctxt;
             size = MAX(256000, ps_dec->u2_pic_wd * ps_dec->u2_pic_ht * 3 / 2);
            pv_buf = ps_dec->pf_aligned_alloc(pv_mem_ctxt, 128, size);
             RETURN_IF((NULL == pv_buf), IV_FAIL);
             ps_dec->pu1_bits_buf_dynamic = pv_buf;
             ps_dec->u4_dynamic_bits_buf_size = size;
 }

 if(ps_dec->pu1_bits_buf_dynamic)
 {
            pu1_bitstrm_buf = ps_dec->pu1_bits_buf_dynamic;
            buf_size = ps_dec->u4_dynamic_bits_buf_size;
 }
 else
 {
            pu1_bitstrm_buf = ps_dec->pu1_bits_buf_static;
            buf_size = ps_dec->u4_static_bits_buf_size;
 }

        u4_next_is_aud = 0;

        buflen = ih264d_find_start_code(pu1_buf, 0, u4_max_ofst,
 &u4_length_of_start_code,
 &u4_next_is_aud);

 if(buflen == -1)
            buflen = 0;
 /* Ignore bytes beyond the allocated size of intermediate buffer */
 /* Since 8 bytes are read ahead, ensure 8 bytes are free at the
        end of the buffer, which will be memset to 0 after emulation prevention */
        buflen = MIN(buflen, buf_size - 8);

        bytes_consumed = buflen + u4_length_of_start_code;
        ps_dec_op->u4_num_bytes_consumed += bytes_consumed;

 {
            UWORD8 u1_firstbyte, u1_nal_ref_idc;

 if(ps_dec->i4_app_skip_mode == IVD_SKIP_B)
 {
                u1_firstbyte = *(pu1_buf + u4_length_of_start_code);
                u1_nal_ref_idc = (UWORD8)(NAL_REF_IDC(u1_firstbyte));
 if(u1_nal_ref_idc == 0)
 {
 /*skip non reference frames*/
                    cur_slice_is_nonref = 1;
 continue;
 }
 else
 {
 if(1 == cur_slice_is_nonref)
 {
 /*We have encountered a referenced frame,return to app*/
                        ps_dec_op->u4_num_bytes_consumed -=
                                        bytes_consumed;
                        ps_dec_op->e_pic_type = IV_B_FRAME;
                        ps_dec_op->u4_error_code =
                                        IVD_DEC_FRM_SKIPPED;
                        ps_dec_op->u4_error_code |= (1
 << IVD_UNSUPPORTEDPARAM);
                        ps_dec_op->u4_frame_decoded_flag = 0;
                        ps_dec_op->u4_size =
 sizeof(ivd_video_decode_op_t);
 /*signal the decode thread*/
                        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
                            ih264d_signal_bs_deblk_thread(ps_dec);
 }

 return (IV_FAIL);
 }
 }

 }

 }


 if(buflen)
 {
            memcpy(pu1_bitstrm_buf, pu1_buf + u4_length_of_start_code,
                   buflen);
 /* Decoder may read extra 8 bytes near end of the frame */
 if((buflen + 8) < buf_size)
 {
                memset(pu1_bitstrm_buf + buflen, 0, 8);
 }
            u4_first_start_code_found = 1;

 }
 else
 {
 /*start code not found*/

 if(u4_first_start_code_found == 0)
 {
 /*no start codes found in current process call*/

                ps_dec->i4_error_code = ERROR_START_CODE_NOT_FOUND;
                ps_dec_op->u4_error_code |= 1 << IVD_INSUFFICIENTDATA;

 if(ps_dec->u4_pic_buf_got == 0)
 {

                    ih264d_fill_output_struct_from_context(ps_dec,
                                                           ps_dec_op);

                    ps_dec_op->u4_error_code = ps_dec->i4_error_code;
                    ps_dec_op->u4_frame_decoded_flag = 0;

 return (IV_FAIL);
 }
 else
 {
                    ps_dec->u1_pic_decode_done = 1;
 continue;
 }
 }
 else
 {
 /* a start code has already been found earlier in the same process call*/
                frame_data_left = 0;
                header_data_left = 0;
 continue;
 }

 }

        ps_dec->u4_return_to_app = 0;
        ret = ih264d_parse_nal_unit(dec_hdl, ps_dec_op,
                              pu1_bitstrm_buf, buflen);
 if(ret != OK)
 {
            UWORD32 error =  ih264d_map_error(ret);
            ps_dec_op->u4_error_code = error | ret;
            api_ret_value = IV_FAIL;

 if((ret == IVD_RES_CHANGED)
 || (ret == IVD_MEM_ALLOC_FAILED)
 || (ret == ERROR_UNAVAIL_PICBUF_T)
 || (ret == ERROR_UNAVAIL_MVBUF_T)
 || (ret == ERROR_INV_SPS_PPS_T)
 || (ret == IVD_DISP_FRM_ZERO_OP_BUF_SIZE))
 {
                ps_dec->u4_slice_start_code_found = 0;
 break;
 }

 if((ret == ERROR_INCOMPLETE_FRAME) || (ret == ERROR_DANGLING_FIELD_IN_PIC))
 {
                ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
                api_ret_value = IV_FAIL;
 break;
 }

 if(ret == ERROR_IN_LAST_SLICE_OF_PIC)
 {
                api_ret_value = IV_FAIL;
 break;
 }

 }

 if(ps_dec->u4_return_to_app)
 {
 /*We have encountered a referenced frame,return to app*/
            ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
            ps_dec_op->u4_error_code = IVD_DEC_FRM_SKIPPED;
            ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
            ps_dec_op->u4_frame_decoded_flag = 0;
            ps_dec_op->u4_size = sizeof(ivd_video_decode_op_t);
 /*signal the decode thread*/
            ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
                ih264d_signal_bs_deblk_thread(ps_dec);
 }
 return (IV_FAIL);

 }



        header_data_left = ((ps_dec->i4_decode_header == 1)
 && (ps_dec->i4_header_decoded != 3)
 && (ps_dec_op->u4_num_bytes_consumed
 < ps_dec_ip->u4_num_Bytes));
        frame_data_left = (((ps_dec->i4_decode_header == 0)
 && ((ps_dec->u1_pic_decode_done == 0)
 || (u4_next_is_aud == 1)))
 && (ps_dec_op->u4_num_bytes_consumed
 < ps_dec_ip->u4_num_Bytes));
 }
 while(( header_data_left == 1)||(frame_data_left == 1));

 if((ps_dec->u4_pic_buf_got == 1)
 && (ret != IVD_MEM_ALLOC_FAILED)
 && ps_dec->u2_total_mbs_coded < ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        WORD32 num_mb_skipped;
        WORD32 prev_slice_err;
 pocstruct_t temp_poc;
        WORD32 ret1;
        WORD32 ht_in_mbs;
        ht_in_mbs = ps_dec->u2_pic_ht >> (4 + ps_dec->ps_cur_slice->u1_field_pic_flag);
        num_mb_skipped = (ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;

 if(ps_dec->u4_first_slice_in_pic && (ps_dec->u4_pic_buf_got == 0))
            prev_slice_err = 1;
 else
            prev_slice_err = 2;

 if(ps_dec->u4_first_slice_in_pic && (ps_dec->u2_total_mbs_coded == 0))
            prev_slice_err = 1;

        ret1 = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, ps_dec->u1_nal_unit_type == IDR_SLICE_NAL, ps_dec->ps_cur_slice->u2_frame_num,
 &temp_poc, prev_slice_err);

 if((ret1 == ERROR_UNAVAIL_PICBUF_T) || (ret1 == ERROR_UNAVAIL_MVBUF_T) ||
 (ret1 == ERROR_INV_SPS_PPS_T))
 {
            ret = ret1;
 }
 }

 if((ret == IVD_RES_CHANGED)
 || (ret == IVD_MEM_ALLOC_FAILED)
 || (ret == ERROR_UNAVAIL_PICBUF_T)
 || (ret == ERROR_UNAVAIL_MVBUF_T)
 || (ret == ERROR_INV_SPS_PPS_T))
 {

 /* signal the decode thread */
        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet */
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 /* dont consume bitstream for change in resolution case */
 if(ret == IVD_RES_CHANGED)
 {
            ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
 }
 return IV_FAIL;
 }


 if(ps_dec->u1_separate_parse)
 {
 /* If Format conversion is not complete,
         complete it here */
 if(ps_dec->u4_num_cores == 2)
 {

 /*do deblocking of all mbs*/
 if((ps_dec->u4_nmb_deblk == 0) &&(ps_dec->u4_start_recon_deblk == 1) && (ps_dec->ps_cur_sps->u1_mb_aff_flag == 0))
 {
                UWORD32 u4_num_mbs,u4_max_addr;
 tfr_ctxt_t s_tfr_ctxt;
 tfr_ctxt_t *ps_tfr_cxt = &s_tfr_ctxt;
 pad_mgr_t *ps_pad_mgr = &ps_dec->s_pad_mgr;

 /*BS is done for all mbs while parsing*/
                u4_max_addr = (ps_dec->u2_frm_wd_in_mbs * ps_dec->u2_frm_ht_in_mbs) - 1;
                ps_dec->u4_cur_bs_mb_num = u4_max_addr + 1;


                ih264d_init_deblk_tfr_ctxt(ps_dec, ps_pad_mgr, ps_tfr_cxt,
                                           ps_dec->u2_frm_wd_in_mbs, 0);


                u4_num_mbs = u4_max_addr
 - ps_dec->u4_cur_deblk_mb_num + 1;

                DEBUG_PERF_PRINTF("mbs left for deblocking= %d \n",u4_num_mbs);

 if(u4_num_mbs != 0)
                    ih264d_check_mb_map_deblk(ps_dec, u4_num_mbs,
                                                   ps_tfr_cxt,1);

                ps_dec->u4_start_recon_deblk  = 0;

 }

 }

 /*signal the decode thread*/
        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 }


    DATA_SYNC();


 if((ps_dec_op->u4_error_code & 0xff)
 != ERROR_DYNAMIC_RESOLUTION_NOT_SUPPORTED)
 {
        ps_dec_op->u4_pic_wd = (UWORD32)ps_dec->u2_disp_width;
        ps_dec_op->u4_pic_ht = (UWORD32)ps_dec->u2_disp_height;
 }

 if(ps_dec->i4_header_decoded != 3)
 {
        ps_dec_op->u4_error_code |= (1 << IVD_INSUFFICIENTDATA);

 }

 if(ps_dec->i4_decode_header == 1 && ps_dec->i4_header_decoded != 3)
 {
        ps_dec_op->u4_error_code |= (1 << IVD_INSUFFICIENTDATA);

 }
 if(ps_dec->u4_prev_nal_skipped)
 {
 /*We have encountered a referenced frame,return to app*/
        ps_dec_op->u4_error_code = IVD_DEC_FRM_SKIPPED;
        ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
        ps_dec_op->u4_frame_decoded_flag = 0;
        ps_dec_op->u4_size = sizeof(ivd_video_decode_op_t);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 return (IV_FAIL);

 }

 if((ps_dec->u4_pic_buf_got == 1)
 && (ERROR_DANGLING_FIELD_IN_PIC != i4_err_status))
 {
 /*
         * For field pictures, set the bottom and top picture decoded u4_flag correctly.
         */

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
 {
 if(1 == ps_dec->ps_cur_slice->u1_bottom_field_flag)
 {
                ps_dec->u1_top_bottom_decoded |= BOT_FIELD_ONLY;
 }
 else
 {
                ps_dec->u1_top_bottom_decoded |= TOP_FIELD_ONLY;
 }
 }
 else
 {
                ps_dec->u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY;
 }

 /* if new frame in not found (if we are still getting slices from previous frame)
         * ih264d_deblock_display is not called. Such frames will not be added to reference /display
         */
 if ((ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC) == 0)
 {
 /* Calling Function to deblock Picture and Display */
            ret = ih264d_deblock_display(ps_dec);
 }


 /*set to complete ,as we dont support partial frame decode*/
 if(ps_dec->i4_header_decoded == 3)
 {
            ps_dec->u2_total_mbs_coded = ps_dec->ps_cur_sps->u2_max_mb_addr + 1;
 }

 /*Update the i4_frametype at the end of picture*/
 if(ps_dec->ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL)
 {
            ps_dec->i4_frametype = IV_IDR_FRAME;
 }
 else if(ps_dec->i4_pic_type == B_SLICE)
 {
            ps_dec->i4_frametype = IV_B_FRAME;
 }
 else if(ps_dec->i4_pic_type == P_SLICE)
 {
            ps_dec->i4_frametype = IV_P_FRAME;
 }
 else if(ps_dec->i4_pic_type == I_SLICE)
 {
            ps_dec->i4_frametype = IV_I_FRAME;
 }
 else
 {
            H264_DEC_DEBUG_PRINT("Shouldn't come here\n");
 }

        ps_dec->i4_content_type = ps_dec->ps_cur_slice->u1_field_pic_flag;

        ps_dec->u4_total_frames_decoded = ps_dec->u4_total_frames_decoded + 2;
        ps_dec->u4_total_frames_decoded = ps_dec->u4_total_frames_decoded
 - ps_dec->ps_cur_slice->u1_field_pic_flag;

 }

 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
        ih264d_signal_bs_deblk_thread(ps_dec);
 }


 {
 /* In case the decoder is configured to run in low delay mode,
         * then get display buffer and then format convert.
         * Note in this mode, format conversion does not run paralelly in a thread and adds to the codec cycles
         */

 if((IVD_DECODE_FRAME_OUT == ps_dec->e_frm_out_mode)
 && ps_dec->u1_init_dec_flag)
 {

            ih264d_get_next_display_field(ps_dec, ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = 0;
                ps_dec->u4_output_present = 1;
 }
 }

        ih264d_fill_output_struct_from_context(ps_dec, ps_dec_op);

 /* If Format conversion is not complete,
         complete it here */
 if(ps_dec->u4_output_present &&
 (ps_dec->u4_fmt_conv_cur_row < ps_dec->s_disp_frame_info.u4_y_ht))
 {
            ps_dec->u4_fmt_conv_num_rows = ps_dec->s_disp_frame_info.u4_y_ht
 - ps_dec->u4_fmt_conv_cur_row;
            ih264d_format_convert(ps_dec, &(ps_dec->s_disp_op),
                                  ps_dec->u4_fmt_conv_cur_row,
                                  ps_dec->u4_fmt_conv_num_rows);
            ps_dec->u4_fmt_conv_cur_row += ps_dec->u4_fmt_conv_num_rows;
 }

        ih264d_release_display_field(ps_dec, &(ps_dec->s_disp_op));
 }

 if(ps_dec->i4_decode_header == 1 && (ps_dec->i4_header_decoded & 1) == 1)
 {
        ps_dec_op->u4_progressive_frame_flag = 1;
 if((NULL != ps_dec->ps_cur_sps) && (1 == (ps_dec->ps_cur_sps->u1_is_valid)))
 {
 if((0 == ps_dec->ps_sps->u1_frame_mbs_only_flag)
 && (0 == ps_dec->ps_sps->u1_mb_aff_flag))
                ps_dec_op->u4_progressive_frame_flag = 0;

 }
 }

 if((TOP_FIELD_ONLY | BOT_FIELD_ONLY) == ps_dec->u1_top_bottom_decoded)
 {
        ps_dec->u1_top_bottom_decoded = 0;
 }
 /*--------------------------------------------------------------------*/
 /* Do End of Pic processing.                                          */
 /* Should be called only if frame was decoded in previous process call*/
 /*--------------------------------------------------------------------*/
 if(ps_dec->u4_pic_buf_got == 1)
 {
 if(1 == ps_dec->u1_last_pic_not_decoded)
 {
            ret = ih264d_end_of_pic_dispbuf_mgr(ps_dec);

 if(ret != OK)
 return ret;

            ret = ih264d_end_of_pic(ps_dec);
 if(ret != OK)
 return ret;
 }
 else
 {
            ret = ih264d_end_of_pic(ps_dec);
 if(ret != OK)
 return ret;
 }

 }


 /*Data memory barrier instruction,so that yuv write by the library is complete*/
    DATA_SYNC();

    H264_DEC_DEBUG_PRINT("The num bytes consumed: %d\n",
                         ps_dec_op->u4_num_bytes_consumed);
 return api_ret_value;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Parcel::writeString16(const String16& str)
{
 return writeString16(str.string(), str.size());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static byte parseHexChar(char ch) {
 if (isdigit(ch))
 return ch - '0';
 else if ('A' <= ch && ch <= 'F')
 return ch - 'A' + 10;
 else if ('a' <= ch && ch <= 'f')
 return ch - 'a' + 10;
 else {
        ALOGE("invalid character in bssid %c", ch);
 return 0;
 }

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_process_pairing_public_key(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = (uint8_t*)p_data;
 uint8_t reason = SMP_INVALID_PARAMETERS;

  SMP_TRACE_DEBUG("%s", __func__);

 if (smp_command_has_invalid_parameters(p_cb)) {
    smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &reason);
 return;
 }

  STREAM_TO_ARRAY(p_cb->peer_publ_key.x, p, BT_OCTET32_LEN);
  STREAM_TO_ARRAY(p_cb->peer_publ_key.y, p, BT_OCTET32_LEN);

 Point pt;
  memcpy(pt.x, p_cb->peer_publ_key.x, BT_OCTET32_LEN);
  memcpy(pt.y, p_cb->peer_publ_key.y, BT_OCTET32_LEN);

 if (!ECC_ValidatePoint(pt)) {
    android_errorWriteLog(0x534e4554, "72377774");
    smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &reason);
 return;
 }

  p_cb->flags |= SMP_PAIR_FLAG_HAVE_PEER_PUBL_KEY;

  smp_wait_for_both_public_keys(p_cb, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeInt64(int64_t val)
{
 return writeAligned(val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_video::allocate_input_meta_buffer(
        OMX_HANDLETYPE       hComp,
        OMX_BUFFERHEADERTYPE **bufferHdr,
        OMX_PTR              appData,
        OMX_U32              bytes)
{
 unsigned index = 0;
 if (!bufferHdr || bytes < sizeof(encoder_media_buffer_type)) {
        DEBUG_PRINT_ERROR("wrong params allocate_input_meta_buffer Hdr %p len %u",
                bufferHdr, (unsigned int)bytes);
 return OMX_ErrorBadParameter;
 }

 if (!m_inp_mem_ptr && !mUseProxyColorFormat) {
        m_inp_mem_ptr = meta_buffer_hdr;
        DEBUG_PRINT_LOW("use meta_buffer_hdr (%p) as m_inp_mem_ptr = %p",
                meta_buffer_hdr, m_inp_mem_ptr);
 }
 for (index = 0; ((index < m_sInPortDef.nBufferCountActual) &&
                meta_buffer_hdr[index].pBuffer); index++);
 if (index == m_sInPortDef.nBufferCountActual) {
        DEBUG_PRINT_ERROR("All buffers are allocated input_meta_buffer");
 return OMX_ErrorBadParameter;
 }
 if (mUseProxyColorFormat) {
 if (opaque_buffer_hdr[index]) {
            DEBUG_PRINT_ERROR("All buffers are allocated opaque_buffer_hdr");
 return OMX_ErrorBadParameter;
 }
 if (allocate_input_buffer(hComp,&opaque_buffer_hdr[index],
                    PORT_INDEX_IN,appData,m_sInPortDef.nBufferSize) != OMX_ErrorNone) {
            DEBUG_PRINT_ERROR("All buffers are allocated opaque_buffer_hdr");
 return OMX_ErrorBadParameter;
 }
 }
    BITMASK_SET(&m_inp_bm_count,index);
 *bufferHdr = &meta_buffer_hdr[index];
    memset(&meta_buffer_hdr[index], 0, sizeof(meta_buffer_hdr[index]));
    meta_buffer_hdr[index].nSize = sizeof(meta_buffer_hdr[index]);
    meta_buffer_hdr[index].nAllocLen = bytes;
    meta_buffer_hdr[index].nVersion.nVersion = OMX_SPEC_VERSION;
    meta_buffer_hdr[index].nInputPortIndex = PORT_INDEX_IN;
    meta_buffer_hdr[index].pBuffer = (OMX_U8*)&meta_buffers[index];
    meta_buffer_hdr[index].pAppPrivate = appData;
 if (mUseProxyColorFormat) {
        m_opq_pmem_q.insert_entry((unsigned long)opaque_buffer_hdr[index],0,0);
        DEBUG_PRINT_HIGH("opaque_buffer_hdr insert %p", opaque_buffer_hdr[index]);
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int effect_lib_release(effect_handle_t handle)
{
 effect_context_t *context = (effect_context_t *)handle;
 int status;

 if (lib_init() != 0)
 return init_status;

    ALOGV("%s context %p", __func__, handle);
    pthread_mutex_lock(&lock);
    status = -EINVAL;
 if (effect_exists(context)) {
 output_context_t *out_ctxt = get_output(context->out_handle);
 if (out_ctxt != NULL)
            remove_effect_from_output(out_ctxt, context);
        list_remove(&context->effects_list_node);
 if (context->ops.release)
            context->ops.release(context);
        free(context);
        status = 0;
 }
    pthread_mutex_unlock(&lock);

 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void usage_exit() {
   fprintf(stderr, "Usage: %s <infile> <outfile>\n", exec_name);
   exit(EXIT_FAILURE);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_pool_delete(png_store *ps, store_pool *pool)
{
 if (pool->list != NULL)
 {
      fprintf(stderr, "%s: %s %s: memory lost (list follows):\n", ps->test,
         pool == &ps->read_memory_pool ? "read" : "write",
         pool == &ps->read_memory_pool ? (ps->current != NULL ?
            ps->current->name : "unknown file") : ps->wname);
 ++ps->nerrors;

 do
 {
         store_memory *next = pool->list;
         pool->list = next->next;

          next->next = NULL;
 
          fprintf(stderr, "\t%lu bytes @ %p\n",
             (unsigned long)next->size, (PNG_CONST void*)(next+1));
          /* The NULL means this will always return, even if the memory is
           * corrupted.
           */
         store_memory_free(NULL, pool, next);
 }
 while (pool->list != NULL);
 }

 /* And reset the other fields too for the next time. */
 if (pool->max > pool->max_max) pool->max_max = pool->max;
   pool->max = 0;
 if (pool->current != 0) /* unexpected internal error */
      fprintf(stderr, "%s: %s %s: memory counter mismatch (internal error)\n",
         ps->test, pool == &ps->read_memory_pool ? "read" : "write",
         pool == &ps->read_memory_pool ? (ps->current != NULL ?
            ps->current->name : "unknown file") : ps->wname);
   pool->current = 0;

 if (pool->limit > pool->max_limit)
      pool->max_limit = pool->limit;

   pool->limit = 0;

 if (pool->total > pool->max_total)
      pool->max_total = pool->total;

   pool->total = 0;

 /* Get a new mark too. */
   store_pool_mark(pool->mark);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void SoftVPX::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mOutputPortSettingsChange != NONE) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);
 bool EOSseen = false;

 while (!inQueue.empty() && !outQueue.empty()) {
 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
 EOSseen = true;
 if (inHeader->nFilledLen == 0) {
                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);

                outHeader->nFilledLen = 0;
                outHeader->nFlags = OMX_BUFFERFLAG_EOS;

                outQueue.erase(outQueue.begin());
                outInfo->mOwnedByUs = false;
                notifyFillBufferDone(outHeader);
 return;
 }
 }

 if (mImg == NULL) {
 if (vpx_codec_decode(
 (vpx_codec_ctx_t *)mCtx,
                        inHeader->pBuffer + inHeader->nOffset,
                        inHeader->nFilledLen,
                        NULL,
 0)) {
                ALOGE("on2 decoder failed to decode frame.");

                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 vpx_codec_iter_t iter = NULL;
            mImg = vpx_codec_get_frame((vpx_codec_ctx_t *)mCtx, &iter);

         }
 
         if (mImg != NULL) {
            CHECK_EQ(mImg->fmt, IMG_FMT_I420);
 
             uint32_t width = mImg->d_w;
             uint32_t height = mImg->d_h;
 bool portWillReset = false;
            handlePortSettingsChange(&portWillReset, width, height);
 if (portWillReset) {
 return;
 }

            outHeader->nOffset = 0;
            outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;
            outHeader->nFlags = EOSseen ? OMX_BUFFERFLAG_EOS : 0;

             outHeader->nTimeStamp = inHeader->nTimeStamp;
 
             uint8_t *dst = outHeader->pBuffer;
            const uint8_t *srcY = (const uint8_t *)mImg->planes[PLANE_Y];
            const uint8_t *srcU = (const uint8_t *)mImg->planes[PLANE_U];
            const uint8_t *srcV = (const uint8_t *)mImg->planes[PLANE_V];
            size_t srcYStride = mImg->stride[PLANE_Y];
            size_t srcUStride = mImg->stride[PLANE_U];
            size_t srcVStride = mImg->stride[PLANE_V];
             copyYV12FrameToOutputBuffer(dst, srcY, srcU, srcV, srcYStride, srcUStride, srcVStride);
 
             mImg = NULL;
            outInfo->mOwnedByUs = false;
            outQueue.erase(outQueue.begin());
            outInfo = NULL;
            notifyFillBufferDone(outHeader);
            outHeader = NULL;
 }

        inInfo->mOwnedByUs = false;
        inQueue.erase(inQueue.begin());
        inInfo = NULL;
        notifyEmptyBufferDone(inHeader);
        inHeader = NULL;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual void TearDown() {
    delete[] src_;
    delete[] ref_;
     libvpx_test::ClearSystemState();
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t OMXNodeInstance::allocateBufferWithBackup(
        OMX_U32 portIndex, const sp<IMemory> &params,
        OMX::buffer_id *buffer, OMX_U32 allottedSize) {
 Mutex::Autolock autoLock(mLock);
 if (allottedSize > params->size()) {

         return BAD_VALUE;
     }
 
    BufferMeta *buffer_meta = new BufferMeta(params, true);
 
     OMX_BUFFERHEADERTYPE *header;
 
    OMX_ERRORTYPE err = OMX_AllocateBuffer(
            mHandle, &header, portIndex, buffer_meta, allottedSize);
 if (err != OMX_ErrorNone) {
        CLOG_ERROR(allocateBufferWithBackup, err,
                SIMPLE_BUFFER(portIndex, (size_t)allottedSize, params->pointer()));
 delete buffer_meta;
        buffer_meta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, buffer_meta);

 *buffer = makeBufferID(header);

    addActiveBuffer(portIndex, *buffer);

    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && portIndex == kPortIndexInput) {
        bufferSource->addCodecBuffer(header);
 }

    CLOG_BUFFER(allocateBufferWithBackup, NEW_BUFFER_FMT(*buffer, portIndex, "%zu@%p :> %u@%p",
            params->size(), params->pointer(), allottedSize, header->pBuffer));

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: chromaticity_y(CIE_color c)
{
 return c.Y / (c.X + c.Y + c.Z);

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_parse_slice_header(codec_t *ps_codec,
 nal_header_t *ps_nal)

 {
     IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
     WORD32 value;
    WORD32 i;
     WORD32 sps_id;
 
     pps_t *ps_pps;
 sps_t *ps_sps;
 slice_header_t *ps_slice_hdr;
    WORD32 disable_deblocking_filter_flag;
 bitstrm_t *ps_bitstrm = &ps_codec->s_parse.s_bitstrm;
    WORD32 idr_pic_flag;
    WORD32 pps_id;
    WORD32 first_slice_in_pic_flag;
    WORD32 no_output_of_prior_pics_flag = 0;
    WORD8 i1_nal_unit_type = ps_nal->i1_nal_unit_type;
    WORD32 num_poc_total_curr = 0;
    WORD32 slice_address;

 if(ps_codec->i4_slice_error == 1)
 return ret;

    idr_pic_flag = (NAL_IDR_W_LP == i1_nal_unit_type) ||
 (NAL_IDR_N_LP == i1_nal_unit_type);


    BITS_PARSE("first_slice_in_pic_flag", first_slice_in_pic_flag, ps_bitstrm, 1);
 if((NAL_BLA_W_LP <= i1_nal_unit_type) &&
 (NAL_RSV_RAP_VCL23          >= i1_nal_unit_type))
 {
        BITS_PARSE("no_output_of_prior_pics_flag", no_output_of_prior_pics_flag, ps_bitstrm, 1);
 }
    UEV_PARSE("pic_parameter_set_id", pps_id, ps_bitstrm);
    pps_id = CLIP3(pps_id, 0, MAX_PPS_CNT - 2);

 /* Get the current PPS structure */
    ps_pps = ps_codec->s_parse.ps_pps_base + pps_id;
 if(0 == ps_pps->i1_pps_valid)
 {
 pps_t *ps_pps_ref = ps_codec->ps_pps_base;
 while(0 == ps_pps_ref->i1_pps_valid)
            ps_pps_ref++;

 if((ps_pps_ref - ps_codec->ps_pps_base >= MAX_PPS_CNT - 1))
 return IHEVCD_INVALID_HEADER;

        ihevcd_copy_pps(ps_codec, pps_id, ps_pps_ref->i1_pps_id);
 }

 /* Get SPS id for the current PPS */
    sps_id = ps_pps->i1_sps_id;

 /* Get the current SPS structure */
    ps_sps = ps_codec->s_parse.ps_sps_base + sps_id;

 /* When the current slice is the first in a pic,
     *  check whether the previous frame is complete
     *  If the previous frame is incomplete -
     *  treat the remaining CTBs as skip */
 if((0 != ps_codec->u4_pic_cnt || ps_codec->i4_pic_present) &&
                    first_slice_in_pic_flag)
 {
 if(ps_codec->i4_pic_present)
 {
 slice_header_t *ps_slice_hdr_next;
            ps_codec->i4_slice_error = 1;
            ps_codec->s_parse.i4_cur_slice_idx--;
 if(ps_codec->s_parse.i4_cur_slice_idx < 0)
                ps_codec->s_parse.i4_cur_slice_idx = 0;

            ps_slice_hdr_next = ps_codec->s_parse.ps_slice_hdr_base + ((ps_codec->s_parse.i4_cur_slice_idx + 1) & (MAX_SLICE_HDR_CNT - 1));
            ps_slice_hdr_next->i2_ctb_x = 0;
            ps_slice_hdr_next->i2_ctb_y = ps_codec->s_parse.ps_sps->i2_pic_ht_in_ctb;
 return ret;
 }
 else
 {
            ps_codec->i4_slice_error = 0;
 }
 }

 if(first_slice_in_pic_flag)
 {
        ps_codec->s_parse.i4_cur_slice_idx = 0;
 }
 else
 {
 /* If the current slice is not the first slice in the pic,
         * but the first one to be parsed, set the current slice indx to 1
         * Treat the first slice to be missing and copy the current slice header
         * to the first one */
 if(0 == ps_codec->i4_pic_present)
            ps_codec->s_parse.i4_cur_slice_idx = 1;
 }

    ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr_base + (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1));


 if((ps_pps->i1_dependent_slice_enabled_flag) &&
 (!first_slice_in_pic_flag))
 {
        BITS_PARSE("dependent_slice_flag", value, ps_bitstrm, 1);

 /* If dependendent slice, copy slice header from previous slice */
 if(value && (ps_codec->s_parse.i4_cur_slice_idx > 0))
 {
            ihevcd_copy_slice_hdr(ps_codec,
 (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1)),
 ((ps_codec->s_parse.i4_cur_slice_idx - 1) & (MAX_SLICE_HDR_CNT - 1)));
 }
        ps_slice_hdr->i1_dependent_slice_flag = value;
 }
 else
 {
        ps_slice_hdr->i1_dependent_slice_flag = 0;
 }
    ps_slice_hdr->i1_nal_unit_type = i1_nal_unit_type;
    ps_slice_hdr->i1_pps_id = pps_id;
    ps_slice_hdr->i1_first_slice_in_pic_flag = first_slice_in_pic_flag;

    ps_slice_hdr->i1_no_output_of_prior_pics_flag = 1;
 if((NAL_BLA_W_LP <= i1_nal_unit_type) &&
 (NAL_RSV_RAP_VCL23          >= i1_nal_unit_type))
 {
        ps_slice_hdr->i1_no_output_of_prior_pics_flag = no_output_of_prior_pics_flag;
 }
    ps_slice_hdr->i1_pps_id = pps_id;

 if(!ps_slice_hdr->i1_first_slice_in_pic_flag)
 {
        WORD32 num_bits;

 /* Use CLZ to compute Ceil( Log2( PicSizeInCtbsY ) ) */
        num_bits = 32 - CLZ(ps_sps->i4_pic_size_in_ctb - 1);
        BITS_PARSE("slice_address", value, ps_bitstrm, num_bits);

        slice_address = value;
 /* If slice address is greater than the number of CTBs in a picture,
         * ignore the slice */
 if(value >= ps_sps->i4_pic_size_in_ctb)
 return IHEVCD_IGNORE_SLICE;
 }
 else
 {
        slice_address = 0;
 }

 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
        ps_slice_hdr->i1_pic_output_flag = 1;
        ps_slice_hdr->i4_pic_order_cnt_lsb = 0;
        ps_slice_hdr->i1_num_long_term_sps = 0;
        ps_slice_hdr->i1_num_long_term_pics = 0;

 for(i = 0; i < ps_pps->i1_num_extra_slice_header_bits; i++)
 {
            BITS_PARSE("slice_reserved_undetermined_flag[ i ]", value, ps_bitstrm, 1);
 }
        UEV_PARSE("slice_type", value, ps_bitstrm);
        ps_slice_hdr->i1_slice_type = value;

 /* If the picture is IRAP, slice type must be equal to ISLICE */
 if((ps_slice_hdr->i1_nal_unit_type >= NAL_BLA_W_LP) &&
 (ps_slice_hdr->i1_nal_unit_type <= NAL_RSV_RAP_VCL23))
            ps_slice_hdr->i1_slice_type = ISLICE;

 if((ps_slice_hdr->i1_slice_type < 0) ||
 (ps_slice_hdr->i1_slice_type > 2))
 return IHEVCD_IGNORE_SLICE;

 if(ps_pps->i1_output_flag_present_flag)
 {
            BITS_PARSE("pic_output_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_pic_output_flag = value;
 }
        ps_slice_hdr->i1_colour_plane_id = 0;
 if(1 == ps_sps->i1_separate_colour_plane_flag)
 {
            BITS_PARSE("colour_plane_id", value, ps_bitstrm, 2);
            ps_slice_hdr->i1_colour_plane_id = value;
 }
        ps_slice_hdr->i1_slice_temporal_mvp_enable_flag = 0;

 if(!idr_pic_flag)
 {

            WORD32 st_rps_idx;
            WORD32 num_neg_pics;
            WORD32 num_pos_pics;
            WORD8 *pi1_used;

            BITS_PARSE("pic_order_cnt_lsb", value, ps_bitstrm, ps_sps->i1_log2_max_pic_order_cnt_lsb);
            ps_slice_hdr->i4_pic_order_cnt_lsb = value;

            BITS_PARSE("short_term_ref_pic_set_sps_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_short_term_ref_pic_set_sps_flag = value;

 if(1 == ps_slice_hdr->i1_short_term_ref_pic_set_sps_flag)
 {
                WORD32 numbits;

                ps_slice_hdr->i1_short_term_ref_pic_set_idx = 0;
 if(ps_sps->i1_num_short_term_ref_pic_sets > 1)
 {
                    numbits = 32 - CLZ(ps_sps->i1_num_short_term_ref_pic_sets - 1);
                    BITS_PARSE("short_term_ref_pic_set_idx", value, ps_bitstrm, numbits);
                    ps_slice_hdr->i1_short_term_ref_pic_set_idx = value;
 }

                st_rps_idx = ps_slice_hdr->i1_short_term_ref_pic_set_idx;
                num_neg_pics = ps_sps->as_stref_picset[st_rps_idx].i1_num_neg_pics;
                num_pos_pics = ps_sps->as_stref_picset[st_rps_idx].i1_num_pos_pics;
                pi1_used = ps_sps->as_stref_picset[st_rps_idx].ai1_used;
 }
 else
 {
                ihevcd_short_term_ref_pic_set(ps_bitstrm,
 &ps_sps->as_stref_picset[0],
                                              ps_sps->i1_num_short_term_ref_pic_sets,
                                              ps_sps->i1_num_short_term_ref_pic_sets,
 &ps_slice_hdr->s_stref_picset);

                st_rps_idx = ps_sps->i1_num_short_term_ref_pic_sets;
                num_neg_pics = ps_slice_hdr->s_stref_picset.i1_num_neg_pics;
                num_pos_pics = ps_slice_hdr->s_stref_picset.i1_num_pos_pics;
                pi1_used = ps_slice_hdr->s_stref_picset.ai1_used;
 }

 if(ps_sps->i1_long_term_ref_pics_present_flag)
 {
 if(ps_sps->i1_num_long_term_ref_pics_sps > 0)
 {
                    UEV_PARSE("num_long_term_sps", value, ps_bitstrm);
                    ps_slice_hdr->i1_num_long_term_sps = value;

                    ps_slice_hdr->i1_num_long_term_sps = CLIP3(ps_slice_hdr->i1_num_long_term_sps,
 0, MAX_DPB_SIZE - num_neg_pics - num_pos_pics);
 }
                UEV_PARSE("num_long_term_pics", value, ps_bitstrm);
                ps_slice_hdr->i1_num_long_term_pics = value;
                ps_slice_hdr->i1_num_long_term_pics = CLIP3(ps_slice_hdr->i1_num_long_term_pics,
 0, MAX_DPB_SIZE - num_neg_pics - num_pos_pics -
                                                            ps_slice_hdr->i1_num_long_term_sps);

 for(i = 0; i < (ps_slice_hdr->i1_num_long_term_sps +
                                ps_slice_hdr->i1_num_long_term_pics); i++)
 {
 if(i < ps_slice_hdr->i1_num_long_term_sps)
 {
 /* Use CLZ to compute Ceil( Log2( num_long_term_ref_pics_sps ) ) */
                        WORD32 num_bits = 32 - CLZ(ps_sps->i1_num_long_term_ref_pics_sps);
                        BITS_PARSE("lt_idx_sps[ i ]", value, ps_bitstrm, num_bits);
                        ps_slice_hdr->ai4_poc_lsb_lt[i] = ps_sps->ai1_lt_ref_pic_poc_lsb_sps[value];
                        ps_slice_hdr->ai1_used_by_curr_pic_lt_flag[i] = ps_sps->ai1_used_by_curr_pic_lt_sps_flag[value];

 }
 else
 {
                        BITS_PARSE("poc_lsb_lt[ i ]", value, ps_bitstrm, ps_sps->i1_log2_max_pic_order_cnt_lsb);
                        ps_slice_hdr->ai4_poc_lsb_lt[i] = value;

                        BITS_PARSE("used_by_curr_pic_lt_flag[ i ]", value, ps_bitstrm, 1);
                        ps_slice_hdr->ai1_used_by_curr_pic_lt_flag[i] = value;

 }
                    BITS_PARSE("delta_poc_msb_present_flag[ i ]", value, ps_bitstrm, 1);
                    ps_slice_hdr->ai1_delta_poc_msb_present_flag[i] = value;


                    ps_slice_hdr->ai1_delta_poc_msb_cycle_lt[i] = 0;
 if(ps_slice_hdr->ai1_delta_poc_msb_present_flag[i])
 {

                        UEV_PARSE("delata_poc_msb_cycle_lt[ i ]", value, ps_bitstrm);
                        ps_slice_hdr->ai1_delta_poc_msb_cycle_lt[i] = value;
 }

 if((i != 0) && (i != ps_slice_hdr->i1_num_long_term_sps))
 {
                        ps_slice_hdr->ai1_delta_poc_msb_cycle_lt[i] += ps_slice_hdr->ai1_delta_poc_msb_cycle_lt[i - 1];
 }

 }
 }

 for(i = 0; i < num_neg_pics + num_pos_pics; i++)
 {
 if(pi1_used[i])
 {
                    num_poc_total_curr++;
 }
 }
 for(i = 0; i < ps_slice_hdr->i1_num_long_term_sps + ps_slice_hdr->i1_num_long_term_pics; i++)
 {
 if(ps_slice_hdr->ai1_used_by_curr_pic_lt_flag[i])
 {
                    num_poc_total_curr++;
 }
 }


 if(ps_sps->i1_sps_temporal_mvp_enable_flag)
 {
                BITS_PARSE("enable_temporal_mvp_flag", value, ps_bitstrm, 1);
                ps_slice_hdr->i1_slice_temporal_mvp_enable_flag = value;
 }

 }
        ps_slice_hdr->i1_slice_sao_luma_flag = 0;
        ps_slice_hdr->i1_slice_sao_chroma_flag = 0;
 if(ps_sps->i1_sample_adaptive_offset_enabled_flag)
 {
            BITS_PARSE("slice_sao_luma_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_slice_sao_luma_flag = value;

            BITS_PARSE("slice_sao_chroma_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_slice_sao_chroma_flag = value;

 }

        ps_slice_hdr->i1_max_num_merge_cand = 1;
        ps_slice_hdr->i1_cabac_init_flag = 0;

        ps_slice_hdr->i1_num_ref_idx_l0_active = 0;
        ps_slice_hdr->i1_num_ref_idx_l1_active = 0;
        ps_slice_hdr->i1_slice_cb_qp_offset = 0;
        ps_slice_hdr->i1_slice_cr_qp_offset = 0;
 if((PSLICE == ps_slice_hdr->i1_slice_type) ||
 (BSLICE == ps_slice_hdr->i1_slice_type))
 {
            BITS_PARSE("num_ref_idx_active_override_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_num_ref_idx_active_override_flag = value;

 if(ps_slice_hdr->i1_num_ref_idx_active_override_flag)
 {
                UEV_PARSE("num_ref_idx_l0_active_minus1", value, ps_bitstrm);
                ps_slice_hdr->i1_num_ref_idx_l0_active = value + 1;

 if(BSLICE == ps_slice_hdr->i1_slice_type)
 {
                    UEV_PARSE("num_ref_idx_l1_active_minus1", value, ps_bitstrm);
                    ps_slice_hdr->i1_num_ref_idx_l1_active = value + 1;
 }

 }
 else
 {
                ps_slice_hdr->i1_num_ref_idx_l0_active = ps_pps->i1_num_ref_idx_l0_default_active;

 if(BSLICE == ps_slice_hdr->i1_slice_type)
 {
                    ps_slice_hdr->i1_num_ref_idx_l1_active = ps_pps->i1_num_ref_idx_l1_default_active;
 }
 }

            ps_slice_hdr->i1_num_ref_idx_l0_active = CLIP3(ps_slice_hdr->i1_num_ref_idx_l0_active, 0, MAX_DPB_SIZE - 1);
            ps_slice_hdr->i1_num_ref_idx_l1_active = CLIP3(ps_slice_hdr->i1_num_ref_idx_l1_active, 0, MAX_DPB_SIZE - 1);

 if(0 == num_poc_total_curr)
 return IHEVCD_IGNORE_SLICE;
 if((ps_pps->i1_lists_modification_present_flag) && (num_poc_total_curr > 1))
 {
                ihevcd_ref_pic_list_modification(ps_bitstrm,
                                                 ps_slice_hdr, num_poc_total_curr);
 }
 else
 {
                ps_slice_hdr->s_rplm.i1_ref_pic_list_modification_flag_l0 = 0;
                ps_slice_hdr->s_rplm.i1_ref_pic_list_modification_flag_l1 = 0;
 }

 if(BSLICE == ps_slice_hdr->i1_slice_type)
 {
                BITS_PARSE("mvd_l1_zero_flag", value, ps_bitstrm, 1);
                ps_slice_hdr->i1_mvd_l1_zero_flag = value;
 }

            ps_slice_hdr->i1_cabac_init_flag = 0;
 if(ps_pps->i1_cabac_init_present_flag)
 {
                BITS_PARSE("cabac_init_flag", value, ps_bitstrm, 1);
                ps_slice_hdr->i1_cabac_init_flag = value;

 }
            ps_slice_hdr->i1_collocated_from_l0_flag = 1;
            ps_slice_hdr->i1_collocated_ref_idx = 0;
 if(ps_slice_hdr->i1_slice_temporal_mvp_enable_flag)
 {
 if(BSLICE == ps_slice_hdr->i1_slice_type)
 {
                    BITS_PARSE("collocated_from_l0_flag", value, ps_bitstrm, 1);
                    ps_slice_hdr->i1_collocated_from_l0_flag = value;
 }

 if((ps_slice_hdr->i1_collocated_from_l0_flag  && (ps_slice_hdr->i1_num_ref_idx_l0_active > 1)) ||
 (!ps_slice_hdr->i1_collocated_from_l0_flag  && (ps_slice_hdr->i1_num_ref_idx_l1_active > 1)))
 {
                    UEV_PARSE("collocated_ref_idx", value, ps_bitstrm);
                    ps_slice_hdr->i1_collocated_ref_idx = value;
 }

 }
            ps_slice_hdr->i1_collocated_ref_idx = CLIP3(ps_slice_hdr->i1_collocated_ref_idx, 0, MAX_DPB_SIZE - 1);

 if((ps_pps->i1_weighted_pred_flag  && (PSLICE == ps_slice_hdr->i1_slice_type)) ||
 (ps_pps->i1_weighted_bipred_flag  && (BSLICE == ps_slice_hdr->i1_slice_type)))
 {
                ihevcd_parse_pred_wt_ofst(ps_bitstrm, ps_sps, ps_pps, ps_slice_hdr);
 }
            UEV_PARSE("five_minus_max_num_merge_cand", value, ps_bitstrm);
            ps_slice_hdr->i1_max_num_merge_cand = 5 - value;

 }
        ps_slice_hdr->i1_max_num_merge_cand = CLIP3(ps_slice_hdr->i1_max_num_merge_cand, 1, 5);
        SEV_PARSE("slice_qp_delta", value, ps_bitstrm);
        ps_slice_hdr->i1_slice_qp_delta = value;

 if(ps_pps->i1_pic_slice_level_chroma_qp_offsets_present_flag)
 {
            SEV_PARSE("slice_cb_qp_offset", value, ps_bitstrm);
            ps_slice_hdr->i1_slice_cb_qp_offset = value;

            SEV_PARSE("slice_cr_qp_offset", value, ps_bitstrm);
            ps_slice_hdr->i1_slice_cr_qp_offset = value;

 }
        ps_slice_hdr->i1_deblocking_filter_override_flag = 0;
        ps_slice_hdr->i1_slice_disable_deblocking_filter_flag  = ps_pps->i1_pic_disable_deblocking_filter_flag;
        ps_slice_hdr->i1_beta_offset_div2 = ps_pps->i1_beta_offset_div2;
        ps_slice_hdr->i1_tc_offset_div2 = ps_pps->i1_tc_offset_div2;

        disable_deblocking_filter_flag = ps_pps->i1_pic_disable_deblocking_filter_flag;

 if(ps_pps->i1_deblocking_filter_control_present_flag)
 {

 if(ps_pps->i1_deblocking_filter_override_enabled_flag)
 {
                BITS_PARSE("deblocking_filter_override_flag", value, ps_bitstrm, 1);
                ps_slice_hdr->i1_deblocking_filter_override_flag = value;
 }

 if(ps_slice_hdr->i1_deblocking_filter_override_flag)
 {
                BITS_PARSE("slice_disable_deblocking_filter_flag", value, ps_bitstrm, 1);
                ps_slice_hdr->i1_slice_disable_deblocking_filter_flag = value;
                disable_deblocking_filter_flag = ps_slice_hdr->i1_slice_disable_deblocking_filter_flag;

 if(!ps_slice_hdr->i1_slice_disable_deblocking_filter_flag)
 {
                    SEV_PARSE("beta_offset_div2", value, ps_bitstrm);
                    ps_slice_hdr->i1_beta_offset_div2 = value;

                    SEV_PARSE("tc_offset_div2", value, ps_bitstrm);
                    ps_slice_hdr->i1_tc_offset_div2 = value;

 }
 }
 }

        ps_slice_hdr->i1_slice_loop_filter_across_slices_enabled_flag = ps_pps->i1_loop_filter_across_slices_enabled_flag;
 if(ps_pps->i1_loop_filter_across_slices_enabled_flag  &&
 (ps_slice_hdr->i1_slice_sao_luma_flag  ||  ps_slice_hdr->i1_slice_sao_chroma_flag  || !disable_deblocking_filter_flag))
 {
            BITS_PARSE("slice_loop_filter_across_slices_enabled_flag", value, ps_bitstrm, 1);
            ps_slice_hdr->i1_slice_loop_filter_across_slices_enabled_flag = value;
 }

 }

 /* Check sanity of slice */
 if((!first_slice_in_pic_flag) &&
 (ps_codec->i4_pic_present))
 {
 slice_header_t *ps_slice_hdr_base = ps_codec->ps_slice_hdr_base;


 /* According to the standard, the above conditions must be satisfied - But for error resilience,
         * only the following conditions are checked */
 if((ps_slice_hdr_base->i1_pps_id != ps_slice_hdr->i1_pps_id) ||
 (ps_slice_hdr_base->i4_pic_order_cnt_lsb != ps_slice_hdr->i4_pic_order_cnt_lsb))
 {
 return IHEVCD_IGNORE_SLICE;
 }

 }


 if(0 == ps_codec->i4_pic_present)
 {
        ps_slice_hdr->i4_abs_pic_order_cnt = ihevcd_calc_poc(ps_codec, ps_nal, ps_sps->i1_log2_max_pic_order_cnt_lsb, ps_slice_hdr->i4_pic_order_cnt_lsb);
 }
 else
 {
        ps_slice_hdr->i4_abs_pic_order_cnt = ps_codec->s_parse.i4_abs_pic_order_cnt;
 }


 if(!first_slice_in_pic_flag)
 {
 /* Check if the current slice belongs to the same pic (Pic being parsed) */
 if(ps_codec->s_parse.i4_abs_pic_order_cnt == ps_slice_hdr->i4_abs_pic_order_cnt)
 {

 /* If the Next CTB's index is less than the slice address,
             * the previous slice is incomplete.
             * Indicate slice error, and treat the remaining CTBs as skip */
 if(slice_address > ps_codec->s_parse.i4_next_ctb_indx)
 {
 if(ps_codec->i4_pic_present)
 {
                    ps_codec->i4_slice_error = 1;
                    ps_codec->s_parse.i4_cur_slice_idx--;
 if(ps_codec->s_parse.i4_cur_slice_idx < 0)
                        ps_codec->s_parse.i4_cur_slice_idx = 0;

 return ret;
 }
 else
 {
 return IHEVCD_IGNORE_SLICE;
 }
 }
 /* If the slice address is less than the next CTB's index,
             * extra CTBs have been decoded in the previous slice.
             * Ignore the current slice. Treat it as incomplete */
 else if(slice_address < ps_codec->s_parse.i4_next_ctb_indx)
 {
 return IHEVCD_IGNORE_SLICE;
 }
 else
 {
                ps_codec->i4_slice_error = 0;
 }
 }

 /* The current slice does not belong to the pic that is being parsed */
 else
 {
 /* The previous pic is incomplete.
             * Treat the remaining CTBs as skip */
 if(ps_codec->i4_pic_present)
 {
 slice_header_t *ps_slice_hdr_next;
                ps_codec->i4_slice_error = 1;
                ps_codec->s_parse.i4_cur_slice_idx--;
 if(ps_codec->s_parse.i4_cur_slice_idx < 0)
                    ps_codec->s_parse.i4_cur_slice_idx = 0;

                ps_slice_hdr_next = ps_codec->s_parse.ps_slice_hdr_base + ((ps_codec->s_parse.i4_cur_slice_idx + 1) & (MAX_SLICE_HDR_CNT - 1));
                ps_slice_hdr_next->i2_ctb_x = 0;
                ps_slice_hdr_next->i2_ctb_y = ps_codec->s_parse.ps_sps->i2_pic_ht_in_ctb;
 return ret;
 }

 /* If the previous pic is complete,
             * return if the current slice is dependant
             * otherwise, update the parse context's POC */
 else
 {
 if(ps_slice_hdr->i1_dependent_slice_flag)
 return IHEVCD_IGNORE_SLICE;

                ps_codec->s_parse.i4_abs_pic_order_cnt = ps_slice_hdr->i4_abs_pic_order_cnt;
 }
 }
 }

 /* If the slice is the first slice in the pic, update the parse context's POC */
 else
 {
 /* If the first slice is repeated, ignore the second occurrence
         * If any other slice is repeated, the CTB addr will be greater than the slice addr,
         * and hence the second occurrence is ignored */
 if(ps_codec->s_parse.i4_abs_pic_order_cnt == ps_slice_hdr->i4_abs_pic_order_cnt)
 return IHEVCD_IGNORE_SLICE;

        ps_codec->s_parse.i4_abs_pic_order_cnt = ps_slice_hdr->i4_abs_pic_order_cnt;
 }

    ps_slice_hdr->i4_num_entry_point_offsets = 0;
 if((ps_pps->i1_tiles_enabled_flag) ||
 (ps_pps->i1_entropy_coding_sync_enabled_flag))
 {
        UEV_PARSE("num_entry_point_offsets", value, ps_bitstrm);
        ps_slice_hdr->i4_num_entry_point_offsets = value;

 {
            WORD32 max_num_entry_point_offsets;
 if((ps_pps->i1_tiles_enabled_flag) &&
 (ps_pps->i1_entropy_coding_sync_enabled_flag))
 {
                max_num_entry_point_offsets = ps_pps->i1_num_tile_columns * (ps_sps->i2_pic_ht_in_ctb - 1);
 }
 else if(ps_pps->i1_tiles_enabled_flag)
 {
                max_num_entry_point_offsets = ps_pps->i1_num_tile_columns * ps_pps->i1_num_tile_rows;
 }
 else
 {
                max_num_entry_point_offsets = (ps_sps->i2_pic_ht_in_ctb - 1);
 }

            ps_slice_hdr->i4_num_entry_point_offsets = CLIP3(ps_slice_hdr->i4_num_entry_point_offsets,
 0, max_num_entry_point_offsets);
 }

 if(ps_slice_hdr->i4_num_entry_point_offsets > 0)
 {
            UEV_PARSE("offset_len_minus1", value, ps_bitstrm);
            ps_slice_hdr->i1_offset_len = value + 1;

 for(i = 0; i < ps_slice_hdr->i4_num_entry_point_offsets; i++)
 {
                BITS_PARSE("entry_point_offset", value, ps_bitstrm, ps_slice_hdr->i1_offset_len);

 /* TODO: pu4_entry_point_offset needs to be initialized */
 }

 }
 }

 if(ps_pps->i1_slice_header_extension_present_flag)
 {
        UEV_PARSE("slice_header_extension_length", value, ps_bitstrm);
        ps_slice_hdr->i2_slice_header_extension_length = value;


 for(i = 0; i < ps_slice_hdr->i2_slice_header_extension_length; i++)
 {
            BITS_PARSE("slice_header_extension_data_byte", value, ps_bitstrm, 8);
 }

 }

    ihevcd_bits_flush_to_byte_boundary(ps_bitstrm);

 {
 dpb_mgr_t *ps_dpb_mgr = (dpb_mgr_t *)ps_codec->pv_dpb_mgr;
        WORD32 r_idx;

 if((NAL_IDR_W_LP == ps_slice_hdr->i1_nal_unit_type) ||
 (NAL_IDR_N_LP == ps_slice_hdr->i1_nal_unit_type) ||
 (NAL_BLA_N_LP == ps_slice_hdr->i1_nal_unit_type) ||
 (NAL_BLA_W_DLP == ps_slice_hdr->i1_nal_unit_type) ||
 (NAL_BLA_W_LP == ps_slice_hdr->i1_nal_unit_type) ||
 (0 == ps_codec->u4_pic_cnt))
 {
 for(i = 0; i < MAX_DPB_BUFS; i++)
 {
 if(ps_dpb_mgr->as_dpb_info[i].ps_pic_buf)
 {
 pic_buf_t *ps_pic_buf = ps_dpb_mgr->as_dpb_info[i].ps_pic_buf;
 mv_buf_t *ps_mv_buf;

 /* Long term index is set to MAX_DPB_BUFS to ensure it is not added as LT */

                     ihevc_dpb_mgr_del_ref((dpb_mgr_t *)ps_codec->pv_dpb_mgr, (buf_mgr_t *)ps_codec->pv_pic_buf_mgr, ps_pic_buf->i4_abs_poc);
                     /* Find buffer id of the MV bank corresponding to the buffer being freed (Buffer with POC of u4_abs_poc) */
                     ps_mv_buf = (mv_buf_t *)ps_codec->ps_mv_buf;
                    for(i = 0; i < BUF_MGR_MAX_CNT; i++)
                     {
                         if(ps_mv_buf && ps_mv_buf->i4_abs_poc == ps_pic_buf->i4_abs_poc)
                         {
                            ihevc_buf_mgr_release((buf_mgr_t *)ps_codec->pv_mv_buf_mgr, i, BUF_MGR_REF);
                             break;
                         }
                         ps_mv_buf++;
 }

 }

 }

 /* Initialize the reference lists to NULL
             * This is done to take care of the cases where the first pic is not IDR
             * but the reference list is not created for the first pic because
             * pic count is zero leaving the reference list uninitialised  */
 for(r_idx = 0; r_idx < MAX_DPB_SIZE; r_idx++)
 {
                ps_slice_hdr->as_ref_pic_list0[r_idx].pv_pic_buf = NULL;
                ps_slice_hdr->as_ref_pic_list0[r_idx].pv_mv_buf = NULL;

                ps_slice_hdr->as_ref_pic_list1[r_idx].pv_pic_buf = NULL;
                ps_slice_hdr->as_ref_pic_list1[r_idx].pv_mv_buf = NULL;
 }

 }
 else
 {
            ret = ihevcd_ref_list(ps_codec, ps_pps, ps_sps, ps_slice_hdr);
 if ((WORD32)IHEVCD_SUCCESS != ret)
 {
 return ret;
 }

 }

 }

 /* Fill the remaining entries of the reference lists with the nearest POC
     * This is done to handle cases where there is a corruption in the reference index */
 if(ps_codec->i4_pic_present)
 {
 pic_buf_t *ps_pic_buf_ref;
 mv_buf_t *ps_mv_buf_ref;
        WORD32 r_idx;
 dpb_mgr_t *ps_dpb_mgr = (dpb_mgr_t *)ps_codec->pv_dpb_mgr;
 buf_mgr_t *ps_mv_buf_mgr = (buf_mgr_t *)ps_codec->pv_mv_buf_mgr;

        ps_pic_buf_ref = ihevc_dpb_mgr_get_ref_by_nearest_poc(ps_dpb_mgr, ps_slice_hdr->i4_abs_pic_order_cnt);
 if(NULL == ps_pic_buf_ref)
 {
            ps_pic_buf_ref = ps_codec->as_process[0].ps_cur_pic;
            ps_mv_buf_ref = ps_codec->s_parse.ps_cur_mv_buf;
 }
 else
 {
            ps_mv_buf_ref = ihevcd_mv_mgr_get_poc(ps_mv_buf_mgr, ps_pic_buf_ref->i4_abs_poc);
 }

 for(r_idx = 0; r_idx < ps_slice_hdr->i1_num_ref_idx_l0_active; r_idx++)
 {
 if(NULL == ps_slice_hdr->as_ref_pic_list0[r_idx].pv_pic_buf)
 {
                ps_slice_hdr->as_ref_pic_list0[r_idx].pv_pic_buf = (void *)ps_pic_buf_ref;
                ps_slice_hdr->as_ref_pic_list0[r_idx].pv_mv_buf = (void *)ps_mv_buf_ref;
 }
 }

 for(r_idx = ps_slice_hdr->i1_num_ref_idx_l0_active; r_idx < MAX_DPB_SIZE; r_idx++)
 {
            ps_slice_hdr->as_ref_pic_list0[r_idx].pv_pic_buf = (void *)ps_pic_buf_ref;
            ps_slice_hdr->as_ref_pic_list0[r_idx].pv_mv_buf = (void *)ps_mv_buf_ref;
 }

 for(r_idx = 0; r_idx < ps_slice_hdr->i1_num_ref_idx_l1_active; r_idx++)
 {
 if(NULL == ps_slice_hdr->as_ref_pic_list1[r_idx].pv_pic_buf)
 {
                ps_slice_hdr->as_ref_pic_list1[r_idx].pv_pic_buf = (void *)ps_pic_buf_ref;
                ps_slice_hdr->as_ref_pic_list1[r_idx].pv_mv_buf = (void *)ps_mv_buf_ref;
 }
 }

 for(r_idx = ps_slice_hdr->i1_num_ref_idx_l1_active; r_idx < MAX_DPB_SIZE; r_idx++)
 {
            ps_slice_hdr->as_ref_pic_list1[r_idx].pv_pic_buf = (void *)ps_pic_buf_ref;
            ps_slice_hdr->as_ref_pic_list1[r_idx].pv_mv_buf = (void *)ps_mv_buf_ref;
 }
 }

 /* Update slice address in the header */
 if(!ps_slice_hdr->i1_first_slice_in_pic_flag)
 {
        ps_slice_hdr->i2_ctb_x = slice_address % ps_sps->i2_pic_wd_in_ctb;
        ps_slice_hdr->i2_ctb_y = slice_address / ps_sps->i2_pic_wd_in_ctb;

 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
            ps_slice_hdr->i2_independent_ctb_x = ps_slice_hdr->i2_ctb_x;
            ps_slice_hdr->i2_independent_ctb_y = ps_slice_hdr->i2_ctb_y;
 }
 }
 else
 {
        ps_slice_hdr->i2_ctb_x = 0;
        ps_slice_hdr->i2_ctb_y = 0;

        ps_slice_hdr->i2_independent_ctb_x = 0;
        ps_slice_hdr->i2_independent_ctb_y = 0;
 }

 /* If the first slice in the pic is missing, copy the current slice header to
     * the first slice's header */
 if((!first_slice_in_pic_flag) &&
 (0 == ps_codec->i4_pic_present))
 {
 slice_header_t *ps_slice_hdr_prev = ps_codec->s_parse.ps_slice_hdr_base;
        ihevcd_copy_slice_hdr(ps_codec, 0, (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1)));

        ps_codec->i4_slice_error = 1;

        ps_slice_hdr_prev->i2_ctb_x = 0;
        ps_slice_hdr_prev->i2_ctb_y = 0;

        ps_codec->s_parse.i4_ctb_x = 0;
        ps_codec->s_parse.i4_ctb_y = 0;

        ps_codec->s_parse.i4_cur_slice_idx = 0;

 if((ps_slice_hdr->i2_ctb_x == 0) &&
 (ps_slice_hdr->i2_ctb_y == 0))
 {
            ps_slice_hdr->i2_ctb_x++;
 }
 }

 {
 /* If skip B is enabled,
         * ignore pictures that are non-reference
         * TODO: (i1_nal_unit_type < NAL_BLA_W_LP) && (i1_nal_unit_type % 2 == 0) only says it is
         * sub-layer non-reference slice. May need to find a way to detect actual non-reference pictures*/

 if((i1_nal_unit_type < NAL_BLA_W_LP) &&
 (i1_nal_unit_type % 2 == 0))
 {
 if(IVD_SKIP_B == ps_codec->e_pic_skip_mode)
 return IHEVCD_IGNORE_SLICE;
 }

 /* If skip PB is enabled,
         * decode only I slices */
 if((IVD_SKIP_PB == ps_codec->e_pic_skip_mode) &&
 (ISLICE != ps_slice_hdr->i1_slice_type))
 {
 return IHEVCD_IGNORE_SLICE;
 }
 }

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void bta_hl_co_put_rx_data (UINT8 app_id, tBTA_HL_MDL_HANDLE mdl_handle,
                            UINT16 data_size, UINT8 *p_data, UINT16 evt)
{
    UINT8 app_idx, mcl_idx, mdl_idx;
 btif_hl_mdl_cb_t *p_dcb;
    tBTA_HL_STATUS status = BTA_HL_STATUS_FAIL;
 int            r;
    BTIF_TRACE_DEBUG("%s app_id=%d mdl_handle=0x%x data_size=%d",
                      __FUNCTION__,app_id, mdl_handle, data_size);

 if (btif_hl_find_mdl_idx_using_handle(mdl_handle, &app_idx, &mcl_idx, &mdl_idx))
 {
        p_dcb = BTIF_HL_GET_MDL_CB_PTR(app_idx, mcl_idx, mdl_idx);

 if ((p_dcb->p_rx_pkt = (UINT8 *)btif_hl_get_buf(data_size)) != NULL)
 {
            memcpy(p_dcb->p_rx_pkt, p_data, data_size);
 if (p_dcb->p_scb)

             {
                 BTIF_TRACE_DEBUG("app_idx=%d mcl_idx=0x%x mdl_idx=0x%x data_size=%d",
                                   app_idx, mcl_idx, mdl_idx, data_size);
                r = send(p_dcb->p_scb->socket_id[1], p_dcb->p_rx_pkt, data_size, 0);
 
                 if (r == data_size)
                 {
                    BTIF_TRACE_DEBUG("socket send success data_size=%d",  data_size);
                    status = BTA_HL_STATUS_OK;
 }
 else
 {
                    BTIF_TRACE_ERROR("socket send failed r=%d data_size=%d",r, data_size);
 }


 }
            btif_hl_free_buf((void **) &p_dcb->p_rx_pkt);
 }
 }

    bta_hl_ci_put_rx_data(mdl_handle,  status, evt);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int check_fragments_for_errors(VP8D_COMP *pbi)
{
 if (!pbi->ec_active &&
        pbi->fragments.count <= 1 && pbi->fragments.sizes[0] == 0)
 {
        VP8_COMMON *cm = &pbi->common;

 /* If error concealment is disabled we won't signal missing frames
         * to the decoder.
         */
 if (cm->fb_idx_ref_cnt[cm->lst_fb_idx] > 1)
 {
 /* The last reference shares buffer with another reference
             * buffer. Move it to its own buffer before setting it as
             * corrupt, otherwise we will make multiple buffers corrupt.
             */
 const int prev_idx = cm->lst_fb_idx;
            cm->fb_idx_ref_cnt[prev_idx]--;
            cm->lst_fb_idx = get_free_fb(cm);
            vp8_yv12_copy_frame(&cm->yv12_fb[prev_idx],
 &cm->yv12_fb[cm->lst_fb_idx]);
 }
 /* This is used to signal that we are missing frames.
         * We do not know if the missing frame(s) was supposed to update
         * any of the reference buffers, but we act conservative and
         * mark only the last buffer as corrupted.
         */
        cm->yv12_fb[cm->lst_fb_idx].corrupted = 1;

 /* Signal that we have no frame to show. */
        cm->show_frame = 0;

 /* Nothing more to do. */
 return 0;
 }

 return 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_video_decode(iv_obj_t *dec_hdl, void *pv_api_ip, void *pv_api_op)
{
 /* ! */

 dec_struct_t * ps_dec = (dec_struct_t *)(dec_hdl->pv_codec_handle);

    WORD32 i4_err_status = 0;
    UWORD8 *pu1_buf = NULL;
    WORD32 buflen;
    UWORD32 u4_max_ofst, u4_length_of_start_code = 0;

    UWORD32 bytes_consumed = 0;
    UWORD32 cur_slice_is_nonref = 0;
    UWORD32 u4_next_is_aud;
    UWORD32 u4_first_start_code_found = 0;
    WORD32 ret = 0,api_ret_value = IV_SUCCESS;
    WORD32 header_data_left = 0,frame_data_left = 0;
    UWORD8 *pu1_bitstrm_buf;
 ivd_video_decode_ip_t *ps_dec_ip;
 ivd_video_decode_op_t *ps_dec_op;

    ithread_set_name((void*)"Parse_thread");

    ps_dec_ip = (ivd_video_decode_ip_t *)pv_api_ip;
    ps_dec_op = (ivd_video_decode_op_t *)pv_api_op;

 {
        UWORD32 u4_size;
        u4_size = ps_dec_op->u4_size;
        memset(ps_dec_op, 0, sizeof(ivd_video_decode_op_t));
        ps_dec_op->u4_size = u4_size;
 }

    ps_dec->pv_dec_out = ps_dec_op;
 if(ps_dec->init_done != 1)
 {
 return IV_FAIL;
 }

 /*Data memory barries instruction,so that bitstream write by the application is complete*/
    DATA_SYNC();

 if(0 == ps_dec->u1_flushfrm)
 {
 if(ps_dec_ip->pv_stream_buffer == NULL)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_FRM_BS_BUF_NULL;
 return IV_FAIL;
 }
 if(ps_dec_ip->u4_num_Bytes <= 0)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_NUMBYTES_INV;
 return IV_FAIL;

 }
 }
    ps_dec->u1_pic_decode_done = 0;

    ps_dec_op->u4_num_bytes_consumed = 0;

    ps_dec->ps_out_buffer = NULL;

 if(ps_dec_ip->u4_size
 >= offsetof(ivd_video_decode_ip_t, s_out_buffer))
        ps_dec->ps_out_buffer = &ps_dec_ip->s_out_buffer;

    ps_dec->u4_fmt_conv_cur_row = 0;

    ps_dec->u4_output_present = 0;
    ps_dec->s_disp_op.u4_error_code = 1;
    ps_dec->u4_fmt_conv_num_rows = FMT_CONV_NUM_ROWS;
 if(0 == ps_dec->u4_share_disp_buf
 && ps_dec->i4_decode_header == 0)
 {
        UWORD32 i;
 if(ps_dec->ps_out_buffer->u4_num_bufs == 0)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0; i < ps_dec->ps_out_buffer->u4_num_bufs; i++)
 {
 if(ps_dec->ps_out_buffer->pu1_bufs[i] == NULL)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_dec->ps_out_buffer->u4_min_out_buf_size[i] == 0)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |=
                                IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }

 if(ps_dec->u4_total_frames_decoded >= NUM_FRAMES_LIMIT)
 {
        ps_dec_op->u4_error_code = ERROR_FRAME_LIMIT_OVER;
 return IV_FAIL;
 }

 /* ! */
    ps_dec->u4_ts = ps_dec_ip->u4_ts;

    ps_dec_op->u4_error_code = 0;
    ps_dec_op->e_pic_type = -1;
    ps_dec_op->u4_output_present = 0;
    ps_dec_op->u4_frame_decoded_flag = 0;

    ps_dec->i4_frametype = -1;
    ps_dec->i4_content_type = -1;
 /*
     * For field pictures, set the bottom and top picture decoded u4_flag correctly.
     */
 {
 if((TOP_FIELD_ONLY | BOT_FIELD_ONLY) == ps_dec->u1_top_bottom_decoded)
 {
            ps_dec->u1_top_bottom_decoded = 0;
 }
 }
    ps_dec->u4_slice_start_code_found = 0;

 /* In case the deocder is not in flush mode(in shared mode),
     then decoder has to pick up a buffer to write current frame.
     Check if a frame is available in such cases */

 if(ps_dec->u1_init_dec_flag == 1 && ps_dec->u4_share_disp_buf == 1
 && ps_dec->u1_flushfrm == 0)
 {
        UWORD32 i;

        WORD32 disp_avail = 0, free_id;

 /* Check if at least one buffer is available with the codec */
 /* If not then return to application with error */
 for(i = 0; i < ps_dec->u1_pic_bufs; i++)
 {
 if(0 == ps_dec->u4_disp_buf_mapping[i]
 || 1 == ps_dec->u4_disp_buf_to_be_freed[i])
 {
                disp_avail = 1;
 break;
 }

 }

 if(0 == disp_avail)
 {
 /* If something is queued for display wait for that buffer to be returned */

            ps_dec_op->u4_error_code = IVD_DEC_REF_BUF_NULL;
            ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
 return (IV_FAIL);
 }

 while(1)
 {
 pic_buffer_t *ps_pic_buf;
            ps_pic_buf = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr, &free_id);

 if(ps_pic_buf == NULL)
 {
                UWORD32 i, display_queued = 0;

 /* check if any buffer was given for display which is not returned yet */
 for(i = 0; i < (MAX_DISP_BUFS_NEW); i++)
 {
 if(0 != ps_dec->u4_disp_buf_mapping[i])
 {
                        display_queued = 1;
 break;
 }
 }
 /* If some buffer is queued for display, then codec has to singal an error and wait
                 for that buffer to be returned.
                 If nothing is queued for display then codec has ownership of all display buffers
                 and it can reuse any of the existing buffers and continue decoding */

 if(1 == display_queued)
 {
 /* If something is queued for display wait for that buffer to be returned */
                    ps_dec_op->u4_error_code = IVD_DEC_REF_BUF_NULL;
                    ps_dec_op->u4_error_code |= (1
 << IVD_UNSUPPORTEDPARAM);
 return (IV_FAIL);
 }
 }
 else
 {
 /* If the buffer is with display, then mark it as in use and then look for a buffer again */
 if(1 == ps_dec->u4_disp_buf_mapping[free_id])
 {
                    ih264_buf_mgr_set_status(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                    free_id,
                                    BUF_MGR_IO);
 }
 else
 {
 /**
                     *  Found a free buffer for present call. Release it now.
                     *  Will be again obtained later.
                     */
                    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                          free_id,
                                          BUF_MGR_IO);
 break;
 }
 }
 }

 }

 if(ps_dec->u1_flushfrm && ps_dec->u1_init_dec_flag)
 {

        ih264d_get_next_display_field(ps_dec, ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
            ps_dec->u4_fmt_conv_cur_row = 0;
            ps_dec->u4_fmt_conv_num_rows = ps_dec->s_disp_frame_info.u4_y_ht;
            ih264d_format_convert(ps_dec, &(ps_dec->s_disp_op),
                                  ps_dec->u4_fmt_conv_cur_row,
                                  ps_dec->u4_fmt_conv_num_rows);
            ps_dec->u4_fmt_conv_cur_row += ps_dec->u4_fmt_conv_num_rows;
            ps_dec->u4_output_present = 1;

 }
        ih264d_release_display_field(ps_dec, &(ps_dec->s_disp_op));

        ps_dec_op->u4_pic_wd = (UWORD32)ps_dec->u2_disp_width;
        ps_dec_op->u4_pic_ht = (UWORD32)ps_dec->u2_disp_height;

        ps_dec_op->u4_new_seq = 0;

        ps_dec_op->u4_output_present = ps_dec->u4_output_present;
        ps_dec_op->u4_progressive_frame_flag =
                        ps_dec->s_disp_op.u4_progressive_frame_flag;
        ps_dec_op->e_output_format =
                        ps_dec->s_disp_op.e_output_format;
        ps_dec_op->s_disp_frm_buf = ps_dec->s_disp_op.s_disp_frm_buf;
        ps_dec_op->e4_fld_type = ps_dec->s_disp_op.e4_fld_type;
        ps_dec_op->u4_ts = ps_dec->s_disp_op.u4_ts;
        ps_dec_op->u4_disp_buf_id = ps_dec->s_disp_op.u4_disp_buf_id;

 /*In the case of flush ,since no frame is decoded set pic type as invalid*/
        ps_dec_op->u4_is_ref_flag = -1;
        ps_dec_op->e_pic_type = IV_NA_FRAME;
        ps_dec_op->u4_frame_decoded_flag = 0;

 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
 return (IV_SUCCESS);
 }
 else
 return (IV_FAIL);

 }
 if(ps_dec->u1_res_changed == 1)
 {
 /*if resolution has changed and all buffers have been flushed, reset decoder*/
        ih264d_init_decoder(ps_dec);
 }

    ps_dec->u4_prev_nal_skipped = 0;

    ps_dec->u2_cur_mb_addr = 0;
    ps_dec->u2_total_mbs_coded = 0;
    ps_dec->u2_cur_slice_num = 0;
    ps_dec->cur_dec_mb_num = 0;
    ps_dec->cur_recon_mb_num = 0;
    ps_dec->u4_first_slice_in_pic = 2;
    ps_dec->u1_slice_header_done = 0;
    ps_dec->u1_dangling_field = 0;

    ps_dec->u4_dec_thread_created = 0;
    ps_dec->u4_bs_deblk_thread_created = 0;
    ps_dec->u4_cur_bs_mb_num = 0;
    ps_dec->u4_start_recon_deblk  = 0;

    DEBUG_THREADS_PRINTF(" Starting process call\n");


    ps_dec->u4_pic_buf_got = 0;

 do
 {
        WORD32 buf_size;

        pu1_buf = (UWORD8*)ps_dec_ip->pv_stream_buffer
 + ps_dec_op->u4_num_bytes_consumed;

        u4_max_ofst = ps_dec_ip->u4_num_Bytes
 - ps_dec_op->u4_num_bytes_consumed;

 /* If dynamic bitstream buffer is not allocated and
         * header decode is done, then allocate dynamic bitstream buffer
         */
 if((NULL == ps_dec->pu1_bits_buf_dynamic) &&
 (ps_dec->i4_header_decoded & 1))
 {
            WORD32 size;

 void *pv_buf;
 void *pv_mem_ctxt = ps_dec->pv_mem_ctxt;
            size = MAX(256000, ps_dec->u2_pic_wd * ps_dec->u2_pic_ht * 3 / 2);
            pv_buf = ps_dec->pf_aligned_alloc(pv_mem_ctxt, 128, size);
            RETURN_IF((NULL == pv_buf), IV_FAIL);
            ps_dec->pu1_bits_buf_dynamic = pv_buf;
            ps_dec->u4_dynamic_bits_buf_size = size;
 }

 if(ps_dec->pu1_bits_buf_dynamic)
 {
            pu1_bitstrm_buf = ps_dec->pu1_bits_buf_dynamic;
            buf_size = ps_dec->u4_dynamic_bits_buf_size;
 }
 else
 {
            pu1_bitstrm_buf = ps_dec->pu1_bits_buf_static;
            buf_size = ps_dec->u4_static_bits_buf_size;
 }

        u4_next_is_aud = 0;

        buflen = ih264d_find_start_code(pu1_buf, 0, u4_max_ofst,
 &u4_length_of_start_code,
 &u4_next_is_aud);

 if(buflen == -1)
            buflen = 0;
 /* Ignore bytes beyond the allocated size of intermediate buffer */
        buflen = MIN(buflen, buf_size);

        bytes_consumed = buflen + u4_length_of_start_code;
        ps_dec_op->u4_num_bytes_consumed += bytes_consumed;

 {
            UWORD8 u1_firstbyte, u1_nal_ref_idc;

 if(ps_dec->i4_app_skip_mode == IVD_SKIP_B)
 {
                u1_firstbyte = *(pu1_buf + u4_length_of_start_code);
                u1_nal_ref_idc = (UWORD8)(NAL_REF_IDC(u1_firstbyte));
 if(u1_nal_ref_idc == 0)
 {
 /*skip non reference frames*/
                    cur_slice_is_nonref = 1;
 continue;
 }
 else
 {
 if(1 == cur_slice_is_nonref)
 {
 /*We have encountered a referenced frame,return to app*/
                        ps_dec_op->u4_num_bytes_consumed -=
                                        bytes_consumed;
                        ps_dec_op->e_pic_type = IV_B_FRAME;
                        ps_dec_op->u4_error_code =
                                        IVD_DEC_FRM_SKIPPED;
                        ps_dec_op->u4_error_code |= (1
 << IVD_UNSUPPORTEDPARAM);
                        ps_dec_op->u4_frame_decoded_flag = 0;
                        ps_dec_op->u4_size =
 sizeof(ivd_video_decode_op_t);
 /*signal the decode thread*/
                        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
                            ih264d_signal_bs_deblk_thread(ps_dec);
 }

 return (IV_FAIL);
 }
 }

 }

 }


 if(buflen)
 {
            memcpy(pu1_bitstrm_buf, pu1_buf + u4_length_of_start_code,
                   buflen);
 /* Decoder may read extra 8 bytes near end of the frame */
 if((buflen + 8) < buf_size)
 {
                memset(pu1_bitstrm_buf + buflen, 0, 8);
 }
            u4_first_start_code_found = 1;

 }
 else
 {
 /*start code not found*/

 if(u4_first_start_code_found == 0)
 {
 /*no start codes found in current process call*/

                ps_dec->i4_error_code = ERROR_START_CODE_NOT_FOUND;
                ps_dec_op->u4_error_code |= 1 << IVD_INSUFFICIENTDATA;

 if(ps_dec->u4_pic_buf_got == 0)
 {

                    ih264d_fill_output_struct_from_context(ps_dec,
                                                           ps_dec_op);

                    ps_dec_op->u4_error_code = ps_dec->i4_error_code;
                    ps_dec_op->u4_frame_decoded_flag = 0;

 return (IV_FAIL);
 }
 else
 {
                    ps_dec->u1_pic_decode_done = 1;
 continue;
 }
 }
 else
 {
 /* a start code has already been found earlier in the same process call*/
                frame_data_left = 0;
 continue;
 }

 }

        ps_dec->u4_return_to_app = 0;
        ret = ih264d_parse_nal_unit(dec_hdl, ps_dec_op,
                              pu1_bitstrm_buf, buflen);
 if(ret != OK)
 {
            UWORD32 error =  ih264d_map_error(ret);
            ps_dec_op->u4_error_code = error | ret;
            api_ret_value = IV_FAIL;


             if((ret == IVD_RES_CHANGED)
                             || (ret == IVD_MEM_ALLOC_FAILED)
                             || (ret == ERROR_UNAVAIL_PICBUF_T)
                            || (ret == ERROR_UNAVAIL_MVBUF_T))
             {
                 break;
             }
 
 if((ret == ERROR_INCOMPLETE_FRAME) || (ret == ERROR_DANGLING_FIELD_IN_PIC))
 {
                ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
                api_ret_value = IV_FAIL;
 break;
 }

 if(ret == ERROR_IN_LAST_SLICE_OF_PIC)
 {
                api_ret_value = IV_FAIL;
 break;
 }

 }

 if(ps_dec->u4_return_to_app)
 {
 /*We have encountered a referenced frame,return to app*/
            ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
            ps_dec_op->u4_error_code = IVD_DEC_FRM_SKIPPED;
            ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
            ps_dec_op->u4_frame_decoded_flag = 0;
            ps_dec_op->u4_size = sizeof(ivd_video_decode_op_t);
 /*signal the decode thread*/
            ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
                ih264d_signal_bs_deblk_thread(ps_dec);
 }
 return (IV_FAIL);

 }



        header_data_left = ((ps_dec->i4_decode_header == 1)
 && (ps_dec->i4_header_decoded != 3)
 && (ps_dec_op->u4_num_bytes_consumed
 < ps_dec_ip->u4_num_Bytes));
        frame_data_left = (((ps_dec->i4_decode_header == 0)
 && ((ps_dec->u1_pic_decode_done == 0)
 || (u4_next_is_aud == 1)))
 && (ps_dec_op->u4_num_bytes_consumed
 < ps_dec_ip->u4_num_Bytes));
 }
 while(( header_data_left == 1)||(frame_data_left == 1));

 if((ps_dec->u4_slice_start_code_found == 1)
 && (ret != IVD_MEM_ALLOC_FAILED)
 && ps_dec->u2_total_mbs_coded < ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        WORD32 num_mb_skipped;
        WORD32 prev_slice_err;
 pocstruct_t temp_poc;
        WORD32 ret1;

        num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;

 if(ps_dec->u4_first_slice_in_pic && (ps_dec->u4_pic_buf_got == 0))
            prev_slice_err = 1;
 else
            prev_slice_err = 2;

        ret1 = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, ps_dec->u1_nal_unit_type == IDR_SLICE_NAL, ps_dec->ps_cur_slice->u2_frame_num,
 &temp_poc, prev_slice_err);

 if((ret1 == ERROR_UNAVAIL_PICBUF_T) || (ret1 == ERROR_UNAVAIL_MVBUF_T))
 {
 return IV_FAIL;
 }
 }


     if((ret == IVD_RES_CHANGED)
                     || (ret == IVD_MEM_ALLOC_FAILED)
                     || (ret == ERROR_UNAVAIL_PICBUF_T)
                    || (ret == ERROR_UNAVAIL_MVBUF_T))
     {
 
         /* signal the decode thread */
        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet */
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 /* dont consume bitstream for change in resolution case */
 if(ret == IVD_RES_CHANGED)
 {
            ps_dec_op->u4_num_bytes_consumed -= bytes_consumed;
 }
 return IV_FAIL;
 }


 if(ps_dec->u1_separate_parse)
 {
 /* If Format conversion is not complete,
         complete it here */
 if(ps_dec->u4_num_cores == 2)
 {

 /*do deblocking of all mbs*/
 if((ps_dec->u4_nmb_deblk == 0) &&(ps_dec->u4_start_recon_deblk == 1) && (ps_dec->ps_cur_sps->u1_mb_aff_flag == 0))
 {
                UWORD32 u4_num_mbs,u4_max_addr;
 tfr_ctxt_t s_tfr_ctxt;
 tfr_ctxt_t *ps_tfr_cxt = &s_tfr_ctxt;
 pad_mgr_t *ps_pad_mgr = &ps_dec->s_pad_mgr;

 /*BS is done for all mbs while parsing*/
                u4_max_addr = (ps_dec->u2_frm_wd_in_mbs * ps_dec->u2_frm_ht_in_mbs) - 1;
                ps_dec->u4_cur_bs_mb_num = u4_max_addr + 1;


                ih264d_init_deblk_tfr_ctxt(ps_dec, ps_pad_mgr, ps_tfr_cxt,
                                           ps_dec->u2_frm_wd_in_mbs, 0);


                u4_num_mbs = u4_max_addr
 - ps_dec->u4_cur_deblk_mb_num + 1;

                DEBUG_PERF_PRINTF("mbs left for deblocking= %d \n",u4_num_mbs);

 if(u4_num_mbs != 0)
                    ih264d_check_mb_map_deblk(ps_dec, u4_num_mbs,
                                                   ps_tfr_cxt,1);

                ps_dec->u4_start_recon_deblk  = 0;

 }

 }

 /*signal the decode thread*/
        ih264d_signal_decode_thread(ps_dec);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 }


    DATA_SYNC();


 if((ps_dec_op->u4_error_code & 0xff)
 != ERROR_DYNAMIC_RESOLUTION_NOT_SUPPORTED)
 {
        ps_dec_op->u4_pic_wd = (UWORD32)ps_dec->u2_disp_width;
        ps_dec_op->u4_pic_ht = (UWORD32)ps_dec->u2_disp_height;
 }

 if(ps_dec->i4_header_decoded != 3)
 {
        ps_dec_op->u4_error_code |= (1 << IVD_INSUFFICIENTDATA);

 }

 if(ps_dec->i4_decode_header == 1 && ps_dec->i4_header_decoded != 3)
 {
        ps_dec_op->u4_error_code |= (1 << IVD_INSUFFICIENTDATA);

 }
 if(ps_dec->u4_prev_nal_skipped)
 {
 /*We have encountered a referenced frame,return to app*/
        ps_dec_op->u4_error_code = IVD_DEC_FRM_SKIPPED;
        ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
        ps_dec_op->u4_frame_decoded_flag = 0;
        ps_dec_op->u4_size = sizeof(ivd_video_decode_op_t);
 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
            ih264d_signal_bs_deblk_thread(ps_dec);
 }
 return (IV_FAIL);

 }

 if((ps_dec->u4_slice_start_code_found == 1)
 && (ERROR_DANGLING_FIELD_IN_PIC != i4_err_status))
 {
 /*
         * For field pictures, set the bottom and top picture decoded u4_flag correctly.
         */

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
 {
 if(1 == ps_dec->ps_cur_slice->u1_bottom_field_flag)
 {
                ps_dec->u1_top_bottom_decoded |= BOT_FIELD_ONLY;
 }
 else
 {
                ps_dec->u1_top_bottom_decoded |= TOP_FIELD_ONLY;
 }
 }

 /* if new frame in not found (if we are still getting slices from previous frame)
         * ih264d_deblock_display is not called. Such frames will not be added to reference /display
         */
 if((ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC) == 0)
 {
 /* Calling Function to deblock Picture and Display */
            ret = ih264d_deblock_display(ps_dec);
 if(ret != 0)
 {
 return IV_FAIL;
 }
 }


 /*set to complete ,as we dont support partial frame decode*/
 if(ps_dec->i4_header_decoded == 3)
 {
            ps_dec->u2_total_mbs_coded = ps_dec->ps_cur_sps->u2_max_mb_addr + 1;
 }

 /*Update the i4_frametype at the end of picture*/
 if(ps_dec->ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL)
 {
            ps_dec->i4_frametype = IV_IDR_FRAME;
 }
 else if(ps_dec->i4_pic_type == B_SLICE)
 {
            ps_dec->i4_frametype = IV_B_FRAME;
 }
 else if(ps_dec->i4_pic_type == P_SLICE)
 {
            ps_dec->i4_frametype = IV_P_FRAME;
 }
 else if(ps_dec->i4_pic_type == I_SLICE)
 {
            ps_dec->i4_frametype = IV_I_FRAME;
 }
 else
 {
            H264_DEC_DEBUG_PRINT("Shouldn't come here\n");
 }

        ps_dec->i4_content_type = ps_dec->ps_cur_slice->u1_field_pic_flag;

        ps_dec->u4_total_frames_decoded = ps_dec->u4_total_frames_decoded + 2;
        ps_dec->u4_total_frames_decoded = ps_dec->u4_total_frames_decoded
 - ps_dec->ps_cur_slice->u1_field_pic_flag;

 }

 /* close deblock thread if it is not closed yet*/
 if(ps_dec->u4_num_cores == 3)
 {
        ih264d_signal_bs_deblk_thread(ps_dec);
 }


 {
 /* In case the decoder is configured to run in low delay mode,
         * then get display buffer and then format convert.
         * Note in this mode, format conversion does not run paralelly in a thread and adds to the codec cycles
         */

 if((IVD_DECODE_FRAME_OUT == ps_dec->e_frm_out_mode)
 && ps_dec->u1_init_dec_flag)
 {

            ih264d_get_next_display_field(ps_dec, ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 if(0 == ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = 0;
                ps_dec->u4_output_present = 1;
 }
 }

        ih264d_fill_output_struct_from_context(ps_dec, ps_dec_op);

 /* If Format conversion is not complete,
         complete it here */
 if(ps_dec->u4_output_present &&
 (ps_dec->u4_fmt_conv_cur_row < ps_dec->s_disp_frame_info.u4_y_ht))
 {
            ps_dec->u4_fmt_conv_num_rows = ps_dec->s_disp_frame_info.u4_y_ht
 - ps_dec->u4_fmt_conv_cur_row;
            ih264d_format_convert(ps_dec, &(ps_dec->s_disp_op),
                                  ps_dec->u4_fmt_conv_cur_row,
                                  ps_dec->u4_fmt_conv_num_rows);
            ps_dec->u4_fmt_conv_cur_row += ps_dec->u4_fmt_conv_num_rows;
 }

        ih264d_release_display_field(ps_dec, &(ps_dec->s_disp_op));
 }

 if(ps_dec->i4_decode_header == 1 && (ps_dec->i4_header_decoded & 1) == 1)
 {
        ps_dec_op->u4_progressive_frame_flag = 1;
 if((NULL != ps_dec->ps_cur_sps) && (1 == (ps_dec->ps_cur_sps->u1_is_valid)))
 {
 if((0 == ps_dec->ps_sps->u1_frame_mbs_only_flag)
 && (0 == ps_dec->ps_sps->u1_mb_aff_flag))
                ps_dec_op->u4_progressive_frame_flag = 0;

 }
 }

 /*Data memory barrier instruction,so that yuv write by the library is complete*/
    DATA_SYNC();

    H264_DEC_DEBUG_PRINT("The num bytes consumed: %d\n",
                         ps_dec_op->u4_num_bytes_consumed);
 return api_ret_value;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  virtual status_t prepareForAdaptivePlayback(
            node_id node, OMX_U32 port_index, OMX_BOOL enable,
            OMX_U32 max_width, OMX_U32 max_height) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeInt32((int32_t)enable);
        data.writeInt32(max_width);
        data.writeInt32(max_height);
        remote()->transact(PREPARE_FOR_ADAPTIVE_PLAYBACK, data, &reply);

 status_t err = reply.readInt32();
 return err;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void TryTransitionResultArrayToPacked(Handle<JSArray> array) {
 if (!IsHoleyElementsKind(kind())) return;
 int length = Smi::cast(array->length())->value();
 Handle<FixedArrayBase> backing_store(array->elements());
 if (!Subclass::IsPackedImpl(array, backing_store, 0, length)) {
 return;
 }
 ElementsKind packed_kind = GetPackedElementsKind(kind());
 Handle<Map> new_map =
 JSObject::GetElementsTransitionMap(array, packed_kind);
 JSObject::MigrateToMap(array, new_map);
 if (FLAG_trace_elements_transitions) {
 JSObject::PrintElementsTransition(stdout, array, kind(), backing_store,
                                        packed_kind, backing_store);
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NsDisable(preproc_effect_t *effect)
{
    ALOGV("NsDisable");
    webrtc::NoiseSuppression *ns = static_cast<webrtc::NoiseSuppression *>(effect->engine);
    ns->Enable(false);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_proc_id_addr(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = p_data->p_data;
  tBTM_LE_PID_KEYS pid_key;

  SMP_TRACE_DEBUG("%s", __func__);
  smp_update_key_mask(p_cb, SMP_SEC_KEY_TYPE_ID, true);

  STREAM_TO_UINT8(pid_key.addr_type, p);
  STREAM_TO_BDADDR(pid_key.static_addr, p);
  memcpy(pid_key.irk, p_cb->tk, BT_OCTET16_LEN);

 /* to use as BD_ADDR for lk derived from ltk */
  p_cb->id_addr_rcvd = true;
  p_cb->id_addr_type = pid_key.addr_type;
  p_cb->id_addr = pid_key.static_addr;

 /* store the ID key from peer device */
 if ((p_cb->peer_auth_req & SMP_AUTH_BOND) &&
 (p_cb->loc_auth_req & SMP_AUTH_BOND))
    btm_sec_save_le_key(p_cb->pairing_bda, BTM_LE_KEY_PID,
 (tBTM_LE_KEY_VALUE*)&pid_key, true);
  smp_key_distribution_by_transport(p_cb, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void IPCThreadState::setStrictModePolicy(int32_t policy)
{
    mStrictModePolicy = policy;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readStrongBinderVector(std::vector<sp<IBinder>>* val) const {
 return readTypedVector(val, &Parcel::readStrongBinder);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlIsNameChar(xmlParserCtxtPtr ctxt, int c) {
 if ((ctxt->options & XML_PARSE_OLD10) == 0) {
 /*
	 * Use the new checks of production [4] [4a] amd [5] of the
	 * Update 5 of XML-1.0
	 */
 if ((c != ' ') && (c != '>') && (c != '/') && /* accelerators */
 (((c >= 'a') && (c <= 'z')) ||
 ((c >= 'A') && (c <= 'Z')) ||
 ((c >= '0') && (c <= '9')) || /* !start */
 (c == '_') || (c == ':') ||
 (c == '-') || (c == '.') || (c == 0xB7) || /* !start */
 ((c >= 0xC0) && (c <= 0xD6)) ||
 ((c >= 0xD8) && (c <= 0xF6)) ||
 ((c >= 0xF8) && (c <= 0x2FF)) ||
 ((c >= 0x300) && (c <= 0x36F)) || /* !start */
 ((c >= 0x370) && (c <= 0x37D)) ||
 ((c >= 0x37F) && (c <= 0x1FFF)) ||
 ((c >= 0x200C) && (c <= 0x200D)) ||
 ((c >= 0x203F) && (c <= 0x2040)) || /* !start */
 ((c >= 0x2070) && (c <= 0x218F)) ||
 ((c >= 0x2C00) && (c <= 0x2FEF)) ||
 ((c >= 0x3001) && (c <= 0xD7FF)) ||
 ((c >= 0xF900) && (c <= 0xFDCF)) ||
 ((c >= 0xFDF0) && (c <= 0xFFFD)) ||
 ((c >= 0x10000) && (c <= 0xEFFFF))))
 return(1);
 } else {
 if ((IS_LETTER(c)) || (IS_DIGIT(c)) ||
 (c == '.') || (c == '-') ||
 (c == '_') || (c == ':') ||
 (IS_COMBINING(c)) ||
 (IS_EXTENDER(c)))
 return(1);
 }
 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_dm_start_discovery(void)
{
    tBTA_DM_INQ inq_params;
    tBTA_SERVICE_MASK services = 0;
    tBTA_DM_BLE_PF_FILT_PARAMS adv_filt_param;

    BTIF_TRACE_EVENT("%s", __FUNCTION__);

#if (defined(BLE_INCLUDED) && (BLE_INCLUDED == TRUE))
    memset(&adv_filt_param, 0, sizeof(tBTA_DM_BLE_PF_FILT_PARAMS));
 /* Cleanup anything remaining on index 0 */
    BTA_DmBleScanFilterSetup(BTA_DM_BLE_SCAN_COND_DELETE, 0, &adv_filt_param, NULL,
                             bte_scan_filt_param_cfg_evt, 0);

 /* Add an allow-all filter on index 0*/
    adv_filt_param.dely_mode = IMMEDIATE_DELY_MODE;
    adv_filt_param.feat_seln = ALLOW_ALL_FILTER;
    adv_filt_param.filt_logic_type = BTA_DM_BLE_PF_FILT_LOGIC_OR;
    adv_filt_param.list_logic_type = BTA_DM_BLE_PF_LIST_LOGIC_OR;
    adv_filt_param.rssi_low_thres = LOWEST_RSSI_VALUE;
    adv_filt_param.rssi_high_thres = LOWEST_RSSI_VALUE;
    BTA_DmBleScanFilterSetup(BTA_DM_BLE_SCAN_COND_ADD, 0, &adv_filt_param, NULL,
                             bte_scan_filt_param_cfg_evt, 0);

 /* TODO: Do we need to handle multiple inquiries at the same time? */

 /* Set inquiry params and call API */
    inq_params.mode = BTA_DM_GENERAL_INQUIRY|BTA_BLE_GENERAL_INQUIRY;
#if (defined(BTA_HOST_INTERLEAVE_SEARCH) && BTA_HOST_INTERLEAVE_SEARCH == TRUE)
    inq_params.intl_duration[0]= BTIF_DM_INTERLEAVE_DURATION_BR_ONE;
    inq_params.intl_duration[1]= BTIF_DM_INTERLEAVE_DURATION_LE_ONE;
    inq_params.intl_duration[2]= BTIF_DM_INTERLEAVE_DURATION_BR_TWO;
    inq_params.intl_duration[3]= BTIF_DM_INTERLEAVE_DURATION_LE_TWO;
#endif
#else
    inq_params.mode = BTA_DM_GENERAL_INQUIRY;
#endif
    inq_params.duration = BTIF_DM_DEFAULT_INQ_MAX_DURATION;

    inq_params.max_resps = BTIF_DM_DEFAULT_INQ_MAX_RESULTS;
    inq_params.report_dup = TRUE;

    inq_params.filter_type = BTA_DM_INQ_CLR;
 /* TODO: Filter device by BDA needs to be implemented here */

 /* Will be enabled to TRUE once inquiry busy level has been received */
    btif_dm_inquiry_in_progress = FALSE;
 /* find nearby devices */
    BTA_DmSearch(&inq_params, services, bte_search_devices_evt);

 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uintptr_t Parcel::ipcObjects() const
{
 return reinterpret_cast<uintptr_t>(mObjects);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t OMXNodeInstance::updateGraphicBufferInMeta_l(
         OMX_U32 portIndex, const sp<GraphicBuffer>& graphicBuffer,
         OMX::buffer_id buffer, OMX_BUFFERHEADERTYPE *header) {
     if (portIndex != kPortIndexInput && portIndex != kPortIndexOutput) {
         return BAD_VALUE;
     }

 BufferMeta *bufferMeta = (BufferMeta *)(header->pAppPrivate);
    bufferMeta->setGraphicBuffer(graphicBuffer);
 if (mMetadataType[portIndex] == kMetadataBufferTypeGrallocSource
 && header->nAllocLen >= sizeof(VideoGrallocMetadata)) {
 VideoGrallocMetadata &metadata = *(VideoGrallocMetadata *)(header->pBuffer);
        metadata.eType = kMetadataBufferTypeGrallocSource;
        metadata.pHandle = graphicBuffer == NULL ? NULL : graphicBuffer->handle;
 } else if (mMetadataType[portIndex] == kMetadataBufferTypeANWBuffer
 && header->nAllocLen >= sizeof(VideoNativeMetadata)) {
 VideoNativeMetadata &metadata = *(VideoNativeMetadata *)(header->pBuffer);
        metadata.eType = kMetadataBufferTypeANWBuffer;
        metadata.pBuffer = graphicBuffer == NULL ? NULL : graphicBuffer->getNativeBuffer();
        metadata.nFenceFd = -1;
 } else {
        CLOG_BUFFER(updateGraphicBufferInMeta, "%s:%u, %#x bad type (%d) or size (%u)",
            portString(portIndex), portIndex, buffer, mMetadataType[portIndex], header->nAllocLen);
 return BAD_VALUE;
 }

    CLOG_BUFFER(updateGraphicBufferInMeta, "%s:%u, %#x := %p",
            portString(portIndex), portIndex, buffer,
            graphicBuffer == NULL ? NULL : graphicBuffer->handle);
 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::notifyStatus(bool idle) {
 {
 Mutex::Autolock l(mLock);
 if (mStatus != STATUS_ACTIVE && mStatus != STATUS_CONFIGURED) {
 return;
 }
        ALOGV("%s: Camera %d: Now %s", __FUNCTION__, mId,
                idle ? "idle" : "active");
        internalUpdateStatusLocked(idle ? STATUS_CONFIGURED : STATUS_ACTIVE);

 if (mPauseStateNotify) return;
 }
 NotificationListener *listener;
 {
 Mutex::Autolock l(mOutputLock);
        listener = mListener;
 }
 if (idle && listener != NULL) {
        listener->notifyIdle();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: allocbuffer(Image *image)
{
 png_size_t size = PNG_IMAGE_BUFFER_SIZE(image->image, image->stride);

 if (size+32 > image->bufsize)
 {
      freebuffer(image);
      image->buffer = voidcast(png_bytep, malloc(size+32));
 if (image->buffer == NULL)
 {
         fflush(stdout);
         fprintf(stderr,
 "simpletest: out of memory allocating %lu(+32) byte buffer\n",
 (unsigned long)size);
         exit(1);
 }
      image->bufsize = size+32;
 }

   memset(image->buffer, 95, image->bufsize);
   memset(image->buffer+16, BUFFER_INIT8, size);
   image->allocsize = size;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_slice_delivery_mode(OMX_U32 enable)
{
 struct v4l2_control control;

 if (enable) {
        control.id = V4L2_CID_MPEG_VIDEO_MULTI_SLICE_DELIVERY_MODE;
        control.value = 1;
        DEBUG_PRINT_LOW("Set slice_delivery_mode: %d", control.value);

 if (multislice.mslice_mode == V4L2_MPEG_VIDEO_MULTI_SICE_MODE_MAX_MB && m_sVenc_cfg.codectype == V4L2_PIX_FMT_H264) {
 if (ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control)) {
                DEBUG_PRINT_ERROR("Request for setting slice delivery mode failed");
 return false;
 } else {
                DEBUG_PRINT_LOW("Successfully set Slice delivery mode id: %d, value=%d", control.id, control.value);
                slice_mode.enable = 1;
 }
 } else {
            DEBUG_PRINT_ERROR("Failed to set slice delivery mode, slice_mode [%lu] "
 "is not MB BASED or [%lu] is not H264 codec ", multislice.mslice_mode,
                    m_sVenc_cfg.codectype);
 }
 } else {
        DEBUG_PRINT_ERROR("Slice_DELIVERY_MODE not enabled");
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_transform_png_set_scale_16_set(PNG_CONST image_transform *this,
     transform_display *that, png_structp pp, png_infop pi)
 {
    png_set_scale_16(pp);
    this->next->set(this->next, that, pp, pi);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool ID3::ParseSyncsafeInteger(const uint8_t encoded[4], size_t *x) {
 *x = 0;
 for (int32_t i = 0; i < 4; ++i) {
 if (encoded[i] & 0x80) {
 return false;
 }

 *x = ((*x) << 7) | encoded[i];
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int vol_effect_get_descriptor(effect_handle_t   self,
 effect_descriptor_t *descriptor)
{
 vol_listener_context_t *context = (vol_listener_context_t *)self;
    ALOGV("%s Called ", __func__);

 if (descriptor == NULL) {
        ALOGE("%s: descriptor is NULL", __func__);
 return -EINVAL;
 }

 *descriptor = *context->desc;
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void uipc_stop_main_server_thread(void)
{
 /* request shutdown of read thread */
    UIPC_LOCK();
    uipc_main.running = 0;
    uipc_wakeup_locked();
    UIPC_UNLOCK();

 /* wait until read thread is fully terminated */
 /* tid might hold pointer value where it's value
       is negative vaule with singed bit is set, so
       corrected the logic to check zero or non zero */
 if (uipc_main.tid)
        pthread_join(uipc_main.tid, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int omx_venc::dev_extradata_log_buffers(char *buffer)
{
 return handle->venc_extradata_log_buffers(buffer);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BufferQueueConsumer::setConsumerUsageBits(uint32_t usage) {
    ATRACE_CALL();
    BQ_LOGV("setConsumerUsageBits: %#x", usage);
 Mutex::Autolock lock(mCore->mMutex);
    mCore->mConsumerUsageBits = usage;
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long SimpleBlock::Parse() { return m_block.Parse(m_pCluster); }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::get_config(OMX_IN OMX_HANDLETYPE      hComp,
        OMX_IN OMX_INDEXTYPE configIndex,
        OMX_INOUT OMX_PTR     configData)
{
 (void)hComp;

 if (configData == NULL) {
        DEBUG_PRINT_ERROR("ERROR: param is null");
 return OMX_ErrorBadParameter;
 }

 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("ERROR: can't be in invalid state");
 return OMX_ErrorIncorrectStateOperation;
 }

 switch ((int)configIndex) {
 case OMX_IndexConfigVideoBitrate:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_VIDEO_CONFIG_BITRATETYPE);
                OMX_VIDEO_CONFIG_BITRATETYPE* pParam = reinterpret_cast<OMX_VIDEO_CONFIG_BITRATETYPE*>(configData);
                memcpy(pParam, &m_sConfigBitrate, sizeof(m_sConfigBitrate));
 break;
 }
 case OMX_IndexConfigVideoFramerate:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_CONFIG_FRAMERATETYPE);
                OMX_CONFIG_FRAMERATETYPE* pParam = reinterpret_cast<OMX_CONFIG_FRAMERATETYPE*>(configData);
                memcpy(pParam, &m_sConfigFramerate, sizeof(m_sConfigFramerate));
 break;
 }
 case OMX_IndexConfigCommonRotate:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_CONFIG_ROTATIONTYPE);
                OMX_CONFIG_ROTATIONTYPE* pParam = reinterpret_cast<OMX_CONFIG_ROTATIONTYPE*>(configData);
                memcpy(pParam, &m_sConfigFrameRotation, sizeof(m_sConfigFrameRotation));
 break;
 }
 case QOMX_IndexConfigVideoIntraperiod:
 {
                DEBUG_PRINT_LOW("get_config:QOMX_IndexConfigVideoIntraperiod");
                VALIDATE_OMX_PARAM_DATA(configData, QOMX_VIDEO_INTRAPERIODTYPE);
                QOMX_VIDEO_INTRAPERIODTYPE* pParam = reinterpret_cast<QOMX_VIDEO_INTRAPERIODTYPE*>(configData);
                memcpy(pParam, &m_sIntraperiod, sizeof(m_sIntraperiod));
 break;
 }
 case OMX_IndexConfigVideoAVCIntraPeriod:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_VIDEO_CONFIG_AVCINTRAPERIOD);
                OMX_VIDEO_CONFIG_AVCINTRAPERIOD *pParam =
 reinterpret_cast<OMX_VIDEO_CONFIG_AVCINTRAPERIOD*>(configData);
                DEBUG_PRINT_LOW("get_config: OMX_IndexConfigVideoAVCIntraPeriod");
                memcpy(pParam, &m_sConfigAVCIDRPeriod, sizeof(m_sConfigAVCIDRPeriod));
 break;
 }
 case OMX_IndexConfigCommonDeinterlace:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_VIDEO_CONFIG_DEINTERLACE);
                OMX_VIDEO_CONFIG_DEINTERLACE *pParam =
 reinterpret_cast<OMX_VIDEO_CONFIG_DEINTERLACE*>(configData);
                DEBUG_PRINT_LOW("get_config: OMX_IndexConfigCommonDeinterlace");
                memcpy(pParam, &m_sConfigDeinterlace, sizeof(m_sConfigDeinterlace));
 break;
 }
 case OMX_IndexConfigVideoVp8ReferenceFrame:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_VIDEO_VP8REFERENCEFRAMETYPE);
               OMX_VIDEO_VP8REFERENCEFRAMETYPE* pParam =
 reinterpret_cast<OMX_VIDEO_VP8REFERENCEFRAMETYPE*>(configData);
               DEBUG_PRINT_LOW("get_config: OMX_IndexConfigVideoVp8ReferenceFrame");
               memcpy(pParam, &m_sConfigVp8ReferenceFrame, sizeof(m_sConfigVp8ReferenceFrame));
 break;
 }
 case OMX_QcomIndexConfigPerfLevel:
 {
                VALIDATE_OMX_PARAM_DATA(configData, OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL);
                OMX_U32 perflevel;
                OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *pParam =
 reinterpret_cast<OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL*>(configData);
                DEBUG_PRINT_LOW("get_config: OMX_QcomIndexConfigPerfLevel");
 if (!dev_get_performance_level(&perflevel)) {
                    DEBUG_PRINT_ERROR("Invalid entry returned from get_performance_level %d",
                        pParam->ePerfLevel);
 } else {
                    pParam->ePerfLevel = (QOMX_VIDEO_PERF_LEVEL)perflevel;
 }
 break;
 }
 default:
            DEBUG_PRINT_ERROR("ERROR: unsupported index %d", (int) configIndex);
 return OMX_ErrorUnsupportedIndex;
 }
 return OMX_ErrorNone;

}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: BOOLEAN btif_hl_find_avail_mcl_idx(UINT8 app_idx, UINT8 *p_mcl_idx){
    BOOLEAN found=FALSE;
    UINT8 i;

 for (i=0; i < BTA_HL_NUM_MCLS ; i ++)
 {
 if (!btif_hl_cb.acb[app_idx].mcb[i].in_use)
 {
            found = TRUE;
 *p_mcl_idx = i;
 break;
 }
 }
    BTIF_TRACE_DEBUG("%s found=%d mcl_idx=%d", __FUNCTION__, found, i);
 return found;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtUseOptionsInternal(xmlParserCtxtPtr ctxt, int options, const char *encoding)
{
 if (ctxt == NULL)
 return(-1);
 if (encoding != NULL) {
 if (ctxt->encoding != NULL)
	    xmlFree((xmlChar *) ctxt->encoding);
        ctxt->encoding = xmlStrdup((const xmlChar *) encoding);
 }
 if (options & XML_PARSE_RECOVER) {
        ctxt->recovery = 1;
        options -= XML_PARSE_RECOVER;
	ctxt->options |= XML_PARSE_RECOVER;
 } else
        ctxt->recovery = 0;
 if (options & XML_PARSE_DTDLOAD) {
        ctxt->loadsubset = XML_DETECT_IDS;
        options -= XML_PARSE_DTDLOAD;
	ctxt->options |= XML_PARSE_DTDLOAD;
 } else
        ctxt->loadsubset = 0;
 if (options & XML_PARSE_DTDATTR) {
        ctxt->loadsubset |= XML_COMPLETE_ATTRS;
        options -= XML_PARSE_DTDATTR;
	ctxt->options |= XML_PARSE_DTDATTR;
 }
 if (options & XML_PARSE_NOENT) {
        ctxt->replaceEntities = 1;
 /* ctxt->loadsubset |= XML_DETECT_IDS; */
        options -= XML_PARSE_NOENT;
	ctxt->options |= XML_PARSE_NOENT;
 } else
        ctxt->replaceEntities = 0;
 if (options & XML_PARSE_PEDANTIC) {
        ctxt->pedantic = 1;
        options -= XML_PARSE_PEDANTIC;
	ctxt->options |= XML_PARSE_PEDANTIC;
 } else
        ctxt->pedantic = 0;
 if (options & XML_PARSE_NOBLANKS) {
        ctxt->keepBlanks = 0;
        ctxt->sax->ignorableWhitespace = xmlSAX2IgnorableWhitespace;
        options -= XML_PARSE_NOBLANKS;
	ctxt->options |= XML_PARSE_NOBLANKS;
 } else
        ctxt->keepBlanks = 1;
 if (options & XML_PARSE_DTDVALID) {
        ctxt->validate = 1;
 if (options & XML_PARSE_NOWARNING)
            ctxt->vctxt.warning = NULL;
 if (options & XML_PARSE_NOERROR)
            ctxt->vctxt.error = NULL;
        options -= XML_PARSE_DTDVALID;
	ctxt->options |= XML_PARSE_DTDVALID;
 } else
        ctxt->validate = 0;
 if (options & XML_PARSE_NOWARNING) {
        ctxt->sax->warning = NULL;
        options -= XML_PARSE_NOWARNING;
 }
 if (options & XML_PARSE_NOERROR) {
        ctxt->sax->error = NULL;
        ctxt->sax->fatalError = NULL;
        options -= XML_PARSE_NOERROR;
 }
#ifdef LIBXML_SAX1_ENABLED
 if (options & XML_PARSE_SAX1) {
        ctxt->sax->startElement = xmlSAX2StartElement;
        ctxt->sax->endElement = xmlSAX2EndElement;
        ctxt->sax->startElementNs = NULL;
        ctxt->sax->endElementNs = NULL;
        ctxt->sax->initialized = 1;
        options -= XML_PARSE_SAX1;
	ctxt->options |= XML_PARSE_SAX1;
 }
#endif /* LIBXML_SAX1_ENABLED */
 if (options & XML_PARSE_NODICT) {
        ctxt->dictNames = 0;
        options -= XML_PARSE_NODICT;
	ctxt->options |= XML_PARSE_NODICT;
 } else {
        ctxt->dictNames = 1;
 }
 if (options & XML_PARSE_NOCDATA) {
        ctxt->sax->cdataBlock = NULL;
        options -= XML_PARSE_NOCDATA;
	ctxt->options |= XML_PARSE_NOCDATA;
 }
 if (options & XML_PARSE_NSCLEAN) {
	ctxt->options |= XML_PARSE_NSCLEAN;
        options -= XML_PARSE_NSCLEAN;
 }
 if (options & XML_PARSE_NONET) {
	ctxt->options |= XML_PARSE_NONET;
        options -= XML_PARSE_NONET;
 }
 if (options & XML_PARSE_COMPACT) {
	ctxt->options |= XML_PARSE_COMPACT;
        options -= XML_PARSE_COMPACT;
 }
 if (options & XML_PARSE_OLD10) {
	ctxt->options |= XML_PARSE_OLD10;
        options -= XML_PARSE_OLD10;
 }
 if (options & XML_PARSE_NOBASEFIX) {
	ctxt->options |= XML_PARSE_NOBASEFIX;
        options -= XML_PARSE_NOBASEFIX;
 }
 if (options & XML_PARSE_HUGE) {
	ctxt->options |= XML_PARSE_HUGE;
        options -= XML_PARSE_HUGE;
 if (ctxt->dict != NULL)
            xmlDictSetLimit(ctxt->dict, 0);
 }
 if (options & XML_PARSE_OLDSAX) {
	ctxt->options |= XML_PARSE_OLDSAX;
        options -= XML_PARSE_OLDSAX;
 }
 if (options & XML_PARSE_IGNORE_ENC) {
	ctxt->options |= XML_PARSE_IGNORE_ENC;
        options -= XML_PARSE_IGNORE_ENC;
 }
 if (options & XML_PARSE_BIG_LINES) {
	ctxt->options |= XML_PARSE_BIG_LINES;
        options -= XML_PARSE_BIG_LINES;
 }
    ctxt->linenumbers = 1;
 return (options);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  double GetMinPsnr() const {
 return psnr_;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int64_t render_latency(audio_usecase_t usecase)
{
 (void)usecase;
 /* TODO */
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Chapters::Atom::GetTime(
    const Chapters* pChapters,
    long long timecode)
{
    if (pChapters == NULL)
        return -1;
    Segment* const pSegment = pChapters->m_pSegment;
    if (pSegment == NULL)  // weird
        return -1;
    const SegmentInfo* const pInfo = pSegment->GetInfo();
    if (pInfo == NULL)
        return -1;
    const long long timecode_scale = pInfo->GetTimeCodeScale();
    if (timecode_scale < 1)  // weird
        return -1;
    if (timecode < 0)
        return -1;
    const long long result = timecode_scale * timecode;
    return result;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int main(int argc, char **argv)
{

    i32 instCount, instRunning;
    i32 i;
    u32 maxNumPics;
    u32 strmLen;
    H264SwDecRet ret;
    u32 numErrors = 0;
    u32 cropDisplay = 0;
    u32 disableOutputReordering = 0;
 FILE *finput;
 Decoder **decoder;
 char outFileName[256] = "out.yuv";


 if ( argc > 1 && strcmp(argv[1], "-T") == 0 )
 {
        fprintf(stderr, "%s\n", tagName);
 return 0;
 }

 if (argc < 2)
 {
        DEBUG((
 "Usage: %s [-Nn] [-Ooutfile] [-P] [-U] [-C] [-R] [-T] file1.264 [file2.264] .. [fileN.264]\n",
            argv[0]));
        DEBUG(("\t-Nn forces decoding to stop after n pictures\n"));
#if defined(_NO_OUT)
        DEBUG(("\t-Ooutfile output writing disabled at compile time\n"));
#else
        DEBUG(("\t-Ooutfile write output to \"outfile\" (default out.yuv)\n"));
        DEBUG(("\t-Onone does not write output\n"));
#endif
        DEBUG(("\t-C display cropped image (default decoded image)\n"));
        DEBUG(("\t-R disable DPB output reordering\n"));
        DEBUG(("\t-T to print tag name and exit\n"));
        exit(100);
 }

    instCount = argc - 1;

 /* read command line arguments */
    maxNumPics = 0;
 for (i = 1; i < (argc-1); i++)
 {
 if ( strncmp(argv[i], "-N", 2) == 0 )
 {
            maxNumPics = (u32)atoi(argv[i]+2);
            instCount--;
 }
 else if ( strncmp(argv[i], "-O", 2) == 0 )
 {
            strcpy(outFileName, argv[i]+2);
            instCount--;
 }
 else if ( strcmp(argv[i], "-C") == 0 )
 {
            cropDisplay = 1;
            instCount--;
 }
 else if ( strcmp(argv[i], "-R") == 0 )
 {
            disableOutputReordering = 1;
            instCount--;
 }
 }

 if (instCount < 1)
 {
        DEBUG(("No input files\n"));
        exit(100);
 }

 /* allocate memory for multiple decoder instances
     * one instance for every stream file */
    decoder = (Decoder **)malloc(sizeof(Decoder*)*(u32)instCount);
 if (decoder == NULL)
 {
        DEBUG(("Unable to allocate memory\n"));
        exit(100);
 }

 /* prepare each decoder instance */
 for (i = 0; i < instCount; i++)
 {
        decoder[i] = (Decoder *)calloc(1, sizeof(Decoder));

 /* open input file */
        finput = fopen(argv[argc-instCount+i],"rb");
 if (finput == NULL)
 {
            DEBUG(("Unable to open input file <%s>\n", argv[argc-instCount+i]));
            exit(100);
 }

        DEBUG(("Reading input file[%d] %s\n", i, argv[argc-instCount+i]));

 /* read input stream to buffer */
        fseek(finput,0L,SEEK_END);
        strmLen = (u32)ftell(finput);
        rewind(finput);
        decoder[i]->byteStrmStart = (u8 *)malloc(sizeof(u8)*strmLen);
 if (decoder[i]->byteStrmStart == NULL)
 {
            DEBUG(("Unable to allocate memory\n"));
            exit(100);
 }
        fread(decoder[i]->byteStrmStart, sizeof(u8), strmLen, finput);
        fclose(finput);

 /* open output file */
 if (strcmp(outFileName, "none") != 0)
 {
#if defined(_NO_OUT)
            decoder[i]->foutput = NULL;
#else
            sprintf(decoder[i]->outFileName, "%s%i", outFileName, i);
            decoder[i]->foutput = fopen(decoder[i]->outFileName, "wb");
 if (decoder[i]->foutput == NULL)
 {
                DEBUG(("Unable to open output file\n"));
                exit(100);
 }
#endif
 }

        ret = H264SwDecInit(&(decoder[i]->decInst), disableOutputReordering);

 if (ret != H264SWDEC_OK)
 {
            DEBUG(("Init failed %d\n", ret));
            exit(100);
 }

        decoder[i]->decInput.pStream = decoder[i]->byteStrmStart;
        decoder[i]->decInput.dataLen = strmLen;
        decoder[i]->decInput.intraConcealmentMethod = 0;

 }

 /* main decoding loop */
 do
 {
 /* decode once using each instance */
 for (i = 0; i < instCount; i++)
 {
            ret = H264SwDecDecode(decoder[i]->decInst,
 &(decoder[i]->decInput),
 &(decoder[i]->decOutput));

 switch(ret)
 {

 case H264SWDEC_HDRS_RDY_BUFF_NOT_EMPTY:

                    ret = H264SwDecGetInfo(decoder[i]->decInst,
 &(decoder[i]->decInfo));
 if (ret != H264SWDEC_OK)
                        exit(1);

 if (cropDisplay && decoder[i]->decInfo.croppingFlag)
 {
                        DEBUG(("Decoder[%d] Cropping params: (%d, %d) %dx%d\n",
                            i,
                            decoder[i]->decInfo.cropParams.cropLeftOffset,
                            decoder[i]->decInfo.cropParams.cropTopOffset,
                            decoder[i]->decInfo.cropParams.cropOutWidth,
                            decoder[i]->decInfo.cropParams.cropOutHeight));
 }

                    DEBUG(("Decoder[%d] Width %d Height %d\n", i,
                        decoder[i]->decInfo.picWidth,
                        decoder[i]->decInfo.picHeight));

                    DEBUG(("Decoder[%d] videoRange %d, matricCoefficients %d\n",
                        i, decoder[i]->decInfo.videoRange,
                        decoder[i]->decInfo.matrixCoefficients));
                    decoder[i]->decInput.dataLen -=
 (u32)(decoder[i]->decOutput.pStrmCurrPos -
                              decoder[i]->decInput.pStream);
                    decoder[i]->decInput.pStream =
                        decoder[i]->decOutput.pStrmCurrPos;
 break;

 case H264SWDEC_PIC_RDY_BUFF_NOT_EMPTY:
                    decoder[i]->decInput.dataLen -=
 (u32)(decoder[i]->decOutput.pStrmCurrPos -
                              decoder[i]->decInput.pStream);
                    decoder[i]->decInput.pStream =
                        decoder[i]->decOutput.pStrmCurrPos;
 /* fall through */
 case H264SWDEC_PIC_RDY:
 if (ret == H264SWDEC_PIC_RDY)
                        decoder[i]->decInput.dataLen = 0;

                    ret = H264SwDecGetInfo(decoder[i]->decInst,
 &(decoder[i]->decInfo));
 if (ret != H264SWDEC_OK)
                        exit(1);

 while (H264SwDecNextPicture(decoder[i]->decInst,
 &(decoder[i]->decPicture), 0) == H264SWDEC_PIC_RDY)
 {
                        decoder[i]->picNumber++;

                        numErrors += decoder[i]->decPicture.nbrOfErrMBs;

                        DEBUG(("Decoder[%d] PIC %d, type %s, concealed %d\n",
                            i, decoder[i]->picNumber,
                            decoder[i]->decPicture.isIdrPicture
 ? "IDR" : "NON-IDR",
                            decoder[i]->decPicture.nbrOfErrMBs));
                        fflush(stdout);

 CropWriteOutput(decoder[i]->foutput,
 (u8*)decoder[i]->decPicture.pOutputPicture,
                                cropDisplay, &(decoder[i]->decInfo));
 }

 if (maxNumPics && decoder[i]->picNumber == maxNumPics)
                        decoder[i]->decInput.dataLen = 0;
 break;

 case H264SWDEC_STRM_PROCESSED:
 case H264SWDEC_STRM_ERR:
 case H264SWDEC_PARAM_ERR:
                    decoder[i]->decInput.dataLen = 0;
 break;

 default:
                    DEBUG(("Decoder[%d] FATAL ERROR\n", i));
                    exit(10);
 break;

 }
 }

 /* check if any of the instances is still running (=has more data) */
        instRunning = instCount;
 for (i = 0; i < instCount; i++)
 {
 if (decoder[i]->decInput.dataLen == 0)
                instRunning--;
 }

 } while (instRunning);


 /* get last frames and close each instance */
 for (i = 0; i < instCount; i++)
 {
 while (H264SwDecNextPicture(decoder[i]->decInst,
 &(decoder[i]->decPicture), 1) == H264SWDEC_PIC_RDY)
 {
            decoder[i]->picNumber++;

            DEBUG(("Decoder[%d] PIC %d, type %s, concealed %d\n",
                i, decoder[i]->picNumber,
                decoder[i]->decPicture.isIdrPicture
 ? "IDR" : "NON-IDR",
                decoder[i]->decPicture.nbrOfErrMBs));
            fflush(stdout);

 CropWriteOutput(decoder[i]->foutput,
 (u8*)decoder[i]->decPicture.pOutputPicture,
                    cropDisplay, &(decoder[i]->decInfo));
 }

        H264SwDecRelease(decoder[i]->decInst);

 if (decoder[i]->foutput)
            fclose(decoder[i]->foutput);

        free(decoder[i]->byteStrmStart);

        free(decoder[i]);
 }

    free(decoder);

 if (numErrors)
 return 1;
 else
 return 0;

}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t MPEG4Source::parseSampleAuxiliaryInformationOffsets(off64_t offset, off64_t size) {
    ALOGV("parseSampleAuxiliaryInformationOffsets");
 uint8_t version;
 if (mDataSource->readAt(offset, &version, sizeof(version)) != 1) {
 return ERROR_IO;
 }
    offset++;

 uint32_t flags;
 if (!mDataSource->getUInt24(offset, &flags)) {
 return ERROR_IO;
 }
    offset += 3;

 uint32_t entrycount;
 if (!mDataSource->getUInt32(offset, &entrycount)) {
 return ERROR_IO;
 }
    offset += 4;
 if (entrycount == 0) {
 return OK;
 }
 if (entrycount > UINT32_MAX / 8) {
 return ERROR_MALFORMED;
 }

 if (entrycount > mCurrentSampleInfoOffsetsAllocSize) {
 uint64_t *newPtr = (uint64_t *)realloc(mCurrentSampleInfoOffsets, entrycount * 8);
 if (newPtr == NULL) {
 return NO_MEMORY;
 }
        mCurrentSampleInfoOffsets = newPtr;
        mCurrentSampleInfoOffsetsAllocSize = entrycount;
 }
    mCurrentSampleInfoOffsetCount = entrycount;

 if (mCurrentSampleInfoOffsets == NULL) {
 return OK;
 }

 for (size_t i = 0; i < entrycount; i++) {
 if (version == 0) {
 uint32_t tmp;
 if (!mDataSource->getUInt32(offset, &tmp)) {
 return ERROR_IO;
 }
            mCurrentSampleInfoOffsets[i] = tmp;
            offset += 4;
 } else {
 uint64_t tmp;
 if (!mDataSource->getUInt64(offset, &tmp)) {
 return ERROR_IO;
 }
            mCurrentSampleInfoOffsets[i] = tmp;
            offset += 8;
 }
 }


 off64_t drmoffset = mCurrentSampleInfoOffsets[0]; // from moof

    drmoffset += mCurrentMoofOffset;
 int ivlength;
    CHECK(mFormat->findInt32(kKeyCryptoDefaultIVSize, &ivlength));

 if (ivlength != 0 && ivlength != 8 && ivlength != 16) {
        ALOGW("unsupported IV length: %d", ivlength);
 return ERROR_MALFORMED;
 }
 for (size_t i = 0; i < mCurrentSampleInfoCount; i++) {
 if (i >= mCurrentSamples.size()) {
            ALOGW("too few samples");
 break;
 }
 Sample *smpl = &mCurrentSamples.editItemAt(i);

        memset(smpl->iv, 0, 16);
 if (mDataSource->readAt(drmoffset, smpl->iv, ivlength) != ivlength) {
 return ERROR_IO;
 }

        drmoffset += ivlength;

 int32_t smplinfosize = mCurrentDefaultSampleInfoSize;
 if (smplinfosize == 0) {
            smplinfosize = mCurrentSampleInfoSizes[i];
 }
 if (smplinfosize > ivlength) {
 uint16_t numsubsamples;
 if (!mDataSource->getUInt16(drmoffset, &numsubsamples)) {
 return ERROR_IO;
 }
            drmoffset += 2;
 for (size_t j = 0; j < numsubsamples; j++) {
 uint16_t numclear;
 uint32_t numencrypted;
 if (!mDataSource->getUInt16(drmoffset, &numclear)) {
 return ERROR_IO;
 }
                drmoffset += 2;
 if (!mDataSource->getUInt32(drmoffset, &numencrypted)) {
 return ERROR_IO;
 }
                drmoffset += 4;
                smpl->clearsizes.add(numclear);
                smpl->encryptedsizes.add(numencrypted);
 }
 } else {
            smpl->clearsizes.add(0);
            smpl->encryptedsizes.add(smpl->size);
 }
 }


 return OK;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void btif_hl_proc_create_ind(tBTA_HL *p_data){
 btif_hl_app_cb_t *p_acb;
 btif_hl_mcl_cb_t *p_mcb;
    tBTA_HL_MDEP            *p_mdep;
    UINT8                   orig_app_idx, mcl_idx, mdep_cfg_idx;
    BOOLEAN                 first_reliable_exist;
    BOOLEAN                 success = TRUE;
    tBTA_HL_DCH_CFG         rsp_cfg = BTA_HL_DCH_CFG_UNKNOWN;
    tBTA_HL_DCH_CREATE_RSP  rsp_code = BTA_HL_DCH_CREATE_RSP_CFG_REJ;
    tBTA_HL_DCH_CREATE_RSP_PARAM create_rsp_param;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

    btif_hl_find_app_idx_using_mdepId(p_data->dch_create_ind.local_mdep_id,&orig_app_idx);
 if (btif_hl_find_mcl_idx(orig_app_idx, p_data->dch_create_ind.bd_addr, &mcl_idx))
 {
        p_acb =BTIF_HL_GET_APP_CB_PTR(orig_app_idx);
        p_mcb =BTIF_HL_GET_MCL_CB_PTR(orig_app_idx, mcl_idx);

 if (btif_hl_find_mdep_cfg_idx(orig_app_idx, p_data->dch_create_ind.local_mdep_id, &mdep_cfg_idx))
 {
            p_mdep = &(p_acb->sup_feature.mdep[mdep_cfg_idx]);
            first_reliable_exist = btif_hl_is_the_first_reliable_existed(orig_app_idx, mcl_idx);
 switch (p_mdep->mdep_cfg.mdep_role)
 {
 case BTA_HL_MDEP_ROLE_SOURCE:
 if (p_data->dch_create_ind.cfg == BTA_HL_DCH_CFG_NO_PREF)
 {
 if (first_reliable_exist)
 {
                            rsp_cfg = p_acb->channel_type[mdep_cfg_idx];
 }
 else
 {
                            rsp_cfg = BTA_HL_DCH_CFG_RELIABLE;
 }
                        rsp_code = BTA_HL_DCH_CREATE_RSP_SUCCESS;
 }

 break;
 case BTA_HL_MDEP_ROLE_SINK:

                    BTIF_TRACE_DEBUG("btif_hl_proc_create_ind:BTA_HL_MDEP_ROLE_SINK");
 if ((p_data->dch_create_ind.cfg  == BTA_HL_DCH_CFG_RELIABLE) ||
 (first_reliable_exist && (p_data->dch_create_ind.cfg  == BTA_HL_DCH_CFG_STREAMING)))
 {
                        rsp_code = BTA_HL_DCH_CREATE_RSP_SUCCESS;
                        rsp_cfg = p_data->dch_create_ind.cfg;
                        BTIF_TRACE_DEBUG("btif_hl_proc_create_ind:BTA_HL_MDEP_ROLE_SINK cfg = %d",rsp_cfg);
 }
 break;
 default:
 break;
 }
 }
 }
 else
 {
        success = FALSE;
 }

 if (success)
 {
        BTIF_TRACE_DEBUG("create response rsp_code=%d rsp_cfg=%d", rsp_code, rsp_cfg );
        create_rsp_param.local_mdep_id = p_data->dch_create_ind.local_mdep_id;
        create_rsp_param.mdl_id = p_data->dch_create_ind.mdl_id;
        create_rsp_param.rsp_code = rsp_code;
        create_rsp_param.cfg_rsp = rsp_cfg;
        BTA_HlDchCreateRsp(p_mcb->mcl_handle, &create_rsp_param);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: RilSapSocket *RilSapSocket::getSocketById(RIL_SOCKET_ID socketId) {
 RilSapSocket *sap_socket;
 RilSapSocketList *current = head;

    RLOGD("Entered getSocketById");
    printList();

 while(NULL != current) {
 if(socketId == current->socket->id) {
            sap_socket = current->socket;
 return sap_socket;
 }
        current = current->next;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: make_standard_palette(png_store* ps, int npalette, int do_tRNS)
{
 static png_uint_32 palette_seed[2] = { 0x87654321, 9 };

 int i = 0;
   png_byte values[256][4];

 /* Always put in black and white plus the six primary and secondary colors.
    */
 for (; i<8; ++i)
 {
      values[i][1] = (png_byte)((i&1) ? 255U : 0U);
      values[i][2] = (png_byte)((i&2) ? 255U : 0U);
      values[i][3] = (png_byte)((i&4) ? 255U : 0U);
 }

 /* Then add 62 grays (one quarter of the remaining 256 slots). */
 {
 int j = 0;
      png_byte random_bytes[4];
      png_byte need[256];

      need[0] = 0; /*got black*/
      memset(need+1, 1, (sizeof need)-2); /*need these*/
      need[255] = 0; /*but not white*/

 while (i<70)
 {
         png_byte b;

 if (j==0)
 {
            make_four_random_bytes(palette_seed, random_bytes);
            j = 4;
 }

         b = random_bytes[--j];
 if (need[b])
 {
            values[i][1] = b;
            values[i][2] = b;
            values[i++][3] = b;
 }
 }
 }

 /* Finally add 192 colors at random - don't worry about matches to things we
    * already have, chance is less than 1/65536.  Don't worry about grays,
    * chance is the same, so we get a duplicate or extra gray less than 1 time
    * in 170.
    */
 for (; i<256; ++i)
      make_four_random_bytes(palette_seed, values[i]);

 /* Fill in the alpha values in the first byte.  Just use all possible values
    * (0..255) in an apparently random order:
    */
 {
      store_palette_entry *palette;
      png_byte selector[4];

      make_four_random_bytes(palette_seed, selector);

 if (do_tRNS)
 for (i=0; i<256; ++i)
            values[i][0] = (png_byte)(i ^ selector[0]);

 else
 for (i=0; i<256; ++i)
            values[i][0] = 255; /* no transparency/tRNS chunk */

 /* 'values' contains 256 ARGB values, but we only need 'npalette'.
       * 'npalette' will always be a power of 2: 2, 4, 16 or 256.  In the low
       * bit depth cases select colors at random, else it is difficult to have
       * a set of low bit depth palette test with any chance of a reasonable
       * range of colors.  Do this by randomly permuting values into the low
       * 'npalette' entries using an XOR mask generated here.  This also
       * permutes the npalette == 256 case in a potentially useful way (there is
       * no relationship between palette index and the color value therein!)
       */
      palette = store_write_palette(ps, npalette);

 for (i=0; i<npalette; ++i)
 {
         palette[i].alpha = values[i ^ selector[1]][0];
         palette[i].red   = values[i ^ selector[1]][1];
         palette[i].green = values[i ^ selector[1]][2];
         palette[i].blue  = values[i ^ selector[1]][3];
 }

 return palette;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::get_state(OMX_IN OMX_HANDLETYPE  hComp,
        OMX_OUT OMX_STATETYPE* state)
{
 (void) hComp;
 *state = m_state;
    DEBUG_PRINT_LOW("get_state: Returning the state %d",*state);
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::LoadedToIdleState::allocateBuffers() {
 status_t err = mCodec->allocateBuffersOnPort(kPortIndexInput);

 if (err != OK) {
 return err;
 }

 return mCodec->allocateBuffersOnPort(kPortIndexOutput);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_session_qp_range(OMX_U32 min_qp, OMX_U32 max_qp)
{
 int rc;
 struct v4l2_control control;

 if ((min_qp >= session_qp_range.minqp) && (max_qp <= session_qp_range.maxqp)) {

 if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_VP8)
            control.id = V4L2_CID_MPEG_VIDC_VIDEO_VP8_MIN_QP;
 else
            control.id = V4L2_CID_MPEG_VIDEO_H264_MIN_QP;
        control.value = min_qp;

        DEBUG_PRINT_LOW("Calling IOCTL set MIN_QP control id=%d, val=%d",
                control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

 if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_VP8)
            control.id = V4L2_CID_MPEG_VIDC_VIDEO_VP8_MAX_QP;
 else
            control.id = V4L2_CID_MPEG_VIDEO_H264_MAX_QP;
        control.value = max_qp;

        DEBUG_PRINT_LOW("Calling IOCTL set MAX_QP control id=%d, val=%d",
                control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }
 } else {
        DEBUG_PRINT_ERROR("Wrong qp values[%u %u], allowed range[%u %u]",
 (unsigned int)min_qp, (unsigned int)max_qp, (unsigned int)session_qp_range.minqp, (unsigned int)session_qp_range.maxqp);
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ih264d_err_pic_dispbuf_mgr(dec_struct_t *ps_dec)
{
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 ivd_video_decode_op_t * ps_dec_output =
 (ivd_video_decode_op_t *)ps_dec->pv_dec_out;

    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                          ps_dec->u1_pic_buf_id,
                          BUF_MGR_REF);
    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                          ps_dec->au1_pic_buf_id_mv_buf_id_map[ps_dec->u1_pic_buf_id],
                          BUF_MGR_REF);
    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                          ps_dec->u1_pic_buf_id,
                          BUF_MGR_IO);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MetadataRetrieverClient::setDataSource(
 const sp<IDataSource>& source)
{
    ALOGV("setDataSource(IDataSource)");
 Mutex::Autolock lock(mLock);

    sp<DataSource> dataSource = DataSource::CreateFromIDataSource(source);
    player_type playerType =
 MediaPlayerFactory::getPlayerType(NULL /* client */, dataSource);
    ALOGV("player type = %d", playerType);
    sp<MediaMetadataRetrieverBase> p = createRetriever(playerType);
 if (p == NULL) return NO_INIT;
 status_t ret = p->setDataSource(dataSource);
 if (ret == NO_ERROR) mRetriever = p;
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Bitmap_hasAlpha(JNIEnv* env, jobject, jlong bitmapHandle) {
 SkBitmap* bitmap = reinterpret_cast<SkBitmap*>(bitmapHandle);
 return !bitmap->isOpaque() ? JNI_TRUE : JNI_FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  unsigned getSampleRate() const {
 return mStreamInfo.sample_rate;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftAVC::SoftAVC(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoDecoderOMXComponent(
            name, "video_decoder.avc", OMX_VIDEO_CodingAVC,
            kProfileLevels, ARRAY_SIZE(kProfileLevels),
 320 /* width */, 240 /* height */, callbacks, appData, component),
      mHandle(NULL),
      mInputBufferCount(0),
      mFirstPicture(NULL),
      mFirstPictureId(-1),
      mPicId(0),
      mHeadersDecoded(false),
      mEOSStatus(INPUT_DATA_AVAILABLE),
      mSignalledError(false) {
 const size_t kMinCompressionRatio = 2;
 const size_t kMaxOutputBufferSize = 2048 * 2048 * 3 / 2;
    initPorts(
            kNumInputBuffers, kMaxOutputBufferSize / kMinCompressionRatio /* minInputBufferSize */,
            kNumOutputBuffers, MEDIA_MIMETYPE_VIDEO_AVC, kMinCompressionRatio);

    CHECK_EQ(initDecoder(), (status_t)OK);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void acquire_node_locked(struct node* node)
{
    node->refcount++;
    TRACE("ACQUIRE %p (%s) rc=%d\n", node, node->name, node->refcount);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t ctrl_set_decryptor(vpx_codec_alg_priv_t *ctx,
                                          va_list args) {
  vpx_decrypt_init *init = va_arg(args, vpx_decrypt_init *);
  ctx->decrypt_cb = init ? init->decrypt_cb : NULL;
  ctx->decrypt_state = init ? init->decrypt_state : NULL;
 return VPX_CODEC_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t detachNextBuffer(sp<GraphicBuffer>* outBuffer,
            sp<Fence>* outFence) {
 if (outBuffer == NULL) {
            ALOGE("detachNextBuffer: outBuffer must not be NULL");
 return BAD_VALUE;
 } else if (outFence == NULL) {
            ALOGE("detachNextBuffer: outFence must not be NULL");
 return BAD_VALUE;
 }
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor());
 status_t result = remote()->transact(DETACH_NEXT_BUFFER, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
        result = reply.readInt32();
 if (result == NO_ERROR) {
 bool nonNull = reply.readInt32();
 if (nonNull) {
 *outBuffer = new GraphicBuffer;
                reply.read(**outBuffer);
 }
            nonNull = reply.readInt32();
 if (nonNull) {
 *outFence = new Fence;
                reply.read(**outFence);
 }
 }
 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API FLAC__bool FLAC__stream_decoder_set_metadata_respond_application(FLAC__StreamDecoder *decoder, const FLAC__byte id[4])
{
	FLAC__ASSERT(0 != decoder);
	FLAC__ASSERT(0 != decoder->private_);
	FLAC__ASSERT(0 != decoder->protected_);
	FLAC__ASSERT(0 != id);
 if(decoder->protected_->state != FLAC__STREAM_DECODER_UNINITIALIZED)
 return false;

 if(decoder->private_->metadata_filter[FLAC__METADATA_TYPE_APPLICATION])
 return true;

	FLAC__ASSERT(0 != decoder->private_->metadata_filter_ids);

 if(decoder->private_->metadata_filter_ids_count == decoder->private_->metadata_filter_ids_capacity) {
 if(0 == (decoder->private_->metadata_filter_ids = safe_realloc_mul_2op_(decoder->private_->metadata_filter_ids, decoder->private_->metadata_filter_ids_capacity, /*times*/2))) {
			decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 return false;
 }
		decoder->private_->metadata_filter_ids_capacity *= 2;
 }

	memcpy(decoder->private_->metadata_filter_ids + decoder->private_->metadata_filter_ids_count * (FLAC__STREAM_METADATA_APPLICATION_ID_LEN/8), id, (FLAC__STREAM_METADATA_APPLICATION_ID_LEN/8));
	decoder->private_->metadata_filter_ids_count++;

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_inter_slice_data_cavlc(dec_struct_t * ps_dec,
 dec_slice_params_t * ps_slice,
                                           UWORD16 u2_first_mb_in_slice)
{
    UWORD32 uc_more_data_flag;
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2, u1_mb_idx;
    UWORD32 i2_mb_skip_run;
    UWORD32 u1_read_mb_type;

    UWORD32 u1_mbaff;
    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end = 0;
    UWORD32 u1_tfr_n_mb = 0;
    UWORD32 u1_decode_nmb = 0;

 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD32 u1_mb_threshold;
    WORD32 ret = OK;

 /******************************************************/
 /* Initialisations specific to B or P slice           */
 /******************************************************/

 if(ps_slice->u1_slice_type == P_SLICE)
 {
        u1_inter_mb_type = P_MB;
        u1_deblk_mb_type = D_INTER_MB;
        u1_mb_threshold = 5;
 }
 else // B_SLICE
 {
        u1_inter_mb_type = B_MB;
        u1_deblk_mb_type = D_B_SLICE;
        u1_mb_threshold = 23;
 }
 /******************************************************/
 /* Slice Level Initialisations                        */
 /******************************************************/
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    u1_num_mbs = u1_mb_idx;

    u1_num_mbsNby2 = 0;
    u1_mbaff = ps_slice->u1_mbaff_frame_flag;
    i2_cur_mb_addr = u2_first_mb_in_slice << u1_mbaff;
    i2_mb_skip_run = 0;
    uc_more_data_flag = 1;
    u1_read_mb_type = 0;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

        ps_dec->pv_prev_mb_parse_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 {
            ret = ERROR_MB_ADDRESS_T;
 break;
 }


        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 if((!i2_mb_skip_run) && (!u1_read_mb_type))
 {

            UWORD32 u4_bitstream_offset = *pu4_bitstrm_ofst;
            UWORD32 u4_word, u4_ldz;

 /***************************************************************/
 /* Find leading zeros in next 32 bits                          */
 /***************************************************************/
            NEXTBITS_32(u4_word, u4_bitstream_offset, pu4_bitstrm_buf);

            u4_ldz = CLZ(u4_word);

 /* Flush the ps_bitstrm */
            u4_bitstream_offset += (u4_ldz + 1);
 /* Read the suffix from the ps_bitstrm */
            u4_word = 0;
 if(u4_ldz)
 {
                GETBITS(u4_word, u4_bitstream_offset, pu4_bitstrm_buf,
                        u4_ldz);
 }
 *pu4_bitstrm_ofst = u4_bitstream_offset;
            i2_mb_skip_run = ((1 << u4_ldz) + u4_word - 1);
            COPYTHECONTEXT("mb_skip_run", i2_mb_skip_run);
            uc_more_data_flag = MORE_RBSP_DATA(ps_bitstrm);
            u1_read_mb_type = uc_more_data_flag;
 }

 /***************************************************************/
 /* Get the required information for decoding of MB                  */
 /* mb_x, mb_y , neighbour availablity,                              */
 /***************************************************************/
        ps_dec->pf_get_mb_info(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /***************************************************************/
 /* Set the deblocking parameters for this MB                   */
 /***************************************************************/
 if(ps_dec->u4_app_disable_deblk_frm == 0)
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);

 if(i2_mb_skip_run)
 {
 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
            ps_dec->i1_prev_mb_qp_delta = 0;
            ps_dec->u1_sub_mb_num = 0;
            ps_cur_mb_info->u1_mb_type = MB_SKIP;
            ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
            ps_cur_mb_info->u1_cbp = 0;

 {
 /* Storing Skip partition info */
 parse_part_params_t *ps_part_info = ps_dec->ps_part;
                ps_part_info->u1_is_direct = PART_DIRECT_16x16;
                ps_part_info->u1_sub_mb_num = 0;
                ps_dec->ps_part++;
 }

 /* Update Nnzs */
            ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

            ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
            ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

            i2_mb_skip_run--;
 }
 else
 {
            u1_read_mb_type = 0;
 /**************************************************************/
 /* Macroblock Layer Begins, Decode the u1_mb_type                */
 /**************************************************************/
 {
                UWORD32 u4_bitstream_offset = *pu4_bitstrm_ofst;
                UWORD32 u4_word, u4_ldz, u4_temp;


 /***************************************************************/
 /* Find leading zeros in next 32 bits                          */
 /***************************************************************/
                NEXTBITS_32(u4_word, u4_bitstream_offset, pu4_bitstrm_buf);
                u4_ldz = CLZ(u4_word);
 /* Flush the ps_bitstrm */
                u4_bitstream_offset += (u4_ldz + 1);
 /* Read the suffix from the ps_bitstrm */
                u4_word = 0;
 if(u4_ldz)
                    GETBITS(u4_word, u4_bitstream_offset, pu4_bitstrm_buf,
                            u4_ldz);
 *pu4_bitstrm_ofst = u4_bitstream_offset;
                u4_temp = ((1 << u4_ldz) + u4_word - 1);
 if(u4_temp > (UWORD32)(25 + u1_mb_threshold))
 return ERROR_MB_TYPE;
                u1_mb_type = u4_temp;
                COPYTHECONTEXT("u1_mb_type", u1_mb_type);
 }
            ps_cur_mb_info->u1_mb_type = u1_mb_type;

 /**************************************************************/
 /* Parse Macroblock data                                      */
 /**************************************************************/
 if(u1_mb_type < u1_mb_threshold)
 {
                ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;

                ret = ps_dec->pf_parse_inter_mb(ps_dec, ps_cur_mb_info, u1_num_mbs,
                                          u1_num_mbsNby2);
 if(ret != OK)
 return ret;
                ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;
 }
 else
 {
 /* Storing Intra partition info */
                ps_parse_mb_data->u1_num_part = 0;
                ps_parse_mb_data->u1_isI_mb = 1;

 if((25 + u1_mb_threshold) == u1_mb_type)
 {
 /* I_PCM_MB */
                    ps_cur_mb_info->ps_curmb->u1_mb_type = I_PCM_MB;
                    ret = ih264d_parse_ipcm_mb(ps_dec, ps_cur_mb_info, u1_num_mbs);
 if(ret != OK)
 return ret;
                    ps_dec->u1_qp = 0;
 }
 else
 {
                    ret = ih264d_parse_imb_cavlc(
                                    ps_dec, ps_cur_mb_info, u1_num_mbs,
 (UWORD8)(u1_mb_type - u1_mb_threshold));
 if(ret != OK)
 return ret;
 }

                ps_cur_deblk_mb->u1_mb_type |= D_INTRA_MB;
 }
            uc_more_data_flag = MORE_RBSP_DATA(ps_bitstrm);
 }
        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if(u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }
 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/

         i2_cur_mb_addr++;
 
         u1_num_mbs++;
        ps_dec->u2_total_mbs_coded++;
         u1_num_mbsNby2++;
         ps_parse_mb_data++;
 
 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = (!(uc_more_data_flag || i2_mb_skip_run));
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 /*u1_dma_nby2mb   = u1_decode_nmb ||
         (u1_num_mbsNby2 == ps_dec->u1_recon_mb_grp_pair);*/

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

 {
                ps_parse_mb_data = ps_dec->ps_parse_mb_data;
                ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }
 }

 /*H264_DEC_DEBUG_PRINT("Pic: %d Mb_X=%d Mb_Y=%d",
         ps_slice->i4_poc >> ps_slice->u1_field_pic_flag,
         ps_dec->u2_mbx,ps_dec->u2_mby + (1 - ps_cur_mb_info->u1_topmb));
         H264_DEC_DEBUG_PRINT("u1_decode_nmb: %d", u1_decode_nmb);*/
 if(u1_decode_nmb)
 {



 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,

                                             u1_num_mbs_next, u1_tfr_n_mb,
                                             u1_end_of_row);
             }
             if(u1_tfr_n_mb)
                 u1_num_mbs = 0;
             u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;

 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - (u2_first_mb_in_slice << u1_mbaff);


 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: compare_two_images(Image *a, Image *b, int via_linear,
   png_const_colorp background)
{
 ptrdiff_t stridea = a->stride;
 ptrdiff_t strideb = b->stride;
   png_const_bytep rowa = a->buffer+16;
   png_const_bytep rowb = b->buffer+16;
 const png_uint_32 width = a->image.width;
 const png_uint_32 height = a->image.height;
 const png_uint_32 formata = a->image.format;
 const png_uint_32 formatb = b->image.format;
 const unsigned int a_sample = PNG_IMAGE_SAMPLE_SIZE(formata);
 const unsigned int b_sample = PNG_IMAGE_SAMPLE_SIZE(formatb);
 int alpha_added, alpha_removed;
 int bchannels;
 int btoa[4];
   png_uint_32 y;
 Transform tr;

 /* This should never happen: */
 if (width != b->image.width || height != b->image.height)
 return logerror(a, a->file_name, ": width x height changed: ",
         b->file_name);

 /* Set up the background and the transform */
   transform_from_formats(&tr, a, b, background, via_linear);

 /* Find the first row and inter-row space. */
 if (!(formata & PNG_FORMAT_FLAG_COLORMAP) &&
 (formata & PNG_FORMAT_FLAG_LINEAR))
      stridea *= 2;

 if (!(formatb & PNG_FORMAT_FLAG_COLORMAP) &&
 (formatb & PNG_FORMAT_FLAG_LINEAR))
      strideb *= 2;

 if (stridea < 0) rowa += (height-1) * (-stridea);
 if (strideb < 0) rowb += (height-1) * (-strideb);

 /* First shortcut the two colormap case by comparing the image data; if it
    * matches then we expect the colormaps to match, although this is not
    * absolutely necessary for an image match.  If the colormaps fail to match
    * then there is a problem in libpng.
    */
 if (formata & formatb & PNG_FORMAT_FLAG_COLORMAP)
 {
 /* Only check colormap entries that actually exist; */
      png_const_bytep ppa, ppb;
 int match;
      png_byte in_use[256], amax = 0, bmax = 0;

      memset(in_use, 0, sizeof in_use);

      ppa = rowa;
      ppb = rowb;

 /* Do this the slow way to accumulate the 'in_use' flags, don't break out
       * of the loop until the end; this validates the color-mapped data to
       * ensure all pixels are valid color-map indexes.
       */
 for (y=0, match=1; y<height && match; ++y, ppa += stridea, ppb += strideb)
 {
         png_uint_32 x;

 for (x=0; x<width; ++x)
 {
            png_byte bval = ppb[x];
            png_byte aval = ppa[x];

 if (bval > bmax)
               bmax = bval;

 if (bval != aval)
               match = 0;

            in_use[aval] = 1;
 if (aval > amax)
               amax = aval;
 }
 }

 /* If the buffers match then the colormaps must too. */
 if (match)
 {
 /* Do the color-maps match, entry by entry?  Only check the 'in_use'
          * entries.  An error here should be logged as a color-map error.
          */
         png_const_bytep a_cmap = (png_const_bytep)a->colormap;
         png_const_bytep b_cmap = (png_const_bytep)b->colormap;
 int result = 1; /* match by default */

 /* This is used in logpixel to get the error message correct. */
         tr.is_palette = 1;

 for (y=0; y<256; ++y, a_cmap += a_sample, b_cmap += b_sample)
 if (in_use[y])
 {
 /* The colormap entries should be valid, but because libpng doesn't
             * do any checking at present the original image may contain invalid
             * pixel values.  These cause an error here (at present) unless
             * accumulating errors in which case the program just ignores them.
             */
 if (y >= a->image.colormap_entries)
 {
 if ((a->opts & ACCUMULATE) == 0)
 {
 char pindex[9];
                  sprintf(pindex, "%lu[%lu]", (unsigned long)y,
 (unsigned long)a->image.colormap_entries);
                  logerror(a, a->file_name, ": bad pixel index: ", pindex);
 }
               result = 0;
 }

 
             else if (y >= b->image.colormap_entries)
             {
               if ((a->opts & ACCUMULATE) == 0)
                   {
                   char pindex[9];
                   sprintf(pindex, "%lu[%lu]", (unsigned long)y,
 (unsigned long)b->image.colormap_entries);
                  logerror(b, b->file_name, ": bad pixel index: ", pindex);
 }
               result = 0;
 }

 /* All the mismatches are logged here; there can only be 256! */
 else if (!cmppixel(&tr, a_cmap, b_cmap, 0, y))
               result = 0;
 }

 /* If reqested copy the error values back from the Transform. */
 if (a->opts & ACCUMULATE)
 {
            tr.error_ptr[0] = tr.error[0];
            tr.error_ptr[1] = tr.error[1];
            tr.error_ptr[2] = tr.error[2];
            tr.error_ptr[3] = tr.error[3];
            result = 1; /* force a continue */
 }

 return result;
 }

 /* else the image buffers don't match pixel-wise so compare sample values
       * instead, but first validate that the pixel indexes are in range (but
       * only if not accumulating, when the error is ignored.)
       */
 else if ((a->opts & ACCUMULATE) == 0)
 {
 /* Check the original image first,
          * TODO: deal with input images with bad pixel values?
          */
 if (amax >= a->image.colormap_entries)
 {
 char pindex[9];
            sprintf(pindex, "%d[%lu]", amax,
 (unsigned long)a->image.colormap_entries);
 return logerror(a, a->file_name, ": bad pixel index: ", pindex);
 }

 else if (bmax >= b->image.colormap_entries)
 {
 char pindex[9];
            sprintf(pindex, "%d[%lu]", bmax,
 (unsigned long)b->image.colormap_entries);
 return logerror(b, b->file_name, ": bad pixel index: ", pindex);
 }
 }
 }

 /* We can directly compare pixel values without the need to use the read
    * or transform support (i.e. a memory compare) if:
    *
    * 1) The bit depth has not changed.
    * 2) RGB to grayscale has not been done (the reverse is ok; we just compare
    *    the three RGB values to the original grayscale.)
    * 3) An alpha channel has not been removed from an 8-bit format, or the
    *    8-bit alpha value of the pixel was 255 (opaque).
    *
    * If an alpha channel has been *added* then it must have the relevant opaque
    * value (255 or 65535).
    *
    * The fist two the tests (in the order given above) (using the boolean
    * equivalence !a && !b == !(a || b))
    */
 if (!(((formata ^ formatb) & PNG_FORMAT_FLAG_LINEAR) |
 (formata & (formatb ^ PNG_FORMAT_FLAG_COLOR) & PNG_FORMAT_FLAG_COLOR)))
 {
 /* Was an alpha channel changed? */
 const png_uint_32 alpha_changed = (formata ^ formatb) &
         PNG_FORMAT_FLAG_ALPHA;

 /* Was an alpha channel removed?  (The third test.)  If so the direct
       * comparison is only possible if the input alpha is opaque.
       */
      alpha_removed = (formata & alpha_changed) != 0;

 /* Was an alpha channel added? */
      alpha_added = (formatb & alpha_changed) != 0;

 /* The channels may have been moved between input and output, this finds
       * out how, recording the result in the btoa array, which says where in
       * 'a' to find each channel of 'b'.  If alpha was added then btoa[alpha]
       * ends up as 4 (and is not used.)
       */
 {
 int i;
         png_byte aloc[4];
         png_byte bloc[4];

 /* The following are used only if the formats match, except that
          * 'bchannels' is a flag for matching formats.  btoa[x] says, for each
          * channel in b, where to find the corresponding value in a, for the
          * bchannels.  achannels may be different for a gray to rgb transform
          * (a will be 1 or 2, b will be 3 or 4 channels.)
          */
 (void)component_loc(aloc, formata);
         bchannels = component_loc(bloc, formatb);

 /* Hence the btoa array. */
 for (i=0; i<4; ++i) if (bloc[i] < 4)
            btoa[bloc[i]] = aloc[i]; /* may be '4' for alpha */

 if (alpha_added)
            alpha_added = bloc[0]; /* location of alpha channel in image b */

 else
            alpha_added = 4; /* Won't match an image b channel */

 if (alpha_removed)
            alpha_removed = aloc[0]; /* location of alpha channel in image a */

 else
            alpha_removed = 4;
 }
 }

 else
 {
 /* Direct compare is not possible, cancel out all the corresponding local
       * variables.
       */
      bchannels = 0;
      alpha_removed = alpha_added = 4;
      btoa[3] = btoa[2] = btoa[1] = btoa[0] = 4; /* 4 == not present */
 }

 for (y=0; y<height; ++y, rowa += stridea, rowb += strideb)
 {
      png_const_bytep ppa, ppb;
      png_uint_32 x;

 for (x=0, ppa=rowa, ppb=rowb; x<width; ++x)
 {
         png_const_bytep psa, psb;

 if (formata & PNG_FORMAT_FLAG_COLORMAP)
            psa = (png_const_bytep)a->colormap + a_sample * *ppa++;
 else
            psa = ppa, ppa += a_sample;

 if (formatb & PNG_FORMAT_FLAG_COLORMAP)
            psb = (png_const_bytep)b->colormap + b_sample * *ppb++;
 else
            psb = ppb, ppb += b_sample;

 /* Do the fast test if possible. */
 if (bchannels)
 {
 /* Check each 'b' channel against either the corresponding 'a'
             * channel or the opaque alpha value, as appropriate.  If
             * alpha_removed value is set (not 4) then also do this only if the
             * 'a' alpha channel (alpha_removed) is opaque; only relevant for
             * the 8-bit case.
             */
 if (formatb & PNG_FORMAT_FLAG_LINEAR) /* 16-bit checks */
 {
               png_const_uint_16p pua = aligncastconst(png_const_uint_16p, psa);
               png_const_uint_16p pub = aligncastconst(png_const_uint_16p, psb);

 switch (bchannels)
 {
 case 4:
 if (pua[btoa[3]] != pub[3]) break;
 case 3:
 if (pua[btoa[2]] != pub[2]) break;
 case 2:
 if (pua[btoa[1]] != pub[1]) break;
 case 1:
 if (pua[btoa[0]] != pub[0]) break;
 if (alpha_added != 4 && pub[alpha_added] != 65535) break;
 continue; /* x loop */
 default:
 break; /* impossible */
 }
 }

 else if (alpha_removed == 4 || psa[alpha_removed] == 255)
 {
 switch (bchannels)
 {
 case 4:
 if (psa[btoa[3]] != psb[3]) break;
 case 3:
 if (psa[btoa[2]] != psb[2]) break;
 case 2:
 if (psa[btoa[1]] != psb[1]) break;
 case 1:
 if (psa[btoa[0]] != psb[0]) break;
 if (alpha_added != 4 && psb[alpha_added] != 255) break;
 continue; /* x loop */
 default:
 break; /* impossible */
 }
 }
 }

 /* If we get to here the fast match failed; do the slow match for this
          * pixel.
          */
 if (!cmppixel(&tr, psa, psb, x, y) && (a->opts & KEEP_GOING) == 0)
 return 0; /* error case */
 }
 }

 /* If reqested copy the error values back from the Transform. */
 if (a->opts & ACCUMULATE)
 {
      tr.error_ptr[0] = tr.error[0];
      tr.error_ptr[1] = tr.error[1];
      tr.error_ptr[2] = tr.error[2];
      tr.error_ptr[3] = tr.error[3];
 }

 return 1;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  bool Cues::LoadCuePoint() const {
   const long long stop = m_start + m_size;
 
   if (m_pos >= stop)
     return false;  // nothing else to do
 
  Init();
 
   IMkvReader* const pReader = m_pSegment->m_pReader;
 
 while (m_pos < stop) {
 const long long idpos = m_pos;

 
     long len;
 
    const long long id = ReadUInt(pReader, m_pos, len);
    assert(id >= 0);  // TODO
    assert((m_pos + len) <= stop);
 
     m_pos += len;  // consume ID
 
     const long long size = ReadUInt(pReader, m_pos, len);
    assert(size >= 0);
    assert((m_pos + len) <= stop);
 
     m_pos += len;  // consume Size field
    assert((m_pos + size) <= stop);
 
     if (id != 0x3B) {  // CuePoint ID
       m_pos += size;  // consume payload
      assert(m_pos <= stop);
 
       continue;
     }
 
    assert(m_preload_count > 0);
    CuePoint* const pCP = m_cue_points[m_count];
    assert(pCP);
    assert((pCP->GetTimeCode() >= 0) || (-pCP->GetTimeCode() == idpos));
    if (pCP->GetTimeCode() < 0 && (-pCP->GetTimeCode() != idpos))
       return false;
 
    pCP->Load(pReader);
     ++m_count;
     --m_preload_count;
 
     m_pos += size;  // consume payload
    assert(m_pos <= stop);
 
     return true;  // yes, we loaded a cue point
   }
 
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void SoundPool::stop(int channelID)
{
    ALOGV("stop(%d)", channelID);
 Mutex::Autolock lock(&mLock);
 SoundChannel* channel = findChannel(channelID);
 if (channel) {
        channel->stop();
 } else {
        channel = findNextChannel(channelID);
 if (channel)
            channel->clearNextEvent();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMPEG4Encoder::initEncParams() {
    CHECK(mHandle != NULL);
    memset(mHandle, 0, sizeof(tagvideoEncControls));

    CHECK(mEncParams != NULL);
    memset(mEncParams, 0, sizeof(tagvideoEncOptions));
 if (!PVGetDefaultEncOption(mEncParams, 0)) {
        ALOGE("Failed to get default encoding parameters");
 return OMX_ErrorUndefined;
 }
    mEncParams->encMode = mEncodeMode;
    mEncParams->encWidth[0] = mWidth;
    mEncParams->encHeight[0] = mHeight;
    mEncParams->encFrameRate[0] = mFramerate >> 16; // mFramerate is in Q16 format
    mEncParams->rcType = VBR_1;
    mEncParams->vbvDelay = 5.0f;

    mEncParams->profile_level = CORE_PROFILE_LEVEL2;
    mEncParams->packetSize = 32;
    mEncParams->rvlcEnable = PV_OFF;
    mEncParams->numLayers = 1;
    mEncParams->timeIncRes = 1000;
    mEncParams->tickPerSrc = ((int64_t)mEncParams->timeIncRes << 16) / mFramerate;

    mEncParams->bitRate[0] = mBitrate;
    mEncParams->iQuant[0] = 15;
    mEncParams->pQuant[0] = 12;
    mEncParams->quantType[0] = 0;
    mEncParams->noFrameSkipped = PV_OFF;

 if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {
        free(mInputFrameData);
        mInputFrameData = NULL;
 if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {
            ALOGE("b/25812794, Buffer size is too big.");
 return OMX_ErrorBadParameter;
 }
        mInputFrameData =
 (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);
        CHECK(mInputFrameData != NULL);
 }

 if (mWidth % 16 != 0 || mHeight % 16 != 0) {
        ALOGE("Video frame size %dx%d must be a multiple of 16",
            mWidth, mHeight);
 return OMX_ErrorBadParameter;
 }

 if (mIDRFrameRefreshIntervalInSec < 0) {
        mEncParams->intraPeriod = -1;
 } else if (mIDRFrameRefreshIntervalInSec == 0) {
        mEncParams->intraPeriod = 1; // All I frames
 } else {
        mEncParams->intraPeriod =
 (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16;
 }

    mEncParams->numIntraMB = 0;
    mEncParams->sceneDetect = PV_ON;
    mEncParams->searchRange = 16;
    mEncParams->mv8x8Enable = PV_OFF;
    mEncParams->gobHeaderInterval = 0;
    mEncParams->useACPred = PV_ON;
    mEncParams->intraDCVlcTh = 0;

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void semaphore_post(semaphore_t *semaphore) {
  assert(semaphore != NULL);
  assert(semaphore->fd != INVALID_FD);

 if (eventfd_write(semaphore->fd, 1ULL) == -1)
    LOG_ERROR("%s unable to post to semaphore: %s", __func__, strerror(errno));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int64_t IPCThreadState::clearCallingIdentity()
{
 int64_t token = ((int64_t)mCallingUid<<32) | mCallingPid;
    clearCaller();
 return token;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Region_setPath(JNIEnv* env, jobject, jlong dstHandle,
                               jlong pathHandle, jlong clipHandle) {
 SkRegion*       dst  = reinterpret_cast<SkRegion*>(dstHandle);
 const SkPath*   path = reinterpret_cast<SkPath*>(pathHandle);
 const SkRegion* clip = reinterpret_cast<SkRegion*>(clipHandle);
 SkASSERT(dst && path && clip);
 bool result = dst->setPath(*path, *clip);
 return boolTojboolean(result);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::set_callbacks(OMX_IN OMX_HANDLETYPE        hComp,
        OMX_IN OMX_CALLBACKTYPE* callbacks,
        OMX_IN OMX_PTR             appData)
{
 (void) hComp;
    m_cb       = *callbacks;
    DEBUG_PRINT_LOW("Callbacks Set %p %p %p",m_cb.EmptyBufferDone,\
            m_cb.EventHandler,m_cb.FillBufferDone);
    m_app_data =    appData;
 return OMX_ErrorNotImplemented;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_get_frame_dimensions(iv_obj_t *ps_codec_obj,
 void *pv_api_ip,
 void *pv_api_op)
{
 ihevcd_cxa_ctl_get_frame_dimensions_ip_t *ps_ip;
 ihevcd_cxa_ctl_get_frame_dimensions_op_t *ps_op;
 codec_t *ps_codec = (codec_t *)ps_codec_obj->pv_codec_handle;
    WORD32 disp_wd, disp_ht, buffer_wd, buffer_ht, x_offset, y_offset;
    ps_ip = (ihevcd_cxa_ctl_get_frame_dimensions_ip_t *)pv_api_ip;
    ps_op = (ihevcd_cxa_ctl_get_frame_dimensions_op_t *)pv_api_op;
    UNUSED(ps_ip);
 if(ps_codec->i4_sps_done)
 {
        disp_wd = ps_codec->i4_disp_wd;
        disp_ht = ps_codec->i4_disp_ht;

 if(0 == ps_codec->i4_share_disp_buf)
 {
            buffer_wd = disp_wd;
            buffer_ht = disp_ht;
 }
 else
 {
            buffer_wd = ps_codec->i4_strd;
            buffer_ht = ps_codec->i4_ht + PAD_HT;
 }
 }
 else
 {

        disp_wd = 0;
        disp_ht = 0;

 if(0 == ps_codec->i4_share_disp_buf)
 {
            buffer_wd = disp_wd;
            buffer_ht = disp_ht;
 }
 else
 {
            buffer_wd = ALIGN16(disp_wd) + PAD_WD;
            buffer_ht = ALIGN16(disp_ht) + PAD_HT;

 }
 }
 if(ps_codec->i4_strd > buffer_wd)
        buffer_wd = ps_codec->i4_strd;

 if(0 == ps_codec->i4_share_disp_buf)
 {
        x_offset = 0;
        y_offset = 0;
 }
 else
 {
        y_offset = PAD_TOP;
        x_offset = PAD_LEFT;
 }

    ps_op->u4_disp_wd[0] = disp_wd;
    ps_op->u4_disp_ht[0] = disp_ht;
    ps_op->u4_buffer_wd[0] = buffer_wd;
    ps_op->u4_buffer_ht[0] = buffer_ht;
    ps_op->u4_x_offset[0] = x_offset;
    ps_op->u4_y_offset[0] = y_offset;

    ps_op->u4_disp_wd[1] = ps_op->u4_disp_wd[2] = ((ps_op->u4_disp_wd[0] + 1)
 >> 1);
    ps_op->u4_disp_ht[1] = ps_op->u4_disp_ht[2] = ((ps_op->u4_disp_ht[0] + 1)
 >> 1);
    ps_op->u4_buffer_wd[1] = ps_op->u4_buffer_wd[2] = (ps_op->u4_buffer_wd[0]
 >> 1);
    ps_op->u4_buffer_ht[1] = ps_op->u4_buffer_ht[2] = (ps_op->u4_buffer_ht[0]
 >> 1);
    ps_op->u4_x_offset[1] = ps_op->u4_x_offset[2] = (ps_op->u4_x_offset[0]
 >> 1);
    ps_op->u4_y_offset[1] = ps_op->u4_y_offset[2] = (ps_op->u4_y_offset[0]
 >> 1);

 if((ps_codec->e_chroma_fmt == IV_YUV_420SP_UV)
 || (ps_codec->e_chroma_fmt == IV_YUV_420SP_VU))
 {
        ps_op->u4_disp_wd[2] = 0;
        ps_op->u4_disp_ht[2] = 0;
        ps_op->u4_buffer_wd[2] = 0;
        ps_op->u4_buffer_ht[2] = 0;
        ps_op->u4_x_offset[2] = 0;
        ps_op->u4_y_offset[2] = 0;

        ps_op->u4_disp_wd[1] <<= 1;
        ps_op->u4_buffer_wd[1] <<= 1;
        ps_op->u4_x_offset[1] <<= 1;
 }

 return IV_SUCCESS;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Chapters(Segment* pSegment, long long payload_start,
 long long payload_size, long long element_start,
 long long element_size)
 : m_pSegment(pSegment),
      m_start(payload_start),
      m_size(payload_size),
      m_element_start(element_start),
      m_element_size(element_size),
      m_editions(NULL),
      m_editions_size(0),
      m_editions_count(0) {}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:         querySurfaceMediaSourceFromMediaServer()
{
 Mutex::Autolock _l(mLock);
    mSurfaceMediaSource =
            mMediaRecorder->querySurfaceMediaSource();
 if (mSurfaceMediaSource == NULL) {
        ALOGE("SurfaceMediaSource could not be initialized!");
 }
 return mSurfaceMediaSource;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX::CallbackDispatcher::CallbackDispatcher(OMXNodeInstance *owner)
 : mOwner(owner),
      mDone(false) {
    mThread = new CallbackDispatcherThread(this);
    mThread->run("OMXCallbackDisp", ANDROID_PRIORITY_FOREGROUND);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::resetDataSource() {
    mHTTPService.clear();
    mHttpSource.clear();
    mUri.clear();
    mUriHeaders.clear();
 if (mFd >= 0) {
        close(mFd);
        mFd = -1;
 }
    mOffset = 0;
    mLength = 0;
    setDrmPlaybackStatusIfNeeded(Playback::STOP, 0);
    mDecryptHandle = NULL;
    mDrmManagerClient = NULL;
    mStarted = false;
    mStopRead = true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void BeginPassHook(unsigned int /*pass*/) {
    file_size_ = 0;
    psnr_ = 0.0;
    n_frames_ = 0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::get_supported_profile_level_for_1080p(OMX_VIDEO_PARAM_PROFILELEVELTYPE *profileLevelType)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 if (!profileLevelType)
 return OMX_ErrorBadParameter;

 if (profileLevelType->nPortIndex == 0) {
 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.avc",OMX_MAX_STRINGNAME_SIZE)) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = OMX_VIDEO_AVCProfileBaseline;
                profileLevelType->eLevel   = OMX_VIDEO_AVCLevel4;

 } else if (profileLevelType->nProfileIndex == 1) {
                profileLevelType->eProfile = OMX_VIDEO_AVCProfileMain;
                profileLevelType->eLevel   = OMX_VIDEO_AVCLevel4;
 } else if (profileLevelType->nProfileIndex == 2) {
                profileLevelType->eProfile = OMX_VIDEO_AVCProfileHigh;
                profileLevelType->eLevel   = OMX_VIDEO_AVCLevel4;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mvc", OMX_MAX_STRINGNAME_SIZE)) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = QOMX_VIDEO_MVCProfileStereoHigh;
                profileLevelType->eLevel   = QOMX_VIDEO_MVCLevel51;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.hevc", OMX_MAX_STRINGNAME_SIZE)) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = OMX_VIDEO_HEVCProfileMain;
                profileLevelType->eLevel   = OMX_VIDEO_HEVCMainTierLevel51;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else if ((!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.h263",OMX_MAX_STRINGNAME_SIZE))) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = OMX_VIDEO_H263ProfileBaseline;
                profileLevelType->eLevel   = OMX_VIDEO_H263Level70;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg4",OMX_MAX_STRINGNAME_SIZE)) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = OMX_VIDEO_MPEG4ProfileSimple;
                profileLevelType->eLevel   = OMX_VIDEO_MPEG4Level5;
 } else if (profileLevelType->nProfileIndex == 1) {
                profileLevelType->eProfile = OMX_VIDEO_MPEG4ProfileAdvancedSimple;
                profileLevelType->eLevel   = OMX_VIDEO_MPEG4Level5;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8",OMX_MAX_STRINGNAME_SIZE)) {
            eRet = OMX_ErrorNoMore;
 } else if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mpeg2",OMX_MAX_STRINGNAME_SIZE)) {
 if (profileLevelType->nProfileIndex == 0) {
                profileLevelType->eProfile = OMX_VIDEO_MPEG2ProfileSimple;
                profileLevelType->eLevel   = OMX_VIDEO_MPEG2LevelHL;
 } else if (profileLevelType->nProfileIndex == 1) {
                profileLevelType->eProfile = OMX_VIDEO_MPEG2ProfileMain;
                profileLevelType->eLevel   = OMX_VIDEO_MPEG2LevelHL;
 } else {
                DEBUG_PRINT_LOW("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported nProfileIndex ret NoMore %u",
 (unsigned int)profileLevelType->nProfileIndex);
                eRet = OMX_ErrorNoMore;
 }
 } else {
            DEBUG_PRINT_ERROR("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported ret NoMore for codec: %s", drv_ctx.kind);
            eRet = OMX_ErrorNoMore;
 }
 } else {
        DEBUG_PRINT_ERROR("get_parameter: OMX_IndexParamVideoProfileLevelQuerySupported should be queries on Input port only %u",
 (unsigned int)profileLevelType->nPortIndex);
        eRet = OMX_ErrorBadPortIndex;
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::addDummyStreamLocked() {
    ATRACE_CALL();
 status_t res;

 if (mDummyStreamId != NO_STREAM) {
        SET_ERR_L("%s: Camera %d: A dummy stream already exists!",
                __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

    ALOGV("%s: Camera %d: Adding a dummy stream", __FUNCTION__, mId);

    sp<Camera3OutputStreamInterface> dummyStream =
 new Camera3DummyStream(mNextStreamId);

    res = mOutputStreams.add(mNextStreamId, dummyStream);
 if (res < 0) {
        SET_ERR_L("Can't add dummy stream to set: %s (%d)", strerror(-res), res);
 return res;
 }

    mDummyStreamId = mNextStreamId;
    mNextStreamId++;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_bit_stream_init(stream_t *ps_stream,
                             UWORD8 *pu1_byte_buf,
                             UWORD32 u4_max_offset)
{
    UWORD8      *pu1_byte_buff;
    UWORD32     *pu4_word_buf;
 size_t     u4_byte_addr;
    UWORD32     u4_temp1,u4_temp2;

 /* Set parameters of the stream structure.Associate the structure with
       the file */
    ps_stream->pv_bs_buf           = pu1_byte_buf;
    ps_stream->u4_offset              = 0;

 /* Take care of unaligned address and create
       nearest greater aligned address */
    pu1_byte_buff               = (UWORD8 *)pu1_byte_buf;
    u4_byte_addr                = (size_t)pu1_byte_buff;

 if((u4_byte_addr & 3) == 1)
 {
        u4_temp1                = ((UWORD32)(*pu1_byte_buff++)) << 8;
        u4_temp1                += ((UWORD32)(*pu1_byte_buff++)) << 16;
        u4_temp1                += ((UWORD32)(*pu1_byte_buff++)) << 24;

        pu4_word_buf            = (UWORD32 *)pu1_byte_buff;

        ps_stream->u4_offset          = 8;
 }
 else if((u4_byte_addr & 3) == 2)
 {
        u4_temp1                = ((UWORD32)(*pu1_byte_buff++)) << 16;
        u4_temp1                += ((UWORD32)(*pu1_byte_buff++)) << 24;

        pu4_word_buf            = (UWORD32 *)pu1_byte_buff;

        ps_stream->u4_offset          = 16;
 }
 else if((u4_byte_addr & 3) == 3)
 {
        u4_temp1                = (((UWORD32)(*pu1_byte_buff++)) << 24);

        pu4_word_buf            = (UWORD32 *)pu1_byte_buff;

        ps_stream->u4_offset          = 24;
 }
 else
 {
        pu4_word_buf            = (UWORD32 *)pu1_byte_buff;

        u4_temp1                = *pu4_word_buf++;
        ps_stream->u4_offset          = 0;
 }

 /* convert the endian ness from Little endian to Big endian so that bits
       are in proper order from MSB to LSB */
    CONV_LE_TO_BE(u4_temp2,u4_temp1)

 /* Read One more word for buf nxt */
    u4_temp1                    = *pu4_word_buf++;
    ps_stream->u4_buf              = u4_temp2;

    CONV_LE_TO_BE(u4_temp2,u4_temp1)

    ps_stream->u4_buf_nxt          = u4_temp2;

    ps_stream->pu4_buf_aligned      = pu4_word_buf;


    ps_stream->u4_max_offset        = (u4_max_offset << 3) + ps_stream->u4_offset;

 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: insert_hIST(png_structp png_ptr, png_infop info_ptr, int nparams, png_charpp params)
 {
    int i;
    png_uint_16 freq[256];

 /* libpng takes the count from the PLTE count; we don't check it here but we
    * do set the array to 0 for unspecified entries.
    */
   memset(freq, 0, sizeof freq);
 for (i=0; i<nparams; ++i)
 {
 char *endptr = NULL;
 unsigned long int l = strtoul(params[i], &endptr, 0/*base*/);

 if (params[i][0] && *endptr == 0 && l <= 65535)
         freq[i] = (png_uint_16)l;

 else
 {
         fprintf(stderr, "hIST[%d]: %s: invalid frequency\n", i, params[i]);
         exit(1);
 }
 }


    png_set_hIST(png_ptr, info_ptr, freq);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void release_buffer(struct resampler_buffer_provider *buffer_provider,
 struct resampler_buffer* buffer)
{
 struct stream_in *in;

 if (buffer_provider == NULL || buffer == NULL)
 return;

    in = (struct stream_in *)((char *)buffer_provider -
                                   offsetof(struct stream_in, buf_provider));

    in->read_buf_frames -= buffer->frame_count;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void copyMultiCh24(short *dst, const int *const *src, unsigned nSamples, unsigned nChannels)
 {
     for (unsigned i = 0; i < nSamples; ++i) {
         for (unsigned c = 0; c < nChannels; ++c) {
 *dst++ = src[c][i] >> 8;
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundEvent::set(const sp<Sample>& sample, int channelID, float leftVolume,
 float rightVolume, int priority, int loop, float rate)
{
    mSample = sample;
    mChannelID = channelID;
    mLeftVolume = leftVolume;
    mRightVolume = rightVolume;
    mPriority = priority;
    mLoop = loop;
    mRate =rate;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Block::GetFrameCount() const { return m_frame_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Chapters::Atom::ParseDisplay(
    IMkvReader* pReader,
    long long pos,
    long long size)
{
    if (!ExpandDisplaysArray())
        return -1;
    Display& d = m_displays[m_displays_count++];
    d.Init();
    return d.Parse(pReader, pos, size);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void IPCThreadState::clearCaller()
{
    mCallingPid = getpid();
    mCallingUid = getuid();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int out_set_format(struct audio_stream *stream, audio_format_t format)
{
 (void)stream;
 (void)format;
 return -ENOSYS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAVC::onReset() {
 SoftVideoDecoderOMXComponent::onReset();

    mSignalledError = false;
    resetDecoder();

     resetPlugin();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeInt32Array(size_t len, const int32_t *val) {
 if (len > INT32_MAX) {
 return BAD_VALUE;
 }

 if (!val) {
 return writeInt32(-1);
 }
 status_t ret = writeInt32(static_cast<uint32_t>(len));
 if (ret == NO_ERROR) {
        ret = write(val, len * sizeof(*val));
 }
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BufferQueueConsumer::BufferQueueConsumer(const sp<BufferQueueCore>& core) :
    mCore(core),
    mSlots(core->mSlots),
    mConsumerName() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool SampleTable::isValid() const {
 return mChunkOffsetOffset >= 0
 && mSampleToChunkOffset >= 0
 && mSampleSizeOffset >= 0
 && mTimeToSample != NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void AddElementsToKeyAccumulatorImpl(Handle<JSObject> receiver,
 KeyAccumulator* accumulator,
 AddKeyConversion convert) {
 Isolate* isolate = accumulator->isolate();
 Handle<FixedArrayBase> elements(receiver->elements(), isolate);
 uint32_t length = GetCapacityImpl(*receiver, *elements);
 for (uint32_t entry = 0; entry < length; entry++) {
 if (!HasEntryImpl(isolate, *elements, entry)) continue;
 Handle<Object> value = GetImpl(isolate, *elements, entry);
      accumulator->AddKey(value, convert);
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void init_poll(int h)
{
 int i;
    ts[h].poll_count = 0;
    ts[h].thread_id = -1;
    ts[h].callback = NULL;
    ts[h].cmd_callback = NULL;
 for(i = 0; i < MAX_POLL; i++)
 {
        ts[h].ps[i].pfd.fd = -1;
        ts[h].psi[i] = -1;
 }
    init_cmd_fd(h);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_br_select_next_key(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s role=%d (0-master) r_keys=0x%x i_keys=0x%x", __func__,
                  p_cb->role, p_cb->local_r_key, p_cb->local_i_key);

 if (p_cb->role == HCI_ROLE_SLAVE ||
 (!p_cb->local_r_key && p_cb->role == HCI_ROLE_MASTER)) {
    smp_key_pick_key(p_cb, p_data);
 }

 if (!p_cb->local_i_key && !p_cb->local_r_key) {
 /* state check to prevent re-entrance */
 if (smp_get_br_state() == SMP_BR_STATE_BOND_PENDING) {
 if (p_cb->total_tx_unacked == 0) {
        tSMP_INT_DATA smp_int_data;
        smp_int_data.status = SMP_SUCCESS;
        smp_br_state_machine_event(p_cb, SMP_BR_AUTH_CMPL_EVT, &smp_int_data);
 } else {
        p_cb->wait_for_authorization_complete = true;
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int skt_disconnect(int fd)
{
    INFO("fd %d", fd);

 if (fd != AUDIO_SKT_DISCONNECTED)
 {
        shutdown(fd, SHUT_RDWR);
        close(fd);
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseDrmSINF(
 off64_t * /* offset */, off64_t data_offset) {
 uint8_t updateIdTag;
 if (mDataSource->readAt(data_offset, &updateIdTag, 1) < 1) {
 return ERROR_IO;
 }
    data_offset ++;

 if (0x01/*OBJECT_DESCRIPTOR_UPDATE_ID_TAG*/ != updateIdTag) {
 return ERROR_MALFORMED;
 }

 uint8_t numOfBytes;
 int32_t size = readSize(data_offset, mDataSource, &numOfBytes);
 if (size < 0) {
 return ERROR_IO;
 }
 int32_t classSize = size;
    data_offset += numOfBytes;

 while(size >= 11 ) {
 uint8_t descriptorTag;
 if (mDataSource->readAt(data_offset, &descriptorTag, 1) < 1) {
 return ERROR_IO;
 }
        data_offset ++;

 if (0x11/*OBJECT_DESCRIPTOR_ID_TAG*/ != descriptorTag) {
 return ERROR_MALFORMED;
 }

 uint8_t buffer[8];
 if (mDataSource->readAt(data_offset, buffer, 2) < 2) {
 return ERROR_IO;
 }
        data_offset += 2;

 if ((buffer[1] >> 5) & 0x0001) { //url flag is set
 return ERROR_MALFORMED;
 }

 if (mDataSource->readAt(data_offset, buffer, 8) < 8) {
 return ERROR_IO;
 }
        data_offset += 8;

 if ((0x0F/*ES_ID_REF_TAG*/ != buffer[1])
 || ( 0x0A/*IPMP_DESCRIPTOR_POINTER_ID_TAG*/ != buffer[5])) {
 return ERROR_MALFORMED;
 }

        SINF *sinf = new SINF;
        sinf->trackID = U16_AT(&buffer[3]);
        sinf->IPMPDescriptorID = buffer[7];
        sinf->next = mFirstSINF;
        mFirstSINF = sinf;

        size -= (8 + 2 + 1);
 }

 if (size != 0) {
 return ERROR_MALFORMED;
 }

 if (mDataSource->readAt(data_offset, &updateIdTag, 1) < 1) {
 return ERROR_IO;
 }
    data_offset ++;

 if(0x05/*IPMP_DESCRIPTOR_UPDATE_ID_TAG*/ != updateIdTag) {
 return ERROR_MALFORMED;
 }

    size = readSize(data_offset, mDataSource, &numOfBytes);
 if (size < 0) {
 return ERROR_IO;
 }
    classSize = size;
    data_offset += numOfBytes;

 while (size > 0) {
 uint8_t tag;
 int32_t dataLen;
 if (mDataSource->readAt(data_offset, &tag, 1) < 1) {
 return ERROR_IO;
 }
        data_offset ++;

 if (0x0B/*IPMP_DESCRIPTOR_ID_TAG*/ == tag) {
 uint8_t id;
            dataLen = readSize(data_offset, mDataSource, &numOfBytes);
 if (dataLen < 0) {
 return ERROR_IO;
 } else if (dataLen < 4) {
 return ERROR_MALFORMED;
 }
            data_offset += numOfBytes;

 if (mDataSource->readAt(data_offset, &id, 1) < 1) {
 return ERROR_IO;
 }
            data_offset ++;

            SINF *sinf = mFirstSINF;
 while (sinf && (sinf->IPMPDescriptorID != id)) {
                sinf = sinf->next;
 }
 if (sinf == NULL) {
 return ERROR_MALFORMED;
 }
            sinf->len = dataLen - 3;
            sinf->IPMPData = new (std::nothrow) char[sinf->len];
 if (sinf->IPMPData == NULL) {
 return ERROR_MALFORMED;
 }
            data_offset += 2;

 if (mDataSource->readAt(data_offset, sinf->IPMPData, sinf->len) < sinf->len) {
 return ERROR_IO;
 }
            data_offset += sinf->len;

            size -= (dataLen + numOfBytes + 1);
 }
 }

 if (size != 0) {
 return ERROR_MALFORMED;
 }

 return UNKNOWN_ERROR; // Return a dummy error.
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long ReadUInt(IMkvReader* pReader, long long pos, long& len) {
 if (!pReader || pos < 0)
 return E_FILE_FORMAT_INVALID;

  len = 1;
 unsigned char b;
 int status = pReader->Read(pos, 1, &b);

 if (status < 0) // error or underflow
 return status;

 if (status > 0) // interpreted as "underflow"
 return E_BUFFER_NOT_FULL;

 if (b == 0) // we can't handle u-int values larger than 8 bytes
 return E_FILE_FORMAT_INVALID;

 unsigned char m = 0x80;

 while (!(b & m)) {
    m >>= 1;
 ++len;
 }

 long long result = b & (~m);
 ++pos;

 for (int i = 1; i < len; ++i) {
    status = pReader->Read(pos, 1, &b);

 if (status < 0) {
      len = 1;
 return status;
 }

 if (status > 0) {
      len = 1;
 return E_BUFFER_NOT_FULL;
 }

    result <<= 8;
    result |= b;

 ++pos;
 }

 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_do_mmco_for_gaps(dpb_manager_t *ps_dpb_mgr,
                             UWORD8 u1_num_ref_frames /*!< num_ref_frames from active SeqParSet*/
 )
{
 struct dpb_info_t *ps_next_dpb;
    UWORD8 u1_num_gaps;
    UWORD8 u1_st_ref_bufs, u1_lt_ref_bufs, u1_del_node;
    WORD8 i;
    WORD32 i4_frame_gaps = 1;
    WORD32 ret;

    u1_st_ref_bufs = ps_dpb_mgr->u1_num_st_ref_bufs;
    u1_lt_ref_bufs = ps_dpb_mgr->u1_num_lt_ref_bufs;

 while(1)
 {
        u1_num_gaps = ps_dpb_mgr->u1_num_gaps;
 if((u1_st_ref_bufs + u1_lt_ref_bufs + u1_num_gaps + i4_frame_gaps)
 > u1_num_ref_frames)
 {
 if(0 == (u1_st_ref_bufs + u1_num_gaps))
 {
                i4_frame_gaps = 0;
                ps_dpb_mgr->u1_num_gaps = (u1_num_ref_frames
 - u1_lt_ref_bufs);
 }
 else
 {
                u1_del_node = 1;
                ps_next_dpb = ps_dpb_mgr->ps_dpb_st_head;

 if(u1_st_ref_bufs > 1)
 {
 for(i = 1; i < (u1_st_ref_bufs - 1); i++)
 {
 if(ps_next_dpb == NULL)
 {
                            UWORD32 i4_error_code;
                            i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }
                        ps_next_dpb = ps_next_dpb->ps_prev_short;
 }

 if(ps_next_dpb->ps_prev_short->ps_prev_short != NULL)
 {
 return ERROR_DBP_MANAGER_T;
 }

 if(u1_num_gaps)
 {
                        ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                            ps_next_dpb->ps_prev_short->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 }

 if(u1_del_node)
 {
                        u1_st_ref_bufs--;
                        ps_next_dpb->ps_prev_short->u1_used_as_ref =
                                        UNUSED_FOR_REF;
                        ps_next_dpb->ps_prev_short->s_top_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ps_next_dpb->ps_prev_short->s_bot_field.u1_reference_info =
                                        UNUSED_FOR_REF;
                        ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                    ps_next_dpb->ps_prev_short->u1_buf_id);
                        ps_next_dpb->ps_prev_short->ps_pic_buf = NULL;
                        ps_next_dpb->ps_prev_short = NULL;
 }
 }
 else
 {
 if(u1_st_ref_bufs)
 {
 if(u1_num_gaps)
 {
                            ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                                ps_next_dpb->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 }

 if(u1_del_node)
 {
                            u1_st_ref_bufs--;
                            ps_next_dpb->u1_used_as_ref = FALSE;
                            ps_next_dpb->s_top_field.u1_reference_info =
                                            UNUSED_FOR_REF;
                            ps_next_dpb->s_bot_field.u1_reference_info =
                                            UNUSED_FOR_REF;
                            ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                        ps_next_dpb->u1_buf_id);
                            ps_next_dpb->ps_pic_buf = NULL;
                            ps_next_dpb = NULL;
                            ps_dpb_mgr->ps_dpb_st_head = NULL;
                            ps_dpb_mgr->u1_num_st_ref_bufs = u1_st_ref_bufs;
 }
 }
 else
 {
                        ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                            INVALID_FRAME_NUM,
 &u1_del_node);
 if(ret != OK)
 return ret;
 if(u1_del_node)
 {
 return ERROR_DBP_MANAGER_T;
 }
 }
 }
 }
 }
 else
 {
            ps_dpb_mgr->u1_num_gaps += i4_frame_gaps;
 break;
 }
 }

    ps_dpb_mgr->u1_num_st_ref_bufs = u1_st_ref_bufs;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: error_handler(png_structp png_ptr, png_const_charp message)
{
   stop(get_control(png_ptr),  LIBPNG_ERROR_CODE, message);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Segment::Segment(IMkvReader* pReader, long long elem_start,
 long long start, long long size)
 : m_pReader(pReader),
      m_element_start(elem_start),
      m_start(start),
      m_size(size),
      m_pos(start),
      m_pUnknownSize(0),
      m_pSeekHead(NULL),
      m_pInfo(NULL),

       m_pTracks(NULL),
       m_pCues(NULL),
       m_pChapters(NULL),
       m_clusters(NULL),
       m_clusterCount(0),
       m_clusterPreloadCount(0),
      m_clusterSize(0) {}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: long SeekHead::Parse() {
 IMkvReader* const pReader = m_pSegment->m_pReader;

 long long pos = m_start;
 const long long stop = m_start + m_size;


 int entry_count = 0;
 int void_element_count = 0;

 while (pos < stop) {
 long long id, size;

 const long status = ParseElementHeader(pReader, pos, stop, id, size);

 if (status < 0) // error
 return status;

 if (id == 0x0DBB) // SeekEntry ID
 ++entry_count;
 else if (id == 0x6C) // Void ID
 ++void_element_count;

    pos += size; // consume payload

 if (pos > stop)
 return E_FILE_FORMAT_INVALID;
 }

 if (pos != stop)
 return E_FILE_FORMAT_INVALID;

  m_entries = new (std::nothrow) Entry[entry_count];

 if (m_entries == NULL)
 return -1;

  m_void_elements = new (std::nothrow) VoidElement[void_element_count];

 if (m_void_elements == NULL)
 return -1;


 Entry* pEntry = m_entries;
 VoidElement* pVoidElement = m_void_elements;

  pos = m_start;

 while (pos < stop) {
 const long long idpos = pos;

 long long id, size;

 const long status = ParseElementHeader(pReader, pos, stop, id, size);

 if (status < 0) // error
 return status;

 if (id == 0x0DBB) { // SeekEntry ID
 if (ParseEntry(pReader, pos, size, pEntry)) {
 Entry& e = *pEntry++;

        e.element_start = idpos;
        e.element_size = (pos + size) - idpos;
 }
 } else if (id == 0x6C) { // Void ID
 VoidElement& e = *pVoidElement++;

      e.element_start = idpos;
      e.element_size = (pos + size) - idpos;
 }

    pos += size; // consume payload
 if (pos > stop)
 return E_FILE_FORMAT_INVALID;
 }

 if (pos != stop)
 return E_FILE_FORMAT_INVALID;

 ptrdiff_t count_ = ptrdiff_t(pEntry - m_entries);
  assert(count_ >= 0);
  assert(count_ <= entry_count);

  m_entry_count = static_cast<int>(count_);

  count_ = ptrdiff_t(pVoidElement - m_void_elements);
  assert(count_ >= 0);
  assert(count_ <= void_element_count);

  m_void_element_count = static_cast<int>(count_);

 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static EAS_RESULT Parse_lrgn (SDLS_SYNTHESIZER_DATA *pDLSData, EAS_I32 pos, EAS_I32 size, EAS_U16 artIndex, EAS_U32 numRegions)
{
    EAS_RESULT result;
    EAS_U32 temp;
    EAS_I32 chunkPos;
    EAS_I32 endChunk;
    EAS_U16 regionCount;

 /* seek to start of chunk */
 if ((result = EAS_HWFileSeek(pDLSData->hwInstData, pDLSData->fileHandle, pos)) != EAS_SUCCESS)
 return result;

 /* read to end of chunk */
    regionCount = 0;
    endChunk = pos + size;
 while (pos < endChunk)
 {
        chunkPos = pos;

 /* get the next chunk type */
 if ((result = NextChunk(pDLSData, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 if ((temp == CHUNK_RGN) || (temp == CHUNK_RGN2))
 {
 if (regionCount == numRegions)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_WARNING, "DLS region count exceeded cRegions value in insh, extra region ignored\n"); */ }
 return EAS_SUCCESS;
 }
 if ((result = Parse_rgn(pDLSData, chunkPos + 12, size, artIndex)) != EAS_SUCCESS)
 return result;
            regionCount++;
 }
 }

 /* set a flag in the last region */
 if ((pDLSData->pDLS != NULL) && (regionCount > 0))
        pDLSData->pDLS->pDLSRegions[pDLSData->regionCount - 1].wtRegion.region.keyGroupAndFlags |= REGION_FLAG_LAST_REGION;

 return EAS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::getConfig(
        OMX_INDEXTYPE index, void *params, size_t /* size */) {
 Mutex::Autolock autoLock(mLock);

    OMX_ERRORTYPE err = OMX_GetConfig(mHandle, index, params);
    OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
 if (err != OMX_ErrorNoMore) {
        CLOG_IF_ERROR(getConfig, err, "%s(%#x)", asString(extIndex), index);
 }
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IDAT_list_size(struct IDAT_list *list, unsigned int length)
 /* Return the size in bytes of an IDAT_list of the given length. */
{
 if (list != NULL)
      length = list->length;

 return sizeof *list - sizeof list->lengths +
      length * sizeof list->lengths[0];
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: u32 h264bsdCheckAccessUnitBoundary(
 strmData_t *strm,
 nalUnit_t *nuNext,
 storage_t *storage,
  u32 *accessUnitBoundaryFlag)
{

/* Variables */

    u32 tmp, ppsId, frameNum, idrPicId, picOrderCntLsb;
    i32 deltaPicOrderCntBottom, deltaPicOrderCnt[2];
 seqParamSet_t *sps;
 picParamSet_t *pps;

/* Code */

    ASSERT(strm);
    ASSERT(nuNext);
    ASSERT(storage);
    ASSERT(storage->sps);
    ASSERT(storage->pps);

 /* initialize default output to FALSE */
 *accessUnitBoundaryFlag = HANTRO_FALSE;

 if ( ( (nuNext->nalUnitType > 5) && (nuNext->nalUnitType < 12) ) ||
 ( (nuNext->nalUnitType > 12) && (nuNext->nalUnitType <= 18) ) )
 {
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 return(HANTRO_OK);
 }
 else if ( nuNext->nalUnitType != NAL_CODED_SLICE &&
              nuNext->nalUnitType != NAL_CODED_SLICE_IDR )
 {
 return(HANTRO_OK);
 }

 /* check if this is the very first call to this function */
 if (storage->aub->firstCallFlag)
 {
 *accessUnitBoundaryFlag = HANTRO_TRUE;
        storage->aub->firstCallFlag = HANTRO_FALSE;
 }

 /* get picture parameter set id */
    tmp = h264bsdCheckPpsId(strm, &ppsId);
 if (tmp != HANTRO_OK)
 return(tmp);

 /* store sps and pps in separate pointers just to make names shorter */
    pps = storage->pps[ppsId];
 if ( pps == NULL || storage->sps[pps->seqParameterSetId] == NULL  ||
 (storage->activeSpsId != MAX_NUM_SEQ_PARAM_SETS &&
          pps->seqParameterSetId != storage->activeSpsId &&
          nuNext->nalUnitType != NAL_CODED_SLICE_IDR) )
 return(PARAM_SET_ERROR);
    sps = storage->sps[pps->seqParameterSetId];

 if (storage->aub->nuPrev->nalRefIdc != nuNext->nalRefIdc &&
 (storage->aub->nuPrev->nalRefIdc == 0 || nuNext->nalRefIdc == 0))
 *accessUnitBoundaryFlag = HANTRO_TRUE;

 if ((storage->aub->nuPrev->nalUnitType == NAL_CODED_SLICE_IDR &&
          nuNext->nalUnitType != NAL_CODED_SLICE_IDR) ||
 (storage->aub->nuPrev->nalUnitType != NAL_CODED_SLICE_IDR &&
       nuNext->nalUnitType == NAL_CODED_SLICE_IDR))
 *accessUnitBoundaryFlag = HANTRO_TRUE;

    tmp = h264bsdCheckFrameNum(strm, sps->maxFrameNum, &frameNum);
 if (tmp != HANTRO_OK)
 return(HANTRO_NOK);

 if (storage->aub->prevFrameNum != frameNum)
 {
        storage->aub->prevFrameNum = frameNum;
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 }

 if (nuNext->nalUnitType == NAL_CODED_SLICE_IDR)
 {
        tmp = h264bsdCheckIdrPicId(strm, sps->maxFrameNum, nuNext->nalUnitType,
 &idrPicId);
 if (tmp != HANTRO_OK)
 return(HANTRO_NOK);

 if (storage->aub->nuPrev->nalUnitType == NAL_CODED_SLICE_IDR &&
          storage->aub->prevIdrPicId != idrPicId)
 *accessUnitBoundaryFlag = HANTRO_TRUE;

        storage->aub->prevIdrPicId = idrPicId;
 }

 if (sps->picOrderCntType == 0)
 {
        tmp = h264bsdCheckPicOrderCntLsb(strm, sps, nuNext->nalUnitType,
 &picOrderCntLsb);
 if (tmp != HANTRO_OK)
 return(HANTRO_NOK);

 if (storage->aub->prevPicOrderCntLsb != picOrderCntLsb)
 {
            storage->aub->prevPicOrderCntLsb = picOrderCntLsb;
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 }

 if (pps->picOrderPresentFlag)
 {
            tmp = h264bsdCheckDeltaPicOrderCntBottom(strm, sps,
                nuNext->nalUnitType, &deltaPicOrderCntBottom);
 if (tmp != HANTRO_OK)
 return(tmp);

 if (storage->aub->prevDeltaPicOrderCntBottom !=
                deltaPicOrderCntBottom)
 {
                storage->aub->prevDeltaPicOrderCntBottom =
                    deltaPicOrderCntBottom;
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 }
 }
 }
 else if (sps->picOrderCntType == 1 && !sps->deltaPicOrderAlwaysZeroFlag)
 {
        tmp = h264bsdCheckDeltaPicOrderCnt(strm, sps, nuNext->nalUnitType,
          pps->picOrderPresentFlag, deltaPicOrderCnt);
 if (tmp != HANTRO_OK)
 return(tmp);

 if (storage->aub->prevDeltaPicOrderCnt[0] != deltaPicOrderCnt[0])
 {
            storage->aub->prevDeltaPicOrderCnt[0] = deltaPicOrderCnt[0];
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 }

 if (pps->picOrderPresentFlag)
 if (storage->aub->prevDeltaPicOrderCnt[1] != deltaPicOrderCnt[1])
 {
                storage->aub->prevDeltaPicOrderCnt[1] = deltaPicOrderCnt[1];
 *accessUnitBoundaryFlag = HANTRO_TRUE;
 }
 }

 *storage->aub->nuPrev = *nuNext;

 return(HANTRO_OK);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioFlinger::EffectModule::addHandle(EffectHandle *handle)
{
 status_t status;

 Mutex::Autolock _l(mLock);
 int priority = handle->priority();
 size_t size = mHandles.size();
 EffectHandle *controlHandle = NULL;
 size_t i;
 for (i = 0; i < size; i++) {
 EffectHandle *h = mHandles[i];
 if (h == NULL || h->destroyed_l()) {
 continue;
 }
 if (controlHandle == NULL) {
            controlHandle = h;
 }
 if (h->priority() <= priority) {
 break;
 }
 }
 if (i == 0) {
 bool enabled = false;
 if (controlHandle != NULL) {
            enabled = controlHandle->enabled();
            controlHandle->setControl(false/*hasControl*/, true /*signal*/, enabled /*enabled*/);
 }
        handle->setControl(true /*hasControl*/, false /*signal*/, enabled /*enabled*/);
        status = NO_ERROR;
 } else {
        status = ALREADY_EXISTS;
 }
    ALOGV("addHandle() %p added handle %p in position %d", this, handle, i);
    mHandles.insertAt(handle, i);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean sspReplyNative(JNIEnv *env, jobject obj, jbyteArray address,
                               jint type, jboolean accept, jint passkey) {
    ALOGV("%s:",__FUNCTION__);

    jbyte *addr;
    jboolean result = JNI_FALSE;
 if (!sBluetoothInterface) return result;

    addr = env->GetByteArrayElements(address, NULL);
 if (addr == NULL) {
        jniThrowIOException(env, EINVAL);
 return result;
 }

 int ret = sBluetoothInterface->ssp_reply((bt_bdaddr_t *)addr,
 (bt_ssp_variant_t) type, accept, passkey);
    env->ReleaseByteArrayElements(address, addr, 0);
    result = (ret == BT_STATUS_SUCCESS) ? JNI_TRUE : JNI_FALSE;

 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Display::~Display()
{
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseAttValue(xmlParserCtxtPtr ctxt) {
 if ((ctxt == NULL) || (ctxt->input == NULL)) return(NULL);
 return(xmlParseAttValueInternal(ctxt, NULL, NULL, 0));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t HevcParameterSets::addNalUnit(const uint8_t* data, size_t size) {
     uint8_t nalUnitType = (data[0] >> 1) & 0x3f;
     status_t err = OK;
     switch (nalUnitType) {
         case 32:  // VPS
             err = parseVps(data + 2, size - 2);
             break;
         case 33:  // SPS
             err = parseSps(data + 2, size - 2);
             break;
         case 34:  // PPS
             err = parsePps(data + 2, size - 2);
             break;
         case 39:  // Prefix SEI
 case 40: // Suffix SEI
 break;
 default:
            ALOGE("Unrecognized NAL unit type.");
 return ERROR_MALFORMED;
 }

 if (err != OK) {
 return err;
 }

    sp<ABuffer> buffer = ABuffer::CreateAsCopy(data, size);
    buffer->setInt32Data(nalUnitType);
    mNalUnits.push(buffer);
 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cluster* Segment::GetNext(const Cluster* pCurr) {
  assert(pCurr);
  assert(pCurr != &m_eos);
  assert(m_clusters);

 long idx = pCurr->m_index;

 if (idx >= 0) {
    assert(m_clusterCount > 0);
    assert(idx < m_clusterCount);
    assert(pCurr == m_clusters[idx]);

 ++idx;

 if (idx >= m_clusterCount)
 return &m_eos; // caller will LoadCluster as desired

 Cluster* const pNext = m_clusters[idx];
    assert(pNext);
    assert(pNext->m_index >= 0);
    assert(pNext->m_index == idx);

 return pNext;
 }

  assert(m_clusterPreloadCount > 0);

 long long pos = pCurr->m_element_start;

  assert(m_size >= 0); // TODO
 const long long stop = m_start + m_size; // end of segment

 {
 long len;

 long long result = GetUIntLength(m_pReader, pos, len);
    assert(result == 0);
    assert((pos + len) <= stop); // TODO

     if (result != 0)
       return NULL;
 
    const long long id = ReadUInt(m_pReader, pos, len);
    assert(id == 0x0F43B675);  // Cluster ID
    if (id != 0x0F43B675)
       return NULL;
 
     pos += len;  // consume ID

    result = GetUIntLength(m_pReader, pos, len);
    assert(result == 0); // TODO
    assert((pos + len) <= stop); // TODO

 const long long size = ReadUInt(m_pReader, pos, len);
    assert(size > 0); // TODO

    pos += len; // consume length of size of element
    assert((pos + size) <= stop); // TODO


    pos += size; // consume payload
 }

 long long off_next = 0;

 while (pos < stop) {
 long len;

 long long result = GetUIntLength(m_pReader, pos, len);
    assert(result == 0);
    assert((pos + len) <= stop); // TODO
 if (result != 0)
 return NULL;

 
     const long long idpos = pos;  // pos of next (potential) cluster
 
    const long long id = ReadUInt(m_pReader, idpos, len);
    assert(id > 0);  // TODO
 
     pos += len;  // consume ID
 
    result = GetUIntLength(m_pReader, pos, len);
    assert(result == 0); // TODO
    assert((pos + len) <= stop); // TODO

 const long long size = ReadUInt(m_pReader, pos, len);
    assert(size >= 0); // TODO

    pos += len; // consume length of size of element
    assert((pos + size) <= stop); // TODO


 if (size == 0) // weird
 continue;

 if (id == 0x0F43B675) { // Cluster ID
 const long long off_next_ = idpos - m_start;

 long long pos_;
 long len_;

 const long status = Cluster::HasBlockEntries(this, off_next_, pos_, len_);

      assert(status >= 0);

 if (status > 0) {
        off_next = off_next_;
 break;
 }
 }

    pos += size; // consume payload
 }

 if (off_next <= 0)
 return 0;

 Cluster** const ii = m_clusters + m_clusterCount;
 Cluster** i = ii;

 Cluster** const jj = ii + m_clusterPreloadCount;
 Cluster** j = jj;

 while (i < j) {

 Cluster** const k = i + (j - i) / 2;
    assert(k < jj);

 Cluster* const pNext = *k;
    assert(pNext);
    assert(pNext->m_index < 0);


    pos = pNext->GetPosition();

 if (pos < off_next)
      i = k + 1;
 else if (pos > off_next)
      j = k;
 else
 return pNext;
 }


   assert(i == j);
 
   Cluster* const pNext = Cluster::Create(this, -1, off_next);
  assert(pNext);
 
   const ptrdiff_t idx_next = i - m_clusters;  // insertion position
 
  PreloadCluster(pNext, idx_next);
   assert(m_clusters);
   assert(idx_next < m_clusterSize);
   assert(m_clusters[idx_next] == pNext);

 return pNext;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE OMXNodeInstance::OnEvent(
        OMX_IN OMX_HANDLETYPE /* hComponent */,
        OMX_IN OMX_PTR pAppData,
        OMX_IN OMX_EVENTTYPE eEvent,
        OMX_IN OMX_U32 nData1,
        OMX_IN OMX_U32 nData2,
        OMX_IN OMX_PTR pEventData) {
 OMXNodeInstance *instance = static_cast<OMXNodeInstance *>(pAppData);
 if (instance->mDying) {
 return OMX_ErrorNone;
 }
 return instance->owner()->OnEvent(
            instance->nodeID(), eEvent, nData1, nData2, pEventData);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API FLAC__StreamDecoderInitStatus FLAC__stream_decoder_init_ogg_FILE(
	FLAC__StreamDecoder *decoder,
 FILE *file,
	FLAC__StreamDecoderWriteCallback write_callback,
	FLAC__StreamDecoderMetadataCallback metadata_callback,
	FLAC__StreamDecoderErrorCallback error_callback,
 void *client_data
)
{
 return init_FILE_internal_(decoder, file, write_callback, metadata_callback, error_callback, client_data, /*is_ogg=*/true);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: display_clean_read(struct display *dp)
{
 if (dp->read_pp != NULL)
      png_destroy_read_struct(&dp->read_pp, &dp->read_ip, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::sProcessCaptureResult(const camera3_callback_ops *cb,
 const camera3_capture_result *result) {
 Camera3Device *d =
 const_cast<Camera3Device*>(static_cast<const Camera3Device*>(cb));

    d->processCaptureResult(result);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static uint32_t NumberOfElementsImpl(JSObject* receiver,
 FixedArrayBase* backing_store) {
 FixedArray* parameter_map = FixedArray::cast(backing_store);
 FixedArrayBase* arguments = FixedArrayBase::cast(parameter_map->get(1));
 uint32_t nof_elements = 0;
 uint32_t length = parameter_map->length() - 2;
 for (uint32_t entry = 0; entry < length; entry++) {
 if (HasParameterMapArg(parameter_map, entry)) nof_elements++;
 }
 return nof_elements +
 ArgumentsAccessor::NumberOfElementsImpl(receiver, arguments);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_nal_unit(iv_obj_t *dec_hdl,
 ivd_video_decode_op_t *ps_dec_op,
                          UWORD8 *pu1_buf,
                          UWORD32 u4_length)
{

 dec_bit_stream_t *ps_bitstrm;


 dec_struct_t *ps_dec = (dec_struct_t *)dec_hdl->pv_codec_handle;
 ivd_video_decode_ip_t *ps_dec_in =
 (ivd_video_decode_ip_t *)ps_dec->pv_dec_in;
 dec_slice_params_t * ps_cur_slice = ps_dec->ps_cur_slice;
    UWORD8 u1_first_byte, u1_nal_ref_idc;
    UWORD8 u1_nal_unit_type;
    WORD32 i_status = OK;
    ps_bitstrm = ps_dec->ps_bitstrm;

 if(pu1_buf)
 {
 if(u4_length)
 {
            ps_dec_op->u4_frame_decoded_flag = 0;
            ih264d_process_nal_unit(ps_dec->ps_bitstrm, pu1_buf,
                                    u4_length);

            SWITCHOFFTRACE;
            u1_first_byte = ih264d_get_bits_h264(ps_bitstrm, 8);

 if(NAL_FORBIDDEN_BIT(u1_first_byte))
 {
                H264_DEC_DEBUG_PRINT("\nForbidden bit set in Nal Unit, Let's try\n");
 }
            u1_nal_unit_type = NAL_UNIT_TYPE(u1_first_byte);
 if ((ps_dec->u4_slice_start_code_found == 1)
 && (ps_dec->u1_pic_decode_done != 1)
 && (u1_nal_unit_type > IDR_SLICE_NAL))
 {
 return ERROR_INCOMPLETE_FRAME;
 }
            ps_dec->u1_nal_unit_type = u1_nal_unit_type;
            u1_nal_ref_idc = (UWORD8)(NAL_REF_IDC(u1_first_byte));
 switch(u1_nal_unit_type)
 {
 case SLICE_DATA_PARTITION_A_NAL:
 case SLICE_DATA_PARTITION_B_NAL:
 case SLICE_DATA_PARTITION_C_NAL:
 if(!ps_dec->i4_decode_header)
                        ih264d_parse_slice_partition(ps_dec, ps_bitstrm);

 break;

 case IDR_SLICE_NAL:
 case SLICE_NAL:

 /* ! */
                    DEBUG_THREADS_PRINTF("Decoding  a slice NAL\n");
 if(!ps_dec->i4_decode_header)
 {
 if(ps_dec->i4_header_decoded == 3)
 {
 /* ! */
                            ps_dec->u4_slice_start_code_found = 1;

                            ih264d_rbsp_to_sodb(ps_dec->ps_bitstrm);

                            i_status = ih264d_parse_decode_slice(
 (UWORD8)(u1_nal_unit_type

                                                             == IDR_SLICE_NAL),
                                             u1_nal_ref_idc, ps_dec);
 
                            if((ps_dec->u4_first_slice_in_pic != 0)&&
                                ((ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC) == 0))
                            {
                                /*  if the first slice header was not valid set to 1 */
                                ps_dec->u4_first_slice_in_pic = 1;
                            }
                             if(i_status != OK)
                             {
                                 return i_status;
 }
 }
 else
 {
                            H264_DEC_DEBUG_PRINT(
 "\nSlice NAL Supplied but no header has been supplied\n");
 }
 }
 break;

 case SEI_NAL:
 if(!ps_dec->i4_decode_header)
 {
                        ih264d_rbsp_to_sodb(ps_dec->ps_bitstrm);
                        i_status = ih264d_parse_sei_message(ps_dec, ps_bitstrm);
 if(i_status != OK)
 return i_status;
                        ih264d_parse_sei(ps_dec, ps_bitstrm);
 }
 break;
 case SEQ_PARAM_NAL:
 /* ! */
                    ih264d_rbsp_to_sodb(ps_dec->ps_bitstrm);
                    i_status = ih264d_parse_sps(ps_dec, ps_bitstrm);
 if(i_status == ERROR_INV_SPS_PPS_T)
 return i_status;
 if(!i_status)
                        ps_dec->i4_header_decoded |= 0x1;
 break;

 case PIC_PARAM_NAL:
 /* ! */
                    ih264d_rbsp_to_sodb(ps_dec->ps_bitstrm);
                    i_status = ih264d_parse_pps(ps_dec, ps_bitstrm);
 if(i_status == ERROR_INV_SPS_PPS_T)
 return i_status;
 if(!i_status)
                        ps_dec->i4_header_decoded |= 0x2;
 break;
 case ACCESS_UNIT_DELIMITER_RBSP:
 if(!ps_dec->i4_decode_header)
 {
                        ih264d_access_unit_delimiter_rbsp(ps_dec);
 }
 break;
 case END_OF_STREAM_RBSP:
 if(!ps_dec->i4_decode_header)
 {
                        ih264d_parse_end_of_stream(ps_dec);
 }
 break;
 case FILLER_DATA_NAL:
 if(!ps_dec->i4_decode_header)
 {
                        ih264d_parse_filler_data(ps_dec, ps_bitstrm);
 }
 break;
 default:
                    H264_DEC_DEBUG_PRINT("\nUnknown NAL type %d\n", u1_nal_unit_type);
 break;
 }

 }

 }

 return i_status;

}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const btrc_ctrl_interface_t *btif_rc_ctrl_get_interface(void)
{
    BTIF_TRACE_EVENT("%s", __FUNCTION__);
 return &bt_rc_ctrl_interface;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BOOLEAN check_hid_le(const bt_bdaddr_t *remote_bdaddr)
{
 uint32_t    remote_dev_type;
 bt_property_t prop_name;

 /* check if we already have it in our btif_storage cache */
    BTIF_STORAGE_FILL_PROPERTY(&prop_name,BT_PROPERTY_TYPE_OF_DEVICE,
 sizeof(uint32_t), &remote_dev_type);
 if (btif_storage_get_remote_device_property((bt_bdaddr_t *)remote_bdaddr,
 &prop_name) == BT_STATUS_SUCCESS)
 {
 if (remote_dev_type == BT_DEVICE_DEVTYPE_BLE)
 {
 bdstr_t bdstr;
            bdaddr_to_string(remote_bdaddr, bdstr, sizeof(bdstr));
 if(btif_config_exist(bdstr, "HidAppId"))
 return TRUE;
 }
 }
 return FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_rem_oob_req (UINT8 *p)
{
    UINT8 *p_bda;
    tBTM_SP_RMT_OOB  evt_data;
    tBTM_SEC_DEV_REC *p_dev_rec;
    BT_OCTET16      c;
    BT_OCTET16      r;

    p_bda = evt_data.bd_addr;

    STREAM_TO_BDADDR (p_bda, p);

    BTM_TRACE_EVENT ("btm_rem_oob_req() BDA: %02x:%02x:%02x:%02x:%02x:%02x",
                      p_bda[0], p_bda[1], p_bda[2], p_bda[3], p_bda[4], p_bda[5]);

 if ( (NULL != (p_dev_rec = btm_find_dev (p_bda))) &&
         btm_cb.api.p_sp_callback)
 {
        memcpy (evt_data.bd_addr, p_dev_rec->bd_addr, BD_ADDR_LEN);
        memcpy (evt_data.dev_class, p_dev_rec->dev_class, DEV_CLASS_LEN);
        BCM_STRNCPY_S((char *)evt_data.bd_name, sizeof(evt_data.bd_name), (char *)p_dev_rec->sec_bd_name, BTM_MAX_REM_BD_NAME_LEN+1);
        evt_data.bd_name[BTM_MAX_REM_BD_NAME_LEN] = 0;

        btm_sec_change_pairing_state(BTM_PAIR_STATE_WAIT_LOCAL_OOB_RSP);
 if ((*btm_cb.api.p_sp_callback) (BTM_SP_RMT_OOB_EVT, (tBTM_SP_EVT_DATA *)&evt_data) == BTM_NOT_AUTHORIZED)
 {
            BTM_RemoteOobDataReply(TRUE, p_bda, c, r);
 }
 return;
 }

 /* something bad. we can only fail this connection */
    btm_cb.acl_disc_reason = HCI_ERR_HOST_REJECT_SECURITY;
    btsnd_hcic_rem_oob_neg_reply (p_bda);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual int handleResponse(WifiEvent& reply) {

        ALOGV("In GetFeatureSetCommand::handleResponse");

 if (reply.get_cmd() != NL80211_CMD_VENDOR) {
            ALOGD("Ignoring reply with cmd = %d", reply.get_cmd());
 return NL_SKIP;
 }

 int id = reply.get_vendor_id();
 int subcmd = reply.get_vendor_subcmd();

        nlattr *vendor_data = reply.get_attribute(NL80211_ATTR_VENDOR_DATA);
 int len = reply.get_vendor_data_len();

        ALOGV("Id = %0x, subcmd = %d, len = %d", id, subcmd, len);
 if (vendor_data == NULL || len == 0) {
            ALOGE("no vendor data in GetFeatureSetCommand response; ignoring it");
 return NL_SKIP;
 }
 if(feature_type == FEATURE_SET) {
 void *data = reply.get_vendor_data();
 if(!fset) {
                ALOGE("Buffers pointers not set");
 return NL_SKIP;
 }
            memcpy(fset, data, min(len, (int) sizeof(*fset)));
 } else {
 int num_features_set = 0;
 int i = 0;

 if(!feature_matrix || !fm_size) {
                ALOGE("Buffers pointers not set");
 return NL_SKIP;
 }

 for (nl_iterator it(vendor_data); it.has_next(); it.next()) {
 if (it.get_type() == ANDR_WIFI_ATTRIBUTE_NUM_FEATURE_SET) {
                    num_features_set = it.get_u32();
                    ALOGV("Got feature list with %d concurrent sets", num_features_set);
 if(set_size_max && (num_features_set > set_size_max))
                        num_features_set = set_size_max;
 *fm_size = num_features_set;
 } else if ((it.get_type() == ANDR_WIFI_ATTRIBUTE_FEATURE_SET) &&
                             i < num_features_set) {
                    feature_matrix[i] = it.get_u32();
                    i++;
 } else {
                    ALOGW("Ignoring invalid attribute type = %d, size = %d",
                            it.get_type(), it.get_len());
 }
 }

 }
 return NL_OK;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlSAXParseFileWithData(xmlSAXHandlerPtr sax, const char *filename,
 int recovery, void *data) {
    xmlDocPtr ret;
    xmlParserCtxtPtr ctxt;

    xmlInitParser();

    ctxt = xmlCreateFileParserCtxt(filename);
 if (ctxt == NULL) {
 return(NULL);
 }
 if (sax != NULL) {
 if (ctxt->sax != NULL)
	    xmlFree(ctxt->sax);
        ctxt->sax = sax;
 }
    xmlDetectSAX2(ctxt);
 if (data!=NULL) {
	ctxt->_private = data;
 }

 if (ctxt->directory == NULL)
        ctxt->directory = xmlParserGetDirectory(filename);

    ctxt->recovery = recovery;

    xmlParseDocument(ctxt);

 if ((ctxt->wellFormed) || recovery) {
        ret = ctxt->myDoc;
 if (ret != NULL) {
 if (ctxt->input->buf->compressed > 0)
		ret->compression = 9;
 else
		ret->compression = ctxt->input->buf->compressed;
 }
 }
 else {
       ret = NULL;
       xmlFreeDoc(ctxt->myDoc);
       ctxt->myDoc = NULL;
 }
 if (sax != NULL)
        ctxt->sax = NULL;
    xmlFreeParserCtxt(ctxt);

 return(ret);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char* Track::GetCodecId() const { return m_info.codecId; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool SniffOgg(
 const sp<DataSource> &source, String8 *mimeType, float *confidence,
        sp<AMessage> *) {
 char tmp[4];
 if (source->readAt(0, tmp, 4) < 4 || memcmp(tmp, "OggS", 4)) {
 return false;
 }

    mimeType->setTo(MEDIA_MIMETYPE_CONTAINER_OGG);
 *confidence = 0.2f;

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_hh_start_vup_timer(bt_bdaddr_t *bd_addr)
{
 btif_hh_device_t *p_dev  = btif_hh_find_connected_dev_by_bda(bd_addr);

 if (p_dev->vup_timer_active == FALSE)
 {
        BTIF_TRACE_DEBUG("Start VUP timer ");
        memset(&p_dev->vup_timer, 0, sizeof(TIMER_LIST_ENT));
        p_dev->vup_timer.param = (UINT32)btif_hh_tmr_hdlr;
        btu_start_timer(&p_dev->vup_timer, BTU_TTYPE_USER_FUNC,
                        BTIF_TIMEOUT_VUP_SECS);
 }
 else
 {
        BTIF_TRACE_DEBUG("Restart VUP timer ");
        btu_stop_timer(&p_dev->vup_timer);
        btu_start_timer(&p_dev->vup_timer, BTU_TTYPE_USER_FUNC,
                        BTIF_TIMEOUT_VUP_SECS);
 }
        p_dev->vup_timer_active = TRUE;

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BufferQueueConsumer::setDefaultBufferSize(uint32_t width,
 uint32_t height) {
    ATRACE_CALL();

 if (width == 0 || height == 0) {
        BQ_LOGV("setDefaultBufferSize: dimensions cannot be 0 (width=%u "
 "height=%u)", width, height);
 return BAD_VALUE;
 }

    BQ_LOGV("setDefaultBufferSize: width=%u height=%u", width, height);

 Mutex::Autolock lock(mCore->mMutex);
    mCore->mDefaultWidth = width;
    mCore->mDefaultHeight = height;
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks, OMX_PTR appData,
        OMX_COMPONENTTYPE **component) {
 return new android::SoftAVC(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SampleTable::CompositionDeltaLookup::setEntries(
 const int32_t *deltaEntries, size_t numDeltaEntries) {
 Mutex::Autolock autolock(mLock);

    mDeltaEntries = deltaEntries;
    mNumDeltaEntries = numDeltaEntries;
    mCurrentDeltaEntry = 0;
    mCurrentEntrySampleIndex = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_vld_decode(
 dec_state_t *ps_dec,
    WORD16      *pi2_outAddr, /*!< Address where decoded symbols will be stored */
 const UWORD8 *pu1_scan, /*!< Scan table to be used */
    UWORD8      *pu1_pos, /*!< Scan table to be used */
    UWORD16     u2_intra_flag, /*!< Intra Macroblock or not */
    UWORD16     u2_chroma_flag, /*!< Chroma Block or not */
    UWORD16     u2_d_picture, /*!< D Picture or not */
    UWORD16     u2_intra_vlc_format, /*!< Intra VLC format */
    UWORD16     u2_mpeg2, /*!< MPEG-2 or not */
    WORD32      *pi4_num_coeffs /*!< Returns the number of coeffs in block */
 )
{

    UWORD32 u4_sym_len;

    UWORD32 u4_decoded_value;
    UWORD32 u4_level_first_byte;
    WORD32  u4_level;
    UWORD32 u4_run, u4_numCoeffs;
    UWORD32 u4_buf;
    UWORD32 u4_buf_nxt;
    UWORD32 u4_offset;
    UWORD32 *pu4_buf_aligned;
    UWORD32 u4_bits;
 stream_t *ps_stream = &ps_dec->s_bit_stream;
    WORD32  u4_pos;
    UWORD32 u4_nz_cols;
    UWORD32 u4_nz_rows;

 *pi4_num_coeffs = 0;

    ps_dec->u4_non_zero_cols = 0;
    ps_dec->u4_non_zero_rows = 0;
    u4_nz_cols = ps_dec->u4_non_zero_cols;
    u4_nz_rows = ps_dec->u4_non_zero_rows;

    GET_TEMP_STREAM_DATA(u4_buf,u4_buf_nxt,u4_offset,pu4_buf_aligned,ps_stream)
 /**************************************************************************/
 /* Decode the DC coefficient in case of Intra block                       */
 /**************************************************************************/
 if(u2_intra_flag)
 {
        WORD32 dc_size;
        WORD32 dc_diff;
        WORD32 maxLen;
        WORD32 idx;


        maxLen = MPEG2_DCT_DC_SIZE_LEN;
        idx = 0;
 if(u2_chroma_flag != 0)
 {
            maxLen += 1;
            idx++;
 }


 {
            WORD16  end = 0;
            UWORD32 maxLen_tmp = maxLen;
            UWORD16 m_iBit;


 /* Get the maximum number of bits needed to decode a symbol */
            IBITS_NXT(u4_buf,u4_buf_nxt,u4_offset,u4_bits,maxLen)
 do
 {
                maxLen_tmp--;
 /* Read one bit at a time from the variable to decode the huffman code */
                m_iBit = (UWORD8)((u4_bits >> maxLen_tmp) & 0x1);

 /* Get the next node pointer or the symbol from the tree */
                end = gai2_impeg2d_dct_dc_size[idx][end][m_iBit];
 }while(end > 0);
            dc_size = end + MPEG2_DCT_DC_SIZE_OFFSET;

 /* Flush the appropriate number of bits from the stream */
            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,(maxLen - maxLen_tmp),pu4_buf_aligned)

 }



 if (dc_size != 0)
 {
            UWORD32 u4_bits;

            IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned, dc_size)
            dc_diff = u4_bits;

 if ((dc_diff & (1 << (dc_size - 1))) == 0) //v Probably the prediction algo?
                dc_diff -= (1 << dc_size) - 1;
 }
 else
 {
            dc_diff = 0;
 }


        pi2_outAddr[*pi4_num_coeffs] = dc_diff;
 /* This indicates the position of the coefficient. Since this is the DC
         * coefficient, we put the position as 0.
         */
        pu1_pos[*pi4_num_coeffs] = pu1_scan[0];
 (*pi4_num_coeffs)++;

 if (0 != dc_diff)
 {
            u4_nz_cols |= 0x01;
            u4_nz_rows |= 0x01;
 }

        u4_numCoeffs = 1;
 }
 /**************************************************************************/
 /* Decoding of first AC coefficient in case of non Intra block            */
 /**************************************************************************/
 else
 {
 /* First symbol can be 1s */
        UWORD32 u4_bits;

        IBITS_NXT(u4_buf,u4_buf_nxt,u4_offset,u4_bits,1)

 if(u4_bits == 1)
 {

            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,1, pu4_buf_aligned)
            IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned, 1)
 if(u4_bits == 1)
 {
                pi2_outAddr[*pi4_num_coeffs] = -1;
 }
 else
 {
                pi2_outAddr[*pi4_num_coeffs] = 1;
 }

 /* This indicates the position of the coefficient. Since this is the DC
             * coefficient, we put the position as 0.
             */
            pu1_pos[*pi4_num_coeffs] = pu1_scan[0];
 (*pi4_num_coeffs)++;
            u4_numCoeffs = 1;

            u4_nz_cols |= 0x01;
            u4_nz_rows |= 0x01;
 }
 else
 {
            u4_numCoeffs = 0;
 }
 }
 if (1 == u2_d_picture)
 {
        PUT_TEMP_STREAM_DATA(u4_buf, u4_buf_nxt, u4_offset, pu4_buf_aligned, ps_stream)
        ps_dec->u4_non_zero_cols  = u4_nz_cols;
        ps_dec->u4_non_zero_rows  = u4_nz_rows;
 return ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE);
 }



 if (1 == u2_intra_vlc_format && u2_intra_flag)
 {

 while(1)
 {

                UWORD32 lead_zeros;
                WORD16 DecodedValue;

                u4_sym_len = 17;
                IBITS_NXT(u4_buf,u4_buf_nxt,u4_offset,u4_bits,u4_sym_len)

 DecodedValue = gau2_impeg2d_tab_one_1_9[u4_bits >> 8];
                u4_sym_len = (DecodedValue & 0xf);
                u4_level = DecodedValue >> 9;
 /* One table lookup */
 if(0 != u4_level)
 {
                    u4_run = ((DecodedValue >> 4) & 0x1f);
                    u4_numCoeffs       += u4_run;
                    u4_pos             = pu1_scan[u4_numCoeffs++ & 63];
                    pu1_pos[*pi4_num_coeffs] = u4_pos;

                    FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                    pi2_outAddr[*pi4_num_coeffs] = u4_level;

 (*pi4_num_coeffs)++;
 }
 else
 {
 if (DecodedValue == END_OF_BLOCK_ONE)
 {
                        u4_sym_len = 4;

 break;
 }
 else
 {
 /*Second table lookup*/
                        lead_zeros = CLZ(u4_bits) - 20;/* -16 since we are dealing with WORD32 */
 if (0 != lead_zeros)
 {

                            u4_bits         = (u4_bits >> (6 - lead_zeros)) & 0x001F;

 /* Flush the number of bits */
 if (1 == lead_zeros)
 {
                                u4_sym_len         = ((u4_bits & 0x18) >> 3) == 2 ? 11:10;
 }
 else
 {
                                u4_sym_len         = 11 + lead_zeros;
 }
 /* flushing */
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)

 /* Calculate the address */
                            u4_bits         = ((lead_zeros - 1) << 5) + u4_bits;

 DecodedValue = gau2_impeg2d_tab_one_10_16[u4_bits];

                            u4_run = BITS(DecodedValue, 8,4);
                            u4_level = ((WORD16) DecodedValue) >> 9;

                            u4_numCoeffs       += u4_run;
                            u4_pos             = pu1_scan[u4_numCoeffs++ & 63];
                            pu1_pos[*pi4_num_coeffs] = u4_pos;
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;
 (*pi4_num_coeffs)++;
 }
 /*********************************************************************/
 /* MPEG2 Escape Code                                                 */
 /*********************************************************************/
 else if(u2_mpeg2 == 1)
 {
                            u4_sym_len         = 6;
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                                IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,18)
                                u4_decoded_value    = u4_bits;
                            u4_run             = (u4_decoded_value >> 12);
                            u4_level           = (u4_decoded_value & 0x0FFF);

 if (u4_level)
                                u4_level = (u4_level - ((u4_level & 0x0800) << 1));

                            u4_numCoeffs       += u4_run;
                            u4_pos             = pu1_scan[u4_numCoeffs++ & 63];
                            pu1_pos[*pi4_num_coeffs] = u4_pos;
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;
 (*pi4_num_coeffs)++;
 }
 /*********************************************************************/
 /* MPEG1 Escape Code                                                 */
 /*********************************************************************/
 else
 {
 /*-----------------------------------------------------------
                            * MPEG-1 Stream
                            *
                            * <See D.9.3 of MPEG-2> Run-level escape syntax
                            * Run-level values that cannot be coded with a VLC are coded
                            * by the escape code '0000 01' followed by
                            * either a 14-bit FLC (127 <= level <= 127),
                            * or a 22-bit FLC (255 <= level <= 255).
                            * This is described in Annex B,B.5f of MPEG-1.standard
                            *-----------------------------------------------------------*/

 /*-----------------------------------------------------------
                            * First 6 bits are the value of the Run. Next is First 8 bits
                            * of Level. These bits decide whether it is 14 bit FLC or
                            * 22-bit FLC.
                            *
                            * If( first 8 bits of Level == '1000000' or '00000000')
                            *      then its is 22-bit FLC.
                            * else
                            *      it is 14-bit FLC.
                            *-----------------------------------------------------------*/
                            u4_sym_len         = 6;
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                                IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,14)
                                u4_decoded_value     = u4_bits;
                            u4_run              = (u4_decoded_value >> 8);
                            u4_level_first_byte = (u4_decoded_value & 0x0FF);
 if(u4_level_first_byte & 0x7F)
 {
 /*-------------------------------------------------------
                                * First 8 bits of level are neither 1000000 nor 00000000
                                * Hence 14-bit FLC (Last 8 bits are used to get level)
                                *
                                *  Level = (msb of Level_First_Byte is 1)?
                                *          Level_First_Byte - 256 : Level_First_Byte
                                *-------------------------------------------------------*/
                                u4_level = (u4_level_first_byte -
 ((u4_level_first_byte & 0x80) << 1));
 }
 else
 {
 /*-------------------------------------------------------
                                * Next 8 bits are either 1000000 or 00000000
                                * Hence 22-bit FLC (Last 16 bits are used to get level)
                                *
                                *  Level = (msb of Level_First_Byte is 1)?
                                *          Level_Second_Byte - 256 : Level_Second_Byte
                                *-------------------------------------------------------*/
                                IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,8)
                                    u4_level = u4_bits;
                                u4_level = (u4_level - (u4_level_first_byte << 1));
 }
                            u4_numCoeffs += u4_run;

                            u4_pos = pu1_scan[u4_numCoeffs++ & 63];

                            pu1_pos[*pi4_num_coeffs] = u4_pos;
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;
 (*pi4_num_coeffs)++;
 }
 }
 }


                 u4_nz_cols |= 1 << (u4_pos & 0x7);
                 u4_nz_rows |= 1 << (u4_pos >> 0x3);
 
 
             }
             IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,u4_sym_len)
            if (u4_numCoeffs > 64)
            {
                return IMPEG2D_MB_TEX_DECODE_ERR;
            }
         }
         else
         {
 while(1)
 {

                UWORD32 lead_zeros;
                UWORD16 DecodedValue;

                u4_sym_len = 17;
                IBITS_NXT(u4_buf, u4_buf_nxt, u4_offset, u4_bits, u4_sym_len)


 DecodedValue = gau2_impeg2d_tab_zero_1_9[u4_bits >> 8];
                u4_sym_len = BITS(DecodedValue, 3, 0);
                u4_level = ((WORD16) DecodedValue) >> 9;

 if (0 != u4_level)
 {
                    u4_run = BITS(DecodedValue, 8,4);

                    u4_numCoeffs       += u4_run;

                    u4_pos                 = pu1_scan[u4_numCoeffs++ & 63];
                    pu1_pos[*pi4_num_coeffs] = u4_pos;

                    FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                    pi2_outAddr[*pi4_num_coeffs] = u4_level;
 (*pi4_num_coeffs)++;
 }
 else
 {
 if(DecodedValue == END_OF_BLOCK_ZERO)
 {
                        u4_sym_len = 2;

 break;
 }
 else
 {
                        lead_zeros = CLZ(u4_bits) - 20;/* -15 since we are dealing with WORD32 */
 /*Second table lookup*/
 if (0 != lead_zeros)
 {
                            u4_bits         = (u4_bits >> (6 - lead_zeros)) & 0x001F;

 /* Flush the number of bits */
                            u4_sym_len         = 11 + lead_zeros;

 /* Calculate the address */
                            u4_bits         = ((lead_zeros - 1) << 5) + u4_bits;

 DecodedValue = gau2_impeg2d_tab_zero_10_16[u4_bits];

                            u4_run = BITS(DecodedValue, 8,4);
                            u4_level = ((WORD16) DecodedValue) >> 9;

                            u4_numCoeffs       += u4_run;

                            u4_pos                 = pu1_scan[u4_numCoeffs++ & 63];
                            pu1_pos[*pi4_num_coeffs] = u4_pos;
 if (1 == lead_zeros)
                                u4_sym_len--;
 /* flushing */
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;

 (*pi4_num_coeffs)++;
 }
 /*Escape Sequence*/
 else if(u2_mpeg2 == 1)
 {
                            u4_sym_len         = 6;
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                            IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,18)
                            u4_decoded_value    = u4_bits;
                            u4_run             = (u4_decoded_value >> 12);
                            u4_level           = (u4_decoded_value & 0x0FFF);

 if (u4_level)
                                u4_level = (u4_level - ((u4_level & 0x0800) << 1));

                            u4_numCoeffs           += u4_run;

                            u4_pos                 = pu1_scan[u4_numCoeffs++ & 63];
                            pu1_pos[*pi4_num_coeffs] = u4_pos;
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;

 (*pi4_num_coeffs)++;
 }
 /*********************************************************************/
 /* MPEG1 Escape Code                                                 */
 /*********************************************************************/
 else
 {
 /*-----------------------------------------------------------
                            * MPEG-1 Stream
                            *
                            * <See D.9.3 of MPEG-2> Run-level escape syntax
                            * Run-level values that cannot be coded with a VLC are coded
                            * by the escape code '0000 01' followed by
                            * either a 14-bit FLC (127 <= level <= 127),
                            * or a 22-bit FLC (255 <= level <= 255).
                            * This is described in Annex B,B.5f of MPEG-1.standard
                            *-----------------------------------------------------------*/

 /*-----------------------------------------------------------
                            * First 6 bits are the value of the Run. Next is First 8 bits
                            * of Level. These bits decide whether it is 14 bit FLC or
                            * 22-bit FLC.
                            *
                            * If( first 8 bits of Level == '1000000' or '00000000')
                            *      then its is 22-bit FLC.
                            * else
                            *      it is 14-bit FLC.
                            *-----------------------------------------------------------*/
                            u4_sym_len             = 6;
                            FLUSH_BITS(u4_offset,u4_buf,u4_buf_nxt,u4_sym_len,pu4_buf_aligned)
                            IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,14)
                            u4_decoded_value        = u4_bits;
                            u4_run                 = (u4_decoded_value >> 8);
                            u4_level_first_byte    = (u4_decoded_value & 0x0FF);
 if(u4_level_first_byte & 0x7F)
 {
 /*-------------------------------------------------------
                                * First 8 bits of level are neither 1000000 nor 00000000
                                * Hence 14-bit FLC (Last 8 bits are used to get level)
                                *
                                *  Level = (msb of Level_First_Byte is 1)?
                                *          Level_First_Byte - 256 : Level_First_Byte
                                *-------------------------------------------------------*/
                                u4_level = (u4_level_first_byte -
 ((u4_level_first_byte & 0x80) << 1));
 }
 else
 {
 /*-------------------------------------------------------
                                * Next 8 bits are either 1000000 or 00000000
                                * Hence 22-bit FLC (Last 16 bits are used to get level)
                                *
                                *  Level = (msb of Level_First_Byte is 1)?
                                *          Level_Second_Byte - 256 : Level_Second_Byte
                                *-------------------------------------------------------*/
                                IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,8)
                                u4_level = u4_bits;
                                u4_level = (u4_level - (u4_level_first_byte << 1));
 }
                            u4_numCoeffs           += u4_run;

                            u4_pos                 = pu1_scan[u4_numCoeffs++ & 63];
                            pu1_pos[*pi4_num_coeffs] = u4_pos;
                            pi2_outAddr[*pi4_num_coeffs] = u4_level;

 (*pi4_num_coeffs)++;
 }
 }
 }

 
                 u4_nz_cols |= 1 << (u4_pos & 0x7);
                 u4_nz_rows |= 1 << (u4_pos >> 0x3);
            }
            if (u4_numCoeffs > 64)
            {
                return IMPEG2D_MB_TEX_DECODE_ERR;
             }
 
             IBITS_GET(u4_buf,u4_buf_nxt,u4_offset,u4_bits,pu4_buf_aligned,u4_sym_len)

 }

        PUT_TEMP_STREAM_DATA(u4_buf, u4_buf_nxt, u4_offset, pu4_buf_aligned, ps_stream)

        ps_dec->u4_non_zero_cols  = u4_nz_cols;
        ps_dec->u4_non_zero_rows  = u4_nz_rows;

 return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: bool ACodec::BaseState::onOMXFrameRendered(
 int64_t mediaTimeUs __unused, nsecs_t systemNano __unused) {
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlLoadEntityContent(xmlParserCtxtPtr ctxt, xmlEntityPtr entity) {
    xmlParserInputPtr input;
    xmlBufferPtr buf;
 int l, c;
 int count = 0;

 if ((ctxt == NULL) || (entity == NULL) ||
 ((entity->etype != XML_EXTERNAL_PARAMETER_ENTITY) &&
 (entity->etype != XML_EXTERNAL_GENERAL_PARSED_ENTITY)) ||
 (entity->content != NULL)) {
	xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR,
 "xmlLoadEntityContent parameter error");
 return(-1);
 }

 if (xmlParserDebugEntities)
	xmlGenericError(xmlGenericErrorContext,
 "Reading %s entity content input\n", entity->name);

    buf = xmlBufferCreate();
 if (buf == NULL) {
	xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR,
 "xmlLoadEntityContent parameter error");
 return(-1);
 }

    input = xmlNewEntityInputStream(ctxt, entity);
 if (input == NULL) {
	xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR,
 "xmlLoadEntityContent input error");
	xmlBufferFree(buf);
 return(-1);
 }

 /*
     * Push the entity as the current input, read char by char
     * saving to the buffer until the end of the entity or an error
     */
 if (xmlPushInput(ctxt, input) < 0) {
        xmlBufferFree(buf);
 return(-1);
 }

    GROW;
    c = CUR_CHAR(l);
 while ((ctxt->input == input) && (ctxt->input->cur < ctxt->input->end) &&
 (IS_CHAR(c))) {
        xmlBufferAdd(buf, ctxt->input->cur, l);
 if (count++ > XML_PARSER_CHUNK_SIZE) {
	    count = 0;
	    GROW;
 if (ctxt->instate == XML_PARSER_EOF) {
                xmlBufferFree(buf);
 return(-1);
 }
 }
	NEXTL(l);
	c = CUR_CHAR(l);
 if (c == 0) {
	    count = 0;
	    GROW;
 if (ctxt->instate == XML_PARSER_EOF) {
                xmlBufferFree(buf);
 return(-1);
 }
	    c = CUR_CHAR(l);
 }
 }

 if ((ctxt->input == input) && (ctxt->input->cur >= ctxt->input->end)) {
        xmlPopInput(ctxt);
 } else if (!IS_CHAR(c)) {
        xmlFatalErrMsgInt(ctxt, XML_ERR_INVALID_CHAR,
 "xmlLoadEntityContent: invalid char value %d\n",
	                  c);
	xmlBufferFree(buf);
 return(-1);
 }
    entity->content = buf->content;
    buf->content = NULL;
    xmlBufferFree(buf);

 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::InputState::~InputState() {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jobject Bitmap_createFromParcel(JNIEnv* env, jobject, jobject parcel) {
 if (parcel == NULL) {
 SkDebugf("-------- unparcel parcel is NULL\n");
 return NULL;
 }

    android::Parcel* p = android::parcelForJavaObject(env, parcel);

 const bool        isMutable = p->readInt32() != 0;
 const SkColorType colorType = (SkColorType)p->readInt32();
 const SkAlphaType alphaType = (SkAlphaType)p->readInt32();
 const int         width = p->readInt32();
 const int         height = p->readInt32();
 const int         rowBytes = p->readInt32();
 const int         density = p->readInt32();

 if (kN32_SkColorType != colorType &&
            kRGB_565_SkColorType != colorType &&
            kARGB_4444_SkColorType != colorType &&
            kIndex_8_SkColorType != colorType &&
            kAlpha_8_SkColorType != colorType) {
 SkDebugf("Bitmap_createFromParcel unknown colortype: %d\n", colorType);

         return NULL;
     }
 
    SkBitmap* bitmap = new SkBitmap;
 
    bitmap->setInfo(SkImageInfo::Make(width, height, colorType, alphaType), rowBytes);
 
     SkColorTable* ctable = NULL;
     if (colorType == kIndex_8_SkColorType) {
         int count = p->readInt32();
         if (count > 0) {
             size_t size = count * sizeof(SkPMColor);
             const SkPMColor* src = (const SkPMColor*)p->readInplace(size);
             ctable = new SkColorTable(src, count);
         }
     }
 
    jbyteArray buffer = GraphicsJNI::allocateJavaPixelRef(env, bitmap, ctable);
     if (NULL == buffer) {
         SkSafeUnref(ctable);
        delete bitmap;
         return NULL;
     }
 
 SkSafeUnref(ctable);

 size_t size = bitmap->getSize();

    android::Parcel::ReadableBlob blob;

     android::status_t status = p->readBlob(size, &blob);
     if (status) {
         doThrowRE(env, "Could not read bitmap from parcel blob.");
        delete bitmap;
         return NULL;
     }
 
    bitmap->lockPixels();
    memcpy(bitmap->getPixels(), blob.data(), size);
    bitmap->unlockPixels();

 
     blob.release();
 
    return GraphicsJNI::createBitmap(env, bitmap, buffer, getPremulBitmapCreateFlags(isMutable),
            NULL, NULL, density);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void unlock_buffer_pool(BufferPool *const pool) {
#if CONFIG_MULTITHREAD
  pthread_mutex_unlock(&pool->pool_mutex);
#else
 (void)pool;
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;


 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {

         ih264d_err_pic_dispbuf_mgr(ps_dec);
         return 0;
     }
     if(prev_slice_err == 1)
     {
         /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;


 if(!ps_dec->u1_first_slice_in_stream)
 {
            ih264d_end_of_pic(ps_dec, u1_is_idr_slice,
                ps_dec->ps_cur_slice->u2_frame_num);
            ps_dec->s_cur_pic_poc.u2_frame_num =
                ps_dec->ps_cur_slice->u2_frame_num;
 }

 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = 0;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
                       j = i;
 {
                ps_dec->ps_cur_slice->u1_bottom_field_flag = 0;
                ps_dec->ps_cur_slice->u1_field_pic_flag = 0;
                ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
                ps_dec->ps_cur_slice->u1_nal_ref_idc = 1;
                ps_dec->ps_cur_slice->u1_nal_unit_type = 1;
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }
 }
 }
 else
 {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;

 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info - 1;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

            ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
            ps_dec->u2_cur_mb_addr--;
            ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if(u1_num_mbs)
 {
 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

            ps_dec->u2_cur_slice_num++;
             ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
            ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
            ps_dec->ps_parse_cur_slice++;

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MAX_FRAMES;
 if((1 >= ps_dec->ps_cur_sps->u1_num_ref_frames) &&
 (0 == ps_dec->i4_display_delay))
 {
            num_entries = 1;
 }
        num_entries = ((2 * num_entries) + 1);
 if(BASE_PROFILE_IDC != ps_dec->ps_cur_sps->u1_profile_idc)
 {
            num_entries *= 2;
 }
        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
    ps_dec->ps_cur_slice->i1_slice_alpha_c0_offset = 0;
    ps_dec->ps_cur_slice->i1_slice_beta_offset = 0;

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded << u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

    H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);

    ps_dec->u2_cur_slice_num++;

 /* incremented here only if first slice is inserted */
 if(ps_dec->u4_first_slice_in_pic != 0)
        ps_dec->ps_parse_cur_slice++;

    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void SoftVPX::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mOutputPortSettingsChange != NONE || mEOSStatus == OUTPUT_FRAMES_FLUSHED) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);
 bool EOSseen = false;
 bool portWillReset = false;

 while ((mEOSStatus == INPUT_EOS_SEEN || !inQueue.empty())
 && !outQueue.empty()) {
 if (mEOSStatus == INPUT_EOS_SEEN || mImg != NULL) {
 if (!outputBuffers(
                     mEOSStatus == INPUT_EOS_SEEN, true /* display */,
                     mEOSStatus == INPUT_EOS_SEEN, &portWillReset)) {
                ALOGE("on2 decoder failed to output frame.");
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 if (portWillReset || mEOSStatus == OUTPUT_FRAMES_FLUSHED ||
                    mEOSStatus == INPUT_EOS_SEEN) {
 return;
 }
 continue;
 }

 BufferInfo *inInfo = *inQueue.begin();
        OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 if (inHeader->nFlags & OMX_BUFFERFLAG_CODECCONFIG) {
 if (mMode == MODE_VP9) {
                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);
 continue;
 } else {
                ALOGW("WARNING: Got CSD buffer for VP8.");
 }
 }

        mTimeStamps[mTimeStampIdx] = inHeader->nTimeStamp;

 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
            mEOSStatus = INPUT_EOS_SEEN;
 EOSseen = true;
 }

 if (inHeader->nFilledLen > 0) {
 vpx_codec_err_t err = vpx_codec_decode(
 (vpx_codec_ctx_t *)mCtx, inHeader->pBuffer + inHeader->nOffset,
                    inHeader->nFilledLen, &mTimeStamps[mTimeStampIdx], 0);
 if (err == VPX_CODEC_OK) {
                inInfo->mOwnedByUs = false;
                inQueue.erase(inQueue.begin());
                inInfo = NULL;
                notifyEmptyBufferDone(inHeader);
                inHeader = NULL;
 } else {
                ALOGE("on2 decoder failed to decode frame. err: %d", err);
                notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 }

        mTimeStampIdx = (mTimeStampIdx + 1) % kNumBuffers;

 if (!outputBuffers(
 EOSseen /* flushDecoder */, true /* display */, EOSseen, &portWillReset)) {
            ALOGE("on2 decoder failed to output frame.");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
 return;
 }
 if (portWillReset) {
 return;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int _ilog(unsigned int v){
 int ret=0;
 while(v){
    ret++;
    v>>=1;
 }
 return(ret);

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool frame_sync_(FLAC__StreamDecoder *decoder)
{
	FLAC__uint32 x;
	FLAC__bool first = true;

 /* If we know the total number of samples in the stream, stop if we've read that many. */
 /* This will stop us, for example, from wasting time trying to sync on an ID3V1 tag. */
 if(FLAC__stream_decoder_get_total_samples(decoder) > 0) {
 if(decoder->private_->samples_decoded >= FLAC__stream_decoder_get_total_samples(decoder)) {
			decoder->protected_->state = FLAC__STREAM_DECODER_END_OF_STREAM;
 return true;
 }
 }

 /* make sure we're byte aligned */
 if(!FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input)) {
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, FLAC__bitreader_bits_left_for_byte_alignment(decoder->private_->input)))
 return false; /* read_callback_ sets the state for us */
 }

 while(1) {
 if(decoder->private_->cached) {
			x = (FLAC__uint32)decoder->private_->lookahead;
			decoder->private_->cached = false;
 }
 else {
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 8))
 return false; /* read_callback_ sets the state for us */
 }
 if(x == 0xff) { /* MAGIC NUMBER for the first 8 frame sync bits */
			decoder->private_->header_warmup[0] = (FLAC__byte)x;
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, 8))
 return false; /* read_callback_ sets the state for us */

 /* we have to check if we just read two 0xff's in a row; the second may actually be the beginning of the sync code */
 /* else we have to check if the second byte is the end of a sync code */
 if(x == 0xff) { /* MAGIC NUMBER for the first 8 frame sync bits */
				decoder->private_->lookahead = (FLAC__byte)x;
				decoder->private_->cached = true;
 }
 else if(x >> 1 == 0x7c) { /* MAGIC NUMBER for the last 6 sync bits and reserved 7th bit */
				decoder->private_->header_warmup[1] = (FLAC__byte)x;
				decoder->protected_->state = FLAC__STREAM_DECODER_READ_FRAME;
 return true;
 }
 }
 if(first) {
			send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);
			first = false;
 }
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:      BufferMeta(const sp<GraphicBuffer> &graphicBuffer, OMX_U32 portIndex)
         : mGraphicBuffer(graphicBuffer),
          mIsBackup(false),
          mPortIndex(portIndex) {
     }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  explicit MyVorbisExtractor(const sp<DataSource> &source)
 : MyOggExtractor(source,
                MEDIA_MIMETYPE_AUDIO_VORBIS,
 /* numHeaders */ 3,
 /* seekPreRollUs */ 0) {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftHEVC::SoftHEVC(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftVideoDecoderOMXComponent(name, componentName, codingType,
            kProfileLevels, ARRAY_SIZE(kProfileLevels),
 320 /* width */, 240 /* height */, callbacks,
            appData, component),
      mCodecCtx(NULL),
      mFlushOutBuffer(NULL),
      mOmxColorFormat(OMX_COLOR_FormatYUV420Planar),
      mIvColorFormat(IV_YUV_420P),
      mChangingResolution(false),
      mSignalledError(false),
      mStride(mWidth) {
 const size_t kMinCompressionRatio = 4 /* compressionRatio (for Level 4+) */;
 const size_t kMaxOutputBufferSize = 2048 * 2048 * 3 / 2;
    initPorts(
            kNumBuffers, max(kMaxOutputBufferSize / kMinCompressionRatio, (size_t)INPUT_BUF_SIZE),
            kNumBuffers, CODEC_MIME_TYPE, kMinCompressionRatio);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int rpng2_x_load_bg_image(void)
{
    uch *src;
 char *dest;
    uch r1, r2, g1, g2, b1, b2;
    uch r1_inv, r2_inv, g1_inv, g2_inv, b1_inv, b2_inv;
 int k, hmax, max;
 int xidx, yidx, yidx_max;
 int even_odd_vert, even_odd_horiz, even_odd;
 int invert_gradient2 = (bg[pat].type & 0x08);
 int invert_column;
 int ximage_rowbytes = ximage->bytes_per_line;
    ulg i, row;
    ulg pixel;

/*---------------------------------------------------------------------------
    Allocate buffer for fake background image to be used with transparent
    images; if this fails, revert to plain background color.
  ---------------------------------------------------------------------------*/

    bg_rowbytes = 3 * rpng2_info.width;
    bg_data = (uch *)malloc(bg_rowbytes * rpng2_info.height);
 if (!bg_data) {
        fprintf(stderr, PROGNAME
 ":  unable to allocate memory for background image\n");
        bg_image = 0;
 return 1;
 }

    bgscale = (pat == 0)? 8 : bgscale_default;
    yidx_max = bgscale - 1;

/*---------------------------------------------------------------------------
    Vertical gradients (ramps) in NxN squares, alternating direction and
    colors (N == bgscale).
  ---------------------------------------------------------------------------*/

 if ((bg[pat].type & 0x07) == 0) {
        uch r1_min  = rgb[bg[pat].rgb1_min].r;
        uch g1_min  = rgb[bg[pat].rgb1_min].g;
        uch b1_min  = rgb[bg[pat].rgb1_min].b;
        uch r2_min  = rgb[bg[pat].rgb2_min].r;
        uch g2_min  = rgb[bg[pat].rgb2_min].g;
        uch b2_min  = rgb[bg[pat].rgb2_min].b;
 int r1_diff = rgb[bg[pat].rgb1_max].r - r1_min;
 int g1_diff = rgb[bg[pat].rgb1_max].g - g1_min;
 int b1_diff = rgb[bg[pat].rgb1_max].b - b1_min;
 int r2_diff = rgb[bg[pat].rgb2_max].r - r2_min;
 int g2_diff = rgb[bg[pat].rgb2_max].g - g2_min;
 int b2_diff = rgb[bg[pat].rgb2_max].b - b2_min;

 for (row = 0;  row < rpng2_info.height; ++row) {
            yidx = (int)(row % bgscale);
            even_odd_vert = (int)((row / bgscale) & 1);

            r1 = r1_min + (r1_diff * yidx) / yidx_max;
            g1 = g1_min + (g1_diff * yidx) / yidx_max;
            b1 = b1_min + (b1_diff * yidx) / yidx_max;
            r1_inv = r1_min + (r1_diff * (yidx_max-yidx)) / yidx_max;
            g1_inv = g1_min + (g1_diff * (yidx_max-yidx)) / yidx_max;
            b1_inv = b1_min + (b1_diff * (yidx_max-yidx)) / yidx_max;

            r2 = r2_min + (r2_diff * yidx) / yidx_max;
            g2 = g2_min + (g2_diff * yidx) / yidx_max;
            b2 = b2_min + (b2_diff * yidx) / yidx_max;
            r2_inv = r2_min + (r2_diff * (yidx_max-yidx)) / yidx_max;
            g2_inv = g2_min + (g2_diff * (yidx_max-yidx)) / yidx_max;
            b2_inv = b2_min + (b2_diff * (yidx_max-yidx)) / yidx_max;

            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                even_odd_horiz = (int)((i / bgscale) & 1);
                even_odd = even_odd_vert ^ even_odd_horiz;
                invert_column =
 (even_odd_horiz && (bg[pat].type & 0x10));
 if (even_odd == 0) { /* gradient #1 */
 if (invert_column) {
 *dest++ = r1_inv;
 *dest++ = g1_inv;
 *dest++ = b1_inv;
 } else {
 *dest++ = r1;
 *dest++ = g1;
 *dest++ = b1;
 }
 } else { /* gradient #2 */
 if ((invert_column && invert_gradient2) ||
 (!invert_column && !invert_gradient2))
 {
 *dest++ = r2; /* not inverted or */
 *dest++ = g2; /*  doubly inverted */
 *dest++ = b2;
 } else {
 *dest++ = r2_inv;
 *dest++ = g2_inv; /* singly inverted */
 *dest++ = b2_inv;
 }
 }
 }
 }

/*---------------------------------------------------------------------------
    Soft gradient-diamonds with scale = bgscale.  Code contributed by Adam
    M. Costello.
  ---------------------------------------------------------------------------*/

 } else if ((bg[pat].type & 0x07) == 1) {

        hmax = (bgscale-1)/2; /* half the max weight of a color */
        max = 2*hmax; /* the max weight of a color */

        r1 = rgb[bg[pat].rgb1_max].r;
        g1 = rgb[bg[pat].rgb1_max].g;
        b1 = rgb[bg[pat].rgb1_max].b;
        r2 = rgb[bg[pat].rgb2_max].r;
        g2 = rgb[bg[pat].rgb2_max].g;
        b2 = rgb[bg[pat].rgb2_max].b;

 for (row = 0;  row < rpng2_info.height; ++row) {
            yidx = (int)(row % bgscale);
 if (yidx > hmax)
                yidx = bgscale-1 - yidx;
            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                xidx = (int)(i % bgscale);
 if (xidx > hmax)
                    xidx = bgscale-1 - xidx;
                k = xidx + yidx;
 *dest++ = (k*r1 + (max-k)*r2) / max;
 *dest++ = (k*g1 + (max-k)*g2) / max;
 *dest++ = (k*b1 + (max-k)*b2) / max;
 }
 }

/*---------------------------------------------------------------------------
    Radial "starburst" with azimuthal sinusoids; [eventually number of sinu-
    soids will equal bgscale?].  This one is slow but very cool.  Code con-
    tributed by Pieter S. van der Meulen (originally in Smalltalk).
  ---------------------------------------------------------------------------*/

 } else if ((bg[pat].type & 0x07) == 2) {
        uch ch;
 int ii, x, y, hw, hh, grayspot;
 double freq, rotate, saturate, gray, intensity;
 double angle=0.0, aoffset=0.0, maxDist, dist;
 double red=0.0, green=0.0, blue=0.0, hue, s, v, f, p, q, t;

        fprintf(stderr, "%s:  computing radial background...",
          PROGNAME);
        fflush(stderr);

        hh = (int)(rpng2_info.height / 2);
        hw = (int)(rpng2_info.width / 2);

 /* variables for radial waves:
         *   aoffset:  number of degrees to rotate hue [CURRENTLY NOT USED]
         *   freq:  number of color beams originating from the center
         *   grayspot:  size of the graying center area (anti-alias)
         *   rotate:  rotation of the beams as a function of radius
         *   saturate:  saturation of beams' shape azimuthally
         */
        angle = CLIP(angle, 0.0, 360.0);
        grayspot = CLIP(bg[pat].bg_gray, 1, (hh + hw));
        freq = MAX((double)bg[pat].bg_freq, 0.0);
        saturate = (double)bg[pat].bg_bsat * 0.1;
        rotate = (double)bg[pat].bg_brot * 0.1;
        gray = 0.0;
        intensity = 0.0;
        maxDist = (double)((hw*hw) + (hh*hh));

 for (row = 0;  row < rpng2_info.height; ++row) {
            y = (int)(row - hh);
            dest = (char *)bg_data + row*bg_rowbytes;
 for (i = 0;  i < rpng2_info.width; ++i) {
                x = (int)(i - hw);
                angle = (x == 0)? PI_2 : atan((double)y / (double)x);
                gray = (double)MAX(ABS(y), ABS(x)) / grayspot;
                gray = MIN(1.0, gray);
                dist = (double)((x*x) + (y*y)) / maxDist;
                intensity = cos((angle+(rotate*dist*PI)) * freq) *
                  gray * saturate;
                intensity = (MAX(MIN(intensity,1.0),-1.0) + 1.0) * 0.5;
                hue = (angle + PI) * INV_PI_360 + aoffset;
                s = gray * ((double)(ABS(x)+ABS(y)) / (double)(hw + hh));
                s = MIN(MAX(s,0.0), 1.0);
                v = MIN(MAX(intensity,0.0), 1.0);

 if (s == 0.0) {
                    ch = (uch)(v * 255.0);
 *dest++ = ch;
 *dest++ = ch;
 *dest++ = ch;
 } else {
 if ((hue < 0.0) || (hue >= 360.0))
                        hue -= (((int)(hue / 360.0)) * 360.0);
                    hue /= 60.0;
                    ii = (int)hue;
                    f = hue - (double)ii;
                    p = (1.0 - s) * v;
                    q = (1.0 - (s * f)) * v;
                    t = (1.0 - (s * (1.0 - f))) * v;
 if (ii == 0) { red = v; green = t; blue = p; }
 else if (ii == 1) { red = q; green = v; blue = p; }
 else if (ii == 2) { red = p; green = v; blue = t; }
 else if (ii == 3) { red = p; green = q; blue = v; }
 else if (ii == 4) { red = t; green = p; blue = v; }
 else if (ii == 5) { red = v; green = p; blue = q; }
 *dest++ = (uch)(red * 255.0);
 *dest++ = (uch)(green * 255.0);
 *dest++ = (uch)(blue * 255.0);
 }
 }
 }
        fprintf(stderr, "done.\n");
        fflush(stderr);
 }

/*---------------------------------------------------------------------------
    Blast background image to display buffer before beginning PNG decode.
  ---------------------------------------------------------------------------*/

 if (depth == 24 || depth == 32) {
        ulg red, green, blue;
 int bpp = ximage->bits_per_pixel;

 for (row = 0;  row < rpng2_info.height; ++row) {
            src = bg_data + row*bg_rowbytes;
            dest = ximage->data + row*ximage_rowbytes;
 if (bpp == 32) { /* slightly optimized version */
 for (i = rpng2_info.width;  i > 0; --i) {
                    red   = *src++;
                    green = *src++;
                    blue  = *src++;
                    pixel = (red   << RShift) |
 (green << GShift) |
 (blue  << BShift);
 /* recall that we set ximage->byte_order = MSBFirst above */
 *dest++ = (char)((pixel >> 24) & 0xff);
 *dest++ = (char)((pixel >> 16) & 0xff);
 *dest++ = (char)((pixel >> 8) & 0xff);
 *dest++ = (char)( pixel        & 0xff);
 }
 } else {
 for (i = rpng2_info.width;  i > 0; --i) {
                    red   = *src++;
                    green = *src++;
                    blue  = *src++;
                    pixel = (red   << RShift) |
 (green << GShift) |
 (blue  << BShift);
 /* recall that we set ximage->byte_order = MSBFirst above */
 /* GRR BUG?  this assumes bpp == 24 & bits are packed low */
 /*           (probably need to use RShift, RMask, etc.) */
 *dest++ = (char)((pixel >> 16) & 0xff);
 *dest++ = (char)((pixel >> 8) & 0xff);
 *dest++ = (char)( pixel        & 0xff);
 }
 }
 }

 } else if (depth == 16) {
        ush red, green, blue;

 for (row = 0;  row < rpng2_info.height; ++row) {
            src = bg_data + row*bg_rowbytes;
            dest = ximage->data + row*ximage_rowbytes;
 for (i = rpng2_info.width;  i > 0; --i) {
                red   = ((ush)(*src) << 8); ++src;
                green = ((ush)(*src) << 8); ++src;
                blue  = ((ush)(*src) << 8); ++src;
                pixel = ((red   >> RShift) & RMask) |
 ((green >> GShift) & GMask) |
 ((blue  >> BShift) & BMask);
 /* recall that we set ximage->byte_order = MSBFirst above */
 *dest++ = (char)((pixel >> 8) & 0xff);
 *dest++ = (char)( pixel        & 0xff);
 }
 }

 } else /* depth == 8 */ {

 /* GRR:  add 8-bit support */

 }

 XPutImage(display, window, gc, ximage, 0, 0, 0, 0, rpng2_info.width,
      rpng2_info.height);

 return 0;

} /* end function rpng2_x_load_bg_image() */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: SoftAVC::~SoftAVC() {
    CHECK_EQ(deInitDecoder(), (status_t)OK);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ATSParser::SyncEvent::init(off64_t offset, const sp<MediaSource> &source,
 int64_t timeUs) {
    mInit = true;
    mOffset = offset;
    mMediaSource = source;
    mTimeUs = timeUs;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::finishWrite(size_t len)
{
    mDataPos += len;
    ALOGV("finishWrite Setting data pos of %p to %zu", this, mDataPos);
 if (mDataPos > mDataSize) {
        mDataSize = mDataPos;
        ALOGV("finishWrite Setting data size of %p to %zu", this, mDataSize);
 }
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_proc_confirm(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = p_data->p_data;

  SMP_TRACE_DEBUG("%s", __func__);

 if (smp_command_has_invalid_parameters(p_cb)) {
    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = SMP_INVALID_PARAMETERS;
    smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &smp_int_data);
 return;
 }

 if (p != NULL) {
 /* save the SConfirm for comparison later */
    STREAM_TO_ARRAY(p_cb->rconfirm, p, BT_OCTET16_LEN);
 }

  p_cb->flags |= SMP_PAIR_FLAGS_CMD_CONFIRM;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OSCL_EXPORT_REF Bool PVInitVideoDecoder(VideoDecControls *decCtrl, uint8 *volbuf[],
 int32 *volbuf_size, int nLayers, int width, int height, MP4DecodingMode mode)
{
 VideoDecData *video = (VideoDecData *) decCtrl->videoDecoderData;
 Bool status = PV_TRUE;
 int idx;
 BitstreamDecVideo *stream;


    oscl_memset(decCtrl, 0, sizeof(VideoDecControls)); /* fix a size bug.   03/28/2001 */
    decCtrl->nLayers = nLayers;
 for (idx = 0; idx < nLayers; idx++)
 {
        decCtrl->volbuf[idx] = volbuf[idx];
        decCtrl->volbuf_size[idx] = volbuf_size[idx];
 }

 /* memory allocation & initialization */
#ifdef DEC_INTERNAL_MEMORY_OPT
    video = IMEM_VideoDecData;
#else
    video = (VideoDecData *) oscl_malloc(sizeof(VideoDecData));
#endif
 if (video != NULL)
 {
        oscl_memset(video, 0, sizeof(VideoDecData));
        video->memoryUsage = sizeof(VideoDecData);
        video->numberOfLayers = nLayers;
#ifdef DEC_INTERNAL_MEMORY_OPT
        video->vol = (Vol **) IMEM_VOL;
#else
 if ((size_t)nLayers > SIZE_MAX / sizeof(Vol *)) {
            status = PV_FALSE;
 goto fail;
 }

        video->vol = (Vol **) oscl_malloc(nLayers * sizeof(Vol *));
#endif
 if (video->vol == NULL) status = PV_FALSE;
        video->memoryUsage += nLayers * sizeof(Vol *);


 /* we need to setup this pointer for the application to */
 /*    pass it around.                                   */
        decCtrl->videoDecoderData = (void *) video;
        video->videoDecControls = decCtrl; /* yes. we have a cyclic */
 /* references here :)    */

 /* Allocating Vop space, this has to change when we add */
 /*    spatial scalability to the decoder                */
#ifdef DEC_INTERNAL_MEMORY_OPT
        video->currVop = IMEM_currVop;
 if (video->currVop == NULL) status = PV_FALSE;
 else oscl_memset(video->currVop, 0, sizeof(Vop));
        video->prevVop = IMEM_prevVop;
 if (video->prevVop == NULL) status = PV_FALSE;
 else oscl_memset(video->prevVop, 0, sizeof(Vop));
        video->memoryUsage += (sizeof(Vop) * 2);
        video->vopHeader = (Vop **) IMEM_vopHEADER;
#else

        video->currVop = (Vop *) oscl_malloc(sizeof(Vop));
 if (video->currVop == NULL) status = PV_FALSE;
 else oscl_memset(video->currVop, 0, sizeof(Vop));
        video->prevVop = (Vop *) oscl_malloc(sizeof(Vop));
 if (video->prevVop == NULL) status = PV_FALSE;
 else oscl_memset(video->prevVop, 0, sizeof(Vop));
        video->memoryUsage += (sizeof(Vop) * 2);

 if ((size_t)nLayers > SIZE_MAX / sizeof(Vop *)) {
            status = PV_FALSE;
 goto fail;
 }

        video->vopHeader = (Vop **) oscl_malloc(sizeof(Vop *) * nLayers);
#endif
 if (video->vopHeader == NULL) status = PV_FALSE;
 else oscl_memset(video->vopHeader, 0, sizeof(Vop *)*nLayers);
        video->memoryUsage += (sizeof(Vop *) * nLayers);

        video->initialized = PV_FALSE;
 /* Decode the header to get all information to allocate data */
 if (status == PV_TRUE)
 {
 /* initialize decoded frame counter.   04/24/2001 */
            video->frame_idx = -1;


 for (idx = 0; idx < nLayers; idx++)
 {

#ifdef DEC_INTERNAL_MEMORY_OPT
                video->vopHeader[idx] = IMEM_vopHeader[idx];
#else
                video->vopHeader[idx] = (Vop *) oscl_malloc(sizeof(Vop));
#endif
 if (video->vopHeader[idx] == NULL)
 {
                    status = PV_FALSE;
 break;
 }
 else
 {
                    oscl_memset(video->vopHeader[idx], 0, sizeof(Vop));
                    video->vopHeader[idx]->timeStamp = 0;
                    video->memoryUsage += (sizeof(Vop));
 }
#ifdef DEC_INTERNAL_MEMORY_OPT
                video->vol[idx] = IMEM_vol[idx];
                video->memoryUsage += sizeof(Vol);
                oscl_memset(video->vol[idx], 0, sizeof(Vol));
 if (video->vol[idx] == NULL) status = PV_FALSE;
                stream = IMEM_BitstreamDecVideo;
#else
                video->vol[idx] = (Vol *) oscl_malloc(sizeof(Vol));
 if (video->vol[idx] == NULL)
 {
                    status = PV_FALSE;
 break;
 }
 else
 {
                    video->memoryUsage += sizeof(Vol);
                    oscl_memset(video->vol[idx], 0, sizeof(Vol));
 }

                stream = (BitstreamDecVideo *) oscl_malloc(sizeof(BitstreamDecVideo));
#endif
                video->memoryUsage += sizeof(BitstreamDecVideo);
 if (stream == NULL)
 {
                    status = PV_FALSE;
 break;
 }
 else
 {
 int32 buffer_size;
 if ((buffer_size = BitstreamOpen(stream, idx)) < 0)
 {
                        mp4dec_log("InitVideoDecoder(): Can't allocate bitstream buffer.\n");
                        status = PV_FALSE;
 break;
 }
                    video->memoryUsage += buffer_size;
                    video->vol[idx]->bitstream = stream;
                    video->vol[idx]->volID = idx;
                    video->vol[idx]->timeInc_offset = 0; /*  11/12/01 */
                    video->vlcDecCoeffIntra = &VlcDecTCOEFShortHeader;
                    video->vlcDecCoeffInter = &VlcDecTCOEFShortHeader;
 if (mode == MPEG4_MODE)
 {
 /* Set up VOL header bitstream for frame-based decoding.  08/30/2000 */
 BitstreamReset(stream, decCtrl->volbuf[idx], decCtrl->volbuf_size[idx]);

 switch (DecodeVOLHeader(video, idx))
 {
 case PV_SUCCESS :
 if (status == PV_TRUE)
                                    status = PV_TRUE; /*  we want to make sure that if first layer is bad, second layer is good return PV_FAIL */
 else
                                    status = PV_FALSE;
 break;
#ifdef PV_TOLERATE_VOL_ERRORS
 case PV_BAD_VOLHEADER:
                                status = PV_TRUE;
 break;
#endif
 default :
                                status = PV_FALSE;
 break;
 }

 }
 else
 {
                        video->shortVideoHeader = PV_TRUE;
 }

 if (video->shortVideoHeader == PV_TRUE)
 {
                        mode = H263_MODE;
 /* Set max width and height.  In H.263 mode, we use    */
 /*  volbuf_size[0] to pass in width and volbuf_size[1] */
 /*  to pass in height.                    04/23/2001 */
                        video->prevVop->temporalRef = 0; /*  11/12/01 */
 /* Compute some convenience variables:   04/23/2001 */
                        video->vol[idx]->quantType = 0;
                        video->vol[idx]->quantPrecision = 5;
                        video->vol[idx]->errorResDisable = 1;
                        video->vol[idx]->dataPartitioning = 0;
                        video->vol[idx]->useReverseVLC = 0;
                        video->intra_acdcPredDisable = 1;
                        video->vol[idx]->scalability = 0;

                        video->displayWidth = width;
                        video->displayHeight = height;
                        video->width = (width + 15) & -16;
                        video->height = (height + 15) & -16;
                        video->size = (int32)video->width * video->height;

#ifdef PV_ANNEX_IJKT_SUPPORT
                        video->modified_quant = 0;
                        video->advanced_INTRA = 0;
                        video->deblocking = 0;
                        video->slice_structure = 0;
#endif
 }

 }
 }

 }
 if (status != PV_FALSE)
 {
            status = PVAllocVideoData(decCtrl, width, height, nLayers);
            video->initialized = PV_TRUE;
 }
 }
 else
 {
        status = PV_FALSE;
 }

fail:
 if (status == PV_FALSE) PVCleanUpVideoDecoder(decCtrl);

 return status;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: UINT8 btif_hl_num_dchs_in_use(UINT8 mcl_handle){

 btif_hl_app_cb_t * p_acb;
 btif_hl_mcl_cb_t *p_mcb;
    UINT8               i,j,x;
    UINT8               cnt=0;

 for (i=0; i<BTA_HL_NUM_APPS; i++)
 {
        BTIF_TRACE_DEBUG("btif_hl_num_dchs:i = %d",i);
        p_acb =BTIF_HL_GET_APP_CB_PTR(i);
 if (p_acb && p_acb->in_use)
 {
 for (j=0; j < BTA_HL_NUM_MCLS ; j++)
 {
 if(p_acb->mcb[j].in_use)
                    BTIF_TRACE_DEBUG("btif_hl_num_dchs:mcb in use j=%d, mcl_handle=%d,mcb handle=%d",
                                        j,mcl_handle, p_acb->mcb[j].mcl_handle);
 if (p_acb->mcb[j].in_use &&
 (p_acb->mcb[j].mcl_handle == mcl_handle))
 {
                    p_mcb = &p_acb->mcb[j];
                    BTIF_TRACE_DEBUG("btif_hl_num_dchs: mcl handle found j =%d",j);
 for (x=0; x < BTA_HL_NUM_MDLS_PER_MCL ; x ++)
 {
 if (p_mcb->mdl[x].in_use)
 {
                            BTIF_TRACE_DEBUG("btif_hl_num_dchs_in_use:found x =%d",x);
                            cnt++;
 }
 }
 }
 }
 }
 }

    BTIF_TRACE_DEBUG("%s dch in use count=%d", __FUNCTION__, cnt);
 return cnt;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_read(png_structp ppIn, png_bytep pb, png_size_t st)
{
   png_const_structp pp = ppIn;
   png_store *ps = voidcast(png_store*, png_get_io_ptr(pp));

 if (ps == NULL || ps->pread != pp)
      png_error(pp, "bad store read call");

   store_read_imp(ps, pb, st);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_hl_clean_mdl_cb(btif_hl_mdl_cb_t *p_dcb)
{
    BTIF_TRACE_DEBUG("%s", __FUNCTION__ );
    btif_hl_free_buf((void **) &p_dcb->p_rx_pkt);
    btif_hl_free_buf((void **) &p_dcb->p_tx_pkt);
    memset(p_dcb, 0 , sizeof(btif_hl_mdl_cb_t));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ID3::Iterator::getstring(String8 *id, bool otherdata) const {
    id->setTo("");

 const uint8_t *frameData = mFrameData;
 if (frameData == NULL) {
 return;
 }

 uint8_t encoding = *frameData;

 if (mParent.mVersion == ID3_V1 || mParent.mVersion == ID3_V1_1) {
 if (mOffset == 126 || mOffset == 127) {
 char tmp[16];
            sprintf(tmp, "%d", (int)*frameData);

            id->setTo(tmp);
 return;
 }

        id->setTo((const char*)frameData, mFrameSize);
 return;
 }

 if (mFrameSize < getHeaderLength() + 1) {
 return;
 }
 size_t n = mFrameSize - getHeaderLength() - 1;
 if (otherdata) {
        frameData += 4;
 int32_t i = n - 4;
 while(--i >= 0 && *++frameData != 0) ;
 int skipped = (frameData - mFrameData);
 if (skipped >= (int)n) {
 return;
 }

         n -= skipped;
     }
 
     if (encoding == 0x00) {
         id->setTo((const char*)frameData + 1, n);
 } else if (encoding == 0x03) {
        id->setTo((const char *)(frameData + 1), n);
 } else if (encoding == 0x02) {
 int len = n / 2;

         const char16_t *framedata = (const char16_t *) (frameData + 1);
         char16_t *framedatacopy = NULL;
 #if BYTE_ORDER == LITTLE_ENDIAN
        framedatacopy = new char16_t[len];
        for (int i = 0; i < len; i++) {
            framedatacopy[i] = bswap_16(framedata[i]);
         }
        framedata = framedatacopy;
 #endif
         id->setTo(framedata, len);
         if (framedatacopy != NULL) {
 delete[] framedatacopy;
 }
 } else if (encoding == 0x01) {
 int len = n / 2;

         const char16_t *framedata = (const char16_t *) (frameData + 1);
         char16_t *framedatacopy = NULL;
         if (*framedata == 0xfffe) {
            framedatacopy = new char16_t[len];
             for (int i = 0; i < len; i++) {
                 framedatacopy[i] = bswap_16(framedata[i]);
             }
             framedata = framedatacopy;
        }
        if (*framedata == 0xfeff) {
             framedata++;
             len--;
         }

 bool eightBit = true;
 for (int i = 0; i < len; i++) {
 if (framedata[i] > 0xff) {
                eightBit = false;
 break;
 }

         }
         if (eightBit) {
            char *frame8 = new char[len];
            for (int i = 0; i < len; i++) {
                frame8[i] = framedata[i];
             }
            id->setTo(frame8, len);
            delete [] frame8;
         } else {
             id->setTo(framedata, len);
         }

 if (framedatacopy != NULL) {
 delete[] framedatacopy;
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: UWORD32 ih264d_unpack_coeff4x4_8x8blk(dec_struct_t * ps_dec,
 dec_mb_info_t * ps_cur_mb_info,
                                   UWORD16 ui2_luma_csbp,
                                   WORD16 *pi2_out_coeff_data)
{
    UWORD8 *pu1_inv_scan;
    UWORD8 u1_mb_field_decoding_flag = ps_cur_mb_info->u1_mb_field_decodingflag;
    UWORD8 u1_field_coding_flag = ps_cur_mb_info->ps_curmb->u1_mb_fld;
    UWORD32 u4_luma_dc_only_csbp = 0;
    WORD32 dc_only_flag = 0;

    PROFILE_DISABLE_UNPACK_LUMA()
 if(u1_field_coding_flag || u1_mb_field_decoding_flag)
 {
        pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan_fld;
 }
 else
 {
        pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }

 if(ui2_luma_csbp & 0x1)
 {
        memset(pi2_out_coeff_data,0,16*sizeof(WORD16));
        dc_only_flag = ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);

        INSERT_BIT(u4_luma_dc_only_csbp, 0, dc_only_flag);
 }

    pi2_out_coeff_data += 16;
 if(ui2_luma_csbp & 0x2)
 {
        memset(pi2_out_coeff_data,0,16*sizeof(WORD16));
        dc_only_flag = ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
        INSERT_BIT(u4_luma_dc_only_csbp, 1, dc_only_flag);
 }

    pi2_out_coeff_data += 16 + 32;
 if(ui2_luma_csbp & 0x10)
 {
        memset(pi2_out_coeff_data,0,16*sizeof(WORD16));
        dc_only_flag = ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
        INSERT_BIT(u4_luma_dc_only_csbp, 4, dc_only_flag);
 }

    pi2_out_coeff_data += 16;
 if(ui2_luma_csbp & 0x20)
 {
        memset(pi2_out_coeff_data,0,16*sizeof(WORD16));
        dc_only_flag = ih264d_unpack_coeff4x4_4x4blk(ps_dec,
                                      pi2_out_coeff_data,
                                      pu1_inv_scan);
        INSERT_BIT(u4_luma_dc_only_csbp, 5, dc_only_flag);
 }
 return u4_luma_dc_only_csbp;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::free_buffer(OMX_IN OMX_HANDLETYPE         hComp,
        OMX_IN OMX_U32                 port,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned int nPortIndex;
 (void) hComp;
    DEBUG_PRINT_LOW("In for decoder free_buffer");

 if (m_state == OMX_StateIdle &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
        DEBUG_PRINT_LOW(" free buffer while Component in Loading pending");
 } else if ((m_inp_bEnabled == OMX_FALSE && port == OMX_CORE_INPUT_PORT_INDEX)||
 (m_out_bEnabled == OMX_FALSE && port == OMX_CORE_OUTPUT_PORT_INDEX)) {
        DEBUG_PRINT_LOW("Free Buffer while port %u disabled", (unsigned int)port);
 } else if ((port == OMX_CORE_INPUT_PORT_INDEX &&
                BITMASK_PRESENT(&m_flags, OMX_COMPONENT_INPUT_ENABLE_PENDING)) ||
 (port == OMX_CORE_OUTPUT_PORT_INDEX &&
             BITMASK_PRESENT(&m_flags, OMX_COMPONENT_OUTPUT_ENABLE_PENDING))) {
        DEBUG_PRINT_LOW("Free Buffer while port %u enable pending", (unsigned int)port);
 } else if (m_state == OMX_StateExecuting || m_state == OMX_StatePause) {
        DEBUG_PRINT_ERROR("Invalid state to free buffer,ports need to be disabled");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);

 return OMX_ErrorIncorrectStateOperation;
 } else if (m_state != OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("Invalid state to free buffer,port lost Buffers");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);
 }

 if (port == OMX_CORE_INPUT_PORT_INDEX) {
 /*Check if arbitrary bytes*/
 if (!arbitrary_bytes && !input_use_buffer)
            nPortIndex = buffer - m_inp_mem_ptr;
 else
            nPortIndex = buffer - m_inp_heap_ptr;

        DEBUG_PRINT_LOW("free_buffer on i/p port - Port idx %d", nPortIndex);
 if (nPortIndex < drv_ctx.ip_buf.actualcount &&
                BITMASK_PRESENT(&m_inp_bm_count, nPortIndex)) {
            BITMASK_CLEAR(&m_inp_bm_count,nPortIndex);
            BITMASK_CLEAR(&m_heap_inp_bm_count,nPortIndex);
 if (input_use_buffer == true) {

                DEBUG_PRINT_LOW("Free pmem Buffer index %d",nPortIndex);
 if (m_phdr_pmem_ptr)
                    free_input_buffer(m_phdr_pmem_ptr[nPortIndex]);
 } else {
 if (arbitrary_bytes) {
 if (m_phdr_pmem_ptr)
                        free_input_buffer(nPortIndex,m_phdr_pmem_ptr[nPortIndex]);
 else
                        free_input_buffer(nPortIndex,NULL);
 } else
                    free_input_buffer(buffer);
 }
            m_inp_bPopulated = OMX_FALSE;
 if(release_input_done())
                release_buffers(this, VDEC_BUFFER_TYPE_INPUT);
 /*Free the Buffer Header*/
 if (release_input_done()) {
                DEBUG_PRINT_HIGH("ALL input buffers are freed/released");
                free_input_buffer_header();
 }
 } else {
            DEBUG_PRINT_ERROR("Error: free_buffer ,Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }

 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING)
 && release_input_done()) {
            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING);
            post_event(OMX_CommandPortDisable,
                    OMX_CORE_INPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 } else if (port == OMX_CORE_OUTPUT_PORT_INDEX) {
        nPortIndex = buffer - client_buffers.get_il_buf_hdr();
 if (nPortIndex < drv_ctx.op_buf.actualcount &&
                BITMASK_PRESENT(&m_out_bm_count, nPortIndex)) {
            DEBUG_PRINT_LOW("free_buffer on o/p port - Port idx %d", nPortIndex);
            BITMASK_CLEAR(&m_out_bm_count,nPortIndex);
            m_out_bPopulated = OMX_FALSE;
            client_buffers.free_output_buffer (buffer);

 if(release_output_done()) {
                release_buffers(this, VDEC_BUFFER_TYPE_OUTPUT);
 }
 if (release_output_done()) {
                free_output_buffer_header();
 }
 } else {
            DEBUG_PRINT_ERROR("Error: free_buffer , Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }
 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING)
 && release_output_done()) {
            DEBUG_PRINT_LOW("FreeBuffer : If any Disable event pending,post it");

            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING);
#ifdef _ANDROID_ICS_
 if (m_enable_android_native_buffers) {
                DEBUG_PRINT_LOW("FreeBuffer - outport disabled: reset native buffers");
                memset(&native_buffer, 0 ,(sizeof(struct nativebuffer) * MAX_NUM_INPUT_OUTPUT_BUFFERS));
 }
#endif

            post_event(OMX_CommandPortDisable,
                    OMX_CORE_OUTPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 } else {
        eRet = OMX_ErrorBadPortIndex;
 }
 if ((eRet == OMX_ErrorNone) &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
 if (release_done()) {
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_LOADING_PENDING);
            post_event(OMX_CommandStateSet, OMX_StateLoaded,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: </s>


Instruction: 
Input: int Chapters::GetEditionCount() const { return m_editions_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_ltrmode(OMX_U32 enable, OMX_U32 count)
{
    DEBUG_PRINT_LOW("venc_set_ltrmode: enable = %u", (unsigned int)enable);
 struct v4l2_control control;
 struct v4l2_ext_control ctrl[2];
 struct v4l2_ext_controls controls;
 int rc;

 if (!venc_validate_hybridhp_params(0, 0, count, 0)) {
        DEBUG_PRINT_ERROR("Invalid settings, LTR enabled with HybridHP");
 return false;
 }

    ctrl[0].id = V4L2_CID_MPEG_VIDC_VIDEO_LTRMODE;
 if (enable)
        ctrl[0].value = V4L2_MPEG_VIDC_VIDEO_LTR_MODE_MANUAL;
 else
        ctrl[0].value = V4L2_MPEG_VIDC_VIDEO_LTR_MODE_DISABLE;

    ctrl[1].id = V4L2_CID_MPEG_VIDC_VIDEO_LTRCOUNT;
 if (enable && count > 0)
        ctrl[1].value = count;
 else if (enable)
        ctrl[1].value = 1;
 else
        ctrl[1].value = 0;

    controls.count = 2;
    controls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
    controls.controls = ctrl;

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%x, val=%d id=%x, val=%d",
                    controls.controls[0].id, controls.controls[0].value,
                    controls.controls[1].id, controls.controls[1].value);

    rc = ioctl(m_nDriver_fd, VIDIOC_S_EXT_CTRLS, &controls);
 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set ltrmode %d", rc);
 return false;
 }
    ltrinfo.enabled = enable;
    ltrinfo.count = count;

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%x, val=%d id=%x, val=%d",
                    controls.controls[0].id, controls.controls[0].value,
                    controls.controls[1].id, controls.controls[1].value);

    control.id = V4L2_CID_MPEG_VIDC_VIDEO_EXTRADATA;
    control.value = V4L2_MPEG_VIDC_EXTRADATA_LTR;

 if (ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control)) {
        DEBUG_PRINT_ERROR("ERROR: Request for setting extradata failed");
 return false;
 }

 if (!venc_set_profile_level(0, 0)) {
        DEBUG_PRINT_ERROR("ERROR: %s(): Driver Profile/Level is NOT SET",
                __func__);
 } else {
        DEBUG_PRINT_HIGH("%s(): Driver Profile[%lu]/Level[%lu] successfully SET",
                __func__, codec_profile.profile, profile_level.level);
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraClient::handlePreviewData(int32_t msgType,
 const sp<IMemory>& mem,
 camera_frame_metadata_t *metadata) {
 ssize_t offset;
 size_t size;
    sp<IMemoryHeap> heap = mem->getMemory(&offset, &size);

 int flags = mPreviewCallbackFlag;

 if (!(flags & CAMERA_FRAME_CALLBACK_FLAG_ENABLE_MASK)) {
        LOG2("frame callback is disabled");
        mLock.unlock();
 return;
 }

    sp<ICameraClient> c = mRemoteCallback;

 if (c == 0 || (mPreviewCallbackFlag & CAMERA_FRAME_CALLBACK_FLAG_ONE_SHOT_MASK)) {
        LOG2("Disable preview callback");
        mPreviewCallbackFlag &= ~(CAMERA_FRAME_CALLBACK_FLAG_ONE_SHOT_MASK |
                                  CAMERA_FRAME_CALLBACK_FLAG_COPY_OUT_MASK |
                                  CAMERA_FRAME_CALLBACK_FLAG_ENABLE_MASK);
        disableMsgType(CAMERA_MSG_PREVIEW_FRAME);
 }

 if (c != 0) {
 if (flags & CAMERA_FRAME_CALLBACK_FLAG_COPY_OUT_MASK) {
            LOG2("frame is copied");
            copyFrameAndPostCopiedFrame(msgType, c, heap, offset, size, metadata);
 } else {
            LOG2("frame is forwarded");
            mLock.unlock();
            c->dataCallback(msgType, mem, metadata);
 }
 } else {
        mLock.unlock();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_video::empty_buffer_done(OMX_HANDLETYPE         hComp,
        OMX_BUFFERHEADERTYPE* buffer)
{
 int buffer_index  = -1;

    buffer_index = buffer - ((mUseProxyColorFormat && !mUsesColorConversion) ? meta_buffer_hdr : m_inp_mem_ptr);
    DEBUG_PRINT_LOW("empty_buffer_done: buffer[%p]", buffer);
 if (buffer == NULL ||
 ((buffer_index > (int)m_sInPortDef.nBufferCountActual))) {
        DEBUG_PRINT_ERROR("ERROR in empty_buffer_done due to index buffer");
 return OMX_ErrorBadParameter;
 }

    pending_input_buffers--;

 if (mUseProxyColorFormat &&
 (buffer_index >= 0 && (buffer_index < (int)m_sInPortDef.nBufferCountActual))) {
 if (!pdest_frame  && !input_flush_progress && mUsesColorConversion) {
            pdest_frame = buffer;
            DEBUG_PRINT_LOW("empty_buffer_done pdest_frame address is %p",pdest_frame);
 return push_input_buffer(hComp);
 }
 bool handleEmptyEosBuffer = (mEmptyEosBuffer == buffer);
 if (mUsesColorConversion || handleEmptyEosBuffer) {
 if (handleEmptyEosBuffer) {
                mEmptyEosBuffer = NULL;
 }
            DEBUG_PRINT_LOW("empty_buffer_done insert address is %p",buffer);
 if (!m_opq_pmem_q.insert_entry((unsigned long)buffer, 0, 0)) {
                DEBUG_PRINT_ERROR("empty_buffer_done: pmem queue is full");
 return OMX_ErrorBadParameter;
 }
 } else {
 if (m_pCallbacks.EmptyBufferDone && buffer) {
                m_pCallbacks.EmptyBufferDone(hComp, m_app_data, buffer);
                DEBUG_PRINT_LOW("empty_buffer_done: Returning client buf %p", buffer);
 }
 }
 } else if (m_pCallbacks.EmptyBufferDone) {
        m_pCallbacks.EmptyBufferDone(hComp ,m_app_data, buffer);
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::GetIndex() const
{
    return m_index;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  explicit SlowSloppyArgumentsElementsAccessor(const char* name)
 : SloppyArgumentsElementsAccessor<
 SlowSloppyArgumentsElementsAccessor, DictionaryElementsAccessor,
 ElementsKindTraits<SLOW_SLOPPY_ARGUMENTS_ELEMENTS> >(name) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAACEncoder::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = kNumSamplesPerFrame * sizeof(int16_t) * 2;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 8192;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/aac");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingAAC;

    addPort(def);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int venc_dev::venc_input_log_buffers(OMX_BUFFERHEADERTYPE *pbuffer, int fd, int plane_offset) {
     if (!m_debug.infile) {
         int size = snprintf(m_debug.infile_name, PROPERTY_VALUE_MAX, "%s/input_enc_%lu_%lu_%p.yuv",
                             m_debug.log_loc, m_sVenc_cfg.input_width, m_sVenc_cfg.input_height, this);
 if ((size > PROPERTY_VALUE_MAX) && (size < 0)) {
             DEBUG_PRINT_ERROR("Failed to open output file: %s for logging size:%d",
                                m_debug.infile_name, size);
 }
        m_debug.infile = fopen (m_debug.infile_name, "ab");
 if (!m_debug.infile) {
            DEBUG_PRINT_HIGH("Failed to open input file: %s for logging", m_debug.infile_name);
            m_debug.infile_name[0] = '\0';
 return -1;
 }
 }
 if (m_debug.infile && pbuffer && pbuffer->nFilledLen) {
 unsigned long i, msize;
 int stride = VENUS_Y_STRIDE(COLOR_FMT_NV12, m_sVenc_cfg.input_width);
 int scanlines = VENUS_Y_SCANLINES(COLOR_FMT_NV12, m_sVenc_cfg.input_height);
 unsigned char *pvirt,*ptemp;

 char *temp = (char *)pbuffer->pBuffer;

        msize = VENUS_BUFFER_SIZE(COLOR_FMT_NV12, m_sVenc_cfg.input_width, m_sVenc_cfg.input_height);
 if (metadatamode == 1) {
            pvirt= (unsigned char *)mmap(NULL, msize, PROT_READ|PROT_WRITE,MAP_SHARED, fd, plane_offset);
 if (pvirt) {
               ptemp = pvirt;
 for (i = 0; i < m_sVenc_cfg.input_height; i++) {
                    fwrite(ptemp, m_sVenc_cfg.input_width, 1, m_debug.infile);
                    ptemp += stride;
 }
               ptemp = pvirt + (stride * scanlines);
 for(i = 0; i < m_sVenc_cfg.input_height/2; i++) {
                   fwrite(ptemp, m_sVenc_cfg.input_width, 1, m_debug.infile);
                   ptemp += stride;
 }
               munmap(pvirt, msize);
 } else if (pvirt == MAP_FAILED) {
                 DEBUG_PRINT_ERROR("%s mmap failed", __func__);
 return -1;
 }
 } else {
 for (i = 0; i < m_sVenc_cfg.input_height; i++) {
                 fwrite(temp, m_sVenc_cfg.input_width, 1, m_debug.infile);
                 temp += stride;
 }

            temp = (char *)pbuffer->pBuffer + (stride * scanlines);

 for(i = 0; i < m_sVenc_cfg.input_height/2; i++) {
                fwrite(temp, m_sVenc_cfg.input_width, 1, m_debug.infile);
                temp += stride;
 }
 }
 }
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: issueLocalRequest(int request, void *data, int len, RIL_SOCKET_ID socket_id) {
 RequestInfo *pRI;
 int ret;
 /* Hook for current context */
 /* pendingRequestsMutextHook refer to &s_pendingRequestsMutex */
 pthread_mutex_t* pendingRequestsMutexHook = &s_pendingRequestsMutex;
 /* pendingRequestsHook refer to &s_pendingRequests */
 RequestInfo**    pendingRequestsHook = &s_pendingRequests;

#if (SIM_COUNT == 2)
 if (socket_id == RIL_SOCKET_2) {
        pendingRequestsMutexHook = &s_pendingRequestsMutex_socket2;
        pendingRequestsHook = &s_pendingRequests_socket2;
 }
#endif

    pRI = (RequestInfo *)calloc(1, sizeof(RequestInfo));
 if (pRI == NULL) {
        RLOGE("Memory allocation failed for request %s", requestToString(request));
 return;
 }

    pRI->local = 1;
    pRI->token = 0xffffffff; // token is not used in this context
    pRI->pCI = &(s_commands[request]);
    pRI->socket_id = socket_id;

    ret = pthread_mutex_lock(pendingRequestsMutexHook);
    assert (ret == 0);

    pRI->p_next = *pendingRequestsHook;
 *pendingRequestsHook = pRI;

    ret = pthread_mutex_unlock(pendingRequestsMutexHook);
    assert (ret == 0);

    RLOGD("C[locl]> %s", requestToString(request));

    CALL_ONREQUEST(request, data, len, pRI, pRI->socket_id);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: namePop(xmlParserCtxtPtr ctxt)
{
 const xmlChar *ret;

 if ((ctxt == NULL) || (ctxt->nameNr <= 0))
 return (NULL);
    ctxt->nameNr--;
 if (ctxt->nameNr > 0)
        ctxt->name = ctxt->nameTab[ctxt->nameNr - 1];
 else
        ctxt->name = NULL;
    ret = ctxt->nameTab[ctxt->nameNr];
    ctxt->nameTab[ctxt->nameNr] = NULL;
 return (ret);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void Region_destructor(JNIEnv* env, jobject, jlong regionHandle) {
 SkRegion* region = reinterpret_cast<SkRegion*>(regionHandle);
 SkASSERT(region);
 delete region;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool mkvparser::Match(IMkvReader* pReader, long long& pos, unsigned long id_,
                      long long& val) {
  assert(pReader);
  assert(pos >= 0);
  long long total, available;
  const long status = pReader->Length(&total, &available);
  assert(status >= 0);
  assert((total < 0) || (available <= total));
  if (status < 0)
     return false;
 
  long len;
 
  const long long id = ReadUInt(pReader, pos, len);
  assert(id >= 0);
  assert(len > 0);
  assert(len <= 8);
  assert((pos + len) <= available);
 
  if ((unsigned long)id != id_)
     return false;
 
   pos += len;  // consume id
 
   const long long size = ReadUInt(pReader, pos, len);
  assert(size >= 0);
  assert(size <= 8);
  assert(len > 0);
  assert(len <= 8);
  assert((pos + len) <= available);
 
   pos += len;  // consume length of size of payload
 
   val = UnserializeUInt(pReader, pos, size);
  assert(val >= 0);
 
   pos += size;  // consume size of payload
 
   return true;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: long long Block::GetDiscardPadding() const { return m_discard_padding; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    static void TearDownTestCase() {
    vpx_free(source_data_);
    source_data_ = NULL;
    vpx_free(reference_data_);
    reference_data_ = NULL;
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  String8 InputDispatcher::checkWindowReadyForMoreInputLocked(nsecs_t currentTime,
         const sp<InputWindowHandle>& windowHandle, const EventEntry* eventEntry,
         const char* targetType) {
 if (windowHandle->getInfo()->paused) {
 return String8::format("Waiting because the %s window is paused.", targetType);
 }

 ssize_t connectionIndex = getConnectionIndexLocked(windowHandle->getInputChannel());
 if (connectionIndex < 0) {
 return String8::format("Waiting because the %s window's input channel is not "
 "registered with the input dispatcher.  The window may be in the process "
 "of being removed.", targetType);
 }

    sp<Connection> connection = mConnectionsByFd.valueAt(connectionIndex);
 if (connection->status != Connection::STATUS_NORMAL) {
 return String8::format("Waiting because the %s window's input connection is %s."
 "The window may be in the process of being removed.", targetType,
                connection->getStatusLabel());
 }

 if (connection->inputPublisherBlocked) {
 return String8::format("Waiting because the %s window's input channel is full.  "
 "Outbound queue length: %d.  Wait queue length: %d.",
                targetType, connection->outboundQueue.count(), connection->waitQueue.count());
 }

 if (eventEntry->type == EventEntry::TYPE_KEY) {
 if (!connection->outboundQueue.isEmpty() || !connection->waitQueue.isEmpty()) {
 return String8::format("Waiting to send key event because the %s window has not "
 "finished processing all of the input events that were previously "
 "delivered to it.  Outbound queue length: %d.  Wait queue length: %d.",
                    targetType, connection->outboundQueue.count(), connection->waitQueue.count());
 }
 } else {
 if (!connection->waitQueue.isEmpty()
 && currentTime >= connection->waitQueue.head->deliveryTime
 + STREAM_AHEAD_EVENT_TIMEOUT) {
 return String8::format("Waiting to send non-key event because the %s window has not "
 "finished processing certain input events that were delivered to it over "
 "%0.1fms ago.  Wait queue length: %d.  Wait queue head age: %0.1fms.",
                    targetType, STREAM_AHEAD_EVENT_TIMEOUT * 0.000001f,
                    connection->waitQueue.count(),
 (currentTime - connection->waitQueue.head->deliveryTime) * 0.000001f);
 }
 }
 return String8::empty();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXCodec::parseAVCCodecSpecificData(
 const void *data, size_t size,
 unsigned *profile, unsigned *level) {
 const uint8_t *ptr = (const uint8_t *)data;

 if (size < 7 || ptr[0] != 1) {
 return ERROR_MALFORMED;
 }

 *profile = ptr[1];
 *level = ptr[3];


 size_t lengthSize __unused = 1 + (ptr[4] & 3);


 size_t numSeqParameterSets = ptr[5] & 31;

    ptr += 6;
    size -= 6;

 for (size_t i = 0; i < numSeqParameterSets; ++i) {
 if (size < 2) {
 return ERROR_MALFORMED;
 }

 size_t length = U16_AT(ptr);

        ptr += 2;
        size -= 2;

 if (size < length) {
 return ERROR_MALFORMED;
 }

        addCodecSpecificData(ptr, length);

        ptr += length;
        size -= length;
 }

 if (size < 1) {
 return ERROR_MALFORMED;
 }

 size_t numPictureParameterSets = *ptr;
 ++ptr;
 --size;

 for (size_t i = 0; i < numPictureParameterSets; ++i) {
 if (size < 2) {
 return ERROR_MALFORMED;
 }

 size_t length = U16_AT(ptr);

        ptr += 2;
        size -= 2;

 if (size < length) {
 return ERROR_MALFORMED;
 }

        addCodecSpecificData(ptr, length);

        ptr += length;
        size -= length;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static EAS_RESULT Parse_wave (SDLS_SYNTHESIZER_DATA *pDLSData, EAS_I32 pos, EAS_U16 waveIndex)
{
    EAS_RESULT result;
    EAS_U32 temp;
    EAS_I32 size;
    EAS_I32 endChunk;
    EAS_I32 chunkPos;
    EAS_I32 wsmpPos = 0;
    EAS_I32 fmtPos = 0;
    EAS_I32 dataPos = 0;
    EAS_I32 dataSize = 0;
    S_WSMP_DATA *p;
 void *pSample;
    S_WSMP_DATA wsmp;

 /* seek to start of chunk */
    chunkPos = pos + 12;
 if ((result = EAS_HWFileSeek(pDLSData->hwInstData, pDLSData->fileHandle, pos)) != EAS_SUCCESS)
 return result;

 /* get the chunk type */
 if ((result = NextChunk(pDLSData, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 /* make sure it is a wave chunk */
 if (temp != CHUNK_WAVE)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "Offset in ptbl does not point to wave chunk\n"); */ }
 return EAS_ERROR_FILE_FORMAT;
 }

 /* read to end of chunk */
    pos = chunkPos;
    endChunk = pos + size;
 while (pos < endChunk)
 {
        chunkPos = pos;

 /* get the chunk type */
 if ((result = NextChunk(pDLSData, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 /* parse useful chunks */
 switch (temp)
 {
 case CHUNK_WSMP:
                wsmpPos = chunkPos + 8;
 break;

 case CHUNK_FMT:
                fmtPos = chunkPos + 8;
 break;

 case CHUNK_DATA:
                dataPos = chunkPos + 8;
                dataSize = size;
 break;

 default:
 break;
 }
 }

 if (dataSize < 0 || dataSize > MAX_DLS_WAVE_SIZE)
 {
 return EAS_ERROR_SOUND_LIBRARY;
 }

 /* for first pass, use temporary variable */
 if (pDLSData->pDLS == NULL)
        p = &wsmp;
 else
        p = &pDLSData->wsmpData[waveIndex];

 /* set the defaults */
    p->fineTune = 0;
    p->unityNote = 60;
    p->gain = 0;
    p->loopStart = 0;
    p->loopLength = 0;

 /* must have a fmt chunk */
 if (!fmtPos)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS wave chunk has no fmt chunk\n"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* must have a data chunk */
 if (!dataPos)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS wave chunk has no data chunk\n"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* parse the wsmp chunk */
 if (wsmpPos)
 {
 if ((result = Parse_wsmp(pDLSData, wsmpPos, p)) != EAS_SUCCESS)
 return result;
 }

 /* parse the fmt chunk */
 if ((result = Parse_fmt(pDLSData, fmtPos, p)) != EAS_SUCCESS)
 return result;

 /* calculate the size of the wavetable needed. We need only half
     * the memory for 16-bit samples when in 8-bit mode, and we need
     * double the memory for 8-bit samples in 16-bit mode. For
     * unlooped samples, we may use ADPCM. If so, we need only 1/4
     * the memory.
     *
     * We also need to add one for looped samples to allow for
     * the first sample to be copied to the end of the loop.
     */

 /* use ADPCM encode for unlooped 16-bit samples if ADPCM is enabled */
 /*lint -e{506} -e{774} groundwork for future version to support 8 & 16 bit */
 if (bitDepth == 8)
 {
 if (p->bitsPerSample == 8)
            size = dataSize;
 else
 /*lint -e{704} use shift for performance */
            size = dataSize >> 1;
 if (p->loopLength)
            size++;
 }

 else
 {
 if (p->bitsPerSample == 16)
            size = dataSize;
 else
 /*lint -e{703} use shift for performance */
            size = dataSize << 1;
 if (p->loopLength)
            size += 2;
 }

 /* for first pass, add size to wave pool size and return */
 if (pDLSData->pDLS == NULL)
 {
        pDLSData->wavePoolSize += (EAS_U32) size;
 return EAS_SUCCESS;
 }

 /* allocate memory and read in the sample data */
    pSample = (EAS_U8*)pDLSData->pDLS->pDLSSamples + pDLSData->wavePoolOffset;
    pDLSData->pDLS->pDLSSampleOffsets[waveIndex] = pDLSData->wavePoolOffset;
    pDLSData->pDLS->pDLSSampleLen[waveIndex] = (EAS_U32) size;
    pDLSData->wavePoolOffset += (EAS_U32) size;
 if (pDLSData->wavePoolOffset > pDLSData->wavePoolSize)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "Wave pool exceeded allocation\n"); */ }
 return EAS_ERROR_SOUND_LIBRARY;
 }

 if ((result = Parse_data(pDLSData, dataPos, dataSize, p, pSample, (EAS_U32)size)) != EAS_SUCCESS)
 return result;

 return EAS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::doPokeUserActivityLockedInterruptible(CommandEntry* commandEntry) {
    mLock.unlock();

    mPolicy->pokeUserActivity(commandEntry->eventTime, commandEntry->userActivityEventType);

    mLock.lock();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static entry_t *entry_new(const char *key, const char *value) {
 entry_t *entry = osi_calloc(sizeof(entry_t));
 if (!entry)
 return NULL;

  entry->key = osi_strdup(key);
  entry->value = osi_strdup(value);
 return entry;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void stopRecording()
 {
        ALOGV("stopRecording");
 Parcel data, reply;
        data.writeInterfaceToken(ICameraRecordingProxy::getInterfaceDescriptor());
        remote()->transact(STOP_RECORDING, data, &reply);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void BTM_PasskeyReqReply(tBTM_STATUS res, BD_ADDR bd_addr, UINT32 passkey)
{
    tBTM_SEC_DEV_REC *p_dev_rec;

    BTM_TRACE_API ("BTM_PasskeyReqReply: State: %s  res:%d",
                    btm_pair_state_descr(btm_cb.pairing_state), res);

 if ( (btm_cb.pairing_state == BTM_PAIR_STATE_IDLE)
 || (memcmp (btm_cb.pairing_bda, bd_addr, BD_ADDR_LEN) != 0) )
 {
 return;
 }

 /* If timeout already expired or has been canceled, ignore the reply */
 if ( (btm_cb.pairing_state == BTM_PAIR_STATE_WAIT_AUTH_COMPLETE) && (res != BTM_SUCCESS) )
 {
 if ((p_dev_rec = btm_find_dev (bd_addr)) != NULL)
 {
            btm_cb.acl_disc_reason = HCI_ERR_HOST_REJECT_SECURITY;

 if (p_dev_rec->hci_handle != BTM_SEC_INVALID_HANDLE)
                btm_sec_send_hci_disconnect (p_dev_rec, HCI_ERR_AUTH_FAILURE, p_dev_rec->hci_handle);
 else
                BTM_SecBondCancel(bd_addr);

            p_dev_rec->sec_flags &= ~(BTM_SEC_LINK_KEY_AUTHED | BTM_SEC_LINK_KEY_KNOWN);

            btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);
 return;
 }
 }
 else if (btm_cb.pairing_state != BTM_PAIR_STATE_KEY_ENTRY)
 return;

 if (passkey > BTM_MAX_PASSKEY_VAL)
        res = BTM_ILLEGAL_VALUE;

    btm_sec_change_pairing_state (BTM_PAIR_STATE_WAIT_AUTH_COMPLETE);

 if (res != BTM_SUCCESS)
 {
 /* use BTM_PAIR_STATE_WAIT_AUTH_COMPLETE to report authentication failed event */
        btm_cb.acl_disc_reason = HCI_ERR_HOST_REJECT_SECURITY;
        btsnd_hcic_user_passkey_neg_reply (bd_addr);
 }
 else
 {
        btm_cb.acl_disc_reason = HCI_SUCCESS;
        btsnd_hcic_user_passkey_reply (bd_addr, passkey);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int spacePush(xmlParserCtxtPtr ctxt, int val) {
 if (ctxt->spaceNr >= ctxt->spaceMax) {
 int *tmp;

	ctxt->spaceMax *= 2;
        tmp = (int *) xmlRealloc(ctxt->spaceTab,
	                         ctxt->spaceMax * sizeof(ctxt->spaceTab[0]));
 if (tmp == NULL) {
	    xmlErrMemory(ctxt, NULL);
	    ctxt->spaceMax /=2;
 return(-1);
 }
	ctxt->spaceTab = tmp;
 }
    ctxt->spaceTab[ctxt->spaceNr] = val;
    ctxt->space = &ctxt->spaceTab[ctxt->spaceNr];
 return(ctxt->spaceNr++);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void run(const char* source_path, const char* label, uid_t uid,
 gid_t gid, userid_t userid, bool multi_user, bool full_write) {
 struct fuse_global global;
 struct fuse fuse_default;
 struct fuse fuse_read;
 struct fuse fuse_write;
 struct fuse_handler handler_default;
 struct fuse_handler handler_read;
 struct fuse_handler handler_write;
 pthread_t thread_default;
 pthread_t thread_read;
 pthread_t thread_write;

    memset(&global, 0, sizeof(global));
    memset(&fuse_default, 0, sizeof(fuse_default));
    memset(&fuse_read, 0, sizeof(fuse_read));
    memset(&fuse_write, 0, sizeof(fuse_write));
    memset(&handler_default, 0, sizeof(handler_default));
    memset(&handler_read, 0, sizeof(handler_read));
    memset(&handler_write, 0, sizeof(handler_write));

    pthread_mutex_init(&global.lock, NULL);
    global.package_to_appid = hashmapCreate(256, str_hash, str_icase_equals);
    global.uid = uid;
    global.gid = gid;
    global.multi_user = multi_user;
    global.next_generation = 0;
    global.inode_ctr = 1;

    memset(&global.root, 0, sizeof(global.root));
    global.root.nid = FUSE_ROOT_ID; /* 1 */
    global.root.refcount = 2;
    global.root.namelen = strlen(source_path);
    global.root.name = strdup(source_path);
    global.root.userid = userid;
    global.root.uid = AID_ROOT;
    global.root.under_android = false;

    strcpy(global.source_path, source_path);

 if (multi_user) {
        global.root.perm = PERM_PRE_ROOT;
        snprintf(global.obb_path, sizeof(global.obb_path), "%s/obb", source_path);
 } else {
        global.root.perm = PERM_ROOT;
        snprintf(global.obb_path, sizeof(global.obb_path), "%s/Android/obb", source_path);
 }

    fuse_default.global = &global;
    fuse_read.global = &global;
    fuse_write.global = &global;

    global.fuse_default = &fuse_default;
    global.fuse_read = &fuse_read;
    global.fuse_write = &fuse_write;

    snprintf(fuse_default.dest_path, PATH_MAX, "/mnt/runtime/default/%s", label);
    snprintf(fuse_read.dest_path, PATH_MAX, "/mnt/runtime/read/%s", label);
    snprintf(fuse_write.dest_path, PATH_MAX, "/mnt/runtime/write/%s", label);

    handler_default.fuse = &fuse_default;
    handler_read.fuse = &fuse_read;
    handler_write.fuse = &fuse_write;

    handler_default.token = 0;
    handler_read.token = 1;
    handler_write.token = 2;

    umask(0);

 if (multi_user) {
 /* Multi-user storage is fully isolated per user, so "other"
         * permissions are completely masked off. */
 if (fuse_setup(&fuse_default, AID_SDCARD_RW, 0006)
 || fuse_setup(&fuse_read, AID_EVERYBODY, 0027)
 || fuse_setup(&fuse_write, AID_EVERYBODY, full_write ? 0007 : 0027)) {
            ERROR("failed to fuse_setup\n");
            exit(1);
 }
 } else {
 /* Physical storage is readable by all users on device, but
         * the Android directories are masked off to a single user
         * deep inside attr_from_stat(). */
 if (fuse_setup(&fuse_default, AID_SDCARD_RW, 0006)
 || fuse_setup(&fuse_read, AID_EVERYBODY, full_write ? 0027 : 0022)
 || fuse_setup(&fuse_write, AID_EVERYBODY, full_write ? 0007 : 0022)) {
            ERROR("failed to fuse_setup\n");
            exit(1);
 }
 }

 /* Drop privs */
 if (setgroups(sizeof(kGroups) / sizeof(kGroups[0]), kGroups) < 0) {
        ERROR("cannot setgroups: %s\n", strerror(errno));
        exit(1);
 }
 if (setgid(gid) < 0) {
        ERROR("cannot setgid: %s\n", strerror(errno));
        exit(1);
 }
 if (setuid(uid) < 0) {
        ERROR("cannot setuid: %s\n", strerror(errno));
        exit(1);
 }

 if (multi_user) {
        fs_prepare_dir(global.obb_path, 0775, uid, gid);
 }

 if (pthread_create(&thread_default, NULL, start_handler, &handler_default)
 || pthread_create(&thread_read, NULL, start_handler, &handler_read)
 || pthread_create(&thread_write, NULL, start_handler, &handler_write)) {
        ERROR("failed to pthread_create\n");
        exit(1);
 }

    watch_package_list(&global);
    ERROR("terminated prematurely\n");
    exit(1);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Camera3Device::tryLockSpinRightRound(Mutex& lock) {
 bool gotLock = false;
 for (size_t i = 0; i < kDumpLockAttempts; ++i) {
 if (lock.tryLock() == NO_ERROR) {
            gotLock = true;
 break;
 } else {
            usleep(kDumpSleepDuration);
 }
 }
 return gotLock;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t setTransformHint(uint32_t hint) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeInt32(hint);
 status_t result = remote()->transact(SET_TRANSFORM_HINT, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int fx_process(effect_handle_t     self,
 audio_buffer_t *inBuffer,
 audio_buffer_t *outBuffer)
{
 struct effect_s *effect = (struct effect_s *)self;
 struct session_s *session;

 if (effect == NULL) {
        ALOGV("fx_process() ERROR effect == NULL");
 return -EINVAL;
 }

 if (inBuffer == NULL  || inBuffer->raw == NULL  ||
            outBuffer == NULL || outBuffer->raw == NULL) {
        ALOGW("fx_process() ERROR bad pointer");
 return -EINVAL;
 }

    session = (struct session_s *)effect->session;

    session->processed_msk |= (1<<effect->id);

 if ((session->processed_msk & session->enabled_msk) == session->enabled_msk) {
        effect->session->processed_msk = 0;
 return 0;
 } else
 return -ENODATA;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Parcel::Blob::clear() {
    mFd = -1;
    mData = NULL;
    mSize = 0;
    mMutable = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gpc_b16c(Pixel *out, const Pixel *in, const Background *back)
{
 if (in->a <= 0)
 {
      out->r = back->ir;
      out->g = back->ig;
      out->b = back->ib;
 }

 else
 {
 double a = in->a/65535.;
 double a1 = 1-a;

      a /= 65535;
      out->r = sRGB(in->r * a + back->dr * a1);
      out->g = sRGB(in->g * a + back->dg * a1);
      out->b = sRGB(in->b * a + back->db * a1);
 }

   out->a = 255;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MediaRecorder::~MediaRecorder()
{
    ALOGV("destructor");
 if (mMediaRecorder != NULL) {
        mMediaRecorder.clear();
 }

 if (mSurfaceMediaSource != NULL) {
        mSurfaceMediaSource.clear();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline const char *portString(OMX_U32 portIndex) {
 switch (portIndex) {
 case kPortIndexInput: return "Input";
 case kPortIndexOutput: return "Output";
 case ~0: return "All";
 default: return "port";
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static section_t *section_new(const char *name) {
 section_t *section = osi_calloc(sizeof(section_t));
 if (!section)
 return NULL;

  section->name = osi_strdup(name);
  section->entries = list_new(entry_free);
 return section;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long ContentEncoding::ParseContentEncAESSettingsEntry(
 long long start, long long size, IMkvReader* pReader,
 ContentEncAESSettings* aes) {
  assert(pReader);
  assert(aes);

 long long pos = start;
 const long long stop = start + size;

 while (pos < stop) {
 long long id, size;
 const long status = ParseElementHeader(pReader, pos, stop, id, size);
 if (status < 0) // error
 return status;

 if (id == 0x7E8) {
      aes->cipher_mode = UnserializeUInt(pReader, pos, size);
 if (aes->cipher_mode != 1)
 return E_FILE_FORMAT_INVALID;

     }
 
     pos += size;  // consume payload
    assert(pos <= stop);
   }
 
   return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: long Chapters::Edition::ParseAtom(
    IMkvReader* pReader,
    long long pos,
    long long size)
{
    if (!ExpandAtomsArray())
        return -1;
 
    Atom& a = m_atoms[m_atoms_count++];
    a.Init();
 
    return a.Parse(pReader, pos, size);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t Camera3Device::RequestThread::queueRequestList(
 List<sp<CaptureRequest> > &requests,
 /*out*/
 int64_t *lastFrameNumber) {
 Mutex::Autolock l(mRequestLock);
 for (List<sp<CaptureRequest> >::iterator it = requests.begin(); it != requests.end();
 ++it) {
        mRequestQueue.push_back(*it);
 }

 if (lastFrameNumber != NULL) {
 *lastFrameNumber = mFrameNumber + mRequestQueue.size() - 1;
        ALOGV("%s: requestId %d, mFrameNumber %" PRId32 ", lastFrameNumber %" PRId64 ".",
              __FUNCTION__, (*(requests.begin()))->mResultExtras.requestId, mFrameNumber,
 *lastFrameNumber);
 }

    unpauseForNewRequests();

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ESDS::getCodecSpecificInfo(const void **data, size_t *size) const {
 if (mInitCheck != OK) {
 return mInitCheck;
 }

 *data = &mData[mDecoderSpecificOffset];
 *size = mDecoderSpecificLength;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  unsigned getChannels() const {
 return mStreamInfo.channels;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::push_input_sc_codec(OMX_HANDLETYPE hComp)
{
    OMX_U32 partial_frame = 1;
    OMX_BOOL generate_ebd = OMX_TRUE;
 unsigned long address = 0, p2 = 0, id = 0;

    DEBUG_PRINT_LOW("Start Parsing the bit stream address %p TimeStamp %lld",
            psource_frame,psource_frame->nTimeStamp);
 if (m_frame_parser.parse_sc_frame(psource_frame,
                pdest_frame,&partial_frame) == -1) {
        DEBUG_PRINT_ERROR("Error In Parsing Return Error");
 return OMX_ErrorBadParameter;
 }

 if (partial_frame == 0) {
        DEBUG_PRINT_LOW("Frame size %u source %p frame count %d",
 (unsigned int)pdest_frame->nFilledLen,psource_frame,frame_count);


        DEBUG_PRINT_LOW("TimeStamp updated %lld", pdest_frame->nTimeStamp);
 /*First Parsed buffer will have only header Hence skip*/
 if (frame_count == 0) {
            DEBUG_PRINT_LOW("H263/MPEG4 Codec First Frame ");

 if (codec_type_parse == CODEC_TYPE_MPEG4 ||
                    codec_type_parse == CODEC_TYPE_DIVX) {
                mp4StreamType psBits;
                psBits.data = pdest_frame->pBuffer + pdest_frame->nOffset;
                psBits.numBytes = pdest_frame->nFilledLen;
                mp4_headerparser.parseHeader(&psBits);
 }

            frame_count++;
 } else {
            pdest_frame->nFlags &= ~OMX_BUFFERFLAG_EOS;
 if (pdest_frame->nFilledLen) {
 /*Push the frame to the Decoder*/
 if (empty_this_buffer_proxy(hComp,pdest_frame) != OMX_ErrorNone) {
 return OMX_ErrorBadParameter;
 }
                frame_count++;
                pdest_frame = NULL;

 if (m_input_free_q.m_size) {
                    m_input_free_q.pop_entry(&address,&p2,&id);
                    pdest_frame = (OMX_BUFFERHEADERTYPE *) address;
                    pdest_frame->nFilledLen = 0;
 }
 } else if (!(psource_frame->nFlags & OMX_BUFFERFLAG_EOS)) {
                DEBUG_PRINT_ERROR("Zero len buffer return back to POOL");
                m_input_free_q.insert_entry((unsigned long) pdest_frame, (unsigned)NULL,
 (unsigned)NULL);
                pdest_frame = NULL;
 }
 }
 } else {
        DEBUG_PRINT_LOW("Not a Complete Frame %u", (unsigned int)pdest_frame->nFilledLen);
 /*Check if Destination Buffer is full*/
 if (pdest_frame->nAllocLen ==
                pdest_frame->nFilledLen + pdest_frame->nOffset) {
            DEBUG_PRINT_ERROR("ERROR:Frame Not found though Destination Filled");
 return OMX_ErrorStreamCorrupt;
 }
 }

 if (psource_frame->nFilledLen == 0) {
 if (psource_frame->nFlags & OMX_BUFFERFLAG_EOS) {
 if (pdest_frame) {
                pdest_frame->nFlags |= psource_frame->nFlags;
                DEBUG_PRINT_LOW("Frame Found start Decoding Size =%u TimeStamp = %lld",
 (unsigned int)pdest_frame->nFilledLen,pdest_frame->nTimeStamp);
                DEBUG_PRINT_LOW("Found a frame size = %u number = %d",
 (unsigned int)pdest_frame->nFilledLen,frame_count++);
 /*Push the frame to the Decoder*/
 if (empty_this_buffer_proxy(hComp,pdest_frame) != OMX_ErrorNone) {
 return OMX_ErrorBadParameter;
 }
                frame_count++;
                pdest_frame = NULL;
 } else {
                DEBUG_PRINT_LOW("Last frame in else dest addr") ;
                generate_ebd = OMX_FALSE;
 }
 }
 if (generate_ebd) {
            DEBUG_PRINT_LOW("Buffer Consumed return back to client %p",psource_frame);
            m_cb.EmptyBufferDone (hComp,m_app_data,psource_frame);
            psource_frame = NULL;

 if (m_input_pending_q.m_size) {
                DEBUG_PRINT_LOW("Pull Next source Buffer %p",psource_frame);
                m_input_pending_q.pop_entry(&address,&p2,&id);
                psource_frame = (OMX_BUFFERHEADERTYPE *) address;
                DEBUG_PRINT_LOW("Next source Buffer %p time stamp %lld",psource_frame,
                        psource_frame->nTimeStamp);
                DEBUG_PRINT_LOW("Next source Buffer flag %u length %u",
 (unsigned int)psource_frame->nFlags, (unsigned int)psource_frame->nFilledLen);
 }
 }
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void init_once() {
    list_init(&created_effects_list);
    list_init(&active_outputs_list);

    pthread_mutex_init(&lock, NULL);

    init_status = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const void* Parcel::readInplace(size_t len) const
{
 if ((mDataPos+PAD_SIZE(len)) >= mDataPos && (mDataPos+PAD_SIZE(len)) <= mDataSize
 && len <= PAD_SIZE(len)) {
 const void* data = mData+mDataPos;
        mDataPos += PAD_SIZE(len);
        ALOGV("readInplace Setting data pos of %p to %zu", this, mDataPos);
 return data;
 }
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_vdec::release_output_done(void)
{

     bool bRet = false;
     unsigned i=0,j=0;
 
    DEBUG_PRINT_LOW("Value of m_out_mem_ptr %p",m_inp_mem_ptr);
     if (m_out_mem_ptr) {
         for (; j < drv_ctx.op_buf.actualcount ; j++) {
             if (BITMASK_PRESENT(&m_out_bm_count,j)) {
 break;
 }
 }
 if (j == drv_ctx.op_buf.actualcount) {
            m_out_bm_count = 0;
            bRet = true;
 }
 } else {
        m_out_bm_count = 0;
        bRet = true;
 }
 return bRet;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_operation_point_set(vps_t *ps_vps, bitstrm_t *ps_bitstrm, WORD32 ops_idx)
{
    WORD32 i;
    WORD32 value;

    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    UNUSED(ops_idx);
 for(i = 0; i <= ps_vps->i1_vps_max_nuh_reserved_zero_layer_id; i++)
 {
        BITS_PARSE("list_entry_l0[ i ]", value, ps_bitstrm, 1);

 }
    UNUSED(value);

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_user_data(dec_state_t *ps_dec)
{
    UWORD32 u4_start_code;
 stream_t *ps_stream;

    ps_stream    = &ps_dec->s_bit_stream;
    u4_start_code = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);


     while(u4_start_code == USER_DATA_START_CODE)
     {
         impeg2d_bit_stream_flush(ps_stream,START_CODE_LEN);
        while(impeg2d_bit_stream_nxt(ps_stream,START_CODE_PREFIX_LEN) != START_CODE_PREFIX)
         {
             impeg2d_bit_stream_flush(ps_stream,8);
         }
        u4_start_code = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_storage_set_remote_addr_type(bt_bdaddr_t *remote_bd_addr,
                                              UINT8 addr_type)
{
 bdstr_t bdstr;
    bdaddr_to_string(remote_bd_addr, bdstr, sizeof(bdstr));
 int ret = btif_config_set_int(bdstr, "AddrType", (int)addr_type);
    btif_config_save();
 return ret ? BT_STATUS_SUCCESS : BT_STATUS_FAIL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t utf16_to_utf8_length(const char16_t *src, size_t src_len)
{
 if (src == NULL || src_len == 0) {
 return -1;
 }

 size_t ret = 0;

     const char16_t* const end = src + src_len;
     while (src < end) {
         if ((*src & 0xFC00) == 0xD800 && (src + 1) < end
                && (*++src & 0xFC00) == 0xDC00) {
             ret += 4;
            src++;
         } else {
             ret += utf32_codepoint_utf8_length((char32_t) *src++);
         }
 }
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MediaMetadataRetriever::DeathNotifier::~DeathNotifier()
{
 Mutex::Autolock lock(sServiceLock);
 if (sService != 0) {
        sService->asBinder()->unlinkToDeath(this);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8::String8(const String8& o)
 : mString(o.mString)
{
 SharedBuffer::bufferFromData(mString)->acquire();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void CopyFromOMX(const OMX_BUFFERHEADERTYPE *header) {
 if (!mCopyFromOmx) {
 return;
 }

        sp<ABuffer> codec = getBuffer(header, false /* backup */, true /* limit */);

        memcpy((OMX_U8 *)mMem->pointer() + header->nOffset, codec->data(), codec->size());
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: VOID ixheaacd_dct3_32(WORD32 *input, WORD32 *output,
 const WORD16 *main_twidle_fwd, const WORD16 *post_tbl,
 const WORD16 *w_16, const WORD32 *p_table) {
  WORD32 n, k;

  WORD32 temp1[6];
  WORD32 temp2[4];
  WORD16 twid_re, twid_im;
  WORD32 *ptr_reverse, *ptr_forward, *p_out, *ptr_out1;
 const WORD16 *twidle_fwd, *twidle_rev;

  ptr_forward = &input[49];
  ptr_reverse = &input[47];

  p_out = output;
  twidle_fwd = main_twidle_fwd;
  twidle_fwd += 4;

 *p_out++ = input[48] >> LP_SHIFT_VAL;
 *p_out++ = 0;

 for (n = 1; n < DCT3_LEN / 2; n++) {
    temp1[0] = *ptr_forward++;
    temp1[1] = *ptr_reverse--;
    temp1[0] = ixheaacd_add32(ixheaacd_shr32(temp1[0], LP_SHIFT_VAL),
                              ixheaacd_shr32(temp1[1], LP_SHIFT_VAL));

    temp1[2] = *(ptr_forward - 33);
    temp1[3] = *(ptr_reverse - 31);
    temp1[1] = ixheaacd_sub32(ixheaacd_shr32(temp1[2], LP_SHIFT_VAL),
                              ixheaacd_shr32(temp1[3], LP_SHIFT_VAL));
    twid_re = *twidle_fwd++;

    twid_im = *twidle_fwd;
    twidle_fwd += 3;
 *p_out++ = mac32x16in32_dual(temp1[0], twid_re, temp1[1], twid_im);
 *p_out++ = msu32x16in32_dual(temp1[0], twid_im, temp1[1], twid_re);
 }
  twid_re = *twidle_fwd++;

  twid_im = *twidle_fwd;
  twidle_fwd += 3;

  temp1[1] = *ptr_reverse--;
  temp1[0] = *(ptr_reverse - 31);
  temp1[1] = ixheaacd_sub32(ixheaacd_shr32(temp1[1], LP_SHIFT_VAL),
                            ixheaacd_shr32(temp1[0], LP_SHIFT_VAL));

  temp1[0] = temp1[1];

  temp2[2] = mac32x16in32_dual(temp1[0], twid_re, temp1[1], twid_im);
  temp2[3] = msu32x16in32_dual(temp1[0], twid_im, temp1[1], twid_re);

  ptr_forward = output;
  ptr_reverse = &output[DCT3_LEN - 1];
  temp2[0] = *ptr_forward++;
  temp2[1] = *ptr_forward--;

  temp1[0] = -temp2[1] - temp2[3];
  temp1[1] = temp2[0] - temp2[2];
  temp2[0] = (temp2[0] + temp2[2] + temp1[0]);
  temp2[1] = (temp2[1] - temp2[3] + temp1[1]);

  temp2[0] >>= 1;
  temp2[1] >>= 1;

 *ptr_forward++ = temp2[0];
 *ptr_forward++ = temp2[1];

  twidle_fwd = post_tbl + 2;
  twidle_rev = post_tbl + 14;

 for (n = 1; n < DCT3_LEN / 4; n++) {
    temp2[0] = *ptr_forward++;
    temp2[1] = *ptr_forward--;
    temp2[3] = *ptr_reverse--;
    temp2[2] = *ptr_reverse++;

    twid_re = *twidle_rev;
    twidle_rev -= 2;
    twid_im = *twidle_fwd;
    twidle_fwd += 2;

    temp1[0] = temp2[0] - temp2[2];
    temp1[1] = (temp2[0] + temp2[2]);

    temp1[2] = temp2[1] + temp2[3];
    temp1[3] = (temp2[1] - temp2[3]);
    temp1[4] = mac32x16in32_dual(temp1[0], twid_re, temp1[2], twid_im);
    temp1[5] = msu32x16in32_dual(temp1[0], twid_im, temp1[2], twid_re);

    temp1[1] >>= 1;
    temp1[3] >>= 1;

 *ptr_forward++ = temp1[1] - temp1[4];
 *ptr_forward++ = temp1[3] + temp1[5];

 *ptr_reverse-- = -temp1[3] + temp1[5];
 *ptr_reverse-- = temp1[1] + temp1[4];
 }
  temp2[0] = *ptr_forward++;
  temp2[1] = *ptr_forward--;
  temp2[3] = *ptr_reverse--;
  temp2[2] = *ptr_reverse++;

  twid_re = *twidle_rev;
  twidle_rev -= 2;
  twid_im = *twidle_fwd;
  twidle_fwd += 2;

  temp1[0] = temp2[0] - temp2[2];
  temp1[1] = (temp2[0] + temp2[2]);

  temp1[2] = temp2[1] + temp2[3];
  temp1[3] = (temp2[1] - temp2[3]);

  temp1[4] = -mac32x16in32_dual(temp1[0], twid_re, temp1[2], twid_im);
  temp1[5] = msu32x16in32_dual(temp1[0], twid_im, temp1[2], twid_re);

  temp1[1] >>= 1;
  temp1[3] >>= 1;
 *ptr_forward++ = temp1[1] + temp1[4];
 *ptr_forward++ = temp1[3] + temp1[5];

  ixheaacd_radix4bfly(w_16, output, 1, 4);
  ixheaacd_postradixcompute4(input, output, p_table, 16);

  output[0] = input[0];
  output[2] = input[1];

  p_out = input + 2;
  ptr_forward = output + 1;
  ptr_reverse = output + 30;
  ptr_out1 = input + 18;

 for (k = (DCT3_LEN / 4) - 1; k != 0; k--) {
    WORD32 tempre, tempim;

    tempre = *p_out++;
    tempim = *p_out++;
 *ptr_forward = (tempim);
    ptr_forward += 2;
 *ptr_forward = (tempre);
    ptr_forward += 2;

    tempre = *ptr_out1++;
    tempim = *ptr_out1++;
 *ptr_reverse = (tempim);
    ptr_reverse -= 2;
 *ptr_reverse = (tempre);
    ptr_reverse -= 2;
 }

 {
    WORD32 tempre, tempim;
    tempre = *p_out++;
    tempim = *p_out++;
 *ptr_forward = (tempim);
    ptr_forward += 2;
 *ptr_forward = (tempre);
    ptr_forward += 2;
 }

 return;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: bool omx_venc::dev_set_buf_req(OMX_U32 *min_buff_count,
        OMX_U32 *actual_buff_count,
        OMX_U32 *buff_size,
        OMX_U32 port)
{
 return handle->venc_set_buf_req(min_buff_count,
            actual_buff_count,
            buff_size,
            port);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual void TearDown() {
      semaphore_free(done);
 AllocationTestHarness::TearDown();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static PropertyDetails GetDetailsImpl(JSObject* holder, uint32_t entry) {
 return PropertyDetails(kData, NONE, 0, PropertyCellType::kNoCell);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Cues::Find(long long time_ns, const Track* pTrack, const CuePoint*& pCP,
 const CuePoint::TrackPosition*& pTP) const {
 if (time_ns < 0 || pTrack == NULL || m_cue_points == NULL || m_count == 0)
 return false;

 CuePoint** const ii = m_cue_points;
 CuePoint** i = ii;

 CuePoint** const jj = ii + m_count;
 CuePoint** j = jj;

  pCP = *i;
 if (pCP == NULL)
 return false;

 if (time_ns <= pCP->GetTime(m_pSegment)) {
    pTP = pCP->Find(pTrack);
 return (pTP != NULL);
 }

 while (i < j) {

 CuePoint** const k = i + (j - i) / 2;
 if (k >= jj)
 return false;

 CuePoint* const pCP = *k;
 if (pCP == NULL)
 return false;

 const long long t = pCP->GetTime(m_pSegment);

 if (t <= time_ns)
      i = k + 1;
 else
      j = k;

 if (i > j)
 return false;
 }

 if (i != j || i > jj || i <= ii)
 return false;

  pCP = *--i;

 if (pCP == NULL || pCP->GetTime(m_pSegment) > time_ns)
 return false;


  pTP = pCP->Find(pTrack);
 return (pTP != NULL);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void bond_state_changed(bt_status_t status, bt_bdaddr_t *bd_addr, bt_bond_state_t state)
{
 if ((pairing_cb.state == state) && (state == BT_BOND_STATE_BONDING))
 {
 if (!bdaddr_is_empty(&pairing_cb.static_bdaddr))
 {
            HAL_CBACK(bt_hal_cbacks, bond_state_changed_cb, status, bd_addr, state);
 }
 return;
 }

 if (pairing_cb.bond_type == BOND_TYPE_TEMPORARY)
        state = BT_BOND_STATE_NONE;

    BTIF_TRACE_DEBUG("%s: state=%d, prev_state=%d, sdp_attempts = %d", __func__,
                      state, pairing_cb.state, pairing_cb.sdp_attempts);

    HAL_CBACK(bt_hal_cbacks, bond_state_changed_cb, status, bd_addr, state);

 if (state == BT_BOND_STATE_BONDING)
 {
        pairing_cb.state = state;
        bdcpy(pairing_cb.bd_addr, bd_addr->address);
 } else {
 if (!pairing_cb.sdp_attempts)
            memset(&pairing_cb, 0, sizeof(pairing_cb));
 else
            BTIF_TRACE_DEBUG("%s: BR-EDR service discovery active", __func__);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool btif_av_is_peer_edr(void) {
  ASSERTC(btif_av_is_connected(), "No active a2dp connection", 0);

 if (btif_av_cb.edr)
 return true;
 else
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::commandPlayRecordingSoundL() {
    mCameraService->playSound(CameraService::SOUND_RECORDING);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const btsnoop_t *btsnoop_get_interface() {
  stack_config = stack_config_get_interface();
 return &interface;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::returnOutputBuffers(
 const camera3_stream_buffer_t *outputBuffers, size_t numBuffers,
 nsecs_t timestamp) {
 for (size_t i = 0; i < numBuffers; i++)
 {
 Camera3Stream *stream = Camera3Stream::cast(outputBuffers[i].stream);
 status_t res = stream->returnBuffer(outputBuffers[i], timestamp);
 if (res != OK) {
            ALOGE("Can't return buffer to its stream: %s (%d)",
                strerror(-res), res);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t MediaHTTP::flags() {
 return kWantsPrefetching | kIsHTTPBasedSource;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::onGetFormatMeta(sp<AMessage> msg) const {
 int32_t audio;
    CHECK(msg->findInt32("audio", &audio));

    sp<AMessage> response = new AMessage;
    sp<MetaData> format = doGetFormatMeta(audio);
    response->setPointer("format", format.get());

    sp<AReplyToken> replyID;
    CHECK(msg->senderAwaitsResponse(&replyID));
    response->postReply(replyID);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int omx_vdec::log_input_buffers(const char *buffer_addr, int buffer_len)
{
 if (m_debug.in_buffer_log && !m_debug.infile) {
 if(!strncmp(drv_ctx.kind,"OMX.qcom.video.decoder.mpeg4", OMX_MAX_STRINGNAME_SIZE)) {
           sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.m4v",
                   m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind,"OMX.qcom.video.decoder.mpeg2", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.mpg", m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this); }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.h263", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.263",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.avc", OMX_MAX_STRINGNAME_SIZE) ||
 !strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.mvc", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.264",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.hevc", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.265",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vc1", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.vc1",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.wmv", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.vc1",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else if(!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8", OMX_MAX_STRINGNAME_SIZE)) {
                sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.ivf",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
 else {
               sprintf(m_debug.infile_name, "%s/input_dec_%d_%d_%p.divx",
                        m_debug.log_loc, drv_ctx.video_resolution.frame_width, drv_ctx.video_resolution.frame_height, this);
 }
        m_debug.infile = fopen (m_debug.infile_name, "ab");
 if (!m_debug.infile) {
            DEBUG_PRINT_HIGH("Failed to open input file: %s for logging", m_debug.infile_name);
            m_debug.infile_name[0] = '\0';
 return -1;
 }
 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8", OMX_MAX_STRINGNAME_SIZE)) {
 struct ivf_file_header {
                OMX_U8 signature[4]; //='DKIF';
                OMX_U8 version         ; //= 0;
                OMX_U8 headersize      ; //= 32;
                OMX_U32 FourCC;
                OMX_U8 width;
                OMX_U8 height;
                OMX_U32 rate;
                OMX_U32 scale;
                OMX_U32 length;
                OMX_U8 unused[4];
 } file_header;

            memset((void *)&file_header,0,sizeof(file_header));
            file_header.signature[0] = 'D';
            file_header.signature[1] = 'K';
            file_header.signature[2] = 'I';
            file_header.signature[3] = 'F';
            file_header.version = 0;
            file_header.headersize = 32;
            file_header.FourCC = 0x30385056;
            fwrite((const char *)&file_header,
 sizeof(file_header),1,m_debug.infile);
 }
 }
 if (m_debug.infile && buffer_addr && buffer_len) {
 if (!strncmp(drv_ctx.kind, "OMX.qcom.video.decoder.vp8", OMX_MAX_STRINGNAME_SIZE)) {
 struct vp8_ivf_frame_header {
                OMX_U32 framesize;
                OMX_U32 timestamp_lo;
                OMX_U32 timestamp_hi;
 } vp8_frame_header;
            vp8_frame_header.framesize = buffer_len;
 /* Currently FW doesn't use timestamp values */
            vp8_frame_header.timestamp_lo = 0;
            vp8_frame_header.timestamp_hi = 0;
            fwrite((const char *)&vp8_frame_header,
 sizeof(vp8_frame_header),1,m_debug.infile);
 }
        fwrite(buffer_addr, buffer_len, 1, m_debug.infile);
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void StreamingProcessor::releaseAllRecordingFramesLocked() {
    ATRACE_CALL();
 status_t res;

 if (mRecordingConsumer == 0) {
 return;
 }

    ALOGV("%s: Camera %d: Releasing all recording buffers", __FUNCTION__,
            mId);

 size_t releasedCount = 0;
 for (size_t itemIndex = 0; itemIndex < mRecordingBuffers.size(); itemIndex++) {
 const BufferItem item = mRecordingBuffers[itemIndex];
 if (item.mBuf != BufferItemConsumer::INVALID_BUFFER_SLOT) {
            res = mRecordingConsumer->releaseBuffer(mRecordingBuffers[itemIndex]);
 if (res != OK) {
                ALOGE("%s: Camera %d: Unable to free recording frame "
 "(buffer_handle_t: %p): %s (%d)", __FUNCTION__,
                        mId, item.mGraphicBuffer->handle, strerror(-res), res);
 }
            mRecordingBuffers.replaceAt(itemIndex);
            releasedCount++;
 }
 }

 if (releasedCount > 0) {
        ALOGW("%s: Camera %d: Force-freed %zu outstanding buffers "
 "from previous recording session", __FUNCTION__, mId, releasedCount);
        ALOGE_IF(releasedCount != mRecordingHeapCount - mRecordingHeapFree,
 "%s: Camera %d: Force-freed %zu buffers, but expected %zu",
            __FUNCTION__, mId, releasedCount, mRecordingHeapCount - mRecordingHeapFree);
 }

    mRecordingHeapHead = 0;
    mRecordingHeapFree = mRecordingHeapCount;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftMPEG4Encoder(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVC::setFrameType(IV_PICTURE_CODING_TYPE_T e_frame_type) {
 ive_ctl_set_frame_type_ip_t s_frame_type_ip;
 ive_ctl_set_frame_type_op_t s_frame_type_op;
    IV_STATUS_T status;
    s_frame_type_ip.e_cmd = IVE_CMD_VIDEO_CTL;
    s_frame_type_ip.e_sub_cmd = IVE_CMD_CTL_SET_FRAMETYPE;

    s_frame_type_ip.e_frame_type = e_frame_type;

    s_frame_type_ip.u4_timestamp_high = -1;
    s_frame_type_ip.u4_timestamp_low = -1;

    s_frame_type_ip.u4_size = sizeof(ive_ctl_set_frame_type_ip_t);
    s_frame_type_op.u4_size = sizeof(ive_ctl_set_frame_type_op_t);

    status = ive_api_function(mCodecCtx, &s_frame_type_ip, &s_frame_type_op);
 if (status != IV_SUCCESS) {
        ALOGE("Unable to set frame type = 0x%x\n",
                s_frame_type_op.u4_error_code);
 return OMX_ErrorUndefined;
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::use_input_heap_buffers(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes,
        OMX_IN OMX_U8*                   buffer)
{
    DEBUG_PRINT_LOW("Inside %s, %p", __FUNCTION__, buffer);
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 if (!m_inp_heap_ptr)
        m_inp_heap_ptr = (OMX_BUFFERHEADERTYPE*)
            calloc( (sizeof(OMX_BUFFERHEADERTYPE)),
                    drv_ctx.ip_buf.actualcount);
 if (!m_phdr_pmem_ptr)
        m_phdr_pmem_ptr = (OMX_BUFFERHEADERTYPE**)
            calloc( (sizeof(OMX_BUFFERHEADERTYPE*)),
                    drv_ctx.ip_buf.actualcount);
 if (!m_inp_heap_ptr || !m_phdr_pmem_ptr) {
        DEBUG_PRINT_ERROR("Insufficent memory");
        eRet = OMX_ErrorInsufficientResources;
 } else if (m_in_alloc_cnt < drv_ctx.ip_buf.actualcount) {
        input_use_buffer = true;
        memset(&m_inp_heap_ptr[m_in_alloc_cnt], 0, sizeof(OMX_BUFFERHEADERTYPE));
        m_inp_heap_ptr[m_in_alloc_cnt].pBuffer = buffer;
        m_inp_heap_ptr[m_in_alloc_cnt].nAllocLen = bytes;
        m_inp_heap_ptr[m_in_alloc_cnt].pAppPrivate = appData;
        m_inp_heap_ptr[m_in_alloc_cnt].nInputPortIndex = (OMX_U32) OMX_DirInput;
        m_inp_heap_ptr[m_in_alloc_cnt].nOutputPortIndex = (OMX_U32) OMX_DirMax;
 *bufferHdr = &m_inp_heap_ptr[m_in_alloc_cnt];
        eRet = allocate_input_buffer(hComp, &m_phdr_pmem_ptr[m_in_alloc_cnt], port, appData, bytes);
        DEBUG_PRINT_HIGH("Heap buffer(%p) Pmem buffer(%p)", *bufferHdr, m_phdr_pmem_ptr[m_in_alloc_cnt]);
 if (!m_input_free_q.insert_entry((unsigned long)m_phdr_pmem_ptr[m_in_alloc_cnt],
 (unsigned)NULL, (unsigned)NULL)) {
            DEBUG_PRINT_ERROR("ERROR:Free_q is full");
 return OMX_ErrorInsufficientResources;
 }
        m_in_alloc_cnt++;
 } else {
        DEBUG_PRINT_ERROR("All i/p buffers have been set!");
        eRet = OMX_ErrorInsufficientResources;
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_dm_proc_loc_oob(BOOLEAN valid, BT_OCTET16 c, BT_OCTET16 r)
{
 FILE *fp;
 char *path_a = "/data/misc/bluedroid/LOCAL/a.key";
 char *path_b = "/data/misc/bluedroid/LOCAL/b.key";
 char *path = NULL;
 char prop_oob[PROPERTY_VALUE_MAX];
    BTIF_TRACE_DEBUG("btif_dm_proc_loc_oob: valid=%d", valid);
 if (oob_cb.sp_c[0] == 0 && oob_cb.sp_c[1] == 0 &&
        oob_cb.sp_c[2] == 0 && oob_cb.sp_c[3] == 0 &&
        valid)
 {
        BTIF_TRACE_DEBUG("save local OOB data in memory");
        memcpy(oob_cb.sp_c, c, BT_OCTET16_LEN);
        memcpy(oob_cb.sp_r, r, BT_OCTET16_LEN);
        property_get("service.brcm.bt.oob", prop_oob, "3");
        BTIF_TRACE_DEBUG("btif_dm_proc_loc_oob prop_oob = %s",prop_oob);
 if (prop_oob[0] == '1')
            path = path_a;
 else if (prop_oob[0] == '2')
            path = path_b;
 if (path)
 {
            fp = fopen(path, "wb+");
 if (fp == NULL)
 {
                BTIF_TRACE_DEBUG("btif_dm_proc_loc_oob: failed to save local OOB data to %s", path);
 }
 else
 {
                BTIF_TRACE_DEBUG("btif_dm_proc_loc_oob: save local OOB data into file %s",path);
                fwrite (c , 1 , BT_OCTET16_LEN , fp );
                fwrite (r , 1 , BT_OCTET16_LEN , fp );
                fclose(fp);
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::updateAudioTrackInfoFromESDS_MPEG4Audio(
 const void *esds_data, size_t esds_size) {
    ESDS esds(esds_data, esds_size);

 uint8_t objectTypeIndication;
 if (esds.getObjectTypeIndication(&objectTypeIndication) != OK) {
 return ERROR_MALFORMED;
 }

 if (objectTypeIndication == 0xe1) {
        mLastTrack->meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_AUDIO_QCELP);
 return OK;
 }

 if (objectTypeIndication  == 0x6b) {
        ALOGE("MP3 track in MP4/3GPP file is not supported");
 return ERROR_UNSUPPORTED;
 }

 const uint8_t *csd;
 size_t csd_size;
 if (esds.getCodecSpecificInfo(
 (const void **)&csd, &csd_size) != OK) {
 return ERROR_MALFORMED;
 }

#if 0
    printf("ESD of size %d\n", csd_size);
    hexdump(csd, csd_size);
#endif

 if (csd_size == 0) {

 return OK;
 }

 if (csd_size < 2) {
 return ERROR_MALFORMED;
 }

 static uint32_t kSamplingRate[] = {
 96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050,
 16000, 12000, 11025, 8000, 7350
 };

 ABitReader br(csd, csd_size);
 uint32_t objectType = br.getBits(5);

 if (objectType == 31) { // AAC-ELD => additional 6 bits
        objectType = 32 + br.getBits(6);
 }

    mLastTrack->meta->setInt32(kKeyAACAOT, objectType);

 uint32_t freqIndex = br.getBits(4);

 int32_t sampleRate = 0;
 int32_t numChannels = 0;
 if (freqIndex == 15) {
 if (csd_size < 5) {
 return ERROR_MALFORMED;
 }
        sampleRate = br.getBits(24);
        numChannels = br.getBits(4);
 } else {
        numChannels = br.getBits(4);

 if (freqIndex == 13 || freqIndex == 14) {
 return ERROR_MALFORMED;
 }

        sampleRate = kSamplingRate[freqIndex];
 }

 if (objectType == AOT_SBR || objectType == AOT_PS) {//SBR specific config per 14496-3 table 1.13
 uint32_t extFreqIndex = br.getBits(4);
 int32_t extSampleRate;
 if (extFreqIndex == 15) {
 if (csd_size < 8) {
 return ERROR_MALFORMED;
 }
            extSampleRate = br.getBits(24);
 } else {
 if (extFreqIndex == 13 || extFreqIndex == 14) {
 return ERROR_MALFORMED;
 }
            extSampleRate = kSamplingRate[extFreqIndex];
 }
 }

 switch (numChannels) {
 case 0:
 case 1:// FC
 case 2:// FL FR
 case 3:// FC, FL FR
 case 4:// FC, FL FR, RC
 case 5:// FC, FL FR, SL SR
 case 6:// FC, FL FR, SL SR, LFE
 break;
 case 11:// FC, FL FR, SL SR, RC, LFE
            numChannels = 7;
 break;
 case 7: // FC, FCL FCR, FL FR, SL SR, LFE
 case 12:// FC, FL  FR,  SL SR, RL RR, LFE
 case 14:// FC, FL  FR,  SL SR, LFE, FHL FHR
            numChannels = 8;
 break;
 default:
 return ERROR_UNSUPPORTED;
 }

 {
 if (objectType == AOT_SBR || objectType == AOT_PS) {
            objectType = br.getBits(5);

 if (objectType == AOT_ESCAPE) {
                objectType = 32 + br.getBits(6);
 }
 }
 if (objectType == AOT_AAC_LC || objectType == AOT_ER_AAC_LC ||
                objectType == AOT_ER_AAC_LD || objectType == AOT_ER_AAC_SCAL ||
                objectType == AOT_ER_BSAC) {
 const int32_t frameLengthFlag = br.getBits(1);

 const int32_t dependsOnCoreCoder = br.getBits(1);

 if (dependsOnCoreCoder ) {
 const int32_t coreCoderDelay = br.getBits(14);
 }

 int32_t extensionFlag = -1;
 if (br.numBitsLeft() > 0) {
                extensionFlag = br.getBits(1);
 } else {
 switch (objectType) {
 case AOT_AAC_LC:
                    extensionFlag = 0;
 break;
 case AOT_ER_AAC_LC:
 case AOT_ER_AAC_SCAL:
 case AOT_ER_BSAC:
 case AOT_ER_AAC_LD:
                    extensionFlag = 1;
 break;
 default:
                    TRESPASS();
 break;
 }
                ALOGW("csd missing extension flag; assuming %d for object type %u.",
                        extensionFlag, objectType);
 }

 if (numChannels == 0) {
 int32_t channelsEffectiveNum = 0;
 int32_t channelsNum = 0;
 const int32_t ElementInstanceTag = br.getBits(4);
 const int32_t Profile = br.getBits(2);
 const int32_t SamplingFrequencyIndex = br.getBits(4);
 const int32_t NumFrontChannelElements = br.getBits(4);
 const int32_t NumSideChannelElements = br.getBits(4);
 const int32_t NumBackChannelElements = br.getBits(4);
 const int32_t NumLfeChannelElements = br.getBits(2);
 const int32_t NumAssocDataElements = br.getBits(3);
 const int32_t NumValidCcElements = br.getBits(4);

 const int32_t MonoMixdownPresent = br.getBits(1);
 if (MonoMixdownPresent != 0) {
 const int32_t MonoMixdownElementNumber = br.getBits(4);
 }

 const int32_t StereoMixdownPresent = br.getBits(1);
 if (StereoMixdownPresent != 0) {
 const int32_t StereoMixdownElementNumber = br.getBits(4);
 }

 const int32_t MatrixMixdownIndexPresent = br.getBits(1);
 if (MatrixMixdownIndexPresent != 0) {
 const int32_t MatrixMixdownIndex = br.getBits(2);
 const int32_t PseudoSurroundEnable = br.getBits(1);
 }

 int i;
 for (i=0; i < NumFrontChannelElements; i++) {
 const int32_t FrontElementIsCpe = br.getBits(1);
 const int32_t FrontElementTagSelect = br.getBits(4);
                    channelsNum += FrontElementIsCpe ? 2 : 1;
 }

 for (i=0; i < NumSideChannelElements; i++) {
 const int32_t SideElementIsCpe = br.getBits(1);
 const int32_t SideElementTagSelect = br.getBits(4);
                    channelsNum += SideElementIsCpe ? 2 : 1;
 }

 for (i=0; i < NumBackChannelElements; i++) {
 const int32_t BackElementIsCpe = br.getBits(1);
 const int32_t BackElementTagSelect = br.getBits(4);
                    channelsNum += BackElementIsCpe ? 2 : 1;
 }
                channelsEffectiveNum = channelsNum;

 for (i=0; i < NumLfeChannelElements; i++) {
 const int32_t LfeElementTagSelect = br.getBits(4);
                    channelsNum += 1;
 }
                ALOGV("mpeg4 audio channelsNum = %d", channelsNum);
                ALOGV("mpeg4 audio channelsEffectiveNum = %d", channelsEffectiveNum);
                numChannels = channelsNum;
 }
 }
 }

 if (numChannels == 0) {
 return ERROR_UNSUPPORTED;
 }

 int32_t prevSampleRate;
    CHECK(mLastTrack->meta->findInt32(kKeySampleRate, &prevSampleRate));

 if (prevSampleRate != sampleRate) {
        ALOGV("mpeg4 audio sample rate different from previous setting. "
 "was: %d, now: %d", prevSampleRate, sampleRate);
 }

    mLastTrack->meta->setInt32(kKeySampleRate, sampleRate);

 int32_t prevChannelCount;
    CHECK(mLastTrack->meta->findInt32(kKeyChannelCount, &prevChannelCount));

 if (prevChannelCount != numChannels) {
        ALOGV("mpeg4 audio channel count different from previous setting. "
 "was: %d, now: %d", prevChannelCount, numChannels);
 }

    mLastTrack->meta->setInt32(kKeyChannelCount, numChannels);

 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t CameraDeviceClient::getRotationTransformLocked(int32_t* transform) {
    ALOGV("%s: begin", __FUNCTION__);

 if (transform == NULL) {
        ALOGW("%s: null transform", __FUNCTION__);
 return BAD_VALUE;
 }

 *transform = 0;

 const CameraMetadata& staticInfo = mDevice->info();
 camera_metadata_ro_entry_t entry = staticInfo.find(ANDROID_SENSOR_ORIENTATION);
 if (entry.count == 0) {
        ALOGE("%s: Camera %d: Can't find android.sensor.orientation in "
 "static metadata!", __FUNCTION__, mCameraId);
 return INVALID_OPERATION;
 }

 int32_t& flags = *transform;

 int orientation = entry.data.i32[0];
 switch (orientation) {
 case 0:
            flags = 0;
 break;
 case 90:
            flags = NATIVE_WINDOW_TRANSFORM_ROT_90;
 break;
 case 180:
            flags = NATIVE_WINDOW_TRANSFORM_ROT_180;
 break;
 case 270:
            flags = NATIVE_WINDOW_TRANSFORM_ROT_270;
 break;
 default:
            ALOGE("%s: Invalid HAL android.sensor.orientation value: %d",
                  __FUNCTION__, orientation);
 return INVALID_OPERATION;
 }

 /**
     * This magic flag makes surfaceflinger un-rotate the buffers
     * to counter the extra global device UI rotation whenever the user
     * physically rotates the device.
     *
     * By doing this, the camera buffer always ends up aligned
     * with the physical camera for a "see through" effect.
     *
     * In essence, the buffer only gets rotated during preview use-cases.
     * The user is still responsible to re-create streams of the proper
     * aspect ratio, or the preview will end up looking non-uniformly
     * stretched.
     */
    flags |= NATIVE_WINDOW_TRANSFORM_INVERSE_DISPLAY;

    ALOGV("%s: final transform = 0x%x", __FUNCTION__, flags);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void impeg2d_dec_seq_disp_ext(dec_state_t *ps_dec)
{
 stream_t *ps_stream;
    ps_stream = &ps_dec->s_bit_stream;

 /*
    sequence_display_extension()
    {
        extension_start_code_identifier 4
        video_format                    3
        colour_description              1
        if (colour_description)
        {
            colour_primaries            8
            transfer_characteristics    8
            matrix_coefficients         8
        }
        display_horizontal_size         14
        marker_bit                      1
        display_vertical_size           14
        next_start_code()
    }
    */

    impeg2d_bit_stream_get(ps_stream,7);
 if (impeg2d_bit_stream_get_bit(ps_stream) == 1)
 {
        impeg2d_bit_stream_get(ps_stream,24);
 }

 /* display_horizontal_size and display_vertical_size */
    ps_dec->u2_display_horizontal_size = impeg2d_bit_stream_get(ps_stream,14);;
    GET_MARKER_BIT(ps_dec,ps_stream);
    ps_dec->u2_display_vertical_size   = impeg2d_bit_stream_get(ps_stream,14);

    impeg2d_next_start_code(ps_dec);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Visualizer_getConfig(VisualizerContext *pContext, effect_config_t *pConfig)
{
 *pConfig = pContext->mConfig;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void rpng2_x_cleanup(void)
{
 if (bg_image && bg_data) {
        free(bg_data);
        bg_data = NULL;
 }

 if (rpng2_info.image_data) {
        free(rpng2_info.image_data);
        rpng2_info.image_data = NULL;
 }

 if (rpng2_info.row_pointers) {
        free(rpng2_info.row_pointers);
        rpng2_info.row_pointers = NULL;
 }

 if (ximage) {
 if (ximage->data) {
            free(ximage->data); /* we allocated it, so we free it */
            ximage->data = (char *)NULL; /*  instead of XDestroyImage() */
 }
 XDestroyImage(ximage);
        ximage = NULL;
 }

 if (have_gc)
 XFreeGC(display, gc);

 if (have_window)
 XDestroyWindow(display, window);

 if (have_colormap)
 XFreeColormap(display, colormap);

 if (have_nondefault_visual)
 XFree(visual_list);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::checkDrmStatus(const sp<DataSource>& dataSource) {
    dataSource->getDrmInfo(mDecryptHandle, &mDrmManagerClient);
 if (mDecryptHandle != NULL) {
        CHECK(mDrmManagerClient);
 if (RightsStatus::RIGHTS_VALID != mDecryptHandle->status) {
            sp<AMessage> msg = dupNotify();
            msg->setInt32("what", kWhatDrmNoLicense);
            msg->post();
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_send_enc_info(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  tBTM_LE_LENC_KEYS le_key;

  SMP_TRACE_DEBUG("%s: p_cb->loc_enc_size = %d", __func__, p_cb->loc_enc_size);
  smp_update_key_mask(p_cb, SMP_SEC_KEY_TYPE_ENC, false);

  smp_send_cmd(SMP_OPCODE_ENCRYPT_INFO, p_cb);
  smp_send_cmd(SMP_OPCODE_MASTER_ID, p_cb);

 /* save the DIV and key size information when acting as slave device */
  memcpy(le_key.ltk, p_cb->ltk, BT_OCTET16_LEN);
  le_key.div = p_cb->div;
  le_key.key_size = p_cb->loc_enc_size;
  le_key.sec_level = p_cb->sec_level;

 if ((p_cb->peer_auth_req & SMP_AUTH_BOND) &&
 (p_cb->loc_auth_req & SMP_AUTH_BOND))
    btm_sec_save_le_key(p_cb->pairing_bda, BTM_LE_KEY_LENC,
 (tBTM_LE_KEY_VALUE*)&le_key, true);

  SMP_TRACE_WARNING("%s", __func__);

  smp_key_distribution(p_cb, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlErrMsgStr(xmlParserCtxtPtr ctxt, xmlParserErrors error,
 const char *msg, const xmlChar * val)
{
 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 if (ctxt != NULL)
	ctxt->errNo = error;
    __xmlRaiseError(NULL, NULL, NULL, ctxt, NULL,
                    XML_FROM_PARSER, error, XML_ERR_ERROR,
                    NULL, 0, (const char *) val, NULL, NULL, 0, 0, msg,
                    val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::setInternalOption(
        OMX_U32 portIndex,
        IOMX::InternalOptionType type,
 const void *data,
 size_t size) {
    CLOG_CONFIG(setInternalOption, "%s(%d): %s:%u %zu@%p",
            asString(type), type, portString(portIndex), portIndex, size, data);
 switch (type) {
 case IOMX::INTERNAL_OPTION_SUSPEND:
 case IOMX::INTERNAL_OPTION_REPEAT_PREVIOUS_FRAME_DELAY:
 case IOMX::INTERNAL_OPTION_MAX_TIMESTAMP_GAP:
 case IOMX::INTERNAL_OPTION_START_TIME:
 case IOMX::INTERNAL_OPTION_TIME_LAPSE:
 {
 const sp<GraphicBufferSource> &bufferSource =
                getGraphicBufferSource();

 if (bufferSource == NULL || portIndex != kPortIndexInput) {
                CLOGW("setInternalOption is only for Surface input");
 return ERROR_UNSUPPORTED;
 }

 if (type == IOMX::INTERNAL_OPTION_SUSPEND) {
 if (size != sizeof(bool)) {
 return INVALID_OPERATION;
 }

 bool suspend = *(bool *)data;
                CLOG_CONFIG(setInternalOption, "suspend=%d", suspend);
                bufferSource->suspend(suspend);
 } else if (type ==
                    IOMX::INTERNAL_OPTION_REPEAT_PREVIOUS_FRAME_DELAY){
 if (size != sizeof(int64_t)) {
 return INVALID_OPERATION;
 }

 int64_t delayUs = *(int64_t *)data;
                CLOG_CONFIG(setInternalOption, "delayUs=%lld", (long long)delayUs);
 return bufferSource->setRepeatPreviousFrameDelayUs(delayUs);
 } else if (type ==
                    IOMX::INTERNAL_OPTION_MAX_TIMESTAMP_GAP){
 if (size != sizeof(int64_t)) {
 return INVALID_OPERATION;
 }

 int64_t maxGapUs = *(int64_t *)data;
                CLOG_CONFIG(setInternalOption, "gapUs=%lld", (long long)maxGapUs);
 return bufferSource->setMaxTimestampGapUs(maxGapUs);
 } else if (type == IOMX::INTERNAL_OPTION_START_TIME) {
 if (size != sizeof(int64_t)) {
 return INVALID_OPERATION;
 }

 int64_t skipFramesBeforeUs = *(int64_t *)data;
                CLOG_CONFIG(setInternalOption, "beforeUs=%lld", (long long)skipFramesBeforeUs);
                bufferSource->setSkipFramesBeforeUs(skipFramesBeforeUs);
 } else { // IOMX::INTERNAL_OPTION_TIME_LAPSE
 if (size != sizeof(int64_t) * 2) {
 return INVALID_OPERATION;
 }

 int64_t timePerFrameUs = ((int64_t *)data)[0];
 int64_t timePerCaptureUs = ((int64_t *)data)[1];
                CLOG_CONFIG(setInternalOption, "perFrameUs=%lld perCaptureUs=%lld",
 (long long)timePerFrameUs, (long long)timePerCaptureUs);

                bufferSource->setTimeLapseUs((int64_t *)data);
 }

 return OK;
 }

 default:
 return ERROR_UNSUPPORTED;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool VBRISeeker::getDuration(int64_t *durationUs) {
 if (mDurationUs < 0) {
 return false;
 }

 *durationUs = mDurationUs;

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long SeekHead::Parse()
{
    IMkvReader* const pReader = m_pSegment->m_pReader;
 
    long long pos = m_start;
    const long long stop = m_start + m_size;
 
 
    int entry_count = 0;
    int void_element_count = 0;
 
    while (pos < stop)
    {
        long long id, size;
 
        const long status = ParseElementHeader(
                                pReader,
                                pos,
                                stop,
                                id,
                                size);
 
        if (status < 0)  //error
            return status;
 
        if (id == 0x0DBB)  //SeekEntry ID
            ++entry_count;
        else if (id == 0x6C)  //Void ID
            ++void_element_count;
 
        pos += size;  //consume payload
        assert(pos <= stop);
     }
 
    assert(pos == stop);
 
    m_entries = new (std::nothrow) Entry[entry_count];
 
    if (m_entries == NULL)
        return -1;
 
    m_void_elements = new (std::nothrow) VoidElement[void_element_count];
 
    if (m_void_elements == NULL)
        return -1;
 
 
    Entry* pEntry = m_entries;
    VoidElement* pVoidElement = m_void_elements;
 
    pos = m_start;
 
    while (pos < stop)
    {
        const long long idpos = pos;
        long long id, size;
        const long status = ParseElementHeader(
                                pReader,
                                pos,
                                stop,
                                id,
                                size);
        if (status < 0)  //error
            return status;
        if (id == 0x0DBB)  //SeekEntry ID
        {
            if (ParseEntry(pReader, pos, size, pEntry))
            {
                Entry& e = *pEntry++;
                e.element_start = idpos;
                e.element_size = (pos + size) - idpos;
            }
        }
        else if (id == 0x6C)  //Void ID
        {
            VoidElement& e = *pVoidElement++;
            e.element_start = idpos;
            e.element_size = (pos + size) - idpos;
        }
        pos += size;  //consume payload
        assert(pos <= stop);
    }
    assert(pos == stop);
    ptrdiff_t count_ = ptrdiff_t(pEntry - m_entries);
    assert(count_ >= 0);
    assert(count_ <= entry_count);
    m_entry_count = static_cast<int>(count_);
    count_ = ptrdiff_t(pVoidElement - m_void_elements);
    assert(count_ >= 0);
    assert(count_ <= void_element_count);
    m_void_element_count = static_cast<int>(count_);
     return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void impeg2d_post_pic_dec_proc(dec_state_t *ps_dec)
{

   WORD32 u4_update_pic_buf = 0;
 /*************************************************************************/
 /* Processing at the end of picture                                      */
 /*************************************************************************/
 if(ps_dec->u2_picture_structure != FRAME_PICTURE)
 {
        ps_dec->u2_num_vert_mb       = (ps_dec->u2_vertical_size + 31) >> 5;

 if(ps_dec->u2_num_flds_decoded == 1)
 {
            ps_dec->u2_num_flds_decoded = 0;
            u4_update_pic_buf = 1;
 }
 else
 {
            ps_dec->u2_num_flds_decoded = 1;
 }
 }
 else
 {
        u4_update_pic_buf = 1;
 }

 if(u4_update_pic_buf)
 {
        ps_dec->i4_frame_decoded = 1;
 if(ps_dec->e_pic_type != B_PIC)
 {
 /* In any sequence first two pictures have to be reference pictures */
 /* Adding of first picture in the sequence */
 if(ps_dec->aps_ref_pics[0] == NULL)
 {
                ps_dec->aps_ref_pics[0] = ps_dec->ps_cur_pic;
 }

 /* Adding of second picture in the sequence */
 else if(ps_dec->aps_ref_pics[1] == NULL)
 {
                ps_dec->aps_ref_pics[1] = ps_dec->ps_cur_pic;
                impeg2_disp_mgr_add(&ps_dec->s_disp_mgr, ps_dec->aps_ref_pics[0], ps_dec->aps_ref_pics[0]->i4_buf_id);
 }
 else
 {

                impeg2_disp_mgr_add(&ps_dec->s_disp_mgr, ps_dec->aps_ref_pics[1], ps_dec->aps_ref_pics[1]->i4_buf_id);
                impeg2_buf_mgr_release(ps_dec->pv_pic_buf_mg, ps_dec->aps_ref_pics[0]->i4_buf_id, BUF_MGR_REF);
                ps_dec->aps_ref_pics[0] = ps_dec->aps_ref_pics[1];
                ps_dec->aps_ref_pics[1] = ps_dec->ps_cur_pic;

 }
 }
 else
 {
            impeg2_disp_mgr_add(&ps_dec->s_disp_mgr, ps_dec->ps_cur_pic, ps_dec->ps_cur_pic->i4_buf_id);

            impeg2_buf_mgr_release(ps_dec->pv_pic_buf_mg, ps_dec->ps_cur_pic->i4_buf_id, BUF_MGR_REF);
 }

 }
 /*************************************************************************/
 /* Update the list of recent reference pictures                          */
 /*************************************************************************/
 if(ps_dec->e_pic_type != B_PIC)
 {
 switch(ps_dec->u2_picture_structure)
 {
 case FRAME_PICTURE:
 {
                ps_dec->as_recent_fld[0][0] = ps_dec->as_recent_fld[1][0];
                ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];

                ps_dec->as_recent_fld[1][0] = ps_dec->s_cur_frm_buf;
                impeg2d_get_bottom_field_buf(&ps_dec->s_cur_frm_buf, &ps_dec->as_recent_fld[1][1],
                ps_dec->u2_frame_width);
 break;
 }
 case TOP_FIELD:
 {
                ps_dec->as_recent_fld[0][0] = ps_dec->as_recent_fld[1][0];
                ps_dec->as_recent_fld[1][0] = ps_dec->s_cur_frm_buf;
 break;
 }
 case BOTTOM_FIELD:
 {
                ps_dec->as_recent_fld[0][1] = ps_dec->as_recent_fld[1][1];
                impeg2d_get_bottom_field_buf(&ps_dec->s_cur_frm_buf, &ps_dec->as_recent_fld[1][1],
                ps_dec->u2_frame_width);
 break;
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Edition::Edition()
{
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<ABuffer> NuPlayer::GenericSource::mediaBufferToABuffer(
 MediaBuffer* mb,
        media_track_type trackType,
 int64_t *actualTimeUs) {
 bool audio = trackType == MEDIA_TRACK_TYPE_AUDIO;
 size_t outLength = mb->range_length();

 if (audio && mAudioIsVorbis) {
        outLength += sizeof(int32_t);
 }

    sp<ABuffer> ab;
 if (mIsWidevine && !audio) {
        ab = new ABuffer(NULL, mb->range_length());
        mb->add_ref();
        ab->setMediaBufferBase(mb);
 } else {
        ab = new ABuffer(outLength);
        memcpy(ab->data(),
 (const uint8_t *)mb->data() + mb->range_offset(),
               mb->range_length());
 }

 if (audio && mAudioIsVorbis) {
 int32_t numPageSamples;
 if (!mb->meta_data()->findInt32(kKeyValidSamples, &numPageSamples)) {
            numPageSamples = -1;
 }

 uint8_t* abEnd = ab->data() + mb->range_length();
        memcpy(abEnd, &numPageSamples, sizeof(numPageSamples));
 }

    sp<AMessage> meta = ab->meta();

 int64_t timeUs;
    CHECK(mb->meta_data()->findInt64(kKeyTime, &timeUs));
    meta->setInt64("timeUs", timeUs);

 if (trackType == MEDIA_TRACK_TYPE_TIMEDTEXT) {
 const char *mime;
        CHECK(mTimedTextTrack.mSource != NULL
 && mTimedTextTrack.mSource->getFormat()->findCString(kKeyMIMEType, &mime));
        meta->setString("mime", mime);
 }

 int64_t durationUs;
 if (mb->meta_data()->findInt64(kKeyDuration, &durationUs)) {
        meta->setInt64("durationUs", durationUs);
 }

 if (trackType == MEDIA_TRACK_TYPE_SUBTITLE) {
        meta->setInt32("trackIndex", mSubtitleTrack.mIndex);
 }

 if (actualTimeUs) {
 *actualTimeUs = timeUs;
 }

    mb->release();
    mb = NULL;

 return ab;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftVPX::onReset() {
 bool portWillReset = false;
 if (!outputBuffers(
 true /* flushDecoder */, false /* display */, false /* eos */, &portWillReset)) {
        ALOGW("Failed to flush decoder. Try to hard reset decoder");
        destroyDecoder();
        initDecoder();
 }
    mEOSStatus = INPUT_DATA_AVAILABLE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cluster* Segment::GetLast() const
{
    if ((m_clusters == NULL) || (m_clusterCount <= 0))
        return &m_eos;
 
    const long idx = m_clusterCount - 1;
 
    Cluster* const pCluster = m_clusters[idx];
    assert(pCluster);
    return pCluster;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static inline int accept_server_socket(int s)

 {
     struct sockaddr_un client_address;
     socklen_t clen;
    int fd = accept(s, (struct sockaddr*)&client_address, &clen);
     APPL_TRACE_DEBUG("accepted fd:%d for server fd:%d", fd, s);
     return fd;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Region_quickContains(JNIEnv* env, jobject region, jint left, jint top, jint right, jint bottom) {
 bool result = GetSkRegion(env, region)->quickContains(left, top, right, bottom);
 return boolTojboolean(result);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long mkvparser::ParseElementHeader(IMkvReader* pReader, long long& pos,
                                   long long stop, long long& id,
                                   long long& size) {
  if ((stop >= 0) && (pos >= stop))
     return E_FILE_FORMAT_INVALID;
 
   long len;
 
  id = ReadUInt(pReader, pos, len);
 
   if (id < 0)
     return E_FILE_FORMAT_INVALID;
 
   pos += len;  // consume id
 
  if ((stop >= 0) && (pos >= stop))
     return E_FILE_FORMAT_INVALID;
 
   size = ReadUInt(pReader, pos, len);
 
  if (size < 0)
     return E_FILE_FORMAT_INVALID;
 
   pos += len;  // consume length of size
 
 
  if ((stop >= 0) && ((pos + size) > stop))
     return E_FILE_FORMAT_INVALID;
 
   return 0;  // success
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: FrameSequence_gif::FrameSequence_gif(Stream* stream) :
        mLoopCount(1), mBgColor(TRANSPARENT), mPreservedFrames(NULL), mRestoringFrames(NULL) {
    mGif = DGifOpen(stream, streamReader, NULL);
 if (!mGif) {
        ALOGW("Gif load failed");
 return;
 }

 if (DGifSlurp(mGif) != GIF_OK) {
        ALOGW("Gif slurp failed");
 DGifCloseFile(mGif, NULL);
        mGif = NULL;
 return;
 }

 long durationMs = 0;
 int lastUnclearedFrame = -1;
    mPreservedFrames = new bool[mGif->ImageCount];
    mRestoringFrames = new int[mGif->ImageCount];

 GraphicsControlBlock gcb;
 for (int i = 0; i < mGif->ImageCount; i++) {
 const SavedImage& image = mGif->SavedImages[i];

 for (int j = 0; (j + 1) < image.ExtensionBlockCount; j++) {
 ExtensionBlock* eb1 = image.ExtensionBlocks + j;
 ExtensionBlock* eb2 = image.ExtensionBlocks + j + 1;
 if (eb1->Function == APPLICATION_EXT_FUNC_CODE
 && eb1->ByteCount == 11
 && !memcmp((const char*)(eb1->Bytes), "NETSCAPE2.0", 11)
 && eb2->Function == CONTINUE_EXT_FUNC_CODE
 && eb2->ByteCount == 3
 && eb2->Bytes[0] == 1) {
                mLoopCount = (int)(eb2->Bytes[2] << 8) + (int)(eb2->Bytes[1]);
 }
 }

 DGifSavedExtensionToGCB(mGif, i, &gcb);

        durationMs += getDelayMs(gcb);

        mPreservedFrames[i] = false;
        mRestoringFrames[i] = -1;
 if (gcb.DisposalMode == DISPOSE_PREVIOUS && lastUnclearedFrame >= 0) {
            mPreservedFrames[lastUnclearedFrame] = true;
            mRestoringFrames[i] = lastUnclearedFrame;
 }
 if (!willBeCleared(gcb)) {
            lastUnclearedFrame = i;
 }
 }

#if GIF_DEBUG
    ALOGD("FrameSequence_gif created with size %d %d, frames %d dur %ld",
            mGif->SWidth, mGif->SHeight, mGif->ImageCount, durationMs);
 for (int i = 0; i < mGif->ImageCount; i++) {
 DGifSavedExtensionToGCB(mGif, i, &gcb);
        ALOGD("    Frame %d - must preserve %d, restore point %d, trans color %d",
                i, mPreservedFrames[i], mRestoringFrames[i], gcb.TransparentColor);
 }
#endif

 if (mGif->SColorMap) {
 GraphicsControlBlock gcb;
 DGifSavedExtensionToGCB(mGif, 0, &gcb);
 if (gcb.TransparentColor == NO_TRANSPARENT_COLOR) {
            mBgColor = gifColorToColor8888(mGif->SColorMap->Colors[mGif->SBackGroundColor]);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BnOMX::onTransact(
 uint32_t code, const Parcel &data, Parcel *reply, uint32_t flags) {
 switch (code) {
 case LIVES_LOCALLY:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);
            node_id node = (node_id)data.readInt32();
 pid_t pid = (pid_t)data.readInt32();
            reply->writeInt32(livesLocally(node, pid));

 return OK;
 }

 case LIST_NODES:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

 List<ComponentInfo> list;
            listNodes(&list);

            reply->writeInt32(list.size());
 for (List<ComponentInfo>::iterator it = list.begin();
                 it != list.end(); ++it) {
 ComponentInfo &cur = *it;

                reply->writeString8(cur.mName);
                reply->writeInt32(cur.mRoles.size());
 for (List<String8>::iterator role_it = cur.mRoles.begin();
                     role_it != cur.mRoles.end(); ++role_it) {
                    reply->writeString8(*role_it);
 }
 }

 return NO_ERROR;
 }

 case ALLOCATE_NODE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

 const char *name = data.readCString();

            sp<IOMXObserver> observer =
                interface_cast<IOMXObserver>(data.readStrongBinder());

            node_id node;

 status_t err = allocateNode(name, observer, &node);
            reply->writeInt32(err);
 if (err == OK) {
                reply->writeInt32((int32_t)node);
 }

 return NO_ERROR;
 }

 case FREE_NODE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();

            reply->writeInt32(freeNode(node));

 return NO_ERROR;
 }

 case SEND_COMMAND:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();

            OMX_COMMANDTYPE cmd =
 static_cast<OMX_COMMANDTYPE>(data.readInt32());

            OMX_S32 param = data.readInt32();
            reply->writeInt32(sendCommand(node, cmd, param));

 return NO_ERROR;
 }

 case GET_PARAMETER:
 case SET_PARAMETER:
 case GET_CONFIG:
 case SET_CONFIG:
 case SET_INTERNAL_OPTION:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_INDEXTYPE index = static_cast<OMX_INDEXTYPE>(data.readInt32());

 
             size_t size = data.readInt64();
 
            void *params = malloc(size);
            data.read(params, size);
 
            status_t err;
            switch (code) {
                case GET_PARAMETER:
                    err = getParameter(node, index, params, size);
                    break;
                case SET_PARAMETER:
                    err = setParameter(node, index, params, size);
                    break;
                case GET_CONFIG:
                    err = getConfig(node, index, params, size);
                    break;
                case SET_CONFIG:
                    err = setConfig(node, index, params, size);
                    break;
                case SET_INTERNAL_OPTION:
                {
                    InternalOptionType type =
                        (InternalOptionType)data.readInt32();
 
                    err = setInternalOption(node, index, type, params, size);
                    break;
                 }
                default:
                    TRESPASS();
             }
 
             reply->writeInt32(err);

 if ((code == GET_PARAMETER || code == GET_CONFIG) && err == OK) {
                reply->write(params, size);
 }

            free(params);
            params = NULL;

 return NO_ERROR;
 }

 case GET_STATE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_STATETYPE state = OMX_StateInvalid;

 status_t err = getState(node, &state);
            reply->writeInt32(state);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case ENABLE_GRAPHIC_BUFFERS:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            OMX_BOOL enable = (OMX_BOOL)data.readInt32();

 status_t err = enableGraphicBuffers(node, port_index, enable);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case GET_GRAPHIC_BUFFER_USAGE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();

            OMX_U32 usage = 0;
 status_t err = getGraphicBufferUsage(node, port_index, &usage);
            reply->writeInt32(err);
            reply->writeInt32(usage);

 return NO_ERROR;
 }

 case USE_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            sp<IMemory> params =
                interface_cast<IMemory>(data.readStrongBinder());

            buffer_id buffer;
 status_t err = useBuffer(node, port_index, params, &buffer);
            reply->writeInt32(err);

 if (err == OK) {
                reply->writeInt32((int32_t)buffer);
 }

 return NO_ERROR;
 }

 case USE_GRAPHIC_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
            data.read(*graphicBuffer);

            buffer_id buffer;
 status_t err = useGraphicBuffer(
                    node, port_index, graphicBuffer, &buffer);
            reply->writeInt32(err);

 if (err == OK) {
                reply->writeInt32((int32_t)buffer);
 }

 return NO_ERROR;
 }

 case UPDATE_GRAPHIC_BUFFER_IN_META:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            sp<GraphicBuffer> graphicBuffer = new GraphicBuffer();
            data.read(*graphicBuffer);
            buffer_id buffer = (buffer_id)data.readInt32();

 status_t err = updateGraphicBufferInMeta(
                    node, port_index, graphicBuffer, buffer);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case CREATE_INPUT_SURFACE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();

            sp<IGraphicBufferProducer> bufferProducer;
 status_t err = createInputSurface(node, port_index,
 &bufferProducer);

            reply->writeInt32(err);

 if (err == OK) {
                reply->writeStrongBinder(bufferProducer->asBinder());
 }

 return NO_ERROR;
 }

 case SIGNAL_END_OF_INPUT_STREAM:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();

 status_t err = signalEndOfInputStream(node);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case STORE_META_DATA_IN_BUFFERS:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            OMX_BOOL enable = (OMX_BOOL)data.readInt32();

 status_t err = storeMetaDataInBuffers(node, port_index, enable);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case PREPARE_FOR_ADAPTIVE_PLAYBACK:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            OMX_BOOL enable = (OMX_BOOL)data.readInt32();
            OMX_U32 max_width = data.readInt32();
            OMX_U32 max_height = data.readInt32();

 status_t err = prepareForAdaptivePlayback(
                    node, port_index, enable, max_width, max_height);
            reply->writeInt32(err);

 return NO_ERROR;
 }

 case CONFIGURE_VIDEO_TUNNEL_MODE:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            OMX_BOOL tunneled = (OMX_BOOL)data.readInt32();
            OMX_U32 audio_hw_sync = data.readInt32();

 native_handle_t *sideband_handle = NULL;
 status_t err = configureVideoTunnelMode(
                    node, port_index, tunneled, audio_hw_sync, &sideband_handle);
            reply->writeInt32(err);
 if(err == OK){
                reply->writeNativeHandle(sideband_handle);
 }

 return NO_ERROR;
 }

 case ALLOC_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
 if (!isSecure(node) || port_index != 0 /* kPortIndexInput */) {
                ALOGE("b/24310423");
                reply->writeInt32(INVALID_OPERATION);
 return NO_ERROR;
 }

 size_t size = data.readInt64();

            buffer_id buffer;
 void *buffer_data;
 status_t err = allocateBuffer(
                    node, port_index, size, &buffer, &buffer_data);
            reply->writeInt32(err);

 if (err == OK) {
                reply->writeInt32((int32_t)buffer);
                reply->writeInt64((uintptr_t)buffer_data);
 }

 return NO_ERROR;
 }

 case ALLOC_BUFFER_WITH_BACKUP:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            sp<IMemory> params =
                interface_cast<IMemory>(data.readStrongBinder());

            buffer_id buffer;
 status_t err = allocateBufferWithBackup(
                    node, port_index, params, &buffer);

            reply->writeInt32(err);

 if (err == OK) {
                reply->writeInt32((int32_t)buffer);
 }

 return NO_ERROR;
 }

 case FREE_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            OMX_U32 port_index = data.readInt32();
            buffer_id buffer = (buffer_id)data.readInt32();
            reply->writeInt32(freeBuffer(node, port_index, buffer));

 return NO_ERROR;
 }

 case FILL_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            buffer_id buffer = (buffer_id)data.readInt32();
            reply->writeInt32(fillBuffer(node, buffer));

 return NO_ERROR;
 }

 case EMPTY_BUFFER:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
            buffer_id buffer = (buffer_id)data.readInt32();
            OMX_U32 range_offset = data.readInt32();
            OMX_U32 range_length = data.readInt32();
            OMX_U32 flags = data.readInt32();
            OMX_TICKS timestamp = data.readInt64();

            reply->writeInt32(
                    emptyBuffer(
                        node, buffer, range_offset, range_length,
                        flags, timestamp));

 return NO_ERROR;
 }

 case GET_EXTENSION_INDEX:
 {
            CHECK_OMX_INTERFACE(IOMX, data, reply);

            node_id node = (node_id)data.readInt32();
 const char *parameter_name = data.readCString();

            OMX_INDEXTYPE index;
 status_t err = getExtensionIndex(node, parameter_name, &index);

            reply->writeInt32(err);

 if (err == OK) {
                reply->writeInt32(index);
 }

 return OK;
 }

 default:
 return BBinder::onTransact(code, data, reply, flags);
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static i32 ComparePictures(const void *ptr1, const void *ptr2)
{

/* Variables */

 dpbPicture_t *pic1, *pic2;

/* Code */

    ASSERT(ptr1);
    ASSERT(ptr2);

    pic1 = (dpbPicture_t*)ptr1;
    pic2 = (dpbPicture_t*)ptr2;

 /* both are non-reference pictures, check if needed for display */
 if (!IS_REFERENCE(*pic1) && !IS_REFERENCE(*pic2))
 {
 if (pic1->toBeDisplayed && !pic2->toBeDisplayed)
 return(-1);
 else if (!pic1->toBeDisplayed && pic2->toBeDisplayed)
 return(1);
 else
 return(0);
 }
 /* only pic 1 needed for reference -> greater */
 else if (!IS_REFERENCE(*pic2))
 return(-1);
 /* only pic 2 needed for reference -> greater */
 else if (!IS_REFERENCE(*pic1))
 return(1);
 /* both are short term reference pictures -> check picNum */
 else if (IS_SHORT_TERM(*pic1) && IS_SHORT_TERM(*pic2))
 {
 if (pic1->picNum > pic2->picNum)
 return(-1);
 else if (pic1->picNum < pic2->picNum)
 return(1);
 else
 return(0);
 }
 /* only pic 1 is short term -> greater */
 else if (IS_SHORT_TERM(*pic1))
 return(-1);
 /* only pic 2 is short term -> greater */
 else if (IS_SHORT_TERM(*pic2))
 return(1);
 /* both are long term reference pictures -> check picNum (contains the
     * longTermPicNum */
 else
 {
 if (pic1->picNum > pic2->picNum)
 return(1);
 else if (pic1->picNum < pic2->picNum)
 return(-1);
 else
 return(0);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::allocate_input_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes)
{
 (void)hComp, (void)port;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned   i = 0;

    DEBUG_PRINT_HIGH("allocate_input_buffer()::");
 if (bytes != m_sInPortDef.nBufferSize) {
        DEBUG_PRINT_ERROR("ERROR: Buffer size mismatch error: bytes[%u] != nBufferSize[%u]",
 (unsigned int)bytes, (unsigned int)m_sInPortDef.nBufferSize);
 return OMX_ErrorBadParameter;
 }

 if (!m_inp_mem_ptr) {
        DEBUG_PRINT_HIGH("%s: size = %u, actual cnt %u", __FUNCTION__,
 (unsigned int)m_sInPortDef.nBufferSize, (unsigned int)m_sInPortDef.nBufferCountActual);
        m_inp_mem_ptr = (OMX_BUFFERHEADERTYPE*) \
                        calloc( (sizeof(OMX_BUFFERHEADERTYPE)), m_sInPortDef.nBufferCountActual);
 if (m_inp_mem_ptr == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_inp_mem_ptr");
 return OMX_ErrorInsufficientResources;
 }

        DEBUG_PRINT_LOW("Successfully allocated m_inp_mem_ptr = %p", m_inp_mem_ptr);
        m_pInput_pmem = (struct pmem *) calloc(sizeof (struct pmem), m_sInPortDef.nBufferCountActual);

 if (m_pInput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_pmem");
 return OMX_ErrorInsufficientResources;
 }
#ifdef USE_ION
        m_pInput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sInPortDef.nBufferCountActual);
 if (m_pInput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif
 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
            m_pInput_pmem[i].fd = -1;
#ifdef USE_ION
            m_pInput_ion[i].ion_device_fd =-1;
            m_pInput_ion[i].fd_ion_data.fd =-1;
            m_pInput_ion[i].ion_alloc_data.handle = 0;
#endif
 }
 }

 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_inp_bm_count,i)) {
 break;
 }
 }
 if (i < m_sInPortDef.nBufferCountActual) {

 *bufferHdr = (m_inp_mem_ptr + i);
 (*bufferHdr)->nSize             = sizeof(OMX_BUFFERHEADERTYPE);
 (*bufferHdr)->nVersion.nVersion = OMX_SPEC_VERSION;
 (*bufferHdr)->nAllocLen         = m_sInPortDef.nBufferSize;
 (*bufferHdr)->pAppPrivate       = appData;
 (*bufferHdr)->nInputPortIndex   = PORT_INDEX_IN;
 (*bufferHdr)->pInputPortPrivate = (OMX_PTR)&m_pInput_pmem[i];

#ifdef USE_ION
#ifdef _MSM8974_
        m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,0);
#else
        m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pInput_ion[i].ion_device_fd < 0) {
            DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }

        m_pInput_pmem[i].fd = m_pInput_ion[i].fd_ion_data.fd;
#else
        m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);

 if (m_pInput_pmem[i].fd == 0) {
            m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pInput_pmem[i].fd < 0) {
            DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() Failed");
 return OMX_ErrorInsufficientResources;
 }
#endif
        m_pInput_pmem[i].size = m_sInPortDef.nBufferSize;
        m_pInput_pmem[i].offset = 0;

        m_pInput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
 if(!secure_session) {
            m_pInput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                m_pInput_pmem[i].size,PROT_READ|PROT_WRITE,
                MAP_SHARED,m_pInput_pmem[i].fd,0);
 if (m_pInput_pmem[i].buffer == MAP_FAILED) {
                DEBUG_PRINT_ERROR("ERROR: mmap FAILED= %d", errno);
            close(m_pInput_pmem[i].fd);
#ifdef USE_ION
            free_ion_memory(&m_pInput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 } else {

             m_pInput_pmem[i].buffer = malloc(sizeof(OMX_U32) + sizeof(native_handle_t*));
         }
 
         (*bufferHdr)->pBuffer           = (OMX_U8 *)m_pInput_pmem[i].buffer;
        DEBUG_PRINT_LOW("Virtual address in allocate buffer is %p", m_pInput_pmem[i].buffer);
        BITMASK_SET(&m_inp_bm_count,i);
 if (!mUseProxyColorFormat && (dev_use_buf(&m_pInput_pmem[i],PORT_INDEX_IN,i) != true)) {
            DEBUG_PRINT_ERROR("ERROR: dev_use_buf FAILED for i/p buf");
 return OMX_ErrorInsufficientResources;
 }
 } else {
        DEBUG_PRINT_ERROR("ERROR: All i/p buffers are allocated, invalid allocate buf call"
 "for index [%d]", i);
        eRet = OMX_ErrorInsufficientResources;
 }

 return eRet;
}

Labels: Yes
----------------lora model----------------
Response: </s>


Instruction: 
Input: static void *listen_fn_(UNUSED_ATTR void *context) {

  prctl(PR_SET_NAME, (unsigned long)LISTEN_THREAD_NAME_, 0, 0, 0);

  listen_socket_ = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
 if (listen_socket_ == -1) {
    LOG_ERROR("%s socket creation failed: %s", __func__, strerror(errno));
 goto cleanup;
 }

 int enable = 1;
 if (setsockopt(listen_socket_, SOL_SOCKET, SO_REUSEADDR, &enable, sizeof(enable)) == -1) {
    LOG_ERROR("%s unable to set SO_REUSEADDR: %s", __func__, strerror(errno));
 goto cleanup;
 }

 struct sockaddr_in addr;
  addr.sin_family = AF_INET;
  addr.sin_addr.s_addr = htonl(LOCALHOST_);
  addr.sin_port = htons(LISTEN_PORT_);
 if (bind(listen_socket_, (struct sockaddr *)&addr, sizeof(addr)) == -1) {
    LOG_ERROR("%s unable to bind listen socket: %s", __func__, strerror(errno));
 goto cleanup;
 }

 if (listen(listen_socket_, 10) == -1) {
    LOG_ERROR("%s unable to listen: %s", __func__, strerror(errno));
 goto cleanup;

   }
 
   for (;;) {
    int client_socket = accept(listen_socket_, NULL, NULL);
     if (client_socket == -1) {
       if (errno == EINVAL || errno == EBADF) {
         break;
 }
      LOG_WARN("%s error accepting socket: %s", __func__, strerror(errno));
 continue;
 }

 /* When a new client connects, we have to send the btsnoop file header. This allows
       a decoder to treat the session as a new, valid btsnoop file. */

     pthread_mutex_lock(&client_socket_lock_);
     safe_close_(&client_socket_);
     client_socket_ = client_socket;
    send(client_socket_, "btsnoop\0\0\0\0\1\0\0\x3\xea", 16, 0);
     pthread_mutex_unlock(&client_socket_lock_);
   }
 
cleanup:
  safe_close_(&listen_socket_);
 return NULL;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   void RunInvTxfm(int16_t *out, uint8_t *dst, int stride) {
     inv_txfm_(out, dst, stride, tx_type_);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void btif_dm_search_services_evt(UINT16 event, char *p_param)
{
    tBTA_DM_SEARCH *p_data = (tBTA_DM_SEARCH*)p_param;

    BTIF_TRACE_EVENT("%s:  event = %d", __FUNCTION__, event);
 switch (event)
 {
 case BTA_DM_DISC_RES_EVT:
 {
 bt_property_t prop;
 uint32_t i = 0;
 bt_bdaddr_t bd_addr;
 bt_status_t ret;

            bdcpy(bd_addr.address, p_data->disc_res.bd_addr);

            BTIF_TRACE_DEBUG("%s:(result=0x%x, services 0x%x)", __FUNCTION__,
                    p_data->disc_res.result, p_data->disc_res.services);
 if ((p_data->disc_res.result != BTA_SUCCESS) &&
 (pairing_cb.state == BT_BOND_STATE_BONDING ) &&
 (pairing_cb.sdp_attempts < BTIF_DM_MAX_SDP_ATTEMPTS_AFTER_PAIRING))
 {
                BTIF_TRACE_WARNING("%s:SDP failed after bonding re-attempting", __FUNCTION__);
                pairing_cb.sdp_attempts++;
                btif_dm_get_remote_services(&bd_addr);
 return;
 }
            prop.type = BT_PROPERTY_UUIDS;
            prop.len = 0;
 if ((p_data->disc_res.result == BTA_SUCCESS) && (p_data->disc_res.num_uuids > 0))
 {
                 prop.val = p_data->disc_res.p_uuid_list;
                 prop.len = p_data->disc_res.num_uuids * MAX_UUID_SIZE;
 for (i=0; i < p_data->disc_res.num_uuids; i++)
 {
 char temp[256];
                      uuid_to_string_legacy((bt_uuid_t*)(p_data->disc_res.p_uuid_list + (i*MAX_UUID_SIZE)), temp);
                      LOG_INFO("%s index:%d uuid:%s", __func__, i, temp);
 }
 }

 /* onUuidChanged requires getBondedDevices to be populated.
            ** bond_state_changed needs to be sent prior to remote_device_property
            */
 if ((pairing_cb.state == BT_BOND_STATE_BONDING) &&
 ((bdcmp(p_data->disc_res.bd_addr, pairing_cb.bd_addr) == 0) ||
 (bdcmp(p_data->disc_res.bd_addr, pairing_cb.static_bdaddr.address) == 0)) &&
                  pairing_cb.sdp_attempts > 0)
 {
                 BTIF_TRACE_DEBUG("%s Remote Service SDP done. Call bond_state_changed_cb BONDED",
                                   __FUNCTION__);
                 pairing_cb.sdp_attempts  = 0;

 if (bdcmp(p_data->disc_res.bd_addr, pairing_cb.static_bdaddr.address) == 0)
                    bond_state_changed(BT_STATUS_SUCCESS, &bd_addr, BT_BOND_STATE_BONDING);

                 bond_state_changed(BT_STATUS_SUCCESS, &bd_addr, BT_BOND_STATE_BONDED);
 }

 if (p_data->disc_res.num_uuids != 0)
 {
 /* Also write this to the NVRAM */
                ret = btif_storage_set_remote_device_property(&bd_addr, &prop);
                ASSERTC(ret == BT_STATUS_SUCCESS, "storing remote services failed", ret);
 /* Send the event to the BTIF */
                HAL_CBACK(bt_hal_cbacks, remote_device_properties_cb,
                                 BT_STATUS_SUCCESS, &bd_addr, 1, &prop);
 }
 }
 break;

 case BTA_DM_DISC_CMPL_EVT:
 /* fixme */
 break;

#if (defined(BLE_INCLUDED) && (BLE_INCLUDED == TRUE))
 case BTA_DM_DISC_BLE_RES_EVT:
             BTIF_TRACE_DEBUG("%s:, services 0x%x)", __FUNCTION__,
                                p_data->disc_ble_res.service.uu.uuid16);
 bt_uuid_t  uuid;
 int i = 0;
 int j = 15;
 if (p_data->disc_ble_res.service.uu.uuid16 == UUID_SERVCLASS_LE_HID)
 {
                BTIF_TRACE_DEBUG("%s: Found HOGP UUID",__FUNCTION__);
 bt_property_t prop;
 bt_bdaddr_t bd_addr;
 char temp[256];
 bt_status_t ret;

                bta_gatt_convert_uuid16_to_uuid128(uuid.uu,p_data->disc_ble_res.service.uu.uuid16);

 while(i < j )
 {
 unsigned char c = uuid.uu[j];
                    uuid.uu[j] = uuid.uu[i];
                    uuid.uu[i] = c;
                    i++;
                    j--;
 }

                uuid_to_string_legacy(&uuid, temp);
                LOG_INFO("%s uuid:%s", __func__, temp);

                bdcpy(bd_addr.address, p_data->disc_ble_res.bd_addr);
                prop.type = BT_PROPERTY_UUIDS;
                prop.val = uuid.uu;
                prop.len = MAX_UUID_SIZE;

 /* Also write this to the NVRAM */
                ret = btif_storage_set_remote_device_property(&bd_addr, &prop);
                ASSERTC(ret == BT_STATUS_SUCCESS, "storing remote services failed", ret);

 /* Send the event to the BTIF */
                HAL_CBACK(bt_hal_cbacks, remote_device_properties_cb,
                                 BT_STATUS_SUCCESS, &bd_addr, 1, &prop);

 }
 break;
#endif /* BLE_INCLUDED */

 default:
 {
            ASSERTC(0, "unhandled search services event", event);
 }
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int LE_command(effect_handle_t self, uint32_t cmdCode, uint32_t cmdSize,
 void *pCmdData, uint32_t *replySize, void *pReplyData) {

 LoudnessEnhancerContext * pContext = (LoudnessEnhancerContext *)self;
 int retsize;

 if (pContext == NULL || pContext->mState == LOUDNESS_ENHANCER_STATE_UNINITIALIZED) {
 return -EINVAL;
 }

 switch (cmdCode) {
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 *(int *) pReplyData = LE_init(pContext);

         break;
     case EFFECT_CMD_SET_CONFIG:
         if (pCmdData == NULL || cmdSize != sizeof(effect_config_t)
                || pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         *(int *) pReplyData = LE_setConfig(pContext,
 (effect_config_t *) pCmdData);
 break;
 case EFFECT_CMD_GET_CONFIG:
 if (pReplyData == NULL ||
 *replySize != sizeof(effect_config_t)) {
 return -EINVAL;
 }
        LE_getConfig(pContext, (effect_config_t *)pReplyData);
 break;
 case EFFECT_CMD_RESET:

         LE_reset(pContext);
         break;
     case EFFECT_CMD_ENABLE:
        if (pReplyData == NULL || *replySize != sizeof(int)) {
             return -EINVAL;
         }
         if (pContext->mState != LOUDNESS_ENHANCER_STATE_INITIALIZED) {
 return -ENOSYS;
 }
        pContext->mState = LOUDNESS_ENHANCER_STATE_ACTIVE;
        ALOGV("EFFECT_CMD_ENABLE() OK");
 *(int *)pReplyData = 0;
 break;
 case EFFECT_CMD_DISABLE:
 if (pReplyData == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 if (pContext->mState != LOUDNESS_ENHANCER_STATE_ACTIVE) {
 return -ENOSYS;
 }
        pContext->mState = LOUDNESS_ENHANCER_STATE_INITIALIZED;
        ALOGV("EFFECT_CMD_DISABLE() OK");
 *(int *)pReplyData = 0;
 break;

     case EFFECT_CMD_GET_PARAM: {
         if (pCmdData == NULL ||
             cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t)) ||
            pReplyData == NULL ||
             *replySize < (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t))) {
             return -EINVAL;
         }
        memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + sizeof(uint32_t));
 effect_param_t *p = (effect_param_t *)pReplyData;
        p->status = 0;
 *replySize = sizeof(effect_param_t) + sizeof(uint32_t);
 if (p->psize != sizeof(uint32_t)) {
            p->status = -EINVAL;
 break;
 }
 switch (*(uint32_t *)p->data) {
 case LOUDNESS_ENHANCER_PARAM_TARGET_GAIN_MB:
            ALOGV("get target gain(mB) = %d", pContext->mTargetGainmB);
 *((int32_t *)p->data + 1) = pContext->mTargetGainmB;
            p->vsize = sizeof(int32_t);
 *replySize += sizeof(int32_t);
 break;
 default:
            p->status = -EINVAL;
 }
 } break;

     case EFFECT_CMD_SET_PARAM: {
         if (pCmdData == NULL ||
             cmdSize != (int)(sizeof(effect_param_t) + sizeof(uint32_t) + sizeof(uint32_t)) ||
            pReplyData == NULL || *replySize != sizeof(int32_t)) {
             return -EINVAL;
         }
         *(int32_t *)pReplyData = 0;
 effect_param_t *p = (effect_param_t *)pCmdData;
 if (p->psize != sizeof(uint32_t) || p->vsize != sizeof(uint32_t)) {
 *(int32_t *)pReplyData = -EINVAL;
 break;
 }
 switch (*(uint32_t *)p->data) {
 case LOUDNESS_ENHANCER_PARAM_TARGET_GAIN_MB:
            pContext->mTargetGainmB = *((int32_t *)p->data + 1);
            ALOGV("set target gain(mB) = %d", pContext->mTargetGainmB);
            LE_reset(pContext); // apply parameter update
 break;
 default:
 *(int32_t *)pReplyData = -EINVAL;
 }
 } break;
 case EFFECT_CMD_SET_DEVICE:
 case EFFECT_CMD_SET_VOLUME:
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;

 default:
        ALOGW("LE_command invalid command %d",cmdCode);
 return -EINVAL;
 }

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::notifyPreparedAndCleanup(status_t err) {
 if (err != OK) {
        mMetaDataSize = -1ll;
        mContentType = "";
        mSniffedMIME = "";
 {
            sp<DataSource> dataSource = mDataSource;
            sp<NuCachedSource2> cachedSource = mCachedSource;
            sp<DataSource> httpSource = mHttpSource;

             {
                 Mutex::Autolock _l(mDisconnectLock);
                 mDataSource.clear();
                 mCachedSource.clear();
                 mHttpSource.clear();
             }
 }

        cancelPollBuffering();
 }
    notifyPrepared(err);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int CameraService::getDeviceVersion(int cameraId, int* facing) {
 struct camera_info info;
 if (mModule->get_camera_info(cameraId, &info) != OK) {
 return -1;
 }

 int deviceVersion;
 if (mModule->common.module_api_version >= CAMERA_MODULE_API_VERSION_2_0) {
        deviceVersion = info.device_version;
 } else {
        deviceVersion = CAMERA_DEVICE_API_VERSION_1_0;
 }

 if (facing) {
 *facing = info.facing;
 }

 return deviceVersion;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void packet_finished(UNUSED_ATTR serial_data_type_t type) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long _book_maptype1_quantvals(codebook *b){
 /* get us a starting hint, we'll polish it below */
 int bits=_ilog(b->entries);
 int vals=b->entries>>((bits-1)*(b->dim-1)/b->dim);

 while(1){
 long acc=1;
 long acc1=1;
 int i;
 for(i=0;i<b->dim;i++){
      acc*=vals;
      acc1*=vals+1;
 }
 if(acc<=b->entries && acc1>b->entries){
 return(vals);
 }else{
 if(acc>b->entries){
        vals--;
 }else{
        vals++;
 }
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  bool adapter_enable_disable() {
   int error;
 
  CALL_AND_WAIT(error = bt_interface->enable(), adapter_state_changed);
   TASSERT(error == BT_STATUS_SUCCESS, "Error enabling Bluetooth: %d", error);
   TASSERT(adapter_get_state() == BT_STATE_ON, "Adapter did not turn on.");
 
  CALL_AND_WAIT(error = bt_interface->disable(), adapter_state_changed);
  TASSERT(error == BT_STATUS_SUCCESS, "Error disabling Bluetooth: %d", error);
  TASSERT(adapter_get_state() == BT_STATE_OFF, "Adapter did not turn off.");

 return true;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: one_file(struct global *global, const char *file_name, const char *out_name)
{
 int rc;
 struct control control;

 if (global->verbose)
      fprintf(stderr, "FILE %s -> %s\n", file_name,
         out_name ? out_name : "<none>");

 /* Although control_init can return a failure code the structure is always
    * initialized, so control_end can be used to accumulate any status codes.
    */
   rc = control_init(&control, global, file_name, out_name);

 if (rc == 0)
      rc = read_png(&control);

   rc |= control_end(&control);

 return rc;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Chapters::Display::Parse(
    IMkvReader* pReader,
    long long pos,
    long long size)
{
    const long long stop = pos + size;
    while (pos < stop)
    {
        long long id, size;
        long status = ParseElementHeader(
                        pReader,
                        pos,
                        stop,
                        id,
                        size);
        if (status < 0)  // error
            return status;
        if (size == 0)  // weird
            continue;
        if (id == 0x05)  // ChapterString ID
        {
            status = UnserializeString(pReader, pos, size, m_string);
            if (status)
              return status;
        }
        else if (id == 0x037C)  // ChapterLanguage ID
        {
            status = UnserializeString(pReader, pos, size, m_language);
            if (status)
              return status;
        }
        else if (id == 0x037E)  // ChapterCountry ID
        {
            status = UnserializeString(pReader, pos, size, m_country);
            if (status)
              return status;
        }
        pos += size;
        assert(pos <= stop);
    }
    assert(pos == stop);
    return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bt_status_t btif_storage_get_remote_addr_type(bt_bdaddr_t *remote_bd_addr,
 int*addr_type)
{
 bdstr_t bdstr;
    bdaddr_to_string(remote_bd_addr, bdstr, sizeof(bdstr));
 int ret = btif_config_get_int(bdstr, "AddrType", addr_type);
 return ret ? BT_STATUS_SUCCESS : BT_STATUS_FAIL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::Init() {
    RETURN_IF_NOT_OK(flushInterfaces());
 XfrmSocketImpl sock;
    RETURN_IF_NOT_OK(sock.open());
    RETURN_IF_NOT_OK(flushSaDb(sock));
 return flushPolicyDb(sock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void create_EXIF_internal(ExifElement_t* elements, int exifTagCount, int gpsTagCount, int hasDateTimeTag, char* Buffer)
{
 unsigned short NumEntries;
 int DataWriteIndex;
 int DirIndex;
 int DirExifLink = 0;

#ifdef SUPERDEBUG
    ALOGE("create_EXIF %d exif elements, %d gps elements", exifTagCount, gpsTagCount);
#endif

 MotorolaOrder = 0;

    memcpy(Buffer+2, "Exif\0\0II",8);
 Put16u(Buffer+10, 0x2a);

 DataWriteIndex = 16;
 Put32u(Buffer+12, DataWriteIndex-8); // first IFD offset.  Means start 16 bytes in.

 {
 DirIndex = DataWriteIndex;
 NumEntries = 1 + exifTagCount; // the extra is the thumbnail
 if (gpsTagCount) {
 ++NumEntries; // allow for the GPS info tag
 }
 if (!hasDateTimeTag) {
 ++NumEntries;
 }
 DataWriteIndex += 2 + NumEntries*12 + 4;

 Put16u(Buffer+DirIndex, NumEntries); // Number of entries
 DirIndex += 2;

 if (!hasDateTimeTag) {
 char* dateTime = NULL;
 char dateBuf[20];
 if (ImageInfo.numDateTimeTags) {
                dateTime = ImageInfo.DateTime;
 } else {
 FileTimeAsString(dateBuf);
                dateTime = dateBuf;
 }
            writeExifTagAndData(TAG_DATETIME,
                                FMT_STRING,
 20,
 (long)(char*)dateBuf,
                                FALSE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);

 }
 if (exifTagCount > 0) {
 int i;
 for (i = 0; i < exifTagCount + gpsTagCount; i++) {
 if (elements[i].GpsTag) {
 continue;
 }
 const TagTable_t* entry = TagToTagTableEntry(elements[i].Tag);
 if (entry == NULL) {
 continue;
 }
#ifdef SUPERDEBUG
                ALOGE("create_EXIF saving tag %x value \"%s\"",elements[i].Tag, elements[i].Value);
#endif
                writeExifTagAndData(elements[i].Tag,
                                    entry->Format,
                                    entry->DataLength,
 (long)elements[i].Value,
                                    TRUE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }

 if (gpsTagCount) {
                writeExifTagAndData(TAG_GPSINFO,
                                    FMT_ULONG,
 1,
 DataWriteIndex-8,
                                    FALSE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }

 int exifDirPtr = DataWriteIndex-8;
 if (gpsTagCount) {
                exifDirPtr += 2 + gpsTagCount*12 + 4;
 }
 DirExifLink = DirIndex;
            writeExifTagAndData(TAG_EXIF_OFFSET,
                                FMT_ULONG,
 1,
                                exifDirPtr,
                                FALSE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }

 Put32u(Buffer+DirIndex, 0);
        printf("Ending Exif section DirIndex = %d DataWriteIndex %d", DirIndex, DataWriteIndex);
 }


 if (gpsTagCount) {
 DirIndex = DataWriteIndex;
        printf("Starting GPS section DirIndex = %d", DirIndex);
 NumEntries = gpsTagCount;
 DataWriteIndex += 2 + NumEntries*12 + 4;

 Put16u(Buffer+DirIndex, NumEntries); // Number of entries
 DirIndex += 2;
 {
 int i;
 for (i = 0; i < exifTagCount + gpsTagCount; i++) {
 if (!elements[i].GpsTag) {
 continue;
 }
 const TagTable_t* entry = GpsTagToTagTableEntry(elements[i].Tag);
 if (entry == NULL) {
 continue;
 }
#ifdef SUPERDEBUG
                ALOGE("create_EXIF saving GPS tag %x value \"%s\"",elements[i].Tag, elements[i].Value);
#endif
                writeExifTagAndData(elements[i].Tag,
                                    entry->Format,
                                    entry->DataLength,
 (long)elements[i].Value,
                                    TRUE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }
 }

 Put32u(Buffer+DirIndex, 0);
        printf("Ending GPS section DirIndex = %d DataWriteIndex %d", DirIndex, DataWriteIndex);
 }

 {
 Put32u(Buffer+DirExifLink+8, DataWriteIndex-8);

        printf("Starting Thumbnail section DirIndex = %d", DirIndex);
 DirIndex = DataWriteIndex;
 NumEntries = 2;
 DataWriteIndex += 2 + NumEntries*12 + 4;

 Put16u(Buffer+DirIndex, NumEntries); // Number of entries
 DirIndex += 2;
 {
            writeExifTagAndData(TAG_THUMBNAIL_OFFSET,
                                FMT_ULONG,
 1,
 DataWriteIndex-8,
                                FALSE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }

 {
            writeExifTagAndData(TAG_THUMBNAIL_LENGTH,
                                FMT_ULONG,
 1,
 0,
                                FALSE,
 Buffer,
 &DirIndex,
 &DataWriteIndex);
 }

 Put32u(Buffer+DirIndex, 0);
        printf("Ending Thumbnail section DirIndex = %d DataWriteIndex %d", DirIndex, DataWriteIndex);
 }


 Buffer[0] = (unsigned char)(DataWriteIndex >> 8);
 Buffer[1] = (unsigned char)DataWriteIndex;

 RemoveSectionType(M_EXIF);

 {
 unsigned char * NewBuf = malloc(DataWriteIndex);
 if (NewBuf == NULL){
 ErrFatal("Could not allocate memory");
 }
        memcpy(NewBuf, Buffer, DataWriteIndex);

 CreateSection(M_EXIF, NewBuf, DataWriteIndex);

        process_EXIF(NewBuf, DataWriteIndex);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_process_keypress_notification(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = (uint8_t*)p_data;

   uint8_t reason = SMP_INVALID_PARAMETERS;
 
   SMP_TRACE_DEBUG("%s", __func__);
  p_cb->status = *(uint8_t*)p_data;
 
   if (smp_command_has_invalid_parameters(p_cb)) {
     smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &reason);
     return;
   }
 
   if (p != NULL) {
     STREAM_TO_UINT8(p_cb->peer_keypress_notification, p);
   } else {
    p_cb->peer_keypress_notification = BTM_SP_KEY_OUT_OF_RANGE;
 }
  p_cb->cb_evt = SMP_PEER_KEYPR_NOT_EVT;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool check_mac_perms_from_getcon(pid_t spid, uid_t uid, const char *perm)
{
 if (selinux_enabled <= 0) {
 return true;
 }

 return check_mac_perms(spid, uid, service_manager_context, perm, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void* H264SwDecMalloc(u32 size) {
    return malloc(size);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraClient::enableShutterSound(bool enable) {
    LOG1("enableShutterSound (pid %d)", getCallingPid());

 status_t result = checkPidAndHardware();
 if (result != NO_ERROR) return result;

 if (enable) {
        mPlayShutterSound = true;
 return OK;
 }

 char value[PROPERTY_VALUE_MAX];
    property_get("ro.camera.sound.forced", value, "0");
 if (strcmp(value, "0") != 0) {
 if (getCallingPid() != getpid()) {
            ALOGE("Failed to disable shutter sound. Permission denied (pid %d)", getCallingPid());
 return PERMISSION_DENIED;
 }
 }

    mPlayShutterSound = false;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline void set_poll(poll_slot_t* ps, int fd, int type, int flags, uint32_t user_id)
{
    ps->pfd.fd = fd;
    ps->user_id = user_id;
 if(ps->type != 0 && ps->type != type)
        APPL_TRACE_ERROR("poll socket type should not changed! type was:%d, type now:%d", ps->type, type);
    ps->type = type;
    ps->flags = flags;
    ps->pfd.events = flags2pevents(flags);
    ps->pfd.revents = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: transform_enable(PNG_CONST char *name)
 {
    /* Everything starts out enabled, so if we see an 'enable' disabled
     * everything else the first time round.
    */
 static int all_disabled = 0;
 int found_it = 0;
   image_transform *list = image_transform_first;

 while (list != &image_transform_end)
 {
 if (strcmp(list->name, name) == 0)
 {
 list->enable = 1;
         found_it = 1;
 }
 else if (!all_disabled)
 list->enable = 0;

 list = list->list;
 }

   all_disabled = 1;

 if (!found_it)
 {
      fprintf(stderr, "pngvalid: --transform-enable=%s: unknown transform\n",
         name);
      exit(99);
 }

 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool InputDispatcher::checkInjectionPermission(const sp<InputWindowHandle>& windowHandle,
 const InjectionState* injectionState) {
 if (injectionState
 && (windowHandle == NULL
 || windowHandle->getInfo()->ownerUid != injectionState->injectorUid)
 && !hasInjectionPermission(injectionState->injectorPid, injectionState->injectorUid)) {
 if (windowHandle != NULL) {
            ALOGW("Permission denied: injecting event from pid %d uid %d to window %s "
 "owned by uid %d",
                    injectionState->injectorPid, injectionState->injectorUid,
                    windowHandle->getName().string(),
                    windowHandle->getInfo()->ownerUid);
 } else {
            ALOGW("Permission denied: injecting event from pid %d uid %d",
                    injectionState->injectorPid, injectionState->injectorUid);
 }
 return false;
 }
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int spacePop(xmlParserCtxtPtr ctxt) {
 int ret;
 if (ctxt->spaceNr <= 0) return(0);
    ctxt->spaceNr--;
 if (ctxt->spaceNr > 0)
	ctxt->space = &ctxt->spaceTab[ctxt->spaceNr - 1];
 else
        ctxt->space = &ctxt->spaceTab[0];
    ret = ctxt->spaceTab[ctxt->spaceNr];
    ctxt->spaceTab[ctxt->spaceNr] = -1;
 return(ret);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleIterator::getSampleSizeDirect(
 uint32_t sampleIndex, size_t *size) {
 *size = 0;

 if (sampleIndex >= mTable->mNumSampleSizes) {
 return ERROR_OUT_OF_RANGE;
 }

 if (mTable->mDefaultSampleSize > 0) {
 *size = mTable->mDefaultSampleSize;
 return OK;
 }

 switch (mTable->mSampleSizeFieldSize) {
 case 32:
 {
 if (mTable->mDataSource->readAt(
                        mTable->mSampleSizeOffset + 12 + 4 * sampleIndex,
                        size, sizeof(*size)) < (ssize_t)sizeof(*size)) {
 return ERROR_IO;
 }

 *size = ntohl(*size);
 break;
 }

 case 16:
 {
 uint16_t x;
 if (mTable->mDataSource->readAt(
                        mTable->mSampleSizeOffset + 12 + 2 * sampleIndex,
 &x, sizeof(x)) < (ssize_t)sizeof(x)) {
 return ERROR_IO;
 }

 *size = ntohs(x);
 break;
 }

 case 8:
 {
 uint8_t x;
 if (mTable->mDataSource->readAt(
                        mTable->mSampleSizeOffset + 12 + sampleIndex,
 &x, sizeof(x)) < (ssize_t)sizeof(x)) {
 return ERROR_IO;
 }

 *size = x;
 break;
 }

 default:
 {
            CHECK_EQ(mTable->mSampleSizeFieldSize, 4);

 uint8_t x;
 if (mTable->mDataSource->readAt(
                        mTable->mSampleSizeOffset + 12 + sampleIndex / 2,
 &x, sizeof(x)) < (ssize_t)sizeof(x)) {
 return ERROR_IO;
 }

 *size = (sampleIndex & 1) ? x & 0x0f : x >> 4;
 break;
 }
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioSource::read(
 MediaBuffer **out, const ReadOptions * /* options */) {
 Mutex::Autolock autoLock(mLock);
 *out = NULL;

 if (mInitCheck != OK) {
 return NO_INIT;
 }

 while (mStarted && mBuffersReceived.empty()) {
        mFrameAvailableCondition.wait(mLock);
 }
 if (!mStarted) {
 return OK;
 }
 MediaBuffer *buffer = *mBuffersReceived.begin();
    mBuffersReceived.erase(mBuffersReceived.begin());
 ++mNumClientOwnedBuffers;
    buffer->setObserver(this);
    buffer->add_ref();

 int64_t timeUs;
    CHECK(buffer->meta_data()->findInt64(kKeyTime, &timeUs));
 int64_t elapsedTimeUs = timeUs - mStartTimeUs;
 if (elapsedTimeUs < kAutoRampStartUs) {
        memset((uint8_t *) buffer->data(), 0, buffer->range_length());
 } else if (elapsedTimeUs < kAutoRampStartUs + kAutoRampDurationUs) {
 int32_t autoRampDurationFrames =
 ((int64_t)kAutoRampDurationUs * mSampleRate + 500000LL) / 1000000LL; //Need type casting

 int32_t autoRampStartFrames =
 ((int64_t)kAutoRampStartUs * mSampleRate + 500000LL) / 1000000LL; //Need type casting

 int32_t nFrames = mNumFramesReceived - autoRampStartFrames;
        rampVolume(nFrames, autoRampDurationFrames,
 (uint8_t *) buffer->data(), buffer->range_length());
 }

 if (mTrackMaxAmplitude) {
        trackMaxAmplitude(
 (int16_t *) buffer->data(), buffer->range_length() >> 1);
 }

 if (mSampleRate != mOutSampleRate) {
 if (mFirstSampleTimeUs < 0) {
            mFirstSampleTimeUs = timeUs;
 }
        timeUs = mFirstSampleTimeUs + (timeUs - mFirstSampleTimeUs)
 * (int64_t)mSampleRate / (int64_t)mOutSampleRate;
        buffer->meta_data()->setInt64(kKeyTime, timeUs);
 }

 *out = buffer;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_config_flush(void) {
  assert(config != NULL);
  assert(alarm_timer != NULL);

  alarm_cancel(alarm_timer);
  btif_config_write();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_decode_gaps_in_frame_num(dec_struct_t *ps_dec,
                                       UWORD16 u2_frame_num)
{
    UWORD32 u4_next_frm_num, u4_start_frm_num;
    UWORD32 u4_max_frm_num;
 pocstruct_t s_tmp_poc;
    WORD32 i4_poc;
 dec_slice_params_t *ps_cur_slice;

 dec_pic_params_t *ps_pic_params;
    WORD8 i1_gap_idx;
    WORD32 *i4_gaps_start_frm_num;
 dpb_manager_t *ps_dpb_mgr;
    WORD32 i4_frame_gaps;
    WORD8 *pi1_gaps_per_seq;
    WORD32 ret;

    ps_cur_slice = ps_dec->ps_cur_slice;
 if(ps_cur_slice->u1_field_pic_flag)
 {
 if(ps_dec->u2_prev_ref_frame_num == u2_frame_num)
 return 0;
 }

    u4_next_frm_num = ps_dec->u2_prev_ref_frame_num + 1;
    u4_max_frm_num = ps_dec->ps_cur_sps->u2_u4_max_pic_num_minus1 + 1;

 if(u4_next_frm_num >= u4_max_frm_num)
 {
        u4_next_frm_num -= u4_max_frm_num;
 }

 if(u4_next_frm_num == u2_frame_num)
 {
 return (0);
 }

 if((ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 && (u4_next_frm_num >= u2_frame_num))
 {
 return (0);
 }
    u4_start_frm_num = u4_next_frm_num;

    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[0] = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[1] = 0;

 
     ps_cur_slice = ps_dec->ps_cur_slice;
     ps_pic_params = ps_dec->ps_cur_pps;
    ps_cur_slice->u1_field_pic_flag = 0;
 
     i4_frame_gaps = 0;
     ps_dpb_mgr = ps_dec->ps_dpb_mgr;

 /* Find a empty slot to store gap seqn info */
    i4_gaps_start_frm_num = ps_dpb_mgr->ai4_gaps_start_frm_num;
 for(i1_gap_idx = 0; i1_gap_idx < MAX_FRAMES; i1_gap_idx++)
 {
 if(INVALID_FRAME_NUM == i4_gaps_start_frm_num[i1_gap_idx])
 break;
 }
 if(MAX_FRAMES == i1_gap_idx)
 {
        UWORD32 i4_error_code;
        i4_error_code = ERROR_DBP_MANAGER_T;
 return i4_error_code;
 }

    i4_poc = 0;
    i4_gaps_start_frm_num[i1_gap_idx] = u4_start_frm_num;
    ps_dpb_mgr->ai4_gaps_end_frm_num[i1_gap_idx] = u2_frame_num - 1;
    pi1_gaps_per_seq = ps_dpb_mgr->ai1_gaps_per_seq;
    pi1_gaps_per_seq[i1_gap_idx] = 0;
 while(u4_next_frm_num != u2_frame_num)
 {
        ih264d_delete_nonref_nondisplay_pics(ps_dpb_mgr);
 if(ps_pic_params->ps_sps->u1_pic_order_cnt_type)
 {
 /* allocate a picture buffer and insert it as ST node */
            ret = ih264d_decode_pic_order_cnt(0, u4_next_frm_num,
 &ps_dec->s_prev_pic_poc,
 &s_tmp_poc, ps_cur_slice,
                                              ps_pic_params, 1, 0, 0,
 &i4_poc);
 if(ret != OK)
 return ret;

 /* Display seq no calculations */
 if(i4_poc >= ps_dec->i4_max_poc)
                ps_dec->i4_max_poc = i4_poc;
 /* IDR Picture or POC wrap around */
 if(i4_poc == 0)
 {
                ps_dec->i4_prev_max_display_seq =
                                ps_dec->i4_prev_max_display_seq
 + ps_dec->i4_max_poc
 + ps_dec->u1_max_dec_frame_buffering
 + 1;
                ps_dec->i4_max_poc = 0;
 }

            ps_cur_slice->u1_mmco_equalto5 = 0;
            ps_cur_slice->u2_frame_num = u4_next_frm_num;
 }

 if(ps_dpb_mgr->i1_poc_buf_id_entries
 >= ps_dec->u1_max_dec_frame_buffering)
 {
            ret = ih264d_assign_display_seq(ps_dec);
 if(ret != OK)
 return ret;
 }

        ret = ih264d_insert_pic_in_display_list(
                        ps_dec->ps_dpb_mgr, (WORD8) DO_NOT_DISP,
 (WORD32)(ps_dec->i4_prev_max_display_seq + i4_poc),
                        u4_next_frm_num);
 if(ret != OK)
 return ret;

        pi1_gaps_per_seq[i1_gap_idx]++;
        ret = ih264d_do_mmco_for_gaps(ps_dpb_mgr,
                                ps_dec->ps_cur_sps->u1_num_ref_frames);
 if(ret != OK)
 return ret;

        ih264d_delete_nonref_nondisplay_pics(ps_dpb_mgr);

        u4_next_frm_num++;
 if(u4_next_frm_num >= u4_max_frm_num)
 {
            u4_next_frm_num -= u4_max_frm_num;
 }

        i4_frame_gaps++;
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int str16eq(const uint16_t *a, const char *b)
{
 while (*a && *b)
 if (*a++ != *b++) return 0;
 if (*a || *b)
 return 0;
 return 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static size_t GetCPUCoreCount() {
 long cpuCoreCount = 1;
#if defined(_SC_NPROCESSORS_ONLN)
    cpuCoreCount = sysconf(_SC_NPROCESSORS_ONLN);
#else
    cpuCoreCount = sysconf(_SC_NPROC_ONLN);
#endif
    CHECK(cpuCoreCount >= 1);
    ALOGV("Number of CPU cores: %ld", cpuCoreCount);
 return (size_t)cpuCoreCount;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::ipSecDeleteSecurityAssociation(
 int32_t transformId, const std::string& sourceAddress, const std::string& destinationAddress,
 int32_t spi, int32_t markValue, int32_t markMask) {
    ALOGD("XfrmController:%s, line=%d", __FUNCTION__, __LINE__);
    ALOGD("transformId=%d", transformId);
    ALOGD("sourceAddress=%s", sourceAddress.c_str());
    ALOGD("destinationAddress=%s", destinationAddress.c_str());
    ALOGD("spi=%0.8x", spi);
    ALOGD("markValue=%x", markValue);
    ALOGD("markMask=%x", markMask);

 XfrmId saId{};
    netdutils::Status ret =
        fillXfrmId(sourceAddress, destinationAddress, spi, markValue, markMask, transformId, &saId);
 if (!isOk(ret)) {
 return ret;
 }

 XfrmSocketImpl sock;
    netdutils::Status socketStatus = sock.open();
 if (!isOk(socketStatus)) {
        ALOGD("Sock open failed for XFRM, line=%d", __LINE__);
 return socketStatus;
 }

    ret = deleteSecurityAssociation(saId, sock);
 if (!isOk(ret)) {
        ALOGD("Failed to delete Security Association, line=%d", __LINE__);
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_adapter_properties_evt(bt_status_t status, uint32_t num_props,
 bt_property_t *p_props)
{
    HAL_CBACK(bt_hal_cbacks, adapter_properties_cb,
                     status, num_props, p_props);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: init_display(display *d, const char *program)
{
   memset(d, 0, sizeof *d);
   d->png_ptr = NULL;
   d->info_ptr = d->end_ptr = NULL;
   d->error_count = d->warning_count = 0;
   d->program = program;
   d->file = program;
   d->test = init;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long long Segment::CreateInstance(IMkvReader* pReader, long long pos,
                                   Segment*& pSegment) {
  assert(pReader);
  assert(pos >= 0);
 
   pSegment = NULL;
 
 long long total, available;

 const long status = pReader->Length(&total, &available);

 if (status < 0) // error
 return status;

 if (available < 0)
 return -1;

 if ((total >= 0) && (available > total))
 return -1;


 for (;;) {
 if ((total >= 0) && (pos >= total))
 return E_FILE_FORMAT_INVALID;

 long len;
 long long result = GetUIntLength(pReader, pos, len);

 if (result) // error, or too few available bytes
 return result;

 if ((total >= 0) && ((pos + len) > total))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > available)

       return pos + len;
 
     const long long idpos = pos;
    const long long id = ReadUInt(pReader, pos, len);
 
    if (id < 0)  // error
      return id;
 
     pos += len;  // consume ID
 

    result = GetUIntLength(pReader, pos, len);

 if (result) // error, or too few available bytes
 return result;

 if ((total >= 0) && ((pos + len) > total))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > available)
 return pos + len;

 long long size = ReadUInt(pReader, pos, len);

 if (size < 0) // error
 return size;

    pos += len; // consume length of size of element


 const long long unknown_size = (1LL << (7 * len)) - 1;

 if (id == 0x08538067) { // Segment ID
 if (size == unknown_size)
        size = -1;

 else if (total < 0)
        size = -1;

 else if ((pos + size) > total)
        size = -1;

      pSegment = new (std::nothrow) Segment(pReader, idpos,
                                            pos, size);

 if (pSegment == 0)
 return -1; // generic error

 return 0; // success
 }

 if (size == unknown_size)
 return E_FILE_FORMAT_INVALID;

 if ((total >= 0) && ((pos + size) > total))
 return E_FILE_FORMAT_INVALID;

 if ((pos + size) > available)
 return pos + size;

    pos += size; // consume payload
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: sp<MediaSource> OMXCodec::Create(
 const sp<IOMX> &omx,
 const sp<MetaData> &meta, bool createEncoder,
 const sp<MediaSource> &source,
 const char *matchComponentName,
 uint32_t flags,
 const sp<ANativeWindow> &nativeWindow) {
 int32_t requiresSecureBuffers;
 if (source->getFormat()->findInt32(
                kKeyRequiresSecureBuffers,
 &requiresSecureBuffers)
 && requiresSecureBuffers) {
        flags |= kIgnoreCodecSpecificData;
        flags |= kUseSecureInputBuffers;
 }

 const char *mime;
 bool success = meta->findCString(kKeyMIMEType, &mime);
    CHECK(success);

 Vector<CodecNameAndQuirks> matchingCodecs;
    findMatchingCodecs(
            mime, createEncoder, matchComponentName, flags, &matchingCodecs);

 if (matchingCodecs.isEmpty()) {
        ALOGV("No matching codecs! (mime: %s, createEncoder: %s, "
 "matchComponentName: %s, flags: 0x%x)",
                mime, createEncoder ? "true" : "false", matchComponentName, flags);
 return NULL;
 }

    sp<OMXCodecObserver> observer = new OMXCodecObserver;
    IOMX::node_id node = 0;

 for (size_t i = 0; i < matchingCodecs.size(); ++i) {
 const char *componentNameBase = matchingCodecs[i].mName.string();
 uint32_t quirks = matchingCodecs[i].mQuirks;
 const char *componentName = componentNameBase;

 AString tmp;
 if (flags & kUseSecureInputBuffers) {
            tmp = componentNameBase;
            tmp.append(".secure");

            componentName = tmp.c_str();
 }

 if (createEncoder) {
            sp<MediaSource> softwareCodec =
 InstantiateSoftwareEncoder(componentName, source, meta);

 if (softwareCodec != NULL) {
                ALOGV("Successfully allocated software codec '%s'", componentName);

 return softwareCodec;
 }
 }

        ALOGV("Attempting to allocate OMX node '%s'", componentName);

 status_t err = omx->allocateNode(componentName, observer, &node);
 if (err == OK) {
            ALOGV("Successfully allocated OMX node '%s'", componentName);

            sp<OMXCodec> codec = new OMXCodec(
                    omx, node, quirks, flags,
                    createEncoder, mime, componentName,
                    source, nativeWindow);

            observer->setCodec(codec);

            err = codec->configureCodec(meta);
 if (err == OK) {
 return codec;
 }

            ALOGV("Failed to configure codec '%s'", componentName);
 }
 }

 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SampleIterator::SampleIterator(SampleTable *table)
 : mTable(table),
      mInitialized(false),
      mTimeToSampleIndex(0),
      mTTSSampleIndex(0),
      mTTSSampleTime(0),
      mTTSCount(0),
      mTTSDuration(0) {
    reset();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t vp8_peek_si_internal(const uint8_t *data,
 unsigned int data_sz,
 vpx_codec_stream_info_t *si,
                                            vpx_decrypt_cb decrypt_cb,
 void *decrypt_state)
{
 vpx_codec_err_t res = VPX_CODEC_OK;

 if(data + data_sz <= data)
 {
        res = VPX_CODEC_INVALID_PARAM;
 }
 else
 {
 /* Parse uncompresssed part of key frame header.
         * 3 bytes:- including version, frame type and an offset
         * 3 bytes:- sync code (0x9d, 0x01, 0x2a)
         * 4 bytes:- including image width and height in the lowest 14 bits
         *           of each 2-byte value.
         */
 uint8_t clear_buffer[10];
 const uint8_t *clear = data;
 if (decrypt_cb)
 {
 int n = MIN(sizeof(clear_buffer), data_sz);
            decrypt_cb(decrypt_state, data, clear_buffer, n);
            clear = clear_buffer;
 }
        si->is_kf = 0;

 if (data_sz >= 10 && !(clear[0] & 0x01)) /* I-Frame */
 {
            si->is_kf = 1;

 /* vet via sync code */
 if (clear[3] != 0x9d || clear[4] != 0x01 || clear[5] != 0x2a)
 return VPX_CODEC_UNSUP_BITSTREAM;

            si->w = (clear[6] | (clear[7] << 8)) & 0x3fff;

             si->h = (clear[8] | (clear[9] << 8)) & 0x3fff;
 
             /*printf("w=%d, h=%d\n", si->w, si->h);*/
            if (!(si->h | si->w))
                res = VPX_CODEC_UNSUP_BITSTREAM;
         }
         else
         {
            res = VPX_CODEC_UNSUP_BITSTREAM;
 }
 }

 return res;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ACodec::ACodec()
 : mQuirks(0),
      mNode(0),
      mNativeWindowUsageBits(0),
      mSentFormat(false),
      mIsVideo(false),
      mIsEncoder(false),
      mFatalError(false),
      mShutdownInProgress(false),
      mExplicitShutdown(false),
      mEncoderDelay(0),
      mEncoderPadding(0),
      mRotationDegrees(0),
      mChannelMaskPresent(false),
      mChannelMask(0),
      mDequeueCounter(0),
      mInputMetadataType(kMetadataBufferTypeInvalid),
      mOutputMetadataType(kMetadataBufferTypeInvalid),
      mLegacyAdaptiveExperiment(false),
      mMetadataBuffersToSubmit(0),
      mRepeatFrameDelayUs(-1ll),
      mMaxPtsGapUs(-1ll),
      mMaxFps(-1),
      mTimePerFrameUs(-1ll),
      mTimePerCaptureUs(-1ll),
      mCreateInputBuffersSuspended(false),
      mTunneled(false) {
    mUninitializedState = new UninitializedState(this);
    mLoadedState = new LoadedState(this);
    mLoadedToIdleState = new LoadedToIdleState(this);
    mIdleToExecutingState = new IdleToExecutingState(this);
    mExecutingState = new ExecutingState(this);

    mOutputPortSettingsChangedState =
 new OutputPortSettingsChangedState(this);

    mExecutingToIdleState = new ExecutingToIdleState(this);
    mIdleToLoadedState = new IdleToLoadedState(this);
    mFlushingState = new FlushingState(this);

    mPortEOS[kPortIndexInput] = mPortEOS[kPortIndexOutput] = false;
    mInputEOSResult = OK;

    changeState(mUninitializedState);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const CuePoint* Cues::GetLast() const
{
    if (m_cue_points == NULL)
        return NULL;
    if (m_count <= 0)
        return NULL;
 
 #if 0
     LoadCuePoint();  //init cues

 const size_t count = m_count + m_preload_count;

 if (count == 0) //weird
 return NULL;

 const size_t index = count - 1;

 CuePoint* const* const pp = m_cue_points;
    assert(pp);

 CuePoint* const pCP = pp[index];
    assert(pCP);


     pCP->Load(m_pSegment->m_pReader);
     assert(pCP->GetTimeCode() >= 0);
 #else
    const long index = m_count - 1;
 
    CuePoint* const* const pp = m_cue_points;
    assert(pp);
 
    CuePoint* const pCP = pp[index];
    assert(pCP);
    assert(pCP->GetTimeCode() >= 0);
 #endif
 
    return pCP;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: process_chunk(struct file *file, png_uint_32 file_crc, png_uint_32 next_length,
   png_uint_32 next_type)
 /* Called when the chunk data has been read, next_length and next_type
    * will be set for the next chunk (or 0 if this is IEND).
    *
    * When this routine returns, chunk_length and chunk_type will be set for the
    * next chunk to write because if a chunk is skipped this return calls back
    * to read_chunk.
    */
{
 const png_uint_32 type = file->type;

 if (file->global->verbose > 1)
 {
      fputs("  ", stderr);
      type_name(file->type, stderr);
      fprintf(stderr, " %lu 0x%.8x 0x%.8x\n", (unsigned long)file->length,
         file->crc ^ 0xffffffff, file_crc);
 }

 /* The basic structure seems correct but the CRC may not match, in this
    * case assume that it is simply a bad CRC, either wrongly calculated or
    * because of damaged stream data.
    */
 if ((file->crc ^ 0xffffffff) != file_crc)
 {
 /* The behavior is set by the 'skip' setting; if it is anything other
       * than SKIP_BAD_CRC ignore the bad CRC and return the chunk, with a
       * corrected CRC and possibly processed, to libpng.  Otherwise skip the
       * chunk, which will result in a fatal error if the chunk is critical.
       */
      file->status_code |= CRC_ERROR;

 /* Ignore the bad CRC  */
 if (file->global->skip != SKIP_BAD_CRC)
         type_message(file, type, "bad CRC");

 /* This will cause an IEND with a bad CRC to stop */
 else if (CRITICAL(type))
         stop(file, READ_ERROR_CODE, "bad CRC in critical chunk");

 else
 {
         type_message(file, type, "skipped: bad CRC");

 /* NOTE: this cannot be reached for IEND because it is critical. */
 goto skip_chunk;
 }
 }

 /* Check for other 'skip' cases and handle these; these only apply to
    * ancillary chunks (and not tRNS, which should probably have been a critical
    * chunk.)
    */
 if (skip_chunk_type(file->global, type))
 goto skip_chunk;

 /* The chunk may still be skipped if problems are detected in the LZ data,
    * however the LZ data check requires a chunk.  Handle this by instantiating
    * a chunk unless an IDAT is already instantiated (IDAT control structures
    * instantiate their own chunk.)
    */
 if (type != png_IDAT)
      file->alloc(file, 0/*chunk*/);

 else if (file->idat == NULL)
      file->alloc(file, 1/*IDAT*/);

 else
 {
 /* The chunk length must be updated for process_IDAT */
      assert(file->chunk != NULL);
      assert(file->chunk->chunk_type == png_IDAT);
      file->chunk->chunk_length = file->length;
 }

 /* Record the 'next' information too, now that the original values for
    * this chunk have been copied.  Notice that the IDAT chunks only make a
    * copy of the position of the first chunk, this is fine - process_IDAT does
    * not need the position of this chunk.
    */
   file->length = next_length;
   file->type = next_type;
   getpos(file);

 /* Do per-type processing, note that if this code does not return from the
    * function the chunk will be skipped.  The rewrite is cancelled here so that
    * it can be set in the per-chunk processing.
    */
   file->chunk->rewrite_length = 0;
   file->chunk->rewrite_offset = 0;
 switch (type)
 {
 default:
 return;

 case png_IHDR:
 /* Read this now and update the control structure with the information
          * it contains.  The header is validated completely to ensure this is a
          * PNG.
          */
 {
 struct chunk *chunk = file->chunk;

 if (chunk->chunk_length != 13)
               stop_invalid(file, "IHDR length");

 /* Read all the IHDR information and validate it. */
            setpos(chunk);
            file->width = reread_4(file);
            file->height = reread_4(file);
            file->bit_depth = reread_byte(file);
            file->color_type = reread_byte(file);
            file->compression_method = reread_byte(file);
            file->filter_method = reread_byte(file);
            file->interlace_method = reread_byte(file);

 /* This validates all the fields, and calls stop_invalid if
             * there is a problem.
             */
            calc_image_size(file);
 }
 return;

 /* Ancillary chunks that require further processing: */
 case png_zTXt: case png_iCCP:
 if (process_zTXt_iCCP(file))
 return;
         chunk_end(&file->chunk);
         file_setpos(file, &file->data_pos);
 break;

 case png_iTXt:
 if (process_iTXt(file))
 return;
         chunk_end(&file->chunk);
         file_setpos(file, &file->data_pos);
 break;

 case png_IDAT:
 if (process_IDAT(file))
 return;
 /* First pass: */
         assert(next_type == png_IDAT);
 break;
 }

 /* Control reaches this point if the chunk must be skipped.  For chunks other
    * than IDAT this means that the zlib compressed data is fatally damanged and
    * the chunk will not be passed to libpng.  For IDAT it means that the end of
    * the IDAT stream has not yet been reached and we must handle the next
    * (IDAT) chunk.  If the LZ data in an IDAT stream cannot be read 'stop' must
    * be used to halt parsing of the PNG.
    */
   read_chunk(file);
 return;

 /* This is the generic code to skip the current chunk; simply jump to the
    * next one.
    */
skip_chunk:
   file->length = next_length;
   file->type = next_type;
   getpos(file);
   read_chunk(file);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int in_set_sample_rate(struct audio_stream *stream, uint32_t rate)
{
 struct a2dp_stream_in *in = (struct a2dp_stream_in *)stream;

    FNLOG();

 if (in->common.cfg.rate > 0 && in->common.cfg.rate == rate)
 return 0;
 else
 return -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseQNameAndCompare(xmlParserCtxtPtr ctxt, xmlChar const *name,
                        xmlChar const *prefix) {
 const xmlChar *cmp;
 const xmlChar *in;
 const xmlChar *ret;
 const xmlChar *prefix2;

 if (prefix == NULL) return(xmlParseNameAndCompare(ctxt, name));

    GROW;
    in = ctxt->input->cur;

    cmp = prefix;
 while (*in != 0 && *in == *cmp) {
 ++in;
 ++cmp;
 }
 if ((*cmp == 0) && (*in == ':')) {
        in++;
	cmp = name;
 while (*in != 0 && *in == *cmp) {
 ++in;
 ++cmp;
 }
 if (*cmp == 0 && (*in == '>' || IS_BLANK_CH (*in))) {
 /* success */
	    ctxt->input->cur = in;
 return((const xmlChar*) 1);
 }
 }
 /*
     * all strings coms from the dictionary, equality can be done directly
     */
    ret = xmlParseQName (ctxt, &prefix2);
 if ((ret == name) && (prefix == prefix2))
 return((const xmlChar*) 1);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Tags::Tag::GetSimpleTagCount() const { return m_simple_tags_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ATSParser::Stream::isVideo() const {
 switch (mStreamType) {
 case STREAMTYPE_H264:
 case STREAMTYPE_MPEG1_VIDEO:
 case STREAMTYPE_MPEG2_VIDEO:
 case STREAMTYPE_MPEG4_VIDEO:
 return true;

 default:
 return false;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: UWORD16 impeg2d_dec_ac_coeff_zero(stream_t *ps_stream, UWORD16* pu2_sym_len, UWORD16* pu2_sym_val)
{
    UWORD16 u2_offset,u2_decoded_value;
    UWORD8  u1_shift;
    UWORD32 u4_bits_read;

    u4_bits_read = (UWORD16)impeg2d_bit_stream_nxt(ps_stream,MPEG2_AC_COEFF_MAX_LEN);

 if ((UWORD16)u4_bits_read >= 0x0800)
 {
        u2_offset = (UWORD16)u4_bits_read >> 11;
 }
 else if ((UWORD16)u4_bits_read >= 0x40)
 {
        u2_offset = 31 + ((UWORD16)u4_bits_read >> 6);
 }
 else if ((UWORD16)u4_bits_read >= 0x20)
 {
        u2_offset = 64;
 }
 else
 {
        u2_offset      = 63;
        u4_bits_read    = (UWORD16)u4_bits_read - 0x10;
 }
 /*-----------------------------------------------------------------------
     * The table gOffset contains both the offset for the group to which the
     * Vld code belongs in the Ac Coeff Table and the no of bits with which
     * the BitsRead should be shifted
     *-----------------------------------------------------------------------*/
    u2_offset = gau2_impeg2d_offset_zero[u2_offset];
    u1_shift  = u2_offset & 0xF;

 /*-----------------------------------------------------------------------
     * Depending upon the vld code, we index exactly to that particular
     * Vld codes value in the Ac Coeff Table.
     * (Offset >> 4)       gives the offset for the group in the AcCoeffTable.
     * (BitsRead >> shift) gives the offset within its group
     *-----------------------------------------------------------------------*/
     u2_offset = (u2_offset >> 4) + ((UWORD16)u4_bits_read >> u1_shift);
 /*-----------------------------------------------------------------------
     * DecodedValue has the Run, Level and the number of bits used by Vld code
     *-----------------------------------------------------------------------*/
    u2_decoded_value = gau2_impeg2d_dct_coeff_zero[u2_offset];
 if(u2_decoded_value == END_OF_BLOCK)
 {
 *pu2_sym_len = 2;
 *pu2_sym_val = EOB_CODE_VALUE;
 }
 else if(u2_decoded_value == ESCAPE_CODE)
 {
 *pu2_sym_len     = u2_decoded_value & 0x1F;
 *pu2_sym_val = ESC_CODE_VALUE;
 }
 else
 {
 *pu2_sym_len = u2_decoded_value & 0x1F;
 *pu2_sym_val = u2_decoded_value >> 5;
 }
 return(u2_decoded_value);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  generate_row(png_bytep row, size_t rowbytes, unsigned int y, int color_type,
    int bit_depth, png_const_bytep gamma_table, double conv,
   unsigned int *colors)
 {
   png_uint_32 size_max = image_size_of_type(color_type, bit_depth, colors)-1;
    png_uint_32 depth_max = (1U << bit_depth)-1; /* up to 65536 */
 
   if (colors[0] == 0) switch (channels_of_type(color_type))
    {
    /* 1 channel: a square image with a diamond, the least luminous colors are on
     *    the edge of the image, the most luminous in the center.
    */
 case 1:
 {
            png_uint_32 x;
            png_uint_32 base = 2*size_max - abs(2*y-size_max);

 for (x=0; x<=size_max; ++x)
 {
               png_uint_32 luma = base - abs(2*x-size_max);

 /* 'luma' is now in the range 0..2*size_max, we need
                * 0..depth_max
                */
               luma = (luma*depth_max + size_max) / (2*size_max);
               set_value(row, rowbytes, x, bit_depth, luma, gamma_table, conv);
 }
 }
 break;

 /* 2 channels: the color channel increases in luminosity from top to bottom,
    *    the alpha channel increases in opacity from left to right.
    */
 case 2:
 {
            png_uint_32 alpha = (depth_max * y * 2 + size_max) / (2 * size_max);
            png_uint_32 x;

 for (x=0; x<=size_max; ++x)
 {
               set_value(row, rowbytes, 2*x, bit_depth,
 (depth_max * x * 2 + size_max) / (2 * size_max), gamma_table,
                  conv);
               set_value(row, rowbytes, 2*x+1, bit_depth, alpha, gamma_table,
                  conv);
 }
 }
 break;

 /* 3 channels: linear combinations of, from the top-left corner clockwise,
    *    black, green, white, red.
    */
 case 3:
 {
 /* x0: the black->red scale (the value of the red component) at the
             *     start of the row (blue and green are 0).
             * x1: the green->white scale (the value of the red and blue
             *     components at the end of the row; green is depth_max).
             */
            png_uint_32 Y = (depth_max * y * 2 + size_max) / (2 * size_max);
            png_uint_32 x;

 /* Interpolate x/depth_max from start to end:
             *
             *        start end         difference
             * red:     Y    Y            0
             * green:   0   depth_max   depth_max
             * blue:    0    Y            Y
             */
 for (x=0; x<=size_max; ++x)
 {
               set_value(row, rowbytes, 3*x+0, bit_depth, /* red */ Y,
                     gamma_table, conv);
               set_value(row, rowbytes, 3*x+1, bit_depth, /* green */
 (depth_max * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
               set_value(row, rowbytes, 3*x+2, bit_depth, /* blue */
 (Y * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
 }
 }
 break;

 /* 4 channels: linear combinations of, from the top-left corner clockwise,
    *    transparent, red, green, blue.
    */
 case 4:
 {
 /* x0: the transparent->blue scale (the value of the blue and alpha
             *     components) at the start of the row (red and green are 0).
             * x1: the red->green scale (the value of the red and green
             *     components at the end of the row; blue is 0 and alpha is
             *     depth_max).
             */
            png_uint_32 Y = (depth_max * y * 2 + size_max) / (2 * size_max);
            png_uint_32 x;

 /* Interpolate x/depth_max from start to end:
             *
             *        start    end       difference
             * red:     0   depth_max-Y depth_max-Y
             * green:   0       Y             Y
             * blue:    Y       0            -Y
             * alpha:   Y    depth_max  depth_max-Y
             */
 for (x=0; x<=size_max; ++x)
 {
               set_value(row, rowbytes, 4*x+0, bit_depth, /* red */
 ((depth_max-Y) * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
               set_value(row, rowbytes, 4*x+1, bit_depth, /* green */
 (Y * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
               set_value(row, rowbytes, 4*x+2, bit_depth, /* blue */
                  Y - (Y * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
               set_value(row, rowbytes, 4*x+3, bit_depth, /* alpha */
                  Y + ((depth_max-Y) * x * 2 + size_max) / (2 * size_max),
                  gamma_table, conv);
 }
 }
 break;

 default:
         fprintf(stderr, "makepng: internal bad channel count\n");
         exit(2);
 }

 else if (color_type & PNG_COLOR_MASK_PALETTE)
 {
 /* Palette with fixed color: the image rows are all 0 and the image width
       * is 16.
       */
      memset(row, 0, rowbytes);
 }

 else if (colors[0] == channels_of_type(color_type))
 switch (channels_of_type(color_type))
 {
 case 1:
 {
 const png_uint_32 luma = colors[1];
               png_uint_32 x;

 for (x=0; x<=size_max; ++x)
                  set_value(row, rowbytes, x, bit_depth, luma, gamma_table,
                     conv);
 }
 break;

 case 2:
 {
 const png_uint_32 luma = colors[1];
 const png_uint_32 alpha = colors[2];
               png_uint_32 x;

 for (x=0; x<size_max; ++x)
 {
                  set_value(row, rowbytes, 2*x, bit_depth, luma, gamma_table,
                     conv);
                  set_value(row, rowbytes, 2*x+1, bit_depth, alpha, gamma_table,
                     conv);
 }
 }
 break;

 case 3:
 {
 const png_uint_32 red = colors[1];
 const png_uint_32 green = colors[2];
 const png_uint_32 blue = colors[3];
               png_uint_32 x;

 for (x=0; x<=size_max; ++x)
 {
                  set_value(row, rowbytes, 3*x+0, bit_depth, red, gamma_table,
                     conv);
                  set_value(row, rowbytes, 3*x+1, bit_depth, green, gamma_table,
                     conv);
                  set_value(row, rowbytes, 3*x+2, bit_depth, blue, gamma_table,
                     conv);
 }
 }
 break;

 case 4:
 {
 const png_uint_32 red = colors[1];
 const png_uint_32 green = colors[2];
 const png_uint_32 blue = colors[3];
 const png_uint_32 alpha = colors[4];
               png_uint_32 x;

 for (x=0; x<=size_max; ++x)
 {
                  set_value(row, rowbytes, 4*x+0, bit_depth, red, gamma_table,
                     conv);
                  set_value(row, rowbytes, 4*x+1, bit_depth, green, gamma_table,
                     conv);
                  set_value(row, rowbytes, 4*x+2, bit_depth, blue, gamma_table,
                     conv);
                  set_value(row, rowbytes, 4*x+3, bit_depth, alpha, gamma_table,
                     conv);
 }
 }
 break;

 default:
            fprintf(stderr, "makepng: internal bad channel count\n");
            exit(2);
 }

 else
 {
      fprintf(stderr,
 "makepng: --color: count(%u) does not match channels(%u)\n",

          colors[0], channels_of_type(color_type));
       exit(1);
    }
 }

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: sp<IMediaMetadataRetriever> MediaPlayerService::createMetadataRetriever()
{
 pid_t pid = IPCThreadState::self()->getCallingPid();
    sp<MetadataRetrieverClient> retriever = new MetadataRetrieverClient(pid);
    ALOGV("Create new media retriever from pid %d", pid);
 return retriever;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void MediaPlayerService::addBatteryData(uint32_t params)
{
 Mutex::Autolock lock(mLock);

 int32_t time = systemTime() / 1000000L;

 if ((params & kBatteryDataSpeakerOn)
 || (params & kBatteryDataOtherAudioDeviceOn)) {

 int deviceOn[NUM_AUDIO_DEVICES];
 for (int i = 0; i < NUM_AUDIO_DEVICES; i++) {
            deviceOn[i] = 0;
 }

 if ((params & kBatteryDataSpeakerOn)
 && (params & kBatteryDataOtherAudioDeviceOn)) {
            deviceOn[SPEAKER_AND_OTHER] = 1;
 } else if (params & kBatteryDataSpeakerOn) {
            deviceOn[SPEAKER] = 1;
 } else {
            deviceOn[OTHER_AUDIO_DEVICE] = 1;
 }

 for (int i = 0; i < NUM_AUDIO_DEVICES; i++) {
 if (mBatteryAudio.deviceOn[i] != deviceOn[i]){

 if (mBatteryAudio.refCount > 0) { // if playing audio
 if (!deviceOn[i]) {
                        mBatteryAudio.lastTime[i] += time;
                        mBatteryAudio.totalTime[i] += mBatteryAudio.lastTime[i];
                        mBatteryAudio.lastTime[i] = 0;
 } else {
                        mBatteryAudio.lastTime[i] = 0 - time;
 }
 }

                mBatteryAudio.deviceOn[i] = deviceOn[i];
 }
 }
 return;
 }

 if (params & kBatteryDataAudioFlingerStart) {
 if (mBatteryAudio.refCount == 0) {
 for (int i = 0; i < NUM_AUDIO_DEVICES; i++) {
 if (mBatteryAudio.deviceOn[i]) {
                    mBatteryAudio.lastTime[i] -= time;
 }
 }
 }

        mBatteryAudio.refCount ++;
 return;

 } else if (params & kBatteryDataAudioFlingerStop) {
 if (mBatteryAudio.refCount <= 0) {
            ALOGW("Battery track warning: refCount is <= 0");
 return;
 }

 if (mBatteryAudio.refCount == 1) {
 for (int i = 0; i < NUM_AUDIO_DEVICES; i++) {
 if (mBatteryAudio.deviceOn[i]) {
                    mBatteryAudio.lastTime[i] += time;
                    mBatteryAudio.totalTime[i] += mBatteryAudio.lastTime[i];
                    mBatteryAudio.lastTime[i] = 0;
 }
 }
 }

        mBatteryAudio.refCount --;
 return;
 }

 int uid = IPCThreadState::self()->getCallingUid();
 if (uid == AID_MEDIA) {
 return;
 }
 int index = mBatteryData.indexOfKey(uid);

 if (index < 0) { // create a new entry for this UID
 BatteryUsageInfo info;
        info.audioTotalTime = 0;
        info.videoTotalTime = 0;
        info.audioLastTime = 0;
        info.videoLastTime = 0;
        info.refCount = 0;

 if (mBatteryData.add(uid, info) == NO_MEMORY) {
            ALOGE("Battery track error: no memory for new app");
 return;
 }
 }

 BatteryUsageInfo &info = mBatteryData.editValueFor(uid);

 if (params & kBatteryDataCodecStarted) {
 if (params & kBatteryDataTrackAudio) {
            info.audioLastTime -= time;
            info.refCount ++;
 }
 if (params & kBatteryDataTrackVideo) {
            info.videoLastTime -= time;
            info.refCount ++;
 }
 } else {
 if (info.refCount == 0) {
            ALOGW("Battery track warning: refCount is already 0");
 return;
 } else if (info.refCount < 0) {
            ALOGE("Battery track error: refCount < 0");
            mBatteryData.removeItem(uid);
 return;
 }

 if (params & kBatteryDataTrackAudio) {
            info.audioLastTime += time;
            info.refCount --;
 }
 if (params & kBatteryDataTrackVideo) {
            info.videoLastTime += time;
            info.refCount --;
 }

 if (info.refCount == 0) {
            info.audioTotalTime += info.audioLastTime;
            info.audioLastTime = 0;
            info.videoTotalTime += info.videoLastTime;
            info.videoLastTime = 0;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlSAXParseDTD(xmlSAXHandlerPtr sax, const xmlChar *ExternalID,
 const xmlChar *SystemID) {
    xmlDtdPtr ret = NULL;
    xmlParserCtxtPtr ctxt;
    xmlParserInputPtr input = NULL;
    xmlCharEncoding enc;
    xmlChar* systemIdCanonic;

 if ((ExternalID == NULL) && (SystemID == NULL)) return(NULL);

    ctxt = xmlNewParserCtxt();
 if (ctxt == NULL) {
 return(NULL);
 }

 /* We are loading a DTD */
    ctxt->options |= XML_PARSE_DTDLOAD;

 /*
     * Set-up the SAX context
     */
 if (sax != NULL) {
 if (ctxt->sax != NULL)
	    xmlFree(ctxt->sax);
        ctxt->sax = sax;
        ctxt->userData = ctxt;
 }

 /*
     * Canonicalise the system ID
     */
    systemIdCanonic = xmlCanonicPath(SystemID);
 if ((SystemID != NULL) && (systemIdCanonic == NULL)) {
	xmlFreeParserCtxt(ctxt);
 return(NULL);
 }

 /*
     * Ask the Entity resolver to load the damn thing
     */

 if ((ctxt->sax != NULL) && (ctxt->sax->resolveEntity != NULL))
	input = ctxt->sax->resolveEntity(ctxt->userData, ExternalID,
	                                 systemIdCanonic);
 if (input == NULL) {
 if (sax != NULL) ctxt->sax = NULL;
	xmlFreeParserCtxt(ctxt);
 if (systemIdCanonic != NULL)
	    xmlFree(systemIdCanonic);
 return(NULL);
 }

 /*
     * plug some encoding conversion routines here.
     */
 if (xmlPushInput(ctxt, input) < 0) {
 if (sax != NULL) ctxt->sax = NULL;
	xmlFreeParserCtxt(ctxt);
 if (systemIdCanonic != NULL)
	    xmlFree(systemIdCanonic);
 return(NULL);
 }
 if ((ctxt->input->end - ctxt->input->cur) >= 4) {
	enc = xmlDetectCharEncoding(ctxt->input->cur, 4);
	xmlSwitchEncoding(ctxt, enc);
 }

 if (input->filename == NULL)
	input->filename = (char *) systemIdCanonic;
 else
	xmlFree(systemIdCanonic);
    input->line = 1;
    input->col = 1;
    input->base = ctxt->input->cur;
    input->cur = ctxt->input->cur;
    input->free = NULL;

 /*
     * let's parse that entity knowing it's an external subset.
     */
    ctxt->inSubset = 2;
    ctxt->myDoc = xmlNewDoc(BAD_CAST "1.0");
 if (ctxt->myDoc == NULL) {
	xmlErrMemory(ctxt, "New Doc failed");
 if (sax != NULL) ctxt->sax = NULL;
	xmlFreeParserCtxt(ctxt);
 return(NULL);
 }
    ctxt->myDoc->properties = XML_DOC_INTERNAL;
    ctxt->myDoc->extSubset = xmlNewDtd(ctxt->myDoc, BAD_CAST "none",
 ExternalID, SystemID);
    xmlParseExternalSubset(ctxt, ExternalID, SystemID);

 if (ctxt->myDoc != NULL) {
 if (ctxt->wellFormed) {
	    ret = ctxt->myDoc->extSubset;
	    ctxt->myDoc->extSubset = NULL;
 if (ret != NULL) {
		xmlNodePtr tmp;

		ret->doc = NULL;
		tmp = ret->children;
 while (tmp != NULL) {
		    tmp->doc = NULL;
		    tmp = tmp->next;
 }
 }
 } else {
	    ret = NULL;
 }
        xmlFreeDoc(ctxt->myDoc);
        ctxt->myDoc = NULL;
 }
 if (sax != NULL) ctxt->sax = NULL;
    xmlFreeParserCtxt(ctxt);

 return(ret);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  static byte parseHexByte(const char * &str) {
     byte b = parseHexChar(str[0]);
    if (str[1] == ':' || str[1] == '\0') {
        str += 2;
        return b;
     } else {
         b = b << 4 | parseHexChar(str[1]);
        str += 3;
        return b;
     }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void update_rate_histogram(struct rate_hist *hist,
 const vpx_codec_enc_cfg_t *cfg,
 const vpx_codec_cx_pkt_t *pkt) {
 int i;
 int64_t then = 0;
 int64_t avg_bitrate = 0;
 int64_t sum_sz = 0;
 const int64_t now = pkt->data.frame.pts * 1000 *
 (uint64_t)cfg->g_timebase.num /
 (uint64_t)cfg->g_timebase.den;

 int idx = hist->frames++ % hist->samples;
  hist->pts[idx] = now;
  hist->sz[idx] = (int)pkt->data.frame.sz;


   if (now < cfg->rc_buf_initial_sz)
     return;
 
   then = now;
 
   /* Sum the size over the past rc_buf_sz ms */
 for (i = hist->frames; i > 0 && hist->frames - i < hist->samples; i--) {
 const int i_idx = (i - 1) % hist->samples;

    then = hist->pts[i_idx];
 if (now - then > cfg->rc_buf_sz)
 break;
    sum_sz += hist->sz[i_idx];
 }

 if (now == then)
 return;

  avg_bitrate = sum_sz * 8 * 1000 / (now - then);
  idx = (int)(avg_bitrate * (RATE_BINS / 2) / (cfg->rc_target_bitrate * 1000));
 if (idx < 0)
    idx = 0;
 if (idx > RATE_BINS - 1)
    idx = RATE_BINS - 1;
 if (hist->bucket[idx].low > avg_bitrate)
    hist->bucket[idx].low = (int)avg_bitrate;
 if (hist->bucket[idx].high < avg_bitrate)
    hist->bucket[idx].high = (int)avg_bitrate;
  hist->bucket[idx].count++;
  hist->total++;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: xmlParseStartTag2(xmlParserCtxtPtr ctxt, const xmlChar **pref,
 const xmlChar **URI, int *tlen) {
 const xmlChar *localname;
 const xmlChar *prefix;
 const xmlChar *attname;
 const xmlChar *aprefix;
 const xmlChar *nsname;
    xmlChar *attvalue;
 const xmlChar **atts = ctxt->atts;
 int maxatts = ctxt->maxatts;
 int nratts, nbatts, nbdef;
 int i, j, nbNs, attval, oldline, oldcol, inputNr;
 const xmlChar *base;
 unsigned long cur;
 int nsNr = ctxt->nsNr;

 if (RAW != '<') return(NULL);
    NEXT1;

 /*
     * NOTE: it is crucial with the SAX2 API to never call SHRINK beyond that
     *       point since the attribute values may be stored as pointers to
     *       the buffer and calling SHRINK would destroy them !
     *       The Shrinking is only possible once the full set of attribute
     *       callbacks have been done.
     */
reparse:
    SHRINK;
    base = ctxt->input->base;
    cur = ctxt->input->cur - ctxt->input->base;
    inputNr = ctxt->inputNr;
    oldline = ctxt->input->line;
    oldcol = ctxt->input->col;
    nbatts = 0;
    nratts = 0;
    nbdef = 0;
    nbNs = 0;
    attval = 0;
 /* Forget any namespaces added during an earlier parse of this element. */
    ctxt->nsNr = nsNr;

    localname = xmlParseQName(ctxt, &prefix);
 if (localname == NULL) {
	xmlFatalErrMsg(ctxt, XML_ERR_NAME_REQUIRED,
 "StartTag: invalid element name\n");
 return(NULL);
 }
 *tlen = ctxt->input->cur - ctxt->input->base - cur;

 /*
     * Now parse the attributes, it ends up with the ending
     *
     * (S Attribute)* S?
     */
    SKIP_BLANKS;
    GROW;
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr))
 goto base_changed;

 while (((RAW != '>') &&
 ((RAW != '/') || (NXT(1) != '>')) &&
 (IS_BYTE_CHAR(RAW))) && (ctxt->instate != XML_PARSER_EOF)) {
 const xmlChar *q = CUR_PTR;
 unsigned int cons = ctxt->input->consumed;
 int len = -1, alloc = 0;

	attname = xmlParseAttribute2(ctxt, prefix, localname,
 &aprefix, &attvalue, &len, &alloc);
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr)) {
 if ((attvalue != NULL) && (alloc != 0))
	        xmlFree(attvalue);
	    attvalue = NULL;
 goto base_changed;
 }
 if ((attname != NULL) && (attvalue != NULL)) {
 if (len < 0) len = xmlStrlen(attvalue);
 if ((attname == ctxt->str_xmlns) && (aprefix == NULL)) {
 const xmlChar *URL = xmlDictLookup(ctxt->dict, attvalue, len);
		xmlURIPtr uri;

 if (URL == NULL) {
		    xmlErrMemory(ctxt, "dictionary allocation failure");
 if ((attvalue != NULL) && (alloc != 0))
			xmlFree(attvalue);
 return(NULL);
 }
 if (*URL != 0) {
		    uri = xmlParseURI((const char *) URL);
 if (uri == NULL) {
			xmlNsErr(ctxt, XML_WAR_NS_URI,
 "xmlns: '%s' is not a valid URI\n",
					   URL, NULL, NULL);
 } else {
 if (uri->scheme == NULL) {
			    xmlNsWarn(ctxt, XML_WAR_NS_URI_RELATIVE,
 "xmlns: URI %s is not absolute\n",
				      URL, NULL, NULL);
 }
			xmlFreeURI(uri);
 }
 if (URL == ctxt->str_xml_ns) {
 if (attname != ctxt->str_xml) {
			    xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "xml namespace URI cannot be the default namespace\n",
				     NULL, NULL, NULL);
 }
 goto skip_default_ns;
 }
 if ((len == 29) &&
 (xmlStrEqual(URL,
				 BAD_CAST "http://www.w3.org/2000/xmlns/"))) {
			xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "reuse of the xmlns namespace name is forbidden\n",
				 NULL, NULL, NULL);
 goto skip_default_ns;
 }
 }
 /*
		 * check that it's not a defined namespace
		 */
 for (j = 1;j <= nbNs;j++)
 if (ctxt->nsTab[ctxt->nsNr - 2 * j] == NULL)
 break;
 if (j <= nbNs)
		    xmlErrAttributeDup(ctxt, NULL, attname);
 else
 if (nsPush(ctxt, NULL, URL) > 0) nbNs++;
skip_default_ns:
 if ((attvalue != NULL) && (alloc != 0)) {
		    xmlFree(attvalue);
		    attvalue = NULL;
 }
 if ((RAW == '>') || (((RAW == '/') && (NXT(1) == '>'))))
 break;
 if (!IS_BLANK_CH(RAW)) {
		    xmlFatalErrMsg(ctxt, XML_ERR_SPACE_REQUIRED,
 "attributes construct error\n");
 break;
 }
		SKIP_BLANKS;
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr))
 goto base_changed;
 continue;
 }
 if (aprefix == ctxt->str_xmlns) {
 const xmlChar *URL = xmlDictLookup(ctxt->dict, attvalue, len);
		xmlURIPtr uri;

 if (attname == ctxt->str_xml) {
 if (URL != ctxt->str_xml_ns) {
		        xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "xml namespace prefix mapped to wrong URI\n",
			         NULL, NULL, NULL);
 }
 /*
		     * Do not keep a namespace definition node
		     */
 goto skip_ns;
 }
 if (URL == ctxt->str_xml_ns) {
 if (attname != ctxt->str_xml) {
		        xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "xml namespace URI mapped to wrong prefix\n",
			         NULL, NULL, NULL);
 }
 goto skip_ns;
 }
 if (attname == ctxt->str_xmlns) {
		    xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "redefinition of the xmlns prefix is forbidden\n",
			     NULL, NULL, NULL);
 goto skip_ns;
 }
 if ((len == 29) &&
 (xmlStrEqual(URL,
		                 BAD_CAST "http://www.w3.org/2000/xmlns/"))) {
		    xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "reuse of the xmlns namespace name is forbidden\n",
			     NULL, NULL, NULL);
 goto skip_ns;
 }
 if ((URL == NULL) || (URL[0] == 0)) {
		    xmlNsErr(ctxt, XML_NS_ERR_XML_NAMESPACE,
 "xmlns:%s: Empty XML namespace is not allowed\n",
			          attname, NULL, NULL);
 goto skip_ns;
 } else {
		    uri = xmlParseURI((const char *) URL);
 if (uri == NULL) {
			xmlNsErr(ctxt, XML_WAR_NS_URI,
 "xmlns:%s: '%s' is not a valid URI\n",
					   attname, URL, NULL);
 } else {
 if ((ctxt->pedantic) && (uri->scheme == NULL)) {
			    xmlNsWarn(ctxt, XML_WAR_NS_URI_RELATIVE,
 "xmlns:%s: URI %s is not absolute\n",
				      attname, URL, NULL);
 }
			xmlFreeURI(uri);
 }
 }

 /*
		 * check that it's not a defined namespace
		 */
 for (j = 1;j <= nbNs;j++)
 if (ctxt->nsTab[ctxt->nsNr - 2 * j] == attname)
 break;
 if (j <= nbNs)
		    xmlErrAttributeDup(ctxt, aprefix, attname);
 else
 if (nsPush(ctxt, attname, URL) > 0) nbNs++;
skip_ns:
 if ((attvalue != NULL) && (alloc != 0)) {
		    xmlFree(attvalue);
		    attvalue = NULL;
 }
 if ((RAW == '>') || (((RAW == '/') && (NXT(1) == '>'))))
 break;
 if (!IS_BLANK_CH(RAW)) {
		    xmlFatalErrMsg(ctxt, XML_ERR_SPACE_REQUIRED,
 "attributes construct error\n");
 break;
 }
		SKIP_BLANKS;
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr))
 goto base_changed;
 continue;
 }

 /*
	     * Add the pair to atts
	     */
 if ((atts == NULL) || (nbatts + 5 > maxatts)) {
 if (xmlCtxtGrowAttrs(ctxt, nbatts + 5) < 0) {
 if (attvalue[len] == 0)
			xmlFree(attvalue);
 goto failed;
 }
	        maxatts = ctxt->maxatts;
		atts = ctxt->atts;
 }
	    ctxt->attallocs[nratts++] = alloc;
	    atts[nbatts++] = attname;
	    atts[nbatts++] = aprefix;
	    atts[nbatts++] = NULL; /* the URI will be fetched later */
	    atts[nbatts++] = attvalue;
	    attvalue += len;
	    atts[nbatts++] = attvalue;
 /*
	     * tag if some deallocation is needed
	     */
 if (alloc != 0) attval = 1;
 } else {
 if ((attvalue != NULL) && (attvalue[len] == 0))
		xmlFree(attvalue);
 }

failed:

	GROW
 if (ctxt->instate == XML_PARSER_EOF)
 break;
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr))
 goto base_changed;
 if ((RAW == '>') || (((RAW == '/') && (NXT(1) == '>'))))
 break;
 if (!IS_BLANK_CH(RAW)) {
	    xmlFatalErrMsg(ctxt, XML_ERR_SPACE_REQUIRED,
 "attributes construct error\n");
 break;
 }
	SKIP_BLANKS;
 if ((cons == ctxt->input->consumed) && (q == CUR_PTR) &&
 (attname == NULL) && (attvalue == NULL)) {
	    xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR,
 "xmlParseStartTag: problem parsing attributes\n");
 break;
 }
        GROW;
 if ((ctxt->input->base != base) || (inputNr != ctxt->inputNr))
 goto base_changed;
 }

 /*
     * The attributes defaulting
     */
 if (ctxt->attsDefault != NULL) {
        xmlDefAttrsPtr defaults;

	defaults = xmlHashLookup2(ctxt->attsDefault, localname, prefix);
 if (defaults != NULL) {
 for (i = 0;i < defaults->nbAttrs;i++) {
	        attname = defaults->values[5 * i];
		aprefix = defaults->values[5 * i + 1];

 /*
		 * special work for namespaces defaulted defs
		 */
 if ((attname == ctxt->str_xmlns) && (aprefix == NULL)) {
 /*
		     * check that it's not a defined namespace
		     */
 for (j = 1;j <= nbNs;j++)
 if (ctxt->nsTab[ctxt->nsNr - 2 * j] == NULL)
 break;
 if (j <= nbNs) continue;

		    nsname = xmlGetNamespace(ctxt, NULL);
 if (nsname != defaults->values[5 * i + 2]) {
 if (nsPush(ctxt, NULL,
			           defaults->values[5 * i + 2]) > 0)
			    nbNs++;
 }
 } else if (aprefix == ctxt->str_xmlns) {
 /*
		     * check that it's not a defined namespace
		     */
 for (j = 1;j <= nbNs;j++)
 if (ctxt->nsTab[ctxt->nsNr - 2 * j] == attname)
 break;
 if (j <= nbNs) continue;

		    nsname = xmlGetNamespace(ctxt, attname);
 if (nsname != defaults->values[2]) {
 if (nsPush(ctxt, attname,
			           defaults->values[5 * i + 2]) > 0)
			    nbNs++;
 }
 } else {
 /*
		     * check that it's not a defined attribute
		     */
 for (j = 0;j < nbatts;j+=5) {
 if ((attname == atts[j]) && (aprefix == atts[j+1]))
 break;
 }
 if (j < nbatts) continue;

 if ((atts == NULL) || (nbatts + 5 > maxatts)) {
 if (xmlCtxtGrowAttrs(ctxt, nbatts + 5) < 0) {
 return(NULL);
 }
			maxatts = ctxt->maxatts;
			atts = ctxt->atts;
 }
		    atts[nbatts++] = attname;
		    atts[nbatts++] = aprefix;
 if (aprefix == NULL)
			atts[nbatts++] = NULL;
 else
		        atts[nbatts++] = xmlGetNamespace(ctxt, aprefix);
		    atts[nbatts++] = defaults->values[5 * i + 2];
		    atts[nbatts++] = defaults->values[5 * i + 3];
 if ((ctxt->standalone == 1) &&
 (defaults->values[5 * i + 4] != NULL)) {
			xmlValidityError(ctxt, XML_DTD_STANDALONE_DEFAULTED,
 "standalone: attribute %s on %s defaulted from external subset\n",
	                                 attname, localname);
 }
		    nbdef++;
 }
 }
 }
 }

 /*
     * The attributes checkings
     */
 for (i = 0; i < nbatts;i += 5) {
 /*
	* The default namespace does not apply to attribute names.
	*/
 if (atts[i + 1] != NULL) {
	    nsname = xmlGetNamespace(ctxt, atts[i + 1]);
 if (nsname == NULL) {
		xmlNsErr(ctxt, XML_NS_ERR_UNDEFINED_NAMESPACE,
 "Namespace prefix %s for %s on %s is not defined\n",
		    atts[i + 1], atts[i], localname);
 }
	    atts[i + 2] = nsname;
 } else
	    nsname = NULL;
 /*
	 * [ WFC: Unique Att Spec ]
	 * No attribute name may appear more than once in the same
	 * start-tag or empty-element tag.
	 * As extended by the Namespace in XML REC.
	 */
 for (j = 0; j < i;j += 5) {
 if (atts[i] == atts[j]) {
 if (atts[i+1] == atts[j+1]) {
		    xmlErrAttributeDup(ctxt, atts[i+1], atts[i]);
 break;
 }
 if ((nsname != NULL) && (atts[j + 2] == nsname)) {
		    xmlNsErr(ctxt, XML_NS_ERR_ATTRIBUTE_REDEFINED,
 "Namespaced Attribute %s in '%s' redefined\n",
			     atts[i], nsname, NULL);
 break;
 }
 }
 }
 }

    nsname = xmlGetNamespace(ctxt, prefix);
 if ((prefix != NULL) && (nsname == NULL)) {
	xmlNsErr(ctxt, XML_NS_ERR_UNDEFINED_NAMESPACE,
 "Namespace prefix %s on %s is not defined\n",
		 prefix, localname, NULL);
 }
 *pref = prefix;
 *URI = nsname;

 /*
     * SAX: Start of Element !
     */
 if ((ctxt->sax != NULL) && (ctxt->sax->startElementNs != NULL) &&
 (!ctxt->disableSAX)) {
 if (nbNs > 0)
	    ctxt->sax->startElementNs(ctxt->userData, localname, prefix,
			  nsname, nbNs, &ctxt->nsTab[ctxt->nsNr - 2 * nbNs],
			  nbatts / 5, nbdef, atts);
 else
	    ctxt->sax->startElementNs(ctxt->userData, localname, prefix,
	                  nsname, 0, NULL, nbatts / 5, nbdef, atts);
 }

 /*
     * Free up attribute allocated strings if needed
     */
 if (attval != 0) {
 for (i = 3,j = 0; j < nratts;i += 5,j++)
 if ((ctxt->attallocs[j] != 0) && (atts[i] != NULL))
	        xmlFree((xmlChar *) atts[i]);
 }

 return(localname);

base_changed:
 /*
     * the attribute strings are valid iif the base didn't changed
     */
 if (attval != 0) {
 for (i = 3,j = 0; j < nratts;i += 5,j++)
 if ((ctxt->attallocs[j] != 0) && (atts[i] != NULL))
	        xmlFree((xmlChar *) atts[i]);
 }

 /*
     * We can't switch from one entity to another in the middle
     * of a start tag
     */
 if (inputNr != ctxt->inputNr) {
        xmlFatalErrMsg(ctxt, XML_ERR_ENTITY_BOUNDARY,
 "Start tag doesn't start and stop in the same entity\n");
 return(NULL);
 }

    ctxt->input->cur = ctxt->input->base + cur;
    ctxt->input->line = oldline;
    ctxt->input->col = oldcol;
 if (ctxt->wellFormed == 1) {
 goto reparse;
 }
 return(NULL);
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void cleanup(int service_uuid) {
  BTIF_TRACE_EVENT("%s", __func__);

  btif_transfer_context(btif_av_handle_event, BTIF_AV_CLEANUP_REQ_EVT, NULL, 0,
                        NULL);

  btif_disable_service(service_uuid);

  alarm_free(av_open_on_rc_timer);
  av_open_on_rc_timer = NULL;

 /* Also shut down the AV state machine */
  btif_sm_shutdown(btif_av_cb.sm_handle);
  btif_av_cb.sm_handle = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: media_status_t AMediaCodecCryptoInfo_delete(AMediaCodecCryptoInfo* info) {
    free(info);
 return AMEDIA_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ID3::ID3(const sp<DataSource> &source, bool ignoreV1, off64_t offset)
 : mIsValid(false),
      mData(NULL),
      mSize(0),
      mFirstFrameOffset(0),
      mVersion(ID3_UNKNOWN),
      mRawSize(0) {
    mIsValid = parseV2(source, offset);

 if (!mIsValid && !ignoreV1) {
        mIsValid = parseV1(source);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int in_set_parameters(struct audio_stream *stream, const char *kvpairs)
{
    UNUSED(stream);
    UNUSED(kvpairs);

    FNLOG();
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::prepare(int maxCount, int streamId) {
    ATRACE_CALL();
    ALOGV("%s: Camera %d: Preparing stream %d", __FUNCTION__, mId, streamId);
 Mutex::Autolock il(mInterfaceLock);
 Mutex::Autolock l(mLock);

    sp<Camera3StreamInterface> stream;
 ssize_t outputStreamIdx = mOutputStreams.indexOfKey(streamId);
 if (outputStreamIdx == NAME_NOT_FOUND) {
        CLOGE("Stream %d does not exist", streamId);
 return BAD_VALUE;
 }

    stream = mOutputStreams.editValueAt(outputStreamIdx);

 if (stream->isUnpreparable() || stream->hasOutstandingBuffers() ) {
        CLOGE("Stream %d has already been a request target", streamId);
 return BAD_VALUE;
 }

 if (mRequestThread->isStreamPending(stream)) {
        CLOGE("Stream %d is already a target in a pending request", streamId);
 return BAD_VALUE;
 }

 return mPreparerThread->prepare(maxCount, stream);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int PreProcessingFx_Process(effect_handle_t     self,
 audio_buffer_t *inBuffer,
 audio_buffer_t *outBuffer)
{
 preproc_effect_t * effect = (preproc_effect_t *)self;
 int    status = 0;

 if (effect == NULL){
        ALOGV("PreProcessingFx_Process() ERROR effect == NULL");
 return -EINVAL;
 }
 preproc_session_t * session = (preproc_session_t *)effect->session;

 if (inBuffer == NULL  || inBuffer->raw == NULL  ||
            outBuffer == NULL || outBuffer->raw == NULL){
        ALOGW("PreProcessingFx_Process() ERROR bad pointer");
 return -EINVAL;
 }

    session->processedMsk |= (1<<effect->procId);


 if ((session->processedMsk & session->enabledMsk) == session->enabledMsk) {
        effect->session->processedMsk = 0;
 size_t framesRq = outBuffer->frameCount;
 size_t framesWr = 0;
 if (session->framesOut) {
 size_t fr = session->framesOut;
 if (outBuffer->frameCount < fr) {
                fr = outBuffer->frameCount;
 }
            memcpy(outBuffer->s16,
                  session->outBuf,
                  fr * session->outChannelCount * sizeof(int16_t));
            memcpy(session->outBuf,
                  session->outBuf + fr * session->outChannelCount,
 (session->framesOut - fr) * session->outChannelCount * sizeof(int16_t));
            session->framesOut -= fr;
            framesWr += fr;
 }
        outBuffer->frameCount = framesWr;
 if (framesWr == framesRq) {
            inBuffer->frameCount = 0;
 return 0;
 }

 if (session->inResampler != NULL) {
 size_t fr = session->frameCount - session->framesIn;
 if (inBuffer->frameCount < fr) {
                fr = inBuffer->frameCount;
 }
 if (session->inBufSize < session->framesIn + fr) {
                session->inBufSize = session->framesIn + fr;
                session->inBuf = (int16_t *)realloc(session->inBuf,
                                 session->inBufSize * session->inChannelCount * sizeof(int16_t));
 }
            memcpy(session->inBuf + session->framesIn * session->inChannelCount,
                   inBuffer->s16,
                   fr * session->inChannelCount * sizeof(int16_t));
#ifdef DUAL_MIC_TEST
            pthread_mutex_lock(&gPcmDumpLock);
 if (gPcmDumpFh != NULL) {
                fwrite(inBuffer->raw,
                       fr * session->inChannelCount * sizeof(int16_t), 1, gPcmDumpFh);
 }
            pthread_mutex_unlock(&gPcmDumpLock);
#endif

            session->framesIn += fr;
            inBuffer->frameCount = fr;
 if (session->framesIn < session->frameCount) {
 return 0;
 }
 spx_uint32_t frIn = session->framesIn;
 spx_uint32_t frOut = session->apmFrameCount;
 if (session->inChannelCount == 1) {
                speex_resampler_process_int(session->inResampler,
 0,
                                            session->inBuf,
 &frIn,
                                            session->procFrame->_payloadData,
 &frOut);
 } else {
                speex_resampler_process_interleaved_int(session->inResampler,
                                                        session->inBuf,
 &frIn,
                                                        session->procFrame->_payloadData,
 &frOut);
 }
            memcpy(session->inBuf,
                   session->inBuf + frIn * session->inChannelCount,
 (session->framesIn - frIn) * session->inChannelCount * sizeof(int16_t));
            session->framesIn -= frIn;
 } else {
 size_t fr = session->frameCount - session->framesIn;
 if (inBuffer->frameCount < fr) {
                fr = inBuffer->frameCount;
 }
            memcpy(session->procFrame->_payloadData + session->framesIn * session->inChannelCount,
                   inBuffer->s16,
                   fr * session->inChannelCount * sizeof(int16_t));

#ifdef DUAL_MIC_TEST
            pthread_mutex_lock(&gPcmDumpLock);
 if (gPcmDumpFh != NULL) {
                fwrite(inBuffer->raw,
                       fr * session->inChannelCount * sizeof(int16_t), 1, gPcmDumpFh);
 }
            pthread_mutex_unlock(&gPcmDumpLock);
#endif

            session->framesIn += fr;
            inBuffer->frameCount = fr;
 if (session->framesIn < session->frameCount) {
 return 0;
 }
            session->framesIn = 0;
 }
        session->procFrame->_payloadDataLengthInSamples =
                session->apmFrameCount * session->inChannelCount;

        effect->session->apm->ProcessStream(session->procFrame);

 if (session->outBufSize < session->framesOut + session->frameCount) {
            session->outBufSize = session->framesOut + session->frameCount;
            session->outBuf = (int16_t *)realloc(session->outBuf,
                              session->outBufSize * session->outChannelCount * sizeof(int16_t));
 }

 if (session->outResampler != NULL) {
 spx_uint32_t frIn = session->apmFrameCount;
 spx_uint32_t frOut = session->frameCount;
 if (session->inChannelCount == 1) {
                speex_resampler_process_int(session->outResampler,
 0,
                                    session->procFrame->_payloadData,
 &frIn,
                                    session->outBuf + session->framesOut * session->outChannelCount,
 &frOut);
 } else {
                speex_resampler_process_interleaved_int(session->outResampler,
                                    session->procFrame->_payloadData,
 &frIn,
                                    session->outBuf + session->framesOut * session->outChannelCount,
 &frOut);
 }
            session->framesOut += frOut;
 } else {
            memcpy(session->outBuf + session->framesOut * session->outChannelCount,
                   session->procFrame->_payloadData,
                   session->frameCount * session->outChannelCount * sizeof(int16_t));
            session->framesOut += session->frameCount;
 }
 size_t fr = session->framesOut;
 if (framesRq - framesWr < fr) {
            fr = framesRq - framesWr;
 }
        memcpy(outBuffer->s16 + framesWr * session->outChannelCount,
              session->outBuf,
              fr * session->outChannelCount * sizeof(int16_t));
        memcpy(session->outBuf,
              session->outBuf + fr * session->outChannelCount,
 (session->framesOut - fr) * session->outChannelCount * sizeof(int16_t));
        session->framesOut -= fr;
        outBuffer->frameCount += fr;

 return 0;
 } else {
 return -ENODATA;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void CollectElementIndicesImpl(Handle<JSObject> object,
 Handle<FixedArrayBase> backing_store,
 KeyAccumulator* keys) {
 uint32_t length = GetString(*object)->length();
 Factory* factory = keys->isolate()->factory();
 for (uint32_t i = 0; i < length; i++) {
      keys->AddKey(factory->NewNumberFromUint(i));
 }
 BackingStoreAccessor::CollectElementIndicesImpl(object, backing_store,
                                                    keys);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::Client::start()
{
    ALOGV("[%d] start", mConnId);
    sp<MediaPlayerBase> p = getPlayer();
 if (p == 0) return UNKNOWN_ERROR;
    p->setLooping(mLoop);
 return p->start();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParseBalancedChunkMemory(xmlDocPtr doc, xmlSAXHandlerPtr sax,
 void *user_data, int depth, const xmlChar *string, xmlNodePtr *lst) {
 return xmlParseBalancedChunkMemoryRecover( doc, sax, user_data,
                                                depth, string, lst, 0 );
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::onMessageReceived(const sp<AMessage> &msg) {
 switch (msg->what()) {
 case kWhatPrepareAsync:
 {
          onPrepareAsync();
 break;
 }
 case kWhatFetchSubtitleData:
 {
          fetchTextData(kWhatSendSubtitleData, MEDIA_TRACK_TYPE_SUBTITLE,
                  mFetchSubtitleDataGeneration, mSubtitleTrack.mPackets, msg);
 break;
 }

 case kWhatFetchTimedTextData:
 {
          fetchTextData(kWhatSendTimedTextData, MEDIA_TRACK_TYPE_TIMEDTEXT,
                  mFetchTimedTextDataGeneration, mTimedTextTrack.mPackets, msg);
 break;
 }

 case kWhatSendSubtitleData:
 {
          sendTextData(kWhatSubtitleData, MEDIA_TRACK_TYPE_SUBTITLE,
                  mFetchSubtitleDataGeneration, mSubtitleTrack.mPackets, msg);
 break;
 }

 case kWhatSendTimedTextData:
 {
          sendTextData(kWhatTimedTextData, MEDIA_TRACK_TYPE_TIMEDTEXT,
                  mFetchTimedTextDataGeneration, mTimedTextTrack.mPackets, msg);
 break;
 }

 case kWhatChangeAVSource:
 {
 int32_t trackIndex;
          CHECK(msg->findInt32("trackIndex", &trackIndex));
 const sp<MediaSource> source = mSources.itemAt(trackIndex);

 Track* track;
 const char *mime;
          media_track_type trackType, counterpartType;
          sp<MetaData> meta = source->getFormat();
          meta->findCString(kKeyMIMEType, &mime);
 if (!strncasecmp(mime, "audio/", 6)) {
              track = &mAudioTrack;
              trackType = MEDIA_TRACK_TYPE_AUDIO;
              counterpartType = MEDIA_TRACK_TYPE_VIDEO;;
 } else {
              CHECK(!strncasecmp(mime, "video/", 6));
              track = &mVideoTrack;
              trackType = MEDIA_TRACK_TYPE_VIDEO;
              counterpartType = MEDIA_TRACK_TYPE_AUDIO;;
 }


 if (track->mSource != NULL) {
              track->mSource->stop();
 }
          track->mSource = source;
          track->mSource->start();
          track->mIndex = trackIndex;

 status_t avail;
 if (!track->mPackets->hasBufferAvailable(&avail)) {
              TRESPASS();
 break;
 }

 int64_t timeUs, actualTimeUs;
 const bool formatChange = true;
          sp<AMessage> latestMeta = track->mPackets->getLatestEnqueuedMeta();
          CHECK(latestMeta != NULL && latestMeta->findInt64("timeUs", &timeUs));
          readBuffer(trackType, timeUs, &actualTimeUs, formatChange);
          readBuffer(counterpartType, -1, NULL, formatChange);
          ALOGV("timeUs %lld actualTimeUs %lld", timeUs, actualTimeUs);

 break;
 }
 case kWhatPollBuffering:
 {
 int32_t generation;
          CHECK(msg->findInt32("generation", &generation));
 if (generation == mPollBufferingGeneration) {
              onPollBuffering();
 }
 break;
 }

 case kWhatGetFormat:
 {
          onGetFormatMeta(msg);
 break;
 }

 case kWhatGetSelectedTrack:
 {
          onGetSelectedTrack(msg);
 break;
 }

 case kWhatSelectTrack:
 {
          onSelectTrack(msg);
 break;
 }

 case kWhatSeek:
 {
          onSeek(msg);
 break;
 }

 case kWhatReadBuffer:
 {
          onReadBuffer(msg);
 break;
 }

 case kWhatStopWidevine:
 {
          mStopRead = true;
 if (mVideoTrack.mSource != NULL) {
              mVideoTrack.mPackets->clear();
 }
          sp<AMessage> response = new AMessage;
 uint32_t replyID;
          CHECK(msg->senderAwaitsResponse(&replyID));
          response->postReply(replyID);
 break;
 }
 default:
 Source::onMessageReceived(msg);
 break;
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: BlockEntry::Kind SimpleBlock::GetKind() const
{
    return kBlockSimple;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void mca_ccb_hdl_req(tMCA_CCB* p_ccb, tMCA_CCB_EVT* p_data) {
  BT_HDR* p_pkt = &p_data->hdr;
 uint8_t *p, *p_start;
  tMCA_DCB* p_dcb;
  tMCA_CTRL evt_data;
  tMCA_CCB_MSG* p_rx_msg = NULL;
 uint8_t reject_code = MCA_RSP_NO_RESOURCE;
 bool send_rsp = false;
 bool check_req = false;
 uint8_t reject_opcode;

  MCA_TRACE_DEBUG("mca_ccb_hdl_req status:%d", p_ccb->status);

   p_rx_msg = (tMCA_CCB_MSG*)p_pkt;
   p = (uint8_t*)(p_pkt + 1) + p_pkt->offset;
   evt_data.hdr.op_code = *p++;
  BE_STREAM_TO_UINT16(evt_data.hdr.mdl_id, p);
   reject_opcode = evt_data.hdr.op_code + 1;
 
   MCA_TRACE_DEBUG("received mdl id: %d ", evt_data.hdr.mdl_id);
   if (p_ccb->status == MCA_CCB_STAT_PENDING) {
     MCA_TRACE_DEBUG("received req inpending state");
 /* allow abort in pending state */
 if ((p_ccb->status == MCA_CCB_STAT_PENDING) &&
 (evt_data.hdr.op_code == MCA_OP_MDL_ABORT_REQ)) {
      reject_code = MCA_RSP_SUCCESS;
      send_rsp = true;
 /* clear the pending status */
      p_ccb->status = MCA_CCB_STAT_NORM;
 if (p_ccb->p_tx_req &&
 ((p_dcb = mca_dcb_by_hdl(p_ccb->p_tx_req->dcb_idx)) != NULL)) {
        mca_dcb_dealloc(p_dcb, NULL);
        osi_free_and_reset((void**)&p_ccb->p_tx_req);
 }
 } else
      reject_code = MCA_RSP_BAD_OP;
 } else if (p_ccb->p_rx_msg) {
    MCA_TRACE_DEBUG("still handling prev req");
 /* still holding previous message, reject this new one ?? */

 } else if (p_ccb->p_tx_req) {
    MCA_TRACE_DEBUG("still waiting for a response ctrl_vpsm:0x%x",
                    p_ccb->ctrl_vpsm);
 /* sent a request; waiting for response */
 if (p_ccb->ctrl_vpsm == 0) {
      MCA_TRACE_DEBUG("local is ACP. accept the cmd from INT");
 /* local is acceptor, need to handle the request */
      check_req = true;
      reject_code = MCA_RSP_SUCCESS;
 /* drop the previous request */
 if ((p_ccb->p_tx_req->op_code == MCA_OP_MDL_CREATE_REQ) &&
 ((p_dcb = mca_dcb_by_hdl(p_ccb->p_tx_req->dcb_idx)) != NULL)) {
        mca_dcb_dealloc(p_dcb, NULL);
 }
      osi_free_and_reset((void**)&p_ccb->p_tx_req);
      mca_stop_timer(p_ccb);
 } else {
 /*  local is initiator, ignore the req */
      osi_free(p_pkt);
 return;
 }
 } else if (p_pkt->layer_specific != MCA_RSP_SUCCESS) {
    reject_code = (uint8_t)p_pkt->layer_specific;
 if (((evt_data.hdr.op_code >= MCA_NUM_STANDARD_OPCODE) &&
 (evt_data.hdr.op_code < MCA_FIRST_SYNC_OP)) ||
 (evt_data.hdr.op_code > MCA_LAST_SYNC_OP)) {
 /* invalid op code */
      reject_opcode = MCA_OP_ERROR_RSP;
      evt_data.hdr.mdl_id = 0;
 }
 } else {
    check_req = true;
    reject_code = MCA_RSP_SUCCESS;
 }

 if (check_req) {
 if (reject_code == MCA_RSP_SUCCESS) {
      reject_code = MCA_RSP_BAD_MDL;
 if (MCA_IS_VALID_MDL_ID(evt_data.hdr.mdl_id) ||
 ((evt_data.hdr.mdl_id == MCA_ALL_MDL_ID) &&
 (evt_data.hdr.op_code == MCA_OP_MDL_DELETE_REQ))) {
        reject_code = MCA_RSP_SUCCESS;
 /* mdl_id is valid according to the spec */
 switch (evt_data.hdr.op_code) {
 case MCA_OP_MDL_CREATE_REQ:
            evt_data.create_ind.dep_id = *p++;
            evt_data.create_ind.cfg = *p++;
            p_rx_msg->mdep_id = evt_data.create_ind.dep_id;
 if (!mca_is_valid_dep_id(p_ccb->p_rcb, p_rx_msg->mdep_id)) {
              MCA_TRACE_ERROR("%s: Invalid local MDEP ID %d", __func__,
                              p_rx_msg->mdep_id);
              reject_code = MCA_RSP_BAD_MDEP;
 } else if (mca_ccb_uses_mdl_id(p_ccb, evt_data.hdr.mdl_id)) {
              MCA_TRACE_DEBUG("the mdl_id is currently used in the CL(create)");
              mca_dcb_close_by_mdl_id(p_ccb, evt_data.hdr.mdl_id);
 } else {
 /* check if this dep still have MDL available */
 if (mca_dep_free_mdl(p_ccb, evt_data.create_ind.dep_id) == 0) {
                MCA_TRACE_ERROR("%s: MAX_MDL is used by MDEP %d", __func__,
                                evt_data.create_ind.dep_id);
                reject_code = MCA_RSP_MDEP_BUSY;
 }
 }
 break;

 case MCA_OP_MDL_RECONNECT_REQ:
 if (mca_ccb_uses_mdl_id(p_ccb, evt_data.hdr.mdl_id)) {
              MCA_TRACE_ERROR("%s: MDL_ID %d busy, in CL(reconn)", __func__,
                              evt_data.hdr.mdl_id);
              reject_code = MCA_RSP_MDL_BUSY;
 }
 break;

 case MCA_OP_MDL_ABORT_REQ:
            reject_code = MCA_RSP_BAD_OP;
 break;

 case MCA_OP_MDL_DELETE_REQ:
 /* delete the associated mdl */
            mca_dcb_close_by_mdl_id(p_ccb, evt_data.hdr.mdl_id);
            send_rsp = true;
 break;
 }
 }
 }
 }

 if (((reject_code != MCA_RSP_SUCCESS) &&
 (evt_data.hdr.op_code != MCA_OP_SYNC_INFO_IND)) ||
      send_rsp) {
    BT_HDR* p_buf = (BT_HDR*)osi_malloc(MCA_CTRL_MTU + sizeof(BT_HDR));
    p_buf->offset = L2CAP_MIN_OFFSET;
    p = p_start = (uint8_t*)(p_buf + 1) + L2CAP_MIN_OFFSET;
 *p++ = reject_opcode;
 *p++ = reject_code;
 bool valid_response = true;
 switch (reject_opcode) {
 case MCA_OP_ERROR_RSP:
 case MCA_OP_MDL_CREATE_RSP:
 case MCA_OP_MDL_RECONNECT_RSP:
 case MCA_OP_MDL_ABORT_RSP:
 case MCA_OP_MDL_DELETE_RSP:
        UINT16_TO_BE_STREAM(p, evt_data.hdr.mdl_id);
 break;
 case MCA_OP_SYNC_CAP_RSP:
        memset(p, 0, 7);
        p += 7;
 break;
 case MCA_OP_SYNC_SET_RSP:
        memset(p, 0, 14);
        p += 14;
 break;
 default:
        MCA_TRACE_ERROR("%s: reject_opcode 0x%02x not recognized", __func__,
                        reject_opcode);
        valid_response = false;
 break;
 }
 if (valid_response) {
      p_buf->len = p - p_start;
      MCA_TRACE_ERROR("%s: reject_opcode=0x%02x, reject_code=0x%02x, length=%d",
                      __func__, reject_opcode, reject_code, p_buf->len);
      L2CA_DataWrite(p_ccb->lcid, p_buf);
 } else {
      osi_free(p_buf);
 }
 }

 if (reject_code == MCA_RSP_SUCCESS) {
 /* use the received GKI buffer to store information to double check response
     * API */
    p_rx_msg->op_code = evt_data.hdr.op_code;
    p_rx_msg->mdl_id = evt_data.hdr.mdl_id;
    p_ccb->p_rx_msg = p_rx_msg;
 if (send_rsp) {
      osi_free(p_pkt);
      p_ccb->p_rx_msg = NULL;
 }
    mca_ccb_report_event(p_ccb, evt_data.hdr.op_code, &evt_data);
 } else
    osi_free(p_pkt);
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void Block::SetKey(bool bKey)
{
    if (bKey)
        m_flags |= static_cast<unsigned char>(1 << 7);
    else
        m_flags &= 0x7F;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::LoadedState::onSetInputSurface(
 const sp<AMessage> &msg) {
    ALOGV("onSetInputSurface");

    sp<AMessage> notify = mCodec->mNotify->dup();
    notify->setInt32("what", CodecBase::kWhatInputSurfaceAccepted);

    sp<RefBase> obj;
    CHECK(msg->findObject("input-surface", &obj));
    sp<PersistentSurface> surface = static_cast<PersistentSurface *>(obj.get());

 status_t err = mCodec->mOMX->setInputSurface(
            mCodec->mNode, kPortIndexInput, surface->getBufferConsumer(),
 &mCodec->mInputMetadataType);

 if (err == OK) {
        err = setupInputSurface();
 }

 if (err != OK) {
        ALOGE("[%s] onSetInputSurface returning error %d",
                mCodec->mComponentName.c_str(), err);
        notify->setInt32("err", err);
 }
    notify->post();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMX::fillBuffer(node_id node, buffer_id buffer, int fenceFd) {
 return findInstance(node)->fillBuffer(buffer, fenceFd);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static EAS_RESULT Parse_rgn (SDLS_SYNTHESIZER_DATA *pDLSData, EAS_I32 pos, EAS_I32 size, EAS_U16 artIndex)
{
    EAS_RESULT result;
    EAS_U32 temp;
    EAS_I32 chunkPos;
    EAS_I32 endChunk;
    EAS_I32 rgnhPos;
    EAS_I32 lartPos;
    EAS_I32 lartSize;
    EAS_I32 lar2Pos;
    EAS_I32 lar2Size;
    EAS_I32 wlnkPos;
    EAS_I32 wsmpPos;
    EAS_U32 waveIndex;
    S_DLS_ART_VALUES art;
    S_WSMP_DATA wsmp;
    S_WSMP_DATA *pWsmp;
    EAS_U16 regionIndex;

 /* seek to start of chunk */
 if ((result = EAS_HWFileSeek(pDLSData->hwInstData, pDLSData->fileHandle, pos)) != EAS_SUCCESS)
 return result;

 /* no chunks found yet */
    rgnhPos = lartPos = lartSize = lar2Pos = lar2Size = wsmpPos = wlnkPos = 0;
    regionIndex = (EAS_U16) pDLSData->regionCount;

 /* read to end of chunk */
    endChunk = pos + size;
 while (pos < endChunk)
 {
        chunkPos = pos;

 /* get the next chunk type */
 if ((result = NextChunk(pDLSData, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 /* parse useful chunks */
 switch (temp)
 {
 case CHUNK_CDL:
 if ((result = Parse_cdl(pDLSData, size, &temp)) != EAS_SUCCESS)
 return result;

 /* if conditional chunk evaluates false, skip this list */
 if (!temp)
 return EAS_SUCCESS;
 break;

 case CHUNK_RGNH:
                rgnhPos = chunkPos + 8;
 break;

 case CHUNK_WLNK:
                wlnkPos = chunkPos + 8;
 break;

 case CHUNK_WSMP:
                wsmpPos = chunkPos + 8;
 break;

 case CHUNK_LART:
                lartPos = chunkPos + 12;
                lartSize = size;
 break;

 case CHUNK_LAR2:
                lar2Pos = chunkPos + 12;
                lar2Size = size;
 break;

 default:
 break;
 }
 }

 /* must have a rgnh chunk to be useful */
 if (!rgnhPos)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS rgn chunk has no rgnh chunk\n"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* must have a wlnk chunk to be useful */
 if (!wlnkPos)
 {
 { /* dpp: EAS_ReportEx(_EAS_SEVERITY_ERROR, "DLS rgn chunk has no wlnk chunk\n"); */ }
 return EAS_ERROR_UNRECOGNIZED_FORMAT;
 }

 /* parse wlnk chunk */
 if ((result = Parse_wlnk(pDLSData, wlnkPos, &waveIndex)) != EAS_SUCCESS)
 return result;
    pWsmp = &pDLSData->wsmpData[waveIndex];

 /* if there is any articulation data, parse it */
    EAS_HWMemCpy(&art, &defaultArt, sizeof(S_DLS_ART_VALUES));
 if (lartPos)
 {
 if ((result = Parse_lart(pDLSData, lartPos, lartSize, &art)) != EAS_SUCCESS)
 return result;
 }

 if (lar2Pos)
 {
 if ((result = Parse_lart(pDLSData, lar2Pos, lar2Size, &art)) != EAS_SUCCESS)
 return result;
 }

 /* if second pass, process region header */
 if (pDLSData->pDLS)
 {

 /* if local data was found convert it */
 if (art.values[PARAM_MODIFIED] == EAS_TRUE)
 {
 Convert_art(pDLSData, &art, (EAS_U16) pDLSData->artCount);
            artIndex = (EAS_U16) pDLSData->artCount;
 }

 /* parse region header */
 if ((result = Parse_rgnh(pDLSData, rgnhPos, &pDLSData->pDLS->pDLSRegions[regionIndex & REGION_INDEX_MASK])) != EAS_SUCCESS)
 return result;

 /* parse wsmp chunk, copying parameters from original first */
 if (wsmpPos)
 {
            EAS_HWMemCpy(&wsmp, pWsmp, sizeof(wsmp));
 if ((result = Parse_wsmp(pDLSData, wsmpPos, &wsmp)) != EAS_SUCCESS)
 return result;

            pWsmp = &wsmp;
 }

 Convert_rgn(pDLSData, regionIndex, artIndex, (EAS_U16) waveIndex, pWsmp);
 }

 /* if local articulation, bump count */
 if (art.values[PARAM_MODIFIED])
        pDLSData->artCount++;

 /* increment region count */
    pDLSData->regionCount++;
 return EAS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::Client::setNextPlayer(const sp<IMediaPlayer>& player) {

     ALOGV("setNextPlayer");
     Mutex::Autolock l(mLock);
     sp<Client> c = static_cast<Client*>(player.get());
     mNextClient = c;
 
     if (c != NULL) {
 if (mAudioOutput != NULL) {
            mAudioOutput->setNextOutput(c->mAudioOutput);
 } else if ((mPlayer != NULL) && !mPlayer->hardwareOutput()) {
            ALOGE("no current audio output");
 }

 if ((mPlayer != NULL) && (mNextClient->getPlayer() != NULL)) {
            mPlayer->setNextPlayer(mNextClient->getPlayer());
 }
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SYSCALL_DEFINE2(setreuid, uid_t, ruid, uid_t, euid)
{
 const struct cred *old;
 struct cred *new;
 int retval;

 new = prepare_creds();
 if (!new)
 return -ENOMEM;
	old = current_cred();

	retval = -EPERM;
 if (ruid != (uid_t) -1) {
 new->uid = ruid;
 if (old->uid != ruid &&
		    old->euid != ruid &&
 !nsown_capable(CAP_SETUID))
 goto error;
 }

 if (euid != (uid_t) -1) {
 new->euid = euid;
 if (old->uid != euid &&
		    old->euid != euid &&
		    old->suid != euid &&
 !nsown_capable(CAP_SETUID))
 goto error;
 }

 if (new->uid != old->uid) {
		retval = set_user(new);
 if (retval < 0)
 goto error;
 }
 if (ruid != (uid_t) -1 ||
 (euid != (uid_t) -1 && euid != old->uid))
 new->suid = new->euid;
 new->fsuid = new->euid;

	retval = security_task_fix_setuid(new, old, LSM_SETID_RE);
 if (retval < 0)
 goto error;

 return commit_creds(new);

error:
	abort_creds(new);
 return retval;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint32_t uuid_to_id(const effect_uuid_t * uuid)
{
 size_t i;
 for (i = 0; i < NUM_ID; i++)
 if (memcmp(uuid, uuid_to_id_table[i], sizeof(*uuid)) == 0)
 break;

 return i;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool isValidMotionAction(int32_t action, int32_t actionButton, int32_t pointerCount) {
 switch (action & AMOTION_EVENT_ACTION_MASK) {
 case AMOTION_EVENT_ACTION_DOWN:
 case AMOTION_EVENT_ACTION_UP:
 case AMOTION_EVENT_ACTION_CANCEL:
 case AMOTION_EVENT_ACTION_MOVE:
 case AMOTION_EVENT_ACTION_OUTSIDE:
 case AMOTION_EVENT_ACTION_HOVER_ENTER:
 case AMOTION_EVENT_ACTION_HOVER_MOVE:
 case AMOTION_EVENT_ACTION_HOVER_EXIT:
 case AMOTION_EVENT_ACTION_SCROLL:
 return true;
 case AMOTION_EVENT_ACTION_POINTER_DOWN:
 case AMOTION_EVENT_ACTION_POINTER_UP: {
 int32_t index = getMotionEventActionPointerIndex(action);
 return index >= 0 && size_t(index) < pointerCount;
 }
 case AMOTION_EVENT_ACTION_BUTTON_PRESS:
 case AMOTION_EVENT_ACTION_BUTTON_RELEASE:
 return actionButton != 0;
 default:
 return false;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_entropy_config(OMX_BOOL enable, OMX_U32 i_cabac_level)
{
 int rc = 0;
 struct v4l2_control control;

    DEBUG_PRINT_LOW("venc_set_entropy_config: CABAC = %u level: %u", enable, (unsigned int)i_cabac_level);

 if (enable && (codec_profile.profile != V4L2_MPEG_VIDEO_H264_PROFILE_BASELINE) &&
 (codec_profile.profile != V4L2_MPEG_VIDEO_H264_PROFILE_CONSTRAINED_BASELINE)) {

        control.value = V4L2_MPEG_VIDEO_H264_ENTROPY_MODE_CABAC;
        control.id = V4L2_CID_MPEG_VIDEO_H264_ENTROPY_MODE;

        DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

        DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);
        entropy.longentropysel = control.value;

 if (i_cabac_level == 0) {
            control.value = V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_0;
 } else if (i_cabac_level == 1) {
            control.value = V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_1;
 } else if (i_cabac_level == 2) {
            control.value = V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL_2;
 }

        control.id = V4L2_CID_MPEG_VIDC_VIDEO_H264_CABAC_MODEL;
        DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

        DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);
        entropy.cabacmodel=control.value;
 } else if (!enable) {
        control.value =  V4L2_MPEG_VIDEO_H264_ENTROPY_MODE_CAVLC;
        control.id = V4L2_CID_MPEG_VIDEO_H264_ENTROPY_MODE;
        DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

        DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);
        entropy.longentropysel=control.value;
 } else {
        DEBUG_PRINT_ERROR("Invalid Entropy mode for Baseline Profile");
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t NuPlayer::GenericSource::setBuffers(
         bool audio, Vector<MediaBuffer *> &buffers) {
    if (mIsSecure && !audio) {
         return mVideoTrack.mSource->setBuffers(buffers);
     }
     return INVALID_OPERATION;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAACEncoder2::internalGetParameter(
        OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamAudioPortFormat:
 {
            OMX_AUDIO_PARAM_PORTFORMATTYPE *formatParams =
 (OMX_AUDIO_PARAM_PORTFORMATTYPE *)params;

 if (!isValidOMXParam(formatParams)) {
 return OMX_ErrorBadParameter;
 }

 if (formatParams->nPortIndex > 1) {
 return OMX_ErrorUndefined;
 }

 if (formatParams->nIndex > 0) {
 return OMX_ErrorNoMore;
 }

            formatParams->eEncoding =
 (formatParams->nPortIndex == 0)
 ? OMX_AUDIO_CodingPCM : OMX_AUDIO_CodingAAC;

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {
            OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
 (OMX_AUDIO_PARAM_AACPROFILETYPE *)params;

 if (!isValidOMXParam(aacParams)) {
 return OMX_ErrorBadParameter;
 }

 if (aacParams->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

            aacParams->nBitRate = mBitRate;
            aacParams->nAudioBandWidth = 0;
            aacParams->nAACtools = 0;
            aacParams->nAACERtools = 0;
            aacParams->eAACProfile = (OMX_AUDIO_AACPROFILETYPE) mAACProfile;
            aacParams->eAACStreamFormat = OMX_AUDIO_AACStreamFormatMP4FF;
            aacParams->eChannelMode = OMX_AUDIO_ChannelModeStereo;

            aacParams->nChannels = mNumChannels;
            aacParams->nSampleRate = mSampleRate;
            aacParams->nFrameLength = 0;

 switch (mSBRMode) {
 case 1: // sbr on
 switch (mSBRRatio) {
 case 0:
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidDSBR;
 break;
 case 1:
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidDSBR;
 break;
 case 2:
                    aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidSSBR;
                    aacParams->nAACtools |= OMX_AUDIO_AACToolAndroidDSBR;
 break;
 default:
                    ALOGE("invalid SBR ratio %d", mSBRRatio);
                    TRESPASS();
 }
 break;
 case 0: // sbr off
 case -1: // sbr undefined
                aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidSSBR;
                aacParams->nAACtools &= ~OMX_AUDIO_AACToolAndroidDSBR;
 break;
 default:
                ALOGE("invalid SBR mode %d", mSBRMode);
                TRESPASS();
 }



 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {
            OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex != 0) {
 return OMX_ErrorUndefined;
 }

            pcmParams->eNumData = OMX_NumericalDataSigned;
            pcmParams->eEndian = OMX_EndianBig;
            pcmParams->bInterleaved = OMX_TRUE;
            pcmParams->nBitPerSample = 16;
            pcmParams->ePCMMode = OMX_AUDIO_PCMModeLinear;
            pcmParams->eChannelMapping[0] = OMX_AUDIO_ChannelLF;
            pcmParams->eChannelMapping[1] = OMX_AUDIO_ChannelRF;

            pcmParams->nChannels = mNumChannels;
            pcmParams->nSamplingRate = mSampleRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalGetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int Session_Init(preproc_session_t *session)
{
 size_t i;
 int status = 0;

    session->state = PREPROC_SESSION_STATE_INIT;
    session->id = 0;
    session->io = 0;
    session->createdMsk = 0;
    session->apm = NULL;
 for (i = 0; i < PREPROC_NUM_EFFECTS && status == 0; i++) {
        status = Effect_Init(&session->effects[i], i);
 }
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btif_hl_find_peer_mdep_id(UINT8 app_id, BD_ADDR bd_addr,
                                         tBTA_HL_MDEP_ROLE local_mdep_role,
                                         UINT16 data_type,
                                         tBTA_HL_MDEP_ID *p_peer_mdep_id){
    UINT8               app_idx, mcl_idx;
 btif_hl_mcl_cb_t *p_mcb;
    tBTA_HL_SDP_REC     *p_rec;
    UINT8               i, num_mdeps;
    BOOLEAN             found = FALSE;
    tBTA_HL_MDEP_ROLE   peer_mdep_role;


    BTIF_TRACE_DEBUG("%s app_id=%d local_mdep_role=%d, data_type=%d",
                      __FUNCTION__, app_id, local_mdep_role, data_type);

    BTIF_TRACE_DEBUG("DB [%02x:%02x:%02x:%02x:%02x:%02x]",
                      bd_addr[0],  bd_addr[1],
                      bd_addr[2],  bd_addr[3],
                      bd_addr[4],  bd_addr[5]);


    BTIF_TRACE_DEBUG("local_mdep_role=%d", local_mdep_role);
    BTIF_TRACE_DEBUG("data_type=%d", data_type);

 if (local_mdep_role == BTA_HL_MDEP_ROLE_SINK)
        peer_mdep_role = BTA_HL_MDEP_ROLE_SOURCE;
 else
        peer_mdep_role = BTA_HL_MDEP_ROLE_SINK;

 if (btif_hl_find_app_idx(app_id, &app_idx) )
 {
        BTIF_HL_GET_APP_CB_PTR(app_idx);
 if (btif_hl_find_mcl_idx(app_idx, bd_addr, &mcl_idx))
 {
            p_mcb  =BTIF_HL_GET_MCL_CB_PTR(app_idx, mcl_idx);

            BTIF_TRACE_DEBUG("app_idx=%d mcl_idx=%d",app_idx, mcl_idx);
            BTIF_TRACE_DEBUG("valid_spd_idx=%d sdp_idx=%d",p_mcb->valid_sdp_idx, p_mcb->sdp_idx);
 if (p_mcb->valid_sdp_idx)
 {
                p_rec = &p_mcb->sdp.sdp_rec[p_mcb->sdp_idx];
                num_mdeps = p_rec->num_mdeps;
                BTIF_TRACE_DEBUG("num_mdeps=%d", num_mdeps);

 for (i=0; i< num_mdeps; i++)
 {
                    BTIF_TRACE_DEBUG("p_rec->mdep_cfg[%d].mdep_role=%d",i, p_rec->mdep_cfg[i].mdep_role);
                    BTIF_TRACE_DEBUG("p_rec->mdep_cfg[%d].data_type =%d",i, p_rec->mdep_cfg[i].data_type );
 if ((p_rec->mdep_cfg[i].mdep_role == peer_mdep_role) &&
 (p_rec->mdep_cfg[i].data_type == data_type))
 {
                        found = TRUE;
 *p_peer_mdep_id = p_rec->mdep_cfg[i].mdep_id;
 break;
 }
 }
 }
 }
 }

    BTIF_TRACE_DEBUG("found =%d  *p_peer_mdep_id=%d", found, *p_peer_mdep_id);

 return found;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void processWakeupCallback(int fd, short flags, void *param) {
 char buff[16];
 int ret;

    RLOGV("processWakeupCallback");

 /* empty our wakeup socket out */
 do {
        ret = read(s_fdWakeupRead, &buff, sizeof(buff));
 } while (ret > 0 || (ret < 0 && errno == EINTR));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD16 impeg2d_dec_vld_symbol(stream_t *ps_stream,const WORD16 ai2_code_table[][2],  UWORD16 u2_max_len)
{
  UWORD16 u2_data;
  WORD16  u2_end = 0;
  UWORD16 u2_org_max_len = u2_max_len;
  UWORD16 u2_i_bit;

 /* Get the maximum number of bits needed to decode a symbol */
  u2_data = impeg2d_bit_stream_nxt(ps_stream,u2_max_len);
 do
 {
    u2_max_len--;
 /* Read one bit at a time from the variable to decode the huffman code */
    u2_i_bit = (UWORD8)((u2_data >> u2_max_len) & 0x1);

 /* Get the next node pointer or the symbol from the tree */
    u2_end = ai2_code_table[u2_end][u2_i_bit];
 }while(u2_end > 0);

 /* Flush the appropriate number of bits from the ps_stream */
  impeg2d_bit_stream_flush(ps_stream,(UWORD8)(u2_org_max_len - u2_max_len));
 return(u2_end);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static bool HasAccessorsImpl(JSObject* holder,
 FixedArrayBase* backing_store) {
 return DictionaryElementsAccessor::HasAccessorsImpl(holder, backing_store);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int fuse_setup(struct fuse* fuse, gid_t gid, mode_t mask) {
 char opts[256];

    fuse->fd = open("/dev/fuse", O_RDWR);
 if (fuse->fd == -1) {
        ERROR("failed to open fuse device: %s\n", strerror(errno));
 return -1;
 }

    umount2(fuse->dest_path, MNT_DETACH);

    snprintf(opts, sizeof(opts),
 "fd=%i,rootmode=40000,default_permissions,allow_other,user_id=%d,group_id=%d",
            fuse->fd, fuse->global->uid, fuse->global->gid);
 if (mount("/dev/fuse", fuse->dest_path, "fuse", MS_NOSUID | MS_NODEV | MS_NOEXEC |
            MS_NOATIME, opts) != 0) {
        ERROR("failed to mount fuse filesystem: %s\n", strerror(errno));
 return -1;
 }

    fuse->gid = gid;
    fuse->mask = mask;

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::setInputFilterEnabled(bool enabled) {
#if DEBUG_FOCUS
    ALOGD("setInputFilterEnabled: enabled=%d", enabled);
#endif

 { // acquire lock
 AutoMutex _l(mLock);

 if (mInputFilterEnabled == enabled) {
 return;
 }

        mInputFilterEnabled = enabled;
        resetAndDropEverythingLocked("input filter is being enabled or disabled");
 } // release lock

    mLooper->wake();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btsock_rfc_init(int poll_thread_handle) {
  pth = poll_thread_handle;

  memset(rfc_slots, 0, sizeof(rfc_slots));
 for (size_t i = 0; i < ARRAY_SIZE(rfc_slots); ++i) {
    rfc_slots[i].scn = -1;
    rfc_slots[i].sdp_handle = 0;
    rfc_slots[i].fd = INVALID_FD;
    rfc_slots[i].app_fd = INVALID_FD;
    rfc_slots[i].incoming_queue = list_new(GKI_freebuf);
    assert(rfc_slots[i].incoming_queue != NULL);
 }

  BTA_JvEnable(jv_dm_cback);

 return BT_STATUS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long Segment::ParseCues(long long off, long long& pos, long& len) {
   if (m_pCues)
     return 0;  // success

 if (off < 0)
 return -1;

 long long total, avail;

 const int status = m_pReader->Length(&total, &avail);

 if (status < 0) // error
 return status;

  assert((total < 0) || (avail <= total));

  pos = m_start + off;

 if ((total < 0) || (pos >= total))
 return 1; // don't bother parsing cues

 const long long element_start = pos;
 const long long segment_stop = (m_size < 0) ? -1 : m_start + m_size;

 if ((pos + 1) > avail) {
    len = 1;
 return E_BUFFER_NOT_FULL;
 }

 long long result = GetUIntLength(m_pReader, pos, len);

 if (result < 0) // error
 return static_cast<long>(result);

 if (result > 0) // underflow (weird)
 {
    len = 1;
 return E_BUFFER_NOT_FULL;
 }

 if ((segment_stop >= 0) && ((pos + len) > segment_stop))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 
   const long long idpos = pos;
 
  const long long id = ReadUInt(m_pReader, idpos, len);
 
   if (id != 0x0C53BB6B)  // Cues ID
     return E_FILE_FORMAT_INVALID;

  pos += len; // consume ID
  assert((segment_stop < 0) || (pos <= segment_stop));


 if ((pos + 1) > avail) {
    len = 1;
 return E_BUFFER_NOT_FULL;
 }

  result = GetUIntLength(m_pReader, pos, len);

 if (result < 0) // error
 return static_cast<long>(result);

 if (result > 0) // underflow (weird)
 {
    len = 1;
 return E_BUFFER_NOT_FULL;
 }

 if ((segment_stop >= 0) && ((pos + len) > segment_stop))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 const long long size = ReadUInt(m_pReader, pos, len);

 if (size < 0) // error
 return static_cast<long>(size);

 if (size == 0) // weird, although technically not illegal
 return 1; // done

  pos += len; // consume length of size of element
  assert((segment_stop < 0) || (pos <= segment_stop));


 const long long element_stop = pos + size;

 if ((segment_stop >= 0) && (element_stop > segment_stop))
 return E_FILE_FORMAT_INVALID;

 if ((total >= 0) && (element_stop > total))
 return 1; // don't bother parsing anymore

  len = static_cast<long>(size);

 if (element_stop > avail)
 return E_BUFFER_NOT_FULL;

 const long long element_size = element_stop - element_start;

 
   m_pCues =
       new (std::nothrow) Cues(this, pos, size, element_start, element_size);
  assert(m_pCues);  // TODO
 
   return 0;  // success
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: display_error(png_structp pp, png_const_charp error)
{
 struct display *dp = get_dp(pp);

   display_log(dp, LIBPNG_ERROR, "%s", error);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void addRange(vector<uint32_t> &coverage, uint32_t start, uint32_t end) {
#ifdef VERBOSE_DEBUG
    ALOGD("adding range %d-%d\n", start, end);
#endif
 if (coverage.empty() || coverage.back() < start) {
        coverage.push_back(start);
        coverage.push_back(end);
 } else {
        coverage.back() = end;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    void SetConstantInput(int value) {
     memset(input_, value, kInputBufferSize);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  static uint32_t GetMaxIndex(JSObject* receiver, FixedArrayBase* elements) {
    UNREACHABLE();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Chapters::Atom::GetDisplayCount() const { return m_displays_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::TouchState::removeWindow(const sp<InputWindowHandle>& windowHandle) {
 for (size_t i = 0; i < windows.size(); i++) {
 if (windows.itemAt(i).windowHandle == windowHandle) {
            windows.removeAt(i);
 return;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void AddElementsToKeyAccumulatorImpl(Handle<JSObject> receiver,
 KeyAccumulator* accumulator,
 AddKeyConversion convert) {
 Isolate* isolate = receiver->GetIsolate();
 Handle<FixedArrayBase> elements(receiver->elements());
 uint32_t length = AccessorClass::GetCapacityImpl(*receiver, *elements);
 for (uint32_t i = 0; i < length; i++) {
 Handle<Object> value = AccessorClass::GetImpl(isolate, *elements, i);
      accumulator->AddKey(value, convert);
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const CuePoint::TrackPosition* CuePoint::Find(const Track* pTrack) const
{
    assert(pTrack);
 
    const long long n = pTrack->GetNumber();
 
    const TrackPosition* i = m_track_positions;
    const TrackPosition* const j = i + m_track_positions_count;
 
    while (i != j)
    {
        const TrackPosition& p = *i++;
 
        if (p.m_track == n)
            return &p;
    }
    return NULL;  //no matching track number found
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int out_standby(struct audio_stream *stream)
{
 struct stream_out *out = (struct stream_out *)stream;
 struct audio_device *adev = out->dev;

    ALOGV("%s: enter: usecase(%d: %s)", __func__,
          out->usecase, use_case_table[out->usecase]);
    lock_output_stream(out);
 if (!out->standby) {
        pthread_mutex_lock(&adev->lock);
        do_out_standby_l(out);
        pthread_mutex_unlock(&adev->lock);
 }
    pthread_mutex_unlock(&out->lock);
    ALOGV("%s: exit", __func__);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_ble_rx_test_cback(void *p)
{
    btif_transfer_context(btif_dm_generic_evt, BTIF_DM_CB_LE_RX_TEST,
 (char *)p, 1, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: make_size_image(png_store* PNG_CONST ps, png_byte PNG_CONST colour_type,
    png_byte PNG_CONST bit_depth, int PNG_CONST interlace_type,
    png_uint_32 PNG_CONST w, png_uint_32 PNG_CONST h,
    int PNG_CONST do_interlace)
 {
    context(ps, fault);
 
   /* At present libpng does not support the write of an interlaced image unless
    * PNG_WRITE_INTERLACING_SUPPORTED, even with do_interlace so the code here
    * does the pixel interlace itself, so:
    */
    check_interlace_type(interlace_type);
 
    Try
 {
      png_infop pi;
      png_structp pp;
 unsigned int pixel_size;

 
       /* Make a name and get an appropriate id for the store: */
       char name[FILE_NAME_SIZE];
      PNG_CONST png_uint_32 id = FILEID(colour_type, bit_depth, 0/*palette*/,
          interlace_type, w, h, do_interlace);
 
       standard_name_from_id(name, sizeof name, 0, id);
      pp = set_store_for_write(ps, &pi, name);

 /* In the event of a problem return control to the Catch statement below
       * to do the clean up - it is not possible to 'return' directly from a Try
       * block.
       */
 if (pp == NULL)
 Throw ps;

      png_set_IHDR(pp, pi, w, h, bit_depth, colour_type, interlace_type,
         PNG_COMPRESSION_TYPE_BASE, PNG_FILTER_TYPE_BASE);

#ifdef PNG_TEXT_SUPPORTED
 {
 static char key[] = "image name"; /* must be writeable */
 size_t pos;
         png_text text;
 char copy[FILE_NAME_SIZE];

 /* Use a compressed text string to test the correct interaction of text
          * compression and IDAT compression.
          */
         text.compression = TEXT_COMPRESSION;
         text.key = key;
 /* Yuck: the text must be writable! */
         pos = safecat(copy, sizeof copy, 0, ps->wname);
         text.text = copy;
         text.text_length = pos;
         text.itxt_length = 0;
         text.lang = 0;
         text.lang_key = 0;

         png_set_text(pp, pi, &text, 1);
 }
#endif

 if (colour_type == 3) /* palette */
         init_standard_palette(ps, pp, pi, 1U << bit_depth, 0/*do tRNS*/);

      png_write_info(pp, pi);

 /* Calculate the bit size, divide by 8 to get the byte size - this won't
       * overflow because we know the w values are all small enough even for
       * a system where 'unsigned int' is only 16 bits.

        */
       pixel_size = bit_size(pp, colour_type, bit_depth);
       if (png_get_rowbytes(pp, pi) != ((w * pixel_size) + 7) / 8)
         png_error(pp, "row size incorrect");
 
       else
       {
 int npasses = npasses_from_interlace_type(pp, interlace_type);
         png_uint_32 y;
 int pass;
#        ifdef PNG_WRITE_FILTER_SUPPORTED
 int nfilter = PNG_FILTER_VALUE_LAST;
#        endif
         png_byte image[16][SIZE_ROWMAX];

 /* To help consistent error detection make the parts of this buffer
          * that aren't set below all '1':

           */
          memset(image, 0xff, sizeof image);
 
         if (!do_interlace && npasses != png_set_interlace_handling(pp))
             png_error(pp, "write: png_set_interlace_handling failed");
 
          /* Prepare the whole image first to avoid making it 7 times: */
 for (y=0; y<h; ++y)
            size_row(image[y], w * pixel_size, y);


          for (pass=0; pass<npasses; ++pass)
          {
             /* The following two are for checking the macros: */
            PNG_CONST png_uint_32 wPass = PNG_PASS_COLS(w, pass);
 
             /* If do_interlace is set we don't call png_write_row for every
              * row because some of them are empty.  In fact, for a 1x1 image,
             * most of them are empty!
             */
 for (y=0; y<h; ++y)
 {
               png_const_bytep row = image[y];
               png_byte tempRow[SIZE_ROWMAX];

 /* If do_interlace *and* the image is interlaced we
                * need a reduced interlace row; this may be reduced
                * to empty.
                */
 if (do_interlace && interlace_type == PNG_INTERLACE_ADAM7)
 {
 /* The row must not be written if it doesn't exist, notice
                   * that there are two conditions here, either the row isn't
                   * ever in the pass or the row would be but isn't wide
                   * enough to contribute any pixels.  In fact the wPass test
                   * can be used to skip the whole y loop in this case.
                   */
 if (PNG_ROW_IN_INTERLACE_PASS(y, pass) && wPass > 0)
 {
 /* Set to all 1's for error detection (libpng tends to

                       * set unset things to 0).
                       */
                      memset(tempRow, 0xff, sizeof tempRow);
                     interlace_row(tempRow, row, pixel_size, w, pass);
                      row = tempRow;
                   }
                   else
 continue;
 }

#           ifdef PNG_WRITE_FILTER_SUPPORTED
 /* Only get to here if the row has some pixels in it, set the
                * filters to 'all' for the very first row and thereafter to a
                * single filter.  It isn't well documented, but png_set_filter
                * does accept a filter number (per the spec) as well as a bit
                * mask.
                *
                * The apparent wackiness of decrementing nfilter rather than
                * incrementing is so that Paeth gets used in all images bigger
                * than 1 row - it's the tricky one.
                */
               png_set_filter(pp, 0/*method*/,
                  nfilter >= PNG_FILTER_VALUE_LAST ? PNG_ALL_FILTERS : nfilter);

 if (nfilter-- == 0)
                  nfilter = PNG_FILTER_VALUE_LAST-1;
#           endif

               png_write_row(pp, row);
 }
 }
 }

#ifdef PNG_TEXT_SUPPORTED
 {
 static char key[] = "end marker";
 static char comment[] = "end";
         png_text text;

 /* Use a compressed text string to test the correct interaction of text
          * compression and IDAT compression.
          */
         text.compression = TEXT_COMPRESSION;
         text.key = key;
         text.text = comment;
         text.text_length = (sizeof comment)-1;
         text.itxt_length = 0;
         text.lang = 0;
         text.lang_key = 0;

         png_set_text(pp, pi, &text, 1);
 }
#endif

      png_write_end(pp, pi);

 /* And store this under the appropriate id, then clean up. */
      store_storefile(ps, id);

      store_write_reset(ps);
 }

 Catch(fault)
 {
 /* Use the png_store returned by the exception. This may help the compiler
       * because 'ps' is not used in this branch of the setjmp.  Note that fault
       * and ps will always be the same value.
       */
      store_write_reset(fault);
 }

 }

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: ACodec::ExecutingToIdleState::ExecutingToIdleState(ACodec *codec)
 : BaseState(codec),
      mComponentNowIdle(false) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_get_tu_data_size(WORD32 num_luma_samples)
{


    WORD32 tu_data_size;
    WORD32 num_ctb;
    WORD32 num_luma_tu, num_chroma_tu, num_tu;
    num_ctb = num_luma_samples / (MIN_CTB_SIZE * MIN_CTB_SIZE);

    num_luma_tu = num_luma_samples / (MIN_TU_SIZE * MIN_TU_SIZE);
    num_chroma_tu = num_luma_tu >> 1;

    num_tu = num_luma_tu + num_chroma_tu;
    tu_data_size = 0;

 /* Size for storing tu_t start index each CTB */
 /* One extra entry is needed to compute number of TUs in the last CTB */
    tu_data_size += (num_ctb + 1) * sizeof(WORD32);

 /* Size for storing tu map */
    tu_data_size += num_luma_tu * sizeof(UWORD8);

 /* Size for storing tu_t for each TU */
    tu_data_size += num_tu * sizeof(tu_t);

 /* Size for storing number of coded subblocks and scan_idx for each TU */
    tu_data_size += num_tu * (sizeof(WORD8) + sizeof(WORD8));

 /* Size for storing coeff data for each TU */
    tu_data_size += num_tu * sizeof(tu_sblk_coeff_data_t);


 return tu_data_size;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: read_4(struct file *file, png_uint_32 *pu)
 /* Read four bytes, returns the number of bytes read successfully and, if all
    * four bytes are read, assigns the result to *pu.
    */
{
 unsigned int i = 0;
   png_uint_32 val = 0;

 do
 {
 int ch = read_byte(file);

 if (ch == EOF)
 return i;

      val = (val << 8) + ch;
 } while (++i < 4);

 *pu = val;
 return i;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_delete(iv_obj_t *ps_codec_obj, void *pv_api_ip, void *pv_api_op)
{
 codec_t *ps_dec;
 ihevcd_cxa_delete_ip_t *ps_ip = (ihevcd_cxa_delete_ip_t *)pv_api_ip;
 ihevcd_cxa_delete_op_t *ps_op = (ihevcd_cxa_delete_op_t *)pv_api_op;

    ps_dec = (codec_t *)(ps_codec_obj->pv_codec_handle);
    UNUSED(ps_ip);
    ps_op->s_ivd_delete_op_t.u4_error_code = 0;
    ihevcd_free_dynamic_bufs(ps_dec);
    ihevcd_free_static_bufs(ps_codec_obj);
 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::commandStartFaceDetectionL(int /*type*/) {
    ALOGV("%s: Camera %d: Starting face detection",
          __FUNCTION__, mCameraId);
 status_t res;
 SharedParameters::Lock l(mParameters);
 switch (l.mParameters.state) {
 case Parameters::DISCONNECTED:
 case Parameters::STOPPED:
 case Parameters::WAITING_FOR_PREVIEW_WINDOW:
 case Parameters::STILL_CAPTURE:
            ALOGE("%s: Camera %d: Cannot start face detection without preview active",
                    __FUNCTION__, mCameraId);
 return INVALID_OPERATION;
 case Parameters::PREVIEW:
 case Parameters::RECORD:
 case Parameters::VIDEO_SNAPSHOT:
 break;
 }
 if (l.mParameters.fastInfo.bestFaceDetectMode ==
            ANDROID_STATISTICS_FACE_DETECT_MODE_OFF) {
        ALOGE("%s: Camera %d: Face detection not supported",
                __FUNCTION__, mCameraId);
 return BAD_VALUE;
 }
 if (l.mParameters.enableFaceDetect) return OK;

    l.mParameters.enableFaceDetect = true;

    res = updateRequests(l.mParameters);

 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::onFrameRendered(int64_t mediaTimeUs, nsecs_t systemNano) {
 if (mRenderTracker.onFrameRendered(mediaTimeUs, systemNano) != OK) {
        mRenderTracker.dumpRenderQueue();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ContentEncoding::ContentEncryption::ContentEncryption()
 : algo(0),
      key_id(NULL),
      key_id_len(0),
      signature(NULL),
      signature_len(0),
      sig_key_id(NULL),
      sig_key_id_len(0),
      sig_algo(0),
      sig_hash_algo(0) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: wifi_error wifi_set_nodfs_flag(wifi_interface_handle handle, u32 nodfs)
{
 SetNodfsCommand command(handle, nodfs);
 return (wifi_error) command.requestResponse();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_sec_device_down (void)
{
    BTM_TRACE_EVENT ("btm_sec_device_down()  State: %s", btm_pair_state_descr(btm_cb.pairing_state));

    btm_sec_change_pairing_state (BTM_PAIR_STATE_IDLE);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_av_rc_browse_close(tBTA_AV_CB* p_cb, tBTA_AV_DATA* p_data) {
  APPL_TRACE_WARNING("%s: empty placeholder does nothing!", __func__);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void readpng2_warning_handler(png_structp png_ptr, png_const_charp msg)

 {
     fprintf(stderr, "readpng2 libpng warning: %s\n", msg);
     fflush(stderr);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int enable_snd_device(struct audio_device *adev,
 struct audio_usecase *uc_info,
 snd_device_t snd_device,
 bool update_mixer)
{
 struct mixer_card *mixer_card;
 struct listnode *node;
 const char *snd_device_name = get_snd_device_name(snd_device);

 if (snd_device_name == NULL)
 return -EINVAL;

    adev->snd_dev_ref_cnt[snd_device]++;
 if (adev->snd_dev_ref_cnt[snd_device] > 1) {
        ALOGV("%s: snd_device(%d: %s) is already active",
              __func__, snd_device, snd_device_name);
 return 0;
 }

    ALOGV("%s: snd_device(%d: %s)", __func__,
          snd_device, snd_device_name);

    list_for_each(node, &uc_info->mixer_list) {
        mixer_card = node_to_item(node, struct mixer_card, uc_list_node[uc_info->id]);
        audio_route_apply_path(mixer_card->audio_route, snd_device_name);
 if (update_mixer)
            audio_route_update_mixer(mixer_card->audio_route);
 }

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_hl_co_save_mdl(UINT8 mdep_id, UINT8 item_idx, tBTA_HL_MDL_CFG *p_mdl_cfg )
{

    BTIF_TRACE_DEBUG("%s mdep_id =%d, item_idx=%d active=%d mdl_id=%d time=%d",
                      __FUNCTION__, mdep_id, item_idx,
                      p_mdl_cfg->active,
                      p_mdl_cfg->mdl_id,
                      p_mdl_cfg->time);

    btif_hl_save_mdl_cfg(mdep_id, item_idx, p_mdl_cfg);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ASessionDescription::parseNTPRange(
 const char *s, float *npt1, float *npt2) {
 if (s[0] == '-') {
 return false; // no start time available.
 }

 if (!strncmp("now", s, 3)) {
 return false; // no absolute start time available
 }

 char *end;
 *npt1 = strtof(s, &end);

 if (end == s || *end != '-') {
 return false;
 }

    s = end + 1; // skip the dash.

 if (*s == '\0') {
 *npt2 = FLT_MAX; // open ended.
 return true;
 }

 if (!strncmp("now", s, 3)) {
 return false; // no absolute end time available
 }

 *npt2 = strtof(s, &end);

 if (end == s || *end != '\0') {
 return false;
 }

 return *npt2 > *npt1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Chapters::Display::~Display() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: write_one_file(Image *output, Image *image, int convert_to_8bit)
{
 if (image->opts & FAST_WRITE)
      image->image.flags |= PNG_IMAGE_FLAG_FAST;

 
    if (image->opts & USE_STDIO)
    {
       FILE *f = tmpfile();
 
       if (f != NULL)
       {
 if (png_image_write_to_stdio(&image->image, f, convert_to_8bit,
            image->buffer+16, (png_int_32)image->stride, image->colormap))
 {
 if (fflush(f) == 0)
 {
               rewind(f);
               initimage(output, image->opts, "tmpfile", image->stride_extra);
               output->input_file = f;
 if (!checkopaque(image))
 return 0;
 }

 else
 return logclose(image, f, "tmpfile", ": flush: ");
 }

 else
 {
            fclose(f);
 return logerror(image, "tmpfile", ": write failed", "");
 }
 }

 else
 return logerror(image, "tmpfile", ": open: ", strerror(errno));
 }

 else
 {
 static int counter = 0;
 char name[32];

      sprintf(name, "%s%d.png", tmpf, ++counter);

 if (png_image_write_to_file(&image->image, name, convert_to_8bit,
         image->buffer+16, (png_int_32)image->stride, image->colormap))
 {
         initimage(output, image->opts, output->tmpfile_name,
            image->stride_extra);
 /* Afterwards, or freeimage will delete it! */
         strcpy(output->tmpfile_name, name);

 if (!checkopaque(image))
 return 0;
 }

 else
 return logerror(image, name, ": write failed", "");
 }

 /* 'output' has an initialized temporary image, read this back in and compare
    * this against the original: there should be no change since the original
    * format was written unmodified unless 'convert_to_8bit' was specified.
    * However, if the original image was color-mapped, a simple read will zap
    * the linear, color and maybe alpha flags, this will cause spurious failures
    * under some circumstances.
    */
 if (read_file(output, image->image.format | FORMAT_NO_CHANGE, NULL))
 {
      png_uint_32 original_format = image->image.format;

 if (convert_to_8bit)
         original_format &= ~PNG_FORMAT_FLAG_LINEAR;

 if ((output->image.format & BASE_FORMATS) !=
 (original_format & BASE_FORMATS))
 return logerror(image, image->file_name, ": format changed on read: ",
            output->file_name);

 return compare_two_images(image, output, 0/*via linear*/, NULL);
 }

 else
 return logerror(output, output->tmpfile_name,
 ": read of new file failed", "");
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual status_t encryptNative(
 const sp<GraphicBuffer> &graphicBuffer,
 size_t offset, size_t size, uint32_t streamCTR,
 uint64_t *outInputCTR, void *outData) {
 Parcel data, reply;
        data.writeInterfaceToken(IHDCP::getInterfaceDescriptor());
        data.write(*graphicBuffer);
        data.writeInt32(offset);
        data.writeInt32(size);
        data.writeInt32(streamCTR);
        remote()->transact(HDCP_ENCRYPT_NATIVE, data, &reply);

 status_t err = reply.readInt32();

 if (err != OK) {
 *outInputCTR = 0;
 return err;
 }

 *outInputCTR = reply.readInt64();
        reply.read(outData, size);

 return err;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ASessionDescription::getDurationUs(int64_t *durationUs) const {
 *durationUs = 0;

    CHECK(mIsValid);

 AString value;
 if (!findAttribute(0, "a=range", &value)) {
 return false;
 }

 if (strncmp(value.c_str(), "npt=", 4)) {
 return false;
 }

 float from, to;
 if (!parseNTPRange(value.c_str() + 4, &from, &to)) {
 return false;
 }

 *durationUs = (int64_t)((to - from) * 1E6);

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline SkRegion* GetSkRegion(JNIEnv* env, jobject regionObject) {
    jlong regionHandle = env->GetLongField(regionObject, gRegion_nativeInstanceFieldID);
 SkRegion* region = reinterpret_cast<SkRegion*>(regionHandle);
 SkASSERT(region != NULL);
 return region;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btm_sec_change_pairing_state (tBTM_PAIRING_STATE new_state)
{
    tBTM_PAIRING_STATE  old_state = btm_cb.pairing_state;

    BTM_TRACE_EVENT ("btm_sec_change_pairing_state  Old: %s",  btm_pair_state_descr(btm_cb.pairing_state));
    BTM_TRACE_EVENT ("btm_sec_change_pairing_state  New: %s pairing_flags:0x%x",btm_pair_state_descr(new_state), btm_cb.pairing_flags);

    btm_cb.pairing_state = new_state;

 if (new_state == BTM_PAIR_STATE_IDLE)
 {
        btu_stop_timer (&btm_cb.pairing_tle);

        btm_cb.pairing_flags = 0;
        btm_cb.pin_code_len  = 0;

 /* Make sure the the lcb shows we are not bonding */
        l2cu_update_lcb_4_bonding (btm_cb.pairing_bda, FALSE);

        btm_restore_mode();
        btm_sec_check_pending_reqs();
        btm_inq_clear_ssp();

        memset (btm_cb.pairing_bda, 0xFF, BD_ADDR_LEN);
 }
 else
 {
 /* If transitionng out of idle, mark the lcb as bonding */
 if (old_state == BTM_PAIR_STATE_IDLE)
            l2cu_update_lcb_4_bonding (btm_cb.pairing_bda, TRUE);

        btm_cb.pairing_tle.param = (TIMER_PARAM_TYPE)btm_sec_pairing_timeout;

        btu_start_timer (&btm_cb.pairing_tle, BTU_TTYPE_USER_FUNC, BTM_SEC_TIMEOUT_VALUE);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::useBuffer(
        OMX_U32 portIndex, const sp<IMemory> &params,
        OMX::buffer_id *buffer, OMX_U32 allottedSize) {
 if (params == NULL || buffer == NULL) {
        ALOGE("b/25884056");
 return BAD_VALUE;
 }

 Mutex::Autolock autoLock(mLock);
 if (allottedSize > params->size() || portIndex >= NELEM(mNumPortBuffers)) {
 return BAD_VALUE;
 }

 BufferMeta *buffer_meta;
 bool useBackup = mMetadataType[portIndex] != kMetadataBufferTypeInvalid;
    OMX_U8 *data = static_cast<OMX_U8 *>(params->pointer());
 if (useBackup) {
        data = new (std::nothrow) OMX_U8[allottedSize];
 if (data == NULL) {
 return NO_MEMORY;
 }
        memset(data, 0, allottedSize);

 if (allottedSize != params->size()) {
            CLOG_ERROR(useBuffer, BAD_VALUE, SIMPLE_BUFFER(portIndex, (size_t)allottedSize, data));
 delete[] data;
 return BAD_VALUE;
 }

        buffer_meta = new BufferMeta(
                params, portIndex, false /* copyToOmx */, false /* copyFromOmx */, data);
 } else {
        buffer_meta = new BufferMeta(
                params, portIndex, false /* copyToOmx */, false /* copyFromOmx */, NULL);
 }

    OMX_BUFFERHEADERTYPE *header;

    OMX_ERRORTYPE err = OMX_UseBuffer(
            mHandle, &header, portIndex, buffer_meta,
            allottedSize, data);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(useBuffer, err, SIMPLE_BUFFER(
                portIndex, (size_t)allottedSize, data));

 delete buffer_meta;
        buffer_meta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, buffer_meta);

 *buffer = makeBufferID(header);

    addActiveBuffer(portIndex, *buffer);

    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && portIndex == kPortIndexInput) {
        bufferSource->addCodecBuffer(header);
 }

    CLOG_BUFFER(useBuffer, NEW_BUFFER_FMT(
 *buffer, portIndex, "%u(%zu)@%p", allottedSize, params->size(), params->pointer()));
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_send_dhkey_check(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);
  smp_send_cmd(SMP_OPCODE_PAIR_DHKEY_CHECK, p_cb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AudioFlinger::EffectModule::setSuspended(bool suspended)
{
 Mutex::Autolock _l(mLock);
    mSuspended = suspended;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Track::GetNext(
    const BlockEntry* pCurrEntry,
    const BlockEntry*& pNextEntry) const
{
    assert(pCurrEntry);
    assert(!pCurrEntry->EOS());  //?
 
    const Block* const pCurrBlock = pCurrEntry->GetBlock();
    assert(pCurrBlock && pCurrBlock->GetTrackNumber() == m_info.number);
    if (!pCurrBlock || pCurrBlock->GetTrackNumber() != m_info.number)
        return -1;
 
    const Cluster* pCluster = pCurrEntry->GetCluster();
    assert(pCluster);
    assert(!pCluster->EOS());
 
    long status = pCluster->GetNext(pCurrEntry, pNextEntry);
 
    if (status < 0)  //error
         return status;
 
    for (int i = 0; ; )
    {
        while (pNextEntry)
        {
            const Block* const pNextBlock = pNextEntry->GetBlock();
            assert(pNextBlock);
 
            if (pNextBlock->GetTrackNumber() == m_info.number)
                return 0;
 
            pCurrEntry = pNextEntry;
 
            status = pCluster->GetNext(pCurrEntry, pNextEntry);
 
            if (status < 0) //error
                return status;
        }
 
        pCluster = m_pSegment->GetNext(pCluster);
 
        if (pCluster == NULL)
        {
            pNextEntry = GetEOS();
            return 1;
        }
 
        if (pCluster->EOS())
        {
 #if 0
             if (m_pSegment->Unparsed() <= 0)   //all clusters have been loaded
             {
                pNextEntry = GetEOS();

                 return 1;
             }
 #else
            if (m_pSegment->DoneParsing())
            {
                pNextEntry = GetEOS();
                return 1;
            }
 #endif
 
 
            pNextEntry = NULL;
            return E_BUFFER_NOT_FULL;
        }
        status = pCluster->GetFirst(pNextEntry);
        if (status < 0)  //error
            return status;
        if (pNextEntry == NULL)  //empty cluster
            continue;
        ++i;
        if (i >= 100)
            break;
     }
 
 
    pNextEntry = GetEOS();  //so we can return a non-NULL value
    return 1;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void CopyDictionaryToObjectElements(
 FixedArrayBase* from_base, uint32_t from_start, FixedArrayBase* to_base,
 ElementsKind to_kind, uint32_t to_start, int raw_copy_size) {
 DisallowHeapAllocation no_allocation;
 SeededNumberDictionary* from = SeededNumberDictionary::cast(from_base);
 int copy_size = raw_copy_size;
 if (raw_copy_size < 0) {
    DCHECK(raw_copy_size == ElementsAccessor::kCopyToEnd ||
           raw_copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole);
    copy_size = from->max_number_key() + 1 - from_start;
 if (raw_copy_size == ElementsAccessor::kCopyToEndAndInitializeToHole) {
 int start = to_start + copy_size;
 int length = to_base->length() - start;
 if (length > 0) {
 Heap* heap = from->GetHeap();
 MemsetPointer(FixedArray::cast(to_base)->data_start() + start,
                      heap->the_hole_value(), length);
 }
 }
 }
  DCHECK(to_base != from_base);
  DCHECK(IsFastSmiOrObjectElementsKind(to_kind));
 if (copy_size == 0) return;
 FixedArray* to = FixedArray::cast(to_base);
 uint32_t to_length = to->length();
 if (to_start + copy_size > to_length) {
    copy_size = to_length - to_start;
 }
 WriteBarrierMode write_barrier_mode = IsFastObjectElementsKind(to_kind)
 ? UPDATE_WRITE_BARRIER
 : SKIP_WRITE_BARRIER;
 Isolate* isolate = from->GetIsolate();
 for (int i = 0; i < copy_size; i++) {
 int entry = from->FindEntry(isolate, i + from_start);
 if (entry != SeededNumberDictionary::kNotFound) {
 Object* value = from->ValueAt(entry);
      DCHECK(!value->IsTheHole(isolate));
      to->set(i + to_start, value, write_barrier_mode);
 } else {
      to->set_the_hole(isolate, i + to_start);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BnMemoryHeap::onTransact(
 uint32_t code, const Parcel& data, Parcel* reply, uint32_t flags)
{
 switch(code) {
 case HEAP_ID: {
            CHECK_INTERFACE(IMemoryHeap, data, reply);
            reply->writeFileDescriptor(getHeapID());
            reply->writeInt32(getSize());
            reply->writeInt32(getFlags());
            reply->writeInt32(getOffset());
 return NO_ERROR;
 } break;
 default:
 return BBinder::onTransact(code, data, reply, flags);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::set_buffer_req(vdec_allocatorproperty *buffer_prop)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned buf_size = 0;
 struct v4l2_format fmt;
 struct v4l2_requestbuffers bufreq;
 int ret;
    DEBUG_PRINT_LOW("SetBufReq IN: ActCnt(%d) Size(%u)",
            buffer_prop->actualcount, (unsigned int)buffer_prop->buffer_size);
    buf_size = (buffer_prop->buffer_size + buffer_prop->alignment - 1)&(~(buffer_prop->alignment - 1));
 if (buf_size != buffer_prop->buffer_size) {
        DEBUG_PRINT_ERROR("Buffer size alignment error: Requested(%u) Required(%d)",
 (unsigned int)buffer_prop->buffer_size, buf_size);
        eRet = OMX_ErrorBadParameter;
 } else {
        memset(&fmt, 0x0, sizeof(struct v4l2_format));
        fmt.fmt.pix_mp.height = drv_ctx.video_resolution.frame_height;
        fmt.fmt.pix_mp.width = drv_ctx.video_resolution.frame_width;

 if (buffer_prop->buffer_type == VDEC_BUFFER_TYPE_INPUT) {
            fmt.type =V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
            fmt.fmt.pix_mp.pixelformat = output_capability;
            fmt.fmt.pix_mp.plane_fmt[0].sizeimage = buf_size;
 } else if (buffer_prop->buffer_type == VDEC_BUFFER_TYPE_OUTPUT) {
            fmt.type =V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
            fmt.fmt.pix_mp.pixelformat = capture_capability;
 } else {
            eRet = OMX_ErrorBadParameter;
 }

        ret = ioctl(drv_ctx.video_driver_fd, VIDIOC_S_FMT, &fmt);
 if (ret) {
 /*TODO: How to handle this case */
            DEBUG_PRINT_ERROR("Setting buffer requirements (format) failed %d", ret);
            eRet = OMX_ErrorInsufficientResources;
 }

        bufreq.memory = V4L2_MEMORY_USERPTR;
        bufreq.count = buffer_prop->actualcount;
 if (buffer_prop->buffer_type == VDEC_BUFFER_TYPE_INPUT) {
            bufreq.type=V4L2_BUF_TYPE_VIDEO_OUTPUT_MPLANE;
 } else if (buffer_prop->buffer_type == VDEC_BUFFER_TYPE_OUTPUT) {
            bufreq.type=V4L2_BUF_TYPE_VIDEO_CAPTURE_MPLANE;
 } else {
            eRet = OMX_ErrorBadParameter;
 }

 if (eRet==OMX_ErrorNone) {
            ret = ioctl(drv_ctx.video_driver_fd,VIDIOC_REQBUFS, &bufreq);
 }

 if (ret) {
            DEBUG_PRINT_ERROR("Setting buffer requirements (reqbufs) failed %d", ret);
 /*TODO: How to handle this case */
            eRet = OMX_ErrorInsufficientResources;
 } else if (bufreq.count < buffer_prop->actualcount) {
            DEBUG_PRINT_ERROR("Driver refused to change the number of buffers"
 " on v4l2 port %d to %d (prefers %d)", bufreq.type,
                    buffer_prop->actualcount, bufreq.count);
            eRet = OMX_ErrorInsufficientResources;
 } else {
 if (!client_buffers.update_buffer_req()) {
                DEBUG_PRINT_ERROR("Setting c2D buffer requirements failed");
                eRet = OMX_ErrorInsufficientResources;
 }
 }
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t MediaHTTP::readAt(off64_t offset, void *data, size_t size) {
 if (mInitCheck != OK) {
 return mInitCheck;
 }

 int64_t startTimeUs = ALooper::GetNowUs();

 size_t numBytesRead = 0;
 while (numBytesRead < size) {
 size_t copy = size - numBytesRead;

 if (copy > 64 * 1024) {
            copy = 64 * 1024;
 }

 ssize_t n = mHTTPConnection->readAt(
                offset + numBytesRead, (uint8_t *)data + numBytesRead, copy);

 if (n < 0) {
 return n;
 } else if (n == 0) {
 break;
 }

        numBytesRead += n;
 }

 int64_t delayUs = ALooper::GetNowUs() - startTimeUs;

    addBandwidthMeasurement(numBytesRead, delayUs);

 return numBytesRead;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   uint8_t* output() const {
     return output_ + BorderTop() * kOuterBlockSize + BorderLeft();
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int in_close_pcm_devices(struct stream_in *in)
{
 struct pcm_device *pcm_device;
 struct listnode *node;
 struct audio_device *adev = in->dev;

    list_for_each(node, &in->pcm_dev_list) {
        pcm_device = node_to_item(node, struct pcm_device, stream_list_node);
 if (pcm_device) {
 if (pcm_device->pcm)
                pcm_close(pcm_device->pcm);
            pcm_device->pcm = NULL;
 if (pcm_device->sound_trigger_handle > 0)
                adev->sound_trigger_close_for_streaming(
                        pcm_device->sound_trigger_handle);
            pcm_device->sound_trigger_handle = 0;
 }
 }
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::unbumpDebugLevel_l(size_t portIndex) {
 if (mDebugLevelBumpPendingBuffers[portIndex]) {
 --mDebugLevelBumpPendingBuffers[portIndex];
 }
 if (!mDebugLevelBumpPendingBuffers[0]
 && !mDebugLevelBumpPendingBuffers[1]) {
        DEBUG_BUMP = DEBUG;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int32_t DownmixLib_Release(effect_handle_t handle) {
 downmix_module_t *pDwmModule = (downmix_module_t *)handle;

    ALOGV("DownmixLib_Release() %p", handle);
 if (handle == NULL) {
 return -EINVAL;
 }

    pDwmModule->context.state = DOWNMIX_STATE_UNINITIALIZED;

    free(pDwmModule);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int equalizer_get_num_presets(equalizer_context_t *context __unused)
{
    ALOGV("%s: presets_num: %d", __func__,
 sizeof(equalizer_preset_names)/sizeof(char *));
 return sizeof(equalizer_preset_names)/sizeof(char *);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int svc_can_register(const uint16_t *name, size_t name_len, pid_t spid, uid_t uid)

 {
     const char *perm = "add";
 
    if (uid >= AID_APP) {
         return 0; /* Don't allow apps to register services */
     }
 
 return check_mac_perms_from_lookup(spid, uid, perm, str8(name, name_len)) ? 1 : 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SoftHEVC::resetDecoder() {
 ivd_ctl_reset_ip_t s_ctl_ip;
 ivd_ctl_reset_op_t s_ctl_op;
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_RESET;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_reset_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_reset_op_t);

    status = ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip,
 (void *)&s_ctl_op);
 if (IV_SUCCESS != status) {
        ALOGE("Error in reset: 0x%x", s_ctl_op.u4_error_code);
 return UNKNOWN_ERROR;
 }
    mSignalledError = false;

 /* Set number of cores/threads to be used by the codec */
    setNumCores();

    mStride = 0;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_decode_slice(UWORD8 u1_is_idr_slice,
                                 UWORD8 u1_nal_ref_idc,
 dec_struct_t *ps_dec /* Decoder parameters */
 )
{
 dec_bit_stream_t * ps_bitstrm = ps_dec->ps_bitstrm;
 dec_pic_params_t *ps_pps;
 dec_seq_params_t *ps_seq;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 pocstruct_t s_tmp_poc;
    WORD32 i_delta_poc[2];
    WORD32 i4_poc = 0;
    UWORD16 u2_first_mb_in_slice, u2_frame_num;
    UWORD8 u1_field_pic_flag, u1_redundant_pic_cnt = 0, u1_slice_type;
    UWORD32 u4_idr_pic_id = 0;
    UWORD8 u1_bottom_field_flag, u1_pic_order_cnt_type;

    UWORD8 u1_nal_unit_type;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    WORD8 i1_is_end_of_poc;

    WORD32 ret, end_of_frame;
    WORD32 prev_slice_err, num_mb_skipped;
    UWORD8 u1_mbaff;
 pocstruct_t *ps_cur_poc;

    UWORD32 u4_temp;
    WORD32 i_temp;
    UWORD32 u4_call_end_of_pic = 0;

 /* read FirstMbInSlice  and slice type*/
    ps_dec->ps_dpb_cmds->u1_dpb_commands_read_slc = 0;
    u2_first_mb_in_slice = ih264d_uev(pu4_bitstrm_ofst,
                                     pu4_bitstrm_buf);
 if(u2_first_mb_in_slice
 > (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs))
 {

 return ERROR_CORRUPTED_SLICE;
 }

 /*we currently don not support ASO*/
 if(((u2_first_mb_in_slice << ps_cur_slice->u1_mbaff_frame_flag)
 <= ps_dec->u2_cur_mb_addr) && (ps_dec->u2_cur_mb_addr != 0)
 && (ps_dec->u4_first_slice_in_pic != 0))
 {
 return ERROR_CORRUPTED_SLICE;
 }

    COPYTHECONTEXT("SH: first_mb_in_slice",u2_first_mb_in_slice);

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);

 if(u4_temp > 9)
 return ERROR_INV_SLC_TYPE_T;

    u1_slice_type = u4_temp;
    COPYTHECONTEXT("SH: slice_type",(u1_slice_type));
    ps_dec->u1_sl_typ_5_9 = 0;
 /* Find Out the Slice Type is 5 to 9 or not then Set the Flag   */
 /* u1_sl_typ_5_9 = 1 .Which tells that all the slices in the Pic*/
 /* will be of same type of current                            */
 if(u1_slice_type > 4)
 {
        u1_slice_type -= 5;
        ps_dec->u1_sl_typ_5_9 = 1;
 }

 {
        UWORD32 skip;

 if((ps_dec->i4_app_skip_mode == IVD_SKIP_PB)
 || (ps_dec->i4_dec_skip_mode == IVD_SKIP_PB))
 {
            UWORD32 u4_bit_stream_offset = 0;

 if(ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else if((I_SLICE == u1_slice_type)
 && (1 >= ps_dec->ps_cur_sps->u1_num_ref_frames))
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else
 {
                skip = 1;
 }

 /* If one frame worth of data is already skipped, do not skip the next one */
 if((0 == u2_first_mb_in_slice) && (1 == ps_dec->u4_prev_nal_skipped))
 {
                skip = 0;
 }

 if(skip)
 {
                ps_dec->u4_prev_nal_skipped = 1;
                ps_dec->i4_dec_skip_mode = IVD_SKIP_PB;
 return 0;
 }
 else
 {
 /* If the previous NAL was skipped, then
                 do not process that buffer in this call.
                 Return to app and process it in the next call.
                 This is necessary to handle cases where I/IDR is not complete in
                 the current buffer and application intends to fill the remaining part of the bitstream
                 later. This ensures we process only frame worth of data in every call */
 if(1 == ps_dec->u4_prev_nal_skipped)
 {
                    ps_dec->u4_return_to_app = 1;
 return 0;
 }
 }
 }

 }

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp & MASK_ERR_PIC_SET_ID)
 return ERROR_INV_SPS_PPS_T;
 /* discard slice if pic param is invalid */
    COPYTHECONTEXT("SH: pic_parameter_set_id", u4_temp);
    ps_pps = &ps_dec->ps_pps[u4_temp];
 if(FALSE == ps_pps->u1_is_valid)
 {
 return ERROR_INV_SPS_PPS_T;
 }
    ps_seq = ps_pps->ps_sps;
 if(!ps_seq)
 return ERROR_INV_SPS_PPS_T;
 if(FALSE == ps_seq->u1_is_valid)
 return ERROR_INV_SPS_PPS_T;

 /* Get the frame num */
    u2_frame_num = ih264d_get_bits_h264(ps_bitstrm,
                                         ps_seq->u1_bits_in_frm_num);

    COPYTHECONTEXT("SH: frame_num", u2_frame_num);

 /* Get the field related flags  */
 if(!ps_seq->u1_frame_mbs_only_flag)
 {

        u1_field_pic_flag = ih264d_get_bit_h264(ps_bitstrm);
        COPYTHECONTEXT("SH: field_pic_flag", u1_field_pic_flag);
        u1_bottom_field_flag = 0;

 if(u1_field_pic_flag)
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan_fld;
            u1_bottom_field_flag = ih264d_get_bit_h264(ps_bitstrm);
            COPYTHECONTEXT("SH: bottom_field_flag", u1_bottom_field_flag);

 }
 else
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }
 }
 else
 {
        u1_field_pic_flag = 0;
        u1_bottom_field_flag = 0;

        ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }

    u1_nal_unit_type = SLICE_NAL;
 if(u1_is_idr_slice)
 {
 if(0 == u1_field_pic_flag)
 {
            ps_dec->u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY;
 }
        u1_nal_unit_type = IDR_SLICE_NAL;
        u4_idr_pic_id = ih264d_uev(pu4_bitstrm_ofst,
                                   pu4_bitstrm_buf);
 if(u4_idr_pic_id > 65535)
 return ERROR_INV_SPS_PPS_T;
        COPYTHECONTEXT("SH:  ", u4_idr_pic_id);
 }

 /* read delta pic order count information*/
    i_delta_poc[0] = i_delta_poc[1] = 0;
    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    u1_pic_order_cnt_type = ps_seq->u1_pic_order_cnt_type;
 if(u1_pic_order_cnt_type == 0)
 {
        i_temp = ih264d_get_bits_h264(
                        ps_bitstrm,
                        ps_seq->u1_log2_max_pic_order_cnt_lsb_minus);
 if(i_temp < 0 || i_temp >= ps_seq->i4_max_pic_order_cntLsb)
 return ERROR_INV_SPS_PPS_T;
        s_tmp_poc.i4_pic_order_cnt_lsb = i_temp;
        COPYTHECONTEXT("SH: pic_order_cnt_lsb", s_tmp_poc.i4_pic_order_cnt_lsb);

 if((ps_pps->u1_pic_order_present_flag == 1) && (!u1_field_pic_flag))
 {
            s_tmp_poc.i4_delta_pic_order_cnt_bottom = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt_bottom",
                            s_tmp_poc.i4_delta_pic_order_cnt_bottom);
 }
 }

    s_tmp_poc.i4_delta_pic_order_cnt[0] = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[1] = 0;
 if(u1_pic_order_cnt_type == 1
 && (!ps_seq->u1_delta_pic_order_always_zero_flag))
 {
        s_tmp_poc.i4_delta_pic_order_cnt[0] = ih264d_sev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
        COPYTHECONTEXT("SH: delta_pic_order_cnt[0]",
                        s_tmp_poc.i4_delta_pic_order_cnt[0]);

 if(ps_pps->u1_pic_order_present_flag && !u1_field_pic_flag)
 {
            s_tmp_poc.i4_delta_pic_order_cnt[1] = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt[1]",
                            s_tmp_poc.i4_delta_pic_order_cnt[1]);
 }
 }

 if(ps_pps->u1_redundant_pic_cnt_present_flag)
 {
        u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp > MAX_REDUNDANT_PIC_CNT)
 return ERROR_INV_SPS_PPS_T;
        u1_redundant_pic_cnt = u4_temp;
        COPYTHECONTEXT("SH: redundant_pic_cnt", u1_redundant_pic_cnt);
 }

 /*--------------------------------------------------------------------*/
 /* Check if the slice is part of new picture                          */
 /*--------------------------------------------------------------------*/
    i1_is_end_of_poc = 0;
 if(!ps_dec->u1_first_slice_in_stream)
 {
        i1_is_end_of_poc = ih264d_is_end_of_pic(u2_frame_num, u1_nal_ref_idc,
 &s_tmp_poc, &ps_dec->s_cur_pic_poc,
                                            ps_cur_slice, u1_pic_order_cnt_type,
                                            u1_nal_unit_type, u4_idr_pic_id,
                                            u1_field_pic_flag,
                                            u1_bottom_field_flag);

 /* since we support only Full frame decode, every new process should
         * process a new pic
         */
 if((ps_dec->u4_first_slice_in_pic == 2) && (i1_is_end_of_poc == 0))
 {
 /* if it is the first slice is process call ,it should be a new frame. If it is not
             * reject current pic and dont add it to dpb
             */
            ps_dec->ps_dec_err_status->u1_err_flag |= REJECT_CUR_PIC;
            i1_is_end_of_poc = 1;
 }
 else
 {
 /* reset REJECT_CUR_PIC */
            ps_dec->ps_dec_err_status->u1_err_flag &= MASK_REJECT_CUR_PIC;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Check for error in slice and parse the missing/corrupted MB's      */
 /* as skip-MB's in an inserted P-slice                                */
 /*--------------------------------------------------------------------*/
    u1_mbaff = ps_seq->u1_mb_aff_flag && (!u1_field_pic_flag);
    prev_slice_err = 0;

 if(i1_is_end_of_poc || ps_dec->u1_first_slice_in_stream)
 {
 if(u2_frame_num != ps_dec->u2_prv_frame_num
 && ps_dec->u1_top_bottom_decoded != 0
 && ps_dec->u1_top_bottom_decoded
 != (TOP_FIELD_ONLY | BOT_FIELD_ONLY))
 {
            ps_dec->u1_dangling_field = 1;
 if(ps_dec->u4_first_slice_in_pic)
 {
                prev_slice_err = 1;
 }
 else
 {
                prev_slice_err = 2;
 }

 if(ps_dec->u1_top_bottom_decoded ==TOP_FIELD_ONLY)
                ps_cur_slice->u1_bottom_field_flag = 1;
 else
                ps_cur_slice->u1_bottom_field_flag = 0;

            num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &ps_dec->s_cur_pic_poc;

            u1_is_idr_slice = ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL;
 }
 else if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice > 0)
 {
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
                ps_cur_poc = &s_tmp_poc;

                ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
                ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
                ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
                ps_cur_slice->i4_pic_order_cnt_lsb =
                        s_tmp_poc.i4_pic_order_cnt_lsb;
                ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
                ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
                ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
                ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;
 }
 }
 else
 {

 if(ps_dec->u4_first_slice_in_pic)
 {
 /* if valid slice header is not decoded do start of pic processing
                 * since in the current process call, frame num is not updated in the slice structure yet
                 * ih264d_is_end_of_pic is checked with valid frame num of previous process call,
                 * although i1_is_end_of_poc is set there could be  more slices in the frame,
                 * so conceal only till cur slice */
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
 }
 else
 {
 /* since i1_is_end_of_poc is set ,means new frame num is encountered. so conceal the current frame
                 * completely */
                prev_slice_err = 2;
                num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
 }
            ps_cur_poc = &s_tmp_poc;
 }
 }
 else
 {
 if((u2_first_mb_in_slice << u1_mbaff) > ps_dec->u2_total_mbs_coded)
 {
            prev_slice_err = 2;
            num_mb_skipped = (u2_first_mb_in_slice << u1_mbaff)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &s_tmp_poc;
 }
 else if((u2_first_mb_in_slice << u1_mbaff) < ps_dec->u2_total_mbs_coded)
 {
 return ERROR_CORRUPTED_SLICE;
 }
 }

 if(prev_slice_err)
 {
        ret = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, u1_is_idr_slice, u2_frame_num, ps_cur_poc, prev_slice_err);

 if(ps_dec->u1_dangling_field == 1)
 {
            ps_dec->u1_second_field = 1 - ps_dec->u1_second_field;
            ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
            ps_dec->u2_prv_frame_num = u2_frame_num;
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_DANGLING_FIELD_IN_PIC;
 }

 if(prev_slice_err == 2)
 {
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_INCOMPLETE_FRAME;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
 /* return if all MBs in frame are parsed*/
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_IN_LAST_SLICE_OF_PIC;
 }

 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
            ih264d_err_pic_dispbuf_mgr(ps_dec);
 return ERROR_NEW_FRAME_EXPECTED;
 }

 if(ret != OK)
 return ret;

        i1_is_end_of_poc = 0;

     }
 
     if (ps_dec->u4_first_slice_in_pic == 0)
         ps_dec->ps_parse_cur_slice++;
 
     ps_dec->u1_slice_header_done = 0;
 
 /*--------------------------------------------------------------------*/
 /* If the slice is part of new picture, do End of Pic processing.     */
 /*--------------------------------------------------------------------*/
 if(!ps_dec->u1_first_slice_in_stream)
 {
        UWORD8 uc_mbs_exceed = 0;

 if(ps_dec->u2_total_mbs_coded
 == (ps_dec->ps_cur_sps->u2_max_mb_addr + 1))
 {
 /*u2_total_mbs_coded is forced  to u2_max_mb_addr+ 1 at the end of decode ,so
             ,if it is first slice in pic dont consider u2_total_mbs_coded to detect new picture */
 if(ps_dec->u4_first_slice_in_pic == 0)
                uc_mbs_exceed = 1;
 }

 if(i1_is_end_of_poc || uc_mbs_exceed)
 {

 if(1 == ps_dec->u1_last_pic_not_decoded)
 {
                ret = ih264d_end_of_pic_dispbuf_mgr(ps_dec);

 if(ret != OK)
 return ret;

                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
 if(ret != OK)
 return ret;
#if WIN32
                H264_DEC_DEBUG_PRINT(" ------ PIC SKIPPED ------\n");
#endif
 return RET_LAST_SKIP;
 }
 else
 {
                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
 if(ret != OK)
 return ret;
 }

 }
 }

 if(u1_field_pic_flag)
 {
        ps_dec->u2_prv_frame_num = u2_frame_num;
 }

 if(ps_cur_slice->u1_mmco_equalto5)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;

 if(!ps_cur_slice->u1_field_pic_flag) // or a complementary field pair
 {
            i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
            i4_bot_field_order_poc =
                            ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
            i4_temp_poc = MIN(i4_top_field_order_poc,
                                     i4_bot_field_order_poc);
 }
 else if(!ps_cur_slice->u1_bottom_field_flag)
            i4_temp_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
 else
            i4_temp_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;

        ps_dec->ps_cur_pic->i4_top_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        ps_dec->ps_cur_pic->i4_bottom_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
        ps_dec->ps_cur_pic->i4_poc = i4_temp_poc;
        ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
 }
 if(ps_dec->u4_first_slice_in_pic == 2)
 {
        ret = ih264d_decode_pic_order_cnt(u1_is_idr_slice, u2_frame_num,
 &ps_dec->s_prev_pic_poc,
 &s_tmp_poc, ps_cur_slice, ps_pps,
                                          u1_nal_ref_idc,
                                          u1_bottom_field_flag,
                                          u1_field_pic_flag, &i4_poc);
 if(ret != OK)
 return ret;
 /* Display seq no calculations */
 if(i4_poc >= ps_dec->i4_max_poc)
            ps_dec->i4_max_poc = i4_poc;
 /* IDR Picture or POC wrap around */
 if(i4_poc == 0)
 {
            ps_dec->i4_prev_max_display_seq = ps_dec->i4_prev_max_display_seq
 + ps_dec->i4_max_poc
 + ps_dec->u1_max_dec_frame_buffering + 1;
            ps_dec->i4_max_poc = 0;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Copy the values read from the bitstream to the slice header and then*/
 /* If the slice is first slice in picture, then do Start of Picture   */
 /* processing.                                                        */
 /*--------------------------------------------------------------------*/
    ps_cur_slice->i4_delta_pic_order_cnt[0] = i_delta_poc[0];
    ps_cur_slice->i4_delta_pic_order_cnt[1] = i_delta_poc[1];
    ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
    ps_cur_slice->u2_first_mb_in_slice = u2_first_mb_in_slice;
    ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
    ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
    ps_cur_slice->u1_slice_type = u1_slice_type;
    ps_cur_slice->i4_pic_order_cnt_lsb = s_tmp_poc.i4_pic_order_cnt_lsb;

    ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
    ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
    ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
    ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;

 if(ps_seq->u1_frame_mbs_only_flag)
        ps_cur_slice->u1_direct_8x8_inference_flag =
                        ps_seq->u1_direct_8x8_inference_flag;
 else
        ps_cur_slice->u1_direct_8x8_inference_flag = 1;

 if(u1_slice_type == B_SLICE)
 {
        ps_cur_slice->u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264(
                        ps_bitstrm);
        COPYTHECONTEXT("SH: direct_spatial_mv_pred_flag",
                        ps_cur_slice->u1_direct_spatial_mv_pred_flag);

 if(ps_cur_slice->u1_direct_spatial_mv_pred_flag)
            ps_cur_slice->pf_decodeDirect = ih264d_decode_spatial_direct;
 else
            ps_cur_slice->pf_decodeDirect = ih264d_decode_temporal_direct;
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaffB;
 }
 else
 {
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
 }

 if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice == 0)
 {
            ret = ih264d_start_of_pic(ps_dec, i4_poc, &s_tmp_poc, u2_frame_num, ps_pps);
 if(ret != OK)
 return ret;
 }

        ps_dec->u4_output_present = 0;

 {
            ih264d_get_next_display_field(ps_dec,
                                          ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
             hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                ps_dec->u4_output_present = 1;
 }
 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                ps_dec->u4_start_recon_deblk = 0;
                ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }

 }

 /* INITIALIZATION of fn ptrs for MC and formMbPartInfo functions */
 {
        UWORD8 uc_nofield_nombaff;



        uc_nofield_nombaff = ((ps_dec->ps_cur_slice->u1_field_pic_flag == 0)
 && (ps_dec->ps_cur_slice->u1_mbaff_frame_flag == 0)
 && (u1_slice_type != B_SLICE)
 && (ps_dec->ps_cur_pps->u1_wted_pred_flag == 0));

 /* Initialise MC and formMbPartInfo fn ptrs one time based on profile_idc */

 if(uc_nofield_nombaff)
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;
 }
 else
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_mp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_mp;
 }


 }

 /*
     * Decide whether to decode the current picture or not
     */
 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if(ps_err->u4_frm_sei_sync == u2_frame_num)
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
            ps_err->u4_frm_sei_sync = SYNC_FRM_DEFAULT;
 }
        ps_err->u4_cur_frm = u2_frame_num;
 }

 /* Decision for decoding if the picture is to be skipped */
 {
        WORD32 i4_skip_b_pic, i4_skip_p_pic;

        i4_skip_b_pic = (ps_dec->u4_skip_frm_mask & B_SLC_BIT)
 && (B_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

        i4_skip_p_pic = (ps_dec->u4_skip_frm_mask & P_SLC_BIT)
 && (P_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

 /**************************************************************/
 /* Skip the B picture if skip mask is set for B picture and   */
 /* Current B picture is a non reference B picture or there is */
 /* no user for reference B picture                            */
 /**************************************************************/
 if(i4_skip_b_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
 /* Don't decode the picture in SKIP-B mode if that picture is B */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 /**************************************************************/
 /* Skip the P picture if skip mask is set for P picture and   */
 /* Current P picture is a non reference P picture or there is */
 /* no user for reference P picture                            */
 /**************************************************************/
 if(i4_skip_p_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
 /* Don't decode the picture in SKIP-P mode if that picture is P */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 }

 {
        UWORD16 u2_mb_x, u2_mb_y;

        ps_dec->i4_submb_ofst = ((u2_first_mb_in_slice
 << ps_cur_slice->u1_mbaff_frame_flag) * SUB_BLK_SIZE)
 - SUB_BLK_SIZE;
 if(u2_first_mb_in_slice)
 {
            UWORD8 u1_mb_aff;
            UWORD8 u1_field_pic;
            UWORD16 u2_frm_wd_in_mbs;
            u2_frm_wd_in_mbs = ps_seq->u2_frm_wd_in_mbs;
            u1_mb_aff = ps_cur_slice->u1_mbaff_frame_flag;
            u1_field_pic = ps_cur_slice->u1_field_pic_flag;

 {
                UWORD32 x_offset;
                UWORD32 y_offset;
                UWORD32 u4_frame_stride;
 tfr_ctxt_t *ps_trns_addr; // = &ps_dec->s_tran_addrecon_parse;

 if(ps_dec->u1_separate_parse)
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon;
 }
                u2_mb_x = MOD(u2_first_mb_in_slice, u2_frm_wd_in_mbs);
                u2_mb_y = DIV(u2_first_mb_in_slice, u2_frm_wd_in_mbs);

                u2_mb_y <<= u1_mb_aff;

 if((u2_mb_x > u2_frm_wd_in_mbs - 1)
 || (u2_mb_y > ps_dec->u2_frm_ht_in_mbs - 1))
 {
 return ERROR_CORRUPTED_SLICE;
 }

                u4_frame_stride = ps_dec->u2_frm_wd_y << u1_field_pic;
                x_offset = u2_mb_x << 4;
                y_offset = (u2_mb_y * u4_frame_stride) << 4;

                ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1 + x_offset
 + y_offset;

                u4_frame_stride = ps_dec->u2_frm_wd_uv << u1_field_pic;
                x_offset >>= 1;
                y_offset = (u2_mb_y * u4_frame_stride) << 3;

                x_offset *= YUV420SP_FACTOR;

                ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2 + x_offset
 + y_offset;
                ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3 + x_offset
 + y_offset;

                ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
                ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
                ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;


 if(ps_dec->u1_separate_parse == 1)
 {
                    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }
 else
 {
                        ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }

                ps_dec->u2_cur_mb_addr = (u2_first_mb_in_slice << u1_mb_aff);

                ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv
 + ((u2_first_mb_in_slice << u1_mb_aff) << 4);
 }
 }
 else
 {
 tfr_ctxt_t *ps_trns_addr;

 if(ps_dec->u1_separate_parse)
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon;
 }

            u2_mb_x = 0xffff;
            u2_mb_y = 0;
            ps_dec->u2_cur_mb_addr = 0;
            ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
            ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
            ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
            ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
            ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

            ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
            ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
            ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;

 }

        ps_dec->ps_part = ps_dec->ps_parse_part_params;

        ps_dec->u2_mbx =
 (MOD(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby =
 (DIV(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby <<= ps_cur_slice->u1_mbaff_frame_flag;
        ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
        ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
 }

 /* RBSP stop bit is used for CABAC decoding*/
    ps_bitstrm->u4_max_ofst += ps_dec->ps_cur_pps->u1_entropy_coding_mode;

    ps_dec->u1_B = (u1_slice_type == B_SLICE);
    ps_dec->u4_next_mb_skip = 0;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice =
                    ps_dec->ps_cur_slice->u2_first_mb_in_slice;
    ps_dec->ps_parse_cur_slice->slice_type =
                    ps_dec->ps_cur_slice->u1_slice_type;


    ps_dec->u4_start_recon_deblk = 1;
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MAX_FRAMES;
 if((1 >= ps_dec->ps_cur_sps->u1_num_ref_frames) &&
 (0 == ps_dec->i4_display_delay))
 {
            num_entries = 1;
 }
        num_entries = ((2 * num_entries) + 1);
 if(BASE_PROFILE_IDC != ps_dec->ps_cur_sps->u1_profile_idc)
 {
            num_entries *= 2;
 }

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = ( void *)pu1_buf;
 }

 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 if(u1_slice_type == I_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= I_SLC_BIT;

        ret = ih264d_parse_islice(ps_dec, u2_first_mb_in_slice);

 if(ps_dec->i4_pic_type != B_SLICE && ps_dec->i4_pic_type != P_SLICE)
            ps_dec->i4_pic_type = I_SLICE;

 }
 else if(u1_slice_type == P_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
        ret = ih264d_parse_pslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
 if(ps_dec->i4_pic_type != B_SLICE)
            ps_dec->i4_pic_type = P_SLICE;
 }
 else if(u1_slice_type == B_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
        ret = ih264d_parse_bslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
        ps_dec->i4_pic_type = B_SLICE;
 }
 else
 return ERROR_INV_SLC_TYPE_T;

 if(ps_dec->u1_slice_header_done)
 {
 /* set to zero to indicate a valid slice has been decoded */
 /* first slice header successfully decoded */
        ps_dec->u4_first_slice_in_pic = 0;
        ps_dec->u1_first_slice_in_stream = 0;
 }


     if(ret != OK)
         return ret;
 
    ps_dec->u2_cur_slice_num++;
     /* storing last Mb X and MbY of the slice */
     ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
     ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 /* End of Picture detection */

 if(ps_dec->u2_total_mbs_coded >= (ps_seq->u2_max_mb_addr + 1))
 {
        ps_dec->u1_pic_decode_done = 1;

 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if((ps_err->u1_err_flag & REJECT_PB_PICS)
 && (ps_err->u1_cur_pic_type == PIC_TYPE_I))
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

    PRINT_BIN_BIT_RATIO(ps_dec)

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: BpMemoryHeap::~BpMemoryHeap() {
 if (mHeapId != -1) {
        close(mHeapId);
 if (mRealHeap) {
 if (mBase != MAP_FAILED) {
                sp<IBinder> binder = const_cast<BpMemoryHeap*>(this)->asBinder();

 if (VERBOSE) {
                    ALOGD("UNMAPPING binder=%p, heap=%p, size=%zu, fd=%d",
                            binder.get(), this, mSize, mHeapId);
 CallStack stack(LOG_TAG);
 }

                munmap(mBase, mSize);
 }
 } else {
            sp<IBinder> binder = const_cast<BpMemoryHeap*>(this)->asBinder();
            free_heap(binder);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline char* getEmptyString()
{
    gEmptyStringBuf->acquire();
 return gEmptyString;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Parcel::acquireObjects()
{
 const sp<ProcessState> proc(ProcessState::self());
 size_t i = mObjectsSize;
 uint8_t* const data = mData;
 binder_size_t* const objects = mObjects;
 while (i > 0) {
        i--;
 const flat_binder_object* flat
 = reinterpret_cast<flat_binder_object*>(data+objects[i]);
        acquire_object(proc, *flat, this, &mOpenAshmemSize);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dump_nearby_maps(BacktraceMap* map, log_t* log, pid_t tid) {
 siginfo_t si;
  memset(&si, 0, sizeof(si));
 if (ptrace(PTRACE_GETSIGINFO, tid, 0, &si)) {
    _LOG(log, logtype::MAPS, "cannot get siginfo for %d: %s\n", tid, strerror(errno));
 return;
 }

 bool has_fault_address = signal_has_si_addr(si.si_signo);
 uintptr_t addr = reinterpret_cast<uintptr_t>(si.si_addr);

  _LOG(log, logtype::MAPS, "\nmemory map: %s\n", has_fault_address ? "(fault address prefixed with --->)" : "");

 if (has_fault_address && (addr < map->begin()->start)) {
    _LOG(log, logtype::MAPS, "--->Fault address falls at %" PRIPTR " before any mapped regions\n", addr);
 }

 BacktraceMap::const_iterator prev = map->begin();
 for (BacktraceMap::const_iterator it = map->begin(); it != map->end(); ++it) {
 if (addr >= (*prev).end && addr < (*it).start) {
      _LOG(log, logtype::MAPS, "--->Fault address falls at %" PRIPTR " between mapped regions\n", addr);
 }
    prev = it;
 bool in_map = has_fault_address && (addr >= (*it).start) && (addr < (*it).end);
    dump_map(log, &*it, in_map);
 }
 if (has_fault_address && (addr >= (*prev).end)) {
    _LOG(log, logtype::MAPS, "--->Fault address falls at %" PRIPTR " after any mapped regions\n", addr);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:     sp<ABuffer> getBuffer(const OMX_BUFFERHEADERTYPE *header, bool backup, bool limit) {
        sp<ABuffer> buf;
 if (backup && mMem != NULL) {
            buf = new ABuffer(mMem->pointer(), mMem->size());
 } else {
            buf = new ABuffer(header->pBuffer, header->nAllocLen);
 }
 if (limit) {
 if (header->nOffset + header->nFilledLen > header->nOffset
 && header->nOffset + header->nFilledLen <= header->nAllocLen) {
                buf->setRange(header->nOffset, header->nFilledLen);
 } else {
                buf->setRange(0, 0);
 }
 }
 return buf;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__StreamDecoderLengthStatus FLACParser::lengthCallback(
        FLAC__uint64 *stream_length)
{
 off64_t size;
 if (OK == mDataSource->getSize(&size)) {
 *stream_length = size;
 return FLAC__STREAM_DECODER_LENGTH_STATUS_OK;
 } else {
 return FLAC__STREAM_DECODER_LENGTH_STATUS_UNSUPPORTED;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::getConfig(
        OMX_INDEXTYPE index, void *params, size_t /* size */) {
 Mutex::Autolock autoLock(mLock);

 if (isProhibitedIndex_l(index)) {
        android_errorWriteLog(0x534e4554, "29422020");
 return BAD_INDEX;
 }

    OMX_ERRORTYPE err = OMX_GetConfig(mHandle, index, params);
    OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
 if (err != OMX_ErrorNoMore) {
        CLOG_IF_ERROR(getConfig, err, "%s(%#x)", asString(extIndex), index);
 }
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cluster* Segment::FindCluster(long long time_ns) const
{
    if ((m_clusters == NULL) || (m_clusterCount <= 0))
        return &m_eos;
 
    {
        Cluster* const pCluster = m_clusters[0];
        assert(pCluster);
        assert(pCluster->m_index == 0);
 
        if (time_ns <= pCluster->GetTime())
            return pCluster;
    }
 
 
    long i = 0;
    long j = m_clusterCount;
 
    while (i < j)
    {
        const long k = i + (j - i) / 2;
        assert(k < m_clusterCount);
        Cluster* const pCluster = m_clusters[k];
        assert(pCluster);
        assert(pCluster->m_index == k);
        const long long t = pCluster->GetTime();
        if (t <= time_ns)
            i = k + 1;
        else
            j = k;
        assert(i <= j);
    }
    assert(i == j);
    assert(i > 0);
    assert(i <= m_clusterCount);
    const long k = i - 1;
 
     Cluster* const pCluster = m_clusters[k];
     assert(pCluster);
     assert(pCluster->m_index == k);
    assert(pCluster->GetTime() <= time_ns);
 
    return pCluster;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMP3::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamStandardComponentRole:
 {
 const OMX_PARAM_COMPONENTROLETYPE *roleParams =
 (const OMX_PARAM_COMPONENTROLETYPE *)params;

 if (!isValidOMXParam(roleParams)) {
 return OMX_ErrorBadParameter;
 }

 if (strncmp((const char *)roleParams->cRole,
 "audio_decoder.mp3",
                        OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {
 const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
 (const OMX_AUDIO_PARAM_PCMMODETYPE *)params;

 if (!isValidOMXParam(pcmParams)) {
 return OMX_ErrorBadParameter;
 }

 if (pcmParams->nPortIndex != 1) {
 return OMX_ErrorUndefined;
 }

            mNumChannels = pcmParams->nChannels;
            mSamplingRate = pcmParams->nSamplingRate;

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modifier_total_encodings(PNG_CONST png_modifier *pm)
 {
    return 1 +                 /* (1) nothing */
       pm->ngammas +           /* (2) gamma values to test */
      pm->nencodings + /* (3) total number of encodings */
 /* The following test only works after the first time through the
       * png_modifier code because 'bit_depth' is set when the IHDR is read.
       * modifier_reset, below, preserves the setting until after it has called
       * the iterate function (also below.)
       *
       * For this reason do not rely on this function outside a call to
       * modifier_reset.
       */
 ((pm->bit_depth == 16 || pm->assume_16_bit_calculations) ?
         pm->nencodings : 0); /* (4) encodings with gamma == 1.0 */
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void btif_hl_reset_mdep_filter(UINT8 app_idx)
{
 btif_hl_app_cb_t *p_acb  =BTIF_HL_GET_APP_CB_PTR(app_idx);
    p_acb->filter.num_elems = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  status_t OMXNodeInstance::enableNativeBuffers(
         OMX_U32 portIndex, OMX_BOOL graphic, OMX_BOOL enable) {
     Mutex::Autolock autoLock(mLock);
     CLOG_CONFIG(enableNativeBuffers, "%s:%u%s, %d", portString(portIndex), portIndex,
                 graphic ? ", graphic" : "", enable);
    OMX_STRING name = const_cast<OMX_STRING>(
            graphic ? "OMX.google.android.index.enableAndroidNativeBuffers"
 : "OMX.google.android.index.allocateNativeHandle");

    OMX_INDEXTYPE index;
    OMX_ERRORTYPE err = OMX_GetExtensionIndex(mHandle, name, &index);

 if (err == OMX_ErrorNone) {
 EnableAndroidNativeBuffersParams params;
 InitOMXParams(&params);
        params.nPortIndex = portIndex;
        params.enable = enable;

        err = OMX_SetParameter(mHandle, index, &params);
        CLOG_IF_ERROR(setParameter, err, "%s(%#x): %s:%u en=%d", name, index,
                      portString(portIndex), portIndex, enable);
 if (!graphic) {
 if (err == OMX_ErrorNone) {
                mSecureBufferType[portIndex] =
                    enable ? kSecureBufferTypeNativeHandle : kSecureBufferTypeOpaque;
 } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {
                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;
 }
 }
 } else {
        CLOG_ERROR_IF(enable, getExtensionIndex, err, "%s", name);
 if (!graphic) {
 char value[PROPERTY_VALUE_MAX];
 if (property_get("media.mediadrmservice.enable", value, NULL)
 && (!strcmp("1", value) || !strcasecmp("true", value))) {
                CLOG_CONFIG(enableNativeBuffers, "system property override: using native-handles");
                mSecureBufferType[portIndex] = kSecureBufferTypeNativeHandle;
 } else if (mSecureBufferType[portIndex] == kSecureBufferTypeUnknown) {
                mSecureBufferType[portIndex] = kSecureBufferTypeOpaque;
 }
            err = OMX_ErrorNone;
 }
 }

 return StatusFromOMXError(err);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_context_switched(void *p_msg)
{

    BTIF_TRACE_VERBOSE("btif_context_switched");

    tBTIF_CONTEXT_SWITCH_CBACK *p = (tBTIF_CONTEXT_SWITCH_CBACK *) p_msg;

 /* each callback knows how to parse the data */
 if (p->p_cb)
        p->p_cb(p->event, p->p_param);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::write(const void* data, size_t len)
{
 void* const d = writeInplace(len);
 if (d) {
        memcpy(d, data, len);
 return NO_ERROR;
 }
 return mError;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void reference_idct4x4(const int16_t *input, int16_t *output) {
 const int16_t *ip = input;
 int16_t *op = output;

 for (int i = 0; i < 4; ++i) {
 const int a1 = ip[0] + ip[8];
 const int b1 = ip[0] - ip[8];
 const int temp1 = (ip[4] * sinpi8sqrt2) >> 16;
 const int temp2 = ip[12] + ((ip[12] * cospi8sqrt2minus1) >> 16);
 const int c1 = temp1 - temp2;
 const int temp3 = ip[4] + ((ip[4] * cospi8sqrt2minus1) >> 16);
 const int temp4 = (ip[12] * sinpi8sqrt2) >> 16;
 const int d1 = temp3 + temp4;
    op[0] = a1 + d1;
    op[12] = a1 - d1;
    op[4] = b1 + c1;
    op[8] = b1 - c1;
 ++ip;
 ++op;
 }
  ip = output;
  op = output;
 for (int i = 0; i < 4; ++i) {
 const int a1 = ip[0] + ip[2];
 const int b1 = ip[0] - ip[2];
 const int temp1 = (ip[1] * sinpi8sqrt2) >> 16;
 const int temp2 = ip[3] + ((ip[3] * cospi8sqrt2minus1) >> 16);
 const int c1 = temp1 - temp2;
 const int temp3 = ip[1] + ((ip[1] * cospi8sqrt2minus1) >> 16);
 const int temp4 = (ip[3] * sinpi8sqrt2) >> 16;
 const int d1 = temp3 + temp4;
    op[0] = (a1 + d1 + 4) >> 3;
    op[3] = (a1 - d1 + 4) >> 3;
    op[1] = (b1 + c1 + 4) >> 3;
    op[2] = (b1 - c1 + 4) >> 3;
    ip += 4;
    op += 4;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t strlen16(const char16_t *s)
{
 const char16_t *ss = s;
 while ( *ss )
    ss++;
 return ss-s;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void butterfly_16x16_dct_1d(double input[16], double output[16]) {
 double step[16];
 double intermediate[16];
 double temp1, temp2;

  step[ 0] = input[0] + input[15];
  step[ 1] = input[1] + input[14];
  step[ 2] = input[2] + input[13];
  step[ 3] = input[3] + input[12];
  step[ 4] = input[4] + input[11];
  step[ 5] = input[5] + input[10];
  step[ 6] = input[6] + input[ 9];
  step[ 7] = input[7] + input[ 8];
  step[ 8] = input[7] - input[ 8];
  step[ 9] = input[6] - input[ 9];
  step[10] = input[5] - input[10];
  step[11] = input[4] - input[11];
  step[12] = input[3] - input[12];
  step[13] = input[2] - input[13];
  step[14] = input[1] - input[14];
  step[15] = input[0] - input[15];

  output[0] = step[0] + step[7];
  output[1] = step[1] + step[6];
  output[2] = step[2] + step[5];
  output[3] = step[3] + step[4];
  output[4] = step[3] - step[4];
  output[5] = step[2] - step[5];
  output[6] = step[1] - step[6];
  output[7] = step[0] - step[7];

  temp1 = step[ 8] * C7;
  temp2 = step[15] * C9;
  output[ 8] = temp1 + temp2;

  temp1 = step[ 9] * C11;
  temp2 = step[14] * C5;
  output[ 9] = temp1 - temp2;

  temp1 = step[10] * C3;
  temp2 = step[13] * C13;
  output[10] = temp1 + temp2;

  temp1 = step[11] * C15;
  temp2 = step[12] * C1;
  output[11] = temp1 - temp2;

  temp1 = step[11] * C1;
  temp2 = step[12] * C15;
  output[12] = temp2 + temp1;

  temp1 = step[10] * C13;
  temp2 = step[13] * C3;
  output[13] = temp2 - temp1;

  temp1 = step[ 9] * C5;
  temp2 = step[14] * C11;
  output[14] = temp2 + temp1;

  temp1 = step[ 8] * C9;
  temp2 = step[15] * C7;
  output[15] = temp2 - temp1;

  step[ 0] = output[0] + output[3];
  step[ 1] = output[1] + output[2];
  step[ 2] = output[1] - output[2];
  step[ 3] = output[0] - output[3];

  temp1 = output[4] * C14;
  temp2 = output[7] * C2;
  step[ 4] = temp1 + temp2;

  temp1 = output[5] * C10;
  temp2 = output[6] * C6;
  step[ 5] = temp1 + temp2;

  temp1 = output[5] * C6;
  temp2 = output[6] * C10;
  step[ 6] = temp2 - temp1;

  temp1 = output[4] * C2;
  temp2 = output[7] * C14;
  step[ 7] = temp2 - temp1;

  step[ 8] = output[ 8] + output[11];
  step[ 9] = output[ 9] + output[10];
  step[10] = output[ 9] - output[10];
  step[11] = output[ 8] - output[11];

  step[12] = output[12] + output[15];
  step[13] = output[13] + output[14];
  step[14] = output[13] - output[14];
  step[15] = output[12] - output[15];

  output[ 0] = (step[ 0] + step[ 1]);
  output[ 8] = (step[ 0] - step[ 1]);

  temp1 = step[2] * C12;
  temp2 = step[3] * C4;
  temp1 = temp1 + temp2;
  output[ 4] = 2*(temp1 * C8);

  temp1 = step[2] * C4;
  temp2 = step[3] * C12;
  temp1 = temp2 - temp1;
  output[12] = 2 * (temp1 * C8);

  output[ 2] = 2 * ((step[4] + step[ 5]) * C8);
  output[14] = 2 * ((step[7] - step[ 6]) * C8);

  temp1 = step[4] - step[5];
  temp2 = step[6] + step[7];
  output[ 6] = (temp1 + temp2);
  output[10] = (temp1 - temp2);

  intermediate[8] = step[8] + step[14];
  intermediate[9] = step[9] + step[15];

  temp1 = intermediate[8] * C12;
  temp2 = intermediate[9] * C4;
  temp1 = temp1 - temp2;
  output[3] = 2 * (temp1 * C8);

  temp1 = intermediate[8] * C4;
  temp2 = intermediate[9] * C12;
  temp1 = temp2 + temp1;
  output[13] = 2 * (temp1 * C8);

  output[ 9] = 2 * ((step[10] + step[11]) * C8);

  intermediate[11] = step[10] - step[11];
  intermediate[12] = step[12] + step[13];
  intermediate[13] = step[12] - step[13];
  intermediate[14] = step[ 8] - step[14];
  intermediate[15] = step[ 9] - step[15];

  output[15] = (intermediate[11] + intermediate[12]);
  output[ 1] = -(intermediate[11] - intermediate[12]);

  output[ 7] = 2 * (intermediate[13] * C8);

  temp1 = intermediate[14] * C12;
  temp2 = intermediate[15] * C4;
  temp1 = temp1 - temp2;
  output[11] = -2 * (temp1 * C8);

  temp1 = intermediate[14] * C4;
  temp2 = intermediate[15] * C12;
  temp1 = temp2 + temp1;
  output[ 5] = 2 * (temp1 * C8);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeNoException()
{
 return writeInt32(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long UnserializeInt(IMkvReader* pReader, long long pos, long long size,
 long long& result_ref) {
 if (!pReader || pos < 0 || size < 1 || size > 8)
 return E_FILE_FORMAT_INVALID;

 signed char first_byte = 0;
 const long status = pReader->Read(pos, 1, (unsigned char*)&first_byte);

 if (status < 0)
 return status;

 unsigned long long result = first_byte;
 ++pos;

 for (long i = 1; i < size; ++i) {
 unsigned char b;

 const long status = pReader->Read(pos, 1, &b);

 if (status < 0)
 return status;

    result <<= 8;
    result |= b;

 ++pos;
 }

  result_ref = static_cast<long long>(result);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__StreamDecoderReadStatus FLACParser::readCallback(
        FLAC__byte buffer[], size_t *bytes)
{
 size_t requested = *bytes;
 ssize_t actual = mDataSource->readAt(mCurrentPos, buffer, requested);
 if (0 > actual) {
 *bytes = 0;
 return FLAC__STREAM_DECODER_READ_STATUS_ABORT;
 } else if (0 == actual) {
 *bytes = 0;
        mEOF = true;
 return FLAC__STREAM_DECODER_READ_STATUS_END_OF_STREAM;
 } else {
        assert(actual <= requested);
 *bytes = actual;
        mCurrentPos += actual;
 return FLAC__STREAM_DECODER_READ_STATUS_CONTINUE;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void H264SwDecFree(void *ptr) {
    free(ptr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void AddImpl(Handle<JSObject> object, uint32_t index,
 Handle<Object> value, PropertyAttributes attributes,
 uint32_t new_capacity) {
    UNREACHABLE();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: StreamingProcessor::~StreamingProcessor() {
    deletePreviewStream();
    deleteRecordingStream();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: media_status_t AMediaCodecCryptoInfo_getClearBytes(AMediaCodecCryptoInfo* ci, size_t *dst) {
 if (!ci) {
 return AMEDIA_ERROR_INVALID_OBJECT;
 }
 if (!dst) {
 return AMEDIA_ERROR_INVALID_PARAMETER;
 }
    memcpy(dst, ci->clearbytes, sizeof(size_t) * ci->numsubsamples);
 return AMEDIA_OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  ContentEncoding::ContentEncryption::~ContentEncryption() {
  delete [] key_id;
  delete [] signature;
  delete [] sig_key_id;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int blockingWrite_helper(int fd, void *buffer, size_t len) {
 return android::blockingWrite(fd, buffer, len);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static ssize_t out_write(struct audio_stream_out *stream, const void* buffer,
 size_t bytes)
{
 struct a2dp_stream_out *out = (struct a2dp_stream_out *)stream;
 int sent;

    DEBUG("write %zu bytes (fd %d)", bytes, out->common.audio_fd);

    pthread_mutex_lock(&out->common.lock);

 if (out->common.state == AUDIO_A2DP_STATE_SUSPENDED)
 {
        DEBUG("stream suspended");
        pthread_mutex_unlock(&out->common.lock);
 return -1;
 }

 /* only allow autostarting if we are in stopped or standby */
 if ((out->common.state == AUDIO_A2DP_STATE_STOPPED) ||
 (out->common.state == AUDIO_A2DP_STATE_STANDBY))
 {
 if (start_audio_datapath(&out->common) < 0)
 {
 /* emulate time this write represents to avoid very fast write
               failures during transition periods or remote suspend */

 int us_delay = calc_audiotime(out->common.cfg, bytes);

 
             DEBUG("emulate a2dp write delay (%d us)", us_delay);
 
            usleep(us_delay);
             pthread_mutex_unlock(&out->common.lock);
             return -1;
         }
 }
 else if (out->common.state != AUDIO_A2DP_STATE_STARTED)
 {
        ERROR("stream not in stopped or standby");
        pthread_mutex_unlock(&out->common.lock);
 return -1;
 }

    pthread_mutex_unlock(&out->common.lock);
    sent = skt_write(out->common.audio_fd, buffer,  bytes);

 if (sent == -1) {
        skt_disconnect(out->common.audio_fd);
        out->common.audio_fd = AUDIO_SKT_DISCONNECTED;
 if (out->common.state != AUDIO_A2DP_STATE_SUSPENDED)
            out->common.state = AUDIO_A2DP_STATE_STOPPED;
 else
            ERROR("write failed : stream suspended, avoid resetting state");
 } else {
 const size_t frames = bytes / audio_stream_out_frame_size(stream);
        out->frames_rendered += frames;
        out->frames_presented += frames;
 }

    DEBUG("wrote %d bytes out of %zu bytes", sent, bytes);
 return sent;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::read(
 MediaBuffer **out, const ReadOptions *options) {
 Mutex::Autolock autoLock(mLock);

    CHECK(mStarted);

 if (mFirstMoofOffset > 0) {
 return fragmentedRead(out, options);
 }

 *out = NULL;

 int64_t targetSampleTimeUs = -1;

 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if (options && options->getSeekTo(&seekTimeUs, &mode)) {
 uint32_t findFlags = 0;
 switch (mode) {
 case ReadOptions::SEEK_PREVIOUS_SYNC:
                findFlags = SampleTable::kFlagBefore;
 break;
 case ReadOptions::SEEK_NEXT_SYNC:
                findFlags = SampleTable::kFlagAfter;
 break;
 case ReadOptions::SEEK_CLOSEST_SYNC:
 case ReadOptions::SEEK_CLOSEST:
                findFlags = SampleTable::kFlagClosest;
 break;
 default:
                CHECK(!"Should not be here.");
 break;
 }

 uint32_t sampleIndex;
 status_t err = mSampleTable->findSampleAtTime(
                seekTimeUs, 1000000, mTimescale,
 &sampleIndex, findFlags);

 if (mode == ReadOptions::SEEK_CLOSEST) {
            findFlags = SampleTable::kFlagBefore;
 }

 uint32_t syncSampleIndex;
 if (err == OK) {
            err = mSampleTable->findSyncSampleNear(
                    sampleIndex, &syncSampleIndex, findFlags);
 }

 uint32_t sampleTime;
 if (err == OK) {
            err = mSampleTable->getMetaDataForSample(
                    sampleIndex, NULL, NULL, &sampleTime);
 }

 if (err != OK) {
 if (err == ERROR_OUT_OF_RANGE) {
                err = ERROR_END_OF_STREAM;
 }
            ALOGV("end of stream");
 return err;
 }

 if (mode == ReadOptions::SEEK_CLOSEST) {
            targetSampleTimeUs = (sampleTime * 1000000ll) / mTimescale;
 }

#if 0
 uint32_t syncSampleTime;
        CHECK_EQ(OK, mSampleTable->getMetaDataForSample(
                    syncSampleIndex, NULL, NULL, &syncSampleTime));

        ALOGI("seek to time %lld us => sample at time %lld us, "
 "sync sample at time %lld us",
             seekTimeUs,
             sampleTime * 1000000ll / mTimescale,
             syncSampleTime * 1000000ll / mTimescale);
#endif

        mCurrentSampleIndex = syncSampleIndex;
 if (mBuffer != NULL) {
            mBuffer->release();
            mBuffer = NULL;
 }

 }

 off64_t offset;
 size_t size;
 uint32_t cts, stts;
 bool isSyncSample;
 bool newBuffer = false;
 if (mBuffer == NULL) {
        newBuffer = true;

 status_t err =
            mSampleTable->getMetaDataForSample(
                    mCurrentSampleIndex, &offset, &size, &cts, &isSyncSample, &stts);

 if (err != OK) {
 return err;
 }

        err = mGroup->acquire_buffer(&mBuffer);

 if (err != OK) {
            CHECK(mBuffer == NULL);
 return err;
 }
 if (size > mBuffer->size()) {
            ALOGE("buffer too small: %zu > %zu", size, mBuffer->size());
 return ERROR_BUFFER_TOO_SMALL;
 }
 }

 if ((!mIsAVC && !mIsHEVC) || mWantsNALFragments) {
 if (newBuffer) {
 ssize_t num_bytes_read =
                mDataSource->readAt(offset, (uint8_t *)mBuffer->data(), size);

 if (num_bytes_read < (ssize_t)size) {
                mBuffer->release();
                mBuffer = NULL;

 return ERROR_IO;
 }

            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);
            mBuffer->meta_data()->clear();
            mBuffer->meta_data()->setInt64(
                    kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
            mBuffer->meta_data()->setInt64(
                    kKeyDuration, ((int64_t)stts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
                mBuffer->meta_data()->setInt64(
                        kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
                mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;
 }

 if (!mIsAVC && !mIsHEVC) {
 *out = mBuffer;
            mBuffer = NULL;

 return OK;
 }


        CHECK(mBuffer->range_length() >= mNALLengthSize);

 const uint8_t *src =
 (const uint8_t *)mBuffer->data() + mBuffer->range_offset();

 size_t nal_size = parseNALSize(src);
 if (mNALLengthSize > SIZE_MAX - nal_size) {
            ALOGE("b/24441553, b/24445122");
 }
 if (mBuffer->range_length() - mNALLengthSize < nal_size) {
            ALOGE("incomplete NAL unit.");

            mBuffer->release();
            mBuffer = NULL;

 return ERROR_MALFORMED;
 }

 MediaBuffer *clone = mBuffer->clone();
        CHECK(clone != NULL);
        clone->set_range(mBuffer->range_offset() + mNALLengthSize, nal_size);

        CHECK(mBuffer != NULL);
        mBuffer->set_range(
                mBuffer->range_offset() + mNALLengthSize + nal_size,
                mBuffer->range_length() - mNALLengthSize - nal_size);

 if (mBuffer->range_length() == 0) {
            mBuffer->release();
            mBuffer = NULL;
 }

 *out = clone;

 return OK;
 } else {
 ssize_t num_bytes_read = 0;
 int32_t drm = 0;
 bool usesDRM = (mFormat->findInt32(kKeyIsDRM, &drm) && drm != 0);
 if (usesDRM) {
            num_bytes_read =
                mDataSource->readAt(offset, (uint8_t*)mBuffer->data(), size);
 } else {
            num_bytes_read = mDataSource->readAt(offset, mSrcBuffer, size);
 }

 if (num_bytes_read < (ssize_t)size) {
            mBuffer->release();
            mBuffer = NULL;

 return ERROR_IO;
 }

 if (usesDRM) {
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);

 } else {
 uint8_t *dstData = (uint8_t *)mBuffer->data();
 size_t srcOffset = 0;
 size_t dstOffset = 0;

 while (srcOffset < size) {
 bool isMalFormed = !isInRange((size_t)0u, size, srcOffset, mNALLengthSize);
 size_t nalLength = 0;
 if (!isMalFormed) {
                    nalLength = parseNALSize(&mSrcBuffer[srcOffset]);
                    srcOffset += mNALLengthSize;
                    isMalFormed = !isInRange((size_t)0u, size, srcOffset, nalLength);
 }

 if (isMalFormed) {
                    ALOGE("Video is malformed");
                    mBuffer->release();
                    mBuffer = NULL;
 return ERROR_MALFORMED;
 }

 if (nalLength == 0) {
 continue;
 }

 if (dstOffset > SIZE_MAX - 4 ||
                        dstOffset + 4 > SIZE_MAX - nalLength ||
                        dstOffset + 4 + nalLength > mBuffer->size()) {
                    ALOGE("b/27208621 : %zu %zu", dstOffset, mBuffer->size());
                    android_errorWriteLog(0x534e4554, "27208621");
                    mBuffer->release();
                    mBuffer = NULL;
 return ERROR_MALFORMED;
 }

                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 1;
                memcpy(&dstData[dstOffset], &mSrcBuffer[srcOffset], nalLength);
                srcOffset += nalLength;
                dstOffset += nalLength;
 }
            CHECK_EQ(srcOffset, size);
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, dstOffset);
 }

        mBuffer->meta_data()->clear();
        mBuffer->meta_data()->setInt64(
                kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
        mBuffer->meta_data()->setInt64(
                kKeyDuration, ((int64_t)stts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
            mBuffer->meta_data()->setInt64(
                    kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
            mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;

 *out = mBuffer;
        mBuffer = NULL;

 return OK;
 }
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static inline int btpan_role_to_bta(int btpan_role)
{
 int bta_pan_role = PAN_ROLE_INACTIVE;
    BTIF_TRACE_DEBUG("btpan_role:0x%x", btpan_role);
 if (btpan_role & BTPAN_ROLE_PANNAP)
        bta_pan_role |= PAN_ROLE_NAP_SERVER;
 if (btpan_role & BTPAN_ROLE_PANU)
        bta_pan_role |= PAN_ROLE_CLIENT;
 return bta_pan_role;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::use_EGL_image(OMX_IN OMX_HANDLETYPE     hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                        port,
        OMX_IN OMX_PTR                     appData,
        OMX_IN void*                      eglImage)
{
 (void) appData;
    OMX_QCOM_PLATFORM_PRIVATE_LIST pmem_list;
    OMX_QCOM_PLATFORM_PRIVATE_ENTRY pmem_entry;
    OMX_QCOM_PLATFORM_PRIVATE_PMEM_INFO pmem_info;

#ifdef USE_EGL_IMAGE_GPU
    PFNEGLQUERYIMAGEQUALCOMMPROC egl_queryfunc;
 EGLint fd = -1, offset = 0,pmemPtr = 0;
#else
 int fd = -1, offset = 0;
#endif
    DEBUG_PRINT_HIGH("use EGL image support for decoder");
 if (!bufferHdr || !eglImage|| port != OMX_CORE_OUTPUT_PORT_INDEX) {
        DEBUG_PRINT_ERROR("Invalid EGL image");
 }
#ifdef USE_EGL_IMAGE_GPU
 if (m_display_id == NULL) {
        DEBUG_PRINT_ERROR("Display ID is not set by IL client");
 return OMX_ErrorInsufficientResources;
 }
    egl_queryfunc = (PFNEGLQUERYIMAGEQUALCOMMPROC)
        eglGetProcAddress("eglQueryImageKHR");
    egl_queryfunc(m_display_id, eglImage, EGL_BUFFER_HANDLE, &fd);
    egl_queryfunc(m_display_id, eglImage, EGL_BUFFER_OFFSET, &offset);
    egl_queryfunc(m_display_id, eglImage, EGL_BITMAP_POINTER_KHR,&pmemPtr);
#else //with OMX test app
 struct temp_egl {
 int pmem_fd;
 int offset;
 };
 struct temp_egl *temp_egl_id = NULL;
 void * pmemPtr = (void *) eglImage;
    temp_egl_id = (struct temp_egl *)eglImage;
 if (temp_egl_id != NULL) {
        fd = temp_egl_id->pmem_fd;
        offset = temp_egl_id->offset;
 }
#endif
 if (fd < 0) {
        DEBUG_PRINT_ERROR("Improper pmem fd by EGL client %d",fd);
 return OMX_ErrorInsufficientResources;
 }
    pmem_info.pmem_fd = (OMX_U32) fd;
    pmem_info.offset = (OMX_U32) offset;
    pmem_entry.entry = (void *) &pmem_info;
    pmem_entry.type = OMX_QCOM_PLATFORM_PRIVATE_PMEM;
    pmem_list.entryList = &pmem_entry;
    pmem_list.nEntries = 1;
    ouput_egl_buffers = true;
 if (OMX_ErrorNone != use_buffer(hComp,bufferHdr, port,
 (void *)&pmem_list, drv_ctx.op_buf.buffer_size,
 (OMX_U8 *)pmemPtr)) {
        DEBUG_PRINT_ERROR("use buffer call failed for egl image");
 return OMX_ErrorInsufficientResources;
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static dev_t ashmem_rdev()
{
 static dev_t __ashmem_rdev;
 static pthread_mutex_t __ashmem_rdev_lock = PTHREAD_MUTEX_INITIALIZER;

    pthread_mutex_lock(&__ashmem_rdev_lock);

 dev_t rdev = __ashmem_rdev;
 if (!rdev) {
 int fd = TEMP_FAILURE_RETRY(open("/dev/ashmem", O_RDONLY));
 if (fd >= 0) {
 struct stat st;

 int ret = TEMP_FAILURE_RETRY(fstat(fd, &st));
            close(fd);
 if ((ret >= 0) && S_ISCHR(st.st_mode)) {
                rdev = __ashmem_rdev = st.st_rdev;
 }
 }
 }

    pthread_mutex_unlock(&__ashmem_rdev_lock);

 return rdev;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_transform_png_set_@_mod(PNG_CONST image_transform *this,
    image_pixel *that, png_const_structp pp,
    PNG_CONST transform_display *display)
{
   this->next->mod(this->next, that, pp, display);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::component_deinit(OMX_IN OMX_HANDLETYPE hComp)
{
 (void) hComp;
#ifdef _ANDROID_
 if (iDivXDrmDecrypt) {
 delete iDivXDrmDecrypt;
        iDivXDrmDecrypt=NULL;
 }
#endif //_ANDROID_

 unsigned i = 0;
 if (OMX_StateLoaded != m_state) {
        DEBUG_PRINT_ERROR("WARNING:Rxd DeInit,OMX not in LOADED state %d",\
                m_state);
        DEBUG_PRINT_ERROR("Playback Ended - FAILED");
 } else {
        DEBUG_PRINT_HIGH("Playback Ended - PASSED");
 }

 /*Check if the output buffers have to be cleaned up*/
 if (m_out_mem_ptr) {
        DEBUG_PRINT_LOW("Freeing the Output Memory");
 for (i = 0; i < drv_ctx.op_buf.actualcount; i++ ) {
            free_output_buffer (&m_out_mem_ptr[i]);
 }
#ifdef _ANDROID_ICS_
        memset(&native_buffer, 0, (sizeof(nativebuffer) * MAX_NUM_INPUT_OUTPUT_BUFFERS));
#endif
 }

 /*Check if the input buffers have to be cleaned up*/
 if (m_inp_mem_ptr || m_inp_heap_ptr) {
        DEBUG_PRINT_LOW("Freeing the Input Memory");
 for (i = 0; i<drv_ctx.ip_buf.actualcount; i++ ) {
 if (m_inp_mem_ptr)
                free_input_buffer (i,&m_inp_mem_ptr[i]);
 else
                free_input_buffer (i,NULL);
 }
 }
    free_input_buffer_header();
    free_output_buffer_header();
 if (h264_scratch.pBuffer) {
        free(h264_scratch.pBuffer);
        h264_scratch.pBuffer = NULL;
 }

 if (h264_parser) {
 delete h264_parser;
        h264_parser = NULL;
 }

 if (m_frame_parser.mutils) {
        DEBUG_PRINT_LOW("Free utils parser");
 delete (m_frame_parser.mutils);
        m_frame_parser.mutils = NULL;
 }

 if (m_platform_list) {
        free(m_platform_list);
        m_platform_list = NULL;
 }
 if (m_vendor_config.pData) {
        free(m_vendor_config.pData);
        m_vendor_config.pData = NULL;
 }

    m_ftb_q.m_size=0;
    m_cmd_q.m_size=0;
    m_etb_q.m_size=0;
    m_ftb_q.m_read = m_ftb_q.m_write =0;
    m_cmd_q.m_read = m_cmd_q.m_write =0;
    m_etb_q.m_read = m_etb_q.m_write =0;
#ifdef _ANDROID_
 if (m_debug_timestamp) {
        m_timestamp_list.reset_ts_list();
 }
#endif

    DEBUG_PRINT_LOW("Calling VDEC_IOCTL_STOP_NEXT_MSG");
    DEBUG_PRINT_HIGH("Close the driver instance");

 if (m_debug.infile) {
        fclose(m_debug.infile);
        m_debug.infile = NULL;
 }
 if (m_debug.outfile) {
        fclose(m_debug.outfile);
        m_debug.outfile = NULL;
 }
#ifdef OUTPUT_EXTRADATA_LOG
 if (outputExtradataFile)
        fclose (outputExtradataFile);
#endif
    DEBUG_PRINT_INFO("omx_vdec::component_deinit() complete");
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t StreamingProcessor::setRecordingFormat(int format,
        android_dataspace dataSpace) {
    ATRACE_CALL();

 Mutex::Autolock m(mMutex);

    ALOGV("%s: Camera %d: New recording format/dataspace from encoder: %X, %X",
            __FUNCTION__, mId, format, dataSpace);

    mRecordingFormat = format;
    mRecordingDataSpace = dataSpace;
 int prevGrallocUsage = mRecordingGrallocUsage;
 if (mRecordingFormat == HAL_PIXEL_FORMAT_IMPLEMENTATION_DEFINED) {
        mRecordingGrallocUsage = GRALLOC_USAGE_HW_VIDEO_ENCODER;
 } else {
        mRecordingGrallocUsage = GRALLOC_USAGE_SW_READ_OFTEN;
 }

    ALOGV("%s: Camera %d: New recording gralloc usage: %08X", __FUNCTION__, mId,
            mRecordingGrallocUsage);

 if (prevGrallocUsage != mRecordingGrallocUsage) {
        ALOGV("%s: Camera %d: Resetting recording consumer for new usage",
            __FUNCTION__, mId);

 if (isStreamActive(mActiveStreamIds, mRecordingStreamId)) {
            ALOGE("%s: Camera %d: Changing recording format when "
 "recording stream is already active!", __FUNCTION__,
                    mId);
 return INVALID_OPERATION;
 }

        releaseAllRecordingFramesLocked();

        mRecordingConsumer.clear();
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  bool Cues::Find(long long time_ns, const Track* pTrack, const CuePoint*& pCP,
                 const CuePoint::TrackPosition*& pTP) const {
  assert(time_ns >= 0);
  assert(pTrack);
#if 0
    LoadCuePoint();  //establish invariant
    assert(m_cue_points);
    assert(m_count > 0);
    CuePoint** const ii = m_cue_points;
    CuePoint** i = ii;
    CuePoint** const jj = ii + m_count + m_preload_count;
    CuePoint** j = jj;
    pCP = *i;
    assert(pCP);
    if (time_ns <= pCP->GetTime(m_pSegment))
    {
        pTP = pCP->Find(pTrack);
        return (pTP != NULL);
    }
    IMkvReader* const pReader = m_pSegment->m_pReader;
    while (i < j)
    {
        CuePoint** const k = i + (j - i) / 2;
        assert(k < jj);
        CuePoint* const pCP = *k;
        assert(pCP);
        pCP->Load(pReader);
        const long long t = pCP->GetTime(m_pSegment);
        if (t <= time_ns)
            i = k + 1;
        else
            j = k;
        assert(i <= j);
    }
    assert(i == j);
    assert(i <= jj);
    assert(i > ii);
    pCP = *--i;
    assert(pCP);
    assert(pCP->GetTime(m_pSegment) <= time_ns);
#else
  if (m_cue_points == NULL)
    return false;
  if (m_count == 0)
     return false;
 
   CuePoint** const ii = m_cue_points;
 CuePoint** i = ii;

 CuePoint** const jj = ii + m_count;

   CuePoint** j = jj;
 
   pCP = *i;
  assert(pCP);
 
   if (time_ns <= pCP->GetTime(m_pSegment)) {
     pTP = pCP->Find(pTrack);
 return (pTP != NULL);
 }

 while (i < j) {

 
     CuePoint** const k = i + (j - i) / 2;
    assert(k < jj);
 
     CuePoint* const pCP = *k;
    assert(pCP);
 
     const long long t = pCP->GetTime(m_pSegment);
 
 if (t <= time_ns)
      i = k + 1;

     else
       j = k;
 
    assert(i <= j);
   }
 
  assert(i == j);
  assert(i <= jj);
  assert(i > ii);
 
   pCP = *--i;
  assert(pCP);
  assert(pCP->GetTime(m_pSegment) <= time_ns);
#endif
 

  pTP = pCP->Find(pTrack);

   return (pTP != NULL);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: WORD16  impeg2d_get_chroma_dc_diff(stream_t *ps_stream)
{
    UWORD16 u2_dc_size;
    WORD16  i2_dc_diff;
    u2_dc_size = impeg2d_dec_vld_symbol(ps_stream,gai2_impeg2d_dct_dc_size[1],
                        MPEG2_DCT_DC_CHROMA_SIZE_LEN) +
                        MPEG2_DCT_DC_SIZE_OFFSET;
 if (u2_dc_size != 0)
 {
        i2_dc_diff = impeg2d_bit_stream_get(ps_stream,u2_dc_size);
 if ((i2_dc_diff & (1 << (u2_dc_size - 1))) == 0)
            i2_dc_diff -= (1 << u2_dc_size) - 1;
 }
 else
 {
        i2_dc_diff = 0;
 }
 return i2_dc_diff;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: extern "C" int EffectCreate(const effect_uuid_t *uuid,
 int32_t             sessionId,
 int32_t             ioId,
 effect_handle_t *pHandle){
 int ret = 0;
 int sessionNo;
 int i;
 EffectContext *pContext = NULL;
 bool newBundle = false;
 SessionContext *pSessionContext;

    ALOGV("\n\tEffectCreate start session %d", sessionId);

 if (pHandle == NULL || uuid == NULL){
        ALOGV("\tLVM_ERROR : EffectCreate() called with NULL pointer");
        ret = -EINVAL;
 goto exit;
 }

 if(LvmInitFlag == LVM_FALSE){
 LvmInitFlag = LVM_TRUE;
        ALOGV("\tEffectCreate - Initializing all global memory");
 LvmGlobalBundle_init();
 }

 for(i=0; i<LVM_MAX_SESSIONS; i++){
 if((SessionIndex[i] == LVM_UNUSED_SESSION)||(SessionIndex[i] == sessionId)){
            sessionNo       = i;
 SessionIndex[i] = sessionId;
            ALOGV("\tEffectCreate: Allocating SessionNo %d for SessionId %d\n", sessionNo,sessionId);
 break;
 }
 }

 if(i==LVM_MAX_SESSIONS){
        ALOGV("\tLVM_ERROR : Cannot find memory to allocate for current session");
        ret = -EINVAL;
 goto exit;
 }

    pContext = new EffectContext;

 if(GlobalSessionMemory[sessionNo].bBundledEffectsEnabled == LVM_FALSE){
        ALOGV("\tEffectCreate - This is the first effect in current sessionId %d sessionNo %d",
                sessionId, sessionNo);

 GlobalSessionMemory[sessionNo].bBundledEffectsEnabled = LVM_TRUE;
 GlobalSessionMemory[sessionNo].pBundledContext        = new BundledEffectContext;
        newBundle = true;

        pContext->pBundledContext = GlobalSessionMemory[sessionNo].pBundledContext;
        pContext->pBundledContext->SessionNo = sessionNo;
        pContext->pBundledContext->SessionId = sessionId;
        pContext->pBundledContext->hInstance                = NULL;
        pContext->pBundledContext->bVolumeEnabled           = LVM_FALSE;
        pContext->pBundledContext->bEqualizerEnabled        = LVM_FALSE;
        pContext->pBundledContext->bBassEnabled             = LVM_FALSE;
        pContext->pBundledContext->bBassTempDisabled        = LVM_FALSE;
        pContext->pBundledContext->bVirtualizerEnabled      = LVM_FALSE;
        pContext->pBundledContext->bVirtualizerTempDisabled = LVM_FALSE;
        pContext->pBundledContext->NumberEffectsEnabled = 0;
        pContext->pBundledContext->NumberEffectsCalled = 0;
        pContext->pBundledContext->firstVolume              = LVM_TRUE;
        pContext->pBundledContext->volume                   = 0;

 #ifdef LVM_PCM
 char fileName[256];
        snprintf(fileName, 256, "/data/tmp/bundle_%p_pcm_in.pcm", pContext->pBundledContext);
        pContext->pBundledContext->PcmInPtr = fopen(fileName, "w");
 if (pContext->pBundledContext->PcmInPtr == NULL) {
            ALOGV("cannot open %s", fileName);
            ret = -EINVAL;
 goto exit;
 }

        snprintf(fileName, 256, "/data/tmp/bundle_%p_pcm_out.pcm", pContext->pBundledContext);
        pContext->pBundledContext->PcmOutPtr = fopen(fileName, "w");
 if (pContext->pBundledContext->PcmOutPtr == NULL) {
            ALOGV("cannot open %s", fileName);
            fclose(pContext->pBundledContext->PcmInPtr);
           pContext->pBundledContext->PcmInPtr = NULL;
           ret = -EINVAL;
 goto exit;
 }
 #endif

 /* Saved strength is used to return the exact strength that was used in the set to the get
         * because we map the original strength range of 0:1000 to 1:15, and this will avoid
         * quantisation like effect when returning
         */
        pContext->pBundledContext->BassStrengthSaved = 0;
        pContext->pBundledContext->VirtStrengthSaved = 0;
        pContext->pBundledContext->CurPreset = PRESET_CUSTOM;
        pContext->pBundledContext->levelSaved               = 0;
        pContext->pBundledContext->bMuteEnabled             = LVM_FALSE;
        pContext->pBundledContext->bStereoPositionEnabled   = LVM_FALSE;
        pContext->pBundledContext->positionSaved            = 0;
        pContext->pBundledContext->workBuffer               = NULL;
        pContext->pBundledContext->frameCount               = -1;
        pContext->pBundledContext->SamplesToExitCountVirt = 0;
        pContext->pBundledContext->SamplesToExitCountBb = 0;
        pContext->pBundledContext->SamplesToExitCountEq = 0;

 for (int i = 0; i < FIVEBAND_NUMBANDS; i++) {
            pContext->pBundledContext->bandGaindB[i] = EQNB_5BandSoftPresets[i];
 }

        ALOGV("\tEffectCreate - Calling LvmBundle_init");
        ret = LvmBundle_init(pContext);

 if (ret < 0){
            ALOGV("\tLVM_ERROR : EffectCreate() Bundle init failed");
 goto exit;
 }
 }
 else{
        ALOGV("\tEffectCreate - Assigning memory for previously created effect on sessionNo %d",
                sessionNo);
        pContext->pBundledContext =
 GlobalSessionMemory[sessionNo].pBundledContext;
 }
    ALOGV("\tEffectCreate - pBundledContext is %p", pContext->pBundledContext);

    pSessionContext = &GlobalSessionMemory[pContext->pBundledContext->SessionNo];

 if (memcmp(uuid, &gBassBoostDescriptor.uuid, sizeof(effect_uuid_t)) == 0){
        ALOGV("\tEffectCreate - Effect to be created is LVM_BASS_BOOST");
        pSessionContext->bBassInstantiated = LVM_TRUE;
        pContext->pBundledContext->SamplesToExitCountBb = 0;

        pContext->itfe       = &gLvmEffectInterface;
        pContext->EffectType = LVM_BASS_BOOST;
 } else if (memcmp(uuid, &gVirtualizerDescriptor.uuid, sizeof(effect_uuid_t)) == 0){
        ALOGV("\tEffectCreate - Effect to be created is LVM_VIRTUALIZER");
        pSessionContext->bVirtualizerInstantiated=LVM_TRUE;
        pContext->pBundledContext->SamplesToExitCountVirt = 0;

        pContext->itfe       = &gLvmEffectInterface;
        pContext->EffectType = LVM_VIRTUALIZER;
 } else if (memcmp(uuid, &gEqualizerDescriptor.uuid, sizeof(effect_uuid_t)) == 0){
        ALOGV("\tEffectCreate - Effect to be created is LVM_EQUALIZER");
        pSessionContext->bEqualizerInstantiated = LVM_TRUE;
        pContext->pBundledContext->SamplesToExitCountEq = 0;

        pContext->itfe       = &gLvmEffectInterface;
        pContext->EffectType = LVM_EQUALIZER;
 } else if (memcmp(uuid, &gVolumeDescriptor.uuid, sizeof(effect_uuid_t)) == 0){
        ALOGV("\tEffectCreate - Effect to be created is LVM_VOLUME");
        pSessionContext->bVolumeInstantiated = LVM_TRUE;

        pContext->itfe       = &gLvmEffectInterface;
        pContext->EffectType = LVM_VOLUME;
 }
 else{
        ALOGV("\tLVM_ERROR : EffectCreate() invalid UUID");
        ret = -EINVAL;
 goto exit;
 }

exit:
 if (ret != 0) {
 if (pContext != NULL) {
 if (newBundle) {
 GlobalSessionMemory[sessionNo].bBundledEffectsEnabled = LVM_FALSE;
 SessionIndex[sessionNo] = LVM_UNUSED_SESSION;
 delete pContext->pBundledContext;
 }
 delete pContext;
 }
 *pHandle = (effect_handle_t)NULL;
 } else {
 *pHandle = (effect_handle_t)pContext;
 }
    ALOGV("\tEffectCreate end..\n\n");
 return ret;
} /* end EffectCreate */

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  int main(int argc, char **argv) {
   FILE *infile = NULL;
  vpx_codec_ctx_t codec = {0};
  vpx_codec_enc_cfg_t cfg = {0};
   int frame_count = 0;
  vpx_image_t raw = {0};
   vpx_codec_err_t res;
  VpxVideoInfo info = {0};
   VpxVideoWriter *writer = NULL;
   const VpxInterface *encoder = NULL;
   const int fps = 2;        // TODO(dkovalev) add command line argument
   const double bits_per_pixel_per_frame = 0.067;
 
   exec_name = argv[0];
   if (argc != 6)
     die("Invalid number of arguments");
 
  encoder = get_vpx_encoder_by_name(argv[1]);
  if (!encoder)
    die("Unsupported codec.");
 
   info.codec_fourcc = encoder->fourcc;
   info.frame_width = strtol(argv[2], NULL, 0);
   info.frame_height = strtol(argv[3], NULL, 0);
  info.time_base.numerator = 1;
  info.time_base.denominator = fps;

 if (info.frame_width <= 0 ||
      info.frame_height <= 0 ||
 (info.frame_width % 2) != 0 ||
 (info.frame_height % 2) != 0) {
    die("Invalid frame size: %dx%d", info.frame_width, info.frame_height);
 }

 if (!vpx_img_alloc(&raw, VPX_IMG_FMT_I420, info.frame_width,
                                             info.frame_height, 1)) {

     die("Failed to allocate image.");
   }
 
  printf("Using %s\n", vpx_codec_iface_name(encoder->interface()));
 
  res = vpx_codec_enc_config_default(encoder->interface(), &cfg, 0);
   if (res)
     die_codec(&codec, "Failed to get default codec config.");
 
  cfg.g_w = info.frame_width;
  cfg.g_h = info.frame_height;
  cfg.g_timebase.num = info.time_base.numerator;
  cfg.g_timebase.den = info.time_base.denominator;
  cfg.rc_target_bitrate = (unsigned int)(bits_per_pixel_per_frame * cfg.g_w *
                                         cfg.g_h * fps / 1000);
  cfg.g_lag_in_frames = 0;

  writer = vpx_video_writer_open(argv[5], kContainerIVF, &info);
 if (!writer)
    die("Failed to open %s for writing.", argv[5]);


   if (!(infile = fopen(argv[4], "rb")))
     die("Failed to open %s for reading.", argv[4]);
 
  if (vpx_codec_enc_init(&codec, encoder->interface(), &cfg, 0))
     die_codec(&codec, "Failed to initialize encoder");
 
   while (vpx_img_read(&raw, infile)) {
     ++frame_count;
 
 if (frame_count == 22 && encoder->fourcc == VP8_FOURCC) {
      set_roi_map(&cfg, &codec);
 } else if (frame_count == 33) {
      set_active_map(&cfg, &codec);
 } else if (frame_count == 44) {
      unset_active_map(&cfg, &codec);
 }

 
     encode_frame(&codec, &raw, frame_count, writer);
   }
  encode_frame(&codec, NULL, -1, writer);
   printf("\n");
   fclose(infile);
   printf("Processed %d frames.\n", frame_count);

  vpx_img_free(&raw);
 if (vpx_codec_destroy(&codec))
    die_codec(&codec, "Failed to destroy codec.");

  vpx_video_writer_close(writer);

 return EXIT_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: long long Chapters::Atom::GetStopTime(const Chapters* pChapters) const {
 return GetTime(pChapters, m_stop_timecode);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: u32 h264bsdInitDpb(
 dpbStorage_t *dpb,
  u32 picSizeInMbs,
  u32 dpbSize,
  u32 maxRefFrames,
  u32 maxFrameNum,
  u32 noReordering)
{

/* Variables */

    u32 i;

/* Code */

    ASSERT(picSizeInMbs);
    ASSERT(maxRefFrames <= MAX_NUM_REF_PICS);
    ASSERT(maxRefFrames <= dpbSize);

     ASSERT(maxFrameNum);
     ASSERT(dpbSize);
 
     dpb->maxLongTermFrameIdx = NO_LONG_TERM_FRAME_INDICES;
     dpb->maxRefFrames        = MAX(maxRefFrames, 1);
     if (noReordering)
        dpb->dpbSize         = dpb->maxRefFrames;
 else
        dpb->dpbSize         = dpbSize;
    dpb->maxFrameNum         = maxFrameNum;
    dpb->noReordering        = noReordering;
    dpb->fullness            = 0;
    dpb->numRefFrames        = 0;
    dpb->prevRefFrameNum     = 0;

    ALLOCATE(dpb->buffer, MAX_NUM_REF_IDX_L0_ACTIVE + 1, dpbPicture_t);
 if (dpb->buffer == NULL)
 return(MEMORY_ALLOCATION_ERROR);
    H264SwDecMemset(dpb->buffer, 0,
 (MAX_NUM_REF_IDX_L0_ACTIVE + 1)*sizeof(dpbPicture_t));
 for (i = 0; i < dpb->dpbSize + 1; i++)
 {
 /* Allocate needed amount of memory, which is:
         * image size + 32 + 15, where 32 cames from the fact that in ARM OpenMax
         * DL implementation Functions may read beyond the end of an array,
         * by a maximum of 32 bytes. And +15 cames for the need to align memory
         * to 16-byte boundary */
        ALLOCATE(dpb->buffer[i].pAllocatedData, (picSizeInMbs*384 + 32+15), u8);
 if (dpb->buffer[i].pAllocatedData == NULL)
 return(MEMORY_ALLOCATION_ERROR);

        dpb->buffer[i].data = ALIGN(dpb->buffer[i].pAllocatedData, 16);
 }

    ALLOCATE(dpb->list, MAX_NUM_REF_IDX_L0_ACTIVE + 1, dpbPicture_t*);
    ALLOCATE(dpb->outBuf, dpb->dpbSize+1, dpbOutPicture_t);

 if (dpb->list == NULL || dpb->outBuf == NULL)
 return(MEMORY_ALLOCATION_ERROR);

    H264SwDecMemset(dpb->list, 0,
 ((MAX_NUM_REF_IDX_L0_ACTIVE + 1) * sizeof(dpbPicture_t*)) );

    dpb->numOut = dpb->outIndex = 0;

 return(HANTRO_OK);

}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<VBRISeeker> VBRISeeker::CreateFromSource(
 const sp<DataSource> &source, off64_t post_id3_pos) {
 off64_t pos = post_id3_pos;

 uint8_t header[4];
 ssize_t n = source->readAt(pos, header, sizeof(header));
 if (n < (ssize_t)sizeof(header)) {
 return NULL;
 }

 uint32_t tmp = U32_AT(&header[0]);
 size_t frameSize;
 int sampleRate;
 if (!GetMPEGAudioFrameSize(tmp, &frameSize, &sampleRate)) {
 return NULL;
 }

    pos += sizeof(header) + 32;

 uint8_t vbriHeader[26];
    n = source->readAt(pos, vbriHeader, sizeof(vbriHeader));
 if (n < (ssize_t)sizeof(vbriHeader)) {
 return NULL;
 }

 if (memcmp(vbriHeader, "VBRI", 4)) {
 return NULL;
 }

 size_t numFrames = U32_AT(&vbriHeader[14]);

 int64_t durationUs =
        numFrames * 1000000ll * (sampleRate >= 32000 ? 1152 : 576) / sampleRate;

    ALOGV("duration = %.2f secs", durationUs / 1E6);

 size_t numEntries = U16_AT(&vbriHeader[18]);
 size_t entrySize = U16_AT(&vbriHeader[22]);
 size_t scale = U16_AT(&vbriHeader[20]);

    ALOGV("%zu entries, scale=%zu, size_per_entry=%zu",
         numEntries,

          scale,
          entrySize);
 
     size_t totalEntrySize = numEntries * entrySize;
    uint8_t *buffer = new uint8_t[totalEntrySize];
 
     n = source->readAt(pos + sizeof(vbriHeader), buffer, totalEntrySize);
     if (n < (ssize_t)totalEntrySize) {
 delete[] buffer;
        buffer = NULL;


         return NULL;
     }
 
    sp<VBRISeeker> seeker = new VBRISeeker;
     seeker->mBasePos = post_id3_pos + frameSize;
 if (durationUs) {
        seeker->mDurationUs = durationUs;
 }

 off64_t offset = post_id3_pos;
 for (size_t i = 0; i < numEntries; ++i) {
 uint32_t numBytes;
 switch (entrySize) {
 case 1: numBytes = buffer[i]; break;
 case 2: numBytes = U16_AT(buffer + 2 * i); break;
 case 3: numBytes = U24_AT(buffer + 3 * i); break;
 default:
 {
                CHECK_EQ(entrySize, 4u);
                numBytes = U32_AT(buffer + 4 * i); break;
 }
 }

        numBytes *= scale;

        seeker->mSegments.push(numBytes);

        ALOGV("entry #%zu: %u offset %#016llx", i, numBytes, (long long)offset);
        offset += numBytes;
 }

 delete[] buffer;
    buffer = NULL;

    ALOGI("Found VBRI header.");

 return seeker;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_av_disable(tBTA_AV_CB* p_cb, UNUSED_ATTR tBTA_AV_DATA* p_data) {
  BT_HDR hdr;
 uint16_t xx;

  p_cb->disabling = true;

  bta_av_close_all_rc(p_cb);

  osi_free_and_reset((void**)&p_cb->p_disc_db);

 /* disable audio/video - de-register all channels,
   * expect BTA_AV_DEREG_COMP_EVT when deregister is complete */
 for (xx = 0; xx < BTA_AV_NUM_STRS; xx++) {
 if (p_cb->p_scb[xx] != NULL) {
      hdr.layer_specific = xx + 1;
      bta_av_api_deregister((tBTA_AV_DATA*)&hdr);
 }
 }

  alarm_free(p_cb->link_signalling_timer);
  p_cb->link_signalling_timer = NULL;
  alarm_free(p_cb->accept_signalling_timer);
  p_cb->accept_signalling_timer = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: omx_video::omx_video():
    c2d_opened(false),
    psource_frame(NULL),
    pdest_frame(NULL),
    secure_session(false),
    mEmptyEosBuffer(NULL),
    m_pipe_in(-1),
    m_pipe_out(-1),
    m_pInput_pmem(NULL),
    m_pOutput_pmem(NULL),
#ifdef USE_ION
    m_pInput_ion(NULL),
    m_pOutput_ion(NULL),
#endif
    m_error_propogated(false),
    m_state(OMX_StateInvalid),
    m_app_data(NULL),
    m_use_input_pmem(OMX_FALSE),
    m_use_output_pmem(OMX_FALSE),
    m_input_msg_id(OMX_COMPONENT_GENERATE_ETB),
    m_inp_mem_ptr(NULL),
    m_out_mem_ptr(NULL),
    input_flush_progress (false),
    output_flush_progress (false),
    input_use_buffer (false),
    output_use_buffer (false),
    pending_input_buffers(0),
    pending_output_buffers(0),
    m_out_bm_count(0),
    m_inp_bm_count(0),
    m_flags(0),
    m_etb_count(0),
    m_fbd_count(0),
    m_event_port_settings_sent(false),
    hw_overload(false)
{
    DEBUG_PRINT_HIGH("omx_video(): Inside Constructor()");
    memset(&m_cmp,0,sizeof(m_cmp));
    memset(&m_pCallbacks,0,sizeof(m_pCallbacks));
    async_thread_created = false;
    msg_thread_created = false;

    mUsesColorConversion = false;
    pthread_mutex_init(&m_lock, NULL);
    sem_init(&m_cmd_lock,0,0);
    DEBUG_PRINT_LOW("meta_buffer_hdr = %p", meta_buffer_hdr);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void onPnoNetworkFound(wifi_request_id id,
 unsigned num_results, wifi_scan_result *results) {

 JNIHelper helper(mVM);

    ALOGD("onPnoNetworkFound called, vm = %p, obj = %p, num_results %u", mVM, mCls, num_results);

 if (results == 0 || num_results == 0) {
       ALOGE("onPnoNetworkFound: Error no results");
 return;
 }

    jbyte *bytes;
 JNIObject<jobjectArray> scanResults(helper, NULL);

 for (unsigned i=0; i<num_results; i++) {

 JNIObject<jobject> scanResult = createScanResult(helper, &results[i]);
 if (i == 0) {
            scanResults = helper.newObjectArray(
                    num_results, "android/net/wifi/ScanResult", scanResult);
 if (scanResults == 0) {
                ALOGD("cant allocate array");
 } else {
                ALOGD("allocated array %u", helper.getArrayLength(scanResults));
 }
 } else {
            helper.setObjectArrayElement(scanResults, i, scanResult);
 }

        ALOGD("Scan result with ie length %d, i %u, <%s> rssi=%d %02x:%02x:%02x:%02x:%02x:%02x",
                results->ie_length, i, results[i].ssid, results[i].rssi, results[i].bssid[0],
                results[i].bssid[1],results[i].bssid[2], results[i].bssid[3], results[i].bssid[4],
                results[i].bssid[5]);

 /*elements = helper.newByteArray(results->ie_length);
        if (elements == NULL) {
            ALOGE("Error in allocating array");
            return;
        }*/



 }


    ALOGD("calling report");

    helper.reportEvent(mCls, "onPnoNetworkFound", "(I[Landroid/net/wifi/ScanResult;)V", id,
               scanResults.get());
        ALOGD("free ref");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void event_acl_stream_has_bytes(UNUSED_ATTR eager_reader_t *reader, UNUSED_ATTR void *context) {
  callbacks->data_ready(DATA_TYPE_ACL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: read_function(png_structp pp, png_bytep data, png_size_t size)
{
   buffer_read(get_dp(pp), get_buffer(pp), data, size);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static inline bool should_forward(tETH_HDR* hdr)
{
 uint16_t proto = ntohs(hdr->h_proto);
 if (proto == ETH_P_IP || proto == ETH_P_ARP || proto == ETH_P_IPV6)
 return true;
    BTIF_TRACE_DEBUG("unknown proto:%x", proto);
 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_residual_partitioned_rice_(FLAC__StreamDecoder *decoder, unsigned predictor_order, unsigned partition_order, FLAC__EntropyCodingMethod_PartitionedRiceContents *partitioned_rice_contents, FLAC__int32 *residual, FLAC__bool is_extended)
{
	FLAC__uint32 rice_parameter;
 int i;
 unsigned partition, sample, u;
 const unsigned partitions = 1u << partition_order;
 const unsigned partition_samples = partition_order > 0? decoder->private_->frame.header.blocksize >> partition_order : decoder->private_->frame.header.blocksize - predictor_order;
 const unsigned plen = is_extended? FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2_PARAMETER_LEN : FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_PARAMETER_LEN;
 const unsigned pesc = is_extended? FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2_ESCAPE_PARAMETER : FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_ESCAPE_PARAMETER;

 /* sanity checks */
 if(partition_order == 0) {
 if(decoder->private_->frame.header.blocksize < predictor_order) {
			send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);
			decoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;
 return true;
 }
 }
 else {
 if(partition_samples < predictor_order) {
			send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);
			decoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;
 return true;
 }
 }

 if(!FLAC__format_entropy_coding_method_partitioned_rice_contents_ensure_size(partitioned_rice_contents, flac_max(6u, partition_order))) {
		decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 return false;
 }

	sample = 0;
 for(partition = 0; partition < partitions; partition++) {
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &rice_parameter, plen))
 return false; /* read_callback_ sets the state for us */
		partitioned_rice_contents->parameters[partition] = rice_parameter;
 if(rice_parameter < pesc) {
			partitioned_rice_contents->raw_bits[partition] = 0;
			u = (partition_order == 0 || partition > 0)? partition_samples : partition_samples - predictor_order;
 if(!FLAC__bitreader_read_rice_signed_block(decoder->private_->input, residual + sample, u, rice_parameter))
 return false; /* read_callback_ sets the state for us */
			sample += u;
 }
 else {
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &rice_parameter, FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_RAW_LEN))
 return false; /* read_callback_ sets the state for us */
			partitioned_rice_contents->raw_bits[partition] = rice_parameter;
 for(u = (partition_order == 0 || partition > 0)? 0 : predictor_order; u < partition_samples; u++, sample++) {
 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i, rice_parameter))
 return false; /* read_callback_ sets the state for us */
				residual[sample] = i;
 }
 }
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t ACodec::setSupportedOutputFormat(bool getLegacyFlexibleFormat) {
    OMX_VIDEO_PARAM_PORTFORMATTYPE format, legacyFormat;
 InitOMXParams(&format);
    format.nPortIndex = kPortIndexOutput;

 InitOMXParams(&legacyFormat);
    legacyFormat.eColorFormat = OMX_COLOR_FormatUnused;

 for (OMX_U32 index = 0; ; ++index) {
        format.nIndex = index;
 status_t err = mOMX->getParameter(
                mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));
 if (err != OK) {
 if (legacyFormat.eColorFormat != OMX_COLOR_FormatUnused) {
                 memcpy(&format, &legacyFormat, sizeof(format));
 break;
 }
 return err;
 }
 if (format.eCompressionFormat != OMX_VIDEO_CodingUnused) {
 return OMX_ErrorBadParameter;
 }
 if (!getLegacyFlexibleFormat) {
 break;
 }
 if (format.eColorFormat == OMX_COLOR_FormatYUV420Planar
 || format.eColorFormat == OMX_COLOR_FormatYUV420PackedPlanar
 || format.eColorFormat == OMX_COLOR_FormatYUV420SemiPlanar
 || format.eColorFormat == OMX_COLOR_FormatYUV420PackedSemiPlanar
 || format.eColorFormat == OMX_TI_COLOR_FormatYUV420PackedSemiPlanar) {
 break;
 }
        OMX_U32 flexibleEquivalent;
 if (legacyFormat.eColorFormat == OMX_COLOR_FormatUnused
 && isFlexibleColorFormat(
                        mOMX, mNode, format.eColorFormat, false /* usingNativeBuffers */,
 &flexibleEquivalent)
 && flexibleEquivalent == OMX_COLOR_FormatYUV420Flexible) {
            memcpy(&legacyFormat, &format, sizeof(format));
 }
 }
 return mOMX->setParameter(
            mNode, OMX_IndexParamVideoPortFormat,
 &format, sizeof(format));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_decode_slice(UWORD8 u1_is_idr_slice,
                                 UWORD8 u1_nal_ref_idc,
 dec_struct_t *ps_dec /* Decoder parameters */
 )
{
 dec_bit_stream_t * ps_bitstrm = ps_dec->ps_bitstrm;
 dec_pic_params_t *ps_pps;
 dec_seq_params_t *ps_seq;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 pocstruct_t s_tmp_poc;
    WORD32 i_delta_poc[2];
    WORD32 i4_poc = 0;
    UWORD16 u2_first_mb_in_slice, u2_frame_num;
    UWORD8 u1_field_pic_flag, u1_redundant_pic_cnt = 0, u1_slice_type;
    UWORD32 u4_idr_pic_id = 0;
    UWORD8 u1_bottom_field_flag, u1_pic_order_cnt_type;

    UWORD8 u1_nal_unit_type;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    WORD8 i1_is_end_of_poc;

    WORD32 ret, end_of_frame;
    WORD32 prev_slice_err, num_mb_skipped;
    UWORD8 u1_mbaff;
 pocstruct_t *ps_cur_poc;

    UWORD32 u4_temp;
    WORD32 i_temp;
    UWORD32 u4_call_end_of_pic = 0;

 /* read FirstMbInSlice  and slice type*/
    ps_dec->ps_dpb_cmds->u1_dpb_commands_read_slc = 0;
    u2_first_mb_in_slice = ih264d_uev(pu4_bitstrm_ofst,
                                     pu4_bitstrm_buf);
 if(u2_first_mb_in_slice
 > (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs))
 {

 return ERROR_CORRUPTED_SLICE;
 }

 /*we currently don not support ASO*/
 if(((u2_first_mb_in_slice << ps_cur_slice->u1_mbaff_frame_flag)
 <= ps_dec->u2_cur_mb_addr) && (ps_dec->u4_first_slice_in_pic == 0))
 {
 return ERROR_CORRUPTED_SLICE;
 }

    COPYTHECONTEXT("SH: first_mb_in_slice",u2_first_mb_in_slice);

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);

 if(u4_temp > 9)
 return ERROR_INV_SLC_TYPE_T;

    u1_slice_type = u4_temp;
    COPYTHECONTEXT("SH: slice_type",(u1_slice_type));
    ps_dec->u1_sl_typ_5_9 = 0;
 /* Find Out the Slice Type is 5 to 9 or not then Set the Flag   */
 /* u1_sl_typ_5_9 = 1 .Which tells that all the slices in the Pic*/
 /* will be of same type of current                            */
 if(u1_slice_type > 4)
 {
        u1_slice_type -= 5;
        ps_dec->u1_sl_typ_5_9 = 1;
 }

 {
        UWORD32 skip;

 if((ps_dec->i4_app_skip_mode == IVD_SKIP_PB)
 || (ps_dec->i4_dec_skip_mode == IVD_SKIP_PB))
 {
            UWORD32 u4_bit_stream_offset = 0;

 if(ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else if((I_SLICE == u1_slice_type)
 && (1 >= ps_dec->ps_cur_sps->u1_num_ref_frames))
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else
 {
                skip = 1;
 }

 /* If one frame worth of data is already skipped, do not skip the next one */
 if((0 == u2_first_mb_in_slice) && (1 == ps_dec->u4_prev_nal_skipped))
 {
                skip = 0;
 }

 if(skip)
 {
                ps_dec->u4_prev_nal_skipped = 1;
                ps_dec->i4_dec_skip_mode = IVD_SKIP_PB;
 return 0;
 }
 else
 {
 /* If the previous NAL was skipped, then
                 do not process that buffer in this call.
                 Return to app and process it in the next call.
                 This is necessary to handle cases where I/IDR is not complete in
                 the current buffer and application intends to fill the remaining part of the bitstream
                 later. This ensures we process only frame worth of data in every call */
 if(1 == ps_dec->u4_prev_nal_skipped)
 {
                    ps_dec->u4_return_to_app = 1;
 return 0;
 }
 }
 }

 }

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp & MASK_ERR_PIC_SET_ID)
 return ERROR_INV_SLICE_HDR_T;
 /* discard slice if pic param is invalid */
    COPYTHECONTEXT("SH: pic_parameter_set_id", u4_temp);
    ps_pps = &ps_dec->ps_pps[u4_temp];
 if(FALSE == ps_pps->u1_is_valid)
 {
 return ERROR_INV_SLICE_HDR_T;
 }
    ps_seq = ps_pps->ps_sps;
 if(!ps_seq)
 return ERROR_INV_SLICE_HDR_T;
 if(FALSE == ps_seq->u1_is_valid)
 return ERROR_INV_SLICE_HDR_T;

 /* Get the frame num */
    u2_frame_num = ih264d_get_bits_h264(ps_bitstrm,
                                         ps_seq->u1_bits_in_frm_num);

 
     COPYTHECONTEXT("SH: frame_num", u2_frame_num);
    if(!ps_dec->u1_first_slice_in_stream && (ps_dec->u4_first_slice_in_pic == 2))
     {
         pocstruct_t *ps_prev_poc = &ps_dec->s_prev_pic_poc;
         pocstruct_t *ps_cur_poc = &ps_dec->s_cur_pic_poc;

        ps_dec->u2_mbx = 0xffff;
        ps_dec->u2_mby = 0;

 if((0 == u1_is_idr_slice) && ps_cur_slice->u1_nal_ref_idc)
            ps_dec->u2_prev_ref_frame_num = ps_cur_slice->u2_frame_num;

 if(u1_is_idr_slice || ps_cur_slice->u1_mmco_equalto5)
            ps_dec->u2_prev_ref_frame_num = 0;

 if(ps_dec->ps_cur_sps->u1_gaps_in_frame_num_value_allowed_flag)
 {
            ih264d_decode_gaps_in_frame_num(ps_dec, u2_frame_num);
 }

        ps_prev_poc->i4_prev_frame_num_ofst = ps_cur_poc->i4_prev_frame_num_ofst;
        ps_prev_poc->u2_frame_num = ps_cur_poc->u2_frame_num;
        ps_prev_poc->u1_mmco_equalto5 = ps_cur_slice->u1_mmco_equalto5;
 if(ps_cur_slice->u1_nal_ref_idc)
 {
            ps_prev_poc->i4_pic_order_cnt_lsb = ps_cur_poc->i4_pic_order_cnt_lsb;
            ps_prev_poc->i4_pic_order_cnt_msb = ps_cur_poc->i4_pic_order_cnt_msb;
            ps_prev_poc->i4_delta_pic_order_cnt_bottom =
                            ps_cur_poc->i4_delta_pic_order_cnt_bottom;
            ps_prev_poc->i4_delta_pic_order_cnt[0] =
                            ps_cur_poc->i4_delta_pic_order_cnt[0];
            ps_prev_poc->i4_delta_pic_order_cnt[1] =
                            ps_cur_poc->i4_delta_pic_order_cnt[1];
            ps_prev_poc->u1_bot_field = ps_cur_poc->u1_bot_field;
 }

        ps_dec->u2_total_mbs_coded = 0;
 }
 /* Get the field related flags  */
 if(!ps_seq->u1_frame_mbs_only_flag)
 {

        u1_field_pic_flag = ih264d_get_bit_h264(ps_bitstrm);
        COPYTHECONTEXT("SH: field_pic_flag", u1_field_pic_flag);
        u1_bottom_field_flag = 0;

 if(u1_field_pic_flag)
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan_fld;
            u1_bottom_field_flag = ih264d_get_bit_h264(ps_bitstrm);
            COPYTHECONTEXT("SH: bottom_field_flag", u1_bottom_field_flag);

 }
 else
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }
 }
 else
 {
        u1_field_pic_flag = 0;
        u1_bottom_field_flag = 0;

        ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }

    u1_nal_unit_type = SLICE_NAL;
 if(u1_is_idr_slice)
 {
 if(0 == u1_field_pic_flag)
 {
            ps_dec->u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY;
 }
        u1_nal_unit_type = IDR_SLICE_NAL;
        u4_idr_pic_id = ih264d_uev(pu4_bitstrm_ofst,
                                   pu4_bitstrm_buf);
 if(u4_idr_pic_id > 65535)
 return ERROR_INV_SLICE_HDR_T;
        COPYTHECONTEXT("SH:  ", u4_idr_pic_id);
 }

 /* read delta pic order count information*/
    i_delta_poc[0] = i_delta_poc[1] = 0;
    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    u1_pic_order_cnt_type = ps_seq->u1_pic_order_cnt_type;
 if(u1_pic_order_cnt_type == 0)
 {
        i_temp = ih264d_get_bits_h264(
                        ps_bitstrm,
                        ps_seq->u1_log2_max_pic_order_cnt_lsb_minus);
 if(i_temp < 0 || i_temp >= ps_seq->i4_max_pic_order_cntLsb)
 return ERROR_INV_SLICE_HDR_T;
        s_tmp_poc.i4_pic_order_cnt_lsb = i_temp;
        COPYTHECONTEXT("SH: pic_order_cnt_lsb", s_tmp_poc.i4_pic_order_cnt_lsb);

 if((ps_pps->u1_pic_order_present_flag == 1) && (!u1_field_pic_flag))
 {
            s_tmp_poc.i4_delta_pic_order_cnt_bottom = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt_bottom",
                            s_tmp_poc.i4_delta_pic_order_cnt_bottom);
 }
 }

    s_tmp_poc.i4_delta_pic_order_cnt[0] = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[1] = 0;
 if(u1_pic_order_cnt_type == 1
 && (!ps_seq->u1_delta_pic_order_always_zero_flag))
 {
        s_tmp_poc.i4_delta_pic_order_cnt[0] = ih264d_sev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
        COPYTHECONTEXT("SH: delta_pic_order_cnt[0]",
                        s_tmp_poc.i4_delta_pic_order_cnt[0]);

 if(ps_pps->u1_pic_order_present_flag && !u1_field_pic_flag)
 {
            s_tmp_poc.i4_delta_pic_order_cnt[1] = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt[1]",
                            s_tmp_poc.i4_delta_pic_order_cnt[1]);
 }
 }

 if(ps_pps->u1_redundant_pic_cnt_present_flag)
 {
        u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if(u4_temp > MAX_REDUNDANT_PIC_CNT)
 return ERROR_INV_SLICE_HDR_T;
        u1_redundant_pic_cnt = u4_temp;
        COPYTHECONTEXT("SH: redundant_pic_cnt", u1_redundant_pic_cnt);
 }

 /*--------------------------------------------------------------------*/
 /* Check if the slice is part of new picture                          */
 /*--------------------------------------------------------------------*/
 /* First slice of a picture is always considered as part of new picture */

     i1_is_end_of_poc = 1;
     ps_dec->ps_dec_err_status->u1_err_flag &= MASK_REJECT_CUR_PIC;
 
    if(ps_dec->u4_first_slice_in_pic != 2)
     {
         i1_is_end_of_poc = ih264d_is_end_of_pic(u2_frame_num, u1_nal_ref_idc,
                                             &s_tmp_poc, &ps_dec->s_cur_pic_poc,
                                            ps_cur_slice, u1_pic_order_cnt_type,
                                            u1_nal_unit_type, u4_idr_pic_id,
                                            u1_field_pic_flag,
                                            u1_bottom_field_flag);
 if(i1_is_end_of_poc)
 {
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_INCOMPLETE_FRAME;
 }

 }

 /*--------------------------------------------------------------------*/
 /* Check for error in slice and parse the missing/corrupted MB's      */
 /* as skip-MB's in an inserted P-slice                                */
 /*--------------------------------------------------------------------*/
    u1_mbaff = ps_seq->u1_mb_aff_flag && (!u1_field_pic_flag);
    prev_slice_err = 0;

 if(i1_is_end_of_poc || ps_dec->u1_first_slice_in_stream)
 {
 if(u2_frame_num != ps_dec->u2_prv_frame_num
 && ps_dec->u1_top_bottom_decoded != 0
 && ps_dec->u1_top_bottom_decoded
 != (TOP_FIELD_ONLY | BOT_FIELD_ONLY))
 {
            ps_dec->u1_dangling_field = 1;
 if(ps_dec->u4_first_slice_in_pic)
 {
                prev_slice_err = 1;
 }
 else
 {
                prev_slice_err = 2;
 }

 if(ps_dec->u1_top_bottom_decoded ==TOP_FIELD_ONLY)
                ps_cur_slice->u1_bottom_field_flag = 1;
 else
                ps_cur_slice->u1_bottom_field_flag = 0;

            num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &ps_dec->s_cur_pic_poc;

 
             u1_is_idr_slice = ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL;
         }
        else if(ps_dec->u4_first_slice_in_pic == 2)
         {
             if(u2_first_mb_in_slice > 0)
             {
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
                ps_cur_poc = &s_tmp_poc;

                ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
                ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
                ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
                ps_cur_slice->i4_pic_order_cnt_lsb =
                        s_tmp_poc.i4_pic_order_cnt_lsb;
                ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
                ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
                ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
                ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;
                ps_cur_slice->u1_mbaff_frame_flag = ps_seq->u1_mb_aff_flag
 && (!u1_field_pic_flag);
 }

         }
         else
         {
            if(ps_dec->u4_first_slice_in_pic)
            {
                /* if valid slice header is not decoded do start of pic processing
                 * since in the current process call, frame num is not updated in the slice structure yet
                 * ih264d_is_end_of_pic is checked with valid frame num of previous process call,
                 * although i1_is_end_of_poc is set there could be  more slices in the frame,
                 * so conceal only till cur slice */
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
            }
            else
            {
                /* since i1_is_end_of_poc is set ,means new frame num is encountered. so conceal the current frame
                 * completely */
                prev_slice_err = 2;
                num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
                        - ps_dec->u2_total_mbs_coded;
            }
             ps_cur_poc = &s_tmp_poc;
         }
     }
 else
 {
 if((u2_first_mb_in_slice << u1_mbaff) > ps_dec->u2_total_mbs_coded)
 {
            prev_slice_err = 2;
            num_mb_skipped = (u2_first_mb_in_slice << u1_mbaff)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &s_tmp_poc;
 }
 else if((u2_first_mb_in_slice << u1_mbaff) < ps_dec->u2_total_mbs_coded)
 {
 return ERROR_CORRUPTED_SLICE;
 }
 }

 if(prev_slice_err)
 {
        ret = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, u1_is_idr_slice, u2_frame_num, ps_cur_poc, prev_slice_err);

 if(ps_dec->u1_dangling_field == 1)
 {
            ps_dec->u1_second_field = 1 - ps_dec->u1_second_field;
            ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
            ps_dec->u2_prv_frame_num = u2_frame_num;
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_DANGLING_FIELD_IN_PIC;
 }

 if(prev_slice_err == 2)
 {
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_INCOMPLETE_FRAME;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
 /* return if all MBs in frame are parsed*/
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_IN_LAST_SLICE_OF_PIC;
 }

 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
            ih264d_err_pic_dispbuf_mgr(ps_dec);
 return ERROR_NEW_FRAME_EXPECTED;
 }

 if(ret != OK)
 return ret;

        i1_is_end_of_poc = 0;
 }

 if (ps_dec->u4_first_slice_in_pic == 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

 if((ps_dec->u1_separate_parse == 0) && (ps_dec->u4_first_slice_in_pic == 0))
 {
        ps_dec->ps_decode_cur_slice++;
 }
    ps_dec->u1_slice_header_done = 0;


 if(u1_field_pic_flag)
 {
        ps_dec->u2_prv_frame_num = u2_frame_num;
 }

 if(ps_cur_slice->u1_mmco_equalto5)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;

 if(!ps_cur_slice->u1_field_pic_flag) // or a complementary field pair
 {
            i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
            i4_bot_field_order_poc =
                            ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
            i4_temp_poc = MIN(i4_top_field_order_poc,
                                     i4_bot_field_order_poc);
 }
 else if(!ps_cur_slice->u1_bottom_field_flag)
            i4_temp_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
 else
            i4_temp_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;

        ps_dec->ps_cur_pic->i4_top_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        ps_dec->ps_cur_pic->i4_bottom_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;

         ps_dec->ps_cur_pic->i4_poc = i4_temp_poc;
         ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
     }
    if(ps_dec->u4_first_slice_in_pic == 2)
     {
         ret = ih264d_decode_pic_order_cnt(u1_is_idr_slice, u2_frame_num,
                                           &ps_dec->s_prev_pic_poc,
 &s_tmp_poc, ps_cur_slice, ps_pps,
                                          u1_nal_ref_idc,
                                          u1_bottom_field_flag,
                                          u1_field_pic_flag, &i4_poc);
 if(ret != OK)
 return ret;
 /* Display seq no calculations */
 if(i4_poc >= ps_dec->i4_max_poc)
            ps_dec->i4_max_poc = i4_poc;
 /* IDR Picture or POC wrap around */
 if(i4_poc == 0)
 {
            ps_dec->i4_prev_max_display_seq = ps_dec->i4_prev_max_display_seq
 + ps_dec->i4_max_poc
 + ps_dec->u1_max_dec_frame_buffering + 1;
            ps_dec->i4_max_poc = 0;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Copy the values read from the bitstream to the slice header and then*/
 /* If the slice is first slice in picture, then do Start of Picture   */
 /* processing.                                                        */
 /*--------------------------------------------------------------------*/
    ps_cur_slice->i4_delta_pic_order_cnt[0] = i_delta_poc[0];
    ps_cur_slice->i4_delta_pic_order_cnt[1] = i_delta_poc[1];
    ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
    ps_cur_slice->u2_first_mb_in_slice = u2_first_mb_in_slice;
    ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
    ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
    ps_cur_slice->u1_slice_type = u1_slice_type;
    ps_cur_slice->i4_pic_order_cnt_lsb = s_tmp_poc.i4_pic_order_cnt_lsb;

    ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
    ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
    ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
    ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;

 if(ps_seq->u1_frame_mbs_only_flag)
        ps_cur_slice->u1_direct_8x8_inference_flag =
                        ps_seq->u1_direct_8x8_inference_flag;
 else
        ps_cur_slice->u1_direct_8x8_inference_flag = 1;

 if(u1_slice_type == B_SLICE)
 {
        ps_cur_slice->u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264(
                        ps_bitstrm);
        COPYTHECONTEXT("SH: direct_spatial_mv_pred_flag",
                        ps_cur_slice->u1_direct_spatial_mv_pred_flag);

 if(ps_cur_slice->u1_direct_spatial_mv_pred_flag)
            ps_cur_slice->pf_decodeDirect = ih264d_decode_spatial_direct;
 else
            ps_cur_slice->pf_decodeDirect = ih264d_decode_temporal_direct;
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaffB;
 }
 else
 {
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))

             ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
     }
 
    if(ps_dec->u4_first_slice_in_pic == 2)
     {
         if(u2_first_mb_in_slice == 0)
         {
            ret = ih264d_start_of_pic(ps_dec, i4_poc, &s_tmp_poc, u2_frame_num, ps_pps);
 if(ret != OK)
 return ret;
 }

        ps_dec->u4_output_present = 0;

 {
            ih264d_get_next_display_field(ps_dec,
                                          ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
             hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                ps_dec->u4_output_present = 1;
 }
 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                ps_dec->u4_start_recon_deblk = 0;
                ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }

 }

 /* INITIALIZATION of fn ptrs for MC and formMbPartInfo functions */
 {
        UWORD8 uc_nofield_nombaff;



        uc_nofield_nombaff = ((ps_dec->ps_cur_slice->u1_field_pic_flag == 0)
 && (ps_dec->ps_cur_slice->u1_mbaff_frame_flag == 0)
 && (u1_slice_type != B_SLICE)
 && (ps_dec->ps_cur_pps->u1_wted_pred_flag == 0));

 /* Initialise MC and formMbPartInfo fn ptrs one time based on profile_idc */

 if(uc_nofield_nombaff)
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;
 }
 else
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_mp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_mp;
 }


 }

 /*
     * Decide whether to decode the current picture or not
     */
 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if(ps_err->u4_frm_sei_sync == u2_frame_num)
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
            ps_err->u4_frm_sei_sync = SYNC_FRM_DEFAULT;
 }
        ps_err->u4_cur_frm = u2_frame_num;
 }

 /* Decision for decoding if the picture is to be skipped */
 {
        WORD32 i4_skip_b_pic, i4_skip_p_pic;

        i4_skip_b_pic = (ps_dec->u4_skip_frm_mask & B_SLC_BIT)
 && (B_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

        i4_skip_p_pic = (ps_dec->u4_skip_frm_mask & P_SLC_BIT)
 && (P_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

 /**************************************************************/
 /* Skip the B picture if skip mask is set for B picture and   */
 /* Current B picture is a non reference B picture or there is */
 /* no user for reference B picture                            */
 /**************************************************************/
 if(i4_skip_b_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
 /* Don't decode the picture in SKIP-B mode if that picture is B */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 /**************************************************************/
 /* Skip the P picture if skip mask is set for P picture and   */
 /* Current P picture is a non reference P picture or there is */
 /* no user for reference P picture                            */
 /**************************************************************/
 if(i4_skip_p_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
 /* Don't decode the picture in SKIP-P mode if that picture is P */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 }

 {
        UWORD16 u2_mb_x, u2_mb_y;

        ps_dec->i4_submb_ofst = ((u2_first_mb_in_slice
 << ps_cur_slice->u1_mbaff_frame_flag) * SUB_BLK_SIZE)
 - SUB_BLK_SIZE;
 if(u2_first_mb_in_slice)
 {
            UWORD8 u1_mb_aff;
            UWORD8 u1_field_pic;
            UWORD16 u2_frm_wd_in_mbs;
            u2_frm_wd_in_mbs = ps_seq->u2_frm_wd_in_mbs;
            u1_mb_aff = ps_cur_slice->u1_mbaff_frame_flag;
            u1_field_pic = ps_cur_slice->u1_field_pic_flag;

 {
                UWORD32 x_offset;
                UWORD32 y_offset;
                UWORD32 u4_frame_stride;
 tfr_ctxt_t *ps_trns_addr; // = &ps_dec->s_tran_addrecon_parse;

 if(ps_dec->u1_separate_parse)
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon;
 }
                u2_mb_x = MOD(u2_first_mb_in_slice, u2_frm_wd_in_mbs);
                u2_mb_y = DIV(u2_first_mb_in_slice, u2_frm_wd_in_mbs);

                u2_mb_y <<= u1_mb_aff;

 if((u2_mb_x > u2_frm_wd_in_mbs - 1)
 || (u2_mb_y > ps_dec->u2_frm_ht_in_mbs - 1))
 {
 return ERROR_CORRUPTED_SLICE;
 }

                u4_frame_stride = ps_dec->u2_frm_wd_y << u1_field_pic;
                x_offset = u2_mb_x << 4;
                y_offset = (u2_mb_y * u4_frame_stride) << 4;

                ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1 + x_offset
 + y_offset;

                u4_frame_stride = ps_dec->u2_frm_wd_uv << u1_field_pic;
                x_offset >>= 1;
                y_offset = (u2_mb_y * u4_frame_stride) << 3;

                x_offset *= YUV420SP_FACTOR;

                ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2 + x_offset
 + y_offset;
                ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3 + x_offset
 + y_offset;

                ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
                ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
                ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;


 if(ps_dec->u1_separate_parse == 1)
 {
                    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }
 else
 {
                        ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }

                ps_dec->u2_cur_mb_addr = (u2_first_mb_in_slice << u1_mb_aff);

                ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv
 + ((u2_first_mb_in_slice << u1_mb_aff) << 4);
 }
 }
 else
 {
 tfr_ctxt_t *ps_trns_addr;

 if(ps_dec->u1_separate_parse)
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon;
 }

            u2_mb_x = 0xffff;
            u2_mb_y = 0;
            ps_dec->u2_cur_mb_addr = 0;
            ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
            ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
            ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
            ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
            ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

            ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
            ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
            ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;

 }

        ps_dec->ps_part = ps_dec->ps_parse_part_params;

        ps_dec->u2_mbx =
 (MOD(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby =
 (DIV(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby <<= ps_cur_slice->u1_mbaff_frame_flag;
        ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
        ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
 }

 /* RBSP stop bit is used for CABAC decoding*/
    ps_bitstrm->u4_max_ofst += ps_dec->ps_cur_pps->u1_entropy_coding_mode;

    ps_dec->u1_B = (u1_slice_type == B_SLICE);
    ps_dec->u4_next_mb_skip = 0;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice =
                    ps_dec->ps_cur_slice->u2_first_mb_in_slice;
    ps_dec->ps_parse_cur_slice->slice_type =
                    ps_dec->ps_cur_slice->u1_slice_type;


    ps_dec->u4_start_recon_deblk = 1;
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = ( void *)pu1_buf;
 }

 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 if(u1_slice_type == I_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= I_SLC_BIT;

        ret = ih264d_parse_islice(ps_dec, u2_first_mb_in_slice);

 if(ps_dec->i4_pic_type != B_SLICE && ps_dec->i4_pic_type != P_SLICE)
            ps_dec->i4_pic_type = I_SLICE;

 }
 else if(u1_slice_type == P_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
        ret = ih264d_parse_pslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
 if(ps_dec->i4_pic_type != B_SLICE)
            ps_dec->i4_pic_type = P_SLICE;
 }
 else if(u1_slice_type == B_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
        ret = ih264d_parse_bslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
        ps_dec->i4_pic_type = B_SLICE;
 }
 else
 return ERROR_INV_SLC_TYPE_T;


     if(ps_dec->u1_slice_header_done)
     {
         /* set to zero to indicate a valid slice has been decoded */
        /* first slice header successfully decoded */
        ps_dec->u4_first_slice_in_pic = 0;
         ps_dec->u1_first_slice_in_stream = 0;
     }
 
 if(ret != OK)
 return ret;

 /* storing last Mb X and MbY of the slice */
    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 /* End of Picture detection */

 if(ps_dec->u2_total_mbs_coded >= (ps_seq->u2_max_mb_addr + 1))
 {
        ps_dec->u1_pic_decode_done = 1;

 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if((ps_err->u1_err_flag & REJECT_PB_PICS)
 && (ps_err->u1_cur_pic_type == PIC_TYPE_I))
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

    PRINT_BIN_BIT_RATIO(ps_dec)

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: bool config_has_key(const config_t *config, const char *section, const char *key) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);

 return (entry_find(config, section, key) != NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_start_of_pic(dec_struct_t *ps_dec,
                         WORD32 i4_poc,
 pocstruct_t *ps_temp_poc,
                         UWORD16 u2_frame_num,
 dec_pic_params_t *ps_pps)
{
 pocstruct_t *ps_prev_poc = &ps_dec->s_cur_pic_poc;
 pocstruct_t *ps_cur_poc = ps_temp_poc;

 pic_buffer_t *pic_buf;

 ivd_video_decode_op_t * ps_dec_output =
 (ivd_video_decode_op_t *)ps_dec->pv_dec_out;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 dec_seq_params_t *ps_seq = ps_pps->ps_sps;
    UWORD8 u1_bottom_field_flag = ps_cur_slice->u1_bottom_field_flag;
    UWORD8 u1_field_pic_flag = ps_cur_slice->u1_field_pic_flag;
 /* high profile related declarations */
 high_profile_tools_t s_high_profile;
    WORD32 ret;

    H264_MUTEX_LOCK(&ps_dec->process_disp_mutex);

 /* check output buffer size given by the application */
 if(check_app_out_buf_size(ps_dec) != IV_SUCCESS)
 return IVD_DISP_FRM_ZERO_OP_BUF_SIZE;

    ps_prev_poc->i4_pic_order_cnt_lsb = ps_cur_poc->i4_pic_order_cnt_lsb;
    ps_prev_poc->i4_pic_order_cnt_msb = ps_cur_poc->i4_pic_order_cnt_msb;
    ps_prev_poc->i4_delta_pic_order_cnt_bottom =
                    ps_cur_poc->i4_delta_pic_order_cnt_bottom;
    ps_prev_poc->i4_delta_pic_order_cnt[0] =
                    ps_cur_poc->i4_delta_pic_order_cnt[0];
    ps_prev_poc->i4_delta_pic_order_cnt[1] =
                    ps_cur_poc->i4_delta_pic_order_cnt[1];
    ps_prev_poc->u1_bot_field = ps_dec->ps_cur_slice->u1_bottom_field_flag;
    ps_prev_poc->i4_prev_frame_num_ofst = ps_cur_poc->i4_prev_frame_num_ofst;
    ps_prev_poc->u2_frame_num = u2_frame_num;
    ps_dec->i1_prev_mb_qp_delta = 0;
    ps_dec->i1_next_ctxt_idx = 0;


    ps_dec->u4_nmb_deblk = 0;
 if(ps_dec->u4_num_cores == 1)
       ps_dec->u4_nmb_deblk = 1;



 if(ps_seq->u1_mb_aff_flag == 1)
 {
        ps_dec->u4_nmb_deblk = 0;
 if(ps_dec->u4_num_cores > 2)
            ps_dec->u4_num_cores = 2;
 }

        ps_dec->u4_use_intrapred_line_copy = 0;



 if (ps_seq->u1_mb_aff_flag == 0)
 {
        ps_dec->u4_use_intrapred_line_copy = 1;
 }

    ps_dec->u4_app_disable_deblk_frm = 0;
 /* If degrade is enabled, set the degrade flags appropriately */
 if(ps_dec->i4_degrade_type && ps_dec->i4_degrade_pics)
 {
        WORD32 degrade_pic;
        ps_dec->i4_degrade_pic_cnt++;
        degrade_pic = 0;

 /* If degrade is to be done in all frames, then do not check further */
 switch(ps_dec->i4_degrade_pics)
 {
 case 4:
 {
                degrade_pic = 1;
 break;
 }
 case 3:
 {
 if(ps_cur_slice->u1_slice_type != I_SLICE)
                    degrade_pic = 1;

 break;
 }
 case 2:
 {

 /* If pic count hits non-degrade interval or it is an islice, then do not degrade */
 if((ps_cur_slice->u1_slice_type != I_SLICE)
 && (ps_dec->i4_degrade_pic_cnt
 != ps_dec->i4_nondegrade_interval))
                    degrade_pic = 1;

 break;
 }
 case 1:
 {
 /* Check if the current picture is non-ref */
 if(0 == ps_cur_slice->u1_nal_ref_idc)
 {
                    degrade_pic = 1;
 }
 break;
 }

 }
 if(degrade_pic)
 {
 if(ps_dec->i4_degrade_type & 0x2)
                ps_dec->u4_app_disable_deblk_frm = 1;

 /* MC degrading is done only for non-ref pictures */
 if(0 == ps_cur_slice->u1_nal_ref_idc)
 {
 if(ps_dec->i4_degrade_type & 0x4)
                    ps_dec->i4_mv_frac_mask = 0;

 if(ps_dec->i4_degrade_type & 0x8)
                    ps_dec->i4_mv_frac_mask = 0;
 }
 }
 else
            ps_dec->i4_degrade_pic_cnt = 0;
 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if((ps_cur_slice->u1_slice_type == I_SLICE)
 || (ps_cur_slice->u1_slice_type == SI_SLICE))
            ps_err->u1_cur_pic_type = PIC_TYPE_I;
 else
            ps_err->u1_cur_pic_type = PIC_TYPE_UNKNOWN;

 if(ps_err->u1_pic_aud_i == PIC_TYPE_I)
 {
            ps_err->u1_cur_pic_type = PIC_TYPE_I;
            ps_err->u1_pic_aud_i = PIC_TYPE_UNKNOWN;
 }

 if(ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL)
 {
 if(ps_err->u1_err_flag)
                ih264d_reset_ref_bufs(ps_dec->ps_dpb_mgr);
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

 if(ps_dec->u1_init_dec_flag && ps_dec->s_prev_seq_params.u1_eoseq_pending)
 {
 /* Reset the decoder picture buffers */
        WORD32 j;
 for(j = 0; j < MAX_DISP_BUFS_NEW; j++)
 {

            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                  j,
                                  BUF_MGR_REF);
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                  ps_dec->au1_pic_buf_id_mv_buf_id_map[j],
                                  BUF_MGR_REF);
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                  j,
                                  BUF_MGR_IO);
 }

 /* reset the decoder structure parameters related to buffer handling */
        ps_dec->u1_second_field = 0;
        ps_dec->i4_cur_display_seq = 0;

 /********************************************************************/
 /* indicate in the decoder output i4_status that some frames are being */
 /* dropped, so that it resets timestamp and wait for a new sequence */
 /********************************************************************/

        ps_dec->s_prev_seq_params.u1_eoseq_pending = 0;
 }
    ret = ih264d_init_pic(ps_dec, u2_frame_num, i4_poc, ps_pps);
 if(ret != OK)
 return ret;

    ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_pic_tu_coeff_data;
    ps_dec->pv_proc_tu_coeff_data  = ps_dec->pv_pic_tu_coeff_data;
    ps_dec->ps_nmb_info = ps_dec->ps_frm_mb_info;
 if(ps_dec->u1_separate_parse)
 {
        UWORD16 pic_wd;
        UWORD16 pic_ht;
        UWORD32 num_mbs;

        pic_wd = ps_dec->u2_pic_wd;
        pic_ht = ps_dec->u2_pic_ht;
        num_mbs = (pic_wd * pic_ht) >> 8;

 if(ps_dec->pu1_dec_mb_map)
 {
            memset((void *)ps_dec->pu1_dec_mb_map, 0, num_mbs);
 }

 if(ps_dec->pu1_recon_mb_map)
 {

            memset((void *)ps_dec->pu1_recon_mb_map, 0, num_mbs);
 }

 if(ps_dec->pu2_slice_num_map)
 {
            memset((void *)ps_dec->pu2_slice_num_map, 0,
 (num_mbs * sizeof(UWORD16)));
 }

 }

    ps_dec->ps_parse_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->ps_decode_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->ps_computebs_cur_slice = &(ps_dec->ps_dec_slice_buf[0]);
    ps_dec->u2_cur_slice_num = 0;

 /* Initialize all the HP toolsets to zero */
    ps_dec->s_high_profile.u1_scaling_present = 0;
    ps_dec->s_high_profile.u1_transform8x8_present = 0;

 /* Get Next Free Picture */
 if(1 == ps_dec->u4_share_disp_buf)
 {
        UWORD32 i;
 /* Free any buffer that is in the queue to be freed */
 for(i = 0; i < MAX_DISP_BUFS_NEW; i++)
 {
 if(0 == ps_dec->u4_disp_buf_to_be_freed[i])
 continue;
            ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr, i,
            BUF_MGR_IO);
            ps_dec->u4_disp_buf_to_be_freed[i] = 0;
            ps_dec->u4_disp_buf_mapping[i] = 0;

 }
 }
 if(!(u1_field_pic_flag && 0 != ps_dec->u1_top_bottom_decoded)) //ps_dec->u1_second_field))
 {
 pic_buffer_t *ps_cur_pic;
        WORD32 cur_pic_buf_id, cur_mv_buf_id;
 col_mv_buf_t *ps_col_mv;
 while(1)
 {
            ps_cur_pic = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
 &cur_pic_buf_id);
 if(ps_cur_pic == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_PICBUF_T;
 return ERROR_UNAVAIL_PICBUF_T;
 }
 if(0 == ps_dec->u4_disp_buf_mapping[cur_pic_buf_id])
 {
 break;
 }

 }
        ps_col_mv = (col_mv_buf_t *)ih264_buf_mgr_get_next_free((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
 &cur_mv_buf_id);
 if(ps_col_mv == NULL)
 {
            ps_dec->i4_error_code = ERROR_UNAVAIL_MVBUF_T;
 return ERROR_UNAVAIL_MVBUF_T;
 }

        ps_dec->ps_cur_pic = ps_cur_pic;
        ps_dec->u1_pic_buf_id = cur_pic_buf_id;
        ps_cur_pic->u4_ts = ps_dec->u4_ts;


        ps_cur_pic->u1_mv_buf_id = cur_mv_buf_id;
        ps_dec->au1_pic_buf_id_mv_buf_id_map[cur_pic_buf_id] = cur_mv_buf_id;

        ps_cur_pic->pu1_col_zero_flag = (UWORD8 *)ps_col_mv->pv_col_zero_flag;
        ps_cur_pic->ps_mv = (mv_pred_t *)ps_col_mv->pv_mv;
        ps_dec->au1_pic_buf_ref_flag[cur_pic_buf_id] = 0;

 {
 /*make first entry of list0 and list1 point to cur pic,
             *so that if first slice is in error, ref pic struct will have valid entries*/
            ps_dec->ps_ref_pic_buf_lx[0] = ps_dec->ps_dpb_mgr->ps_init_dpb[0];
            ps_dec->ps_ref_pic_buf_lx[1] = ps_dec->ps_dpb_mgr->ps_init_dpb[1];
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[0][0]) = *ps_cur_pic;
 /* Initialize for field reference as well */
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[0][MAX_REF_BUFS]) = *ps_cur_pic;

 *(ps_dec->ps_dpb_mgr->ps_mod_dpb[0][0]) = *ps_cur_pic;
 /* Initialize for field reference as well */
 *(ps_dec->ps_dpb_mgr->ps_mod_dpb[0][MAX_REF_BUFS]) = *ps_cur_pic;
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[1][0]) = *ps_cur_pic;
 /* Initialize for field reference as well */
 *(ps_dec->ps_dpb_mgr->ps_init_dpb[1][MAX_REF_BUFS]) = *ps_cur_pic;
 *(ps_dec->ps_dpb_mgr->ps_mod_dpb[1][0]) = *ps_cur_pic;
 /* Initialize for field reference as well */
 *(ps_dec->ps_dpb_mgr->ps_mod_dpb[1][MAX_REF_BUFS]) = *ps_cur_pic;
 }

 if(!ps_dec->ps_cur_pic)
 {
            WORD32 j;
            H264_DEC_DEBUG_PRINT("------- Display Buffers Reset --------\n");
 for(j = 0; j < MAX_DISP_BUFS_NEW; j++)
 {

                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                      j,
                                      BUF_MGR_REF);
                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                                      ps_dec->au1_pic_buf_id_mv_buf_id_map[j],
                                      BUF_MGR_REF);
                ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                                      j,
                                      BUF_MGR_IO);
 }

            ps_dec->i4_cur_display_seq = 0;
            ps_dec->i4_prev_max_display_seq = 0;
            ps_dec->i4_max_poc = 0;

            ps_cur_pic = (pic_buffer_t *)ih264_buf_mgr_get_next_free(
 (buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
 &cur_pic_buf_id);
 if(ps_cur_pic == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_PICBUF_T;
 return ERROR_UNAVAIL_PICBUF_T;
 }

            ps_col_mv = (col_mv_buf_t *)ih264_buf_mgr_get_next_free((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
 &cur_mv_buf_id);
 if(ps_col_mv == NULL)
 {
                ps_dec->i4_error_code = ERROR_UNAVAIL_MVBUF_T;
 return ERROR_UNAVAIL_MVBUF_T;
 }

            ps_dec->ps_cur_pic = ps_cur_pic;
            ps_dec->u1_pic_buf_id = cur_pic_buf_id;
            ps_cur_pic->u4_ts = ps_dec->u4_ts;
            ps_dec->apv_buf_id_pic_buf_map[cur_pic_buf_id] = (void *)ps_cur_pic;

            ps_cur_pic->u1_mv_buf_id = cur_mv_buf_id;
            ps_dec->au1_pic_buf_id_mv_buf_id_map[cur_pic_buf_id] = cur_mv_buf_id;

            ps_cur_pic->pu1_col_zero_flag = (UWORD8 *)ps_col_mv->pv_col_zero_flag;
            ps_cur_pic->ps_mv = (mv_pred_t *)ps_col_mv->pv_mv;
            ps_dec->au1_pic_buf_ref_flag[cur_pic_buf_id] = 0;

 }

        ps_dec->ps_cur_pic->u1_picturetype = u1_field_pic_flag;
        ps_dec->ps_cur_pic->u4_pack_slc_typ = SKIP_NONE;
        H264_DEC_DEBUG_PRINT("got a buffer\n");
 }
 else
 {
        H264_DEC_DEBUG_PRINT("did not get a buffer\n");
 }

    ps_dec->u4_pic_buf_got = 1;

    ps_dec->ps_cur_pic->i4_poc = i4_poc;
    ps_dec->ps_cur_pic->i4_frame_num = u2_frame_num;
    ps_dec->ps_cur_pic->i4_pic_num = u2_frame_num;
    ps_dec->ps_cur_pic->i4_top_field_order_cnt = ps_pps->i4_top_field_order_cnt;
    ps_dec->ps_cur_pic->i4_bottom_field_order_cnt =
                    ps_pps->i4_bottom_field_order_cnt;
    ps_dec->ps_cur_pic->i4_avg_poc = ps_pps->i4_avg_poc;
    ps_dec->ps_cur_pic->u4_time_stamp = ps_dec->u4_pts;

    ps_dec->s_cur_pic = *(ps_dec->ps_cur_pic);
 if(u1_field_pic_flag && u1_bottom_field_flag)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;
 /* Point to odd lines, since it's bottom field */
        ps_dec->s_cur_pic.pu1_buf1 += ps_dec->s_cur_pic.u2_frm_wd_y;
        ps_dec->s_cur_pic.pu1_buf2 += ps_dec->s_cur_pic.u2_frm_wd_uv;
        ps_dec->s_cur_pic.pu1_buf3 += ps_dec->s_cur_pic.u2_frm_wd_uv;
        ps_dec->s_cur_pic.ps_mv +=
 ((ps_dec->u2_pic_ht * ps_dec->u2_pic_wd) >> 5);
        ps_dec->s_cur_pic.pu1_col_zero_flag += ((ps_dec->u2_pic_ht
 * ps_dec->u2_pic_wd) >> 5);
        ps_dec->ps_cur_pic->u1_picturetype |= BOT_FLD;
        i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        i4_bot_field_order_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
        i4_temp_poc = MIN(i4_top_field_order_poc,
                                 i4_bot_field_order_poc);
        ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
 }

    ps_cur_slice->u1_mbaff_frame_flag = ps_seq->u1_mb_aff_flag
 && (!u1_field_pic_flag);

    ps_dec->ps_cur_pic->u1_picturetype |= (ps_cur_slice->u1_mbaff_frame_flag
 << 2);

    ps_dec->ps_cur_mb_row = ps_dec->ps_nbr_mb_row; //[0];
    ps_dec->ps_cur_mb_row += 2;
    ps_dec->ps_top_mb_row = ps_dec->ps_nbr_mb_row;
    ps_dec->ps_top_mb_row += ((ps_dec->u2_frm_wd_in_mbs + 2) << (1 - ps_dec->ps_cur_sps->u1_frame_mbs_only_flag));
    ps_dec->ps_top_mb_row += 2;

 /* CHANGED CODE */
    ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
    ps_dec->ps_mv_top = ps_dec->ps_mv_top_p[0];
 /* CHANGED CODE */
    ps_dec->u1_mv_top_p = 0;
    ps_dec->u1_mb_idx = 0;
 /* CHANGED CODE */
    ps_dec->ps_mv_left = ps_dec->s_cur_pic.ps_mv;
    ps_dec->u2_total_mbs_coded = 0;
    ps_dec->i4_submb_ofst = -(SUB_BLK_SIZE);
    ps_dec->u4_pred_info_idx = 0;
    ps_dec->u4_pred_info_pkd_idx = 0;
    ps_dec->u4_dma_buf_idx = 0;
    ps_dec->ps_mv = ps_dec->s_cur_pic.ps_mv;
    ps_dec->ps_mv_bank_cur = ps_dec->s_cur_pic.ps_mv;
    ps_dec->pu1_col_zero_flag = ps_dec->s_cur_pic.pu1_col_zero_flag;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;
    ps_dec->i2_prev_slice_mbx = -1;
    ps_dec->i2_prev_slice_mby = 0;
    ps_dec->u2_mv_2mb[0] = 0;
    ps_dec->u2_mv_2mb[1] = 0;
    ps_dec->u1_last_pic_not_decoded = 0;

    ps_dec->u2_cur_slice_num_dec_thread = 0;
    ps_dec->u2_cur_slice_num_bs = 0;
    ps_dec->u4_intra_pred_line_ofst = 0;
    ps_dec->pu1_cur_y_intra_pred_line = ps_dec->pu1_y_intra_pred_line;
    ps_dec->pu1_cur_u_intra_pred_line = ps_dec->pu1_u_intra_pred_line;
    ps_dec->pu1_cur_v_intra_pred_line = ps_dec->pu1_v_intra_pred_line;

    ps_dec->pu1_cur_y_intra_pred_line_base = ps_dec->pu1_y_intra_pred_line;
    ps_dec->pu1_cur_u_intra_pred_line_base = ps_dec->pu1_u_intra_pred_line;
    ps_dec->pu1_cur_v_intra_pred_line_base = ps_dec->pu1_v_intra_pred_line;





    ps_dec->pu1_prev_y_intra_pred_line = ps_dec->pu1_y_intra_pred_line
 + (ps_dec->u2_frm_wd_in_mbs * MB_SIZE);

    ps_dec->pu1_prev_u_intra_pred_line = ps_dec->pu1_u_intra_pred_line
 + ps_dec->u2_frm_wd_in_mbs * BLK8x8SIZE * YUV420SP_FACTOR;
    ps_dec->pu1_prev_v_intra_pred_line = ps_dec->pu1_v_intra_pred_line
 + ps_dec->u2_frm_wd_in_mbs * BLK8x8SIZE;

    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
 /* Initialize The Function Pointer Depending Upon the Entropy and MbAff Flag */
 {
 if(ps_cur_slice->u1_mbaff_frame_flag)
 {
            ps_dec->pf_compute_bs = ih264d_compute_bs_mbaff;
            ps_dec->pf_mvpred = ih264d_mvpred_mbaff;
 }
 else
 {
            ps_dec->pf_compute_bs = ih264d_compute_bs_non_mbaff;
            ps_dec->u1_cur_mb_fld_dec_flag = ps_cur_slice->u1_field_pic_flag;
 }
 }
 /* Set up the Parameter for DMA transfer */
 {
        UWORD8 u1_field_pic_flag = ps_dec->ps_cur_slice->u1_field_pic_flag;

        UWORD8 u1_mbaff = ps_cur_slice->u1_mbaff_frame_flag;

        UWORD8 uc_lastmbs = (((ps_dec->u2_pic_wd) >> 4)
 % (ps_dec->u1_recon_mb_grp >> u1_mbaff));
        UWORD16 ui16_lastmbs_widthY =
 (uc_lastmbs ? (uc_lastmbs << 4) : ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) << 4));
        UWORD16 ui16_lastmbs_widthUV =
                        uc_lastmbs ? (uc_lastmbs << 3) : ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) << 3);

        ps_dec->s_tran_addrecon.pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
        ps_dec->s_tran_addrecon.pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
        ps_dec->s_tran_addrecon.pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

        ps_dec->s_tran_addrecon.u2_frm_wd_y = ps_dec->u2_frm_wd_y
 << u1_field_pic_flag;
        ps_dec->s_tran_addrecon.u2_frm_wd_uv = ps_dec->u2_frm_wd_uv
 << u1_field_pic_flag;

 if(u1_field_pic_flag)
 {
            ui16_lastmbs_widthY += ps_dec->u2_frm_wd_y;
            ui16_lastmbs_widthUV += ps_dec->u2_frm_wd_uv;
 }

 /* Normal Increment of Pointer */
        ps_dec->s_tran_addrecon.u4_inc_y[0] = ((ps_dec->u1_recon_mb_grp << 4)
 >> u1_mbaff);
        ps_dec->s_tran_addrecon.u4_inc_uv[0] = ((ps_dec->u1_recon_mb_grp << 4)
 >> u1_mbaff);

 /* End of Row Increment */
        ps_dec->s_tran_addrecon.u4_inc_y[1] = (ui16_lastmbs_widthY
 + (PAD_LEN_Y_H << 1)
 + ps_dec->s_tran_addrecon.u2_frm_wd_y
 * ((15 << u1_mbaff) + u1_mbaff));
        ps_dec->s_tran_addrecon.u4_inc_uv[1] = (ui16_lastmbs_widthUV
 + (PAD_LEN_UV_H << 2)
 + ps_dec->s_tran_addrecon.u2_frm_wd_uv
 * ((15 << u1_mbaff) + u1_mbaff));

 /* Assign picture numbers to each frame/field  */
 /* only once per picture.                      */
        ih264d_assign_pic_num(ps_dec);
        ps_dec->s_tran_addrecon.u2_mv_top_left_inc = (ps_dec->u1_recon_mb_grp
 << 2) - 1 - (u1_mbaff << 2);
        ps_dec->s_tran_addrecon.u2_mv_left_inc = ((ps_dec->u1_recon_mb_grp
 >> u1_mbaff) - 1) << (4 + u1_mbaff);
 }
 /**********************************************************************/
 /* High profile related initialization at pictrue level               */
 /**********************************************************************/
 if(ps_seq->u1_profile_idc == HIGH_PROFILE_IDC)
 {
 if((ps_seq->i4_seq_scaling_matrix_present_flag)
 || (ps_pps->i4_pic_scaling_matrix_present_flag))
 {
            ih264d_form_scaling_matrix_picture(ps_seq, ps_pps, ps_dec);
            ps_dec->s_high_profile.u1_scaling_present = 1;
 }
 else
 {
            ih264d_form_default_scaling_matrix(ps_dec);
 }

 if(ps_pps->i4_transform_8x8_mode_flag)
 {
            ps_dec->s_high_profile.u1_transform8x8_present = 1;
 }
 }
 else
 {
        ih264d_form_default_scaling_matrix(ps_dec);
 }

 /* required while reading the transform_size_8x8 u4_flag */
    ps_dec->s_high_profile.u1_direct_8x8_inference_flag =
                    ps_seq->u1_direct_8x8_inference_flag;
    ps_dec->s_high_profile.s_cavlc_ctxt = ps_dec->s_cavlc_ctxt;

    ps_dec->i1_recon_in_thread3_flag = 1;
    ps_dec->ps_frame_buf_ip_recon = &ps_dec->s_tran_addrecon;
 if(ps_dec->u1_separate_parse)
 {
        memcpy(&ps_dec->s_tran_addrecon_parse, &ps_dec->s_tran_addrecon,
 sizeof(tfr_ctxt_t));
 if(ps_dec->u4_num_cores >= 3 && ps_dec->i1_recon_in_thread3_flag)
 {
            memcpy(&ps_dec->s_tran_iprecon, &ps_dec->s_tran_addrecon,
 sizeof(tfr_ctxt_t));
            ps_dec->ps_frame_buf_ip_recon = &ps_dec->s_tran_iprecon;
 }
 }


    ih264d_init_deblk_tfr_ctxt(ps_dec,&(ps_dec->s_pad_mgr), &(ps_dec->s_tran_addrecon),
                               ps_dec->u2_frm_wd_in_mbs, 0);

    ps_dec->ps_cur_deblk_mb = ps_dec->ps_deblk_pic;
    ps_dec->u4_cur_deblk_mb_num = 0;

    ps_dec->u4_deblk_mb_x = 0;
    ps_dec->u4_deblk_mb_y = 0;
    ps_dec->pu4_wt_ofsts = ps_dec->pu4_wts_ofsts_mat;

    ps_dec->u4_first_slice_in_pic = 0;
    H264_MUTEX_UNLOCK(&ps_dec->process_disp_mutex);
 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_cabac_init(cab_ctxt_t *ps_cabac,
 bitstrm_t *ps_bitstrm,
                                 WORD32 qp,
                                 WORD32 cabac_init_idc,
 const UWORD8 *pu1_init_ctxt)
{
 /* Sanity checks */
    ASSERT(ps_cabac != NULL);
    ASSERT(ps_bitstrm != NULL);
    ASSERT((qp >= 0) && (qp < 52));
    ASSERT((cabac_init_idc >= 0) && (cabac_init_idc < 3));
    UNUSED(qp);
    UNUSED(cabac_init_idc);
 /* CABAC engine uses 32 bit range instead of 9 bits as specified by
     * the spec. This is done to reduce number of renormalizations
     */
 /* cabac engine initialization */
#if FULLRANGE
    ps_cabac->u4_range = (UWORD32)510 << RANGE_SHIFT;
    BITS_GET(ps_cabac->u4_ofst, ps_bitstrm->pu4_buf, ps_bitstrm->u4_bit_ofst,
                    ps_bitstrm->u4_cur_word, ps_bitstrm->u4_nxt_word, (9 + RANGE_SHIFT));

#else
    ps_cabac->u4_range = (UWORD32)510;
    BITS_GET(ps_cabac->u4_ofst, ps_bitstrm->pu4_buf, ps_bitstrm->u4_bit_ofst,
                    ps_bitstrm->u4_cur_word, ps_bitstrm->u4_nxt_word, 9);

#endif

 /* cabac context initialization based on init idc and slice qp */
    memcpy(ps_cabac->au1_ctxt_models,

            pu1_init_ctxt,
            IHEVC_CAB_CTXT_END);
     DEBUG_RANGE_OFST("init", ps_cabac->u4_range, ps_cabac->u4_ofst);
     return ((IHEVCD_ERROR_T)IHEVCD_SUCCESS);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleTable::setChunkOffsetParams(
 uint32_t type, off64_t data_offset, size_t data_size) {
 if (mChunkOffsetOffset >= 0) {
 return ERROR_MALFORMED;
 }

    CHECK(type == kChunkOffsetType32 || type == kChunkOffsetType64);

    mChunkOffsetOffset = data_offset;
    mChunkOffsetType = type;

 if (data_size < 8) {
 return ERROR_MALFORMED;
 }

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;
 }

    mNumChunkOffsets = U32_AT(&header[4]);

 if (mChunkOffsetType == kChunkOffsetType32) {
 if ((data_size - 8) / 4 < mNumChunkOffsets) {
 return ERROR_MALFORMED;
 }
 } else {
 if ((data_size - 8) / 8 < mNumChunkOffsets) {
 return ERROR_MALFORMED;
 }
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::getPortFormat(OMX_U32 portIndex, sp<AMessage> &notify) {
 const char *niceIndex = portIndex == kPortIndexInput ? "input" : "output";
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

 status_t err = mOMX->getParameter(mNode, OMX_IndexParamPortDefinition, &def, sizeof(def));
 if (err != OK) {
 return err;
 }

 if (def.eDir != (portIndex == kPortIndexOutput ? OMX_DirOutput : OMX_DirInput)) {
        ALOGE("unexpected dir: %s(%d) on %s port", asString(def.eDir), def.eDir, niceIndex);
 return BAD_VALUE;
 }

 switch (def.eDomain) {
 case OMX_PortDomainVideo:
 {
            OMX_VIDEO_PORTDEFINITIONTYPE *videoDef = &def.format.video;
 switch ((int)videoDef->eCompressionFormat) {
 case OMX_VIDEO_CodingUnused:
 {
                    CHECK(mIsEncoder ^ (portIndex == kPortIndexOutput));
                    notify->setString("mime", MEDIA_MIMETYPE_VIDEO_RAW);

                    notify->setInt32("stride", videoDef->nStride);
                    notify->setInt32("slice-height", videoDef->nSliceHeight);
                    notify->setInt32("color-format", videoDef->eColorFormat);

 if (mNativeWindow == NULL) {
 DescribeColorFormatParams describeParams;
 InitOMXParams(&describeParams);
                        describeParams.eColorFormat = videoDef->eColorFormat;
                        describeParams.nFrameWidth = videoDef->nFrameWidth;
                        describeParams.nFrameHeight = videoDef->nFrameHeight;
                        describeParams.nStride = videoDef->nStride;
                        describeParams.nSliceHeight = videoDef->nSliceHeight;
                        describeParams.bUsingNativeBuffers = OMX_FALSE;

 if (describeColorFormat(mOMX, mNode, describeParams)) {
                            notify->setBuffer(
 "image-data",
 ABuffer::CreateAsCopy(
 &describeParams.sMediaImage,
 sizeof(describeParams.sMediaImage)));

 MediaImage *img = &describeParams.sMediaImage;
                            ALOGV("[%s] MediaImage { F(%ux%u) @%u+%u+%u @%u+%u+%u @%u+%u+%u }",
                                    mComponentName.c_str(), img->mWidth, img->mHeight,
                                    img->mPlane[0].mOffset, img->mPlane[0].mColInc, img->mPlane[0].mRowInc,
                                    img->mPlane[1].mOffset, img->mPlane[1].mColInc, img->mPlane[1].mRowInc,
                                    img->mPlane[2].mOffset, img->mPlane[2].mColInc, img->mPlane[2].mRowInc);
 }
 }

 if (portIndex != kPortIndexOutput) {
 break;
 }

                    OMX_CONFIG_RECTTYPE rect;
 InitOMXParams(&rect);
                    rect.nPortIndex = portIndex;

 if (mOMX->getConfig(
                                mNode,
 (portIndex == kPortIndexOutput ?
                                        OMX_IndexConfigCommonOutputCrop :
                                        OMX_IndexConfigCommonInputCrop),
 &rect, sizeof(rect)) != OK) {
                        rect.nLeft = 0;
                        rect.nTop = 0;
                        rect.nWidth = videoDef->nFrameWidth;
                        rect.nHeight = videoDef->nFrameHeight;
 }

 if (rect.nLeft < 0 ||
                        rect.nTop < 0 ||
                        rect.nLeft + rect.nWidth > videoDef->nFrameWidth ||
                        rect.nTop + rect.nHeight > videoDef->nFrameHeight) {
                        ALOGE("Wrong cropped rect (%d, %d) - (%u, %u) vs. frame (%u, %u)",
                                rect.nLeft, rect.nTop,
                                rect.nLeft + rect.nWidth, rect.nTop + rect.nHeight,
                                videoDef->nFrameWidth, videoDef->nFrameHeight);
 return BAD_VALUE;
 }

                    notify->setRect(
 "crop",
                            rect.nLeft,
                            rect.nTop,
                            rect.nLeft + rect.nWidth - 1,
                            rect.nTop + rect.nHeight - 1);

 break;
 }

 case OMX_VIDEO_CodingVP8:
 case OMX_VIDEO_CodingVP9:
 {
                    OMX_VIDEO_PARAM_ANDROID_VP8ENCODERTYPE vp8type;
 InitOMXParams(&vp8type);
                    vp8type.nPortIndex = kPortIndexOutput;
 status_t err = mOMX->getParameter(
                            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamVideoAndroidVp8Encoder,
 &vp8type,
 sizeof(vp8type));

 if (err == OK) {
 AString tsSchema = "none";
 if (vp8type.eTemporalPattern
 == OMX_VIDEO_VPXTemporalLayerPatternWebRTC) {
 switch (vp8type.nTemporalLayerCount) {
 case 1:
 {
                                    tsSchema = "webrtc.vp8.1-layer";
 break;
 }
 case 2:
 {
                                    tsSchema = "webrtc.vp8.2-layer";
 break;
 }
 case 3:
 {
                                    tsSchema = "webrtc.vp8.3-layer";
 break;
 }
 default:
 {
 break;
 }
 }
 }
                        notify->setString("ts-schema", tsSchema);
 }
 }

 default:
 {
 if (mIsEncoder ^ (portIndex == kPortIndexOutput)) {
                        ALOGE("Raw port video compression format is %s(%d)",
                                asString(videoDef->eCompressionFormat),
                                videoDef->eCompressionFormat);
 return BAD_VALUE;
 }
 AString mime;
 if (GetMimeTypeForVideoCoding(
                        videoDef->eCompressionFormat, &mime) != OK) {
                        notify->setString("mime", "application/octet-stream");
 } else {
                        notify->setString("mime", mime.c_str());
 }
 break;
 }
 }
            notify->setInt32("width", videoDef->nFrameWidth);
            notify->setInt32("height", videoDef->nFrameHeight);
            ALOGV("[%s] %s format is %s", mComponentName.c_str(),
                    portIndex == kPortIndexInput ? "input" : "output",
                    notify->debugString().c_str());

 break;
 }

 case OMX_PortDomainAudio:
 {
            OMX_AUDIO_PORTDEFINITIONTYPE *audioDef = &def.format.audio;

 switch ((int)audioDef->eEncoding) {
 case OMX_AUDIO_CodingPCM:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

 if (params.nChannels <= 0
 || (params.nChannels != 1 && !params.bInterleaved)
 || params.nBitPerSample != 16u
 || params.eNumData != OMX_NumericalDataSigned
 || params.ePCMMode != OMX_AUDIO_PCMModeLinear) {
                        ALOGE("unsupported PCM port: %u channels%s, %u-bit, %s(%d), %s(%d) mode ",
                                params.nChannels,
                                params.bInterleaved ? " interleaved" : "",
                                params.nBitPerSample,
                                asString(params.eNumData), params.eNumData,
                                asString(params.ePCMMode), params.ePCMMode);
 return FAILED_TRANSACTION;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_RAW);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);

 if (mChannelMaskPresent) {
                        notify->setInt32("channel-mask", mChannelMask);
 }
 break;
 }

 case OMX_AUDIO_CodingAAC:
 {
                    OMX_AUDIO_PARAM_AACPROFILETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioAac, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AAC);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAMR:
 {
                    OMX_AUDIO_PARAM_AMRTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioAmr, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setInt32("channel-count", 1);
 if (params.eAMRBandMode >= OMX_AUDIO_AMRBandModeWB0) {
                        notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AMR_WB);
                        notify->setInt32("sample-rate", 16000);
 } else {
                        notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AMR_NB);
                        notify->setInt32("sample-rate", 8000);
 }
 break;
 }

 case OMX_AUDIO_CodingFLAC:
 {
                    OMX_AUDIO_PARAM_FLACTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioFlac, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_FLAC);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingMP3:
 {
                    OMX_AUDIO_PARAM_MP3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioMp3, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_MPEG);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingVORBIS:
 {
                    OMX_AUDIO_PARAM_VORBISTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, OMX_IndexParamAudioVorbis, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_VORBIS);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidAC3:
 {
                    OMX_AUDIO_PARAM_ANDROID_AC3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidAc3,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_AC3);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidEAC3:
 {
                    OMX_AUDIO_PARAM_ANDROID_EAC3TYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidEac3,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_EAC3);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingAndroidOPUS:
 {
                    OMX_AUDIO_PARAM_ANDROID_OPUSTYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidOpus,
 &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_OPUS);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSampleRate);
 break;
 }

 case OMX_AUDIO_CodingG711:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                            mNode, (OMX_INDEXTYPE)OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

 const char *mime = NULL;
 if (params.ePCMMode == OMX_AUDIO_PCMModeMULaw) {
                        mime = MEDIA_MIMETYPE_AUDIO_G711_MLAW;
 } else if (params.ePCMMode == OMX_AUDIO_PCMModeALaw) {
                        mime = MEDIA_MIMETYPE_AUDIO_G711_ALAW;
 } else { // params.ePCMMode == OMX_AUDIO_PCMModeLinear
                        mime = MEDIA_MIMETYPE_AUDIO_RAW;
 }
                    notify->setString("mime", mime);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);
 break;
 }

 case OMX_AUDIO_CodingGSMFR:
 {
                    OMX_AUDIO_PARAM_PCMMODETYPE params;
 InitOMXParams(&params);
                    params.nPortIndex = portIndex;

                    err = mOMX->getParameter(
                                mNode, OMX_IndexParamAudioPcm, &params, sizeof(params));
 if (err != OK) {
 return err;
 }

                    notify->setString("mime", MEDIA_MIMETYPE_AUDIO_MSGSM);
                    notify->setInt32("channel-count", params.nChannels);
                    notify->setInt32("sample-rate", params.nSamplingRate);
 break;
 }

 default:
                    ALOGE("Unsupported audio coding: %s(%d)\n",
                            asString(audioDef->eEncoding), audioDef->eEncoding);
 return BAD_TYPE;
 }
 break;
 }

 default:
            ALOGE("Unsupported domain: %s(%d)", asString(def.eDomain), def.eDomain);
 return BAD_TYPE;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void btif_remote_properties_evt(bt_status_t status, bt_bdaddr_t *remote_addr,
 uint32_t num_props, bt_property_t *p_props)
{
    HAL_CBACK(bt_hal_cbacks, remote_device_properties_cb,
                     status, remote_addr, num_props, p_props);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static Maybe<int64_t> IndexOfValueSlowPath(Isolate* isolate,
 Handle<JSObject> receiver,
 Handle<Object> value,
 uint32_t start_from,
 uint32_t length) {
 for (uint32_t k = start_from; k < length; ++k) {
 LookupIterator it(isolate, receiver, k);
 if (!it.IsFound()) {
 continue;
 }
 Handle<Object> element_k;
    ASSIGN_RETURN_ON_EXCEPTION_VALUE(
        isolate, element_k, Object::GetProperty(&it), Nothing<int64_t>());

 if (value->StrictEquals(*element_k)) return Just<int64_t>(k);
 }


   return Just<int64_t>(-1);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t MediaPlayerService::AudioOutput::getSampleRate() const
{
 Mutex::Autolock lock(mLock);
 if (mTrack == 0) return 0;
 return mTrack->getSampleRate();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int get_remote_service_record(bt_bdaddr_t *remote_addr, bt_uuid_t *uuid)
{
 /* sanity check */
 if (interface_ready() == FALSE)
 return BT_STATUS_NOT_READY;

 return btif_get_remote_service_record(remote_addr, uuid);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int btpan_tap_send(int tap_fd, const BD_ADDR src, const BD_ADDR dst, UINT16 proto, const char* buf,
                    UINT16 len, BOOLEAN ext, BOOLEAN forward)
{
    UNUSED(ext);
    UNUSED(forward);
 if (tap_fd != INVALID_FD)
 {
        tETH_HDR eth_hdr;
        memcpy(&eth_hdr.h_dest, dst, ETH_ADDR_LEN);
        memcpy(&eth_hdr.h_src, src, ETH_ADDR_LEN);
        eth_hdr.h_proto = htons(proto);
 char packet[TAP_MAX_PKT_WRITE_LEN + sizeof(tETH_HDR)];
        memcpy(packet, &eth_hdr, sizeof(tETH_HDR));
 if (len > TAP_MAX_PKT_WRITE_LEN)
 {
            LOG_ERROR("btpan_tap_send eth packet size:%d is exceeded limit!", len);
 return -1;
 }

         memcpy(packet + sizeof(tETH_HDR), buf, len);
 
         /* Send data to network interface */
        int ret = write(tap_fd, packet, len + sizeof(tETH_HDR));
         BTIF_TRACE_DEBUG("ret:%d", ret);
         return ret;
     }
 return -1;

}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static l2cap_socket *btsock_l2cap_alloc(const char *name, const bt_bdaddr_t *addr,
 char is_server, int flags)
{
    l2cap_socket *ret;

    pthread_mutex_lock(&state_lock);
    ret = btsock_l2cap_alloc_l(name, addr, is_server, flags);
    pthread_mutex_unlock(&state_lock);

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AgcDisable(preproc_effect_t *effect)
{
    ALOGV("AgcDisable");
    webrtc::GainControl *agc = static_cast<webrtc::GainControl *>(effect->engine);
    agc->Enable(false);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int get_next_buffer(struct resampler_buffer_provider *buffer_provider,
 struct resampler_buffer* buffer)
{
 struct stream_in *in;
 struct pcm_device *pcm_device;

 if (buffer_provider == NULL || buffer == NULL)
 return -EINVAL;

    in = (struct stream_in *)((char *)buffer_provider -
                                   offsetof(struct stream_in, buf_provider));

 if (list_empty(&in->pcm_dev_list)) {
        buffer->raw = NULL;
        buffer->frame_count = 0;
        in->read_status = -ENODEV;
 return -ENODEV;
 }

    pcm_device = node_to_item(list_head(&in->pcm_dev_list),
 struct pcm_device, stream_list_node);

 if (in->read_buf_frames == 0) {
 size_t size_in_bytes = pcm_frames_to_bytes(pcm_device->pcm, in->config.period_size);
 if (in->read_buf_size < in->config.period_size) {
            in->read_buf_size = in->config.period_size;
            in->read_buf = (int16_t *) realloc(in->read_buf, size_in_bytes);
            ALOG_ASSERT((in->read_buf != NULL),
 "get_next_buffer() failed to reallocate read_buf");
 }

        in->read_status = pcm_read(pcm_device->pcm, (void*)in->read_buf, size_in_bytes);

 if (in->read_status != 0) {
            ALOGE("get_next_buffer() pcm_read error %d", in->read_status);
            buffer->raw = NULL;
            buffer->frame_count = 0;
 return in->read_status;
 }
        in->read_buf_frames = in->config.period_size;
 }

    buffer->frame_count = (buffer->frame_count > in->read_buf_frames) ?
                                in->read_buf_frames : buffer->frame_count;
    buffer->i16 = in->read_buf + (in->config.period_size - in->read_buf_frames) *
                                                in->config.channels;
 return in->read_status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::getConfig(

         OMX_INDEXTYPE index, void *params, size_t /* size */) {
     Mutex::Autolock autoLock(mLock);
 
     OMX_ERRORTYPE err = OMX_GetConfig(mHandle, index, params);
     OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
 if (err != OMX_ErrorNoMore) {
        CLOG_IF_ERROR(getConfig, err, "%s(%#x)", asString(extIndex), index);
 }
 return StatusFromOMXError(err);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleIterator::seekTo(uint32_t sampleIndex) {
    ALOGV("seekTo(%d)", sampleIndex);

 if (sampleIndex >= mTable->mNumSampleSizes) {
 return ERROR_END_OF_STREAM;
 }

 if (mTable->mSampleToChunkOffset < 0
 || mTable->mChunkOffsetOffset < 0
 || mTable->mSampleSizeOffset < 0
 || mTable->mTimeToSampleCount == 0) {

 return ERROR_MALFORMED;
 }

 if (mInitialized && mCurrentSampleIndex == sampleIndex) {
 return OK;
 }

 if (!mInitialized || sampleIndex < mFirstChunkSampleIndex) {
        reset();
 }

 if (sampleIndex >= mStopChunkSampleIndex) {
 status_t err;
 if ((err = findChunkRange(sampleIndex)) != OK) {
            ALOGE("findChunkRange failed");
 return err;
 }
 }

    CHECK(sampleIndex < mStopChunkSampleIndex);

 if (mSamplesPerChunk == 0) {
        ALOGE("b/22802344");
 return ERROR_MALFORMED;
 }

 uint32_t chunk =
 (sampleIndex - mFirstChunkSampleIndex) / mSamplesPerChunk

         + mFirstChunk;
 
     if (!mInitialized || chunk != mCurrentChunkIndex) {
        mCurrentChunkIndex = chunk;
         status_t err;
         if ((err = getChunkOffset(chunk, &mCurrentChunkOffset)) != OK) {
             ALOGE("getChunkOffset return error");
 return err;
 }

        mCurrentChunkSampleSizes.clear();

 
         uint32_t firstChunkSampleIndex =
             mFirstChunkSampleIndex
                + mSamplesPerChunk * (mCurrentChunkIndex - mFirstChunk);
 
         for (uint32_t i = 0; i < mSamplesPerChunk; ++i) {
             size_t sampleSize;
             if ((err = getSampleSizeDirect(
                             firstChunkSampleIndex + i, &sampleSize)) != OK) {
                 ALOGE("getSampleSizeDirect return error");
                 return err;
             }
 
             mCurrentChunkSampleSizes.push(sampleSize);
         }
     }
 
     uint32_t chunkRelativeSampleIndex =
 (sampleIndex - mFirstChunkSampleIndex) % mSamplesPerChunk;

    mCurrentSampleOffset = mCurrentChunkOffset;
 for (uint32_t i = 0; i < chunkRelativeSampleIndex; ++i) {
        mCurrentSampleOffset += mCurrentChunkSampleSizes[i];
 }

    mCurrentSampleSize = mCurrentChunkSampleSizes[chunkRelativeSampleIndex];
 if (sampleIndex < mTTSSampleIndex) {
        mTimeToSampleIndex = 0;
        mTTSSampleIndex = 0;
        mTTSSampleTime = 0;
        mTTSCount = 0;
        mTTSDuration = 0;
 }

 status_t err;
 if ((err = findSampleTimeAndDuration(
            sampleIndex, &mCurrentSampleTime, &mCurrentSampleDuration)) != OK) {
        ALOGE("findSampleTime return error");
 return err;
 }

    mCurrentSampleIndex = sampleIndex;

    mInitialized = true;

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftMPEG4Encoder::initEncParams() {
    CHECK(mHandle != NULL);
    memset(mHandle, 0, sizeof(tagvideoEncControls));

    CHECK(mEncParams != NULL);
    memset(mEncParams, 0, sizeof(tagvideoEncOptions));
 if (!PVGetDefaultEncOption(mEncParams, 0)) {

         ALOGE("Failed to get default encoding parameters");
         return OMX_ErrorUndefined;
     }
     mEncParams->encMode = mEncodeMode;
     mEncParams->encWidth[0] = mWidth;
     mEncParams->encHeight[0] = mHeight;
    mEncParams->encFrameRate[0] = mFramerate >> 16; // mFramerate is in Q16 format
    mEncParams->rcType = VBR_1;
    mEncParams->vbvDelay = 5.0f;

    mEncParams->profile_level = CORE_PROFILE_LEVEL2;
    mEncParams->packetSize = 32;
    mEncParams->rvlcEnable = PV_OFF;
    mEncParams->numLayers = 1;
    mEncParams->timeIncRes = 1000;
    mEncParams->tickPerSrc = ((int64_t)mEncParams->timeIncRes << 16) / mFramerate;

    mEncParams->bitRate[0] = mBitrate;
    mEncParams->iQuant[0] = 15;
    mEncParams->pQuant[0] = 12;
    mEncParams->quantType[0] = 0;
    mEncParams->noFrameSkipped = PV_OFF;

 if (mColorFormat != OMX_COLOR_FormatYUV420Planar || mInputDataIsMeta) {
        free(mInputFrameData);
        mInputFrameData = NULL;
 if (((uint64_t)mWidth * mHeight) > ((uint64_t)INT32_MAX / 3)) {
            ALOGE("b/25812794, Buffer size is too big.");
 return OMX_ErrorBadParameter;
 }
        mInputFrameData =
 (uint8_t *) malloc((mWidth * mHeight * 3 ) >> 1);
        CHECK(mInputFrameData != NULL);
 }

 if (mWidth % 16 != 0 || mHeight % 16 != 0) {
        ALOGE("Video frame size %dx%d must be a multiple of 16",
            mWidth, mHeight);
 return OMX_ErrorBadParameter;
 }

 if (mIDRFrameRefreshIntervalInSec < 0) {
        mEncParams->intraPeriod = -1;
 } else if (mIDRFrameRefreshIntervalInSec == 0) {
        mEncParams->intraPeriod = 1; // All I frames
 } else {
        mEncParams->intraPeriod =
 (mIDRFrameRefreshIntervalInSec * mFramerate) >> 16;
 }

    mEncParams->numIntraMB = 0;
    mEncParams->sceneDetect = PV_ON;
    mEncParams->searchRange = 16;
    mEncParams->mv8x8Enable = PV_OFF;
    mEncParams->gobHeaderInterval = 0;
    mEncParams->useACPred = PV_ON;
    mEncParams->intraDCVlcTh = 0;

 return OMX_ErrorNone;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool venc_dev::venc_validate_hybridhp_params(OMX_U32 layers, OMX_U32 bFrames, OMX_U32 count, int mode)
{
 if (layers && (mode == HIER_P || mode == HIER_B) && hier_layers.hier_mode == HIER_P_HYBRID)
 return false;

 if (bFrames && hier_layers.hier_mode == HIER_P_HYBRID)
 return false;

 if (layers && mode == HIER_P_HYBRID && (intra_period.num_bframes || hier_layers.hier_mode == HIER_P ||
           hier_layers.hier_mode == HIER_B || ltrinfo.count))
 return false;

 if (count && hier_layers.hier_mode == HIER_P_HYBRID)
 return false;

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::Client::setNextPlayer(const sp<IMediaPlayer>& player) {
    ALOGV("setNextPlayer");
 Mutex::Autolock l(mLock);
    sp<Client> c = static_cast<Client*>(player.get());
    mNextClient = c;

 if (c != NULL) {
 if (mAudioOutput != NULL) {
            mAudioOutput->setNextOutput(c->mAudioOutput);
 } else if ((mPlayer != NULL) && !mPlayer->hardwareOutput()) {
            ALOGE("no current audio output");
 }

 if ((mPlayer != NULL) && (mNextClient->getPlayer() != NULL)) {
            mPlayer->setNextPlayer(mNextClient->getPlayer());
 }
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void unmarshallAudioAttributes(const Parcel& parcel, audio_attributes_t *attributes)
{
    attributes->usage = (audio_usage_t) parcel.readInt32();
    attributes->content_type = (audio_content_type_t) parcel.readInt32();
    attributes->source = (audio_source_t) parcel.readInt32();
    attributes->flags = (audio_flags_mask_t) parcel.readInt32();
 const bool hasFlattenedTag = (parcel.readInt32() == kAudioAttributesMarshallTagFlattenTags);
 if (hasFlattenedTag) {
 String16 tags = parcel.readString16();
 ssize_t realTagSize = utf16_to_utf8_length(tags.string(), tags.size());
 if (realTagSize <= 0) {
            strcpy(attributes->tags, "");
 } else {
 size_t tagSize = realTagSize > AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - 1 ?
                    AUDIO_ATTRIBUTES_TAGS_MAX_SIZE - 1 : realTagSize;
            utf16_to_utf8(tags.string(), tagSize, attributes->tags,
 sizeof(attributes->tags) / sizeof(attributes->tags[0]));
 }
 } else {
        ALOGE("unmarshallAudioAttributes() received unflattened tags, ignoring tag values");
        strcpy(attributes->tags, "");
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_residual4x4_cavlc(dec_struct_t * ps_dec,
 dec_mb_info_t *ps_cur_mb_info,
                                      UWORD8 u1_offset)
{
    UWORD8 u1_cbp = ps_cur_mb_info->u1_cbp;
    UWORD16 ui16_csbp = 0;
    UWORD32 u4_nbr_avl;
    WORD16 *pi2_residual_buf;

    UWORD8 u1_is_top_mb_avail;
    UWORD8 u1_is_left_mb_avail;

    UWORD8 *pu1_top_nnz = ps_cur_mb_info->ps_curmb->pu1_nnz_y;
    UWORD8 *pu1_left_nnz = ps_dec->pu1_left_nnz_y;
    WORD16 *pi2_coeff_block = NULL;
    UWORD32 *pu4_dummy;
    WORD32 ret;

    WORD32 (**pf_cavlc_parse_8x8block)(WORD16 *pi2_coeff_block,
                                       UWORD32 u4_sub_block_strd,
                                       UWORD32 u4_isdc,
 struct _DecStruct *ps_dec,
                                       UWORD8 *pu1_top_nnz,
                                       UWORD8 *pu1_left_nnz,
                                       UWORD8 u1_tran_form8x8,
                                       UWORD8 u1_mb_field_decodingflag,
                                       UWORD32 *pu4_dummy) = ps_dec->pf_cavlc_parse_8x8block;


 {
        UWORD8 uc_temp = ps_dec->u1_mb_ngbr_availablity;
        u1_is_top_mb_avail = BOOLEAN(uc_temp & TOP_MB_AVAILABLE_MASK);
        u1_is_left_mb_avail = BOOLEAN(uc_temp & LEFT_MB_AVAILABLE_MASK);
        u4_nbr_avl = (u1_is_top_mb_avail << 1) | u1_is_left_mb_avail;
 }

    ps_cur_mb_info->u1_qp_div6 = ps_dec->u1_qp_y_div6;
    ps_cur_mb_info->u1_qp_rem6 = ps_dec->u1_qp_y_rem6;
    ps_cur_mb_info->u1_qpc_div6 = ps_dec->u1_qp_u_div6;
    ps_cur_mb_info->u1_qpc_rem6 = ps_dec->u1_qp_u_rem6;
    ps_cur_mb_info->u1_qpcr_div6 = ps_dec->u1_qp_v_div6;
    ps_cur_mb_info->u1_qpcr_rem6 = ps_dec->u1_qp_v_rem6;

 if(u1_cbp & 0xf)
 {
        pu1_top_nnz[0] = ps_cur_mb_info->ps_top_mb->pu1_nnz_y[0];
        pu1_top_nnz[1] = ps_cur_mb_info->ps_top_mb->pu1_nnz_y[1];
        pu1_top_nnz[2] = ps_cur_mb_info->ps_top_mb->pu1_nnz_y[2];
        pu1_top_nnz[3] = ps_cur_mb_info->ps_top_mb->pu1_nnz_y[3];

 /*******************************************************************/
 /* Block 0 residual decoding, check cbp and proceed (subblock = 0) */
 /*******************************************************************/
 if(!(u1_cbp & 0x1))
 {
 *(UWORD16 *)(pu1_top_nnz) = 0;
 *(UWORD16 *)(pu1_left_nnz) = 0;

 }
 else
 {
            UWORD32 u4_temp;
            ret = pf_cavlc_parse_8x8block[u4_nbr_avl](
                        pi2_coeff_block, 4, u1_offset, ps_dec, pu1_top_nnz,
                        pu1_left_nnz, ps_cur_mb_info->u1_tran_form8x8,
                        ps_cur_mb_info->u1_mb_field_decodingflag, &u4_temp);
 if(ret != OK)
 return ret;
            ui16_csbp = u4_temp;
 }

 /*******************************************************************/
 /* Block 1 residual decoding, check cbp and proceed (subblock = 2) */
 /*******************************************************************/
 if(ps_cur_mb_info->u1_tran_form8x8)
 {
            pi2_coeff_block += 64;
 }
 else
 {
            pi2_coeff_block += (2 * NUM_COEFFS_IN_4x4BLK);
 }

 if(!(u1_cbp & 0x2))
 {
 *(UWORD16 *)(pu1_top_nnz + 2) = 0;
 *(UWORD16 *)(pu1_left_nnz) = 0;
 }
 else
 {
            UWORD32 u4_temp = (u4_nbr_avl | 0x1);
            ret = pf_cavlc_parse_8x8block[u4_temp](
                        pi2_coeff_block, 4, u1_offset, ps_dec,
 (pu1_top_nnz + 2), pu1_left_nnz,
                        ps_cur_mb_info->u1_tran_form8x8,
                        ps_cur_mb_info->u1_mb_field_decodingflag, &u4_temp);
 if(ret != OK)
 return ret;
            ui16_csbp |= (u4_temp << 2);
 }

 /*******************************************************************/
 /* Block 2 residual decoding, check cbp and proceed (subblock = 8) */
 /*******************************************************************/
 if(ps_cur_mb_info->u1_tran_form8x8)
 {
            pi2_coeff_block += 64;
 }
 else
 {
            pi2_coeff_block += (6 * NUM_COEFFS_IN_4x4BLK);
 }

 if(!(u1_cbp & 0x4))
 {
 *(UWORD16 *)(pu1_top_nnz) = 0;
 *(UWORD16 *)(pu1_left_nnz + 2) = 0;
 }
 else
 {
            UWORD32 u4_temp = (u4_nbr_avl | 0x2);
            ret = pf_cavlc_parse_8x8block[u4_temp](
                        pi2_coeff_block, 4, u1_offset, ps_dec, pu1_top_nnz,
 (pu1_left_nnz + 2), ps_cur_mb_info->u1_tran_form8x8,
                        ps_cur_mb_info->u1_mb_field_decodingflag, &u4_temp);
 if(ret != OK)
 return ret;
            ui16_csbp |= (u4_temp << 8);
 }

 /*******************************************************************/
 /* Block 3 residual decoding, check cbp and proceed (subblock = 10)*/
 /*******************************************************************/
 if(ps_cur_mb_info->u1_tran_form8x8)
 {
            pi2_coeff_block += 64;
 }
 else
 {
            pi2_coeff_block += (2 * NUM_COEFFS_IN_4x4BLK);
 }

 if(!(u1_cbp & 0x8))
 {
 *(UWORD16 *)(pu1_top_nnz + 2) = 0;
 *(UWORD16 *)(pu1_left_nnz + 2) = 0;
 }
 else
 {
            UWORD32 u4_temp;
            ret = pf_cavlc_parse_8x8block[0x3](
                        pi2_coeff_block, 4, u1_offset, ps_dec,
 (pu1_top_nnz + 2), (pu1_left_nnz + 2),
                        ps_cur_mb_info->u1_tran_form8x8,
                        ps_cur_mb_info->u1_mb_field_decodingflag, &u4_temp);
 if(ret != OK)
 return ret;
            ui16_csbp |= (u4_temp << 10);
 }
 }
 else
 {
 *(UWORD32 *)(pu1_top_nnz) = 0;
 *(UWORD32 *)(pu1_left_nnz) = 0;
 }

    ps_cur_mb_info->u2_luma_csbp = ui16_csbp;
    ps_cur_mb_info->ps_curmb->u2_luma_csbp = ui16_csbp;

 {
        UWORD16 u2_chroma_csbp = 0;
        ps_cur_mb_info->u2_chroma_csbp = 0;
        pu1_top_nnz = ps_cur_mb_info->ps_curmb->pu1_nnz_uv;
        pu1_left_nnz = ps_dec->pu1_left_nnz_uv;

        u1_cbp >>= 4;
 /*--------------------------------------------------------------------*/
 /* if Chroma Component not present OR no ac values present            */
 /* Set the values of N to zero                                        */
 /*--------------------------------------------------------------------*/
 if(u1_cbp == CBPC_ALLZERO || u1_cbp == CBPC_ACZERO)
 {
 *(UWORD32 *)(pu1_top_nnz) = 0;
 *(UWORD32 *)(pu1_left_nnz) = 0;
 }

 if(u1_cbp == CBPC_ALLZERO)
 {
 return (0);
 }
 /*--------------------------------------------------------------------*/
 /* Decode Chroma DC values                                            */
 /*--------------------------------------------------------------------*/
 {
            WORD32 u4_scale_u;
            WORD32 u4_scale_v;
            WORD32 i4_mb_inter_inc;
            u4_scale_u = ps_dec->pu2_quant_scale_u[0] << ps_dec->u1_qp_u_div6;
            u4_scale_v = ps_dec->pu2_quant_scale_v[0] << ps_dec->u1_qp_v_div6;
            i4_mb_inter_inc = (!((ps_cur_mb_info->ps_curmb->u1_mb_type == I_4x4_MB)
 || (ps_cur_mb_info->ps_curmb->u1_mb_type == I_16x16_MB)))
 * 3;

 if(ps_dec->s_high_profile.u1_scaling_present)
 {
                u4_scale_u *=
                                ps_dec->s_high_profile.i2_scalinglist4x4[i4_mb_inter_inc
 + 1][0];
                u4_scale_v *=
                                ps_dec->s_high_profile.i2_scalinglist4x4[i4_mb_inter_inc
 + 2][0];

 }
 else
 {
                u4_scale_u <<= 4;
                u4_scale_v <<= 4;
 }

            ih264d_cavlc_parse_chroma_dc(ps_cur_mb_info,pi2_coeff_block, ps_dec->ps_bitstrm,
                                         u4_scale_u, u4_scale_v,
                                         i4_mb_inter_inc);
 }

 if(u1_cbp == CBPC_ACZERO)
 return (0);

        pu1_top_nnz[0] = ps_cur_mb_info->ps_top_mb->pu1_nnz_uv[0];
        pu1_top_nnz[1] = ps_cur_mb_info->ps_top_mb->pu1_nnz_uv[1];
        pu1_top_nnz[2] = ps_cur_mb_info->ps_top_mb->pu1_nnz_uv[2];
        pu1_top_nnz[3] = ps_cur_mb_info->ps_top_mb->pu1_nnz_uv[3];
 /*--------------------------------------------------------------------*/
 /* Decode Chroma AC values                                            */
 /*--------------------------------------------------------------------*/
 {
            UWORD32 u4_temp;
 /*****************************************************************/
 /* U Block  residual decoding, check cbp and proceed (subblock=0)*/
 /*****************************************************************/
            ret = pf_cavlc_parse_8x8block[u4_nbr_avl](
                        pi2_coeff_block, 2, 1, ps_dec, pu1_top_nnz,
                        pu1_left_nnz, 0, 0, &u4_temp);
 if(ret != OK)
 return ret;
            u2_chroma_csbp = u4_temp;

            pi2_coeff_block += MB_CHROM_SIZE;
 /*****************************************************************/
 /* V Block  residual decoding, check cbp and proceed (subblock=1)*/
 /*****************************************************************/
            ret = pf_cavlc_parse_8x8block[u4_nbr_avl](pi2_coeff_block, 2, 1,
                                                      ps_dec,
 (pu1_top_nnz + 2),
 (pu1_left_nnz + 2), 0,
 0, &u4_temp);
 if(ret != OK)
 return ret;
            u2_chroma_csbp |= (u4_temp << 4);
 }

        ps_cur_mb_info->u2_chroma_csbp = u2_chroma_csbp;
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: size_t asocket::get_max_payload() const {
 size_t max_payload = MAX_PAYLOAD;
 if (transport) {
        max_payload = std::min(max_payload, transport->get_max_payload());
 }
 if (peer && peer->transport) {
        max_payload = std::min(max_payload, peer->transport->get_max_payload());
 }
 return max_payload;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static ogg_uint32_t decpack(long entry,long used_entry,long quantvals,
			    codebook *b,oggpack_buffer *opb,int maptype){
   ogg_uint32_t ret=0;
   int j;
 
 switch(b->dec_type){

 case 0:
 return (ogg_uint32_t)entry;

 case 1:

     if(maptype==1){
       /* vals are already read into temporary column vector here */
       for(j=0;j<b->dim;j++){
	ogg_uint32_t off=entry%quantvals;
	entry/=quantvals;
	ret|=((ogg_uint16_t *)(b->q_val))[off]<<(b->q_bits*j);
       }
     }else{
       for(j=0;j<b->dim;j++)
	ret|=oggpack_read(opb,b->q_bits)<<(b->q_bits*j);
     }
     return ret;
 
 case 2:
 for(j=0;j<b->dim;j++){
 ogg_uint32_t off=entry%quantvals;
      entry/=quantvals;
      ret|=off<<(b->q_pack*j);
 }
 return ret;

 case 3:
 return (ogg_uint32_t)used_entry;

 }
 return 0; /* silence compiler */
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int compare_scan_result_timestamp(const void *v1, const void *v2) {
 const wifi_scan_result *result1 = static_cast<const wifi_scan_result *>(v1);
 const wifi_scan_result *result2 = static_cast<const wifi_scan_result *>(v2);
 return result1->ts - result2->ts;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long UnserializeString(IMkvReader* pReader, long long pos, long long size,
 char*& str) {
 delete[] str;
  str = NULL;

 if (size >= LONG_MAX || size < 0)
 return E_FILE_FORMAT_INVALID;

 const long required_size = static_cast<long>(size) + 1;

  str = SafeArrayAlloc<char>(1, required_size);
 if (str == NULL)
 return E_FILE_FORMAT_INVALID;

 unsigned char* const buf = reinterpret_cast<unsigned char*>(str);

 const long status = pReader->Read(pos, size, buf);

 if (status) {
 delete[] str;
    str = NULL;

 return status;
 }

  str[required_size - 1] = '\0';
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::ExecutingToIdleState::stateEntered() {
    ALOGV("[%s] Now Executing->Idle", mCodec->mComponentName.c_str());

    mComponentNowIdle = false;
    mCodec->mSentFormat = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Maybe<int64_t> IndexOfValueImpl(Isolate* isolate,
 Handle<JSObject> object,

                                          Handle<Object> value,
                                          uint32_t start_from, uint32_t length) {
     DCHECK(JSObject::PrototypeHasNoElements(isolate, *object));
    Handle<Map> original_map = handle(object->map(), isolate);
     Handle<FixedArray> parameter_map(FixedArray::cast(object->elements()),
                                      isolate);
 
     for (uint32_t k = start_from; k < length; ++k) {
       uint32_t entry = GetEntryForIndexImpl(isolate, *object, *parameter_map, k,
                                             ALL_PROPERTIES);
       if (entry == kMaxUInt32) {
 continue;
 }

 Handle<Object> element_k =
 Subclass::GetImpl(isolate, *parameter_map, entry);

 if (element_k->IsAccessorPair()) {
 LookupIterator it(isolate, object, k, LookupIterator::OWN);
        DCHECK(it.IsFound());
        DCHECK_EQ(it.state(), LookupIterator::ACCESSOR);
        ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, element_k,
 Object::GetPropertyWithAccessor(&it),
 Nothing<int64_t>());

 if (value->StrictEquals(*element_k)) {
 return Just<int64_t>(k);
 }

 if (object->map() != *original_map) {
 return IndexOfValueSlowPath(isolate, object, value, k + 1, length);
 }
 } else if (value->StrictEquals(*element_k)) {
 return Just<int64_t>(k);
 }
 }
 return Just<int64_t>(-1);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void expect_data(eager_reader_t *reader, void *context) {
 char *data = (char *)context;
 int length = strlen(data);

 for (int i = 0; i < length; i++) {
 uint8_t byte;
    EXPECT_EQ((size_t)1, eager_reader_read(reader, &byte, 1, true));
    EXPECT_EQ(data[i], byte);
 }

  semaphore_post(done);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::parseChunk(off64_t *offset) {
 uint32_t hdr[2];
 if (mDataSource->readAt(*offset, hdr, 8) < 8) {
 return ERROR_IO;
 }
 uint64_t chunk_size = ntohl(hdr[0]);
 uint32_t chunk_type = ntohl(hdr[1]);
 off64_t data_offset = *offset + 8;

 if (chunk_size == 1) {
 if (mDataSource->readAt(*offset + 8, &chunk_size, 8) < 8) {
 return ERROR_IO;
 }
        chunk_size = ntoh64(chunk_size);
        data_offset += 8;

 if (chunk_size < 16) {
 return ERROR_MALFORMED;
 }
 } else if (chunk_size < 8) {
 return ERROR_MALFORMED;
 }

 char chunk[5];
 MakeFourCCString(chunk_type, chunk);
    ALOGV("MPEG4Source chunk %s @ %llx", chunk, *offset);

 off64_t chunk_data_size = *offset + chunk_size - data_offset;

 switch(chunk_type) {

 case FOURCC('t', 'r', 'a', 'f'):
 case FOURCC('m', 'o', 'o', 'f'): {
 off64_t stop_offset = *offset + chunk_size;
 *offset = data_offset;
 while (*offset < stop_offset) {
 status_t err = parseChunk(offset);
 if (err != OK) {
 return err;
 }
 }
 if (chunk_type == FOURCC('m', 'o', 'o', 'f')) {
                parseChunk(offset); // doesn't actually parse it, just updates offset
                mNextMoofOffset = *offset;
 }
 break;
 }

 case FOURCC('t', 'f', 'h', 'd'): {
 status_t err;
 if ((err = parseTrackFragmentHeader(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }

 case FOURCC('t', 'r', 'u', 'n'): {
 status_t err;
 if (mLastParsedTrackId == mTrackId) {
 if ((err = parseTrackFragmentRun(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 }

 *offset += chunk_size;
 break;
 }

 case FOURCC('s', 'a', 'i', 'z'): {
 status_t err;
 if ((err = parseSampleAuxiliaryInformationSizes(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }
 case FOURCC('s', 'a', 'i', 'o'): {
 status_t err;
 if ((err = parseSampleAuxiliaryInformationOffsets(data_offset, chunk_data_size)) != OK) {
 return err;
 }
 *offset += chunk_size;
 break;
 }

 case FOURCC('m', 'd', 'a', 't'): {
            ALOGV("MPEG4Source::parseChunk mdat");
 *offset += chunk_size;
 break;
 }

 default: {
 *offset += chunk_size;
 break;
 }
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: asocket* create_local_socket(int fd) {
    asocket* s = reinterpret_cast<asocket*>(calloc(1, sizeof(asocket)));
 if (s == NULL) {
        fatal("cannot allocate socket");
 }
    s->fd = fd;
    s->enqueue = local_socket_enqueue;
    s->ready = local_socket_ready;
    s->shutdown = NULL;
    s->close = local_socket_close;
    install_local_socket(s);

    fdevent_install(&s->fde, fd, local_socket_event_func, s);
    D("LS(%d): created (fd=%d)", s->id, s->fd);
 return s;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::flushSaDb(const XfrmSocket& s) {
 struct xfrm_usersa_flush flushUserSa = {.proto = IPSEC_PROTO_ANY};

    std::vector<iovec> iov = {{NULL, 0}, // reserved for the eventual addition of a NLMSG_HDR
 {&flushUserSa, sizeof(flushUserSa)}, // xfrm_usersa_flush structure
 {kPadBytes, NLMSG_ALIGN(sizeof(flushUserSa)) - sizeof(flushUserSa)}};

 return s.sendMessage(XFRM_MSG_FLUSHSA, NETLINK_REQUEST_FLAGS, 0, &iov);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAVC::logVersion() {
 ivd_ctl_getversioninfo_ip_t s_ctl_ip;
 ivd_ctl_getversioninfo_op_t s_ctl_op;
    UWORD8 au1_buf[512];
    IV_API_CALL_STATUS_T status;

    s_ctl_ip.e_cmd = IVD_CMD_VIDEO_CTL;
    s_ctl_ip.e_sub_cmd = IVD_CMD_CTL_GETVERSION;
    s_ctl_ip.u4_size = sizeof(ivd_ctl_getversioninfo_ip_t);
    s_ctl_op.u4_size = sizeof(ivd_ctl_getversioninfo_op_t);
    s_ctl_ip.pv_version_buffer = au1_buf;
    s_ctl_ip.u4_version_buffer_size = sizeof(au1_buf);

    status =
        ivdec_api_function(mCodecCtx, (void *)&s_ctl_ip, (void *)&s_ctl_op);

 if (status != IV_SUCCESS) {
        ALOGE("Error in getting version number: 0x%x",
                s_ctl_op.u4_error_code);
 } else {
        ALOGV("Ittiam decoder version number: %s",
 (char *)s_ctl_ip.pv_version_buffer);
 }
 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool InputDispatcher::TouchState::isSlippery() const {
 bool haveSlipperyForegroundWindow = false;
 for (size_t i = 0; i < windows.size(); i++) {
 const TouchedWindow& window = windows.itemAt(i);
 if (window.targetFlags & InputTarget::FLAG_FOREGROUND) {
 if (haveSlipperyForegroundWindow
 || !(window.windowHandle->getInfo()->layoutParamsFlags
 & InputWindowInfo::FLAG_SLIPPERY)) {
 return false;
 }
            haveSlipperyForegroundWindow = true;
 }
 }
 return haveSlipperyForegroundWindow;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ih264d_unpack_chroma_coeff4x4_mb(dec_struct_t * ps_dec,
 dec_mb_info_t * ps_cur_mb_info)
{
    UWORD8 u1_mb_type = ps_cur_mb_info->u1_mb_type;
    UWORD16 ui2_chroma_csbp = ps_cur_mb_info->u2_chroma_csbp;
    UWORD8 *pu1_inv_scan = ps_dec->pu1_inv_scan;
    WORD16 *pi2_coeff_data = ps_dec->pi2_coeff_data;
    WORD32 i;
    WORD16 *pi2_dc_val_u = NULL;
    WORD16 *pi2_dc_val_v = NULL;

    PROFILE_DISABLE_UNPACK_CHROMA()
 if((ps_cur_mb_info->u1_cbp >> 4) == CBPC_ALLZERO)
 return;

 /*
     * Reserve the pointers to dc vals. The dc vals will be copied
     * after unpacking of ac vals since memset to 0 inside.
     */
 if(CHECKBIT(ps_cur_mb_info->u1_yuv_dc_block_flag,1))
 {
        pi2_dc_val_u = (WORD16 *)ps_dec->pv_proc_tu_coeff_data;

        ps_dec->pv_proc_tu_coeff_data = (void *)(pi2_dc_val_u + 4);
 }
 if(CHECKBIT(ps_cur_mb_info->u1_yuv_dc_block_flag,2))
 {
        pi2_dc_val_v = (WORD16 *)ps_dec->pv_proc_tu_coeff_data;

        ps_dec->pv_proc_tu_coeff_data = (void *)(pi2_dc_val_v + 4);
 }

 if((ps_cur_mb_info->u1_cbp >> 4) == CBPC_NONZERO)
 {
        pi2_coeff_data = ps_dec->pi2_coeff_data;
        ih264d_unpack_coeff4x4_8x8blk_chroma(ps_dec,
                                             ps_cur_mb_info,
                                             ui2_chroma_csbp,
                                             pi2_coeff_data);

        pi2_coeff_data += 64;
        ui2_chroma_csbp = ui2_chroma_csbp >> 4;
        ih264d_unpack_coeff4x4_8x8blk_chroma(ps_dec,
                                             ps_cur_mb_info,
                                             ui2_chroma_csbp,
                                             pi2_coeff_data);

 }

    pi2_coeff_data = ps_dec->pi2_coeff_data;
 if(pi2_dc_val_u != NULL)
 {
        pi2_coeff_data[0] = *pi2_dc_val_u++;
        pi2_coeff_data[1 * 16] = *pi2_dc_val_u++;
        pi2_coeff_data[2 * 16] = *pi2_dc_val_u++;
        pi2_coeff_data[3 * 16] = *pi2_dc_val_u++;
 }
 else
 {
        pi2_coeff_data[0] = 0;
        pi2_coeff_data[1 * 16] = 0;
        pi2_coeff_data[2 * 16] = 0;
        pi2_coeff_data[3 * 16] = 0;
 }
    pi2_coeff_data += 64;
 if(pi2_dc_val_v != NULL)
 {
        pi2_coeff_data[0] = *pi2_dc_val_v++;
        pi2_coeff_data[1 * 16] = *pi2_dc_val_v++;
        pi2_coeff_data[2 * 16] = *pi2_dc_val_v++;
        pi2_coeff_data[3 * 16] = *pi2_dc_val_v++;
 }
 else
 {
        pi2_coeff_data[0] = 0;
        pi2_coeff_data[1 * 16] = 0;
        pi2_coeff_data[2 * 16] = 0;
        pi2_coeff_data[3 * 16] = 0;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_process_io_response(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {

  SMP_TRACE_DEBUG("%s", __func__);
 if (p_cb->flags & SMP_PAIR_FLAGS_WE_STARTED_DD) {
 /* pairing started by local (slave) Security Request */
    smp_set_state(SMP_STATE_SEC_REQ_PENDING);
    smp_send_cmd(SMP_OPCODE_SEC_REQ, p_cb);
 } else /* plan to send pairing respond */
 {
 /* pairing started by peer (master) Pairing Request */
    p_cb->selected_association_model = smp_select_association_model(p_cb);

 if (p_cb->secure_connections_only_mode_required &&
 (!(p_cb->le_secure_connections_mode_is_used) ||
 (p_cb->selected_association_model == SMP_MODEL_SEC_CONN_JUSTWORKS))) {
      SMP_TRACE_ERROR(
 "Slave requires secure connection only mode "
 "but it can't be provided -> Slave fails pairing");
      tSMP_INT_DATA smp_int_data;
      smp_int_data.status = SMP_PAIR_AUTH_FAIL;
      smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &smp_int_data);
 return;
 }

 if (p_cb->selected_association_model == SMP_MODEL_SEC_CONN_OOB) {
 if (smp_request_oob_data(p_cb)) return;
 }

 if (pts_test_send_authentication_complete_failure(p_cb)) return;

    smp_send_pair_rsp(p_cb, NULL);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMX::CallbackDispatcher::post(const omx_message &msg, bool realTime) {
 Mutex::Autolock autoLock(mLock);

    mQueue.push_back(msg);
 if (realTime) {
        mQueueChanged.signal();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: GraphicBuffer::~GraphicBuffer()
{
 if (handle) {
        free_handle();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_transform_png_set_scale_16_mod(PNG_CONST image_transform *this,
     image_pixel *that, png_const_structp pp,
    PNG_CONST transform_display *display)
 {
    if (that->bit_depth == 16)
    {
      that->sample_depth = that->bit_depth = 8;
 if (that->red_sBIT > 8) that->red_sBIT = 8;
 if (that->green_sBIT > 8) that->green_sBIT = 8;
 if (that->blue_sBIT > 8) that->blue_sBIT = 8;
 if (that->alpha_sBIT > 8) that->alpha_sBIT = 8;
 }

 this->next->mod(this->next, that, pp, display);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::allocate_input_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes)
{
 (void)hComp, (void)port;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned   i = 0;

    DEBUG_PRINT_HIGH("allocate_input_buffer()::");
 if (bytes != m_sInPortDef.nBufferSize) {
        DEBUG_PRINT_ERROR("ERROR: Buffer size mismatch error: bytes[%u] != nBufferSize[%u]",
 (unsigned int)bytes, (unsigned int)m_sInPortDef.nBufferSize);
 return OMX_ErrorBadParameter;
 }

 if (!m_inp_mem_ptr) {
        DEBUG_PRINT_HIGH("%s: size = %u, actual cnt %u", __FUNCTION__,
 (unsigned int)m_sInPortDef.nBufferSize, (unsigned int)m_sInPortDef.nBufferCountActual);
        m_inp_mem_ptr = (OMX_BUFFERHEADERTYPE*) \
                        calloc( (sizeof(OMX_BUFFERHEADERTYPE)), m_sInPortDef.nBufferCountActual);
 if (m_inp_mem_ptr == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_inp_mem_ptr");
 return OMX_ErrorInsufficientResources;
 }

        DEBUG_PRINT_LOW("Successfully allocated m_inp_mem_ptr = %p", m_inp_mem_ptr);
        m_pInput_pmem = (struct pmem *) calloc(sizeof (struct pmem), m_sInPortDef.nBufferCountActual);

 if (m_pInput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_pmem");
 return OMX_ErrorInsufficientResources;
 }
#ifdef USE_ION
        m_pInput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sInPortDef.nBufferCountActual);
 if (m_pInput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pInput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif
 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
            m_pInput_pmem[i].fd = -1;
#ifdef USE_ION
            m_pInput_ion[i].ion_device_fd =-1;
            m_pInput_ion[i].fd_ion_data.fd =-1;
            m_pInput_ion[i].ion_alloc_data.handle = 0;
#endif
 }
 }

 for (i=0; i< m_sInPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_inp_bm_count,i)) {
 break;
 }
 }
 if (i < m_sInPortDef.nBufferCountActual) {

 *bufferHdr = (m_inp_mem_ptr + i);
 (*bufferHdr)->nSize             = sizeof(OMX_BUFFERHEADERTYPE);
 (*bufferHdr)->nVersion.nVersion = OMX_SPEC_VERSION;
 (*bufferHdr)->nAllocLen         = m_sInPortDef.nBufferSize;
 (*bufferHdr)->pAppPrivate       = appData;
 (*bufferHdr)->nInputPortIndex   = PORT_INDEX_IN;
 (*bufferHdr)->pInputPortPrivate = (OMX_PTR)&m_pInput_pmem[i];

#ifdef USE_ION
#ifdef _MSM8974_
        m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,0);
#else
        m_pInput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sInPortDef.nBufferSize,
 &m_pInput_ion[i].ion_alloc_data,
 &m_pInput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pInput_ion[i].ion_device_fd < 0) {
            DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }

        m_pInput_pmem[i].fd = m_pInput_ion[i].fd_ion_data.fd;
#else
        m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);

 if (m_pInput_pmem[i].fd == 0) {
            m_pInput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pInput_pmem[i].fd < 0) {
            DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() Failed");
 return OMX_ErrorInsufficientResources;
 }
#endif

         m_pInput_pmem[i].size = m_sInPortDef.nBufferSize;
         m_pInput_pmem[i].offset = 0;
 
        m_pInput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
         if(!secure_session) {
             m_pInput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                 m_pInput_pmem[i].size,PROT_READ|PROT_WRITE,
                 MAP_SHARED,m_pInput_pmem[i].fd,0);
         if (m_pInput_pmem[i].buffer == MAP_FAILED) {
                 DEBUG_PRINT_ERROR("ERROR: mmap FAILED= %d", errno);
             close(m_pInput_pmem[i].fd);
 #ifdef USE_ION
             free_ion_memory(&m_pInput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 } else {

             m_pInput_pmem[i].buffer = malloc(sizeof(OMX_U32) + sizeof(native_handle_t*));
             (*bufferHdr)->nAllocLen = sizeof(OMX_U32) + sizeof(native_handle_t*);
         }
 
 (*bufferHdr)->pBuffer           = (OMX_U8 *)m_pInput_pmem[i].buffer;
        DEBUG_PRINT_LOW("Virtual address in allocate buffer is %p", m_pInput_pmem[i].buffer);
        BITMASK_SET(&m_inp_bm_count,i);
 if (!mUseProxyColorFormat && (dev_use_buf(&m_pInput_pmem[i],PORT_INDEX_IN,i) != true)) {
            DEBUG_PRINT_ERROR("ERROR: dev_use_buf FAILED for i/p buf");
 return OMX_ErrorInsufficientResources;
 }
 } else {
        DEBUG_PRINT_ERROR("ERROR: All i/p buffers are allocated, invalid allocate buf call"
 "for index [%d]", i);
        eRet = OMX_ErrorInsufficientResources;
 }

 return eRet;
}

Labels: Yes
----------------lora model----------------
Response: OMX_ERRORTYPE omx_video::allocate_input_buffer(
        OMX_IN OMX_HANDLETYPE hComp,
        OMX_IN OMX_BUFFERHEADERTYPE *bufferHdr,
        OMX_IN OMX_PTR appData,
        OMX_IN OMX_U32 bytes)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;

    DEBUG_PRINT_LOW("allocate_input_buffer: OMX_ERRORTYPE omx_video::allocate_input_buffer(OMX_ERRORTYPE eRet)
{
        DEBUG_PRINT_LOW("allocate_input_buffer: OMX_ERRORTYPE omx_video::allocate_input_buffer(OMX_ERRORTYPE omx_video::OMX_ERRORTYPE omx_video::OMX_ERRORTYPE omx_video::OMX_ERRORTYPE omx_video::OMX_ERRORTYPE omx_video::OMX_ERRORTYPE
void omx_video::OMX_ERRORTYPE


Instruction: 
Input: BOOLEAN bta_hl_co_get_mdep_config(UINT8  app_id,
                                  UINT8 mdep_idx,
                                  UINT8 mdep_counter,
                                  tBTA_HL_MDEP_ID mdep_id,
                                  tBTA_HL_MDEP_CFG *p_mdep_cfg)
{
    UINT8       idx  ;
    UINT8       app_idx;
    BOOLEAN     success = FALSE;

    BTIF_TRACE_DEBUG("%s app_id=%d mdep_idx=%d mdep_id=%d mdep_counter=%d",
                      __FUNCTION__, app_id,mdep_idx,mdep_id,mdep_counter);

 if (btif_hl_find_app_idx(app_id, &app_idx))
 {
        idx = mdep_idx -mdep_counter-1;
        p_btif_hl_cb->acb[app_idx].sup_feature.mdep[idx].mdep_id = mdep_id;
        memcpy(p_mdep_cfg,
 &p_btif_hl_cb->acb[app_idx].sup_feature.mdep[idx].mdep_cfg,
 sizeof(tBTA_HL_MDEP_CFG));

        success = TRUE;
 }

    BTIF_TRACE_DEBUG("%s success=%d mdep_idx=%d mdep_id=%d",
                      __FUNCTION__, success, mdep_idx, mdep_id );

 return success;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: VOID ixheaacd_hbe_post_anal_prod2(ia_esbr_hbe_txposer_struct *ptr_hbe_txposer,
                                  WORD32 qmf_voc_columns, WORD32 qmf_band_idx) {
  WORD32 i;
  FLOAT32 *norm_ptr = &ptr_hbe_txposer->norm_qmf_in_buf[1][2 * qmf_band_idx];
  FLOAT32 *out_ptr = &ptr_hbe_txposer->qmf_out_buf[1][2 * qmf_band_idx];
  FLOAT32 *x_norm_ptr =
 &ptr_hbe_txposer->norm_qmf_in_buf[HBE_ZERO_BAND_IDX][2 * qmf_band_idx];

  ixheaacd_norm_qmf_in_buf_2(ptr_hbe_txposer, qmf_band_idx);

 for (; qmf_band_idx < ptr_hbe_txposer->x_over_qmf[1]; qmf_band_idx++) {
 for (i = 0; i < qmf_voc_columns; i++) {
      WORD32 k;
      FLOAT32 x_zero_band_r, x_zero_band_i;

      x_zero_band_r = *x_norm_ptr++;
      x_zero_band_i = *x_norm_ptr++;

 for (k = 0; k < HBE_OPER_BLK_LEN_2; k++) {
 register FLOAT32 tmp_r, tmp_i;
        tmp_r = *norm_ptr++;
        tmp_i = *norm_ptr++;

 *out_ptr++ +=
 ((tmp_r * x_zero_band_r - tmp_i * x_zero_band_i) * 0.3333333f);

 *out_ptr++ +=
 ((tmp_r * x_zero_band_i + tmp_i * x_zero_band_r) * 0.3333333f);

        norm_ptr += 126;
        out_ptr += 126;
 }

      norm_ptr -= 128 * 9;
      out_ptr -= 128 * 8;
      x_norm_ptr += 126;
 }
    out_ptr -= (128 * 2 * qmf_voc_columns) - 2;
    norm_ptr -= (128 * qmf_voc_columns) - 2;
    x_norm_ptr -= (128 * qmf_voc_columns) - 2;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btm_sec_start_encryption (tBTM_SEC_DEV_REC *p_dev_rec)
{
 if (!btsnd_hcic_set_conn_encrypt (p_dev_rec->hci_handle, TRUE))
 return(FALSE);

    p_dev_rec->sec_state = BTM_SEC_STATE_ENCRYPTING;
 return(TRUE);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Maybe<bool> IncludesValueImpl(Isolate* isolate,
 Handle<JSObject> receiver,
 Handle<Object> value,
 uint32_t start_from, uint32_t length) {
    DCHECK(JSObject::PrototypeHasNoElements(isolate, *receiver));
 bool search_for_hole = value->IsUndefined(isolate);

 if (!search_for_hole) {
 Maybe<bool> result = Nothing<bool>();
 if (DictionaryElementsAccessor::IncludesValueFastPath(
              isolate, receiver, value, start_from, length, &result)) {

         return result;
       }
     }
     Handle<SeededNumberDictionary> dictionary(
         SeededNumberDictionary::cast(receiver->elements()), isolate);
     for (uint32_t k = start_from; k < length; ++k) {
       int entry = dictionary->FindEntry(isolate, k);
       if (entry == SeededNumberDictionary::kNotFound) {
         if (search_for_hole) return Just(true);
 continue;
 }

 PropertyDetails details = GetDetailsImpl(*dictionary, entry);
 switch (details.kind()) {
 case kData: {
 Object* element_k = dictionary->ValueAt(entry);
 if (value->SameValueZero(element_k)) return Just(true);
 break;
 }
 case kAccessor: {
 LookupIterator it(isolate, receiver, k,
 LookupIterator::OWN_SKIP_INTERCEPTOR);
          DCHECK(it.IsFound());
          DCHECK_EQ(it.state(), LookupIterator::ACCESSOR);
 Handle<Object> element_k;

          ASSIGN_RETURN_ON_EXCEPTION_VALUE(
              isolate, element_k, JSObject::GetPropertyWithAccessor(&it),
 Nothing<bool>());

 if (value->SameValueZero(*element_k)) return Just(true);

 if (!JSObject::PrototypeHasNoElements(isolate, *receiver)) {
 return IncludesValueSlowPath(isolate, receiver, value, k + 1,
                                         length);
 }

 if (*dictionary == receiver->elements()) continue;

 if (receiver->GetElementsKind() != DICTIONARY_ELEMENTS) {
 if (receiver->map()->GetInitialElements() == receiver->elements()) {
 return Just(search_for_hole);
 }
 return IncludesValueSlowPath(isolate, receiver, value, k + 1,
                                         length);
 }
          dictionary = handle(
 SeededNumberDictionary::cast(receiver->elements()), isolate);
 break;
 }
 }
 }
 return Just(false);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cues* Segment::GetCues() const { return m_pCues; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_parse_pred_wt_ofst(bitstrm_t *ps_bitstrm,
 sps_t *ps_sps,
 pps_t *ps_pps,
 slice_header_t *ps_slice_hdr)
{
    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    WORD32 value;
    WORD32 i;

 pred_wt_ofst_t *ps_wt_ofst = &ps_slice_hdr->s_wt_ofst;
    UNUSED(ps_pps);

    UEV_PARSE("luma_log2_weight_denom", value, ps_bitstrm);
    ps_wt_ofst->i1_luma_log2_weight_denom = value;

 if(ps_sps->i1_chroma_format_idc != 0)
 {
        SEV_PARSE("delta_chroma_log2_weight_denom", value, ps_bitstrm);
        ps_wt_ofst->i1_chroma_log2_weight_denom = ps_wt_ofst->i1_luma_log2_weight_denom + value;
 }

 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
        BITS_PARSE("luma_weight_l0_flag[ i ]", value, ps_bitstrm, 1);
        ps_wt_ofst->i1_luma_weight_l0_flag[i] = value;
 }



 if(ps_sps->i1_chroma_format_idc != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
            BITS_PARSE("chroma_weight_l0_flag[ i ]", value, ps_bitstrm, 1);
            ps_wt_ofst->i1_chroma_weight_l0_flag[i] = value;
 }
 }
 else
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
            ps_wt_ofst->i1_chroma_weight_l0_flag[i] = 0;
 }
 }


 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
 if(ps_wt_ofst->i1_luma_weight_l0_flag[i])
 {
            SEV_PARSE("delta_luma_weight_l0[ i ]", value, ps_bitstrm);


            ps_wt_ofst->i2_luma_weight_l0[i] = (1 << ps_wt_ofst->i1_luma_log2_weight_denom) + value;

            SEV_PARSE("luma_offset_l0[ i ]", value, ps_bitstrm);
            ps_wt_ofst->i2_luma_offset_l0[i] = value;

 }
 else
 {
            ps_wt_ofst->i2_luma_weight_l0[i] = (1 << ps_wt_ofst->i1_luma_log2_weight_denom);
            ps_wt_ofst->i2_luma_offset_l0[i] = 0;
 }
 if(ps_wt_ofst->i1_chroma_weight_l0_flag[i])
 {
            WORD32 ofst;
            WORD32 shift = (1 << (BIT_DEPTH_CHROMA - 1));
            SEV_PARSE("delta_chroma_weight_l0[ i ][ j ]", value, ps_bitstrm);
            ps_wt_ofst->i2_chroma_weight_l0_cb[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom) + value;


            SEV_PARSE("delta_chroma_offset_l0[ i ][ j ]", value, ps_bitstrm);
            ofst = ((shift * ps_wt_ofst->i2_chroma_weight_l0_cb[i]) >> ps_wt_ofst->i1_chroma_log2_weight_denom);
            ofst = value - ofst + shift;

            ps_wt_ofst->i2_chroma_offset_l0_cb[i] = CLIP_S8(ofst);

            SEV_PARSE("delta_chroma_weight_l0[ i ][ j ]", value, ps_bitstrm);
            ps_wt_ofst->i2_chroma_weight_l0_cr[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom) + value;


            SEV_PARSE("delta_chroma_offset_l0[ i ][ j ]", value, ps_bitstrm);
            ofst = ((shift * ps_wt_ofst->i2_chroma_weight_l0_cr[i]) >> ps_wt_ofst->i1_chroma_log2_weight_denom);
            ofst = value - ofst + shift;

            ps_wt_ofst->i2_chroma_offset_l0_cr[i] = CLIP_S8(ofst);

 }
 else
 {
            ps_wt_ofst->i2_chroma_weight_l0_cb[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom);
            ps_wt_ofst->i2_chroma_weight_l0_cr[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom);

            ps_wt_ofst->i2_chroma_offset_l0_cb[i] = 0;
            ps_wt_ofst->i2_chroma_offset_l0_cr[i] = 0;
 }
 }
 if(BSLICE == ps_slice_hdr->i1_slice_type)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
            BITS_PARSE("luma_weight_l1_flag[ i ]", value, ps_bitstrm, 1);
            ps_wt_ofst->i1_luma_weight_l1_flag[i] = value;
 }

 if(ps_sps->i1_chroma_format_idc != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                BITS_PARSE("chroma_weight_l1_flag[ i ]", value, ps_bitstrm, 1);
                ps_wt_ofst->i1_chroma_weight_l1_flag[i] = value;
 }
 }
 else
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                ps_wt_ofst->i1_chroma_weight_l1_flag[i] = 0;
 }
 }

 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
 if(ps_wt_ofst->i1_luma_weight_l1_flag[i])
 {
                SEV_PARSE("delta_luma_weight_l1[ i ]", value, ps_bitstrm);


                ps_wt_ofst->i2_luma_weight_l1[i] = (1 << ps_wt_ofst->i1_luma_log2_weight_denom) + value;

                SEV_PARSE("luma_offset_l1[ i ]", value, ps_bitstrm);
                ps_wt_ofst->i2_luma_offset_l1[i] = value;

 }
 else
 {
                ps_wt_ofst->i2_luma_weight_l1[i] = (1 << ps_wt_ofst->i1_luma_log2_weight_denom);
                ps_wt_ofst->i2_luma_offset_l1[i] = 0;
 }

 if(ps_wt_ofst->i1_chroma_weight_l1_flag[i])
 {
                WORD32 ofst;
                WORD32 shift = (1 << (BIT_DEPTH_CHROMA - 1));
                SEV_PARSE("delta_chroma_weight_l1[ i ][ j ]", value, ps_bitstrm);
                ps_wt_ofst->i2_chroma_weight_l1_cb[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom) + value;;


                SEV_PARSE("delta_chroma_offset_l1[ i ][ j ]", value, ps_bitstrm);
                ofst = ((shift * ps_wt_ofst->i2_chroma_weight_l1_cb[i]) >> ps_wt_ofst->i1_chroma_log2_weight_denom);
                ofst = value - ofst + shift;

                ps_wt_ofst->i2_chroma_offset_l1_cb[i] = CLIP_S8(ofst);;

                SEV_PARSE("delta_chroma_weight_l1[ i ][ j ]", value, ps_bitstrm);
                ps_wt_ofst->i2_chroma_weight_l1_cr[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom) + value;


                SEV_PARSE("delta_chroma_offset_l1[ i ][ j ]", value, ps_bitstrm);
                ofst = ((shift * ps_wt_ofst->i2_chroma_weight_l1_cr[i]) >> ps_wt_ofst->i1_chroma_log2_weight_denom);
                ofst = value - ofst + shift;

                ps_wt_ofst->i2_chroma_offset_l1_cr[i] = CLIP_S8(ofst);;

 }
 else
 {
                ps_wt_ofst->i2_chroma_weight_l1_cb[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom);
                ps_wt_ofst->i2_chroma_weight_l1_cr[i] = (1 << ps_wt_ofst->i1_chroma_log2_weight_denom);

                ps_wt_ofst->i2_chroma_offset_l1_cb[i] = 0;
                ps_wt_ofst->i2_chroma_offset_l1_cr[i] = 0;

 }
 }
 }
 return ret;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t AudioFlinger::EffectModule::remove_effect_from_hal_l()
{
 if ((mDescriptor.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_PRE_PROC ||
 (mDescriptor.flags & EFFECT_FLAG_TYPE_MASK) == EFFECT_FLAG_TYPE_POST_PROC) {
        sp<ThreadBase> thread = mThread.promote();
 if (thread != 0) {
 audio_stream_t *stream = thread->stream();
 if (stream != NULL) {
                stream->remove_audio_effect(stream, mEffectInterface);
 }
 }
 }
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void on_cl_rfc_init(tBTA_JV_RFCOMM_CL_INIT *p_init, uint32_t id) {
  pthread_mutex_lock(&slot_lock);

 rfc_slot_t *slot = find_rfc_slot_by_id(id);
 if (!slot)
 goto out;

 if (p_init->status == BTA_JV_SUCCESS)
    slot->rfc_handle = p_init->handle;
 else
    cleanup_rfc_slot(slot);

out:;
  pthread_mutex_unlock(&slot_lock);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t String8::appendFormat(const char* fmt, ...)
{
    va_list args;
    va_start(args, fmt);

 status_t result = appendFormatV(fmt, args);

    va_end(args);
 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  BufferMeta(const sp<IMemory> &mem, bool is_backup = false)
 : mMem(mem),
          mIsBackup(is_backup) {
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int strcmp16(const char16_t *s1, const char16_t *s2)
{
 char16_t ch;
 int d = 0;

 while ( 1 ) {
    d = (int)(ch = *s1++) - (int)*s2++;
 if ( d || !ch )
 break;
 }

 return d;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void VirtualizerSetStrength(EffectContext *pContext, uint32_t strength){
 LVM_ControlParams_t ActiveParams; /* Current control Parameters */
    LVM_ReturnStatus_en     LvmStatus=LVM_SUCCESS; /* Function call status */

    pContext->pBundledContext->VirtStrengthSaved = (int)strength;

 /* Get the current settings */
 LvmStatus = LVM_GetControlParameters(pContext->pBundledContext->hInstance,&ActiveParams);

    LVM_ERROR_CHECK(LvmStatus, "LVM_GetControlParameters", "VirtualizerSetStrength")

 /* Virtualizer parameters */
 ActiveParams.CS_EffectLevel             = (int)((strength*32767)/1000);


 /* Activate the initial settings */
 LvmStatus = LVM_SetControlParameters(pContext->pBundledContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVM_SetControlParameters", "VirtualizerSetStrength")
} /* end setStrength */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ATSParser::SyncEvent::SyncEvent(off64_t offset)
 : mInit(false), mOffset(offset), mTimeUs(0) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t flatten_binder(const sp<ProcessState>& /*proc*/,
 const wp<IBinder>& binder, Parcel* out)
{
    flat_binder_object obj;

    obj.flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS;
 if (binder != NULL) {
        sp<IBinder> real = binder.promote();
 if (real != NULL) {
 IBinder *local = real->localBinder();
 if (!local) {
 BpBinder *proxy = real->remoteBinder();
 if (proxy == NULL) {
                    ALOGE("null proxy");
 }
 const int32_t handle = proxy ? proxy->handle() : 0;
                obj.type = BINDER_TYPE_WEAK_HANDLE;
                obj.binder = 0; /* Don't pass uninitialized stack data to a remote process */
                obj.handle = handle;
                obj.cookie = 0;
 } else {
                obj.type = BINDER_TYPE_WEAK_BINDER;
                obj.binder = reinterpret_cast<uintptr_t>(binder.get_refs());
                obj.cookie = reinterpret_cast<uintptr_t>(binder.unsafe_get());
 }
 return finish_flatten_binder(real, obj, out);
 }

        ALOGE("Unable to unflatten Binder weak reference!");
        obj.type = BINDER_TYPE_BINDER;
        obj.binder = 0;
        obj.cookie = 0;
 return finish_flatten_binder(NULL, obj, out);

 } else {
        obj.type = BINDER_TYPE_BINDER;
        obj.binder = 0;
        obj.cookie = 0;
 return finish_flatten_binder(NULL, obj, out);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool LegacySniffMPEG4(
 const sp<DataSource> &source, String8 *mimeType, float *confidence) {
 uint8_t header[8];

 ssize_t n = source->readAt(4, header, sizeof(header));
 if (n < (ssize_t)sizeof(header)) {
 return false;
 }

 if (!memcmp(header, "ftyp3gp", 7) || !memcmp(header, "ftypmp42", 8)
 || !memcmp(header, "ftyp3gr6", 8) || !memcmp(header, "ftyp3gs6", 8)
 || !memcmp(header, "ftyp3ge6", 8) || !memcmp(header, "ftyp3gg6", 8)
 || !memcmp(header, "ftypisom", 8) || !memcmp(header, "ftypM4V ", 8)
 || !memcmp(header, "ftypM4A ", 8) || !memcmp(header, "ftypf4v ", 8)
 || !memcmp(header, "ftypkddi", 8) || !memcmp(header, "ftypM4VP", 8)) {
 *mimeType = MEDIA_MIMETYPE_CONTAINER_MPEG4;
 *confidence = 0.4;

 return true;
 }

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVC::initEncoder() {
    IV_STATUS_T status;
    WORD32 level;
 uint32_t displaySizeY;
    CHECK(!mStarted);

    OMX_ERRORTYPE errType = OMX_ErrorNone;

    displaySizeY = mWidth * mHeight;
 if (displaySizeY > (1920 * 1088)) {
        level = 50;
 } else if (displaySizeY > (1280 * 720)) {
        level = 40;
 } else if (displaySizeY > (720 * 576)) {
        level = 31;
 } else if (displaySizeY > (624 * 320)) {
        level = 30;
 } else if (displaySizeY > (352 * 288)) {
        level = 21;
 } else {
        level = 20;
 }
    mAVCEncLevel = MAX(level, mAVCEncLevel);

    mStride = mWidth;

 if (mInputDataIsMeta) {
 for (size_t i = 0; i < MAX_CONVERSION_BUFFERS; i++) {
 if (mConversionBuffers[i] != NULL) {
                free(mConversionBuffers[i]);
                mConversionBuffers[i] = 0;
 }

 if (((uint64_t)mStride * mHeight) > ((uint64_t)INT32_MAX / 3)) {
                ALOGE("Buffer size is too big.");
 return OMX_ErrorUndefined;
 }
            mConversionBuffers[i] = (uint8_t *)malloc(mStride * mHeight * 3 / 2);

 if (mConversionBuffers[i] == NULL) {
                ALOGE("Allocating conversion buffer failed.");
 return OMX_ErrorUndefined;
 }

            mConversionBuffersFree[i] = 1;
 }
 }

 switch (mColorFormat) {
 case OMX_COLOR_FormatYUV420SemiPlanar:
            mIvVideoColorFormat = IV_YUV_420SP_UV;
            ALOGV("colorFormat YUV_420SP");
 break;
 default:
 case OMX_COLOR_FormatYUV420Planar:
            mIvVideoColorFormat = IV_YUV_420P;
            ALOGV("colorFormat YUV_420P");
 break;
 }

    ALOGD("Params width %d height %d level %d colorFormat %d", mWidth,
            mHeight, mAVCEncLevel, mIvVideoColorFormat);

 /* Getting Number of MemRecords */
 {
 iv_num_mem_rec_ip_t s_num_mem_rec_ip;
 iv_num_mem_rec_op_t s_num_mem_rec_op;

        s_num_mem_rec_ip.u4_size = sizeof(iv_num_mem_rec_ip_t);
        s_num_mem_rec_op.u4_size = sizeof(iv_num_mem_rec_op_t);

        s_num_mem_rec_ip.e_cmd = IV_CMD_GET_NUM_MEM_REC;

        status = ive_api_function(0, &s_num_mem_rec_ip, &s_num_mem_rec_op);

 if (status != IV_SUCCESS) {
            ALOGE("Get number of memory records failed = 0x%x\n",
                    s_num_mem_rec_op.u4_error_code);
 return OMX_ErrorUndefined;
 }

        mNumMemRecords = s_num_mem_rec_op.u4_num_mem_rec;
 }

 /* Allocate array to hold memory records */
 if (mNumMemRecords > SIZE_MAX / sizeof(iv_mem_rec_t)) {
        ALOGE("requested memory size is too big.");
 return OMX_ErrorUndefined;
 }
    mMemRecords = (iv_mem_rec_t *)malloc(mNumMemRecords * sizeof(iv_mem_rec_t));
 if (NULL == mMemRecords) {
        ALOGE("Unable to allocate memory for hold memory records: Size %zu",
                mNumMemRecords * sizeof(iv_mem_rec_t));
        mSignalledError = true;
        notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;
 }

 {
 iv_mem_rec_t *ps_mem_rec;
        ps_mem_rec = mMemRecords;
 for (size_t i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec->u4_size = sizeof(iv_mem_rec_t);
            ps_mem_rec->pv_base = NULL;
            ps_mem_rec->u4_mem_size = 0;
            ps_mem_rec->u4_mem_alignment = 0;
            ps_mem_rec->e_mem_type = IV_NA_MEM_TYPE;

            ps_mem_rec++;
 }
 }

 /* Getting MemRecords Attributes */
 {
 iv_fill_mem_rec_ip_t s_fill_mem_rec_ip;
 iv_fill_mem_rec_op_t s_fill_mem_rec_op;

        s_fill_mem_rec_ip.u4_size = sizeof(iv_fill_mem_rec_ip_t);
        s_fill_mem_rec_op.u4_size = sizeof(iv_fill_mem_rec_op_t);

        s_fill_mem_rec_ip.e_cmd = IV_CMD_FILL_NUM_MEM_REC;
        s_fill_mem_rec_ip.ps_mem_rec = mMemRecords;
        s_fill_mem_rec_ip.u4_num_mem_rec = mNumMemRecords;
        s_fill_mem_rec_ip.u4_max_wd = mWidth;
        s_fill_mem_rec_ip.u4_max_ht = mHeight;
        s_fill_mem_rec_ip.u4_max_level = mAVCEncLevel;
        s_fill_mem_rec_ip.e_color_format = DEFAULT_INP_COLOR_FORMAT;
        s_fill_mem_rec_ip.u4_max_ref_cnt = DEFAULT_MAX_REF_FRM;
        s_fill_mem_rec_ip.u4_max_reorder_cnt = DEFAULT_MAX_REORDER_FRM;
        s_fill_mem_rec_ip.u4_max_srch_rng_x = DEFAULT_MAX_SRCH_RANGE_X;
        s_fill_mem_rec_ip.u4_max_srch_rng_y = DEFAULT_MAX_SRCH_RANGE_Y;

        status = ive_api_function(0, &s_fill_mem_rec_ip, &s_fill_mem_rec_op);

 if (status != IV_SUCCESS) {
            ALOGE("Fill memory records failed = 0x%x\n",
                    s_fill_mem_rec_op.u4_error_code);
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;
 }
 }

 /* Allocating Memory for Mem Records */
 {
        WORD32 total_size;
 iv_mem_rec_t *ps_mem_rec;
        total_size = 0;
        ps_mem_rec = mMemRecords;

 for (size_t i = 0; i < mNumMemRecords; i++) {
            ps_mem_rec->pv_base = ive_aligned_malloc(
                    ps_mem_rec->u4_mem_alignment, ps_mem_rec->u4_mem_size);
 if (ps_mem_rec->pv_base == NULL) {
                ALOGE("Allocation failure for mem record id %zu size %u\n", i,
                        ps_mem_rec->u4_mem_size);
                mSignalledError = true;
                notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
 return OMX_ErrorUndefined;

 }
            total_size += ps_mem_rec->u4_mem_size;

            ps_mem_rec++;
 }
 }

 /* Codec Instance Creation */
 {
 ive_init_ip_t s_init_ip;
 ive_init_op_t s_init_op;

        mCodecCtx = (iv_obj_t *)mMemRecords[0].pv_base;
        mCodecCtx->u4_size = sizeof(iv_obj_t);
        mCodecCtx->pv_fxns = (void *)ive_api_function;

        s_init_ip.u4_size = sizeof(ive_init_ip_t);
        s_init_op.u4_size = sizeof(ive_init_op_t);

        s_init_ip.e_cmd = IV_CMD_INIT;
        s_init_ip.u4_num_mem_rec = mNumMemRecords;
        s_init_ip.ps_mem_rec = mMemRecords;
        s_init_ip.u4_max_wd = mWidth;
        s_init_ip.u4_max_ht = mHeight;
        s_init_ip.u4_max_ref_cnt = DEFAULT_MAX_REF_FRM;
        s_init_ip.u4_max_reorder_cnt = DEFAULT_MAX_REORDER_FRM;
        s_init_ip.u4_max_level = mAVCEncLevel;
        s_init_ip.e_inp_color_fmt = mIvVideoColorFormat;

 if (mReconEnable || mPSNREnable) {
            s_init_ip.u4_enable_recon = 1;
 } else {
            s_init_ip.u4_enable_recon = 0;
 }
        s_init_ip.e_recon_color_fmt = DEFAULT_RECON_COLOR_FORMAT;
        s_init_ip.e_rc_mode = DEFAULT_RC_MODE;
        s_init_ip.u4_max_framerate = DEFAULT_MAX_FRAMERATE;
        s_init_ip.u4_max_bitrate = DEFAULT_MAX_BITRATE;
        s_init_ip.u4_num_bframes = mBframes;
        s_init_ip.e_content_type = IV_PROGRESSIVE;
        s_init_ip.u4_max_srch_rng_x = DEFAULT_MAX_SRCH_RANGE_X;
        s_init_ip.u4_max_srch_rng_y = DEFAULT_MAX_SRCH_RANGE_Y;
        s_init_ip.e_slice_mode = mSliceMode;
        s_init_ip.u4_slice_param = mSliceParam;
        s_init_ip.e_arch = mArch;
        s_init_ip.e_soc = DEFAULT_SOC;

        status = ive_api_function(mCodecCtx, &s_init_ip, &s_init_op);

 if (status != IV_SUCCESS) {
            ALOGE("Init memory records failed = 0x%x\n",
                    s_init_op.u4_error_code);
            mSignalledError = true;
            notify(OMX_EventError, OMX_ErrorUndefined, 0 /* arg2 */, NULL /* data */);
 return OMX_ErrorUndefined;
 }
 }

 /* Get Codec Version */
    logVersion();

 /* set processor details */
    setNumCores();

 /* Video control Set Frame dimensions */
    setDimensions();

 /* Video control Set Frame rates */
    setFrameRate();

 /* Video control Set IPE Params */
    setIpeParams();

 /* Video control Set Bitrate */
    setBitRate();

 /* Video control Set QP */
    setQp();

 /* Video control Set AIR params */
    setAirParams();

 /* Video control Set VBV params */
    setVbvParams();

 /* Video control Set Motion estimation params */
    setMeParams();

 /* Video control Set GOP params */
    setGopParams();

 /* Video control Set Deblock params */
    setDeblockParams();

 /* Video control Set Profile params */
    setProfileParams();

 /* Video control Set in Encode header mode */
    setEncMode(IVE_ENC_MODE_HEADER);

    ALOGV("init_codec successfull");

    mSpsPpsHeaderReceived = false;
    mStarted = true;

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: long mkvparser::ParseElementHeader(
    IMkvReader* pReader,
    long long& pos,
    long long stop,
    long long& id,
    long long& size)
{
    if ((stop >= 0) && (pos >= stop))
        return E_FILE_FORMAT_INVALID;
 
    long len;
 
    id = ReadUInt(pReader, pos, len);
 
    if (id < 0)
        return E_FILE_FORMAT_INVALID;
 
    pos += len;  //consume id
 
    if ((stop >= 0) && (pos >= stop))
        return E_FILE_FORMAT_INVALID;
 
    size = ReadUInt(pReader, pos, len);
 
    if (size < 0)
        return E_FILE_FORMAT_INVALID;
 
    pos += len;  //consume length of size
 
 
    if ((stop >= 0) && ((pos + size) > stop))
        return E_FILE_FORMAT_INVALID;
    return 0;  //success
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: ESDS::~ESDS() {
 delete[] mData;
    mData = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char *arg_next(struct arg *arg) {
 if (arg->argv[0])
    arg->argv += arg->argv_step;

 return *arg->argv;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Cluster* Segment::FindCluster(long long time_ns) const {
 if ((m_clusters == NULL) || (m_clusterCount <= 0))
 return &m_eos;

 {
 Cluster* const pCluster = m_clusters[0];
    assert(pCluster);
    assert(pCluster->m_index == 0);

 if (time_ns <= pCluster->GetTime())
 return pCluster;
 }


 long i = 0;
 long j = m_clusterCount;

 while (i < j) {

 const long k = i + (j - i) / 2;
    assert(k < m_clusterCount);

 Cluster* const pCluster = m_clusters[k];
    assert(pCluster);
    assert(pCluster->m_index == k);

 const long long t = pCluster->GetTime();

 if (t <= time_ns)
      i = k + 1;
 else
      j = k;

    assert(i <= j);
 }

  assert(i == j);
  assert(i > 0);
  assert(i <= m_clusterCount);

 const long k = i - 1;

 Cluster* const pCluster = m_clusters[k];
  assert(pCluster);
  assert(pCluster->m_index == k);
  assert(pCluster->GetTime() <= time_ns);


   return pCluster;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void IPCThreadState::processPendingDerefs()
{
 if (mIn.dataPosition() >= mIn.dataSize()) {
 size_t numPending = mPendingWeakDerefs.size();
 if (numPending > 0) {
 for (size_t i = 0; i < numPending; i++) {
 RefBase::weakref_type* refs = mPendingWeakDerefs[i];
                refs->decWeak(mProcess.get());
 }
            mPendingWeakDerefs.clear();
 }

        numPending = mPendingStrongDerefs.size();
 if (numPending > 0) {
 for (size_t i = 0; i < numPending; i++) {
 BBinder* obj = mPendingStrongDerefs[i];
                obj->decStrong(mProcess.get());
 }
            mPendingStrongDerefs.clear();
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t attachBuffer(int* slot, const sp<GraphicBuffer>& buffer) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferProducer::getInterfaceDescriptor());
        data.write(*buffer.get());
 status_t result = remote()->transact(ATTACH_BUFFER, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 *slot = reply.readInt32();
        result = reply.readInt32();
 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t UuidToProcId(const effect_uuid_t * uuid)
{
 size_t i;
 for (i = 0; i < PREPROC_NUM_EFFECTS; i++) {
 if (memcmp(uuid, sUuidToPreProcTable[i], sizeof(*uuid)) == 0) {
 break;
 }
 }
 return i;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: wifi_error init_wifi_vendor_hal_func_table(wifi_hal_fn *fn)
{
 if (fn == NULL) {
 return WIFI_ERROR_UNKNOWN;
 }
    fn->wifi_initialize = wifi_initialize;
    fn->wifi_cleanup = wifi_cleanup;
    fn->wifi_event_loop = wifi_event_loop;
    fn->wifi_get_supported_feature_set = wifi_get_supported_feature_set;
    fn->wifi_get_concurrency_matrix = wifi_get_concurrency_matrix;
    fn->wifi_set_scanning_mac_oui =  wifi_set_scanning_mac_oui;
    fn->wifi_get_ifaces = wifi_get_ifaces;
    fn->wifi_get_iface_name = wifi_get_iface_name;
    fn->wifi_start_gscan = wifi_start_gscan;
    fn->wifi_stop_gscan = wifi_stop_gscan;
    fn->wifi_get_cached_gscan_results = wifi_get_cached_gscan_results;
    fn->wifi_set_bssid_hotlist = wifi_set_bssid_hotlist;
    fn->wifi_reset_bssid_hotlist = wifi_reset_bssid_hotlist;
    fn->wifi_set_significant_change_handler = wifi_set_significant_change_handler;
    fn->wifi_reset_significant_change_handler = wifi_reset_significant_change_handler;
    fn->wifi_get_gscan_capabilities = wifi_get_gscan_capabilities;
    fn->wifi_get_link_stats = wifi_get_link_stats;
    fn->wifi_get_valid_channels = wifi_get_valid_channels;
    fn->wifi_rtt_range_request = wifi_rtt_range_request;
    fn->wifi_rtt_range_cancel = wifi_rtt_range_cancel;
    fn->wifi_get_rtt_capabilities = wifi_get_rtt_capabilities;
    fn->wifi_set_nodfs_flag = wifi_set_nodfs_flag;
    fn->wifi_start_logging = wifi_start_logging;
    fn->wifi_set_epno_list = wifi_set_epno_list;
    fn->wifi_set_country_code = wifi_set_country_code;
    fn->wifi_get_firmware_memory_dump = wifi_get_firmware_memory_dump;
    fn->wifi_set_log_handler = wifi_set_log_handler;
    fn->wifi_reset_log_handler = wifi_reset_log_handler;
    fn->wifi_set_alert_handler = wifi_set_alert_handler;
    fn->wifi_reset_alert_handler = wifi_reset_alert_handler;
    fn->wifi_get_firmware_version = wifi_get_firmware_version;
    fn->wifi_get_ring_buffers_status = wifi_get_ring_buffers_status;
    fn->wifi_get_logger_supported_feature_set = wifi_get_logger_supported_feature_set;
    fn->wifi_get_ring_data = wifi_get_ring_data;
    fn->wifi_get_driver_version = wifi_get_driver_version;
    fn->wifi_set_ssid_white_list = wifi_set_ssid_white_list;
    fn->wifi_set_gscan_roam_params = wifi_set_gscan_roam_params;
    fn->wifi_set_bssid_preference = wifi_set_bssid_preference;
    fn->wifi_set_bssid_blacklist = wifi_set_bssid_blacklist;
    fn->wifi_enable_lazy_roam = wifi_enable_lazy_roam;
    fn->wifi_start_rssi_monitoring = wifi_start_rssi_monitoring;
    fn->wifi_stop_rssi_monitoring = wifi_stop_rssi_monitoring;
    fn->wifi_start_sending_offloaded_packet = wifi_start_sending_offloaded_packet;
    fn->wifi_stop_sending_offloaded_packet = wifi_stop_sending_offloaded_packet;
 return WIFI_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoundPool::setPriority(int channelID, int priority)
{
    ALOGV("setPriority(%d, %d)", channelID, priority);
 Mutex::Autolock lock(&mLock);
 SoundChannel* channel = findChannel(channelID);
 if (channel) {
        channel->setPriority(priority);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN check_cached_remote_name(tBTA_DM_SEARCH *p_search_data,
                                UINT8 *p_remote_name, UINT8 *p_remote_name_len)
{
 bt_bdname_t bdname;
 bt_bdaddr_t remote_bdaddr;
 bt_property_t prop_name;

 /* check if we already have it in our btif_storage cache */
    bdcpy(remote_bdaddr.address, p_search_data->inq_res.bd_addr);
    BTIF_STORAGE_FILL_PROPERTY(&prop_name, BT_PROPERTY_BDNAME,
 sizeof(bt_bdname_t), &bdname);
 if (btif_storage_get_remote_device_property(
 &remote_bdaddr, &prop_name) == BT_STATUS_SUCCESS)
 {
 if (p_remote_name && p_remote_name_len)
 {
            strcpy((char *)p_remote_name, (char *)bdname.name);
 *p_remote_name_len = strlen((char *)p_remote_name);
 }
 return TRUE;
 }

 return FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void write_ivf_frame_header(FILE *outfile,
 const vpx_codec_cx_pkt_t *pkt)
{
 char             header[12];
 vpx_codec_pts_t  pts;

 if(pkt->kind != VPX_CODEC_CX_FRAME_PKT)
 return;

    pts = pkt->data.frame.pts;
    mem_put_le32(header, pkt->data.frame.sz);
    mem_put_le32(header+4, pts&0xFFFFFFFF);
    mem_put_le32(header+8, pts >> 32);


     (void) fwrite(header, 1, 12, outfile);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void bta_pan_callback(tBTA_PAN_EVT event, tBTA_PAN *p_data)
{
    btif_transfer_context(bta_pan_callback_transfer, event, (char*)p_data, sizeof(tBTA_PAN), NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint16_t transmit_data(serial_data_type_t type, uint8_t *data, uint16_t length) {
  assert(data != NULL);
  assert(length > 0);

 if (type < DATA_TYPE_COMMAND || type > DATA_TYPE_SCO) {
    LOG_ERROR("%s invalid data type: %d", __func__, type);
 return 0;
 }

 --data;
 uint8_t previous_byte = *data;
 *(data) = type;
 ++length;

 
   uint16_t transmitted_length = 0;
   while (length > 0) {
    ssize_t ret = write(uart_fd, data + transmitted_length, length);
     switch (ret) {
       case -1:
         LOG_ERROR("In %s, error writing to the uart serial port: %s", __func__, strerror(errno));
 goto done;
 case 0:
 goto done;
 default:
        transmitted_length += ret;
        length -= ret;
 break;
 }
 }

done:;
 *(data) = previous_byte;

 if (transmitted_length > 0)
 --transmitted_length;

 return transmitted_length;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void omx_vdec::append_terminator_extradata(OMX_OTHER_EXTRADATATYPE *extra)
{
 if (!client_extradata) {
 return;
 }
    extra->nSize = sizeof(OMX_OTHER_EXTRADATATYPE);
    extra->nVersion.nVersion = OMX_SPEC_VERSION;
    extra->eType = OMX_ExtraDataNone;
    extra->nDataSize = 0;
    extra->data[0] = 0;

    print_debug_extradata(extra);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAVC::onQueueFilled(OMX_U32 portIndex) {
    UNUSED(portIndex);

 if (mSignalledError) {
 return;
 }
 if (mOutputPortSettingsChange != NONE) {
 return;
 }

 if (NULL == mCodecCtx) {
 if (OK != initDecoder()) {
            ALOGE("Failed to initialize decoder");
            notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
            mSignalledError = true;
 return;
 }
 }
 if (outputBufferWidth() != mStride) {
 /* Set the run-time (dynamic) parameters */
        mStride = outputBufferWidth();
        setParams(mStride);
 }

 List<BufferInfo *> &inQueue = getPortQueue(kInputPortIndex);
 List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);

 /* If input EOS is seen and decoder is not in flush mode,
     * set the decoder in flush mode.
     * There can be a case where EOS is sent along with last picture data
     * In that case, only after decoding that input data, decoder has to be
     * put in flush. This case is handled here  */

 if (mReceivedEOS && !mIsInFlush) {
        setFlushMode();
 }

 while (!outQueue.empty()) {
 BufferInfo *inInfo;
        OMX_BUFFERHEADERTYPE *inHeader;

 BufferInfo *outInfo;
        OMX_BUFFERHEADERTYPE *outHeader;
 size_t timeStampIx;

        inInfo = NULL;
        inHeader = NULL;

 if (!mIsInFlush) {
 if (!inQueue.empty()) {
                inInfo = *inQueue.begin();
                inHeader = inInfo->mHeader;
 if (inHeader == NULL) {
                    inQueue.erase(inQueue.begin());
                    inInfo->mOwnedByUs = false;
 continue;
 }
 } else {
 break;
 }
 }

        outInfo = *outQueue.begin();
        outHeader = outInfo->mHeader;
        outHeader->nFlags = 0;
        outHeader->nTimeStamp = 0;
        outHeader->nOffset = 0;

 if (inHeader != NULL) {
 if (inHeader->nFilledLen == 0) {
                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);

 if (!(inHeader->nFlags & OMX_BUFFERFLAG_EOS)) {
 continue;
 }

                mReceivedEOS = true;
                inHeader = NULL;
                setFlushMode();
 } else if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                mReceivedEOS = true;
 }
 }

 /* Get a free slot in timestamp array to hold input timestamp */
 {
 size_t i;
            timeStampIx = 0;
 for (i = 0; i < MAX_TIME_STAMPS; i++) {
 if (!mTimeStampsValid[i]) {
                    timeStampIx = i;
 break;
 }
 }
 if (inHeader != NULL) {
                mTimeStampsValid[timeStampIx] = true;
                mTimeStamps[timeStampIx] = inHeader->nTimeStamp;
 }
 }

 {
 ivd_video_decode_ip_t s_dec_ip;
 ivd_video_decode_op_t s_dec_op;

             WORD32 timeDelay, timeTaken;
             size_t sizeY, sizeUV;
 
            setDecodeArgs(&s_dec_ip, &s_dec_op, inHeader, outHeader, timeStampIx);
             DUMP_TO_FILE(mInFile, s_dec_ip.pv_stream_buffer, s_dec_ip.u4_num_Bytes);
 
            GETTIME(&mTimeStart, NULL);
 /* Compute time elapsed between end of previous decode()
             * to start of current decode() */
            TIME_DIFF(mTimeEnd, mTimeStart, timeDelay);

            IV_API_CALL_STATUS_T status;
            status = ivdec_api_function(mCodecCtx, (void *)&s_dec_ip, (void *)&s_dec_op);

 bool unsupportedResolution =
 (IVD_STREAM_WIDTH_HEIGHT_NOT_SUPPORTED == (s_dec_op.u4_error_code & 0xFF));

 /* Check for unsupported dimensions */
 if (unsupportedResolution) {
                ALOGE("Unsupported resolution : %dx%d", mWidth, mHeight);
                notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
                mSignalledError = true;
 return;
 }

 bool allocationFailed = (IVD_MEM_ALLOC_FAILED == (s_dec_op.u4_error_code & 0xFF));
 if (allocationFailed) {
                ALOGE("Allocation failure in decoder");
                notify(OMX_EventError, OMX_ErrorUnsupportedSetting, 0, NULL);
                mSignalledError = true;
 return;
 }

 bool resChanged = (IVD_RES_CHANGED == (s_dec_op.u4_error_code & 0xFF));

            GETTIME(&mTimeEnd, NULL);
 /* Compute time taken for decode() */
            TIME_DIFF(mTimeStart, mTimeEnd, timeTaken);

            PRINT_TIME("timeTaken=%6d delay=%6d numBytes=%6d", timeTaken, timeDelay,
                   s_dec_op.u4_num_bytes_consumed);
 if (s_dec_op.u4_frame_decoded_flag && !mFlushNeeded) {
                mFlushNeeded = true;
 }

 if ((inHeader != NULL) && (1 != s_dec_op.u4_frame_decoded_flag)) {
 /* If the input did not contain picture data, then ignore
                 * the associated timestamp */
                mTimeStampsValid[timeStampIx] = false;
 }

 if (mChangingResolution && !s_dec_op.u4_output_present) {
                mChangingResolution = false;
                resetDecoder();
                resetPlugin();
 continue;
 }

 if (resChanged) {
                mChangingResolution = true;
 if (mFlushNeeded) {
                    setFlushMode();
 }
 continue;
 }

 if ((0 < s_dec_op.u4_pic_wd) && (0 < s_dec_op.u4_pic_ht)) {
 uint32_t width = s_dec_op.u4_pic_wd;
 uint32_t height = s_dec_op.u4_pic_ht;
 bool portWillReset = false;
                handlePortSettingsChange(&portWillReset, width, height);

 if (portWillReset) {
                    resetDecoder();
 return;
 }
 }

 if (s_dec_op.u4_output_present) {
                outHeader->nFilledLen = (outputBufferWidth() * outputBufferHeight() * 3) / 2;

                outHeader->nTimeStamp = mTimeStamps[s_dec_op.u4_ts];
                mTimeStampsValid[s_dec_op.u4_ts] = false;

                outInfo->mOwnedByUs = false;
                outQueue.erase(outQueue.begin());
                outInfo = NULL;
                notifyFillBufferDone(outHeader);
                outHeader = NULL;
 } else {
 /* If in flush mode and no output is returned by the codec,
                 * then come out of flush mode */
                mIsInFlush = false;

 /* If EOS was recieved on input port and there is no output
                 * from the codec, then signal EOS on output port */
 if (mReceivedEOS) {
                    outHeader->nFilledLen = 0;
                    outHeader->nFlags |= OMX_BUFFERFLAG_EOS;

                    outInfo->mOwnedByUs = false;
                    outQueue.erase(outQueue.begin());
                    outInfo = NULL;
                    notifyFillBufferDone(outHeader);
                    outHeader = NULL;
                    resetPlugin();
 }
 }
 }

 if (inHeader != NULL) {
            inInfo->mOwnedByUs = false;
            inQueue.erase(inQueue.begin());
            inInfo = NULL;
            notifyEmptyBufferDone(inHeader);
            inHeader = NULL;
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static int session_release_effect(struct session_s *session,
 struct effect_s *fx)
{
    ALOGW_IF(effect_release(fx) != 0, " session_release_effect() failed for id %d", fx->id);

    session->created_msk &= ~(1<<fx->id);
 if (session->created_msk == 0)
 {
        ALOGV("session_release_effect() last effect: removing session");
        list_remove(&session->node);
        free(session);
 }

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int prop2cfg(bt_bdaddr_t *remote_bd_addr, bt_property_t *prop)
{
 bdstr_t bdstr = {0};
 if(remote_bd_addr)
        bdaddr_to_string(remote_bd_addr, bdstr, sizeof(bdstr));
    BTIF_TRACE_DEBUG("in, bd addr:%s, prop type:%d, len:%d", bdstr, prop->type, prop->len);
 char value[1024];
 if(prop->len <= 0 || prop->len > (int)sizeof(value) - 1)
 {
        BTIF_TRACE_ERROR("property type:%d, len:%d is invalid", prop->type, prop->len);
 return FALSE;
 }
 switch(prop->type)
 {
 case BT_PROPERTY_REMOTE_DEVICE_TIMESTAMP:
            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_DEVTIME, (int)time(NULL));
 break;
 case BT_PROPERTY_BDNAME:
            strncpy(value, (char*)prop->val, prop->len);
            value[prop->len]='\0';
 if(remote_bd_addr)
                btif_config_set_str(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_NAME, value);
 else btif_config_set_str("Adapter",
                                BTIF_STORAGE_KEY_ADAPTER_NAME, value);
 /* save name immediately */
            btif_config_save();
 break;
 case BT_PROPERTY_REMOTE_FRIENDLY_NAME:
            strncpy(value, (char*)prop->val, prop->len);
            value[prop->len]='\0';
            btif_config_set_str(bdstr, BTIF_STORAGE_PATH_REMOTE_ALIASE, value);
 /* save friendly name immediately */
            btif_config_save();
 break;
 case BT_PROPERTY_ADAPTER_SCAN_MODE:
            btif_config_set_int("Adapter",
                                BTIF_STORAGE_KEY_ADAPTER_SCANMODE, *(int*)prop->val);
 break;
 case BT_PROPERTY_ADAPTER_DISCOVERY_TIMEOUT:
            btif_config_set_int("Adapter",
                                BTIF_STORAGE_KEY_ADAPTER_DISC_TIMEOUT, *(int*)prop->val);
 break;
 case BT_PROPERTY_CLASS_OF_DEVICE:
            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_DEVCLASS, *(int*)prop->val);
 break;
 case BT_PROPERTY_TYPE_OF_DEVICE:
            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_DEVTYPE, *(int*)prop->val);
 break;
 case BT_PROPERTY_UUIDS:
 {
 uint32_t i;
 char buf[64];
            value[0] = 0;
 for (i=0; i < (prop->len)/sizeof(bt_uuid_t); i++)
 {
 bt_uuid_t *p_uuid = (bt_uuid_t*)prop->val + i;
                memset(buf, 0, sizeof(buf));
                uuid_to_string_legacy(p_uuid, buf);
                strcat(value, buf);
                strcat(value, " ");
 }
            btif_config_set_str(bdstr, BTIF_STORAGE_PATH_REMOTE_SERVICE, value);
            btif_config_save();
 break;
 }
 case BT_PROPERTY_REMOTE_VERSION_INFO:
 {
 bt_remote_version_t *info = (bt_remote_version_t *)prop->val;

 if (!info)
 return FALSE;

            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_VER_MFCT, info->manufacturer);
            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_VER_VER, info->version);
            btif_config_set_int(bdstr,
                                BTIF_STORAGE_PATH_REMOTE_VER_SUBVER, info->sub_ver);
            btif_config_save();
 } break;

 default:
             BTIF_TRACE_ERROR("Unknow prop type:%d", prop->type);
 return FALSE;
 }
 return TRUE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_cabac_reset(cab_ctxt_t *ps_cabac,
 bitstrm_t *ps_bitstrm)
{
 /* Sanity checks */
    ASSERT(ps_cabac != NULL);
    ASSERT(ps_bitstrm != NULL);

 /* CABAC engine uses 32 bit range instead of 9 bits as specified by
     * the spec. This is done to reduce number of renormalizations
     */
 /* cabac engine initialization */
#if FULLRANGE
    ps_cabac->u4_range = (UWORD32)510 << RANGE_SHIFT;
    BITS_GET(ps_cabac->u4_ofst, ps_bitstrm->pu4_buf, ps_bitstrm->u4_bit_ofst,
                    ps_bitstrm->u4_cur_word, ps_bitstrm->u4_nxt_word, (9 + RANGE_SHIFT));

#else
    ps_cabac->u4_range = (UWORD32)510;
    BITS_GET(ps_cabac->u4_ofst, ps_bitstrm->pu4_buf, ps_bitstrm->u4_bit_ofst,
                    ps_bitstrm->u4_cur_word, ps_bitstrm->u4_nxt_word, 9);

#endif

 return ((IHEVCD_ERROR_T)IHEVCD_SUCCESS);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVC::internalSetBitrateParams(
 const OMX_VIDEO_PARAM_BITRATETYPE *bitrate) {
 if (bitrate->nPortIndex != kOutputPortIndex) {
 return OMX_ErrorUnsupportedIndex;
 }

    mBitrate = bitrate->nTargetBitrate;
    mBitrateUpdated = true;

 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void GrowCapacityAndConvertImpl(Handle<JSObject> object,
 uint32_t capacity) {
    UNREACHABLE();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void config_set_string(config_t *config, const char *section, const char *key, const char *value) {
 section_t *sec = section_find(config, section);
 if (!sec) {
    sec = section_new(section);
    list_append(config->sections, sec);
 }

 for (const list_node_t *node = list_begin(sec->entries); node != list_end(sec->entries); node = list_next(node)) {
 entry_t *entry = list_node(node);
 if (!strcmp(entry->key, key)) {
      osi_free(entry->value);
      entry->value = osi_strdup(value);
 return;
 }
 }

 entry_t *entry = entry_new(key, value);
  list_append(sec->entries, entry);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_br_process_pairing_command(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t* p = p_data->p_data;
  tBTM_SEC_DEV_REC* p_dev_rec = btm_find_dev(p_cb->pairing_bda);

  SMP_TRACE_DEBUG("%s", __func__);
 /* rejecting BR pairing request over non-SC BR link */
 if (!p_dev_rec->new_encryption_key_is_p256 && p_cb->role == HCI_ROLE_SLAVE) {
    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = SMP_XTRANS_DERIVE_NOT_ALLOW;
    smp_br_state_machine_event(p_cb, SMP_BR_AUTH_CMPL_EVT, &smp_int_data);
 return;
 }

 /* erase all keys if it is slave proc pairing req*/
 if (p_dev_rec && (p_cb->role == HCI_ROLE_SLAVE))
    btm_sec_clear_ble_keys(p_dev_rec);

  p_cb->flags |= SMP_PAIR_FLAG_ENC_AFTER_PAIR;

  STREAM_TO_UINT8(p_cb->peer_io_caps, p);
  STREAM_TO_UINT8(p_cb->peer_oob_flag, p);
  STREAM_TO_UINT8(p_cb->peer_auth_req, p);
  STREAM_TO_UINT8(p_cb->peer_enc_size, p);
  STREAM_TO_UINT8(p_cb->peer_i_key, p);
  STREAM_TO_UINT8(p_cb->peer_r_key, p);

 if (smp_command_has_invalid_parameters(p_cb)) {
    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = SMP_INVALID_PARAMETERS;
    smp_br_state_machine_event(p_cb, SMP_BR_AUTH_CMPL_EVT, &smp_int_data);
 return;
 }

 /* peer (master) started pairing sending Pairing Request */
 /* or being master device always use received i/r key as keys to distribute */
  p_cb->local_i_key = p_cb->peer_i_key;
  p_cb->local_r_key = p_cb->peer_r_key;

 if (p_cb->role == HCI_ROLE_SLAVE) {
    p_dev_rec->new_encryption_key_is_p256 = false;
 /* shortcut to skip Security Grant step */
    p_cb->cb_evt = SMP_BR_KEYS_REQ_EVT;
 } else {
 /* Master receives pairing response */
    SMP_TRACE_DEBUG(
 "%s master rcvs valid PAIRING RESPONSE."
 " Supposed to move to key distribution phase. ",
        __func__);
 }

 /* auth_req received via BR/EDR SM channel is set to 0,
     but everything derived/exchanged has to be saved */
  p_cb->peer_auth_req |= SMP_AUTH_BOND;
  p_cb->loc_auth_req |= SMP_AUTH_BOND;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void mkvparser::GetVersion(int& major, int& minor, int& build, int& revision) {
   major = 1;
   minor = 0;
   build = 0;
  revision = 28;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleTable::setTimeToSampleParams(
 off64_t data_offset, size_t data_size) {
 if (mTimeToSample != NULL || data_size < 8) {
 return ERROR_MALFORMED;
 }

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;

     }
 
     mTimeToSampleCount = U32_AT(&header[4]);
     mTimeToSample = new uint32_t[mTimeToSampleCount * 2];
 
     size_t size = sizeof(uint32_t) * mTimeToSampleCount * 2;
 if (mDataSource->readAt(
                data_offset + 8, mTimeToSample, size) < (ssize_t)size) {
 return ERROR_IO;
 }

 for (uint32_t i = 0; i < mTimeToSampleCount * 2; ++i) {
        mTimeToSample[i] = ntohl(mTimeToSample[i]);
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int in_standby(struct audio_stream *stream)
{
 struct stream_in *in = (struct stream_in *)stream;
 struct audio_device *adev = in->dev;
 int status;
    ALOGV("%s: enter", __func__);
    pthread_mutex_lock(&adev->lock_inputs);
    status = in_standby_l(in);
    pthread_mutex_unlock(&adev->lock_inputs);
    ALOGV("%s: exit:  status(%d)", __func__, status);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: omx_video::omx_cmd_queue::~omx_cmd_queue()
{
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void usage(const char *name) {
  fprintf(stderr, "Usage: %s [--bond|--discover|--discoverable|--up|--sco_listen|--sco_connect] [--bdaddr=<bdaddr>] [--time=<time_in_sec>] --verbose\n", name);
  fprintf(stderr, "     bond: Discover actively advertising devices\n");
  fprintf(stderr, "     discover: Discover actively advertising devices\n");
  fprintf(stderr, "     discoverable: Set into a connectable and discoverable mode\n");
  fprintf(stderr, "     up: Only bring up stack\n");
  fprintf(stderr, "     sco_listen: Listen for incoming SCO connections\n");
  fprintf(stderr, "     sco_connect: Establish a SCO connection with another device\n");
  fprintf(stderr, "     time: Time to hold in the specified mode\n");
  exit(1);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_ctl(iv_obj_t *dec_hdl, void *pv_api_ip, void *pv_api_op)
{
 ivd_ctl_set_config_ip_t *ps_ctl_ip;
 ivd_ctl_set_config_op_t *ps_ctl_op;
    WORD32 ret = IV_SUCCESS;
    UWORD32 subcommand;
 dec_struct_t *ps_dec = dec_hdl->pv_codec_handle;

 if(ps_dec->init_done != 1)
 {
 return IV_FAIL;
 }
    ps_ctl_ip = (ivd_ctl_set_config_ip_t*)pv_api_ip;
    ps_ctl_op = (ivd_ctl_set_config_op_t*)pv_api_op;
    ps_ctl_op->u4_error_code = 0;
    subcommand = ps_ctl_ip->e_sub_cmd;

 switch(subcommand)
 {
 case IVD_CMD_CTL_GETPARAMS:
            ret = ih264d_get_status(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_SETPARAMS:
            ret = ih264d_set_params(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_RESET:
            ret = ih264d_reset(dec_hdl, (void *)pv_api_ip, (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_SETDEFAULT:
            ret = ih264d_set_default_params(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_FLUSH:
            ret = ih264d_set_flush_mode(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_GETBUFINFO:
            ret = ih264d_get_buf_info(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IVD_CMD_CTL_GETVERSION:
            ret = ih264d_get_version(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IH264D_CMD_CTL_DEGRADE:
            ret = ih264d_set_degrade(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;

 case IH264D_CMD_CTL_SET_NUM_CORES:
            ret = ih264d_set_num_cores(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IH264D_CMD_CTL_GET_BUFFER_DIMENSIONS:
            ret = ih264d_get_frame_dimensions(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 case IH264D_CMD_CTL_SET_PROCESSOR:
            ret = ih264d_set_processor(dec_hdl, (void *)pv_api_ip,
 (void *)pv_api_op);
 break;
 default:
            H264_DEC_DEBUG_PRINT("\ndo nothing\n")
 ;
 break;
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_filler_data(dec_struct_t * ps_dec,
 dec_bit_stream_t * ps_bitstrm)
{
    UNUSED(ps_dec);
    UNUSED(ps_bitstrm);
 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMX::prepareForAdaptivePlayback(
        node_id node, OMX_U32 portIndex, OMX_BOOL enable,
        OMX_U32 maxFrameWidth, OMX_U32 maxFrameHeight) {
 return findInstance(node)->prepareForAdaptivePlayback(
            portIndex, enable, maxFrameWidth, maxFrameHeight);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int rpng2_x_msb(ulg u32val)
{
 int i;

 for (i = 31;  i >= 0; --i) {
 if (u32val & 0x80000000L)
 break;
        u32val <<= 1;
 }
 return i;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MyOggExtractor::seekToOffset(off64_t offset) {
 if (mFirstDataOffset >= 0 && offset < mFirstDataOffset) {
        offset = mFirstDataOffset;
 }

 off64_t pageOffset;
 status_t err = findNextPage(offset, &pageOffset);

 if (err != OK) {
 return err;
 }

    findPrevGranulePosition(pageOffset, &mPrevGranulePosition);

    mOffset = pageOffset;

    mCurrentPageSize = 0;
    mFirstPacketInPage = true;
    mCurrentPageSamples = 0;
    mCurrentPage.mNumSegments = 0;
    mCurrentPage.mPrevPacketSize = -1;
    mNextLaceIndex = 0;


 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXNodeInstance::useBuffer(
        OMX_U32 portIndex, const sp<IMemory> &params,
        OMX::buffer_id *buffer, OMX_U32 allottedSize) {
 if (params == NULL || buffer == NULL) {
        ALOGE("b/25884056");
 return BAD_VALUE;
 }

 Mutex::Autolock autoLock(mLock);
 if (allottedSize > params->size() || portIndex >= NELEM(mNumPortBuffers)) {
 return BAD_VALUE;
 }

 BufferMeta *buffer_meta;
 bool useBackup = mMetadataType[portIndex] != kMetadataBufferTypeInvalid;
    OMX_U8 *data = static_cast<OMX_U8 *>(params->pointer());
 if (useBackup) {
        data = new (std::nothrow) OMX_U8[allottedSize];
 if (data == NULL) {
 return NO_MEMORY;
 }
        memset(data, 0, allottedSize);

 if (allottedSize != params->size()) {
            CLOG_ERROR(useBuffer, BAD_VALUE, SIMPLE_BUFFER(portIndex, (size_t)allottedSize, data));
 delete[] data;
 return BAD_VALUE;
 }

        buffer_meta = new BufferMeta(
                params, portIndex, false /* copyToOmx */, false /* copyFromOmx */, data);
 } else {
        buffer_meta = new BufferMeta(
                params, portIndex, false /* copyFromOmx */, false /* copyToOmx */, NULL);
 }

    OMX_BUFFERHEADERTYPE *header;

    OMX_ERRORTYPE err = OMX_UseBuffer(
            mHandle, &header, portIndex, buffer_meta,
            allottedSize, data);

 if (err != OMX_ErrorNone) {
        CLOG_ERROR(useBuffer, err, SIMPLE_BUFFER(
                portIndex, (size_t)allottedSize, data));

 delete buffer_meta;
        buffer_meta = NULL;

 *buffer = 0;

 return StatusFromOMXError(err);
 }

    CHECK_EQ(header->pAppPrivate, buffer_meta);

 *buffer = makeBufferID(header);

    addActiveBuffer(portIndex, *buffer);

    sp<GraphicBufferSource> bufferSource(getGraphicBufferSource());
 if (bufferSource != NULL && portIndex == kPortIndexInput) {
        bufferSource->addCodecBuffer(header);
 }

    CLOG_BUFFER(useBuffer, NEW_BUFFER_FMT(
 *buffer, portIndex, "%u(%zu)@%p", allottedSize, params->size(), params->pointer()));
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void usage(const char *name) {
  printf("Usage: %s <command> [options]\n", name);
  printf("Commands:\n");
 for (size_t i = 0; i < ARRAY_SIZE(commands); ++i)
    printf("  %s\n", commands[i].name);
  printf("For detailed help on a command, run '%s help <command>'.\n", name);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<IMediaSource> OggExtractor::getTrack(size_t index) {
 if (index >= 1) {
 return NULL;
 }

 return new OggSource(this);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ATSParser::Program::switchPIDs(const Vector<StreamInfo> &infos) {
 bool success = false;

 if (mStreams.size() == infos.size()) {
 size_t i;
 KeyedVector<int32_t, Vector<int32_t> > oldType2PIDs, newType2PIDs;
 for (i = 0; i < mStreams.size(); ++i) {
 ssize_t index = oldType2PIDs.indexOfKey(mStreams[i]->type());
 if (index < 0) {
                oldType2PIDs.add(mStreams[i]->type(), Vector<int32_t>());
 }
            oldType2PIDs.editValueFor(mStreams[i]->type()).push_back(mStreams[i]->pid());
 }
 for (i = 0; i < infos.size(); ++i) {
 ssize_t index = newType2PIDs.indexOfKey(infos[i].mType);
 if (index < 0) {
                newType2PIDs.add(infos[i].mType, Vector<int32_t>());
 }
            newType2PIDs.editValueFor(infos[i].mType).push_back(infos[i].mPID);
 }

 if (oldType2PIDs.size() == newType2PIDs.size()) {
            success = true;
 for (i = 0; i < oldType2PIDs.size(); ++i) {
 if (oldType2PIDs.keyAt(i) != newType2PIDs.keyAt(i)
 || oldType2PIDs[i].size() != newType2PIDs[i].size()) {
                     success = false;
 break;
 }
 }
 }

 if (success) {
 KeyedVector<int32_t, sp<Stream> > temp;
 for (i = 0; i < mStreams.size(); ++i) {
                 temp.add(mStreams.keyAt(i), mStreams.editValueAt(i));
 }

            mStreams.clear();
 for (i = 0; i < temp.size(); ++i) {
 ssize_t index = newType2PIDs.indexOfKey(temp[i]->type());
 if (index < 0) {
 return false;
 }
 Vector<int32_t> &newPIDs = newType2PIDs.editValueAt(index);
 if (newPIDs.isEmpty()) {
 return false;
 }

 Vector<int32_t>::iterator it = newPIDs.begin();

                temp.editValueAt(i)->setPID(*it);
                mStreams.add(temp[i]->pid(), temp.editValueAt(i));

                newPIDs.erase(it);
 }
 }
 }
 return success;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static BOOLEAN btif_hl_proc_dch_open_cfm(tBTA_HL *p_data)

{
 btif_hl_mdl_cb_t *p_dcb;
 btif_hl_pending_chan_cb_t *p_pcb;
    UINT8                    app_idx, mcl_idx, mdl_idx, mdep_cfg_idx;
    BOOLEAN                  status = FALSE;
    BOOLEAN                  close_dch = FALSE;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

    btif_hl_find_app_idx_using_mdepId(p_data->dch_open_cfm.local_mdep_id,&app_idx);

 if (btif_hl_find_mcl_idx_using_app_idx(p_data->dch_open_cfm.mcl_handle, app_idx, &mcl_idx ))
 {
        BTIF_HL_GET_APP_CB_PTR(app_idx);
        BTIF_HL_GET_MCL_CB_PTR(app_idx, mcl_idx);
        p_pcb = BTIF_HL_GET_PCB_PTR(app_idx, mcl_idx);

 if (btif_hl_find_avail_mdl_idx(app_idx, mcl_idx, &mdl_idx))
 {
            p_dcb = BTIF_HL_GET_MDL_CB_PTR(app_idx, mcl_idx, mdl_idx);

 if (btif_hl_find_mdep_cfg_idx(app_idx, p_data->dch_open_cfm.local_mdep_id, &mdep_cfg_idx))
 {
                p_dcb->in_use               = TRUE;
                p_dcb->mdl_handle           = p_data->dch_open_cfm.mdl_handle;
                p_dcb->local_mdep_cfg_idx   = mdep_cfg_idx;
                p_dcb->local_mdep_id        = p_data->dch_open_cfm.local_mdep_id;
                p_dcb->mdl_id               = p_data->dch_open_cfm.mdl_id;
                p_dcb->dch_mode             = p_data->dch_open_cfm.dch_mode;
                p_dcb->is_the_first_reliable= p_data->dch_open_cfm.first_reliable;
                p_dcb->mtu                  = p_data->dch_open_cfm.mtu;
                p_dcb->channel_id           = p_pcb->channel_id;

                BTIF_TRACE_DEBUG("app_idx=%d mcl_idx=%d mdl_idx=%d",  app_idx, mcl_idx, mdl_idx  );
                btif_hl_send_setup_connecting_cb(app_idx, mcl_idx);
 if (btif_hl_create_socket(app_idx, mcl_idx, mdl_idx))
 {
                    status = TRUE;
                    BTIF_TRACE_DEBUG("app_idx=%d mcl_idx=%d mdl_idx=%d p_dcb->channel_id=0x%08x",
                                      app_idx, mcl_idx, mdl_idx, p_dcb->channel_id);
                    btif_hl_clean_pcb(p_pcb);
 }
 else
 {
                    BTIF_TRACE_ERROR("Unable to create socket");
                    close_dch = TRUE;
 }
 }
 else
 {
                BTIF_TRACE_ERROR("INVALID_LOCAL_MDEP_ID mdep_id=%d",p_data->dch_open_cfm.local_mdep_id);
                close_dch = TRUE;
 }

 if (close_dch)
 {
                btif_hl_clean_mdl_cb(p_dcb);
                BTA_HlDchClose(p_data->dch_open_cfm.mdl_handle);
 }
 }
 }

 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t BufferQueueConsumer::setDefaultMaxBufferCount(int bufferCount) {
    ATRACE_CALL();
 Mutex::Autolock lock(mCore->mMutex);
 return mCore->setDefaultMaxBufferCountLocked(bufferCount);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void png_warning(png_const_structrp png_ptr, png_const_charp msg)
{
   fprintf(stderr, "validation: %s\n", msg);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: make_size(png_store* PNG_CONST ps, png_byte PNG_CONST colour_type, int bdlo,
    int PNG_CONST bdhi)
 {
    for (; bdlo <= bdhi; ++bdlo)
    {
      png_uint_32 width;

 for (width = 1; width <= 16; ++width)
 {
         png_uint_32 height;

 for (height = 1; height <= 16; ++height)
 {
 /* The four combinations of DIY interlace and interlace or not -
             * no interlace + DIY should be identical to no interlace with
             * libpng doing it.
             */
            make_size_image(ps, colour_type, DEPTH(bdlo), PNG_INTERLACE_NONE,
               width, height, 0);
            make_size_image(ps, colour_type, DEPTH(bdlo), PNG_INTERLACE_NONE,
               width, height, 1);

 #        ifdef PNG_WRITE_INTERLACING_SUPPORTED
             make_size_image(ps, colour_type, DEPTH(bdlo), PNG_INTERLACE_ADAM7,
                width, height, 0);
             make_size_image(ps, colour_type, DEPTH(bdlo), PNG_INTERLACE_ADAM7,
                width, height, 1);
 #        endif
 }
 }
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_parse_user_data_registered_itu_t_t35(codec_t *ps_codec,
                                                           UWORD32 u4_payload_size)
{
 parse_ctxt_t *ps_parse = &ps_codec->s_parse;
 bitstrm_t *ps_bitstrm = &ps_parse->s_bitstrm;
    UWORD32 value;
 user_data_registered_itu_t_t35_t *ps_user_data_registered_itu_t_t35;
    UWORD32 i;
    UWORD32 j = 0;

    ps_parse->s_sei_params.i1_user_data_registered_present_flag = 1;
    ps_user_data_registered_itu_t_t35 =
 &ps_parse->s_sei_params.as_user_data_registered_itu_t_t35[ps_parse->s_sei_params.i4_sei_user_data_cnt];
    ps_parse->s_sei_params.i4_sei_user_data_cnt++;

    ps_user_data_registered_itu_t_t35->i4_payload_size = u4_payload_size;

 if(u4_payload_size > MAX_USERDATA_PAYLOAD)
 {
        u4_payload_size = MAX_USERDATA_PAYLOAD;
 }

    ps_user_data_registered_itu_t_t35->i4_valid_payload_size = u4_payload_size;

    BITS_PARSE("itu_t_t35_country_code", value, ps_bitstrm, 8);
    ps_user_data_registered_itu_t_t35->u1_itu_t_t35_country_code = value;

 if(0xFF != ps_user_data_registered_itu_t_t35->u1_itu_t_t35_country_code)
 {
        i = 1;
 }
 else
 {
        BITS_PARSE("itu_t_t35_country_code_extension_byte", value, ps_bitstrm,
 8);
        ps_user_data_registered_itu_t_t35->u1_itu_t_t35_country_code_extension_byte =
                        value;

        i = 2;
 }

 do
 {
        BITS_PARSE("itu_t_t35_payload_byte", value, ps_bitstrm, 8);
        ps_user_data_registered_itu_t_t35->u1_itu_t_t35_payload_byte[j++] =
                        value;

        i++;
 }while(i < u4_payload_size);

 return (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::allocate_output_buffer(
        OMX_IN OMX_HANDLETYPE            hComp,
        OMX_INOUT OMX_BUFFERHEADERTYPE** bufferHdr,
        OMX_IN OMX_U32                   port,
        OMX_IN OMX_PTR                   appData,
        OMX_IN OMX_U32                   bytes)
{
 (void)hComp, (void)port;
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
    OMX_BUFFERHEADERTYPE       *bufHdr= NULL; // buffer header
 unsigned                         i= 0; // Temporary counter
#ifdef _MSM8974_
 int align_size;
#endif
    DEBUG_PRINT_HIGH("allocate_output_buffer()for %u bytes", (unsigned int)bytes);
 if (!m_out_mem_ptr) {
 int nBufHdrSize        = 0;
        DEBUG_PRINT_HIGH("%s: size = %u, actual cnt %u", __FUNCTION__,
 (unsigned int)m_sOutPortDef.nBufferSize, (unsigned int)m_sOutPortDef.nBufferCountActual);
        nBufHdrSize        = m_sOutPortDef.nBufferCountActual * sizeof(OMX_BUFFERHEADERTYPE);

 /*
         * Memory for output side involves the following:
         * 1. Array of Buffer Headers
         * 2. Bitmask array to hold the buffer allocation details
         * In order to minimize the memory management entire allocation
         * is done in one step.
         */
        m_out_mem_ptr = (OMX_BUFFERHEADERTYPE  *)calloc(nBufHdrSize,1);

#ifdef USE_ION
        m_pOutput_ion = (struct venc_ion *) calloc(sizeof (struct venc_ion), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_ion == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_ion");
 return OMX_ErrorInsufficientResources;
 }
#endif
        m_pOutput_pmem = (struct pmem *) calloc(sizeof(struct pmem), m_sOutPortDef.nBufferCountActual);
 if (m_pOutput_pmem == NULL) {
            DEBUG_PRINT_ERROR("ERROR: calloc() Failed for m_pOutput_pmem");
 return OMX_ErrorInsufficientResources;
 }
 if (m_out_mem_ptr && m_pOutput_pmem) {
            bufHdr          =  m_out_mem_ptr;

 for (i=0; i < m_sOutPortDef.nBufferCountActual ; i++) {
                bufHdr->nSize              = sizeof(OMX_BUFFERHEADERTYPE);
                bufHdr->nVersion.nVersion  = OMX_SPEC_VERSION;
                bufHdr->nAllocLen          = bytes;
                bufHdr->nFilledLen         = 0;
                bufHdr->pAppPrivate        = appData;
                bufHdr->nOutputPortIndex   = PORT_INDEX_OUT;
                bufHdr->pOutputPortPrivate = (OMX_PTR)&m_pOutput_pmem[i];
                bufHdr->pBuffer            = NULL;
                bufHdr++;
                m_pOutput_pmem[i].fd = -1;
#ifdef USE_ION
                m_pOutput_ion[i].ion_device_fd =-1;
                m_pOutput_ion[i].fd_ion_data.fd=-1;
                m_pOutput_ion[i].ion_alloc_data.handle = 0;
#endif
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: calloc() failed for m_out_mem_ptr/m_pOutput_pmem");
            eRet = OMX_ErrorInsufficientResources;
 }
 }

    DEBUG_PRINT_HIGH("actual cnt = %u", (unsigned int)m_sOutPortDef.nBufferCountActual);
 for (i=0; i< m_sOutPortDef.nBufferCountActual; i++) {
 if (BITMASK_ABSENT(&m_out_bm_count,i)) {
            DEBUG_PRINT_LOW("Found a Free Output Buffer %d",i);
 break;
 }
 }
 if (eRet == OMX_ErrorNone) {
 if (i < m_sOutPortDef.nBufferCountActual) {
#ifdef USE_ION
#ifdef _MSM8974_
            align_size = ((m_sOutPortDef.nBufferSize + 4095)/4096) * 4096;
            m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(align_size,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data, ION_FLAG_CACHED);
#else
            m_pOutput_ion[i].ion_device_fd = alloc_map_ion_memory(m_sOutPortDef.nBufferSize,
 &m_pOutput_ion[i].ion_alloc_data,
 &m_pOutput_ion[i].fd_ion_data,ION_FLAG_CACHED);
#endif
 if (m_pOutput_ion[i].ion_device_fd < 0) {
                DEBUG_PRINT_ERROR("ERROR:ION device open() Failed");
 return OMX_ErrorInsufficientResources;
 }

            m_pOutput_pmem[i].fd = m_pOutput_ion[i].fd_ion_data.fd;
#else
            m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 if (m_pOutput_pmem[i].fd == 0) {
                m_pOutput_pmem[i].fd = open (MEM_DEVICE,O_RDWR);
 }

 if (m_pOutput_pmem[i].fd < 0) {
                DEBUG_PRINT_ERROR("ERROR: /dev/pmem_adsp open() failed");
 return OMX_ErrorInsufficientResources;
 }
#endif
            m_pOutput_pmem[i].size = m_sOutPortDef.nBufferSize;
            m_pOutput_pmem[i].offset = 0;

            m_pOutput_pmem[i].buffer = (OMX_U8 *)SECURE_BUFPTR;
 if(!secure_session) {
#ifdef _MSM8974_
                m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                    align_size,PROT_READ|PROT_WRITE,
                    MAP_SHARED,m_pOutput_pmem[i].fd,0);
#else
                m_pOutput_pmem[i].buffer = (unsigned char *)mmap(NULL,
                    m_pOutput_pmem[i].size,PROT_READ|PROT_WRITE,
                    MAP_SHARED,m_pOutput_pmem[i].fd,0);
#endif
 if (m_pOutput_pmem[i].buffer == MAP_FAILED) {
                    DEBUG_PRINT_ERROR("ERROR: MMAP_FAILED in o/p alloc buffer");
                close (m_pOutput_pmem[i].fd);
#ifdef USE_ION
                free_ion_memory(&m_pOutput_ion[i]);
#endif
 return OMX_ErrorInsufficientResources;
 }
 }
 else {
                m_pOutput_pmem[i].buffer = malloc(sizeof(OMX_U32) + sizeof(native_handle_t*));
 native_handle_t *handle = native_handle_create(1, 0);
                handle->data[0] = m_pOutput_pmem[i].fd;
 char *data = (char*) m_pOutput_pmem[i].buffer;
                OMX_U32 type = 1;
                memcpy(data, &type, sizeof(OMX_U32));
                memcpy(data + sizeof(OMX_U32), &handle, sizeof(native_handle_t*));
 }

 *bufferHdr = (m_out_mem_ptr + i );
 (*bufferHdr)->pBuffer = (OMX_U8 *)m_pOutput_pmem[i].buffer;
 (*bufferHdr)->pAppPrivate = appData;

            BITMASK_SET(&m_out_bm_count,i);

 if (dev_use_buf(&m_pOutput_pmem[i],PORT_INDEX_OUT,i) != true) {
                DEBUG_PRINT_ERROR("ERROR: dev_use_buf FAILED for o/p buf");
 return OMX_ErrorInsufficientResources;
 }
 } else {
            DEBUG_PRINT_ERROR("ERROR: All o/p buffers are allocated, invalid allocate buf call"
 "for index [%d] actual: %u", i, (unsigned int)m_sOutPortDef.nBufferCountActual);
 }
 }

 return eRet;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t SampleIterator::findChunkRange(uint32_t sampleIndex) {
    CHECK(sampleIndex >= mFirstChunkSampleIndex);

 while (sampleIndex >= mStopChunkSampleIndex) {
 if (mSampleToChunkIndex == mTable->mNumSampleToChunkOffsets) {
 return ERROR_OUT_OF_RANGE;
 }

        mFirstChunkSampleIndex = mStopChunkSampleIndex;

 const SampleTable::SampleToChunkEntry *entry =
 &mTable->mSampleToChunkEntries[mSampleToChunkIndex];

        mFirstChunk = entry->startChunk;
        mSamplesPerChunk = entry->samplesPerChunk;
        mChunkDesc = entry->chunkDesc;

 if (mSampleToChunkIndex + 1 < mTable->mNumSampleToChunkOffsets) {
            mStopChunk = entry[1].startChunk;

            mStopChunkSampleIndex =
                mFirstChunkSampleIndex
 + (mStopChunk - mFirstChunk) * mSamplesPerChunk;
 } else {
            mStopChunk = 0xffffffff;
            mStopChunkSampleIndex = 0xffffffff;
 }

 ++mSampleToChunkIndex;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayerService::AudioOutput::setAuxEffectSendLevel(float level)
{
    ALOGV("setAuxEffectSendLevel(%f)", level);
 Mutex::Autolock lock(mLock);
    mSendLevel = level;
 if (mTrack != 0) {
 return mTrack->setAuxEffectSendLevel(level);
 }
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlParse3986PathAbEmpty(xmlURIPtr uri, const char **str)
{
 const char *cur;
 int ret;

    cur = *str;

 while (*cur == '/') {
        cur++;
	ret = xmlParse3986Segment(&cur, 0, 1);
 if (ret != 0) return(ret);
 }
 if (uri != NULL) {
 if (uri->path != NULL) xmlFree(uri->path);
 if (*str != cur) {
 if (uri->cleanup & 2)
                uri->path = STRNDUP(*str, cur - *str);
 else
                uri->path = xmlURIUnescapeString(*str, cur - *str, NULL);
 } else {
            uri->path = NULL;
 }
 }
 *str = cur;
 return (0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t GraphicBuffer::unflatten(
 void const*& buffer, size_t& size, int const*& fds, size_t& count) {
 if (size < 8*sizeof(int)) return NO_MEMORY;

 int const* buf = static_cast<int const*>(buffer);
 if (buf[0] != 'GBFR') return BAD_TYPE;


     const size_t numFds  = buf[8];
     const size_t numInts = buf[9];
 
     const size_t sizeNeeded = (10 + numInts) * sizeof(int);
     if (size < sizeNeeded) return NO_MEMORY;
 
    size_t fdCountNeeded = 0;
     if (count < fdCountNeeded) return NO_MEMORY;
 
     if (handle) {
        free_handle();
 }

 if (numFds || numInts) {
        width  = buf[1];
        height = buf[2];
        stride = buf[3];

         format = buf[4];
         usage  = buf[5];
         native_handle* h = native_handle_create(numFds, numInts);
         memcpy(h->data,          fds,     numFds*sizeof(int));
         memcpy(h->data + numFds, &buf[10], numInts*sizeof(int));
         handle = h;
 } else {
        width = height = stride = format = usage = 0;
        handle = NULL;
 }

    mId = static_cast<uint64_t>(buf[6]) << 32;
    mId |= static_cast<uint32_t>(buf[7]);

    mOwner = ownHandle;

 if (handle != 0) {
 status_t err = mBufferMapper.registerBuffer(handle);
 if (err != NO_ERROR) {
            width = height = stride = format = usage = 0;
            handle = NULL;
            ALOGE("unflatten: registerBuffer failed: %s (%d)",
                    strerror(-err), err);
 return err;
 }
 }

    buffer = reinterpret_cast<void const*>(static_cast<int const*>(buffer) + sizeNeeded);
    size -= sizeNeeded;
    fds += numFds;
    count -= numFds;

 return NO_ERROR;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ssize_t NuPlayer::NuPlayerStreamListener::read(
 void *data, size_t size, sp<AMessage> *extra) {
    CHECK_GT(size, 0u);

    extra->clear();

 Mutex::Autolock autoLock(mLock);

 if (mEOS) {
 return 0;
 }

 if (mQueue.empty()) {
        mSendDataNotification = true;

 return -EWOULDBLOCK;
 }

 QueueEntry *entry = &*mQueue.begin();

 if (entry->mIsCommand) {
 switch (entry->mCommand) {
 case EOS:
 {
                mQueue.erase(mQueue.begin());
                entry = NULL;

                mEOS = true;
 return 0;
 }

 case DISCONTINUITY:
 {
 *extra = entry->mExtra;

                mQueue.erase(mQueue.begin());
                entry = NULL;

 return INFO_DISCONTINUITY;
 }

 default:
                TRESPASS();
 break;
 }
 }

 size_t copy = entry->mSize;
 if (copy > size) {

         copy = size;
     }
 
     memcpy(data,
           (const uint8_t *)mBuffers.editItemAt(entry->mIndex)->pointer()
             + entry->mOffset,
            copy);
 
    entry->mOffset += copy;
    entry->mSize -= copy;

 if (entry->mSize == 0) {
        mSource->onBufferAvailable(entry->mIndex);
        mQueue.erase(mQueue.begin());
        entry = NULL;
 }

 return copy;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static WORD32 ihevcd_parse_vui_parameters(bitstrm_t *ps_bitstrm,
 vui_t *ps_vui,
                                          WORD32 sps_max_sub_layers_minus1)
{
    WORD32 ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    UWORD16 u2_sar_width = 0;
    UWORD16 u2_sar_height = 0;

    BITS_PARSE("aspect_ratio_info_present_flag", ps_vui->u1_aspect_ratio_info_present_flag, ps_bitstrm, 1);

    ps_vui->u1_aspect_ratio_idc = SAR_UNUSED;
    u2_sar_width = 0;
    u2_sar_height = 0;
 if(ps_vui->u1_aspect_ratio_info_present_flag)
 {
        BITS_PARSE("aspect_ratio_idc", ps_vui->u1_aspect_ratio_idc, ps_bitstrm, 8);
 switch(ps_vui->u1_aspect_ratio_idc)
 {
 case SAR_1_1:
                u2_sar_width = 1;
                u2_sar_height = 1;
 break;
 case SAR_12_11:
                u2_sar_width = 12;
                u2_sar_height = 11;
 break;
 case SAR_10_11:
                u2_sar_width = 10;
                u2_sar_height = 11;
 break;
 case SAR_16_11:
                u2_sar_width = 16;
                u2_sar_height = 11;
 break;
 case SAR_40_33:
                u2_sar_width = 40;
                u2_sar_height = 33;
 break;
 case SAR_24_11:
                u2_sar_width = 24;
                u2_sar_height = 11;
 break;
 case SAR_20_11:
                u2_sar_width = 20;
                u2_sar_height = 11;
 break;
 case SAR_32_11:
                u2_sar_width = 32;
                u2_sar_height = 11;
 break;
 case SAR_80_33:
                u2_sar_width = 80;
                u2_sar_height = 33;
 break;
 case SAR_18_11:
                u2_sar_width = 18;
                u2_sar_height = 11;
 break;
 case SAR_15_11:
                u2_sar_width = 15;
                u2_sar_height = 11;
 break;
 case SAR_64_33:
                u2_sar_width = 64;
                u2_sar_height = 33;
 break;
 case SAR_160_99:
                u2_sar_width = 160;
                u2_sar_height = 99;
 break;
 case SAR_4_3:
                u2_sar_width = 4;
                u2_sar_height = 3;
 break;
 case SAR_3_2:
                u2_sar_width = 3;
                u2_sar_height = 2;
 break;
 case SAR_2_1:
                u2_sar_width = 2;
                u2_sar_height = 1;
 break;
 case EXTENDED_SAR:
                BITS_PARSE("sar_width", u2_sar_width, ps_bitstrm, 16);
                BITS_PARSE("sar_height", u2_sar_height, ps_bitstrm, 16);
 break;
 default:
                u2_sar_width = 0;
                u2_sar_height = 0;
 break;
 }
 }

    ps_vui->u2_sar_width    = u2_sar_width;
    ps_vui->u2_sar_height   = u2_sar_height;

    BITS_PARSE("overscan_info_present_flag", ps_vui->u1_overscan_info_present_flag, ps_bitstrm, 1);
    ps_vui->u1_overscan_appropriate_flag = 0;
 if(ps_vui->u1_overscan_info_present_flag)
        BITS_PARSE("overscan_appropriate_flag", ps_vui->u1_overscan_appropriate_flag, ps_bitstrm, 1);

    BITS_PARSE("video_signal_type_present_flag", ps_vui->u1_video_signal_type_present_flag, ps_bitstrm, 1);
    ps_vui->u1_video_format = VID_FMT_UNSPECIFIED;
    ps_vui->u1_video_full_range_flag = 0;
    ps_vui->u1_colour_description_present_flag = 0;
    ps_vui->u1_colour_primaries = 2;
    ps_vui->u1_transfer_characteristics = 2;
    ps_vui->u1_matrix_coefficients = 2;

 if(ps_vui->u1_video_signal_type_present_flag)
 {
        BITS_PARSE("video_format", ps_vui->u1_video_format, ps_bitstrm, 3);
        BITS_PARSE("video_full_range_flag", ps_vui->u1_video_full_range_flag, ps_bitstrm, 1);
        BITS_PARSE("colour_description_present_flag", ps_vui->u1_colour_description_present_flag, ps_bitstrm, 1);
 if(ps_vui->u1_colour_description_present_flag)
 {
            BITS_PARSE("colour_primaries", ps_vui->u1_colour_primaries, ps_bitstrm, 8);
            BITS_PARSE("transfer_characteristics", ps_vui->u1_transfer_characteristics, ps_bitstrm, 8);
            BITS_PARSE("matrix_coeffs", ps_vui->u1_matrix_coefficients, ps_bitstrm, 8);
 }
 }

    BITS_PARSE("chroma_loc_info_present_flag", ps_vui->u1_chroma_loc_info_present_flag, ps_bitstrm, 1);
    ps_vui->u1_chroma_sample_loc_type_top_field = 0;
    ps_vui->u1_chroma_sample_loc_type_bottom_field = 0;
 if(ps_vui->u1_chroma_loc_info_present_flag)
 {
        UEV_PARSE("chroma_sample_loc_type_top_field", ps_vui->u1_chroma_sample_loc_type_top_field, ps_bitstrm);
        UEV_PARSE("chroma_sample_loc_type_bottom_field", ps_vui->u1_chroma_sample_loc_type_bottom_field, ps_bitstrm);
 }

    BITS_PARSE("neutral_chroma_indication_flag", ps_vui->u1_neutral_chroma_indication_flag, ps_bitstrm, 1);
    BITS_PARSE("field_seq_flag", ps_vui->u1_field_seq_flag, ps_bitstrm, 1);
    BITS_PARSE("frame_field_info_present_flag", ps_vui->u1_frame_field_info_present_flag, ps_bitstrm, 1);
    BITS_PARSE("default_display_window_flag", ps_vui->u1_default_display_window_flag, ps_bitstrm, 1);
    ps_vui->u4_def_disp_win_left_offset = 0;
    ps_vui->u4_def_disp_win_right_offset = 0;
    ps_vui->u4_def_disp_win_top_offset = 0;
    ps_vui->u4_def_disp_win_bottom_offset = 0;
 if(ps_vui->u1_default_display_window_flag)
 {
        UEV_PARSE("def_disp_win_left_offset", ps_vui->u4_def_disp_win_left_offset, ps_bitstrm);
        UEV_PARSE("def_disp_win_right_offset", ps_vui->u4_def_disp_win_right_offset, ps_bitstrm);
        UEV_PARSE("def_disp_win_top_offset", ps_vui->u4_def_disp_win_top_offset, ps_bitstrm);
        UEV_PARSE("def_disp_win_bottom_offset", ps_vui->u4_def_disp_win_bottom_offset, ps_bitstrm);
 }

    BITS_PARSE("vui_timing_info_present_flag", ps_vui->u1_vui_timing_info_present_flag, ps_bitstrm, 1);
 if(ps_vui->u1_vui_timing_info_present_flag)
 {
        BITS_PARSE("vui_num_units_in_tick", ps_vui->u4_vui_num_units_in_tick, ps_bitstrm, 32);
        BITS_PARSE("vui_time_scale", ps_vui->u4_vui_time_scale, ps_bitstrm, 32);
        BITS_PARSE("vui_poc_proportional_to_timing_flag", ps_vui->u1_poc_proportional_to_timing_flag, ps_bitstrm, 1);
 if(ps_vui->u1_poc_proportional_to_timing_flag)
            UEV_PARSE("vui_num_ticks_poc_diff_one_minus1", ps_vui->u1_num_ticks_poc_diff_one_minus1, ps_bitstrm);

        BITS_PARSE("vui_hrd_parameters_present_flag", ps_vui->u1_vui_hrd_parameters_present_flag, ps_bitstrm, 1);
 if(ps_vui->u1_vui_hrd_parameters_present_flag)
 {
            ret = ihevcd_parse_hrd_parameters(ps_bitstrm, &ps_vui->s_vui_hrd_parameters, 1, sps_max_sub_layers_minus1);
            RETURN_IF((ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS), ret);
 }
 }

    BITS_PARSE("bitstream_restriction_flag", ps_vui->u1_bitstream_restriction_flag, ps_bitstrm, 1);
    ps_vui->u1_tiles_fixed_structure_flag = 0;
    ps_vui->u1_motion_vectors_over_pic_boundaries_flag = 1;
    ps_vui->u1_restricted_ref_pic_lists_flag = 0;
    ps_vui->u4_min_spatial_segmentation_idc = 0;
    ps_vui->u1_max_bytes_per_pic_denom = 2;
    ps_vui->u1_max_bits_per_mincu_denom = 1;
    ps_vui->u1_log2_max_mv_length_horizontal = 15;
    ps_vui->u1_log2_max_mv_length_vertical = 15;
 if(ps_vui->u1_bitstream_restriction_flag)
 {
        BITS_PARSE("tiles_fixed_structure_flag", ps_vui->u1_tiles_fixed_structure_flag, ps_bitstrm, 1);
        BITS_PARSE("motion_vectors_over_pic_boundaries_flag", ps_vui->u1_motion_vectors_over_pic_boundaries_flag, ps_bitstrm, 1);
        BITS_PARSE("restricted_ref_pic_lists_flag", ps_vui->u1_restricted_ref_pic_lists_flag, ps_bitstrm, 1);

        UEV_PARSE("min_spatial_segmentation_idc", ps_vui->u4_min_spatial_segmentation_idc, ps_bitstrm);
        UEV_PARSE("max_bytes_per_pic_denom", ps_vui->u1_max_bytes_per_pic_denom, ps_bitstrm);
        UEV_PARSE("max_bits_per_min_cu_denom", ps_vui->u1_max_bits_per_mincu_denom, ps_bitstrm);
        UEV_PARSE("log2_max_mv_length_horizontal", ps_vui->u1_log2_max_mv_length_horizontal, ps_bitstrm);
        UEV_PARSE("log2_max_mv_length_vertical", ps_vui->u1_log2_max_mv_length_vertical, ps_bitstrm);
 }

 return ret;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static int handle_statfs(struct fuse* fuse, struct fuse_handler* handler,
 const struct fuse_in_header* hdr)
{
 char path[PATH_MAX];
 struct statfs stat;
 struct fuse_statfs_out out;
 int res;

    pthread_mutex_lock(&fuse->global->lock);
    TRACE("[%d] STATFS\n", handler->token);
    res = get_node_path_locked(&fuse->global->root, path, sizeof(path));
    pthread_mutex_unlock(&fuse->global->lock);
 if (res < 0) {
 return -ENOENT;
 }
 if (statfs(fuse->global->root.name, &stat) < 0) {
 return -errno;
 }
    memset(&out, 0, sizeof(out));
    out.st.blocks = stat.f_blocks;
    out.st.bfree = stat.f_bfree;
    out.st.bavail = stat.f_bavail;
    out.st.files = stat.f_files;
    out.st.ffree = stat.f_ffree;
    out.st.bsize = stat.f_bsize;
    out.st.namelen = stat.f_namelen;
    out.st.frsize = stat.f_frsize;
    fuse_reply(fuse, hdr->unique, &out, sizeof(out));
 return NO_STATUS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_searchrange()
{
    DEBUG_PRINT_LOW("venc_set_searchrange");
 struct v4l2_control control;
 struct v4l2_ext_control ctrl[6];
 struct v4l2_ext_controls controls;
 int rc;

 if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_MPEG4) {
        ctrl[0].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_X_RANGE;
        ctrl[0].value = 16;
        ctrl[1].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_Y_RANGE;
        ctrl[1].value = 4;
        ctrl[2].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_X_RANGE;
        ctrl[2].value = 16;
        ctrl[3].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_Y_RANGE;
        ctrl[3].value = 4;
        ctrl[4].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_X_RANGE;
        ctrl[4].value = 12;
        ctrl[5].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_Y_RANGE;
        ctrl[5].value = 4;
 } else if ((m_sVenc_cfg.codectype == V4L2_PIX_FMT_H264) ||
 (m_sVenc_cfg.codectype == V4L2_PIX_FMT_VP8)) {
        ctrl[0].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_X_RANGE;
        ctrl[0].value = 16;
        ctrl[1].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_Y_RANGE;
        ctrl[1].value = 4;
        ctrl[2].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_X_RANGE;
        ctrl[2].value = 16;
        ctrl[3].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_Y_RANGE;
        ctrl[3].value = 4;
        ctrl[4].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_X_RANGE;
        ctrl[4].value = 12;
        ctrl[5].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_Y_RANGE;
        ctrl[5].value = 4;
 } else if (m_sVenc_cfg.codectype == V4L2_PIX_FMT_H263) {
        ctrl[0].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_X_RANGE;
        ctrl[0].value = 4;
        ctrl[1].id = V4L2_CID_MPEG_VIDC_VIDEO_IFRAME_Y_RANGE;
        ctrl[1].value = 4;
        ctrl[2].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_X_RANGE;
        ctrl[2].value = 4;
        ctrl[3].id = V4L2_CID_MPEG_VIDC_VIDEO_PFRAME_Y_RANGE;
        ctrl[3].value = 4;
        ctrl[4].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_X_RANGE;
        ctrl[4].value = 4;
        ctrl[5].id = V4L2_CID_MPEG_VIDC_VIDEO_BFRAME_Y_RANGE;
        ctrl[5].value = 4;
 } else {
        DEBUG_PRINT_ERROR("Invalid codec type");
 return false;
 }
    controls.count = 6;
    controls.ctrl_class = V4L2_CTRL_CLASS_MPEG;
    controls.controls = ctrl;

    DEBUG_PRINT_LOW(" Calling IOCTL set control for"
 "id=%x, val=%d id=%x, val=%d"
 "id=%x, val=%d id=%x, val=%d"
 "id=%x, val=%d id=%x, val=%d",
        controls.controls[0].id, controls.controls[0].value,
        controls.controls[1].id, controls.controls[1].value,
        controls.controls[2].id, controls.controls[2].value,
        controls.controls[3].id, controls.controls[3].value,
        controls.controls[4].id, controls.controls[4].value,
        controls.controls[5].id, controls.controls[5].value);

    rc = ioctl(m_nDriver_fd, VIDIOC_S_EXT_CTRLS, &controls);
 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set search range %d", rc);
 return false;
 }
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_hl_start_cch_timer(UINT8 app_idx, UINT8 mcl_idx)
{
 btif_hl_mcl_cb_t *p_mcb = BTIF_HL_GET_MCL_CB_PTR(app_idx, mcl_idx);
    BTIF_TRACE_DEBUG("%s app_idx=%d, mcl_idx=%d  timer_active=%d timer_in_use=%d",
                      __FUNCTION__,app_idx, mcl_idx,
                      p_mcb->cch_timer_active, p_mcb->cch_timer.in_use);

    p_mcb->cch_timer_active = TRUE;
 if (!p_mcb->cch_timer.in_use)
 {
        BTIF_TRACE_DEBUG("Start CCH timer ");
        memset(&p_mcb->cch_timer, 0, sizeof(TIMER_LIST_ENT));
        p_mcb->cch_timer.param = (UINT32)btif_hl_tmr_hdlr;
        btu_start_timer(&p_mcb->cch_timer, BTU_TTYPE_USER_FUNC,
                        BTIF_TIMEOUT_CCH_NO_DCH_SECS);
 }
 else
 {
        BTIF_TRACE_DEBUG("Restart CCH timer ");
        btu_stop_timer(&p_mcb->cch_timer);
        btu_start_timer(&p_mcb->cch_timer, BTU_TTYPE_USER_FUNC,
                        BTIF_TIMEOUT_CCH_NO_DCH_SECS);
 }

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t Parcel::dataPosition() const
{
 return mDataPos;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaRecorder::setAudioSource(int as)
{
    ALOGV("setAudioSource(%d)", as);
 if (mMediaRecorder == NULL) {
        ALOGE("media recorder is not initialized yet");
 return INVALID_OPERATION;
 }
 if (mCurrentState & MEDIA_RECORDER_IDLE) {
        ALOGV("Call init() since the media recorder is not initialized yet");
 status_t ret = init();
 if (OK != ret) {
 return ret;
 }
 }
 if (mIsAudioSourceSet) {
        ALOGE("audio source has already been set");
 return INVALID_OPERATION;
 }
 if (!(mCurrentState & MEDIA_RECORDER_INITIALIZED)) {
        ALOGE("setAudioSource called in an invalid state(%d)", mCurrentState);
 return INVALID_OPERATION;
 }

 status_t ret = mMediaRecorder->setAudioSource(as);
 if (OK != ret) {
        ALOGV("setAudioSource failed: %d", ret);
        mCurrentState = MEDIA_RECORDER_ERROR;
 return ret;
 }
    mIsAudioSourceSet = true;
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t IPCThreadState::requestDeathNotification(int32_t handle, BpBinder* proxy)
{
    mOut.writeInt32(BC_REQUEST_DEATH_NOTIFICATION);
    mOut.writeInt32((int32_t)handle);
    mOut.writePointer((uintptr_t)proxy);
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_entity(iv_obj_t *ps_dechdl,
 void *pv_api_ip,
 void *pv_api_op)
{
 iv_obj_t *ps_dec_handle;
 dec_state_t *ps_dec_state;
 dec_state_multi_core_t *ps_dec_state_multi_core;

 impeg2d_video_decode_ip_t *ps_dec_ip;

 impeg2d_video_decode_op_t *ps_dec_op;
    WORD32 bytes_remaining;
 pic_buf_t *ps_disp_pic;



    ps_dec_ip = (impeg2d_video_decode_ip_t *)pv_api_ip;
    ps_dec_op = (impeg2d_video_decode_op_t *)pv_api_op;

    memset(ps_dec_op,0,sizeof(impeg2d_video_decode_op_t));

    ps_dec_op->s_ivd_video_decode_op_t.u4_size = sizeof(impeg2d_video_decode_op_t);
    ps_dec_op->s_ivd_video_decode_op_t.u4_output_present = 0;
    bytes_remaining = ps_dec_ip->s_ivd_video_decode_ip_t.u4_num_Bytes;

    ps_dec_handle = (iv_obj_t *)ps_dechdl;

 if(ps_dechdl == NULL)
 {
 return(IV_FAIL);
 }



    ps_dec_state_multi_core  = ps_dec_handle->pv_codec_handle;
    ps_dec_state = ps_dec_state_multi_core->ps_dec_state[0];

    ps_dec_state->ps_disp_frm_buf = &(ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf);
 if(0 == ps_dec_state->u4_share_disp_buf)
 {
        ps_dec_state->ps_disp_frm_buf->pv_y_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[0];
        ps_dec_state->ps_disp_frm_buf->pv_u_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[1];
        ps_dec_state->ps_disp_frm_buf->pv_v_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[2];
 }

    ps_dec_state->ps_disp_pic = NULL;
    ps_dec_state->i4_frame_decoded = 0;
 /*rest bytes consumed */
    ps_dec_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = 0;

    ps_dec_op->s_ivd_video_decode_op_t.u4_error_code           = IV_SUCCESS;

 if((ps_dec_ip->s_ivd_video_decode_ip_t.pv_stream_buffer == NULL)&&(ps_dec_state->u1_flushfrm==0))
 {
        ps_dec_op->s_ivd_video_decode_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
        ps_dec_op->s_ivd_video_decode_op_t.u4_error_code |= IVD_DEC_FRM_BS_BUF_NULL;
 return IV_FAIL;
 }


 if (ps_dec_state->u4_num_frames_decoded > NUM_FRAMES_LIMIT)
 {
        ps_dec_op->s_ivd_video_decode_op_t.u4_error_code       = IMPEG2D_SAMPLE_VERSION_LIMIT_ERR;
 return(IV_FAIL);
 }

 if(((0 == ps_dec_state->u2_header_done) || (ps_dec_state->u2_decode_header == 1)) && (ps_dec_state->u1_flushfrm == 0))
 {
        impeg2d_dec_hdr(ps_dec_state,ps_dec_ip ,ps_dec_op);

         bytes_remaining -= ps_dec_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed;
     }
 
    if((1 != ps_dec_state->u2_decode_header) && ((bytes_remaining > 0) || ps_dec_state->u1_flushfrm))
     {
         if(ps_dec_state->u1_flushfrm)
         {
 if(ps_dec_state->aps_ref_pics[1] != NULL)
 {
                impeg2_disp_mgr_add(&ps_dec_state->s_disp_mgr, ps_dec_state->aps_ref_pics[1], ps_dec_state->aps_ref_pics[1]->i4_buf_id);
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->aps_ref_pics[1]->i4_buf_id, BUF_MGR_REF);
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->aps_ref_pics[0]->i4_buf_id, BUF_MGR_REF);

                ps_dec_state->aps_ref_pics[1] = NULL;
                ps_dec_state->aps_ref_pics[0] = NULL;

 }
 else if(ps_dec_state->aps_ref_pics[0] != NULL)
 {
                impeg2_disp_mgr_add(&ps_dec_state->s_disp_mgr, ps_dec_state->aps_ref_pics[0], ps_dec_state->aps_ref_pics[0]->i4_buf_id);
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->aps_ref_pics[0]->i4_buf_id, BUF_MGR_REF);

                ps_dec_state->aps_ref_pics[0] = NULL;
 }
            ps_dec_ip->s_ivd_video_decode_ip_t.u4_size                 = sizeof(impeg2d_video_decode_ip_t);
            ps_dec_op->s_ivd_video_decode_op_t.u4_size                 = sizeof(impeg2d_video_decode_op_t);

            ps_disp_pic = impeg2_disp_mgr_get(&ps_dec_state->s_disp_mgr, &ps_dec_state->i4_disp_buf_id);

            ps_dec_state->ps_disp_pic = ps_disp_pic;
 if(ps_disp_pic == NULL)
 {
                ps_dec_op->s_ivd_video_decode_op_t.u4_output_present = 0;
 }
 else
 {
                WORD32 fmt_conv;
 if(0 == ps_dec_state->u4_share_disp_buf)
 {
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_y_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[0];
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_u_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[1];
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_v_buf  = ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[2];
                    fmt_conv = 1;
 }
 else
 {
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_y_buf  = ps_disp_pic->pu1_y;
 if(IV_YUV_420P == ps_dec_state->i4_chromaFormat)
 {
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_u_buf  = ps_disp_pic->pu1_u;
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_v_buf  = ps_disp_pic->pu1_v;
                        fmt_conv = 0;
 }
 else
 {
                        UWORD8 *pu1_buf;

                        pu1_buf = ps_dec_state->as_disp_buffers[ps_disp_pic->i4_buf_id].pu1_bufs[1];
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_u_buf  = pu1_buf;

                        pu1_buf = ps_dec_state->as_disp_buffers[ps_disp_pic->i4_buf_id].pu1_bufs[2];
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.pv_v_buf  = pu1_buf;
                        fmt_conv = 1;
 }
 }

 if(fmt_conv == 1)
 {
 iv_yuv_buf_t *ps_dst;


                    ps_dst = &(ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf);
 if(ps_dec_state->u4_deinterlace && (0 == ps_dec_state->u2_progressive_frame))
 {
                        impeg2d_deinterlace(ps_dec_state,
                                            ps_disp_pic,
                                            ps_dst,
 0,
                                            ps_dec_state->u2_vertical_size);

 }
 else
 {
                        impeg2d_format_convert(ps_dec_state,
                                               ps_disp_pic,
                                               ps_dst,
 0,
                                               ps_dec_state->u2_vertical_size);
 }
 }

 if(ps_dec_state->u4_deinterlace)
 {
 if(ps_dec_state->ps_deint_pic)
 {
                        impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg,
                                               ps_dec_state->ps_deint_pic->i4_buf_id,
                                               MPEG2_BUF_MGR_DEINT);
 }
                    ps_dec_state->ps_deint_pic = ps_disp_pic;
 }
 if(0 == ps_dec_state->u4_share_disp_buf)
                    impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_disp_pic->i4_buf_id, BUF_MGR_DISP);

                ps_dec_op->s_ivd_video_decode_op_t.u4_pic_ht = ps_dec_state->u2_vertical_size;
                ps_dec_op->s_ivd_video_decode_op_t.u4_pic_wd = ps_dec_state->u2_horizontal_size;
                ps_dec_op->s_ivd_video_decode_op_t.u4_output_present = 1;

                ps_dec_op->s_ivd_video_decode_op_t.u4_disp_buf_id = ps_disp_pic->i4_buf_id;
                ps_dec_op->s_ivd_video_decode_op_t.u4_ts = ps_disp_pic->u4_ts;

                ps_dec_op->s_ivd_video_decode_op_t.e_output_format = (IV_COLOR_FORMAT_T)ps_dec_state->i4_chromaFormat;

                ps_dec_op->s_ivd_video_decode_op_t.u4_is_ref_flag = (B_PIC != ps_dec_state->e_pic_type);

                ps_dec_op->s_ivd_video_decode_op_t.u4_progressive_frame_flag           = IV_PROGRESSIVE;

                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_wd = ps_dec_state->u2_horizontal_size;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_strd = ps_dec_state->u4_frm_buf_stride;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_ht = ps_dec_state->u2_vertical_size;

                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = ps_dec_state->u2_horizontal_size >> 1;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_strd = ps_dec_state->u4_frm_buf_stride >> 1;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_ht = ps_dec_state->u2_vertical_size >> 1;

                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_wd = ps_dec_state->u2_horizontal_size >> 1;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_strd = ps_dec_state->u4_frm_buf_stride >> 1;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_ht = ps_dec_state->u2_vertical_size >> 1;
                ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_size = sizeof(ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf);

 switch(ps_dec_state->i4_chromaFormat)
 {
 case IV_YUV_420SP_UV:
 case IV_YUV_420SP_VU:
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = ps_dec_state->u2_horizontal_size;
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_strd = ps_dec_state->u4_frm_buf_stride;
 break;
 case IV_YUV_422ILE:
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = 0;
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_ht = 0;
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_wd = 0;
                        ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_ht = 0;
 break;
 default:
 break;
 }


 }
 if(ps_dec_op->s_ivd_video_decode_op_t.u4_output_present)
 {
 if(1 == ps_dec_op->s_ivd_video_decode_op_t.u4_output_present)
 {
                    INSERT_LOGO(ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[0],
                                ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[1],
                                ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[2],
                                ps_dec_state->u4_frm_buf_stride,
                                ps_dec_state->u2_horizontal_size,
                                ps_dec_state->u2_vertical_size,
                                ps_dec_state->i4_chromaFormat,
                                ps_dec_state->u2_horizontal_size,
                                ps_dec_state->u2_vertical_size);
 }
 return(IV_SUCCESS);
 }
 else
 {
                ps_dec_state->u1_flushfrm = 0;

 return(IV_FAIL);
 }

 }
 else if(ps_dec_state->u1_flushfrm==0)
 {
            ps_dec_ip->s_ivd_video_decode_ip_t.u4_size                 = sizeof(impeg2d_video_decode_ip_t);
            ps_dec_op->s_ivd_video_decode_op_t.u4_size                 = sizeof(impeg2d_video_decode_op_t);
 if(ps_dec_ip->s_ivd_video_decode_ip_t.u4_num_Bytes < 4)
 {
                ps_dec_op->s_ivd_video_decode_op_t.u4_num_bytes_consumed = ps_dec_ip->s_ivd_video_decode_ip_t.u4_num_Bytes;
 return(IV_FAIL);
 }

 if(1 == ps_dec_state->u4_share_disp_buf)
 {
 if(0 == impeg2_buf_mgr_check_free(ps_dec_state->pv_pic_buf_mg))
 {
                    ps_dec_op->s_ivd_video_decode_op_t.u4_error_code =
 (IMPEG2D_ERROR_CODES_T)IVD_DEC_REF_BUF_NULL;
 return IV_FAIL;
 }
 }


            ps_dec_op->s_ivd_video_decode_op_t.e_output_format = (IV_COLOR_FORMAT_T)ps_dec_state->i4_chromaFormat;

            ps_dec_op->s_ivd_video_decode_op_t.u4_is_ref_flag = (B_PIC != ps_dec_state->e_pic_type);

            ps_dec_op->s_ivd_video_decode_op_t.u4_progressive_frame_flag           = IV_PROGRESSIVE;

 if (0 == ps_dec_state->u4_frm_buf_stride)
 {
                ps_dec_state->u4_frm_buf_stride = (ps_dec_state->u2_horizontal_size);
 }

            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_wd = ps_dec_state->u2_horizontal_size;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_strd = ps_dec_state->u4_frm_buf_stride;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_y_ht = ps_dec_state->u2_vertical_size;

            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = ps_dec_state->u2_horizontal_size >> 1;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_strd = ps_dec_state->u4_frm_buf_stride >> 1;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_ht = ps_dec_state->u2_vertical_size >> 1;

            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_wd = ps_dec_state->u2_horizontal_size >> 1;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_strd = ps_dec_state->u4_frm_buf_stride >> 1;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_ht = ps_dec_state->u2_vertical_size >> 1;
            ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_size = sizeof(ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf);

 switch(ps_dec_state->i4_chromaFormat)
 {
 case IV_YUV_420SP_UV:
 case IV_YUV_420SP_VU:
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = ps_dec_state->u2_horizontal_size;
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_strd = ps_dec_state->u4_frm_buf_stride;
 break;
 case IV_YUV_422ILE:
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_wd = 0;
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_u_ht = 0;
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_wd = 0;
                    ps_dec_op->s_ivd_video_decode_op_t.s_disp_frm_buf.u4_v_ht = 0;
 break;
 default:
 break;
 }

 if( ps_dec_state->u1_flushfrm == 0)
 {
                ps_dec_state->u1_flushcnt    = 0;

 /*************************************************************************/
 /*                              Frame Decode                             */
 /*************************************************************************/

                impeg2d_dec_frm(ps_dec_state,ps_dec_ip,ps_dec_op);

 if (IVD_ERROR_NONE ==
                        ps_dec_op->s_ivd_video_decode_op_t.u4_error_code)
 {
 if(ps_dec_state->u1_first_frame_done == 0)
 {
                        ps_dec_state->u1_first_frame_done = 1;
 }

 if(ps_dec_state->ps_disp_pic)
 {
                        ps_dec_op->s_ivd_video_decode_op_t.u4_output_present = 1;
 switch(ps_dec_state->ps_disp_pic->e_pic_type)
 {
 case I_PIC :
                            ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_I_FRAME;
 break;

 case P_PIC:
                            ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_P_FRAME;
 break;

 case B_PIC:
                            ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_B_FRAME;
 break;

 case D_PIC:
                            ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_I_FRAME;
 break;

 default :
                            ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_FRAMETYPE_DEFAULT;
 break;
 }
 }
 else
 {
                        ps_dec_op->s_ivd_video_decode_op_t.u4_output_present = 0;
                        ps_dec_op->s_ivd_video_decode_op_t.e_pic_type = IV_NA_FRAME;
 }

                    ps_dec_state->u4_num_frames_decoded++;
 }
 }
 else
 {
                ps_dec_state->u1_flushcnt++;
 }
 }
 if(ps_dec_state->ps_disp_pic)
 {
            ps_dec_op->s_ivd_video_decode_op_t.u4_disp_buf_id = ps_dec_state->ps_disp_pic->i4_buf_id;
            ps_dec_op->s_ivd_video_decode_op_t.u4_ts = ps_dec_state->ps_disp_pic->u4_ts;

 if(0 == ps_dec_state->u4_share_disp_buf)
 {
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg, ps_dec_state->ps_disp_pic->i4_buf_id, BUF_MGR_DISP);
 }
 }

 if(ps_dec_state->u4_deinterlace)
 {
 if(ps_dec_state->ps_deint_pic)
 {
                impeg2_buf_mgr_release(ps_dec_state->pv_pic_buf_mg,
                                       ps_dec_state->ps_deint_pic->i4_buf_id,
                                       MPEG2_BUF_MGR_DEINT);
 }
            ps_dec_state->ps_deint_pic = ps_dec_state->ps_disp_pic;
 }

 if(1 == ps_dec_op->s_ivd_video_decode_op_t.u4_output_present)
 {
            INSERT_LOGO(ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[0],
                        ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[1],
                        ps_dec_ip->s_ivd_video_decode_ip_t.s_out_buffer.pu1_bufs[2],
                        ps_dec_state->u4_frm_buf_stride,
                        ps_dec_state->u2_horizontal_size,
                        ps_dec_state->u2_vertical_size,
                        ps_dec_state->i4_chromaFormat,
                        ps_dec_state->u2_horizontal_size,
                        ps_dec_state->u2_vertical_size);
 }

 }

    ps_dec_op->s_ivd_video_decode_op_t.u4_progressive_frame_flag = 1;
    ps_dec_op->s_ivd_video_decode_op_t.e4_fld_type     = ps_dec_state->s_disp_op.e4_fld_type;


 if(ps_dec_op->s_ivd_video_decode_op_t.u4_error_code)
 return IV_FAIL;
 else
 return IV_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void RilSapSocket::initSapSocket(const char *socketName,
        RIL_RadioFunctions *uimFuncs) {

 if (strcmp(socketName, "sap_uim_socket1") == 0) {
 if(!SocketExists(socketName)) {
            addSocketToList(socketName, RIL_SOCKET_1, uimFuncs);
 }
 }

#if (SIM_COUNT >= 2)
 if (strcmp(socketName, "sap_uim_socket2") == 0) {
 if(!SocketExists(socketName)) {
            addSocketToList(socketName, RIL_SOCKET_2, uimFuncs);
 }
 }
#endif

#if (SIM_COUNT >= 3)
 if (strcmp(socketName, "sap_uim_socket3") == 0) {
 if(!SocketExists(socketName)) {
            addSocketToList(socketName, RIL_SOCKET_3, uimFuncs);
 }
 }
#endif

#if (SIM_COUNT >= 4)
 if (strcmp(socketName, "sap_uim_socket4") == 0) {
 if(!SocketExists(socketName)) {
            addSocketToList(socketName, RIL_SOCKET_4, uimFuncs);
 }
 }
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Cues::~Cues()
{
    const long n = m_count + m_preload_count;
 
    CuePoint** p = m_cue_points;
    CuePoint** const q = p + n;
 
    while (p != q)
    {
        CuePoint* const pCP = *p++;
        assert(pCP);
 
        delete pCP;
    }
 
     delete[] m_cue_points;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t CameraClient::initialize(camera_module_t *module) {
 int callingPid = getCallingPid();
 status_t res;

    LOG1("CameraClient::initialize E (pid %d, id %d)", callingPid, mCameraId);

    res = startCameraOps();
 if (res != OK) {
 return res;
 }

 char camera_device_name[10];
    snprintf(camera_device_name, sizeof(camera_device_name), "%d", mCameraId);

    mHardware = new CameraHardwareInterface(camera_device_name);
    res = mHardware->initialize(&module->common);
 if (res != OK) {
        ALOGE("%s: Camera %d: unable to initialize device: %s (%d)",
                __FUNCTION__, mCameraId, strerror(-res), res);
        mHardware.clear();
 return NO_INIT;
 }

    mHardware->setCallbacks(notifyCallback,
            dataCallback,
            dataCallbackTimestamp,
 (void *)mCameraId);

    enableMsgType(CAMERA_MSG_ERROR | CAMERA_MSG_ZOOM | CAMERA_MSG_FOCUS |
                  CAMERA_MSG_PREVIEW_METADATA | CAMERA_MSG_FOCUS_MOVE);

    LOG1("CameraClient::initialize X (pid %d, id %d)", callingPid, mCameraId);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MetaData> DRMSource::getFormat() {
 return mOriginalMediaSource->getFormat();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_init_ok(UNUSED_ATTR uint16_t event, UNUSED_ATTR char *p_param) {
  BTIF_TRACE_DEBUG("btif_task: received trigger stack init event");
#if (BLE_INCLUDED == TRUE)
  btif_dm_load_ble_local_keys();
#endif
  BTA_EnableBluetooth(bte_dm_evt);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: UWORD32 ih264d_get_outbuf_size(WORD32 pic_wd,
                               UWORD32 pic_ht,
                               UWORD8 u1_chroma_format,
                               UWORD32 *p_buf_size)
{
    UWORD32 u4_min_num_out_bufs = 0;

 if(u1_chroma_format == IV_YUV_420P)
        u4_min_num_out_bufs = MIN_OUT_BUFS_420;
 else if(u1_chroma_format == IV_YUV_422ILE)
        u4_min_num_out_bufs = MIN_OUT_BUFS_422ILE;
 else if(u1_chroma_format == IV_RGB_565)
        u4_min_num_out_bufs = MIN_OUT_BUFS_RGB565;
 else if((u1_chroma_format == IV_YUV_420SP_UV)
 || (u1_chroma_format == IV_YUV_420SP_VU))
        u4_min_num_out_bufs = MIN_OUT_BUFS_420SP;

 if(u1_chroma_format == IV_YUV_420P)
 {
        p_buf_size[0] = (pic_wd * pic_ht);
        p_buf_size[1] = (pic_wd * pic_ht) >> 2;
        p_buf_size[2] = (pic_wd * pic_ht) >> 2;
 }
 else if(u1_chroma_format == IV_YUV_422ILE)
 {
        p_buf_size[0] = (pic_wd * pic_ht) * 2;
        p_buf_size[1] = p_buf_size[2] = 0;
 }
 else if(u1_chroma_format == IV_RGB_565)
 {
        p_buf_size[0] = (pic_wd * pic_ht) * 2;
        p_buf_size[1] = p_buf_size[2] = 0;
 }
 else if((u1_chroma_format == IV_YUV_420SP_UV)
 || (u1_chroma_format == IV_YUV_420SP_VU))
 {
        p_buf_size[0] = (pic_wd * pic_ht);
        p_buf_size[1] = (pic_wd * pic_ht) >> 1;
        p_buf_size[2] = 0;
 }

 return u4_min_num_out_bufs;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::free_buffer(OMX_IN OMX_HANDLETYPE         hComp,
        OMX_IN OMX_U32                 port,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 unsigned int nPortIndex;
 (void) hComp;
    DEBUG_PRINT_LOW("In for decoder free_buffer");

 if (m_state == OMX_StateIdle &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
        DEBUG_PRINT_LOW(" free buffer while Component in Loading pending");
 } else if ((m_inp_bEnabled == OMX_FALSE && port == OMX_CORE_INPUT_PORT_INDEX)||
 (m_out_bEnabled == OMX_FALSE && port == OMX_CORE_OUTPUT_PORT_INDEX)) {
        DEBUG_PRINT_LOW("Free Buffer while port %u disabled", (unsigned int)port);
 } else if ((port == OMX_CORE_INPUT_PORT_INDEX &&
                BITMASK_PRESENT(&m_flags, OMX_COMPONENT_INPUT_ENABLE_PENDING)) ||
 (port == OMX_CORE_OUTPUT_PORT_INDEX &&
             BITMASK_PRESENT(&m_flags, OMX_COMPONENT_OUTPUT_ENABLE_PENDING))) {
        DEBUG_PRINT_LOW("Free Buffer while port %u enable pending", (unsigned int)port);
 } else if (m_state == OMX_StateExecuting || m_state == OMX_StatePause) {
        DEBUG_PRINT_ERROR("Invalid state to free buffer,ports need to be disabled");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);

 return OMX_ErrorIncorrectStateOperation;
 } else if (m_state != OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("Invalid state to free buffer,port lost Buffers");
        post_event(OMX_EventError,
                OMX_ErrorPortUnpopulated,
                OMX_COMPONENT_GENERATE_EVENT);
 }

 if (port == OMX_CORE_INPUT_PORT_INDEX) {
 /*Check if arbitrary bytes*/
 if (!arbitrary_bytes && !input_use_buffer)
            nPortIndex = buffer - m_inp_mem_ptr;
 else
            nPortIndex = buffer - m_inp_heap_ptr;

        DEBUG_PRINT_LOW("free_buffer on i/p port - Port idx %d", nPortIndex);
 if (nPortIndex < drv_ctx.ip_buf.actualcount) {
            BITMASK_CLEAR(&m_inp_bm_count,nPortIndex);
            BITMASK_CLEAR(&m_heap_inp_bm_count,nPortIndex);
 if (input_use_buffer == true) {

                DEBUG_PRINT_LOW("Free pmem Buffer index %d",nPortIndex);
 if (m_phdr_pmem_ptr)
                    free_input_buffer(m_phdr_pmem_ptr[nPortIndex]);
 } else {
 if (arbitrary_bytes) {
 if (m_phdr_pmem_ptr)
                        free_input_buffer(nPortIndex,m_phdr_pmem_ptr[nPortIndex]);
 else
                        free_input_buffer(nPortIndex,NULL);
 } else
                    free_input_buffer(buffer);
 }
            m_inp_bPopulated = OMX_FALSE;
 if(release_input_done())
                release_buffers(this, VDEC_BUFFER_TYPE_INPUT);
 /*Free the Buffer Header*/
 if (release_input_done()) {
                DEBUG_PRINT_HIGH("ALL input buffers are freed/released");
                free_input_buffer_header();
 }
 } else {
            DEBUG_PRINT_ERROR("Error: free_buffer ,Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }

 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING)
 && release_input_done()) {
            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_INPUT_DISABLE_PENDING);
            post_event(OMX_CommandPortDisable,
                    OMX_CORE_INPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 } else if (port == OMX_CORE_OUTPUT_PORT_INDEX) {
        nPortIndex = buffer - client_buffers.get_il_buf_hdr();
 if (nPortIndex < drv_ctx.op_buf.actualcount) {
            DEBUG_PRINT_LOW("free_buffer on o/p port - Port idx %d", nPortIndex);
            BITMASK_CLEAR(&m_out_bm_count,nPortIndex);
            m_out_bPopulated = OMX_FALSE;
            client_buffers.free_output_buffer (buffer);

 if(release_output_done()) {
                release_buffers(this, VDEC_BUFFER_TYPE_OUTPUT);
 }
 if (release_output_done()) {
                free_output_buffer_header();
 }
 } else {
            DEBUG_PRINT_ERROR("Error: free_buffer , Port Index Invalid");
            eRet = OMX_ErrorBadPortIndex;
 }
 if (BITMASK_PRESENT((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING)
 && release_output_done()) {
            DEBUG_PRINT_LOW("FreeBuffer : If any Disable event pending,post it");

            DEBUG_PRINT_LOW("MOVING TO DISABLED STATE");
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_OUTPUT_DISABLE_PENDING);
#ifdef _ANDROID_ICS_
 if (m_enable_android_native_buffers) {
                DEBUG_PRINT_LOW("FreeBuffer - outport disabled: reset native buffers");
                memset(&native_buffer, 0 ,(sizeof(struct nativebuffer) * MAX_NUM_INPUT_OUTPUT_BUFFERS));
 }
#endif

            post_event(OMX_CommandPortDisable,
                    OMX_CORE_OUTPUT_PORT_INDEX,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 } else {
        eRet = OMX_ErrorBadPortIndex;
 }
 if ((eRet == OMX_ErrorNone) &&
 (BITMASK_PRESENT(&m_flags ,OMX_COMPONENT_LOADING_PENDING))) {
 if (release_done()) {
            BITMASK_CLEAR((&m_flags),OMX_COMPONENT_LOADING_PENDING);
            post_event(OMX_CommandStateSet, OMX_StateLoaded,
                    OMX_COMPONENT_GENERATE_EVENT);
 }
 }
 return eRet;
}

Labels: No
----------------lora model----------------
Response: </s>


Instruction: 
Input: void NuPlayer::GenericSource::onPollBuffering() {
 status_t finalStatus = UNKNOWN_ERROR;
 int64_t cachedDurationUs = -1ll;
 ssize_t cachedDataRemaining = -1;

    ALOGW_IF(mWVMExtractor != NULL && mCachedSource != NULL,
 "WVMExtractor and NuCachedSource both present");

 if (mWVMExtractor != NULL) {
        cachedDurationUs =
                mWVMExtractor->getCachedDurationUs(&finalStatus);
 } else if (mCachedSource != NULL) {
        cachedDataRemaining =
                mCachedSource->approxDataRemaining(&finalStatus);

 if (finalStatus == OK) {
 off64_t size;
 int64_t bitrate = 0ll;
 if (mDurationUs > 0 && mCachedSource->getSize(&size) == OK) {
                bitrate = size * 8000000ll / mDurationUs;
 } else if (mBitrate > 0) {
                bitrate = mBitrate;
 }
 if (bitrate > 0) {
                cachedDurationUs = cachedDataRemaining * 8000000ll / bitrate;
 }
 }
 }

 if (finalStatus != OK) {
        ALOGV("onPollBuffering: EOS (finalStatus = %d)", finalStatus);

 if (finalStatus == ERROR_END_OF_STREAM) {
            notifyBufferingUpdate(100);
 }

        stopBufferingIfNecessary();
 return;
 } else if (cachedDurationUs >= 0ll) {
 if (mDurationUs > 0ll) {
 int64_t cachedPosUs = getLastReadPosition() + cachedDurationUs;
 int percentage = 100.0 * cachedPosUs / mDurationUs;
 if (percentage > 100) {
                percentage = 100;
 }

            notifyBufferingUpdate(percentage);
 }

        ALOGV("onPollBuffering: cachedDurationUs %.1f sec",
                cachedDurationUs / 1000000.0f);

 if (cachedDurationUs < kLowWaterMarkUs) {
            startBufferingIfNecessary();
 } else if (cachedDurationUs > kHighWaterMarkUs) {
            stopBufferingIfNecessary();
 }
 } else if (cachedDataRemaining >= 0) {
        ALOGV("onPollBuffering: cachedDataRemaining %zd bytes",
                cachedDataRemaining);

 if (cachedDataRemaining < kLowWaterMarkBytes) {
            startBufferingIfNecessary();
 } else if (cachedDataRemaining > kHighWaterMarkBytes) {
            stopBufferingIfNecessary();
 }
 }

    schedulePollBuffering();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlSAXUserParseFile(xmlSAXHandlerPtr sax, void *user_data,
 const char *filename) {
 int ret = 0;
    xmlParserCtxtPtr ctxt;

    ctxt = xmlCreateFileParserCtxt(filename);
 if (ctxt == NULL) return -1;
 if (ctxt->sax != (xmlSAXHandlerPtr) &xmlDefaultSAXHandler)
	xmlFree(ctxt->sax);
    ctxt->sax = sax;
    xmlDetectSAX2(ctxt);

 if (user_data != NULL)
	ctxt->userData = user_data;

    xmlParseDocument(ctxt);

 if (ctxt->wellFormed)
	ret = 0;
 else {
 if (ctxt->errNo != 0)
	    ret = ctxt->errNo;
 else
	    ret = -1;
 }
 if (sax != NULL)
	ctxt->sax = NULL;
 if (ctxt->myDoc != NULL) {
        xmlFreeDoc(ctxt->myDoc);
	ctxt->myDoc = NULL;
 }
    xmlFreeParserCtxt(ctxt);

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t do_find_service(const uint16_t *s, size_t len, uid_t uid, pid_t spid)
{
 struct svcinfo *si = find_svc(s, len);

 if (!si || !si->handle) {
 return 0;
 }

 if (!si->allow_isolated) {
 uid_t appid = uid % AID_USER;
 if (appid >= AID_ISOLATED_START && appid <= AID_ISOLATED_END) {
 return 0;
 }
 }

 if (!svc_can_find(s, len, spid, uid)) {
 return 0;
 }

 return si->handle;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: check16(png_const_bytep bp, int b)
{
 int i = 16;

 do
 if (*bp != b) return 1;
 while (--i);

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ih264d_rest_of_residual_cav_chroma_dc_block(UWORD32 u4_total_coeff_trail_one,
 dec_bit_stream_t *ps_bitstrm)
{
    UWORD32 u4_total_zeroes;
    WORD16 i;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;

     UWORD32 u4_bitstream_offset = ps_bitstrm->u4_ofst;
     UWORD32 u4_trailing_ones = u4_total_coeff_trail_one & 0xFFFF;
     UWORD32 u4_total_coeff = u4_total_coeff_trail_one >> 16;
    WORD16 i2_level_arr[4];
 
     tu_sblk4x4_coeff_data_t *ps_tu_4x4;
     WORD16 *pi2_coeff_data;
 dec_struct_t *ps_dec = (dec_struct_t *)ps_bitstrm->pv_codec_handle;

    ps_tu_4x4 = (tu_sblk4x4_coeff_data_t *)ps_dec->pv_parse_tu_coeff_data;
    ps_tu_4x4->u2_sig_coeff_map = 0;
    pi2_coeff_data = &ps_tu_4x4->ai2_level[0];

    i = u4_total_coeff - 1;
 if(u4_trailing_ones)
 {
 /*********************************************************************/
 /* Decode Trailing Ones                                              */
 /* read the sign of T1's and put them in level array                 */
 /*********************************************************************/
        UWORD32 u4_signs, u4_cnt = u4_trailing_ones;
        WORD16 (*ppi2_trlone_lkup)[3] =
 (WORD16 (*)[3])gai2_ih264d_trailing_one_level;
        WORD16 *pi2_trlone_lkup;

        GETBITS(u4_signs, u4_bitstream_offset, pu4_bitstrm_buf, u4_cnt);

        pi2_trlone_lkup = ppi2_trlone_lkup[(1 << u4_cnt) - 2 + u4_signs];

 while(u4_cnt--)
            i2_level_arr[i--] = *pi2_trlone_lkup++;
 }

 /****************************************************************/
 /* Decoding Levels Begins                                       */
 /****************************************************************/
 if(i >= 0)
 {
 /****************************************************************/
 /* First level is decoded outside the loop as it has lot of     */
 /* special cases.                                               */
 /****************************************************************/
        UWORD32 u4_lev_suffix, u4_suffix_len, u4_lev_suffix_size;
        UWORD16 u2_lev_code, u2_abs_value;
        UWORD32 u4_lev_prefix;

 /***************************************************************/
 /* u4_suffix_len = 0,  Find leading zeros in next 32 bits      */
 /***************************************************************/
        FIND_ONE_IN_STREAM_32(u4_lev_prefix, u4_bitstream_offset,
                              pu4_bitstrm_buf);

 /*********************************************************/
 /* Special decoding case when trailing ones are 3        */
 /*********************************************************/
        u2_lev_code = MIN(15, u4_lev_prefix);

        u2_lev_code += (3 == u4_trailing_ones) ? 0 : (2);

 if(14 == u4_lev_prefix)
            u4_lev_suffix_size = 4;
 else if(15 <= u4_lev_prefix)
 {
            u2_lev_code += 15;
            u4_lev_suffix_size = u4_lev_prefix - 3;
 }
 else
            u4_lev_suffix_size = 0;

 if(16 <= u4_lev_prefix)
 {
            u2_lev_code += ((1 << (u4_lev_prefix - 3)) - 4096);
 }
 if(u4_lev_suffix_size)
 {
            GETBITS(u4_lev_suffix, u4_bitstream_offset, pu4_bitstrm_buf,
                    u4_lev_suffix_size);
            u2_lev_code += u4_lev_suffix;
 }

        u2_abs_value = (u2_lev_code + 2) >> 1;
 /*********************************************************/
 /* If Level code is odd, level is negative else positive */
 /*********************************************************/
        i2_level_arr[i--] = (u2_lev_code & 1) ? -u2_abs_value : u2_abs_value;

        u4_suffix_len = (u2_abs_value > 3) ? 2 : 1;

 /*********************************************************/
 /* Now loop over the remaining levels                    */
 /*********************************************************/
 while(i >= 0)
 {

 /***************************************************************/
 /* Find leading zeros in next 32 bits                          */
 /***************************************************************/
            FIND_ONE_IN_STREAM_32(u4_lev_prefix, u4_bitstream_offset,
                                  pu4_bitstrm_buf);

            u4_lev_suffix_size =
 (15 <= u4_lev_prefix) ?
 (u4_lev_prefix - 3) : u4_suffix_len;

 /*********************************************************/
 /* Compute level code using prefix and suffix            */
 /*********************************************************/
            GETBITS(u4_lev_suffix, u4_bitstream_offset, pu4_bitstrm_buf,
                    u4_lev_suffix_size);
            u2_lev_code = (MIN(u4_lev_prefix,15) << u4_suffix_len)
 + u4_lev_suffix;

 if(16 <= u4_lev_prefix)
 {
                u2_lev_code += ((1 << (u4_lev_prefix - 3)) - 4096);
 }
            u2_abs_value = (u2_lev_code + 2) >> 1;

 /*********************************************************/
 /* If Level code is odd, level is negative else positive */
 /*********************************************************/
            i2_level_arr[i--] =
 (u2_lev_code & 1) ? -u2_abs_value : u2_abs_value;

 /*********************************************************/
 /* Increment suffix length if required                   */
 /*********************************************************/
            u4_suffix_len += (u2_abs_value > (3 << (u4_suffix_len - 1)));
 }

 /****************************************************************/
 /* Decoding Levels Ends                                         */
 /****************************************************************/
 }

 if(u4_total_coeff < 4)
 {
        UWORD32 u4_max_ldz = (4 - u4_total_coeff);
        FIND_ONE_IN_STREAM_LEN(u4_total_zeroes, u4_bitstream_offset,
                               pu4_bitstrm_buf, u4_max_ldz);
 }
 else
        u4_total_zeroes = 0;

 /**************************************************************/
 /* Decode the runs and form the coefficient buffer            */
 /**************************************************************/
 {
 const UWORD8 *pu1_table_runbefore;
        UWORD32 u4_run;
        UWORD32 u4_scan_pos = (u4_total_coeff + u4_total_zeroes - 1);
        UWORD32 u4_zeroes_left = u4_total_zeroes;
        i = u4_total_coeff - 1;

 /**************************************************************/
 /* Decoding Runs for 0 < zeros left <=6                       */
 /**************************************************************/
        pu1_table_runbefore = (UWORD8 *)gau1_ih264d_table_run_before;
 while(u4_zeroes_left && i)
 {
            UWORD32 u4_code;
            NEXTBITS(u4_code, u4_bitstream_offset, pu4_bitstrm_buf, 3);

            u4_code = pu1_table_runbefore[u4_code + (u4_zeroes_left << 3)];
            u4_run = u4_code >> 2;

            FLUSHBITS(u4_bitstream_offset, (u4_code & 0x03));
            SET_BIT(ps_tu_4x4->u2_sig_coeff_map, u4_scan_pos);
 *pi2_coeff_data++ = i2_level_arr[i--];
            u4_zeroes_left -= u4_run;
            u4_scan_pos -= (u4_run + 1);
 }
 /**************************************************************/
 /* Decoding Runs End                                          */
 /**************************************************************/

 /**************************************************************/
 /* Copy the remaining coefficients                            */
 /**************************************************************/
 while(i >= 0)
 {
            SET_BIT(ps_tu_4x4->u2_sig_coeff_map, u4_scan_pos);
 *pi2_coeff_data++ = i2_level_arr[i--];
            u4_scan_pos--;
 }
 }

 {
        WORD32 offset;
        offset = (UWORD8 *)pi2_coeff_data - (UWORD8 *)ps_tu_4x4;
        offset = ALIGN4(offset);
        ps_dec->pv_parse_tu_coeff_data = (void *)((UWORD8 *)ps_dec->pv_parse_tu_coeff_data + offset);
 }

    ps_bitstrm->u4_ofst = u4_bitstream_offset;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: int equalizer_set_parameter(effect_context_t *context, effect_param_t *p,
 uint32_t size __unused)
{
 equalizer_context_t *eq_ctxt = (equalizer_context_t *)context;
 int voffset = ((p->psize - 1) / sizeof(int32_t) + 1) * sizeof(int32_t);
 void *value = p->data + voffset;
 int32_t *param_tmp = (int32_t *)p->data;
 int32_t param = *param_tmp++;
 int32_t preset;
 int32_t band;
 int32_t level;
 int i;

    ALOGV("%s", __func__);

    p->status = 0;

 switch (param) {
 case EQ_PARAM_CUR_PRESET:
	ALOGV("EQ_PARAM_CUR_PRESET");
        preset = (int32_t)(*(uint16_t *)value);

 if ((preset >= equalizer_get_num_presets(eq_ctxt)) || (preset < 0)) {
           p->status = -EINVAL;
 break;
 }
        equalizer_set_preset(eq_ctxt, preset);
 break;
 case EQ_PARAM_BAND_LEVEL:
	ALOGV("EQ_PARAM_BAND_LEVEL");
        band = *param_tmp;
        level = (int32_t)(*(int16_t *)value);
 if (band >= NUM_EQ_BANDS) {
           p->status = -EINVAL;
 break;
 }
        equalizer_set_band_level(eq_ctxt, band, level);
 break;
 case EQ_PARAM_PROPERTIES: {
	ALOGV("EQ_PARAM_PROPERTIES");
 int16_t *prop = (int16_t *)value;
 if ((int)prop[0] >= equalizer_get_num_presets(eq_ctxt)) {
            p->status = -EINVAL;
 break;
 }
 if (prop[0] >= 0) {
            equalizer_set_preset(eq_ctxt, (int)prop[0]);
 } else {
 if ((int)prop[1] != NUM_EQ_BANDS) {
                p->status = -EINVAL;
 break;
 }
 for (i = 0; i < NUM_EQ_BANDS; i++) {
               equalizer_set_band_level(eq_ctxt, i, (int)prop[2 + i]);
 }
 }
 } break;
 default:
        p->status = -EINVAL;
 break;
 }

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SoftMPEG2::resetPlugin() {
    mIsInFlush = false;
    mReceivedEOS = false;
    memset(mTimeStamps, 0, sizeof(mTimeStamps));
    memset(mTimeStampsValid, 0, sizeof(mTimeStampsValid));

 /* Initialize both start and end times */
    gettimeofday(&mTimeStart, NULL);
    gettimeofday(&mTimeEnd, NULL);

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<JSArray> SliceImpl(Handle<JSObject> receiver, uint32_t start,
 uint32_t end) {
 Isolate* isolate = receiver->GetIsolate();
 uint32_t result_len = end < start ? 0u : end - start;
 Handle<JSArray> result_array = isolate->factory()->NewJSArray(
        FAST_HOLEY_ELEMENTS, result_len, result_len);
 DisallowHeapAllocation no_gc;
 FixedArray* elements = FixedArray::cast(result_array->elements());
 FixedArray* parameters = FixedArray::cast(receiver->elements());
 uint32_t insertion_index = 0;
 for (uint32_t i = start; i < end; i++) {
 uint32_t entry = GetEntryForIndexImpl(isolate, *receiver, parameters, i,
                                            ALL_PROPERTIES);
 if (entry != kMaxUInt32 && HasEntryImpl(isolate, parameters, entry)) {
        elements->set(insertion_index, *GetImpl(isolate, parameters, entry));
 } else {
        elements->set_the_hole(isolate, insertion_index);
 }
      insertion_index++;
 }
 return result_array;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btm_sec_dev_reset (void)
{
#if (BTM_PRE_LISBON_INCLUDED == TRUE)
 if (btm_cb.security_mode == BTM_SEC_MODE_LINK)
 {
        btsnd_hcic_write_auth_enable (TRUE);
        btsnd_hcic_write_encr_mode (HCI_ENCRYPT_MODE_POINT_TO_POINT);
 }
#endif
#if (BTM_PRE_LISBON_INCLUDED == TRUE)
 else
#endif
 /* btm_sec_dev_reset() is only called from btm_decode_ext_features_page(...)
         * right now. */
 if (HCI_SIMPLE_PAIRING_SUPPORTED(btm_cb.devcb.local_lmp_features[HCI_EXT_FEATURES_PAGE_0]))
 {
        btsnd_hcic_write_simple_pairing_mode(HCI_SP_MODE_ENABLED);
#if BLE_INCLUDED == TRUE
        btsnd_hcic_set_event_mask(LOCAL_BR_EDR_CONTROLLER_ID,
 (UINT8 *)HCI_DUMO_EVENT_MASK_EXT);

        btsnd_hcic_ble_set_evt_mask((UINT8 *)HCI_BLE_EVENT_MASK_DEF);

#else
        btsnd_hcic_set_event_mask(LOCAL_BR_EDR_CONTROLLER_ID,
 (UINT8 *)HCI_LISBON_EVENT_MASK_EXT);
#endif
 /* set the default IO capabilities */
        btm_cb.devcb.loc_io_caps = BTM_LOCAL_IO_CAPS;
 /* add mx service to use no security */
#if (RFCOMM_INCLUDED == TRUE)
        BTM_SetSecurityLevel(FALSE, "RFC_MUX", BTM_SEC_SERVICE_RFC_MUX,
                             BTM_SEC_NONE, BT_PSM_RFCOMM, BTM_SEC_PROTO_RFCOMM, 0);
#endif
 }
 else
 {
        btm_cb.security_mode = BTM_SEC_MODE_SERVICE;
 }

    BTM_TRACE_DEBUG ("btm_sec_dev_reset sec mode: %d", btm_cb.security_mode);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_update_source_codec(void* p_data) {
  BTIF_TRACE_DEBUG("%s", __func__);

 btav_a2dp_codec_config_t req;
  memcpy(&req, p_data, sizeof(req));

  btif_a2dp_source_encoder_user_config_update_req(req);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftAVCEncoder(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static MaybeHandle<FixedArray> PrependElementIndicesImpl(
 Handle<JSObject> object, Handle<FixedArrayBase> backing_store,
 Handle<FixedArray> keys, GetKeysConversion convert,
 PropertyFilter filter) {
 Isolate* isolate = object->GetIsolate();
 uint32_t nof_property_keys = keys->length();
 uint32_t initial_list_length =
 Subclass::GetMaxNumberOfEntries(*object, *backing_store);

    initial_list_length += nof_property_keys;
 if (initial_list_length > FixedArray::kMaxLength ||
        initial_list_length < nof_property_keys) {
 return isolate->Throw<FixedArray>(isolate->factory()->NewRangeError(
 MessageTemplate::kInvalidArrayLength));
 }

 MaybeHandle<FixedArray> raw_array =
        isolate->factory()->TryNewFixedArray(initial_list_length);
 Handle<FixedArray> combined_keys;

 if (!raw_array.ToHandle(&combined_keys)) {
 if (IsHoleyElementsKind(kind())) {
        initial_list_length =
 Subclass::NumberOfElementsImpl(*object, *backing_store);
        initial_list_length += nof_property_keys;
 }
      combined_keys = isolate->factory()->NewFixedArray(initial_list_length);
 }

 uint32_t nof_indices = 0;
 bool needs_sorting =
 IsDictionaryElementsKind(kind()) || IsSloppyArgumentsElements(kind());
    combined_keys = Subclass::DirectCollectElementIndicesImpl(
        isolate, object, backing_store,
        needs_sorting ? GetKeysConversion::kKeepNumbers : convert, filter,
        combined_keys, &nof_indices);

 if (needs_sorting) {
 SortIndices(combined_keys, nof_indices);
 if (convert == GetKeysConversion::kConvertToString) {
 for (uint32_t i = 0; i < nof_indices; i++) {
 Handle<Object> index_string = isolate->factory()->Uint32ToString(
              combined_keys->get(i)->Number());
          combined_keys->set(i, *index_string);
 }
 }
 }

 CopyObjectToObjectElements(*keys, FAST_ELEMENTS, 0, *combined_keys,
                               FAST_ELEMENTS, nof_indices, nof_property_keys);

 if (IsHoleyElementsKind(kind()) || IsSloppyArgumentsElements(kind())) {
 int final_size = nof_indices + nof_property_keys;
      DCHECK_LE(final_size, combined_keys->length());
      combined_keys->Shrink(final_size);
 }

 return combined_keys;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t StatusFromOMXError(OMX_ERRORTYPE err) {
 switch (err) {
 case OMX_ErrorNone:
 return OK;
 case OMX_ErrorUnsupportedSetting:
 case OMX_ErrorUnsupportedIndex:
 return ERROR_UNSUPPORTED;
 case OMX_ErrorInsufficientResources:
 return NO_MEMORY;
 default:
 return UNKNOWN_ERROR;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bt_status_t send_data (bt_bdaddr_t *bd_addr, char* data)
{
    CHECK_BTHH_INIT();
 btif_hh_device_t *p_dev;
    BD_ADDR* bda = (BD_ADDR*) bd_addr;

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

    BTIF_TRACE_DEBUG("addr = %02X:%02X:%02X:%02X:%02X:%02X",
 (*bda)[0], (*bda)[1], (*bda)[2], (*bda)[3], (*bda)[4], (*bda)[5]);

 if (btif_hh_cb.status == BTIF_HH_DISABLED) {
        BTIF_TRACE_ERROR("%s: Error, HH status = %d", __FUNCTION__, btif_hh_cb.status);
 return BT_STATUS_FAIL;
 }

    p_dev = btif_hh_find_connected_dev_by_bda(bd_addr);
 if (p_dev == NULL) {
        BTIF_TRACE_ERROR("%s: Error, device %02X:%02X:%02X:%02X:%02X:%02X not opened.",
 (*bda)[0], (*bda)[1], (*bda)[2], (*bda)[3], (*bda)[4], (*bda)[5]);
 return BT_STATUS_FAIL;
 }

 else {
 int    hex_bytes_filled;
        UINT8  *hexbuf;
        UINT16 len = (strlen(data) + 1) / 2;

        hexbuf = GKI_getbuf(len);
 if (hexbuf == NULL) {
            BTIF_TRACE_ERROR("%s: Error, failed to allocate RPT buffer, len = %d",
                __FUNCTION__, len);
 return BT_STATUS_FAIL;
 }

 /* Build a SendData data buffer */
        memset(hexbuf, 0, len);
        hex_bytes_filled = ascii_2_hex(data, len, hexbuf);
        BTIF_TRACE_ERROR("Hex bytes filled, hex value: %d, %d", hex_bytes_filled, len);

 if (hex_bytes_filled) {
            BT_HDR* p_buf = create_pbuf(hex_bytes_filled, hexbuf);
 if (p_buf == NULL) {
                BTIF_TRACE_ERROR("%s: Error, failed to allocate RPT buffer, len = %d",
                                  __FUNCTION__, hex_bytes_filled);
                GKI_freebuf(hexbuf);
 return BT_STATUS_FAIL;
 }
            p_buf->layer_specific = BTA_HH_RPTT_OUTPUT;
            BTA_HhSendData(p_dev->dev_handle, *bda, p_buf);
            GKI_freebuf(hexbuf);
 return BT_STATUS_SUCCESS;
 }
        GKI_freebuf(hexbuf);
 return BT_STATUS_FAIL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MediaSource> ATSParser::getSource(SourceType type) {
 int which = -1; // any

 for (size_t i = 0; i < mPrograms.size(); ++i) {
 const sp<Program> &program = mPrograms.editItemAt(i);

 if (which >= 0 && (int)program->number() != which) {
 continue;
 }

        sp<MediaSource> source = program->getSource(type);

 if (source != NULL) {
 return source;
 }
 }

 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlFatalErr(xmlParserCtxtPtr ctxt, xmlParserErrors error, const char *info)
{
 const char *errmsg;

 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 switch (error) {
 case XML_ERR_INVALID_HEX_CHARREF:
            errmsg = "CharRef: invalid hexadecimal value";
 break;
 case XML_ERR_INVALID_DEC_CHARREF:
            errmsg = "CharRef: invalid decimal value";
 break;
 case XML_ERR_INVALID_CHARREF:
            errmsg = "CharRef: invalid value";
 break;
 case XML_ERR_INTERNAL_ERROR:
            errmsg = "internal error";
 break;
 case XML_ERR_PEREF_AT_EOF:
            errmsg = "PEReference at end of document";
 break;
 case XML_ERR_PEREF_IN_PROLOG:
            errmsg = "PEReference in prolog";
 break;
 case XML_ERR_PEREF_IN_EPILOG:
            errmsg = "PEReference in epilog";
 break;
 case XML_ERR_PEREF_NO_NAME:
            errmsg = "PEReference: no name";
 break;
 case XML_ERR_PEREF_SEMICOL_MISSING:
            errmsg = "PEReference: expecting ';'";
 break;
 case XML_ERR_ENTITY_LOOP:
            errmsg = "Detected an entity reference loop";
 break;
 case XML_ERR_ENTITY_NOT_STARTED:
            errmsg = "EntityValue: \" or ' expected";
 break;
 case XML_ERR_ENTITY_PE_INTERNAL:
            errmsg = "PEReferences forbidden in internal subset";
 break;
 case XML_ERR_ENTITY_NOT_FINISHED:
            errmsg = "EntityValue: \" or ' expected";
 break;
 case XML_ERR_ATTRIBUTE_NOT_STARTED:
            errmsg = "AttValue: \" or ' expected";
 break;
 case XML_ERR_LT_IN_ATTRIBUTE:
            errmsg = "Unescaped '<' not allowed in attributes values";
 break;
 case XML_ERR_LITERAL_NOT_STARTED:
            errmsg = "SystemLiteral \" or ' expected";
 break;
 case XML_ERR_LITERAL_NOT_FINISHED:
            errmsg = "Unfinished System or Public ID \" or ' expected";
 break;
 case XML_ERR_MISPLACED_CDATA_END:
            errmsg = "Sequence ']]>' not allowed in content";
 break;
 case XML_ERR_URI_REQUIRED:
            errmsg = "SYSTEM or PUBLIC, the URI is missing";
 break;
 case XML_ERR_PUBID_REQUIRED:
            errmsg = "PUBLIC, the Public Identifier is missing";
 break;
 case XML_ERR_HYPHEN_IN_COMMENT:
            errmsg = "Comment must not contain '--' (double-hyphen)";
 break;
 case XML_ERR_PI_NOT_STARTED:
            errmsg = "xmlParsePI : no target name";
 break;
 case XML_ERR_RESERVED_XML_NAME:
            errmsg = "Invalid PI name";
 break;
 case XML_ERR_NOTATION_NOT_STARTED:
            errmsg = "NOTATION: Name expected here";
 break;
 case XML_ERR_NOTATION_NOT_FINISHED:
            errmsg = "'>' required to close NOTATION declaration";
 break;
 case XML_ERR_VALUE_REQUIRED:
            errmsg = "Entity value required";
 break;
 case XML_ERR_URI_FRAGMENT:
            errmsg = "Fragment not allowed";
 break;
 case XML_ERR_ATTLIST_NOT_STARTED:
            errmsg = "'(' required to start ATTLIST enumeration";
 break;
 case XML_ERR_NMTOKEN_REQUIRED:
            errmsg = "NmToken expected in ATTLIST enumeration";
 break;
 case XML_ERR_ATTLIST_NOT_FINISHED:
            errmsg = "')' required to finish ATTLIST enumeration";
 break;
 case XML_ERR_MIXED_NOT_STARTED:
            errmsg = "MixedContentDecl : '|' or ')*' expected";
 break;
 case XML_ERR_PCDATA_REQUIRED:
            errmsg = "MixedContentDecl : '#PCDATA' expected";
 break;
 case XML_ERR_ELEMCONTENT_NOT_STARTED:
            errmsg = "ContentDecl : Name or '(' expected";
 break;
 case XML_ERR_ELEMCONTENT_NOT_FINISHED:
            errmsg = "ContentDecl : ',' '|' or ')' expected";
 break;
 case XML_ERR_PEREF_IN_INT_SUBSET:
            errmsg =
 "PEReference: forbidden within markup decl in internal subset";
 break;
 case XML_ERR_GT_REQUIRED:
            errmsg = "expected '>'";
 break;
 case XML_ERR_CONDSEC_INVALID:
            errmsg = "XML conditional section '[' expected";
 break;
 case XML_ERR_EXT_SUBSET_NOT_FINISHED:
            errmsg = "Content error in the external subset";
 break;
 case XML_ERR_CONDSEC_INVALID_KEYWORD:
            errmsg =
 "conditional section INCLUDE or IGNORE keyword expected";
 break;
 case XML_ERR_CONDSEC_NOT_FINISHED:
            errmsg = "XML conditional section not closed";
 break;
 case XML_ERR_XMLDECL_NOT_STARTED:
            errmsg = "Text declaration '<?xml' required";
 break;
 case XML_ERR_XMLDECL_NOT_FINISHED:
            errmsg = "parsing XML declaration: '?>' expected";
 break;
 case XML_ERR_EXT_ENTITY_STANDALONE:
            errmsg = "external parsed entities cannot be standalone";
 break;
 case XML_ERR_ENTITYREF_SEMICOL_MISSING:
            errmsg = "EntityRef: expecting ';'";
 break;
 case XML_ERR_DOCTYPE_NOT_FINISHED:
            errmsg = "DOCTYPE improperly terminated";
 break;
 case XML_ERR_LTSLASH_REQUIRED:
            errmsg = "EndTag: '</' not found";
 break;
 case XML_ERR_EQUAL_REQUIRED:
            errmsg = "expected '='";
 break;
 case XML_ERR_STRING_NOT_CLOSED:
            errmsg = "String not closed expecting \" or '";
 break;
 case XML_ERR_STRING_NOT_STARTED:
            errmsg = "String not started expecting ' or \"";
 break;
 case XML_ERR_ENCODING_NAME:
            errmsg = "Invalid XML encoding name";
 break;
 case XML_ERR_STANDALONE_VALUE:
            errmsg = "standalone accepts only 'yes' or 'no'";
 break;
 case XML_ERR_DOCUMENT_EMPTY:
            errmsg = "Document is empty";
 break;
 case XML_ERR_DOCUMENT_END:
            errmsg = "Extra content at the end of the document";
 break;
 case XML_ERR_NOT_WELL_BALANCED:
            errmsg = "chunk is not well balanced";
 break;
 case XML_ERR_EXTRA_CONTENT:
            errmsg = "extra content at the end of well balanced chunk";
 break;
 case XML_ERR_VERSION_MISSING:
            errmsg = "Malformed declaration expecting version";
 break;
 case XML_ERR_NAME_TOO_LONG:
            errmsg = "Name too long use XML_PARSE_HUGE option";
 break;
#if 0
 case:
            errmsg = "";
 break;
#endif
 default:
            errmsg = "Unregistered error message";
 }
 if (ctxt != NULL)
	ctxt->errNo = error;
 if (info == NULL) {
        __xmlRaiseError(NULL, NULL, NULL, ctxt, NULL, XML_FROM_PARSER, error,
                        XML_ERR_FATAL, NULL, 0, info, NULL, NULL, 0, 0, "%s\n",
                        errmsg);
 } else {
        __xmlRaiseError(NULL, NULL, NULL, ctxt, NULL, XML_FROM_PARSER, error,
                        XML_ERR_FATAL, NULL, 0, info, NULL, NULL, 0, 0, "%s: %s\n",
                        errmsg, info);
 }
 if (ctxt != NULL) {
	ctxt->wellFormed = 0;
 if (ctxt->recovery == 0)
	    ctxt->disableSAX = 1;
 }
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t CameraSource::isCameraAvailable(
 const sp<ICamera>& camera, const sp<ICameraRecordingProxy>& proxy,
 int32_t cameraId, const String16& clientName, uid_t clientUid) {

 if (camera == 0) {
        mCamera = Camera::connect(cameraId, clientName, clientUid);
 if (mCamera == 0) return -EBUSY;
        mCameraFlags &= ~FLAGS_HOT_CAMERA;
 } else {
        mCamera = Camera::create(camera);
 if (mCamera == 0) return -EBUSY;
        mCameraRecordingProxy = proxy;
        mCameraFlags |= FLAGS_HOT_CAMERA;
        mDeathNotifier = new DeathNotifier();
 IInterface::asBinder(mCameraRecordingProxy)->linkToDeath(mDeathNotifier);
 }

    mCamera->lock();

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void wifi_cleanup(wifi_handle handle, wifi_cleaned_up_handler handler)
{
    hal_info *info = getHalInfo(handle);
 char buf[64];

    info->cleaned_up_handler = handler;
 if (write(info->cleanup_socks[0], "Exit", 4) < 1) {
        ALOGE("could not write to the cleanup socket");
 } else {
        memset(buf, 0, sizeof(buf));
 int result = read(info->cleanup_socks[0], buf, sizeof(buf));
        ALOGE("%s: Read after POLL returned %d, error no = %d", __FUNCTION__, result, errno);
 if (strncmp(buf, "Done", 4) == 0) {
            ALOGE("Event processing terminated");
 } else {
            ALOGD("Rx'ed %s", buf);
 }
 }
    info->clean_up = true;
    pthread_mutex_lock(&info->cb_lock);

 int bad_commands = 0;

 for (int i = 0; i < info->num_event_cb; i++) {
        cb_info *cbi = &(info->event_cb[i]);
 WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;
        ALOGI("Command left in event_cb %p:%s", cmd, (cmd ? cmd->getType(): ""));
 }

 while (info->num_cmd > bad_commands) {
 int num_cmd = info->num_cmd;
        cmd_info *cmdi = &(info->cmd[bad_commands]);
 WifiCommand *cmd = cmdi->cmd;
 if (cmd != NULL) {
            ALOGI("Cancelling command %p:%s", cmd, cmd->getType());

             pthread_mutex_unlock(&info->cb_lock);
             cmd->cancel();
             pthread_mutex_lock(&info->cb_lock);
            /* release reference added when command is saved */
            cmd->releaseRef();
             if (num_cmd == info->num_cmd) {
                 ALOGI("Cancelling command %p:%s did not work", cmd, (cmd ? cmd->getType(): ""));
                 bad_commands++;
             }
         }
     }
 
 for (int i = 0; i < info->num_event_cb; i++) {
        cb_info *cbi = &(info->event_cb[i]);
 WifiCommand *cmd = (WifiCommand *)cbi->cb_arg;
        ALOGE("Leaked command %p", cmd);
 }
    pthread_mutex_unlock(&info->cb_lock);
    internal_cleaned_up_handler(handle);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual bool MyIpAddress(std::string* ip_address) {
    my_ip_address_count++;
 *ip_address = my_ip_address_result;
 return !my_ip_address_result.empty();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btif_get_adapter_properties(void)
{
    BTIF_TRACE_EVENT("%s", __FUNCTION__);

 if (!btif_is_enabled())
 return BT_STATUS_NOT_READY;

 return btif_transfer_context(execute_storage_request,
                                 BTIF_CORE_STORAGE_ADAPTER_READ_ALL,
                                 NULL, 0, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::start(MetaData *params) {
 Mutex::Autolock autoLock(mLock);

    CHECK(!mStarted);

 int32_t val;
 if (params && params->findInt32(kKeyWantsNALFragments, &val)
 && val != 0) {
        mWantsNALFragments = true;
 } else {
        mWantsNALFragments = false;
 }

    mGroup = new MediaBufferGroup;

 int32_t max_size;
    CHECK(mFormat->findInt32(kKeyMaxInputSize, &max_size));

    mGroup->add_buffer(new MediaBuffer(max_size));

    mSrcBuffer = new (std::nothrow) uint8_t[max_size];
 if (mSrcBuffer == NULL) {
 return ERROR_MALFORMED;
 }

    mStarted = true;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void get_token(FILE *pnm_file, char *token)
{
 int i = 0;
 int ret;

 /* remove white-space and comment lines */
 do
 {
    ret = fgetc(pnm_file);
 if (ret == '#') {
 /* the rest of this line is a comment */
 do
 {
        ret = fgetc(pnm_file);
 }
 while ((ret != '\n') && (ret != '\r') && (ret != EOF));
 }
 if (ret == EOF) break;
    token[i] = (unsigned char) ret;
 }
 while ((token[i] == '\n') || (token[i] == '\r') || (token[i] == ' '));

 /* read string */
 do
 {
    ret = fgetc(pnm_file);
 if (ret == EOF) break;
    i++;
    token[i] = (unsigned char) ret;
 }
 while ((token[i] != '\n') && (token[i] != '\r') && (token[i] != ' '));

  token[i] = '\0';

 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_move_to_secure_connections_phase2(tSMP_CB* p_cb,
                                           tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);
  smp_sm_event(p_cb, SMP_SC_PHASE1_CMPLT_EVT, NULL);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftHEVC::~SoftHEVC() {
    ALOGV("In SoftHEVC::~SoftHEVC");
    CHECK_EQ(deInitDecoder(), (status_t)OK);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void h264bsdFreeDpb(dpbStorage_t *dpb)
{

/* Variables */

    u32 i;

/* Code */

    ASSERT(dpb);

 if (dpb->buffer)
 {
 for (i = 0; i < dpb->dpbSize+1; i++)
 {
            FREE(dpb->buffer[i].pAllocatedData);
 }
 }
    FREE(dpb->buffer);
    FREE(dpb->list);
    FREE(dpb->outBuf);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int add_remove_audio_effect(const struct audio_stream *stream,
 effect_handle_t effect,
 bool enable)
{
 struct stream_in *in = (struct stream_in *)stream;
 struct audio_device *adev = in->dev;
 int status = 0;
 effect_descriptor_t desc;
#ifdef PREPROCESSING_ENABLED
 int i;
#endif
    status = (*effect)->get_descriptor(effect, &desc);
 if (status != 0)
 return status;

    ALOGI("add_remove_audio_effect(), effect type: %08x, enable: %d ", desc.type.timeLow, enable);

    pthread_mutex_lock(&adev->lock_inputs);
    lock_input_stream(in);
    pthread_mutex_lock(&in->dev->lock);
#ifndef PREPROCESSING_ENABLED
 if ((in->source == AUDIO_SOURCE_VOICE_COMMUNICATION) &&
            in->enable_aec != enable &&
 (memcmp(&desc.type, FX_IID_AEC, sizeof(effect_uuid_t)) == 0)) {
        in->enable_aec = enable;
 if (!in->standby)
            select_devices(in->dev, in->usecase);
 }
#else
 if (enable) {
 if (in->num_preprocessors >= MAX_PREPROCESSORS) {
            status = -ENOSYS;
 goto exit;
 }
        in->preprocessors[in->num_preprocessors].effect_itfe = effect;
        in->num_preprocessors ++;
 /* check compatibility between main channel supported and possible auxiliary channels */
        in_update_aux_channels(in, effect);//wesley crash
        in->aux_channels_changed = true;
 } else {
 /* if ( enable == false ) */
 if (in->num_preprocessors <= 0) {
            status = -ENOSYS;
 goto exit;
 }
        status = -EINVAL;
 for (i = 0; i < in->num_preprocessors && status != 0; i++) {
 if ( in->preprocessors[i].effect_itfe == effect ) {
                ALOGV("add_remove_audio_effect found fx at index %d", i);
                free(in->preprocessors[i].channel_configs);
                in->num_preprocessors--;
                memcpy(in->preprocessors + i,
                       in->preprocessors + i + 1,
 (in->num_preprocessors - i) * sizeof(in->preprocessors[0]));
                memset(in->preprocessors + in->num_preprocessors,
 0,
 sizeof(in->preprocessors[0]));
                status = 0;
 }
 }
 if (status != 0)
 goto exit;
        in->aux_channels_changed = false;
        ALOGV("%s: enable(%d), in->aux_channels_changed(%d)",
              __func__, enable, in->aux_channels_changed);
 }
    ALOGI("%s:  num_preprocessors = %d", __func__, in->num_preprocessors);

exit:
#endif
    ALOGW_IF(status != 0, "add_remove_audio_effect() error %d", status);
    pthread_mutex_unlock(&in->dev->lock);
    pthread_mutex_unlock(&in->lock);
    pthread_mutex_unlock(&adev->lock_inputs);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::postReadBuffer(media_track_type trackType) {
 Mutex::Autolock _l(mReadBufferLock);

 if ((mPendingReadBufferTypes & (1 << trackType)) == 0) {
        mPendingReadBufferTypes |= (1 << trackType);
        sp<AMessage> msg = new AMessage(kWhatReadBuffer, id());
        msg->setInt32("trackType", trackType);
        msg->post();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SampleTable::setSyncSampleParams(off64_t data_offset, size_t data_size) {
 if (mSyncSampleOffset >= 0 || data_size < 8) {
 return ERROR_MALFORMED;
 }

 uint8_t header[8];
 if (mDataSource->readAt(
                data_offset, header, sizeof(header)) < (ssize_t)sizeof(header)) {
 return ERROR_IO;
 }

 if (U32_AT(header) != 0) {
 return ERROR_MALFORMED;
 }

 uint32_t numSyncSamples = U32_AT(&header[4]);

 if (numSyncSamples < 2) {
        ALOGV("Table of sync samples is empty or has only a single entry!");
 }

 uint64_t allocSize = (uint64_t)numSyncSamples * sizeof(uint32_t);
 if (allocSize > kMaxTotalSize) {
        ALOGE("Sync sample table size too large.");
 return ERROR_OUT_OF_RANGE;
 }

    mTotalSize += allocSize;
 if (mTotalSize > kMaxTotalSize) {
        ALOGE("Sync sample table size would make sample table too large.\n"
 "    Requested sync sample table size = %llu\n"
 "    Eventual sample table size >= %llu\n"
 "    Allowed sample table size = %llu\n",
 (unsigned long long)allocSize,
 (unsigned long long)mTotalSize,
 (unsigned long long)kMaxTotalSize);
 return ERROR_OUT_OF_RANGE;
 }

    mSyncSamples = new (std::nothrow) uint32_t[numSyncSamples];
 if (!mSyncSamples) {
        ALOGE("Cannot allocate sync sample table with %llu entries.",
 (unsigned long long)numSyncSamples);
 return ERROR_OUT_OF_RANGE;
 }

 
     if (mDataSource->readAt(data_offset + 8, mSyncSamples,
             (size_t)allocSize) != (ssize_t)allocSize) {
        delete mSyncSamples;
         mSyncSamples = NULL;
         return ERROR_IO;
     }

 for (size_t i = 0; i < numSyncSamples; ++i) {
 if (mSyncSamples[i] == 0) {
            ALOGE("b/32423862, unexpected zero value in stss");
 continue;
 }
        mSyncSamples[i] = ntohl(mSyncSamples[i]) - 1;
 }

    mSyncSampleOffset = data_offset;
    mNumSyncSamples = numSyncSamples;

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int main(int argc, char **argv)
{
 int count = COUNT;

 while (argc > 1)
 {
 if (argc > 2 && strcmp(argv[1], "-c") == 0)
 {
         count = atoi(argv[2]);
         argc -= 2;
         argv += 2;
 }

 else if (strcmp(argv[1], "-v") == 0)
 {
 ++verbose;
 --argc;
 ++argv;
 }

 else
 break;
 }

 if (count > 0 && argc > 1)
 {
 if (strcmp(argv[1], "ascii") == 0)
 return validation_ascii_to_fp(count, argc-1, argv+1);
 else if (strcmp(argv[1], "checkfp") == 0)
 return validation_checkfp(count, argc-1, argv+1);
 else if (strcmp(argv[1], "muldiv") == 0)
 return validation_muldiv(count, argc-1, argv+1);
 else if (strcmp(argv[1], "gamma") == 0)
 return validation_gamma(argc-1, argv+1);
 }

 /* Bad argument: */
   fprintf(stderr,
 "usage: tarith [-v] [-c count] {ascii,muldiv,gamma} [args]\n");
   fprintf(stderr, " arguments: ascii [-a (all results)] [-e error%%]\n");
   fprintf(stderr, "            checkfp [-l max-number-chars]\n");
   fprintf(stderr, "            muldiv\n");
   fprintf(stderr, "            gamma -s (silent) -g (only gamma; no log)\n");
 return 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:      BufferMeta(size_t size, OMX_U32 portIndex)
         : mSize(size),
          mIsBackup(false),
          mPortIndex(portIndex) {
     }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static char* allocFromUTF16(const char16_t* in, size_t len)

 {
     if (len == 0) return getEmptyString();
 
    const ssize_t bytes = utf16_to_utf8_length(in, len);
    if (bytes < 0) {
         return getEmptyString();
     }
 
    SharedBuffer* buf = SharedBuffer::alloc(bytes+1);
     ALOG_ASSERT(buf, "Unable to allocate shared buffer");
     if (!buf) {
         return getEmptyString();
     }
 
    char* str = (char*)buf->data();
    utf16_to_utf8(in, len, str);
    return str;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool config_get_bool(const config_t *config, const char *section, const char *key, bool def_value) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);

 entry_t *entry = entry_find(config, section, key);
 if (!entry)
 return def_value;

 if (!strcmp(entry->value, "true"))
 return true;
 if (!strcmp(entry->value, "false"))
 return false;

 return def_value;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t IPCThreadState::writeTransactionData(int32_t cmd, uint32_t binderFlags,
 int32_t handle, uint32_t code, const Parcel& data, status_t* statusBuffer)
{
    binder_transaction_data tr;

    tr.target.ptr = 0; /* Don't pass uninitialized stack data to a remote process */
    tr.target.handle = handle;
    tr.code = code;
    tr.flags = binderFlags;
    tr.cookie = 0;
    tr.sender_pid = 0;
    tr.sender_euid = 0;
 
 const status_t err = data.errorCheck();
 if (err == NO_ERROR) {
        tr.data_size = data.ipcDataSize();
        tr.data.ptr.buffer = data.ipcData();
        tr.offsets_size = data.ipcObjectsCount()*sizeof(binder_size_t);
        tr.data.ptr.offsets = data.ipcObjects();
 } else if (statusBuffer) {
        tr.flags |= TF_STATUS_CODE;
 *statusBuffer = err;
        tr.data_size = sizeof(status_t);
        tr.data.ptr.buffer = reinterpret_cast<uintptr_t>(statusBuffer);
        tr.offsets_size = 0;
        tr.data.ptr.offsets = 0;
 } else {
 return (mLastError = err);
 }
 
    mOut.writeInt32(cmd);
    mOut.write(&tr, sizeof(tr));
 
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void From2iToMono_32( const LVM_INT32 *src,
                            LVM_INT32 *dst,
                            LVM_INT16 n)
{
   LVM_INT16 ii;
   LVM_INT32 Temp;

 for (ii = n; ii != 0; ii--)
 {
 Temp = (*src>>1);
       src++;

 Temp +=(*src>>1);
       src++;

 *dst = Temp;
       dst++;
 }

 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uch *readpng_get_image(double display_exponent, int *pChannels, ulg *pRowbytes)
{
    ulg  rowbytes;


 /* expand palette images to RGB, low-bit-depth grayscale images to 8 bits,
     * transparency chunks to full alpha channel; strip 16-bit-per-sample
     * images to 8 bits per sample; and convert grayscale to RGB[A] */

 /* GRR WARNING:  grayscale needs to be expanded and channels reset! */

 *pRowbytes = rowbytes = channels*width;
 *pChannels = channels;

 if ((image_data = (uch *)malloc(rowbytes*height)) == NULL) {
 return NULL;
 }

 Trace((stderr, "readpng_get_image:  rowbytes = %ld, height = %ld\n", rowbytes, height));


 
     /* now we can go ahead and just read the whole image */
 
    fread(image_data, 1L, rowbytes*height, saved_infile);
 
     return image_data;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  ContentEncoding::GetCompressionByIndex(unsigned long idx) const {
   const ptrdiff_t count = compression_entries_end_ - compression_entries_;
  assert(count >= 0);

 if (idx >= static_cast<unsigned long>(count))
 return NULL;

 return compression_entries_[idx];
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Chapters::Atom::Init()
{
    m_string_uid = NULL;
    m_uid = 0;
    m_start_timecode = -1;
    m_stop_timecode = -1;
    m_displays = NULL;
    m_displays_size = 0;
    m_displays_count = 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int omx_vdec::alloc_map_ion_memory(OMX_U32 buffer_size,
        OMX_U32 alignment, struct ion_allocation_data *alloc_data,
 struct ion_fd_data *fd_data, int flag)
{
 int fd = -EINVAL;
 int rc = -EINVAL;
 int ion_dev_flag;
 struct vdec_ion ion_buf_info;
 if (!alloc_data || buffer_size <= 0 || !fd_data) {
        DEBUG_PRINT_ERROR("Invalid arguments to alloc_map_ion_memory");
 return -EINVAL;
 }
    ion_dev_flag = O_RDONLY;
    fd = open (MEM_DEVICE, ion_dev_flag);
 if (fd < 0) {
        DEBUG_PRINT_ERROR("opening ion device failed with fd = %d", fd);
 return fd;
 }
    alloc_data->flags = 0;
 if (!secure_mode && (flag & ION_FLAG_CACHED)) {
        alloc_data->flags |= ION_FLAG_CACHED;
 }
    alloc_data->len = buffer_size;
    alloc_data->align = clip2(alignment);
 if (alloc_data->align < 4096) {
        alloc_data->align = 4096;
 }
 if ((secure_mode) && (flag & ION_SECURE))
        alloc_data->flags |= ION_SECURE;

    alloc_data->ION_HEAP_MASK = ION_HEAP(ION_IOMMU_HEAP_ID);
 if (secure_mode && (alloc_data->flags & ION_SECURE))
        alloc_data->ION_HEAP_MASK = ION_HEAP(MEM_HEAP_ID);
    rc = ioctl(fd,ION_IOC_ALLOC,alloc_data);
 if (rc || !alloc_data->handle) {
        DEBUG_PRINT_ERROR("ION ALLOC memory failed");
        alloc_data->handle = 0;
        close(fd);
        fd = -ENOMEM;
 return fd;
 }
    fd_data->handle = alloc_data->handle;
    rc = ioctl(fd,ION_IOC_MAP,fd_data);
 if (rc) {
        DEBUG_PRINT_ERROR("ION MAP failed ");
        ion_buf_info.ion_alloc_data = *alloc_data;
        ion_buf_info.ion_device_fd = fd;
        ion_buf_info.fd_ion_data = *fd_data;
        free_ion_memory(&ion_buf_info);
        fd_data->fd =-1;
        fd = -ENOMEM;
 }

 return fd;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Bitmap_hasMipMap(JNIEnv* env, jobject, jlong bitmapHandle) {
 SkBitmap* bitmap = reinterpret_cast<SkBitmap*>(bitmapHandle);
 return bitmap->hasHardwareMipMap() ? JNI_TRUE : JNI_FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t StreamingProcessor::startStream(StreamType type,
 const Vector<int32_t> &outputStreams) {
    ATRACE_CALL();
 status_t res;

 if (type == NONE) return INVALID_OPERATION;

    sp<CameraDeviceBase> device = mDevice.promote();
 if (device == 0) {
        ALOGE("%s: Camera %d: Device does not exist", __FUNCTION__, mId);
 return INVALID_OPERATION;
 }

    ALOGV("%s: Camera %d: type = %d", __FUNCTION__, mId, type);

 Mutex::Autolock m(mMutex);

 bool isRecordingStreamIdle = !isStreamActive(mActiveStreamIds, mRecordingStreamId);
 bool startRecordingStream = isStreamActive(outputStreams, mRecordingStreamId);
 if (startRecordingStream && isRecordingStreamIdle) {
        releaseAllRecordingFramesLocked();
 }

    ALOGV("%s: Camera %d: %s started, recording heap has %zu free of %zu",
            __FUNCTION__, mId, (type == PREVIEW) ? "preview" : "recording",
            mRecordingHeapFree, mRecordingHeapCount);

 CameraMetadata &request = (type == PREVIEW) ?
            mPreviewRequest : mRecordingRequest;

    res = request.update(
        ANDROID_REQUEST_OUTPUT_STREAMS,
        outputStreams);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to set up preview request: %s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

    res = request.sort();
 if (res != OK) {
        ALOGE("%s: Camera %d: Error sorting preview request: %s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }

    res = device->setStreamingRequest(request);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to set preview request to start preview: "
 "%s (%d)",
                __FUNCTION__, mId, strerror(-res), res);
 return res;
 }
    mActiveRequest = type;
    mPaused = false;
    mActiveStreamIds = outputStreams;
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Parcel::readFileDescriptor() const
{
 const flat_binder_object* flat = readObject(true);

 if (flat && flat->type == BINDER_TYPE_FD) {
 return flat->handle;
 }

 return BAD_TYPE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Visualizer_process(
 effect_handle_t self,audio_buffer_t *inBuffer, audio_buffer_t *outBuffer)
{
 VisualizerContext * pContext = (VisualizerContext *)self;

 if (pContext == NULL) {
 return -EINVAL;
 }

 if (inBuffer == NULL || inBuffer->raw == NULL ||
        outBuffer == NULL || outBuffer->raw == NULL ||
        inBuffer->frameCount != outBuffer->frameCount ||
        inBuffer->frameCount == 0) {
 return -EINVAL;
 }

 if (pContext->mMeasurementMode & MEASUREMENT_MODE_PEAK_RMS) {
 uint32_t inIdx;
 int16_t maxSample = 0;
 float rmsSqAcc = 0;
 for (inIdx = 0 ; inIdx < inBuffer->frameCount * pContext->mChannelCount ; inIdx++) {
 if (inBuffer->s16[inIdx] > maxSample) {
                maxSample = inBuffer->s16[inIdx];
 } else if (-inBuffer->s16[inIdx] > maxSample) {
                maxSample = -inBuffer->s16[inIdx];
 }
            rmsSqAcc += (inBuffer->s16[inIdx] * inBuffer->s16[inIdx]);
 }
        pContext->mPastMeasurements[pContext->mMeasurementBufferIdx].mPeakU16 = (uint16_t)maxSample;
        pContext->mPastMeasurements[pContext->mMeasurementBufferIdx].mRmsSquared =
                rmsSqAcc / (inBuffer->frameCount * pContext->mChannelCount);
        pContext->mPastMeasurements[pContext->mMeasurementBufferIdx].mIsValid = true;
 if (++pContext->mMeasurementBufferIdx >= pContext->mMeasurementWindowSizeInBuffers) {
            pContext->mMeasurementBufferIdx = 0;
 }
 }

 int32_t shift;

 if (pContext->mScalingMode == VISUALIZER_SCALING_MODE_NORMALIZED) {
        shift = 32;
 int len = inBuffer->frameCount * 2;
 for (int i = 0; i < len; i++) {
 int32_t smp = inBuffer->s16[i];
 if (smp < 0) smp = -smp - 1; // take care to keep the max negative in range
 int32_t clz = __builtin_clz(smp);
 if (shift > clz) shift = clz;
 }
        shift = 25 - shift;
 if (shift < 3) {
            shift = 3;
 }
        shift++;
 } else {
        assert(pContext->mScalingMode == VISUALIZER_SCALING_MODE_AS_PLAYED);
        shift = 9;
 }

 uint32_t captIdx;
 uint32_t inIdx;
 uint8_t *buf = pContext->mCaptureBuf;
 for (inIdx = 0, captIdx = pContext->mCaptureIdx;
         inIdx < inBuffer->frameCount;
         inIdx++, captIdx++) {
 if (captIdx >= CAPTURE_BUF_SIZE) {
            captIdx = 0;
 }
 int32_t smp = inBuffer->s16[2 * inIdx] + inBuffer->s16[2 * inIdx + 1];
        smp = smp >> shift;
        buf[captIdx] = ((uint8_t)smp)^0x80;
 }

    pContext->mCaptureIdx = captIdx;
 if (clock_gettime(CLOCK_MONOTONIC, &pContext->mBufferUpdateTime) < 0) {
        pContext->mBufferUpdateTime.tv_sec = 0;
 }

 if (inBuffer->raw != outBuffer->raw) {
 if (pContext->mConfig.outputCfg.accessMode == EFFECT_BUFFER_ACCESS_ACCUMULATE) {
 for (size_t i = 0; i < outBuffer->frameCount*2; i++) {
                outBuffer->s16[i] = clamp16(outBuffer->s16[i] + inBuffer->s16[i]);
 }
 } else {
            memcpy(outBuffer->raw, inBuffer->raw, outBuffer->frameCount * 2 * sizeof(int16_t));
 }
 }
 if (pContext->mState != VISUALIZER_STATE_ACTIVE) {
 return -ENODATA;
 }
 return 0;
} // end Visualizer_process

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gp_g16(Pixel *p, png_const_voidp pb)
{
   png_const_uint_16p pp = voidcast(png_const_uint_16p, pb);

   p->r = p->g = p->b = pp[0];
   p->a = 65535;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera2Client::startRecordingL(Parameters &params, bool restart) {
 status_t res;

    ALOGV("%s: state == %d, restart = %d", __FUNCTION__, params.state, restart);

 switch (params.state) {
 case Parameters::STOPPED:
            res = startPreviewL(params, false);
 if (res != OK) return res;
 break;
 case Parameters::PREVIEW:
 break;
 case Parameters::RECORD:
 case Parameters::VIDEO_SNAPSHOT:
 if (!restart) return OK;
 break;
 default:
            ALOGE("%s: Camera %d: Can't start recording in state %s",
                    __FUNCTION__, mCameraId,
 Parameters::getStateName(params.state));
 return INVALID_OPERATION;
 };

 if (!params.storeMetadataInBuffers) {
        ALOGE("%s: Camera %d: Recording only supported in metadata mode, but "
 "non-metadata recording mode requested!", __FUNCTION__,
                mCameraId);
 return INVALID_OPERATION;
 }

 if (!restart) {
        mCameraService->playSound(CameraService::SOUND_RECORDING);
        mStreamingProcessor->updateRecordingRequest(params);
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to update recording request: %s (%d)",
                    __FUNCTION__, mCameraId, strerror(-res), res);
 return res;
 }
 }

 if (mCallbackProcessor->getStreamId() != NO_STREAM) {
        ALOGV("%s: Camera %d: Clearing out callback stream before "
 "creating recording stream", __FUNCTION__, mCameraId);
        res = mStreamingProcessor->stopStream();
 if (res != OK) {
            ALOGE("%s: Camera %d: Can't stop streaming to delete callback stream",
                    __FUNCTION__, mCameraId);
 return res;
 }
        res = mCallbackProcessor->deleteStream();
 if (res != OK) {
            ALOGE("%s: Camera %d: Unable to delete callback stream before "
 "record: %s (%d)", __FUNCTION__, mCameraId,
                    strerror(-res), res);
 return res;
 }
 }
    params.previewCallbackFlags = 0;

    res = updateProcessorStream<
 StreamingProcessor,
 &StreamingProcessor::updateRecordingStream>(mStreamingProcessor,
                                                        params);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to update recording stream: %s (%d)",
                __FUNCTION__, mCameraId, strerror(-res), res);
 return res;
 }

 Vector<int32_t> outputStreams;
    outputStreams.push(getPreviewStreamId());
    outputStreams.push(getRecordingStreamId());

    res = mStreamingProcessor->startStream(StreamingProcessor::RECORD,
            outputStreams);
 if (res != OK) {
        ALOGE("%s: Camera %d: Unable to start recording stream: %s (%d)",
                __FUNCTION__, mCameraId, strerror(-res), res);
 return res;
 }

 if (params.state < Parameters::RECORD) {
        params.state = Parameters::RECORD;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static int a2dp_ctrl_receive(struct a2dp_stream_common *common, void* buffer, int length)
 {
    int ret = recv(common->ctrl_fd, buffer, length, MSG_NOSIGNAL);
     if (ret < 0)
     {
         ERROR("ack failed (%s)", strerror(errno));
         if (errno == EINTR)
         {
             /* retry again */
            ret = recv(common->ctrl_fd, buffer, length, MSG_NOSIGNAL);
             if (ret < 0)
             {
                ERROR("ack failed (%s)", strerror(errno));
               skt_disconnect(common->ctrl_fd);
               common->ctrl_fd = AUDIO_SKT_DISCONNECTED;
 return -1;
 }
 }
 else
 {
               skt_disconnect(common->ctrl_fd);
               common->ctrl_fd = AUDIO_SKT_DISCONNECTED;
 return -1;

 }
 }
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftMP3::~SoftMP3() {
 if (mDecoderBuf != NULL) {
        free(mDecoderBuf);
        mDecoderBuf = NULL;
 }

 delete mConfig;
    mConfig = NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static struct node* acquire_or_create_child_locked(
 struct fuse* fuse, struct node* parent,
 const char* name, const char* actual_name)
{
 struct node* child = lookup_child_by_name_locked(parent, name);
 if (child) {
        acquire_node_locked(child);
 } else {
        child = create_node_locked(fuse, parent, name, actual_name);
 }
 return child;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::setHandle(OMX::node_id node_id, OMX_HANDLETYPE handle) {
    mNodeID = node_id;
    CLOG_LIFE(allocateNode, "handle=%p", handle);
    CHECK(mHandle == NULL);
    mHandle = handle;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: MediaPlayer* CameraService::newMediaPlayer(const char *file) {
 MediaPlayer* mp = new MediaPlayer();
 if (mp->setDataSource(file, NULL) == NO_ERROR) {
        mp->setAudioStreamType(AUDIO_STREAM_ENFORCED_AUDIBLE);
        mp->prepare();
 } else {
        ALOGE("Failed to load CameraService sounds: %s", file);
 return NULL;
 }
 return mp;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCreatePushParserCtxt(xmlSAXHandlerPtr sax, void *user_data,
 const char *chunk, int size, const char *filename) {
    xmlParserCtxtPtr ctxt;
    xmlParserInputPtr inputStream;
    xmlParserInputBufferPtr buf;
    xmlCharEncoding enc = XML_CHAR_ENCODING_NONE;

 /*
     * plug some encoding conversion routines
     */
 if ((chunk != NULL) && (size >= 4))
	enc = xmlDetectCharEncoding((const xmlChar *) chunk, size);

    buf = xmlAllocParserInputBuffer(enc);
 if (buf == NULL) return(NULL);

    ctxt = xmlNewParserCtxt();
 if (ctxt == NULL) {
        xmlErrMemory(NULL, "creating parser: out of memory\n");
	xmlFreeParserInputBuffer(buf);
 return(NULL);
 }
    ctxt->dictNames = 1;
    ctxt->pushTab = (void **) xmlMalloc(ctxt->nameMax * 3 * sizeof(xmlChar *));
 if (ctxt->pushTab == NULL) {
        xmlErrMemory(ctxt, NULL);
	xmlFreeParserInputBuffer(buf);
	xmlFreeParserCtxt(ctxt);
 return(NULL);
 }
 if (sax != NULL) {
#ifdef LIBXML_SAX1_ENABLED
 if (ctxt->sax != (xmlSAXHandlerPtr) &xmlDefaultSAXHandler)
#endif /* LIBXML_SAX1_ENABLED */
	    xmlFree(ctxt->sax);
	ctxt->sax = (xmlSAXHandlerPtr) xmlMalloc(sizeof(xmlSAXHandler));
 if (ctxt->sax == NULL) {
	    xmlErrMemory(ctxt, NULL);
	    xmlFreeParserInputBuffer(buf);
	    xmlFreeParserCtxt(ctxt);
 return(NULL);
 }
	memset(ctxt->sax, 0, sizeof(xmlSAXHandler));
 if (sax->initialized == XML_SAX2_MAGIC)
	    memcpy(ctxt->sax, sax, sizeof(xmlSAXHandler));
 else
	    memcpy(ctxt->sax, sax, sizeof(xmlSAXHandlerV1));
 if (user_data != NULL)
	    ctxt->userData = user_data;
 }
 if (filename == NULL) {
	ctxt->directory = NULL;
 } else {
        ctxt->directory = xmlParserGetDirectory(filename);
 }

    inputStream = xmlNewInputStream(ctxt);
 if (inputStream == NULL) {
	xmlFreeParserCtxt(ctxt);
	xmlFreeParserInputBuffer(buf);
 return(NULL);
 }

 if (filename == NULL)
	inputStream->filename = NULL;
 else {
	inputStream->filename = (char *)
	    xmlCanonicPath((const xmlChar *) filename);
 if (inputStream->filename == NULL) {
	    xmlFreeParserCtxt(ctxt);
	    xmlFreeParserInputBuffer(buf);
 return(NULL);
 }
 }
    inputStream->buf = buf;
    xmlBufResetInput(inputStream->buf->buffer, inputStream);
    inputPush(ctxt, inputStream);

 /*
     * If the caller didn't provide an initial 'chunk' for determining
     * the encoding, we set the context to XML_CHAR_ENCODING_NONE so
     * that it can be automatically determined later
     */
 if ((size == 0) || (chunk == NULL)) {
	ctxt->charset = XML_CHAR_ENCODING_NONE;
 } else if ((ctxt->input != NULL) && (ctxt->input->buf != NULL)) {
 size_t base = xmlBufGetInputBase(ctxt->input->buf->buffer, ctxt->input);
 size_t cur = ctxt->input->cur - ctxt->input->base;

	xmlParserInputBufferPush(ctxt->input->buf, size, chunk);

        xmlBufSetInputBaseCur(ctxt->input->buf->buffer, ctxt->input, base, cur);
#ifdef DEBUG_PUSH
	xmlGenericError(xmlGenericErrorContext, "PP: pushed %d\n", size);
#endif
 }

 if (enc != XML_CHAR_ENCODING_NONE) {
        xmlSwitchEncoding(ctxt, enc);
 }

 return(ctxt);
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  static void CopyElementsImpl(FixedArrayBase* from, uint32_t from_start,
 FixedArrayBase* to, ElementsKind from_kind,
 uint32_t to_start, int packed_size,
 int copy_size) {
 DisallowHeapAllocation no_allocation;
 switch (from_kind) {
 case FAST_SMI_ELEMENTS:
 CopyPackedSmiToDoubleElements(from, from_start, to, to_start,
                                      packed_size, copy_size);
 break;
 case FAST_HOLEY_SMI_ELEMENTS:
 CopySmiToDoubleElements(from, from_start, to, to_start, copy_size);
 break;
 case FAST_DOUBLE_ELEMENTS:
 case FAST_HOLEY_DOUBLE_ELEMENTS:
 CopyDoubleToDoubleElements(from, from_start, to, to_start, copy_size);
 break;
 case FAST_ELEMENTS:
 case FAST_HOLEY_ELEMENTS:
 CopyObjectToDoubleElements(from, from_start, to, to_start, copy_size);
 break;
 case DICTIONARY_ELEMENTS:
 CopyDictionaryToDoubleElements(from, from_start, to, to_start,
                                       copy_size);
 break;
 case FAST_SLOPPY_ARGUMENTS_ELEMENTS:
 case SLOW_SLOPPY_ARGUMENTS_ELEMENTS:
 case FAST_STRING_WRAPPER_ELEMENTS:
 case SLOW_STRING_WRAPPER_ELEMENTS:
 case NO_ELEMENTS:
#define TYPED_ARRAY_CASE(Type, type, TYPE, ctype, size) case TYPE##_ELEMENTS:
      TYPED_ARRAYS(TYPED_ARRAY_CASE)
#undef TYPED_ARRAY_CASE
      UNREACHABLE();
 break;
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: CameraClient::~CameraClient() {
 Mutex* lock = mCameraService->getClientLockById(mCameraId);
    lock->lock();
    mDestructionStarted = true;
    lock->unlock();
 int callingPid = getCallingPid();
    LOG1("CameraClient::~CameraClient E (pid %d, this %p)", callingPid, this);

    disconnect();
    LOG1("CameraClient::~CameraClient X (pid %d, this %p)", callingPid, this);

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const binder_size_t* Parcel::objects() const
{
 return mObjects;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_dec_seq_scale_ext(dec_state_t *ps_dec)
{
    UNUSED(ps_dec);
 return IMPEG2D_SCALABILITIY_NOT_SUPPORTED;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t IPCThreadState::executeCommand(int32_t cmd)
{
 BBinder* obj;
 RefBase::weakref_type* refs;
 status_t result = NO_ERROR;
 
 switch ((uint32_t)cmd) {
 case BR_ERROR:
        result = mIn.readInt32();
 break;
 
 case BR_OK:
 break;
 
 case BR_ACQUIRE:
        refs = (RefBase::weakref_type*)mIn.readPointer();
        obj = (BBinder*)mIn.readPointer();
        ALOG_ASSERT(refs->refBase() == obj,
 "BR_ACQUIRE: object %p does not match cookie %p (expected %p)",
                   refs, obj, refs->refBase());
        obj->incStrong(mProcess.get());
        IF_LOG_REMOTEREFS() {
            LOG_REMOTEREFS("BR_ACQUIRE from driver on %p", obj);
            obj->printRefs();
 }
        mOut.writeInt32(BC_ACQUIRE_DONE);
        mOut.writePointer((uintptr_t)refs);
        mOut.writePointer((uintptr_t)obj);
 break;
 
 case BR_RELEASE:
        refs = (RefBase::weakref_type*)mIn.readPointer();
        obj = (BBinder*)mIn.readPointer();
        ALOG_ASSERT(refs->refBase() == obj,
 "BR_RELEASE: object %p does not match cookie %p (expected %p)",
                   refs, obj, refs->refBase());
        IF_LOG_REMOTEREFS() {
            LOG_REMOTEREFS("BR_RELEASE from driver on %p", obj);
            obj->printRefs();
 }
        mPendingStrongDerefs.push(obj);
 break;
 
 case BR_INCREFS:
        refs = (RefBase::weakref_type*)mIn.readPointer();
        obj = (BBinder*)mIn.readPointer();
        refs->incWeak(mProcess.get());
        mOut.writeInt32(BC_INCREFS_DONE);
        mOut.writePointer((uintptr_t)refs);
        mOut.writePointer((uintptr_t)obj);
 break;
 
 case BR_DECREFS:
        refs = (RefBase::weakref_type*)mIn.readPointer();
        obj = (BBinder*)mIn.readPointer();
        mPendingWeakDerefs.push(refs);
 break;
 
 case BR_ATTEMPT_ACQUIRE:
        refs = (RefBase::weakref_type*)mIn.readPointer();
        obj = (BBinder*)mIn.readPointer();
 
 {
 const bool success = refs->attemptIncStrong(mProcess.get());
            ALOG_ASSERT(success && refs->refBase() == obj,
 "BR_ATTEMPT_ACQUIRE: object %p does not match cookie %p (expected %p)",
                       refs, obj, refs->refBase());
 
            mOut.writeInt32(BC_ACQUIRE_RESULT);
            mOut.writeInt32((int32_t)success);
 }
 break;
 
 case BR_TRANSACTION:
 {
            binder_transaction_data tr;
            result = mIn.read(&tr, sizeof(tr));
            ALOG_ASSERT(result == NO_ERROR,
 "Not enough command data for brTRANSACTION");
 if (result != NO_ERROR) break;
 
 Parcel buffer;
            buffer.ipcSetDataReference(
 reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer),
                tr.data_size,
 reinterpret_cast<const binder_size_t*>(tr.data.ptr.offsets),
                tr.offsets_size/sizeof(binder_size_t), freeBuffer, this);
 
 const pid_t origPid = mCallingPid;
 const uid_t origUid = mCallingUid;
 const int32_t origStrictModePolicy = mStrictModePolicy;
 const int32_t origTransactionBinderFlags = mLastTransactionBinderFlags;

            mCallingPid = tr.sender_pid;
            mCallingUid = tr.sender_euid;
            mLastTransactionBinderFlags = tr.flags;

 int curPrio = getpriority(PRIO_PROCESS, mMyThreadId);
 if (gDisableBackgroundScheduling) {
 if (curPrio > ANDROID_PRIORITY_NORMAL) {
                    setpriority(PRIO_PROCESS, mMyThreadId, ANDROID_PRIORITY_NORMAL);
 }
 } else {
 if (curPrio >= ANDROID_PRIORITY_BACKGROUND) {
                    set_sched_policy(mMyThreadId, SP_BACKGROUND);
 }
 }


 Parcel reply;
 status_t error;
            IF_LOG_TRANSACTIONS() {
 TextOutput::Bundle _b(alog);
                alog << "BR_TRANSACTION thr " << (void*)pthread_self()
 << " / obj " << tr.target.ptr << " / code "
 << TypeCode(tr.code) << ": " << indent << buffer
 << dedent << endl
 << "Data addr = "
 << reinterpret_cast<const uint8_t*>(tr.data.ptr.buffer)
 << ", offsets addr="

                     << reinterpret_cast<const size_t*>(tr.data.ptr.offsets) << endl;
             }
             if (tr.target.ptr) {
                sp<BBinder> b((BBinder*)tr.cookie);
                error = b->transact(tr.code, buffer, &reply, tr.flags);
 
             } else {
                 error = the_context_object->transact(tr.code, buffer, &reply, tr.flags);
 }

 
 if ((tr.flags & TF_ONE_WAY) == 0) {
                LOG_ONEWAY("Sending reply to %d!", mCallingPid);
 if (error < NO_ERROR) reply.setError(error);
                sendReply(reply, 0);
 } else {
                LOG_ONEWAY("NOT sending reply to %d!", mCallingPid);
 }
 
            mCallingPid = origPid;
            mCallingUid = origUid;
            mStrictModePolicy = origStrictModePolicy;
            mLastTransactionBinderFlags = origTransactionBinderFlags;

            IF_LOG_TRANSACTIONS() {
 TextOutput::Bundle _b(alog);
                alog << "BC_REPLY thr " << (void*)pthread_self() << " / obj "
 << tr.target.ptr << ": " << indent << reply << dedent << endl;
 }
 
 }
 break;
 
 case BR_DEAD_BINDER:
 {
 BpBinder *proxy = (BpBinder*)mIn.readPointer();
            proxy->sendObituary();
            mOut.writeInt32(BC_DEAD_BINDER_DONE);
            mOut.writePointer((uintptr_t)proxy);
 } break;
 
 case BR_CLEAR_DEATH_NOTIFICATION_DONE:
 {
 BpBinder *proxy = (BpBinder*)mIn.readPointer();
            proxy->getWeakRefs()->decWeak(proxy);
 } break;
 
 case BR_FINISHED:
        result = TIMED_OUT;
 break;
 
 case BR_NOOP:
 break;
 
 case BR_SPAWN_LOOPER:
        mProcess->spawnPooledThread(false);
 break;
 
 default:
        printf("*** BAD COMMAND %d received from Binder driver\n", cmd);
        result = UNKNOWN_ERROR;
 break;
 }

 if (result != NO_ERROR) {
        mLastError = result;
 }
 
 return result;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: unsigned venc_dev::venc_stop_done(void)
{
 struct venc_msg venc_msg;
    free_extradata();
    venc_msg.msgcode=VEN_MSG_STOP;
    venc_msg.statuscode=VEN_S_SUCCESS;
    venc_handle->async_message_process(venc_handle,&venc_msg);
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int add_camera_metadata_entry_raw(camera_metadata_t *dst,
 uint32_t tag,
 uint8_t  type,
 const void *data,
 size_t data_count) {

 if (dst == NULL) return ERROR;
 if (dst->entry_count == dst->entry_capacity) return ERROR;
 if (data_count && data == NULL) return ERROR;

 size_t data_bytes =
            calculate_camera_metadata_entry_data_size(type, data_count);
 if (data_bytes + dst->data_count > dst->data_capacity) return ERROR;

 size_t data_payload_bytes =
            data_count * camera_metadata_type_size[type];
 camera_metadata_buffer_entry_t *entry = get_entries(dst) + dst->entry_count;
    memset(entry, 0, sizeof(camera_metadata_buffer_entry_t));
    entry->tag = tag;
    entry->type = type;
    entry->count = data_count;

 if (data_bytes == 0) {
        memcpy(entry->data.value, data,
                data_payload_bytes);
 } else {
        entry->data.offset = dst->data_count;
        memcpy(get_data(dst) + entry->data.offset, data,
                data_payload_bytes);
        dst->data_count += data_bytes;
 }
    dst->entry_count++;
    dst->flags &= ~FLAG_SORTED;
    assert(validate_camera_metadata_structure(dst, NULL) == OK);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char* SegmentInfo::GetMuxingAppAsUTF8() const
{
    return m_pMuxingAppAsUTF8;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::writeDouble(double val)
{
 return writeAligned(val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int out_add_audio_effect(const struct audio_stream *stream, effect_handle_t effect)
{
    UNUSED(stream);
    UNUSED(effect);

    FNLOG();
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readDouble(double *pArg) const
{
 union {
 double d;
 unsigned long long ll;
 } u;
    u.d = 0;
 status_t status;
    status = readAligned(&u.ll);
 *pArg = u.d;
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t IPCThreadState::transact(int32_t handle,
 uint32_t code, const Parcel& data,
 Parcel* reply, uint32_t flags)
{
 status_t err = data.errorCheck();

    flags |= TF_ACCEPT_FDS;

    IF_LOG_TRANSACTIONS() {
 TextOutput::Bundle _b(alog);
        alog << "BC_TRANSACTION thr " << (void*)pthread_self() << " / hand "
 << handle << " / code " << TypeCode(code) << ": "
 << indent << data << dedent << endl;
 }
 
 if (err == NO_ERROR) {
        LOG_ONEWAY(">>>> SEND from pid %d uid %d %s", getpid(), getuid(),
 (flags & TF_ONE_WAY) == 0 ? "READ REPLY" : "ONE WAY");
        err = writeTransactionData(BC_TRANSACTION, flags, handle, code, data, NULL);
 }
 
 if (err != NO_ERROR) {
 if (reply) reply->setError(err);
 return (mLastError = err);
 }
 
 if ((flags & TF_ONE_WAY) == 0) {
 #if 0
 if (code == 4) { // relayout
            ALOGI(">>>>>> CALLING transaction 4");
 } else {
            ALOGI(">>>>>> CALLING transaction %d", code);
 }
 #endif
 if (reply) {
            err = waitForResponse(reply);
 } else {
 Parcel fakeReply;
            err = waitForResponse(&fakeReply);
 }
 #if 0
 if (code == 4) { // relayout
            ALOGI("<<<<<< RETURNING transaction 4");
 } else {
            ALOGI("<<<<<< RETURNING transaction %d", code);
 }
 #endif
 
        IF_LOG_TRANSACTIONS() {
 TextOutput::Bundle _b(alog);
            alog << "BR_REPLY thr " << (void*)pthread_self() << " / hand "
 << handle << ": ";
 if (reply) alog << indent << *reply << dedent << endl;
 else alog << "(none requested)" << endl;
 }
 } else {
        err = waitForResponse(NULL, NULL);
 }
 
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: releaseWakeLock() {
 if (s_callbacks.version >= 13) {
 int ret;
        ret = pthread_mutex_lock(&s_wakeLockCountMutex);
        assert(ret == 0);

 if (s_wakelock_count > 1) {
            s_wakelock_count--;
 } else {
            s_wakelock_count = 0;
            release_wake_lock(ANDROID_WAKE_LOCK_NAME);
 if (s_last_wake_timeout_info != NULL) {
                s_last_wake_timeout_info->userParam = (void *)1;
 }
 }

        ret = pthread_mutex_unlock(&s_wakeLockCountMutex);
        assert(ret == 0);
 } else {
        release_wake_lock(ANDROID_WAKE_LOCK_NAME);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_subframe_fixed_(FLAC__StreamDecoder *decoder, unsigned channel, unsigned bps, const unsigned order, FLAC__bool do_full_decode)
{
	FLAC__Subframe_Fixed *subframe = &decoder->private_->frame.subframes[channel].data.fixed;
	FLAC__int32 i32;
	FLAC__uint32 u32;
 unsigned u;

	decoder->private_->frame.subframes[channel].type = FLAC__SUBFRAME_TYPE_FIXED;

	subframe->residual = decoder->private_->residual[channel];
	subframe->order = order;

 /* read warm-up samples */
 for(u = 0; u < order; u++) {
 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i32, bps))
 return false; /* read_callback_ sets the state for us */
		subframe->warmup[u] = i32;
 }

 /* read entropy coding method info */
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &u32, FLAC__ENTROPY_CODING_METHOD_TYPE_LEN))
 return false; /* read_callback_ sets the state for us */
	subframe->entropy_coding_method.type = (FLAC__EntropyCodingMethodType)u32;
 switch(subframe->entropy_coding_method.type) {
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE:
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2:
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &u32, FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_ORDER_LEN))
 return false; /* read_callback_ sets the state for us */
			subframe->entropy_coding_method.data.partitioned_rice.order = u32;
			subframe->entropy_coding_method.data.partitioned_rice.contents = &decoder->private_->partitioned_rice_contents[channel];
 break;
 default:
			send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_UNPARSEABLE_STREAM);
			decoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;
 return true;
 }

 /* read residual */
 switch(subframe->entropy_coding_method.type) {
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE:
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2:
 if(!read_residual_partitioned_rice_(decoder, order, subframe->entropy_coding_method.data.partitioned_rice.order, &decoder->private_->partitioned_rice_contents[channel], decoder->private_->residual[channel], /*is_extended=*/subframe->entropy_coding_method.type == FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2))
 return false;
 break;
 default:
			FLAC__ASSERT(0);
 }

 /* decode the subframe */
 if(do_full_decode) {
		memcpy(decoder->private_->output[channel], subframe->warmup, sizeof(FLAC__int32) * order);
		FLAC__fixed_restore_signal(decoder->private_->residual[channel], decoder->private_->frame.header.blocksize-order, order, decoder->private_->output[channel]+order);
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int PreProcessingLib_Release(effect_handle_t interface)
{
 int status;
    ALOGV("EffectRelease start %p", interface);
 if (PreProc_Init() != 0) {
 return sInitStatus;
 }

 preproc_effect_t *fx = (preproc_effect_t *)interface;

 if (fx->session->io == 0) {
 return -EINVAL;
 }
 return Session_ReleaseEffect(fx->session, fx);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int main(int argc, char **argv) {
   FILE *infile = NULL;
  VpxVideoWriter *writer = NULL;
   vpx_codec_ctx_t codec;
   vpx_codec_enc_cfg_t cfg;
   vpx_image_t raw;
   vpx_codec_err_t res;
  vpx_fixed_buf_t stats = {0};
  VpxVideoInfo info = {0};
   const VpxInterface *encoder = NULL;
  int pass;
   const int fps = 30;        // TODO(dkovalev) add command line argument
   const int bitrate = 200;   // kbit/s TODO(dkovalev) add command line argument
   const char *const codec_arg = argv[1];
 const char *const width_arg = argv[2];
 const char *const height_arg = argv[3];
 const char *const infile_arg = argv[4];
 const char *const outfile_arg = argv[5];
  exec_name = argv[0];

 if (argc != 6)
    die("Invalid number of arguments.");

  encoder = get_vpx_encoder_by_name(codec_arg);

   if (!encoder)
     die("Unsupported codec.");
 
  info.codec_fourcc = encoder->fourcc;
  info.time_base.numerator = 1;
  info.time_base.denominator = fps;
  info.frame_width = strtol(width_arg, NULL, 0);
  info.frame_height = strtol(height_arg, NULL, 0);
 
  if (info.frame_width <= 0 ||
      info.frame_height <= 0 ||
      (info.frame_width % 2) != 0 ||
      (info.frame_height % 2) != 0) {
    die("Invalid frame size: %dx%d", info.frame_width, info.frame_height);
  }
 
  if (!vpx_img_alloc(&raw, VPX_IMG_FMT_I420, info.frame_width,
                                             info.frame_height, 1)) {
    die("Failed to allocate image", info.frame_width, info.frame_height);
  }
 
  writer = vpx_video_writer_open(outfile_arg, kContainerIVF, &info);
  if (!writer)
    die("Failed to open %s for writing", outfile_arg);
 
  printf("Using %s\n", vpx_codec_iface_name(encoder->interface()));
  res = vpx_codec_enc_config_default(encoder->interface(), &cfg, 0);
   if (res)
     die_codec(&codec, "Failed to get default codec config.");
 
  cfg.g_w = info.frame_width;
  cfg.g_h = info.frame_height;
  cfg.g_timebase.num = info.time_base.numerator;
  cfg.g_timebase.den = info.time_base.denominator;
   cfg.rc_target_bitrate = bitrate;
 
  for (pass = 0; pass < 2; ++pass) {
    int frame_count = 0;
 
    if (pass == 0) {
      cfg.g_pass = VPX_RC_FIRST_PASS;
    } else {
      cfg.g_pass = VPX_RC_LAST_PASS;
      cfg.rc_twopass_stats_in = stats;
    }
 
    if (!(infile = fopen(infile_arg, "rb")))
      die("Failed to open %s for reading", infile_arg);
    if (vpx_codec_enc_init(&codec, encoder->interface(), &cfg, 0))
      die_codec(&codec, "Failed to initialize encoder");
    while (vpx_img_read(&raw, infile)) {
      ++frame_count;
      if (pass == 0) {
        get_frame_stats(&codec, &raw, frame_count, 1, 0, VPX_DL_BEST_QUALITY,
                        &stats);
      } else {
        encode_frame(&codec, &raw, frame_count, 1, 0, VPX_DL_BEST_QUALITY,
                     writer);
      }
    }
    if (pass == 0) {
      get_frame_stats(&codec, NULL, frame_count, 1, 0, VPX_DL_BEST_QUALITY,
                      &stats);
    } else {
      printf("\n");
    }
    fclose(infile);
    printf("Pass %d complete. Processed %d frames.\n", pass + 1, frame_count);
    if (vpx_codec_destroy(&codec))
      die_codec(&codec, "Failed to destroy codec.");
  }
  vpx_img_free(&raw);
   free(stats.buf);
 
  vpx_video_writer_close(writer);
 
   return EXIT_SUCCESS;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static int in_standby(struct audio_stream *stream)
{
    UNUSED(stream);

    FNLOG();
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::setDataSource(
 const sp<IMediaHTTPService> &httpService,
 const char *url, const KeyedVector<String8, String8> *headers)
{

     ALOGV("setDataSource(%s)", url);
     status_t err = BAD_VALUE;
     if (url != NULL) {
        const sp<IMediaPlayerService>& service(getMediaPlayerService());
         if (service != 0) {
             sp<IMediaPlayer> player(service->create(this, mAudioSessionId));
             if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
 (NO_ERROR != player->setDataSource(httpService, url, headers))) {
                player.clear();
 }
            err = attachNewPlayer(player);
 }
 }
 return err;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: inline static status_t finish_unflatten_binder(
 BpBinder* /*proxy*/, const flat_binder_object& /*flat*/,
 const Parcel& /*in*/)
{
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void setup_decoding_thread_data(VP8D_COMP *pbi, MACROBLOCKD *xd, MB_ROW_DEC *mbrd, int count)
{
    VP8_COMMON *const pc = & pbi->common;
 int i;

 for (i = 0; i < count; i++)
 {
        MACROBLOCKD *mbd = &mbrd[i].mbd;
        mbd->subpixel_predict        = xd->subpixel_predict;
        mbd->subpixel_predict8x4     = xd->subpixel_predict8x4;
        mbd->subpixel_predict8x8     = xd->subpixel_predict8x8;
        mbd->subpixel_predict16x16   = xd->subpixel_predict16x16;

        mbd->mode_info_context = pc->mi   + pc->mode_info_stride * (i + 1);
        mbd->mode_info_stride  = pc->mode_info_stride;

        mbd->frame_type = pc->frame_type;
        mbd->pre = xd->pre;
        mbd->dst = xd->dst;

        mbd->segmentation_enabled    = xd->segmentation_enabled;
        mbd->mb_segement_abs_delta     = xd->mb_segement_abs_delta;
        memcpy(mbd->segment_feature_data, xd->segment_feature_data, sizeof(xd->segment_feature_data));

 /*signed char ref_lf_deltas[MAX_REF_LF_DELTAS];*/
        memcpy(mbd->ref_lf_deltas, xd->ref_lf_deltas, sizeof(xd->ref_lf_deltas));
 /*signed char mode_lf_deltas[MAX_MODE_LF_DELTAS];*/
        memcpy(mbd->mode_lf_deltas, xd->mode_lf_deltas, sizeof(xd->mode_lf_deltas));
 /*unsigned char mode_ref_lf_delta_enabled;
        unsigned char mode_ref_lf_delta_update;*/
        mbd->mode_ref_lf_delta_enabled    = xd->mode_ref_lf_delta_enabled;
        mbd->mode_ref_lf_delta_update    = xd->mode_ref_lf_delta_update;

        mbd->current_bc = &pbi->mbc[0];

        memcpy(mbd->dequant_y1_dc, xd->dequant_y1_dc, sizeof(xd->dequant_y1_dc));
        memcpy(mbd->dequant_y1, xd->dequant_y1, sizeof(xd->dequant_y1));
        memcpy(mbd->dequant_y2, xd->dequant_y2, sizeof(xd->dequant_y2));
        memcpy(mbd->dequant_uv, xd->dequant_uv, sizeof(xd->dequant_uv));

        mbd->fullpixel_mask = 0xffffffff;

 if (pc->full_pixel)
            mbd->fullpixel_mask = 0xfffffff8;

 }

 for (i = 0; i < pc->mb_rows; i++)
        pbi->mt_current_mb_col[i] = -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAAC2::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch ((int)index) {
 case OMX_IndexParamStandardComponentRole:
 {

             const OMX_PARAM_COMPONENTROLETYPE *roleParams =
                 (const OMX_PARAM_COMPONENTROLETYPE *)params;
 
             if (strncmp((const char *)roleParams->cRole,
                         "audio_decoder.aac",
                         OMX_MAX_STRINGNAME_SIZE - 1)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAac:
 {

             const OMX_AUDIO_PARAM_AACPROFILETYPE *aacParams =
                 (const OMX_AUDIO_PARAM_AACPROFILETYPE *)params;
 
             if (aacParams->nPortIndex != 0) {
                 return OMX_ErrorUndefined;
             }

 if (aacParams->eAACStreamFormat == OMX_AUDIO_AACStreamFormatMP4FF) {
                mIsADTS = false;
 } else if (aacParams->eAACStreamFormat
 == OMX_AUDIO_AACStreamFormatMP4ADTS) {
                mIsADTS = true;
 } else {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioAndroidAacPresentation:

         {
             const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *aacPresParams =
                     (const OMX_AUDIO_PARAM_ANDROID_AACPRESENTATIONTYPE *)params;
 if (aacPresParams->nMaxOutputChannels >= 0) {
 int max;
 if (aacPresParams->nMaxOutputChannels >= 8) { max = 8; }
 else if (aacPresParams->nMaxOutputChannels >= 6) { max = 6; }
 else if (aacPresParams->nMaxOutputChannels >= 2) { max = 2; }
 else {
                    max = aacPresParams->nMaxOutputChannels;
 }
                ALOGV("set nMaxOutputChannels=%d", max);
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_MAX_OUTPUT_CHANNELS, max);
 }
 bool updateDrcWrapper = false;
 if (aacPresParams->nDrcBoost >= 0) {
                ALOGV("set nDrcBoost=%d", aacPresParams->nDrcBoost);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_BOOST_FACTOR,
                        aacPresParams->nDrcBoost);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nDrcCut >= 0) {
                ALOGV("set nDrcCut=%d", aacPresParams->nDrcCut);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_ATT_FACTOR, aacPresParams->nDrcCut);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nHeavyCompression >= 0) {
                ALOGV("set nHeavyCompression=%d", aacPresParams->nHeavyCompression);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_HEAVY,
                        aacPresParams->nHeavyCompression);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nTargetReferenceLevel >= 0) {
                ALOGV("set nTargetReferenceLevel=%d", aacPresParams->nTargetReferenceLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_DESIRED_TARGET,
                        aacPresParams->nTargetReferenceLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nEncodedTargetLevel >= 0) {
                ALOGV("set nEncodedTargetLevel=%d", aacPresParams->nEncodedTargetLevel);
                mDrcWrap.setParam(DRC_PRES_MODE_WRAP_ENCODER_TARGET,
                        aacPresParams->nEncodedTargetLevel);
                updateDrcWrapper = true;
 }
 if (aacPresParams->nPCMLimiterEnable >= 0) {
                aacDecoder_SetParam(mAACDecoder, AAC_PCM_LIMITER_ENABLE,
 (aacPresParams->nPCMLimiterEnable != 0));
 }
 if (updateDrcWrapper) {
                mDrcWrap.update();
 }

 return OMX_ErrorNone;
 }

 case OMX_IndexParamAudioPcm:
 {

             const OMX_AUDIO_PARAM_PCMMODETYPE *pcmParams =
                 (OMX_AUDIO_PARAM_PCMMODETYPE *)params;
 
             if (pcmParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_BUFFERHEADERTYPE *OMXNodeInstance::findBufferHeader(OMX::buffer_id buffer) {
 if (buffer == 0) {
 return NULL;
 }
 Mutex::Autolock autoLock(mBufferIDLock);
 return mBufferIDToBufferHeader.valueFor(buffer);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_video::fill_buffer_done(OMX_HANDLETYPE hComp,
        OMX_BUFFERHEADERTYPE * buffer)
{
#ifdef _MSM8974_
 int index = buffer - m_out_mem_ptr;
#endif
    DEBUG_PRINT_LOW("fill_buffer_done: buffer->pBuffer[%p], flags=0x%x size = %u",
            buffer->pBuffer, (unsigned)buffer->nFlags, (unsigned int)buffer->nFilledLen);
 if (buffer == NULL || ((buffer - m_out_mem_ptr) > (int)m_sOutPortDef.nBufferCountActual)) {
 return OMX_ErrorBadParameter;
 }

    pending_output_buffers--;

 if(!secure_session) {
    extra_data_handle.create_extra_data(buffer);
#ifndef _MSM8974_
 if (buffer->nFlags & OMX_BUFFERFLAG_EXTRADATA) {
        DEBUG_PRINT_LOW("parsing extradata");
        extra_data_handle.parse_extra_data(buffer);
 }
#endif
 }

 /* For use buffer we need to copy the data */
 if (m_pCallbacks.FillBufferDone) {
 if (buffer->nFilledLen > 0) {
            m_fbd_count++;

 if (dev_get_output_log_flag()) {
                dev_output_log_buffers((const char*)buffer->pBuffer, buffer->nFilledLen);
 }
 }
#ifdef _MSM8974_
 if (buffer->nFlags & OMX_BUFFERFLAG_EXTRADATA) {
 if (!dev_handle_extradata((void *)buffer, index))
                DEBUG_PRINT_ERROR("Failed to parse extradata");

            dev_extradata_log_buffers((char *)(((unsigned long)buffer->pBuffer + buffer->nOffset +
                        buffer->nFilledLen + 3) & (~3)));
 }
#endif
        m_pCallbacks.FillBufferDone (hComp,m_app_data,buffer);
 } else {
 return OMX_ErrorBadParameter;
 }
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::parseAC3SpecificBox(
 off64_t offset, uint16_t sampleRate) {
 uint32_t size;
 const uint32_t kAC3SpecificBoxSize = 11;
 if (!mDataSource->getUInt32(offset, &size) || size < kAC3SpecificBoxSize) {
        ALOGE("MPEG4Extractor: error while reading ac-3 block: cannot read specific box size");
 return ERROR_MALFORMED;
 }

    offset += 4;
 uint32_t type;
 if (!mDataSource->getUInt32(offset, &type) || type != FOURCC('d', 'a', 'c', '3')) {
        ALOGE("MPEG4Extractor: error while reading ac-3 specific block: header not dac3");
 return ERROR_MALFORMED;
 }

    offset += 4;
 const uint32_t kAC3SpecificBoxPayloadSize = 3;
 uint8_t chunk[kAC3SpecificBoxPayloadSize];
 if (mDataSource->readAt(offset, chunk, sizeof(chunk)) != sizeof(chunk)) {
        ALOGE("MPEG4Extractor: error while reading ac-3 specific block: bitstream fields");
 return ERROR_MALFORMED;
 }

 ABitReader br(chunk, sizeof(chunk));
 static const unsigned channelCountTable[] = {2, 1, 2, 3, 3, 4, 4, 5};
 static const unsigned sampleRateTable[] = {48000, 44100, 32000};

 unsigned fscod = br.getBits(2);
 if (fscod == 3) {
        ALOGE("Incorrect fscod (3) in AC3 header");
 return ERROR_MALFORMED;
 }
 unsigned boxSampleRate = sampleRateTable[fscod];
 if (boxSampleRate != sampleRate) {
        ALOGE("sample rate mismatch: boxSampleRate = %d, sampleRate = %d",
            boxSampleRate, sampleRate);
 return ERROR_MALFORMED;
 }

 unsigned bsid = br.getBits(5);
 if (bsid > 8) {
        ALOGW("Incorrect bsid in AC3 header. Possibly E-AC-3?");
 return ERROR_MALFORMED;
 }

 unsigned bsmod __unused = br.getBits(3);

 unsigned acmod = br.getBits(3);
 unsigned lfeon = br.getBits(1);
 unsigned channelCount = channelCountTable[acmod] + lfeon;

 if (mLastTrack == NULL) {
 return ERROR_MALFORMED;
 }
    mLastTrack->meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_AUDIO_AC3);
    mLastTrack->meta->setInt32(kKeyChannelCount, channelCount);
    mLastTrack->meta->setInt32(kKeySampleRate, sampleRate);
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void a2dp_open_ctrl_path(struct a2dp_stream_common *common)
{
 int i;

 /* retry logic to catch any timing variations on control channel */
 for (i = 0; i < CTRL_CHAN_RETRY_COUNT; i++)
 {
 /* connect control channel if not already connected */
 if ((common->ctrl_fd = skt_connect(A2DP_CTRL_PATH, common->buffer_sz)) > 0)
 {
 /* success, now check if stack is ready */
 if (check_a2dp_ready(common) == 0)

                 break;
 
             ERROR("error : a2dp not ready, wait 250 ms and retry");
            usleep(250000);
             skt_disconnect(common->ctrl_fd);
             common->ctrl_fd = AUDIO_SKT_DISCONNECTED;
         }
 
         /* ctrl channel not ready, wait a bit */
        usleep(250000);
     }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int PreProcessingFx_Command(effect_handle_t  self,
 uint32_t            cmdCode,
 uint32_t            cmdSize,
 void *pCmdData,
 uint32_t *replySize,
 void *pReplyData)
{
 preproc_effect_t * effect = (preproc_effect_t *) self;
 int retsize;
 int status;

 if (effect == NULL){
 return -EINVAL;
 }


 switch (cmdCode){
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || *replySize != sizeof(int)){
 return -EINVAL;
 }
 if (effect->ops->init) {
                effect->ops->init(effect);
 }
 *(int *)pReplyData = 0;
 break;

 case EFFECT_CMD_SET_CONFIG: {
 if (pCmdData    == NULL||
                cmdSize     != sizeof(effect_config_t)||
                pReplyData  == NULL||
 *replySize  != sizeof(int)){
                ALOGV("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_SET_CONFIG: ERROR");
 return -EINVAL;
 }
#ifdef DUAL_MIC_TEST
 uint32_t enabledMsk = effect->session->enabledMsk;
 if (gDualMicEnabled) {
                effect->session->enabledMsk = 0;
 }
#endif
 *(int *)pReplyData = Session_SetConfig(effect->session, (effect_config_t *)pCmdData);
#ifdef DUAL_MIC_TEST
 if (gDualMicEnabled) {
                effect->session->enabledMsk = enabledMsk;
 }
#endif
 if (*(int *)pReplyData != 0) {
 break;
 }
 if (effect->state != PREPROC_EFFECT_STATE_ACTIVE) {
 *(int *)pReplyData = Effect_SetState(effect, PREPROC_EFFECT_STATE_CONFIG);
 }
 } break;

 case EFFECT_CMD_GET_CONFIG:
 if (pReplyData == NULL ||
 *replySize != sizeof(effect_config_t)) {
                ALOGV("\tLVM_ERROR : PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_GET_CONFIG: ERROR");
 return -EINVAL;
 }

 Session_GetConfig(effect->session, (effect_config_t *)pReplyData);
 break;

 case EFFECT_CMD_SET_CONFIG_REVERSE:
 if (pCmdData == NULL ||
                cmdSize != sizeof(effect_config_t) ||
                pReplyData == NULL ||
 *replySize != sizeof(int)) {
                ALOGV("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_SET_CONFIG_REVERSE: ERROR");
 return -EINVAL;
 }
 *(int *)pReplyData = Session_SetReverseConfig(effect->session,
 (effect_config_t *)pCmdData);
 if (*(int *)pReplyData != 0) {
 break;
 }
 break;

 case EFFECT_CMD_GET_CONFIG_REVERSE:
 if (pReplyData == NULL ||
 *replySize != sizeof(effect_config_t)){
                ALOGV("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_GET_CONFIG_REVERSE: ERROR");
 return -EINVAL;
 }
 Session_GetReverseConfig(effect->session, (effect_config_t *)pCmdData);
 break;

 case EFFECT_CMD_RESET:
 if (effect->ops->reset) {
                effect->ops->reset(effect);

             }
             break;
 
        case EFFECT_CMD_GET_PARAM:{
            if (pCmdData == NULL ||
                    cmdSize < (int)sizeof(effect_param_t) ||
                    pReplyData == NULL ||
                    *replySize < (int)sizeof(effect_param_t)){
                 ALOGV("PreProcessingFx_Command cmdCode Case: "
                         "EFFECT_CMD_GET_PARAM: ERROR");
                 return -EINVAL;
             }
            effect_param_t *p = (effect_param_t *)pCmdData;
 
             memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + p->psize);
 
            p = (effect_param_t *)pReplyData;

 int voffset = ((p->psize - 1) / sizeof(int32_t) + 1) * sizeof(int32_t);

 if (effect->ops->get_parameter) {
                p->status = effect->ops->get_parameter(effect, p->data,
 &p->vsize,
                                                       p->data + voffset);
 *replySize = sizeof(effect_param_t) + voffset + p->vsize;
 }
 } break;

 
         case EFFECT_CMD_SET_PARAM:{
             if (pCmdData == NULL||
                    cmdSize < (int)sizeof(effect_param_t) ||
                    pReplyData == NULL ||
                     *replySize != sizeof(int32_t)){
                 ALOGV("PreProcessingFx_Command cmdCode Case: "
                         "EFFECT_CMD_SET_PARAM: ERROR");
 return -EINVAL;
 }
 effect_param_t *p = (effect_param_t *) pCmdData;

 if (p->psize != sizeof(int32_t)){
                ALOGV("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_SET_PARAM: ERROR, psize is not sizeof(int32_t)");
 return -EINVAL;
 }
 if (effect->ops->set_parameter) {
 *(int *)pReplyData = effect->ops->set_parameter(effect,
 (void *)p->data,
                                                                p->data + p->psize);
 }

         } break;
 
         case EFFECT_CMD_ENABLE:
            if (pReplyData == NULL || *replySize != sizeof(int)){
                 ALOGV("PreProcessingFx_Command cmdCode Case: EFFECT_CMD_ENABLE: ERROR");
                 return -EINVAL;
             }
 *(int *)pReplyData = Effect_SetState(effect, PREPROC_EFFECT_STATE_ACTIVE);

             break;
 
         case EFFECT_CMD_DISABLE:
            if (pReplyData == NULL || *replySize != sizeof(int)){
                 ALOGV("PreProcessingFx_Command cmdCode Case: EFFECT_CMD_DISABLE: ERROR");
                 return -EINVAL;
             }
 *(int *)pReplyData  = Effect_SetState(effect, PREPROC_EFFECT_STATE_CONFIG);
 break;

 case EFFECT_CMD_SET_DEVICE:
 case EFFECT_CMD_SET_INPUT_DEVICE:
 if (pCmdData == NULL ||
                cmdSize != sizeof(uint32_t)) {
                ALOGV("PreProcessingFx_Command cmdCode Case: EFFECT_CMD_SET_DEVICE: ERROR");
 return -EINVAL;
 }

 if (effect->ops->set_device) {
                effect->ops->set_device(effect, *(uint32_t *)pCmdData);
 }
 break;

 case EFFECT_CMD_SET_VOLUME:
 case EFFECT_CMD_SET_AUDIO_MODE:
 break;

#ifdef DUAL_MIC_TEST
 case PREPROC_CMD_DUAL_MIC_ENABLE: {
 if (pCmdData == NULL|| cmdSize != sizeof(uint32_t) ||
                    pReplyData == NULL || replySize == NULL) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "PREPROC_CMD_DUAL_MIC_ENABLE: ERROR");
 *replySize = 0;
 return -EINVAL;
 }
            gDualMicEnabled = *(bool *)pCmdData;
 if (gDualMicEnabled) {
                effect->aux_channels_on = sHasAuxChannels[effect->procId];
 } else {
                effect->aux_channels_on = false;
 }
            effect->cur_channel_config = (effect->session->inChannelCount == 1) ?
                    CHANNEL_CFG_MONO : CHANNEL_CFG_STEREO;

            ALOGV("PREPROC_CMD_DUAL_MIC_ENABLE: %s", gDualMicEnabled ? "enabled" : "disabled");
 *replySize = sizeof(int);
 *(int *)pReplyData = 0;
 } break;
 case PREPROC_CMD_DUAL_MIC_PCM_DUMP_START: {
 if (pCmdData == NULL|| pReplyData == NULL || replySize == NULL) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "PREPROC_CMD_DUAL_MIC_PCM_DUMP_START: ERROR");
 *replySize = 0;
 return -EINVAL;
 }
            pthread_mutex_lock(&gPcmDumpLock);
 if (gPcmDumpFh != NULL) {
                fclose(gPcmDumpFh);
                gPcmDumpFh = NULL;
 }
 char *path = strndup((char *)pCmdData, cmdSize);
            gPcmDumpFh = fopen((char *)path, "wb");
            pthread_mutex_unlock(&gPcmDumpLock);
            ALOGV("PREPROC_CMD_DUAL_MIC_PCM_DUMP_START: path %s gPcmDumpFh %p",
                  path, gPcmDumpFh);
            ALOGE_IF(gPcmDumpFh <= 0, "gPcmDumpFh open error %d %s", errno, strerror(errno));
            free(path);
 *replySize = sizeof(int);
 *(int *)pReplyData = 0;
 } break;
 case PREPROC_CMD_DUAL_MIC_PCM_DUMP_STOP: {
 if (pReplyData == NULL || replySize == NULL) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "PREPROC_CMD_DUAL_MIC_PCM_DUMP_STOP: ERROR");
 *replySize = 0;
 return -EINVAL;
 }
            pthread_mutex_lock(&gPcmDumpLock);
 if (gPcmDumpFh != NULL) {
                fclose(gPcmDumpFh);
                gPcmDumpFh = NULL;
 }
            pthread_mutex_unlock(&gPcmDumpLock);
            ALOGV("PREPROC_CMD_DUAL_MIC_PCM_DUMP_STOP");
 *replySize = sizeof(int);
 *(int *)pReplyData = 0;
 } break;

 case EFFECT_CMD_GET_FEATURE_SUPPORTED_CONFIGS: {
 if(!gDualMicEnabled) {
 return -EINVAL;
 }
 if (pCmdData == NULL|| cmdSize != 2 * sizeof(uint32_t) ||
                    pReplyData == NULL || replySize == NULL) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_GET_FEATURE_SUPPORTED_CONFIGS: ERROR");
 *replySize = 0;
 return -EINVAL;
 }
 if (*(uint32_t *)pCmdData != EFFECT_FEATURE_AUX_CHANNELS ||
 !effect->aux_channels_on) {
                ALOGV("PreProcessingFx_Command feature EFFECT_FEATURE_AUX_CHANNELS not supported by"
 " fx %d", effect->procId);
 *(uint32_t *)pReplyData = -ENOSYS;
 *replySize = sizeof(uint32_t);
 break;
 }
 size_t num_configs = *((uint32_t *)pCmdData + 1);
 if (*replySize < (2 * sizeof(uint32_t) +
                              num_configs * sizeof(channel_config_t))) {
 *replySize = 0;
 return -EINVAL;
 }

 *((uint32_t *)pReplyData + 1) = CHANNEL_CFG_CNT;
 if (num_configs < CHANNEL_CFG_CNT ||
 *replySize < (2 * sizeof(uint32_t) +
                                     CHANNEL_CFG_CNT * sizeof(channel_config_t))) {
 *(uint32_t *)pReplyData = -ENOMEM;
 } else {
                num_configs = CHANNEL_CFG_CNT;
 *(uint32_t *)pReplyData = 0;
 }
            ALOGV("PreProcessingFx_Command EFFECT_CMD_GET_FEATURE_SUPPORTED_CONFIGS num config %d",
                  num_configs);

 *replySize = 2 * sizeof(uint32_t) + num_configs * sizeof(channel_config_t);
 *((uint32_t *)pReplyData + 1) = num_configs;
            memcpy((uint32_t *)pReplyData + 2, &sDualMicConfigs, num_configs * sizeof(channel_config_t));
 } break;
 case EFFECT_CMD_GET_FEATURE_CONFIG:
 if(!gDualMicEnabled) {
 return -EINVAL;
 }
 if (pCmdData == NULL|| cmdSize != sizeof(uint32_t) ||
                    pReplyData == NULL || replySize == NULL ||
 *replySize < sizeof(uint32_t) + sizeof(channel_config_t)) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_GET_FEATURE_CONFIG: ERROR");
 return -EINVAL;
 }
 if (*(uint32_t *)pCmdData != EFFECT_FEATURE_AUX_CHANNELS || !effect->aux_channels_on) {
 *(uint32_t *)pReplyData = -ENOSYS;
 *replySize = sizeof(uint32_t);
 break;
 }
            ALOGV("PreProcessingFx_Command EFFECT_CMD_GET_FEATURE_CONFIG");
 *(uint32_t *)pReplyData = 0;
 *replySize = sizeof(uint32_t) + sizeof(channel_config_t);
            memcpy((uint32_t *)pReplyData + 1,
 &sDualMicConfigs[effect->cur_channel_config],
 sizeof(channel_config_t));
 break;
 case EFFECT_CMD_SET_FEATURE_CONFIG: {
            ALOGV("PreProcessingFx_Command EFFECT_CMD_SET_FEATURE_CONFIG: "
 "gDualMicEnabled %d effect->aux_channels_on %d",
                  gDualMicEnabled, effect->aux_channels_on);
 if(!gDualMicEnabled) {
 return -EINVAL;
 }
 if (pCmdData == NULL|| cmdSize != (sizeof(uint32_t) + sizeof(channel_config_t)) ||
                    pReplyData == NULL || replySize == NULL ||
 *replySize < sizeof(uint32_t)) {
                ALOGE("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_SET_FEATURE_CONFIG: ERROR\n"
 "pCmdData %p cmdSize %d pReplyData %p replySize %p *replySize %d",
                        pCmdData, cmdSize, pReplyData, replySize, replySize ? *replySize : -1);
 return -EINVAL;
 }
 *replySize = sizeof(uint32_t);
 if (*(uint32_t *)pCmdData != EFFECT_FEATURE_AUX_CHANNELS || !effect->aux_channels_on) {
 *(uint32_t *)pReplyData = -ENOSYS;
                ALOGV("PreProcessingFx_Command cmdCode Case: "
 "EFFECT_CMD_SET_FEATURE_CONFIG: ERROR\n"
 "CmdData %d effect->aux_channels_on %d",
 *(uint32_t *)pCmdData, effect->aux_channels_on);
 break;
 }
 size_t i;
 for (i = 0; i < CHANNEL_CFG_CNT;i++) {
 if (memcmp((uint32_t *)pCmdData + 1,
 &sDualMicConfigs[i], sizeof(channel_config_t)) == 0) {
 break;
 }
 }
 if (i == CHANNEL_CFG_CNT) {
 *(uint32_t *)pReplyData = -EINVAL;
                ALOGW("PreProcessingFx_Command EFFECT_CMD_SET_FEATURE_CONFIG invalid config"
 "[%08x].[%08x]", *((uint32_t *)pCmdData + 1), *((uint32_t *)pCmdData + 2));
 } else {
                effect->cur_channel_config = i;
 *(uint32_t *)pReplyData = 0;
                ALOGV("PreProcessingFx_Command EFFECT_CMD_SET_FEATURE_CONFIG New config"
 "[%08x].[%08x]", sDualMicConfigs[i].main_channels, sDualMicConfigs[i].aux_channels);
 }
 } break;
#endif
 default:
 return -EINVAL;
 }
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: modifier_color_encoding_is_set(PNG_CONST png_modifier *pm)
 {
    return pm->current_gamma != 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: ACodec::BufferInfo *ACodec::dequeueBufferFromNativeWindow() {
 ANativeWindowBuffer *buf;
    CHECK(mNativeWindow.get() != NULL);

 if (mTunneled) {
        ALOGW("dequeueBufferFromNativeWindow() should not be called in tunnel"
 " video playback mode mode!");
 return NULL;
 }

 if (mFatalError) {
        ALOGW("not dequeuing from native window due to fatal error");
 return NULL;
 }

 int fenceFd = -1;
 do {
 status_t err = mNativeWindow->dequeueBuffer(mNativeWindow.get(), &buf, &fenceFd);
 if (err != 0) {
            ALOGE("dequeueBuffer failed: %s(%d).", asString(err), err);
 return NULL;
 }

 bool stale = false;
 for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
 BufferInfo *info = &mBuffers[kPortIndexOutput].editItemAt(i);

 if (info->mGraphicBuffer != NULL &&
                    info->mGraphicBuffer->handle == buf->handle) {
 if (info->mStatus != BufferInfo::OWNED_BY_NATIVE_WINDOW) {
                    ALOGI("dequeued stale buffer %p. discarding", buf);
                    stale = true;
 break;
 }

                ALOGV("dequeued buffer %p", info->mGraphicBuffer->getNativeBuffer());
                info->mStatus = BufferInfo::OWNED_BY_US;
                info->setWriteFence(fenceFd, "dequeueBufferFromNativeWindow");
                updateRenderInfoForDequeuedBuffer(buf, fenceFd, info);
 return info;
 }
 }

 if (!stale && (!storingMetadataInDecodedBuffers() || mLegacyAdaptiveExperiment)) {
            ALOGI("dequeued unrecognized (stale) buffer %p. discarding", buf);
            stale = true;
 }
 if (stale) {
            buf = NULL;
 }
 } while (buf == NULL);

 BufferInfo *oldest = NULL;
 for (size_t i = mBuffers[kPortIndexOutput].size(); i-- > 0;) {
 BufferInfo *info =
 &mBuffers[kPortIndexOutput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_NATIVE_WINDOW &&
 (oldest == NULL ||
             mDequeueCounter - info->mDequeuedAt >
                    mDequeueCounter - oldest->mDequeuedAt)) {
            oldest = info;
 }
 }

    CHECK(oldest != NULL);
    CHECK(storingMetadataInDecodedBuffers());

    oldest->mGraphicBuffer = new GraphicBuffer(buf, false);
    oldest->mStatus = BufferInfo::OWNED_BY_US;
    oldest->setWriteFence(fenceFd, "dequeueBufferFromNativeWindow for oldest");
    mRenderTracker.untrackFrame(oldest->mRenderInfo);
    oldest->mRenderInfo = NULL;

    mOMX->updateGraphicBufferInMeta(
            mNode, kPortIndexOutput, oldest->mGraphicBuffer,
            oldest->mBufferID);

 if (mOutputMetadataType == kMetadataBufferTypeGrallocSource) {
 VideoGrallocMetadata *grallocMeta =
 reinterpret_cast<VideoGrallocMetadata *>(oldest->mData->base());
        ALOGV("replaced oldest buffer #%u with age %u (%p/%p stored in %p)",
 (unsigned)(oldest - &mBuffers[kPortIndexOutput][0]),
                mDequeueCounter - oldest->mDequeuedAt,
 (void *)(uintptr_t)grallocMeta->pHandle,
                oldest->mGraphicBuffer->handle, oldest->mData->base());
 } else if (mOutputMetadataType == kMetadataBufferTypeANWBuffer) {
 VideoNativeMetadata *nativeMeta =
 reinterpret_cast<VideoNativeMetadata *>(oldest->mData->base());
        ALOGV("replaced oldest buffer #%u with age %u (%p/%p stored in %p)",
 (unsigned)(oldest - &mBuffers[kPortIndexOutput][0]),
                mDequeueCounter - oldest->mDequeuedAt,
 (void *)(uintptr_t)nativeMeta->pBuffer,
                oldest->mGraphicBuffer->getNativeBuffer(), oldest->mData->base());
 }

    updateRenderInfoForDequeuedBuffer(buf, fenceFd, oldest);
 return oldest;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void SoundTriggerHwService::sendCallbackEvent_l(const sp<CallbackEvent>& event)
{
    mCallbackThread->sendCallbackEvent(event);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void release_object(const sp<ProcessState>& proc,
 const flat_binder_object& obj, const void* who)
{
 switch (obj.type) {
 case BINDER_TYPE_BINDER:
 if (obj.binder) {
                LOG_REFS("Parcel %p releasing reference on local %p", who, obj.cookie);
 reinterpret_cast<IBinder*>(obj.cookie)->decStrong(who);
 }
 return;
 case BINDER_TYPE_WEAK_BINDER:
 if (obj.binder)
 reinterpret_cast<RefBase::weakref_type*>(obj.binder)->decWeak(who);
 return;
 case BINDER_TYPE_HANDLE: {
 const sp<IBinder> b = proc->getStrongProxyForHandle(obj.handle);
 if (b != NULL) {
                LOG_REFS("Parcel %p releasing reference on remote %p", who, b.get());
                b->decStrong(who);
 }
 return;
 }
 case BINDER_TYPE_WEAK_HANDLE: {
 const wp<IBinder> b = proc->getWeakProxyForHandle(obj.handle);
 if (b != NULL) b.get_refs()->decWeak(who);
 return;
 }
 case BINDER_TYPE_FD: {
 if (obj.cookie != 0) close(obj.handle);
 return;
 }
 }

    ALOGE("Invalid object type 0x%08x", obj.type);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftAACEncoder2::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mSignalledError) {
 return;
 }

 List<BufferInfo *> &inQueue = getPortQueue(0);
 List<BufferInfo *> &outQueue = getPortQueue(1);

 if (!mSentCodecSpecificData) {

 if (outQueue.empty()) {
 return;
 }

 if (AACENC_OK != aacEncEncode(mAACEncoder, NULL, NULL, NULL, NULL)) {
            ALOGE("Unable to initialize encoder for profile / sample-rate / bit-rate / channels");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 return;
 }

        OMX_U32 actualBitRate  = aacEncoder_GetParam(mAACEncoder, AACENC_BITRATE);
 if (mBitRate != actualBitRate) {
            ALOGW("Requested bitrate %u unsupported, using %u", mBitRate, actualBitRate);
 }

        AACENC_InfoStruct encInfo;
 if (AACENC_OK != aacEncInfo(mAACEncoder, &encInfo)) {
            ALOGE("Failed to get AAC encoder info");
            notify(OMX_EventError, OMX_ErrorUndefined, 0, NULL);
            mSignalledError = true;
 return;
 }

 
         BufferInfo *outInfo = *outQueue.begin();
         OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;
         outHeader->nFilledLen = encInfo.confSize;
         outHeader->nFlags = OMX_BUFFERFLAG_CODECCONFIG;
 
 uint8_t *out = outHeader->pBuffer + outHeader->nOffset;
        memcpy(out, encInfo.confBuf, encInfo.confSize);

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        mSentCodecSpecificData = true;
 }

 size_t numBytesPerInputFrame =
        mNumChannels * kNumSamplesPerFrame * sizeof(int16_t);

 if (mAACProfile == OMX_AUDIO_AACObjectELD && numBytesPerInputFrame > 512) {
        numBytesPerInputFrame = 512;
 }

 for (;;) {

 while (mInputSize < numBytesPerInputFrame) {

 if (mSawInputEOS || inQueue.empty()) {
 return;
 }

 BufferInfo *inInfo = *inQueue.begin();
            OMX_BUFFERHEADERTYPE *inHeader = inInfo->mHeader;

 const void *inData = inHeader->pBuffer + inHeader->nOffset;

 size_t copy = numBytesPerInputFrame - mInputSize;
 if (copy > inHeader->nFilledLen) {
                copy = inHeader->nFilledLen;
 }

 if (mInputFrame == NULL) {
                mInputFrame = new int16_t[numBytesPerInputFrame / sizeof(int16_t)];
 }

 if (mInputSize == 0) {
                mInputTimeUs = inHeader->nTimeStamp;
 }

            memcpy((uint8_t *)mInputFrame + mInputSize, inData, copy);
            mInputSize += copy;

            inHeader->nOffset += copy;
            inHeader->nFilledLen -= copy;

            inHeader->nTimeStamp +=
 (copy * 1000000ll / mSampleRate)
 / (mNumChannels * sizeof(int16_t));

 if (inHeader->nFilledLen == 0) {
 if (inHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                    mSawInputEOS = true;

                    memset((uint8_t *)mInputFrame + mInputSize,
 0,
                           numBytesPerInputFrame - mInputSize);

                    mInputSize = numBytesPerInputFrame;
 }

                inQueue.erase(inQueue.begin());
                inInfo->mOwnedByUs = false;
                notifyEmptyBufferDone(inHeader);

                inData = NULL;
                inHeader = NULL;
                inInfo = NULL;
 }
 }


 if (outQueue.empty()) {
 return;
 }

 BufferInfo *outInfo = *outQueue.begin();
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

 uint8_t *outPtr = (uint8_t *)outHeader->pBuffer + outHeader->nOffset;
 size_t outAvailable = outHeader->nAllocLen - outHeader->nOffset;

        AACENC_InArgs inargs;
        AACENC_OutArgs outargs;
        memset(&inargs, 0, sizeof(inargs));
        memset(&outargs, 0, sizeof(outargs));
        inargs.numInSamples = numBytesPerInputFrame / sizeof(int16_t);

 void* inBuffer[] = { (unsigned char *)mInputFrame };
        INT   inBufferIds[] = { IN_AUDIO_DATA };
        INT   inBufferSize[] = { (INT)numBytesPerInputFrame };
        INT   inBufferElSize[] = { sizeof(int16_t) };

        AACENC_BufDesc inBufDesc;
        inBufDesc.numBufs           = sizeof(inBuffer) / sizeof(void*);
        inBufDesc.bufs              = (void**)&inBuffer;
        inBufDesc.bufferIdentifiers = inBufferIds;
        inBufDesc.bufSizes          = inBufferSize;
        inBufDesc.bufElSizes        = inBufferElSize;

 void* outBuffer[] = { outPtr };
        INT   outBufferIds[] = { OUT_BITSTREAM_DATA };
        INT   outBufferSize[] = { 0 };
        INT   outBufferElSize[] = { sizeof(UCHAR) };

        AACENC_BufDesc outBufDesc;
        outBufDesc.numBufs           = sizeof(outBuffer) / sizeof(void*);
        outBufDesc.bufs              = (void**)&outBuffer;
        outBufDesc.bufferIdentifiers = outBufferIds;
        outBufDesc.bufSizes          = outBufferSize;
        outBufDesc.bufElSizes        = outBufferElSize;

        AACENC_ERROR encoderErr = AACENC_OK;
 size_t nOutputBytes = 0;

 do {
            memset(&outargs, 0, sizeof(outargs));

            outBuffer[0] = outPtr;
            outBufferSize[0] = outAvailable - nOutputBytes;

            encoderErr = aacEncEncode(mAACEncoder,
 &inBufDesc,
 &outBufDesc,
 &inargs,
 &outargs);

 if (encoderErr == AACENC_OK) {
                outPtr += outargs.numOutBytes;
                nOutputBytes += outargs.numOutBytes;

 if (outargs.numInSamples > 0) {
 int numRemainingSamples = inargs.numInSamples - outargs.numInSamples;
 if (numRemainingSamples > 0) {
                        memmove(mInputFrame,
 &mInputFrame[outargs.numInSamples],
 sizeof(int16_t) * numRemainingSamples);
 }
                    inargs.numInSamples -= outargs.numInSamples;
 }
 }
 } while (encoderErr == AACENC_OK && inargs.numInSamples > 0);

        outHeader->nFilledLen = nOutputBytes;

        outHeader->nFlags = OMX_BUFFERFLAG_ENDOFFRAME;

 if (mSawInputEOS) {
            outHeader->nFlags = OMX_BUFFERFLAG_EOS;
 }

        outHeader->nTimeStamp = mInputTimeUs;

#if 0
        ALOGI("sending %d bytes of data (time = %lld us, flags = 0x%08lx)",
              nOutputBytes, mInputTimeUs, outHeader->nFlags);

        hexdump(outHeader->pBuffer + outHeader->nOffset, outHeader->nFilledLen);
#endif

        outQueue.erase(outQueue.begin());
        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        outHeader = NULL;
        outInfo = NULL;

        mInputSize = 0;
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: xmlStringDecodeEntities(xmlParserCtxtPtr ctxt, const xmlChar *str, int what,
		        xmlChar end, xmlChar  end2, xmlChar end3) {
 if ((ctxt == NULL) || (str == NULL)) return(NULL);
 return(xmlStringLenDecodeEntities(ctxt, str, xmlStrlen(str), what,
           end, end2, end3));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_hh_co_open(UINT8 dev_handle, UINT8 sub_class, tBTA_HH_ATTR_MASK attr_mask,
                    UINT8 app_id)
{
    UINT32 i;
 btif_hh_device_t *p_dev = NULL;

 if (dev_handle == BTA_HH_INVALID_HANDLE) {
        APPL_TRACE_WARNING("%s: Oops, dev_handle (%d) is invalid...",
                           __FUNCTION__, dev_handle);
 return;
 }

 for (i = 0; i < BTIF_HH_MAX_HID; i++) {
        p_dev = &btif_hh_cb.devices[i];
 if (p_dev->dev_status != BTHH_CONN_STATE_UNKNOWN &&
            p_dev->dev_handle == dev_handle) {
            APPL_TRACE_WARNING("%s: Found an existing device with the same handle "
 "dev_status = %d",__FUNCTION__,
                                                                p_dev->dev_status);
            APPL_TRACE_WARNING("%s:     bd_addr = [%02X:%02X:%02X:%02X:%02X:]", __FUNCTION__,
                 p_dev->bd_addr.address[0], p_dev->bd_addr.address[1], p_dev->bd_addr.address[2],
                 p_dev->bd_addr.address[3], p_dev->bd_addr.address[4]);
                 APPL_TRACE_WARNING("%s:     attr_mask = 0x%04x, sub_class = 0x%02x, app_id = %d",

                                   __FUNCTION__, p_dev->attr_mask, p_dev->sub_class, p_dev->app_id);
 
             if(p_dev->fd<0) {
                p_dev->fd = open(dev_path, O_RDWR | O_CLOEXEC);
                 if (p_dev->fd < 0){
                     APPL_TRACE_ERROR("%s: Error: failed to open uhid, err:%s",
                                                                     __FUNCTION__,strerror(errno));
 return;
 }else
                    APPL_TRACE_DEBUG("%s: uhid fd = %d", __FUNCTION__, p_dev->fd);
 }

            p_dev->hh_keep_polling = 1;
            p_dev->hh_poll_thread_id = create_thread(btif_hh_poll_event_thread, p_dev);
 break;
 }
        p_dev = NULL;
 }

 if (p_dev == NULL) {
 for (i = 0; i < BTIF_HH_MAX_HID; i++) {
 if (btif_hh_cb.devices[i].dev_status == BTHH_CONN_STATE_UNKNOWN) {
                p_dev = &btif_hh_cb.devices[i];
                p_dev->dev_handle = dev_handle;
                p_dev->attr_mask  = attr_mask;
                p_dev->sub_class  = sub_class;
                p_dev->app_id     = app_id;
                p_dev->local_vup  = FALSE;

 
                 btif_hh_cb.device_num++;
                p_dev->fd = open(dev_path, O_RDWR | O_CLOEXEC);
                 if (p_dev->fd < 0){
                     APPL_TRACE_ERROR("%s: Error: failed to open uhid, err:%s",
                                                                     __FUNCTION__,strerror(errno));
 return;
 }else{
                    APPL_TRACE_DEBUG("%s: uhid fd = %d", __FUNCTION__, p_dev->fd);
                    p_dev->hh_keep_polling = 1;
                    p_dev->hh_poll_thread_id = create_thread(btif_hh_poll_event_thread, p_dev);
 }


 break;
 }
 }
 }

 if (p_dev == NULL) {
        APPL_TRACE_ERROR("%s: Error: too many HID devices are connected", __FUNCTION__);
 return;
 }

    p_dev->dev_status = BTHH_CONN_STATE_CONNECTED;
    APPL_TRACE_DEBUG("%s: Return device status %d", __FUNCTION__, p_dev->dev_status);
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void smp_set_local_oob_keys(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);

  memcpy(p_cb->sc_oob_data.loc_oob_data.private_key_used, p_cb->private_key,
         BT_OCTET32_LEN);
  p_cb->sc_oob_data.loc_oob_data.publ_key_used = p_cb->loc_publ_key;
  smp_start_nonce_generation(p_cb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::CommandEntry* InputDispatcher::postCommandLocked(Command command) {
 CommandEntry* commandEntry = new CommandEntry(command);
    mCommandQueue.enqueueAtTail(commandEntry);
 return commandEntry;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CameraSource::DeathNotifier::binderDied(const wp<IBinder>& who __unused) {
    ALOGI("Camera recording proxy died");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void ToColor_S4444_Opaque(SkColor dst[], const void* src, int width,
 SkColorTable*) {
 SkASSERT(width > 0);
 const SkPMColor16* s = (const SkPMColor16*)src;
 do {
 SkPMColor c = SkPixel4444ToPixel32(*s++);
 *dst++ = SkColorSetRGB(SkGetPackedR32(c), SkGetPackedG32(c),
 SkGetPackedB32(c));
 } while (--width != 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_link_encrypted(const RawAddress& bda, uint8_t encr_enable) {
  tSMP_CB* p_cb = &smp_cb;

  SMP_TRACE_DEBUG("%s: encr_enable=%d", __func__, encr_enable);

 if (smp_cb.pairing_bda == bda) {
 /* encryption completed with STK, remember the key size now, could be
     * overwritten when key exchange happens                                 */
 if (p_cb->loc_enc_size != 0 && encr_enable) {
 /* update the link encryption key size if a SMP pairing just performed */
      btm_ble_update_sec_key_size(bda, p_cb->loc_enc_size);
 }

    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = encr_enable;
    smp_sm_event(&smp_cb, SMP_ENCRYPTED_EVT, &smp_int_data);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void  btm_keypress_notif_evt (UINT8 *p)
{
    tBTM_SP_KEYPRESS    evt_data;
    UINT8 *p_bda;

 /* parse & report BTM_SP_KEYPRESS_EVT */
 if (btm_cb.api.p_sp_callback)
 {
        p_bda = evt_data.bd_addr;

        STREAM_TO_BDADDR (p_bda, p);
        evt_data.notif_type = *p;

 (*btm_cb.api.p_sp_callback) (BTM_SP_KEYPRESS_EVT, (tBTM_SP_EVT_DATA *)&evt_data);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int readpng_init(FILE *infile, ulg *pWidth, ulg *pHeight)
{
    uch sig[8];


 /* first do a quick check that the file really is a PNG image; could
     * have used slightly more general png_sig_cmp() function instead */

    fread(sig, 1, 8, infile);
 if (png_sig_cmp(sig, 0, 8))
 return 1; /* bad signature */


 
     /* could pass pointers to user-defined error handlers instead of NULLs: */
 
    png_ptr = png_create_read_struct(PNG_LIBPNG_VER_STRING, NULL, NULL, NULL);
     if (!png_ptr)
         return 4;   /* out of memory */
 
    info_ptr = png_create_info_struct(png_ptr);
 if (!info_ptr) {
        png_destroy_read_struct(&png_ptr, NULL, NULL);
 return 4; /* out of memory */
 }


 /* we could create a second info struct here (end_info), but it's only
     * useful if we want to keep pre- and post-IDAT chunk info separated
     * (mainly for PNG-aware image editors and converters) */


 /* setjmp() must be called in every function that calls a PNG-reading
     * libpng function */

 if (setjmp(png_jmpbuf(png_ptr))) {
        png_destroy_read_struct(&png_ptr, &info_ptr, NULL);
 return 2;
 }


    png_init_io(png_ptr, infile);
    png_set_sig_bytes(png_ptr, 8); /* we already read the 8 signature bytes */

    png_read_info(png_ptr, info_ptr); /* read all PNG info up to image data */


 /* alternatively, could make separate calls to png_get_image_width(),
     * etc., but want bit_depth and color_type for later [don't care about
     * compression_type and filter_type => NULLs] */

    png_get_IHDR(png_ptr, info_ptr, &width, &height, &bit_depth, &color_type,
      NULL, NULL, NULL);
 *pWidth = width;
 *pHeight = height;


 /* OK, that's all we need for now; return happy */

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const BlockEntry* Track::GetEOS() const { return &m_eos; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bt_status_t btsock_l2cap_connect(const bt_bdaddr_t *bd_addr, int channel, int* sock_fd, int flags)
{
 return btsock_l2cap_listen_or_connect(NULL, bd_addr, channel, sock_fd, flags, 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ACodec::FlushingState::onMessageReceived(const sp<AMessage> &msg) {
 bool handled = false;

 switch (msg->what()) {
 case kWhatShutdown:
 {
            mCodec->deferMessage(msg);
 break;
 }

 case kWhatFlush:
 {
            handled = true;
 break;
 }

 default:
            handled = BaseState::onMessageReceived(msg);
 break;
 }

 return handled;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_subframe_constant_(FLAC__StreamDecoder *decoder, unsigned channel, unsigned bps, FLAC__bool do_full_decode)
{
	FLAC__Subframe_Constant *subframe = &decoder->private_->frame.subframes[channel].data.constant;
	FLAC__int32 x;
 unsigned i;
	FLAC__int32 *output = decoder->private_->output[channel];

	decoder->private_->frame.subframes[channel].type = FLAC__SUBFRAME_TYPE_CONSTANT;

 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &x, bps))
 return false; /* read_callback_ sets the state for us */

	subframe->value = x;

 /* decode the subframe */
 if(do_full_decode) {
 for(i = 0; i < decoder->private_->frame.header.blocksize; i++)
			output[i] = x;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: reactor_object_t *reactor_register(reactor_t *reactor,
 int fd, void *context,
 void (*read_ready)(void *context),
 void (*write_ready)(void *context)) {
  assert(reactor != NULL);
  assert(fd != INVALID_FD);

 reactor_object_t *object = (reactor_object_t *)osi_calloc(sizeof(reactor_object_t));
 if (!object) {
    LOG_ERROR("%s unable to allocate reactor object: %s", __func__, strerror(errno));
 return NULL;
 }

  object->reactor = reactor;
  object->fd = fd;
  object->context = context;
  object->read_ready = read_ready;
  object->write_ready = write_ready;
  pthread_mutex_init(&object->lock, NULL);

 struct epoll_event event;
  memset(&event, 0, sizeof(event));
 if (read_ready)
    event.events |= (EPOLLIN | EPOLLRDHUP);
 if (write_ready)
    event.events |= EPOLLOUT;
  event.data.ptr = object;

 if (epoll_ctl(reactor->epoll_fd, EPOLL_CTL_ADD, fd, &event) == -1) {
    LOG_ERROR("%s unable to register fd %d to epoll set: %s", __func__, fd, strerror(errno));
    pthread_mutex_destroy(&object->lock);
    osi_free(object);
 return NULL;
 }

 return object;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AudioSource::queueInputBuffer_l(MediaBuffer *buffer, int64_t timeUs) {
 const size_t bufferSize = buffer->range_length();
 const size_t frameSize = mRecord->frameSize();
 const int64_t timestampUs =
                mPrevSampleTimeUs +
 ((1000000LL * (bufferSize / frameSize)) +
 (mSampleRate >> 1)) / mSampleRate;

 if (mNumFramesReceived == 0) {
        buffer->meta_data()->setInt64(kKeyAnchorTime, mStartTimeUs);
 }

    buffer->meta_data()->setInt64(kKeyTime, mPrevSampleTimeUs);
    buffer->meta_data()->setInt64(kKeyDriftTime, timeUs - mInitialReadTimeUs);
    mPrevSampleTimeUs = timestampUs;
    mNumFramesReceived += bufferSize / frameSize;
    mBuffersReceived.push_back(buffer);
    mFrameAvailableCondition.signal();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SimpleSoftOMXComponent::useBuffer(
        OMX_BUFFERHEADERTYPE **header,
        OMX_U32 portIndex,
        OMX_PTR appPrivate,
        OMX_U32 size,
        OMX_U8 *ptr) {

     Mutex::Autolock autoLock(mLock);
     CHECK_LT(portIndex, mPorts.size());
 
     *header = new OMX_BUFFERHEADERTYPE;
     (*header)->nSize = sizeof(OMX_BUFFERHEADERTYPE);
     (*header)->nVersion.s.nVersionMajor = 1;
 (*header)->nVersion.s.nVersionMinor = 0;
 (*header)->nVersion.s.nRevision = 0;
 (*header)->nVersion.s.nStep = 0;
 (*header)->pBuffer = ptr;
 (*header)->nAllocLen = size;
 (*header)->nFilledLen = 0;
 (*header)->nOffset = 0;
 (*header)->pAppPrivate = appPrivate;
 (*header)->pPlatformPrivate = NULL;
 (*header)->pInputPortPrivate = NULL;
 (*header)->pOutputPortPrivate = NULL;
 (*header)->hMarkTargetComponent = NULL;
 (*header)->pMarkData = NULL;
 (*header)->nTickCount = 0;
 (*header)->nTimeStamp = 0;
 (*header)->nFlags = 0;

     (*header)->nOutputPortIndex = portIndex;
     (*header)->nInputPortIndex = portIndex;
 
    PortInfo *port = &mPorts.editItemAt(portIndex);
     CHECK(mState == OMX_StateLoaded || port->mDef.bEnabled == OMX_FALSE);
 
     CHECK_LT(port->mBuffers.size(), port->mDef.nBufferCountActual);

    port->mBuffers.push();

 BufferInfo *buffer =
 &port->mBuffers.editItemAt(port->mBuffers.size() - 1);

    buffer->mHeader = *header;
    buffer->mOwnedByUs = false;

 if (port->mBuffers.size() == port->mDef.nBufferCountActual) {
        port->mDef.bPopulated = OMX_TRUE;
        checkTransitions();
 }

 return OMX_ErrorNone;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static IV_API_CALL_STATUS_T api_check_struct_sanity(iv_obj_t *ps_handle,
 void *pv_api_ip,
 void *pv_api_op)
{
    IVD_API_COMMAND_TYPE_T e_cmd;
    UWORD32 *pu4_api_ip;
    UWORD32 *pu4_api_op;
    UWORD32 i, j;

 if(NULL == pv_api_op)
 return (IV_FAIL);

 if(NULL == pv_api_ip)
 return (IV_FAIL);

    pu4_api_ip = (UWORD32 *)pv_api_ip;
    pu4_api_op = (UWORD32 *)pv_api_op;
    e_cmd = *(pu4_api_ip + 1);

 /* error checks on handle */
 switch((WORD32)e_cmd)
 {
 case IVD_CMD_CREATE:
 break;

 case IVD_CMD_REL_DISPLAY_FRAME:
 case IVD_CMD_SET_DISPLAY_FRAME:
 case IVD_CMD_GET_DISPLAY_FRAME:
 case IVD_CMD_VIDEO_DECODE:
 case IVD_CMD_DELETE:
 case IVD_CMD_VIDEO_CTL:
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_handle->pv_fxns != ih264d_api_function)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->pv_codec_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }
 break;
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_API_CMD;
 return IV_FAIL;
 }

 switch((WORD32)e_cmd)
 {
 case IVD_CMD_CREATE:
 {
 ih264d_create_ip_t *ps_ip = (ih264d_create_ip_t *)pv_api_ip;
 ih264d_create_op_t *ps_op = (ih264d_create_op_t *)pv_api_op;


            ps_op->s_ivd_create_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_create_ip_t.u4_size > sizeof(ih264d_create_ip_t))
 || (ps_ip->s_ivd_create_ip_t.u4_size
 < sizeof(ivd_create_ip_t)))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_create_op_t.u4_size != sizeof(ih264d_create_op_t))
 && (ps_op->s_ivd_create_op_t.u4_size
 != sizeof(ivd_create_op_t)))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }


 if((ps_ip->s_ivd_create_ip_t.e_output_format != IV_YUV_420P)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_422ILE)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_RGB_565)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_420SP_UV)
 && (ps_ip->s_ivd_create_ip_t.e_output_format
 != IV_YUV_420SP_VU))
 {
                ps_op->s_ivd_create_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_create_op_t.u4_error_code |=
                                IVD_INIT_DEC_COL_FMT_NOT_SUPPORTED;
                H264_DEC_DEBUG_PRINT("\n");
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_GET_DISPLAY_FRAME:
 {
 ih264d_get_display_frame_ip_t *ps_ip =
 (ih264d_get_display_frame_ip_t *)pv_api_ip;
 ih264d_get_display_frame_op_t *ps_op =
 (ih264d_get_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_get_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ih264d_get_display_frame_ip_t))
 && (ps_ip->s_ivd_get_display_frame_ip_t.u4_size
 != sizeof(ivd_get_display_frame_ip_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ih264d_get_display_frame_op_t))
 && (ps_op->s_ivd_get_display_frame_op_t.u4_size
 != sizeof(ivd_get_display_frame_op_t)))
 {
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_get_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }
 }
 break;

 case IVD_CMD_REL_DISPLAY_FRAME:
 {
 ih264d_rel_display_frame_ip_t *ps_ip =
 (ih264d_rel_display_frame_ip_t *)pv_api_ip;
 ih264d_rel_display_frame_op_t *ps_op =
 (ih264d_rel_display_frame_op_t *)pv_api_op;

            ps_op->s_ivd_rel_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ih264d_rel_display_frame_ip_t))
 && (ps_ip->s_ivd_rel_display_frame_ip_t.u4_size
 != sizeof(ivd_rel_display_frame_ip_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ih264d_rel_display_frame_op_t))
 && (ps_op->s_ivd_rel_display_frame_op_t.u4_size
 != sizeof(ivd_rel_display_frame_op_t)))
 {
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_SET_DISPLAY_FRAME:
 {
 ih264d_set_display_frame_ip_t *ps_ip =
 (ih264d_set_display_frame_ip_t *)pv_api_ip;
 ih264d_set_display_frame_op_t *ps_op =
 (ih264d_set_display_frame_op_t *)pv_api_op;
            UWORD32 j;

            ps_op->s_ivd_set_display_frame_op_t.u4_error_code = 0;

 if((ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ih264d_set_display_frame_ip_t))
 && (ps_ip->s_ivd_set_display_frame_ip_t.u4_size
 != sizeof(ivd_set_display_frame_ip_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if((ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ih264d_set_display_frame_op_t))
 && (ps_op->s_ivd_set_display_frame_op_t.u4_size
 != sizeof(ivd_set_display_frame_op_t)))
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs == 0)
 {
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(j = 0; j < ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs;
                            j++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs
 == 0)
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                    IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0;
                                i
 < ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs;
                                i++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].pu1_bufs[i]
 == NULL)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_min_out_buf_size[i]
 == 0)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |=
                                        IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_DECODE:
 {
 ih264d_video_decode_ip_t *ps_ip =
 (ih264d_video_decode_ip_t *)pv_api_ip;
 ih264d_video_decode_op_t *ps_op =
 (ih264d_video_decode_op_t *)pv_api_op;

            H264_DEC_DEBUG_PRINT("The input bytes is: %d",
                                 ps_ip->s_ivd_video_decode_ip_t.u4_num_Bytes);
            ps_op->s_ivd_video_decode_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_video_decode_ip_t.u4_size
 != sizeof(ih264d_video_decode_ip_t)&&
                            ps_ip->s_ivd_video_decode_ip_t.u4_size != offsetof(ivd_video_decode_ip_t, s_out_buffer))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_video_decode_op_t.u4_size
 != sizeof(ih264d_video_decode_op_t)&&
                            ps_op->s_ivd_video_decode_op_t.u4_size != offsetof(ivd_video_decode_op_t, u4_output_present))
 {
                ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_video_decode_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_DELETE:
 {
 ih264d_delete_ip_t *ps_ip =
 (ih264d_delete_ip_t *)pv_api_ip;
 ih264d_delete_op_t *ps_op =
 (ih264d_delete_op_t *)pv_api_op;

            ps_op->s_ivd_delete_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_delete_ip_t.u4_size
 != sizeof(ih264d_delete_ip_t))
 {
                ps_op->s_ivd_delete_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_delete_op_t.u4_error_code |=
                                IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 if(ps_op->s_ivd_delete_op_t.u4_size
 != sizeof(ih264d_delete_op_t))
 {
                ps_op->s_ivd_delete_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                ps_op->s_ivd_delete_op_t.u4_error_code |=
                                IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return (IV_FAIL);
 }

 }
 break;

 case IVD_CMD_VIDEO_CTL:
 {
            UWORD32 *pu4_ptr_cmd;
            UWORD32 sub_command;

            pu4_ptr_cmd = (UWORD32 *)pv_api_ip;
            pu4_ptr_cmd += 2;
            sub_command = *pu4_ptr_cmd;

 switch(sub_command)
 {
 case IVD_CMD_CTL_SETPARAMS:
 {
 ih264d_ctl_set_config_ip_t *ps_ip;
 ih264d_ctl_set_config_op_t *ps_op;
                    ps_ip = (ih264d_ctl_set_config_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_config_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_set_config_ip_t.u4_size
 != sizeof(ih264d_ctl_set_config_ip_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 case IVD_CMD_CTL_SETDEFAULT:
 {
 ih264d_ctl_set_config_op_t *ps_op;
                    ps_op = (ih264d_ctl_set_config_op_t *)pv_api_op;
 if(ps_op->s_ivd_ctl_set_config_op_t.u4_size
 != sizeof(ih264d_ctl_set_config_op_t))
 {
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETPARAMS:
 {
 ih264d_ctl_getstatus_ip_t *ps_ip;
 ih264d_ctl_getstatus_op_t *ps_op;

                    ps_ip = (ih264d_ctl_getstatus_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getstatus_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getstatus_ip_t.u4_size
 != sizeof(ih264d_ctl_getstatus_ip_t))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getstatus_op_t.u4_size
 != sizeof(ih264d_ctl_getstatus_op_t))
 {
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETBUFINFO:
 {
 ih264d_ctl_getbufinfo_ip_t *ps_ip;
 ih264d_ctl_getbufinfo_op_t *ps_op;
                    ps_ip = (ih264d_ctl_getbufinfo_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getbufinfo_op_t *)pv_api_op;

 if(ps_ip->s_ivd_ctl_getbufinfo_ip_t.u4_size
 != sizeof(ih264d_ctl_getbufinfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getbufinfo_op_t.u4_size
 != sizeof(ih264d_ctl_getbufinfo_op_t))
 {
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETVERSION:
 {
 ih264d_ctl_getversioninfo_ip_t *ps_ip;
 ih264d_ctl_getversioninfo_op_t *ps_op;
                    ps_ip = (ih264d_ctl_getversioninfo_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_getversioninfo_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_size
 != sizeof(ih264d_ctl_getversioninfo_ip_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getversioninfo_op_t.u4_size
 != sizeof(ih264d_ctl_getversioninfo_op_t))
 {
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_FLUSH:
 {
 ih264d_ctl_flush_ip_t *ps_ip;
 ih264d_ctl_flush_op_t *ps_op;
                    ps_ip = (ih264d_ctl_flush_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_flush_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_flush_ip_t.u4_size
 != sizeof(ih264d_ctl_flush_ip_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_flush_op_t.u4_size
 != sizeof(ih264d_ctl_flush_op_t))
 {
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_flush_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_RESET:
 {
 ih264d_ctl_reset_ip_t *ps_ip;
 ih264d_ctl_reset_op_t *ps_op;
                    ps_ip = (ih264d_ctl_reset_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_reset_op_t *)pv_api_op;
 if(ps_ip->s_ivd_ctl_reset_ip_t.u4_size
 != sizeof(ih264d_ctl_reset_ip_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_reset_op_t.u4_size
 != sizeof(ih264d_ctl_reset_op_t))
 {
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= 1
 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_ctl_reset_op_t.u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IH264D_CMD_CTL_DEGRADE:
 {
 ih264d_ctl_degrade_ip_t *ps_ip;
 ih264d_ctl_degrade_op_t *ps_op;

                    ps_ip = (ih264d_ctl_degrade_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_degrade_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_degrade_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_degrade_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if((ps_ip->i4_degrade_pics < 0)
 || (ps_ip->i4_degrade_pics > 4)
 || (ps_ip->i4_nondegrade_interval < 0)
 || (ps_ip->i4_degrade_type < 0)
 || (ps_ip->i4_degrade_type > 15))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }

 break;
 }

 case IH264D_CMD_CTL_GET_BUFFER_DIMENSIONS:
 {
 ih264d_ctl_get_frame_dimensions_ip_t *ps_ip;
 ih264d_ctl_get_frame_dimensions_op_t *ps_op;

                    ps_ip = (ih264d_ctl_get_frame_dimensions_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_get_frame_dimensions_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(ih264d_ctl_get_frame_dimensions_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(ih264d_ctl_get_frame_dimensions_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }

 case IH264D_CMD_CTL_SET_NUM_CORES:
 {
 ih264d_ctl_set_num_cores_ip_t *ps_ip;
 ih264d_ctl_set_num_cores_op_t *ps_op;

                    ps_ip = (ih264d_ctl_set_num_cores_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_num_cores_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_set_num_cores_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_set_num_cores_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if((ps_ip->u4_num_cores != 1) && (ps_ip->u4_num_cores != 2)
 && (ps_ip->u4_num_cores != 3)
 && (ps_ip->u4_num_cores != 4))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }
 break;
 }
 case IH264D_CMD_CTL_SET_PROCESSOR:
 {
 ih264d_ctl_set_processor_ip_t *ps_ip;
 ih264d_ctl_set_processor_op_t *ps_op;

                    ps_ip = (ih264d_ctl_set_processor_ip_t *)pv_api_ip;
                    ps_op = (ih264d_ctl_set_processor_op_t *)pv_api_op;

 if(ps_ip->u4_size != sizeof(ih264d_ctl_set_processor_ip_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size != sizeof(ih264d_ctl_set_processor_op_t))
 {
                        ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->u4_error_code |=
                                        IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_UNSUPPORTED_API_CMD;
 return IV_FAIL;
 break;
 }
 }
 break;
 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: u32 h264bsdResetDpb(
 dpbStorage_t *dpb,
  u32 picSizeInMbs,
  u32 dpbSize,
  u32 maxRefFrames,
  u32 maxFrameNum,
  u32 noReordering)
{

/* Code */

    ASSERT(picSizeInMbs);
    ASSERT(maxRefFrames <= MAX_NUM_REF_PICS);
    ASSERT(maxRefFrames <= dpbSize);
    ASSERT(maxFrameNum);
    ASSERT(dpbSize);

    h264bsdFreeDpb(dpb);

 return h264bsdInitDpb(dpb, picSizeInMbs, dpbSize, maxRefFrames,
                          maxFrameNum, noReordering);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_islice_data_cavlc(dec_struct_t * ps_dec,
 dec_slice_params_t * ps_slice,
                                      UWORD16 u2_first_mb_in_slice)
{
    UWORD8 uc_more_data_flag;
    UWORD8 u1_num_mbs, u1_mb_idx;
 dec_mb_info_t *ps_cur_mb_info;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD16 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    WORD16 i2_cur_mb_addr;
    UWORD8 u1_mbaff;
    UWORD8 u1_num_mbs_next, u1_end_of_row, u1_tfr_n_mb;
    WORD32 ret = OK;

    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mbaff = ps_slice->u1_mbaff_frame_flag;

 /* initializations */
    u1_mb_idx = ps_dec->u1_mb_idx;
    u1_num_mbs = u1_mb_idx;

    uc_more_data_flag = 1;
    i2_cur_mb_addr = u2_first_mb_in_slice << u1_mbaff;

 do
 {
        UWORD8 u1_mb_type;

        ps_dec->pv_prev_mb_parse_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 {
            ret = ERROR_MB_ADDRESS_T;
 break;
 }

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);

        ps_cur_mb_info->u1_end_of_slice = 0;

 /***************************************************************/
 /* Get the required information for decoding of MB             */
 /* mb_x, mb_y , neighbour availablity,                         */
 /***************************************************************/
        ps_dec->pf_get_mb_info(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, 0);

 /***************************************************************/
 /* Set the deblocking parameters for this MB                   */
 /***************************************************************/
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

 if(ps_dec->u4_app_disable_deblk_frm == 0)
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);

        ps_cur_deblk_mb->u1_mb_type = ps_cur_deblk_mb->u1_mb_type | D_INTRA_MB;

 /**************************************************************/
 /* Macroblock Layer Begins, Decode the u1_mb_type                */
 /**************************************************************/
 {
            UWORD32 u4_bitstream_offset = *pu4_bitstrm_ofst;
            UWORD32 u4_word, u4_ldz, u4_temp;

 /***************************************************************/
 /* Find leading zeros in next 32 bits                          */
 /***************************************************************/
            NEXTBITS_32(u4_word, u4_bitstream_offset, pu4_bitstrm_buf);
            u4_ldz = CLZ(u4_word);
 /* Flush the ps_bitstrm */
            u4_bitstream_offset += (u4_ldz + 1);
 /* Read the suffix from the ps_bitstrm */
            u4_word = 0;
 if(u4_ldz)
                GETBITS(u4_word, u4_bitstream_offset, pu4_bitstrm_buf,
                        u4_ldz);
 *pu4_bitstrm_ofst = u4_bitstream_offset;
            u4_temp = ((1 << u4_ldz) + u4_word - 1);
 if(u4_temp > 25)
 return ERROR_MB_TYPE;
            u1_mb_type = u4_temp;

 }
        ps_cur_mb_info->u1_mb_type = u1_mb_type;
        COPYTHECONTEXT("u1_mb_type", u1_mb_type);

 /**************************************************************/
 /* Parse Macroblock data                                      */
 /**************************************************************/
 if(25 == u1_mb_type)
 {
 /* I_PCM_MB */
            ps_cur_mb_info->ps_curmb->u1_mb_type = I_PCM_MB;
            ret = ih264d_parse_ipcm_mb(ps_dec, ps_cur_mb_info, u1_num_mbs);
 if(ret != OK)
 return ret;
            ps_cur_deblk_mb->u1_mb_qp = 0;
 }
 else
 {
            ret = ih264d_parse_imb_cavlc(ps_dec, ps_cur_mb_info, u1_num_mbs, u1_mb_type);
 if(ret != OK)
 return ret;
            ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;
 }


         if(u1_mbaff)
         {
             ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
         }
         /**************************************************************/
         /* Get next Macroblock address                                */
 /**************************************************************/

        i2_cur_mb_addr++;
        uc_more_data_flag = MORE_RBSP_DATA(ps_bitstrm);

 /* Store the colocated information */
 {
 mv_pred_t *ps_mv_nmb_start = ps_dec->ps_mv_cur + (u1_num_mbs << 4);

 mv_pred_t s_mvPred =
 {
 { 0, 0, 0, 0 },
 { -1, -1 }, 0, 0};
            ih264d_rep_mv_colz(ps_dec, &s_mvPred, ps_mv_nmb_start, 0,
 (UWORD8)(ps_dec->u1_cur_mb_fld_dec_flag << 1), 4,
 4);
 }

 /*if num _cores is set to 3,compute bs will be done in another thread*/
 if(ps_dec->u4_num_cores < 3)
 {
 if(ps_dec->u4_app_disable_deblk_frm == 0)
                ps_dec->pf_compute_bs(ps_dec, ps_cur_mb_info,
 (UWORD16)(u1_num_mbs >> u1_mbaff));
 }
        u1_num_mbs++;

 /****************************************************************/
 /* Check for End Of Row                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || (!uc_more_data_flag);
        ps_cur_mb_info->u1_end_of_slice = (!uc_more_data_flag);

 /*H264_DEC_DEBUG_PRINT("Pic: %d Mb_X=%d Mb_Y=%d",
         ps_slice->i4_poc >> ps_slice->u1_field_pic_flag,
         ps_dec->u2_mbx,ps_dec->u2_mby + (1 - ps_cur_mb_info->u1_topmb));
         H264_DEC_DEBUG_PRINT("u1_tfr_n_mb || (!uc_more_data_flag): %d", u1_tfr_n_mb || (!uc_more_data_flag));*/
 if(u1_tfr_n_mb || (!uc_more_data_flag))
 {

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                            u1_num_mbs_next, u1_tfr_n_mb,
                                            u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;

 }
 }
 while(uc_more_data_flag);

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr

 - (u2_first_mb_in_slice << u1_mbaff);

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void smp_send_commitment(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  SMP_TRACE_DEBUG("%s", __func__);
  smp_send_cmd(SMP_OPCODE_PAIR_COMMITM, p_cb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::InjectionState::~InjectionState() {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int out_set_volume(struct audio_stream_out *stream, float left,
 float right)
{
 struct stream_out *out = (struct stream_out *)stream;
 struct audio_device *adev = out->dev;
 (void)right;

 if (out->usecase == USECASE_AUDIO_PLAYBACK_MULTI_CH) {
 /* only take left channel into account: the API is for stereo anyway */
        out->muted = (left == 0.0f);
 return 0;
 }

 return -ENOSYS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void bta_hl_co_delete_mdl(UINT8 mdep_id, UINT8 item_idx)
{


    BTIF_TRACE_DEBUG("%s mdep_id=%d, item_idx=%d", __FUNCTION__, mdep_id, item_idx);

    btif_hl_delete_mdl_cfg(mdep_id, item_idx);


}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: blockingWrite(int fd, const void *buffer, size_t len) {
 size_t writeOffset = 0;
 const uint8_t *toWrite;

    toWrite = (const uint8_t *)buffer;

 while (writeOffset < len) {
 ssize_t written;
 do {
            written = write (fd, toWrite + writeOffset,
                                len - writeOffset);
 } while (written < 0 && ((errno == EINTR) || (errno == EAGAIN)));

 if (written >= 0) {
            writeOffset += written;
 } else { // written < 0
            RLOGE ("RIL Response: unexpected error on write errno:%d", errno);
            close(fd);
 return -1;
 }
 }
#if VDBG
    RLOGE("RIL Response bytes written:%d", writeOffset);
#endif
 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: media_status_t AMediaCodec_releaseOutputBufferAtTime(
 AMediaCodec *mData, size_t idx, int64_t timestampNs) {
    ALOGV("render @ %" PRId64, timestampNs);
 return translate_error(mData->mCodec->renderOutputBufferAndRelease(idx, timestampNs));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Cluster::GetTime() const
{
    const long long tc = GetTimeCode();
    if (tc < 0)
        return tc;
    const SegmentInfo* const pInfo = m_pSegment->GetInfo();
    assert(pInfo);
    const long long scale = pInfo->GetTimeCodeScale();
    assert(scale >= 1);
    const long long t = m_timecode * scale;
    return t;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: gp_bgra16(Pixel *p, png_const_voidp pb)
{
   png_const_uint_16p pp = voidcast(png_const_uint_16p, pb);

   p->r = pp[2];
   p->g = pp[1];
   p->b = pp[0];
   p->a = pp[3];
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_decide_association_model(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
 uint8_t int_evt = 0;
  tSMP_INT_DATA smp_int_data;

  SMP_TRACE_DEBUG("%s Association Model = %d", __func__,
                  p_cb->selected_association_model);

 switch (p_cb->selected_association_model) {
 case SMP_MODEL_ENCRYPTION_ONLY: /* TK = 0, go calculate Confirm */
 if (p_cb->role == HCI_ROLE_MASTER &&
 ((p_cb->peer_auth_req & SMP_AUTH_YN_BIT) != 0) &&
 ((p_cb->loc_auth_req & SMP_AUTH_YN_BIT) == 0)) {
        SMP_TRACE_ERROR(
 "IO capability does not meet authentication requirement");
        smp_int_data.status = SMP_PAIR_AUTH_FAIL;
        int_evt = SMP_AUTH_CMPL_EVT;
 } else {
        p_cb->sec_level = SMP_SEC_UNAUTHENTICATE;
        SMP_TRACE_EVENT("p_cb->sec_level =%d (SMP_SEC_UNAUTHENTICATE) ",
                        p_cb->sec_level);

        tSMP_KEY key;
        key.key_type = SMP_KEY_TYPE_TK;
        key.p_data = p_cb->tk;
        smp_int_data.key = key;

        memset(p_cb->tk, 0, BT_OCTET16_LEN);
 /* TK, ready  */
        int_evt = SMP_KEY_READY_EVT;
 }
 break;

 case SMP_MODEL_PASSKEY:
      p_cb->sec_level = SMP_SEC_AUTHENTICATED;
      SMP_TRACE_EVENT("p_cb->sec_level =%d (SMP_SEC_AUTHENTICATED) ",
                      p_cb->sec_level);

      p_cb->cb_evt = SMP_PASSKEY_REQ_EVT;
      int_evt = SMP_TK_REQ_EVT;
 break;

 case SMP_MODEL_OOB:
      SMP_TRACE_ERROR("Association Model = SMP_MODEL_OOB");
      p_cb->sec_level = SMP_SEC_AUTHENTICATED;
      SMP_TRACE_EVENT("p_cb->sec_level =%d (SMP_SEC_AUTHENTICATED) ",
                      p_cb->sec_level);

      p_cb->cb_evt = SMP_OOB_REQ_EVT;
      int_evt = SMP_TK_REQ_EVT;
 break;

 case SMP_MODEL_KEY_NOTIF:
      p_cb->sec_level = SMP_SEC_AUTHENTICATED;
      SMP_TRACE_DEBUG("Need to generate Passkey");

 /* generate passkey and notify application */
      smp_generate_passkey(p_cb, NULL);
 break;

 case SMP_MODEL_SEC_CONN_JUSTWORKS:
 case SMP_MODEL_SEC_CONN_NUM_COMP:
 case SMP_MODEL_SEC_CONN_PASSKEY_ENT:
 case SMP_MODEL_SEC_CONN_PASSKEY_DISP:
 case SMP_MODEL_SEC_CONN_OOB:
      int_evt = SMP_PUBL_KEY_EXCH_REQ_EVT;
 break;

 case SMP_MODEL_OUT_OF_RANGE:
      SMP_TRACE_ERROR("Association Model = SMP_MODEL_OUT_OF_RANGE (failed)");
      smp_int_data.status = SMP_UNKNOWN_IO_CAP;
      int_evt = SMP_AUTH_CMPL_EVT;
 break;

 default:
      SMP_TRACE_ERROR(
 "Association Model = %d (SOMETHING IS WRONG WITH THE CODE)",
          p_cb->selected_association_model);
      smp_int_data.status = SMP_UNKNOWN_IO_CAP;
      int_evt = SMP_AUTH_CMPL_EVT;
 }

  SMP_TRACE_EVENT("sec_level=%d ", p_cb->sec_level);
 if (int_evt) smp_sm_event(p_cb, int_evt, &smp_int_data);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static uint32_t NumberOfElementsImpl(JSObject* receiver,
 FixedArrayBase* backing_store) {
 uint32_t max_index = Subclass::GetMaxIndex(receiver, backing_store);
 if (IsFastPackedElementsKind(Subclass::kind())) return max_index;
 Isolate* isolate = receiver->GetIsolate();
 uint32_t count = 0;
 for (uint32_t i = 0; i < max_index; i++) {
 if (Subclass::HasEntryImpl(isolate, backing_store, i)) count++;
 }
 return count;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setSurface(const sp<Surface> &surface) {
    sp<AMessage> msg = new AMessage(kWhatSetSurface, this);
    msg->setObject("surface", surface);

    sp<AMessage> response;
 status_t err = msg->postAndAwaitResponse(&response);

 if (err == OK) {
 (void)response->findInt32("err", &err);
 }
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVC::setConfig(
        OMX_INDEXTYPE index, const OMX_PTR _params) {
 switch (index) {
 case OMX_IndexConfigVideoIntraVOPRefresh:
 {

             OMX_CONFIG_INTRAREFRESHVOPTYPE *params =
                 (OMX_CONFIG_INTRAREFRESHVOPTYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

            mKeyFrameRequested = params->IntraRefreshVOP;
 return OMX_ErrorNone;
 }

 case OMX_IndexConfigVideoBitrate:
 {

             OMX_VIDEO_CONFIG_BITRATETYPE *params =
                 (OMX_VIDEO_CONFIG_BITRATETYPE *)_params;
 
             if (params->nPortIndex != kOutputPortIndex) {
                 return OMX_ErrorBadPortIndex;
             }

 if (mBitrate != params->nEncodeBitrate) {
                mBitrate = params->nEncodeBitrate;
                mBitrateUpdated = true;
 }
 return OMX_ErrorNone;
 }

 default:
 return SimpleSoftOMXComponent::setConfig(index, _params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_read_mmco_commands(struct _DecStruct * ps_dec)
{
 dec_bit_stream_t *ps_bitstrm = ps_dec->ps_bitstrm;
 dpb_commands_t *ps_dpb_cmds = ps_dec->ps_dpb_cmds;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    WORD32 j;
    UWORD8 u1_buf_mode;
 struct MMCParams *ps_mmc_params;
    UWORD32 *pu4_bitstrm_buf = ps_dec->ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    UWORD32 u4_bit_ofst = ps_dec->ps_bitstrm->u4_ofst;

    ps_slice->u1_mmco_equalto5 = 0;
 {
 if(ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 {
            ps_slice->u1_no_output_of_prior_pics_flag =
                            ih264d_get_bit_h264(ps_bitstrm);
            COPYTHECONTEXT("SH: no_output_of_prior_pics_flag",
                            ps_slice->u1_no_output_of_prior_pics_flag);
            ps_slice->u1_long_term_reference_flag = ih264d_get_bit_h264(
                            ps_bitstrm);
            COPYTHECONTEXT("SH: long_term_reference_flag",
                            ps_slice->u1_long_term_reference_flag);
            ps_dpb_cmds->u1_idr_pic = 1;
            ps_dpb_cmds->u1_no_output_of_prior_pics_flag =
                            ps_slice->u1_no_output_of_prior_pics_flag;
            ps_dpb_cmds->u1_long_term_reference_flag =
                            ps_slice->u1_long_term_reference_flag;
 }
 else
 {
            u1_buf_mode = ih264d_get_bit_h264(ps_bitstrm); //0 - sliding window; 1 - arbitrary
            COPYTHECONTEXT("SH: adaptive_ref_pic_buffering_flag", u1_buf_mode);
            ps_dpb_cmds->u1_buf_mode = u1_buf_mode;
            j = 0;

 if(u1_buf_mode == 1)
 {
                UWORD32 u4_mmco;
                UWORD32 u4_diff_pic_num;
                UWORD32 u4_lt_idx, u4_max_lt_idx;

                u4_mmco = ih264d_uev(pu4_bitstrm_ofst,

                                      pu4_bitstrm_buf);
                 while(u4_mmco != END_OF_MMCO)
                 {
                     ps_mmc_params = &ps_dpb_cmds->as_mmc_params[j];
                     ps_mmc_params->u4_mmco = u4_mmco;
                     switch(u4_mmco)
 {
 case MARK_ST_PICNUM_AS_NONREF:
                            u4_diff_pic_num = ih264d_uev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
                            ps_mmc_params->u4_diff_pic_num = u4_diff_pic_num;
 break;

 case MARK_LT_INDEX_AS_NONREF:
                            u4_lt_idx = ih264d_uev(pu4_bitstrm_ofst,
                                                   pu4_bitstrm_buf);
                            ps_mmc_params->u4_lt_idx = u4_lt_idx;
 break;

 case MARK_ST_PICNUM_AS_LT_INDEX:
                            u4_diff_pic_num = ih264d_uev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
                            ps_mmc_params->u4_diff_pic_num = u4_diff_pic_num;
                            u4_lt_idx = ih264d_uev(pu4_bitstrm_ofst,
                                                   pu4_bitstrm_buf);
                            ps_mmc_params->u4_lt_idx = u4_lt_idx;
 break;

 case SET_MAX_LT_INDEX:
 {
                            u4_max_lt_idx = ih264d_uev(pu4_bitstrm_ofst,
                                                       pu4_bitstrm_buf);
                            ps_mmc_params->u4_max_lt_idx_plus1 = u4_max_lt_idx;
 break;
 }
 case RESET_REF_PICTURES:
 {
                            ps_slice->u1_mmco_equalto5 = 1;
 break;
 }

 case SET_LT_INDEX:
                            u4_lt_idx = ih264d_uev(pu4_bitstrm_ofst,
                                                   pu4_bitstrm_buf);
                            ps_mmc_params->u4_lt_idx = u4_lt_idx;
 break;

 default:
 break;
 }
                    u4_mmco = ih264d_uev(pu4_bitstrm_ofst,
                                         pu4_bitstrm_buf);

                    j++;
 }
                ps_dpb_cmds->u1_num_of_commands = j;

 }
 }
        ps_dpb_cmds->u1_dpb_commands_read = 1;
        ps_dpb_cmds->u1_dpb_commands_read_slc = 1;

 }
    u4_bit_ofst = ps_dec->ps_bitstrm->u4_ofst - u4_bit_ofst;
 return u4_bit_ofst;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: store_init(png_store* ps)
{
   memset(ps, 0, sizeof *ps);
   init_exception_context(&ps->exception_context);
   store_pool_init(ps, &ps->read_memory_pool);
   store_pool_init(ps, &ps->write_memory_pool);
   ps->verbose = 0;
   ps->treat_warnings_as_errors = 0;
   ps->expect_error = 0;
   ps->expect_warning = 0;
   ps->saw_warning = 0;
   ps->speed = 0;
   ps->progressive = 0;
   ps->validated = 0;
   ps->nerrors = ps->nwarnings = 0;
   ps->pread = NULL;
   ps->piread = NULL;
   ps->saved = ps->current = NULL;
   ps->next = NULL;
   ps->readpos = 0;
   ps->image = NULL;
   ps->cb_image = 0;
   ps->cb_row = 0;
   ps->image_h = 0;
   ps->pwrite = NULL;
   ps->piwrite = NULL;
   ps->writepos = 0;
   ps->new.prev = NULL;
   ps->palette = NULL;
   ps->npalette = 0;
   ps->noptions = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool NuMediaExtractor::getTotalBitrate(int64_t *bitrate) const {
 if (mTotalBitrate >= 0) {
 *bitrate = mTotalBitrate;
 return true;

     }
 
     off64_t size;
    if (mDurationUs >= 0 && mDataSource->getSize(&size) == OK) {
         *bitrate = size * 8000000ll / mDurationUs;  // in bits/sec
         return true;
     }

 return false;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uintptr_t Parcel::readPointer() const
{
 return readAligned<binder_uintptr_t>();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void do_cleanup(char UNUSED *p)
{
    bdt_cleanup();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int omx_venc::dev_set_format(int color)
{
 return handle->venc_set_format(color);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Block::~Block()
{
    delete[] m_frames;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtReadDoc(xmlParserCtxtPtr ctxt, const xmlChar * cur,
 const char *URL, const char *encoding, int options)
{
    xmlParserInputPtr stream;

 if (cur == NULL)
 return (NULL);
 if (ctxt == NULL)
 return (NULL);
    xmlInitParser();

    xmlCtxtReset(ctxt);

    stream = xmlNewStringInputStream(ctxt, cur);
 if (stream == NULL) {
 return (NULL);
 }
    inputPush(ctxt, stream);
 return (xmlDoRead(ctxt, URL, encoding, options, 1));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: buffer_start_read(struct buffer *buffer)
{
   buffer->current = &buffer->first;
   buffer->read_count = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Chapters::Atom::GetDisplayCount() const
{
    return m_displays_count;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  bool IsIndexInBorder(int i) {
 return (i < BorderTop() * kOuterBlockSize ||
            i >= (BorderTop() + Height()) * kOuterBlockSize ||
            i % kOuterBlockSize < BorderLeft() ||
            i % kOuterBlockSize >= (BorderLeft() + Width()));
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftMPEG4Encoder::SoftMPEG4Encoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
            OMX_PTR appData,
            OMX_COMPONENTTYPE **component)
 : SoftVideoEncoderOMXComponent(name, callbacks, appData, component),
      mEncodeMode(COMBINE_MODE_WITH_ERR_RES),
      mVideoWidth(176),
      mVideoHeight(144),
      mVideoFrameRate(30),
      mVideoBitRate(192000),
      mVideoColorFormat(OMX_COLOR_FormatYUV420Planar),
      mStoreMetaDataInBuffers(false),
      mIDRFrameRefreshIntervalInSec(1),
      mNumInputFrames(-1),
      mStarted(false),
      mSawInputEOS(false),
      mSignalledError(false),
      mHandle(new tagvideoEncControls),
      mEncParams(new tagvideoEncOptions),
      mInputFrameData(NULL) {

 if (!strcmp(name, "OMX.google.h263.encoder")) {
        mEncodeMode = H263_MODE;
 } else {
        CHECK(!strcmp(name, "OMX.google.mpeg4.encoder"));
 }

    initPorts();
    ALOGI("Construct SoftMPEG4Encoder");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  main(void)
 {
   fprintf(stderr, "pngfix does not work without read support\n");
    return 77;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_BUFFERHEADERTYPE *OMXNodeInstance::findBufferHeader(OMX::buffer_id buffer) {
     if (buffer == 0) {
         return NULL;
     }
 Mutex::Autolock autoLock(mBufferIDLock);
 ssize_t index = mBufferIDToBufferHeader.indexOfKey(buffer);
 if (index < 0) {

         CLOGW("findBufferHeader: buffer %u not found", buffer);
         return NULL;
     }
    return mBufferIDToBufferHeader.valueAt(index);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t GraphicBuffer::flatten(void*& buffer, size_t& size, int*& fds, size_t& count) const {
 size_t sizeNeeded = GraphicBuffer::getFlattenedSize();
 if (size < sizeNeeded) return NO_MEMORY;

 size_t fdCountNeeded = GraphicBuffer::getFdCount();
 if (count < fdCountNeeded) return NO_MEMORY;

 int32_t* buf = static_cast<int32_t*>(buffer);
    buf[0] = 'GBFR';
    buf[1] = width;
    buf[2] = height;
    buf[3] = stride;
    buf[4] = format;
    buf[5] = usage;
    buf[6] = static_cast<int32_t>(mId >> 32);
    buf[7] = static_cast<int32_t>(mId & 0xFFFFFFFFull);
    buf[8] = 0;
    buf[9] = 0;

 if (handle) {
        buf[8] = handle->numFds;
        buf[9] = handle->numInts;
 native_handle_t const* const h = handle;
        memcpy(fds,     h->data,             h->numFds*sizeof(int));
        memcpy(&buf[10], h->data + h->numFds, h->numInts*sizeof(int));
 }

    buffer = reinterpret_cast<void*>(static_cast<int*>(buffer) + sizeNeeded);
    size -= sizeNeeded;
 if (handle) {
        fds += handle->numFds;
        count -= handle->numFds;
 }

 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_get_vui_params(iv_obj_t *ps_codec_obj,
 void *pv_api_ip,
 void *pv_api_op)
{
 ihevcd_cxa_ctl_get_vui_params_ip_t *ps_ip;
 ihevcd_cxa_ctl_get_vui_params_op_t *ps_op;
 codec_t *ps_codec = (codec_t *)ps_codec_obj->pv_codec_handle;
 sps_t *ps_sps;
 vui_t *ps_vui;
    WORD32 i;

    ps_ip = (ihevcd_cxa_ctl_get_vui_params_ip_t *)pv_api_ip;
    ps_op = (ihevcd_cxa_ctl_get_vui_params_op_t *)pv_api_op;

 if(0 == ps_codec->i4_sps_done)
 {
        ps_op->u4_error_code = IHEVCD_VUI_PARAMS_NOT_FOUND;
 return IV_FAIL;
 }

    ps_sps = ps_codec->s_parse.ps_sps;
 if(0 == ps_sps->i1_sps_valid || 0 == ps_sps->i1_vui_parameters_present_flag)
 {
        WORD32 sps_idx = 0;
        ps_sps = ps_codec->ps_sps_base;

 while((0 == ps_sps->i1_sps_valid) || (0 == ps_sps->i1_vui_parameters_present_flag))
 {
            sps_idx++;
            ps_sps++;

 if(sps_idx == MAX_SPS_CNT - 1)
 {
                ps_op->u4_error_code = IHEVCD_VUI_PARAMS_NOT_FOUND;
 return IV_FAIL;
 }
 }
 }

    ps_vui = &ps_sps->s_vui_parameters;
    UNUSED(ps_ip);

    ps_op->u1_aspect_ratio_info_present_flag         =  ps_vui->u1_aspect_ratio_info_present_flag;
    ps_op->u1_aspect_ratio_idc                       =  ps_vui->u1_aspect_ratio_idc;
    ps_op->u2_sar_width                              =  ps_vui->u2_sar_width;
    ps_op->u2_sar_height                             =  ps_vui->u2_sar_height;
    ps_op->u1_overscan_info_present_flag             =  ps_vui->u1_overscan_info_present_flag;
    ps_op->u1_overscan_appropriate_flag              =  ps_vui->u1_overscan_appropriate_flag;
    ps_op->u1_video_signal_type_present_flag         =  ps_vui->u1_video_signal_type_present_flag;
    ps_op->u1_video_format                           =  ps_vui->u1_video_format;
    ps_op->u1_video_full_range_flag                  =  ps_vui->u1_video_full_range_flag;
    ps_op->u1_colour_description_present_flag        =  ps_vui->u1_colour_description_present_flag;
    ps_op->u1_colour_primaries                       =  ps_vui->u1_colour_primaries;
    ps_op->u1_transfer_characteristics               =  ps_vui->u1_transfer_characteristics;
    ps_op->u1_matrix_coefficients                    =  ps_vui->u1_matrix_coefficients;
    ps_op->u1_chroma_loc_info_present_flag           =  ps_vui->u1_chroma_loc_info_present_flag;
    ps_op->u1_chroma_sample_loc_type_top_field       =  ps_vui->u1_chroma_sample_loc_type_top_field;
    ps_op->u1_chroma_sample_loc_type_bottom_field    =  ps_vui->u1_chroma_sample_loc_type_bottom_field;
    ps_op->u1_neutral_chroma_indication_flag         =  ps_vui->u1_neutral_chroma_indication_flag;
    ps_op->u1_field_seq_flag                         =  ps_vui->u1_field_seq_flag;
    ps_op->u1_frame_field_info_present_flag          =  ps_vui->u1_frame_field_info_present_flag;
    ps_op->u1_default_display_window_flag            =  ps_vui->u1_default_display_window_flag;
    ps_op->u4_def_disp_win_left_offset               =  ps_vui->u4_def_disp_win_left_offset;
    ps_op->u4_def_disp_win_right_offset              =  ps_vui->u4_def_disp_win_right_offset;
    ps_op->u4_def_disp_win_top_offset                =  ps_vui->u4_def_disp_win_top_offset;
    ps_op->u4_def_disp_win_bottom_offset             =  ps_vui->u4_def_disp_win_bottom_offset;
    ps_op->u1_vui_hrd_parameters_present_flag        =  ps_vui->u1_vui_hrd_parameters_present_flag;
    ps_op->u1_vui_timing_info_present_flag           =  ps_vui->u1_vui_timing_info_present_flag;
    ps_op->u4_vui_num_units_in_tick                  =  ps_vui->u4_vui_num_units_in_tick;
    ps_op->u4_vui_time_scale                         =  ps_vui->u4_vui_time_scale;
    ps_op->u1_poc_proportional_to_timing_flag        =  ps_vui->u1_poc_proportional_to_timing_flag;
    ps_op->u1_num_ticks_poc_diff_one_minus1          =  ps_vui->u1_num_ticks_poc_diff_one_minus1;
    ps_op->u1_bitstream_restriction_flag             =  ps_vui->u1_bitstream_restriction_flag;
    ps_op->u1_tiles_fixed_structure_flag             =  ps_vui->u1_tiles_fixed_structure_flag;
    ps_op->u1_motion_vectors_over_pic_boundaries_flag =  ps_vui->u1_motion_vectors_over_pic_boundaries_flag;
    ps_op->u1_restricted_ref_pic_lists_flag          =  ps_vui->u1_restricted_ref_pic_lists_flag;
    ps_op->u4_min_spatial_segmentation_idc           =  ps_vui->u4_min_spatial_segmentation_idc;
    ps_op->u1_max_bytes_per_pic_denom                =  ps_vui->u1_max_bytes_per_pic_denom;
    ps_op->u1_max_bits_per_mincu_denom               =  ps_vui->u1_max_bits_per_mincu_denom;
    ps_op->u1_log2_max_mv_length_horizontal          =  ps_vui->u1_log2_max_mv_length_horizontal;
    ps_op->u1_log2_max_mv_length_vertical            =  ps_vui->u1_log2_max_mv_length_vertical;


 /* HRD parameters */
    ps_op->u1_timing_info_present_flag                         =    ps_vui->s_vui_hrd_parameters.u1_timing_info_present_flag;
    ps_op->u4_num_units_in_tick                                =    ps_vui->s_vui_hrd_parameters.u4_num_units_in_tick;
    ps_op->u4_time_scale                                       =    ps_vui->s_vui_hrd_parameters.u4_time_scale;
    ps_op->u1_nal_hrd_parameters_present_flag                  =    ps_vui->s_vui_hrd_parameters.u1_nal_hrd_parameters_present_flag;
    ps_op->u1_vcl_hrd_parameters_present_flag                  =    ps_vui->s_vui_hrd_parameters.u1_vcl_hrd_parameters_present_flag;
    ps_op->u1_cpbdpb_delays_present_flag                       =    ps_vui->s_vui_hrd_parameters.u1_cpbdpb_delays_present_flag;
    ps_op->u1_sub_pic_cpb_params_present_flag                  =    ps_vui->s_vui_hrd_parameters.u1_sub_pic_cpb_params_present_flag;
    ps_op->u1_tick_divisor_minus2                              =    ps_vui->s_vui_hrd_parameters.u1_tick_divisor_minus2;
    ps_op->u1_du_cpb_removal_delay_increment_length_minus1     =    ps_vui->s_vui_hrd_parameters.u1_du_cpb_removal_delay_increment_length_minus1;
    ps_op->u1_sub_pic_cpb_params_in_pic_timing_sei_flag        =    ps_vui->s_vui_hrd_parameters.u1_sub_pic_cpb_params_in_pic_timing_sei_flag;
    ps_op->u1_dpb_output_delay_du_length_minus1                =    ps_vui->s_vui_hrd_parameters.u1_dpb_output_delay_du_length_minus1;
    ps_op->u4_bit_rate_scale                                   =    ps_vui->s_vui_hrd_parameters.u4_bit_rate_scale;
    ps_op->u4_cpb_size_scale                                   =    ps_vui->s_vui_hrd_parameters.u4_cpb_size_scale;
    ps_op->u4_cpb_size_du_scale                                =    ps_vui->s_vui_hrd_parameters.u4_cpb_size_du_scale;
    ps_op->u1_initial_cpb_removal_delay_length_minus1          =    ps_vui->s_vui_hrd_parameters.u1_initial_cpb_removal_delay_length_minus1;
    ps_op->u1_au_cpb_removal_delay_length_minus1               =    ps_vui->s_vui_hrd_parameters.u1_au_cpb_removal_delay_length_minus1;
    ps_op->u1_dpb_output_delay_length_minus1                   =    ps_vui->s_vui_hrd_parameters.u1_dpb_output_delay_length_minus1;

 for(i = 0; i < 6; i++)
 {
        ps_op->au1_fixed_pic_rate_general_flag[i] =    ps_vui->s_vui_hrd_parameters.au1_fixed_pic_rate_general_flag[i];
        ps_op->au1_fixed_pic_rate_within_cvs_flag[i] =    ps_vui->s_vui_hrd_parameters.au1_fixed_pic_rate_within_cvs_flag[i];
        ps_op->au1_elemental_duration_in_tc_minus1[i] =    ps_vui->s_vui_hrd_parameters.au1_elemental_duration_in_tc_minus1[i];
        ps_op->au1_low_delay_hrd_flag[i] =    ps_vui->s_vui_hrd_parameters.au1_low_delay_hrd_flag[i];
        ps_op->au1_cpb_cnt_minus1[i] =    ps_vui->s_vui_hrd_parameters.au1_cpb_cnt_minus1[i];
 }


 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: static void uipc_flush_ch_locked(tUIPC_CH_ID ch_id)
{
 char buf[UIPC_FLUSH_BUFFER_SIZE];
 struct pollfd pfd;
 int ret;

    pfd.events = POLLIN;
    pfd.fd = uipc_main.ch[ch_id].fd;

 if (uipc_main.ch[ch_id].fd == UIPC_DISCONNECTED)
 {
        BTIF_TRACE_EVENT("%s() - fd disconnected. Exiting", __FUNCTION__);
 return;
 }

 
     while (1)
     {
        ret = poll(&pfd, 1, 1);
         BTIF_TRACE_VERBOSE("%s() - polling fd %d, revents: 0x%x, ret %d",
                 __FUNCTION__, pfd.fd, pfd.revents, ret);
 
 if (pfd.revents & (POLLERR|POLLHUP))
 {
            BTIF_TRACE_EVENT("%s() - POLLERR or POLLHUP. Exiting", __FUNCTION__);
 return;
 }

 if (ret <= 0)
 {
            BTIF_TRACE_EVENT("%s() - error (%d). Exiting", __FUNCTION__, ret);
 return;
 }

 
         /* read sufficiently large buffer to ensure flush empties socket faster than
            it is getting refilled */
        read(pfd.fd, &buf, UIPC_FLUSH_BUFFER_SIZE);
     }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraDeviceClient::createDefaultRequest(int templateId,
 /*out*/
 CameraMetadata* request)
{
    ATRACE_CALL();
    ALOGV("%s (templateId = 0x%x)", __FUNCTION__, templateId);

 status_t res;
 if ( (res = checkPid(__FUNCTION__) ) != OK) return res;

 Mutex::Autolock icl(mBinderSerializationLock);

 if (!mDevice.get()) return DEAD_OBJECT;

 CameraMetadata metadata;
 if ( (res = mDevice->createDefaultRequest(templateId, &metadata) ) == OK &&
        request != NULL) {

        request->swap(metadata);
 }

 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool send_app_scn(rfc_slot_t *slot) {
 if(slot->scn_notified == true) {
 return true;
 }
  slot->scn_notified = true;
 return sock_send_all(slot->fd, (const uint8_t*)&slot->scn, sizeof(slot->scn)) == sizeof(slot->scn);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long mkvparser::UnserializeFloat(
    IMkvReader* pReader,
    long long pos,
    long long size_,
    double& result)
{
    assert(pReader);
    assert(pos >= 0);
 
    if ((size_ != 4) && (size_ != 8))
        return E_FILE_FORMAT_INVALID;
 
    const long size = static_cast<long>(size_);
 
    unsigned char buf[8];
 
    const int status = pReader->Read(pos, size, buf);
 
    if (status < 0)  //error
        return status;
 
    if (size == 4)
    {
        union
        {
            float f;
            unsigned long ff;
        };
 
        ff = 0;
 
        for (int i = 0;;)
        {
            ff |= buf[i];
 
            if (++i >= 4)
                break;
 
            ff <<= 8;
        }
        result = f;
    }
    else
    {
        assert(size == 8);
        union
        {
            double d;
            unsigned long long dd;
        };
        dd = 0;
        for (int i = 0;;)
        {
            dd |= buf[i];
            if (++i >= 8)
                break;
            dd <<= 8;
        }
        result = d;
    }
    return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_dec_p_b_slice(dec_state_t *ps_dec)
{
    WORD16 *pi2_vld_out;
    UWORD32 i;
 yuv_buf_t *ps_cur_frm_buf      = &ps_dec->s_cur_frm_buf;

    UWORD32 u4_frm_offset          = 0;
 const dec_mb_params_t *ps_dec_mb_params;
    IMPEG2D_ERROR_CODES_T e_error   = (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;

    pi2_vld_out = ps_dec->ai2_vld_buf;
    memset(ps_dec->ai2_pred_mv,0,sizeof(ps_dec->ai2_pred_mv));

    ps_dec->u2_prev_intra_mb    = 0;
    ps_dec->u2_first_mb       = 1;

    ps_dec->u2_picture_width = ps_dec->u2_frame_width;

 if(ps_dec->u2_picture_structure != FRAME_PICTURE)
 {
        ps_dec->u2_picture_width <<= 1;
 if(ps_dec->u2_picture_structure == BOTTOM_FIELD)
 {
            u4_frm_offset = ps_dec->u2_frame_width;
 }
 }

 do
 {
        UWORD32 u4_x_offset, u4_y_offset;
        WORD32 ret;


        UWORD32 u4_x_dst_offset = 0;
        UWORD32 u4_y_dst_offset = 0;
        UWORD8  *pu1_out_p;
        UWORD8  *pu1_pred;
        WORD32 u4_pred_strd;

        IMPEG2D_TRACE_MB_START(ps_dec->u2_mb_x, ps_dec->u2_mb_y);

 if(ps_dec->e_pic_type == B_PIC)
            ret = impeg2d_dec_pnb_mb_params(ps_dec);
 else
            ret = impeg2d_dec_p_mb_params(ps_dec);

 
         if(ret)
             return IMPEG2D_MB_TEX_DECODE_ERR;
         IMPEG2D_TRACE_MB_START(ps_dec->u2_mb_x, ps_dec->u2_mb_y);
 
         u4_x_dst_offset = u4_frm_offset + (ps_dec->u2_mb_x << 4);
        u4_y_dst_offset = (ps_dec->u2_mb_y << 4) * ps_dec->u2_picture_width;
        pu1_out_p = ps_cur_frm_buf->pu1_y + u4_x_dst_offset + u4_y_dst_offset;
 if(ps_dec->u2_prev_intra_mb == 0)
 {
            UWORD32 offset_x, offset_y, stride;
            UWORD16 index = (ps_dec->u2_motion_type);
 /*only for non intra mb's*/
 if(ps_dec->e_mb_pred == BIDIRECT)
 {
                ps_dec_mb_params = &ps_dec->ps_func_bi_direct[index];
 }
 else
 {
                ps_dec_mb_params = &ps_dec->ps_func_forw_or_back[index];
 }

            stride = ps_dec->u2_picture_width;

            offset_x = u4_frm_offset + (ps_dec->u2_mb_x << 4);

            offset_y = (ps_dec->u2_mb_y << 4);

            ps_dec->s_dest_buf.pu1_y = ps_cur_frm_buf->pu1_y + offset_y * stride + offset_x;

            stride = stride >> 1;

            ps_dec->s_dest_buf.pu1_u = ps_cur_frm_buf->pu1_u + (offset_y >> 1) * stride
 + (offset_x >> 1);

            ps_dec->s_dest_buf.pu1_v = ps_cur_frm_buf->pu1_v + (offset_y >> 1) * stride
 + (offset_x >> 1);

            PROFILE_DISABLE_MC_IF0
            ps_dec_mb_params->pf_mc(ps_dec);

 }
 for(i = 0; i < NUM_LUMA_BLKS; ++i)
 {
 if((ps_dec->u2_cbp & (1 << (BLOCKS_IN_MB - 1 - i))) != 0)
 {
                e_error = ps_dec->pf_vld_inv_quant(ps_dec, pi2_vld_out, ps_dec->pu1_inv_scan_matrix,
                              ps_dec->u2_prev_intra_mb, Y_LUMA, 0);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }

                u4_x_offset = gai2_impeg2_blk_x_off[i];

 if(ps_dec->u2_field_dct == 0)
                    u4_y_offset = gai2_impeg2_blk_y_off_frm[i] ;
 else
                    u4_y_offset = gai2_impeg2_blk_y_off_fld[i] ;





                IMPEG2D_IDCT_INP_STATISTICS(pi2_vld_out, ps_dec->u4_non_zero_cols, ps_dec->u4_non_zero_rows);

                PROFILE_DISABLE_IDCT_IF0
 {
                    WORD32 idx;
 if(1 == (ps_dec->u4_non_zero_cols | ps_dec->u4_non_zero_rows))
                        idx = 0;
 else
                        idx = 1;

 if(0 == ps_dec->u2_prev_intra_mb)
 {
                        pu1_pred = pu1_out_p + u4_y_offset * ps_dec->u2_picture_width + u4_x_offset;
                        u4_pred_strd = ps_dec->u2_picture_width << ps_dec->u2_field_dct;
 }
 else
 {
                        pu1_pred = (UWORD8 *)gau1_impeg2_zerobuf;
                        u4_pred_strd = 8;
 }

                    ps_dec->pf_idct_recon[idx * 2 + ps_dec->i4_last_value_one](pi2_vld_out,
                                                            ps_dec->ai2_idct_stg1,
                                                            pu1_pred,
                                                            pu1_out_p + u4_y_offset * ps_dec->u2_picture_width + u4_x_offset,
 8,
                                                            u4_pred_strd,
                                                            ps_dec->u2_picture_width << ps_dec->u2_field_dct,
 ~ps_dec->u4_non_zero_cols, ~ps_dec->u4_non_zero_rows);
 }
 }

 }

 /* For U and V blocks, divide the x and y offsets by 2. */
        u4_x_dst_offset >>= 1;
        u4_y_dst_offset >>= 2;


 /* In case of chrominance blocks the DCT will be frame DCT */
 /* i = 0, U component and i = 1 is V componet */
 if((ps_dec->u2_cbp & 0x02) != 0)
 {
            pu1_out_p = ps_cur_frm_buf->pu1_u + u4_x_dst_offset + u4_y_dst_offset;
            e_error = ps_dec->pf_vld_inv_quant(ps_dec, pi2_vld_out, ps_dec->pu1_inv_scan_matrix,
                          ps_dec->u2_prev_intra_mb, U_CHROMA, 0);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }


            IMPEG2D_IDCT_INP_STATISTICS(pi2_vld_out, ps_dec->u4_non_zero_cols, ps_dec->u4_non_zero_rows);

            PROFILE_DISABLE_IDCT_IF0
 {
                WORD32 idx;
 if(1 == (ps_dec->u4_non_zero_cols | ps_dec->u4_non_zero_rows))
                    idx = 0;
 else
                    idx = 1;

 if(0 == ps_dec->u2_prev_intra_mb)
 {
                    pu1_pred = pu1_out_p;
                    u4_pred_strd = ps_dec->u2_picture_width >> 1;
 }
 else
 {
                    pu1_pred = (UWORD8 *)gau1_impeg2_zerobuf;
                    u4_pred_strd = 8;
 }

                ps_dec->pf_idct_recon[idx * 2 + ps_dec->i4_last_value_one](pi2_vld_out,
                                                        ps_dec->ai2_idct_stg1,
                                                        pu1_pred,
                                                        pu1_out_p,
 8,
                                                        u4_pred_strd,
                                                        ps_dec->u2_picture_width >> 1,
 ~ps_dec->u4_non_zero_cols, ~ps_dec->u4_non_zero_rows);

 }

 }


 if((ps_dec->u2_cbp & 0x01) != 0)
 {
            pu1_out_p = ps_cur_frm_buf->pu1_v + u4_x_dst_offset + u4_y_dst_offset;
            e_error = ps_dec->pf_vld_inv_quant(ps_dec, pi2_vld_out, ps_dec->pu1_inv_scan_matrix,
                          ps_dec->u2_prev_intra_mb, V_CHROMA, 0);
 if ((IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE != e_error)
 {
 return e_error;
 }


            IMPEG2D_IDCT_INP_STATISTICS(pi2_vld_out, ps_dec->u4_non_zero_cols, ps_dec->u4_non_zero_rows);

            PROFILE_DISABLE_IDCT_IF0
 {
                WORD32 idx;
 if(1 == (ps_dec->u4_non_zero_cols | ps_dec->u4_non_zero_rows))
                    idx = 0;
 else
                    idx = 1;
 if(0 == ps_dec->u2_prev_intra_mb)
 {
                    pu1_pred = pu1_out_p;
                    u4_pred_strd = ps_dec->u2_picture_width >> 1;
 }
 else
 {
                    pu1_pred = (UWORD8 *)gau1_impeg2_zerobuf;
                    u4_pred_strd = 8;
 }

                ps_dec->pf_idct_recon[idx * 2 + ps_dec->i4_last_value_one](pi2_vld_out,
                                                        ps_dec->ai2_idct_stg1,
                                                        pu1_pred,
                                                        pu1_out_p,
 8,
                                                        u4_pred_strd,
                                                        ps_dec->u2_picture_width >> 1,
 ~ps_dec->u4_non_zero_cols, ~ps_dec->u4_non_zero_rows);

 }
 }

        ps_dec->u2_num_mbs_left--;
        ps_dec->u2_first_mb = 0;
        ps_dec->u2_mb_x++;

 if(ps_dec->s_bit_stream.u4_offset > ps_dec->s_bit_stream.u4_max_offset)
 {
 return IMPEG2D_BITSTREAM_BUFF_EXCEEDED_ERR;
 }
 else if (ps_dec->u2_mb_x == ps_dec->u2_num_horiz_mb)
 {
            ps_dec->u2_mb_x = 0;
            ps_dec->u2_mb_y++;

 }
 }
 while(ps_dec->u2_num_mbs_left != 0 && impeg2d_bit_stream_nxt(&ps_dec->s_bit_stream,23) != 0x0);
 return e_error;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t ESDS::parseDecoderConfigDescriptor(size_t offset, size_t size) {
 if (size < 13) {
 return ERROR_MALFORMED;
 }

    mObjectTypeIndication = mData[offset];

    offset += 13;
    size -= 13;

 if (size == 0) {
        mDecoderSpecificOffset = 0;
        mDecoderSpecificLength = 0;
 return OK;
 }

 uint8_t tag;
 size_t sub_offset, sub_size;
 status_t err = skipDescriptorHeader(
            offset, size, &tag, &sub_offset, &sub_size);

 if (err != OK) {
 return err;
 }

 if (tag != kTag_DecoderSpecificInfo) {
 return ERROR_MALFORMED;
 }

    mDecoderSpecificOffset = sub_offset;
    mDecoderSpecificLength = sub_size;

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_dm_hh_open_failed(bt_bdaddr_t *bdaddr)
{
 if (pairing_cb.state == BT_BOND_STATE_BONDING &&
            bdcmp(bdaddr->address, pairing_cb.bd_addr) == 0)
 {
        bond_state_changed(BT_STATUS_FAIL, bdaddr, BT_BOND_STATE_NONE);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gamma_test(png_modifier *pmIn, PNG_CONST png_byte colour_typeIn,
    PNG_CONST png_byte bit_depthIn, PNG_CONST int palette_numberIn,
    PNG_CONST int interlace_typeIn,
    PNG_CONST double file_gammaIn, PNG_CONST double screen_gammaIn,
    PNG_CONST png_byte sbitIn, PNG_CONST int threshold_testIn,
    PNG_CONST char *name,
    PNG_CONST int use_input_precisionIn, PNG_CONST int scale16In,
    PNG_CONST int expand16In, PNG_CONST int do_backgroundIn,
    PNG_CONST png_color_16 *bkgd_colorIn, double bkgd_gammaIn)
 {
    gamma_display d;
    context(&pmIn->this, fault);

   gamma_display_init(&d, pmIn, FILEID(colour_typeIn, bit_depthIn,
      palette_numberIn, interlace_typeIn, 0, 0, 0),
      file_gammaIn, screen_gammaIn, sbitIn,
      threshold_testIn, use_input_precisionIn, scale16In,
      expand16In, do_backgroundIn, bkgd_colorIn, bkgd_gammaIn);

 Try
 {
      png_structp pp;
      png_infop pi;
      gama_modification gama_mod;
      srgb_modification srgb_mod;
      sbit_modification sbit_mod;

 /* For the moment don't use the png_modifier support here. */
      d.pm->encoding_counter = 0;
      modifier_set_encoding(d.pm); /* Just resets everything */
      d.pm->current_gamma = d.file_gamma;

 /* Make an appropriate modifier to set the PNG file gamma to the
       * given gamma value and the sBIT chunk to the given precision.
       */
      d.pm->modifications = NULL;
      gama_modification_init(&gama_mod, d.pm, d.file_gamma);
      srgb_modification_init(&srgb_mod, d.pm, 127 /*delete*/);
 if (d.sbit > 0)
         sbit_modification_init(&sbit_mod, d.pm, d.sbit);

 
       modification_reset(d.pm->modifications);
 
      /* Get a png_struct for writing the image. */
       pp = set_modifier_for_read(d.pm, &pi, d.this.id, name);
       standard_palette_init(&d.this);
 
 /* Introduce the correct read function. */
 if (d.pm->this.progressive)
 {
 /* Share the row function with the standard implementation. */
         png_set_progressive_read_fn(pp, &d, gamma_info, progressive_row,
            gamma_end);

 /* Now feed data into the reader until we reach the end: */
         modifier_progressive_read(d.pm, pp, pi);
 }
 else
 {
 /* modifier_read expects a png_modifier* */
         png_set_read_fn(pp, d.pm, modifier_read);

 /* Check the header values: */
         png_read_info(pp, pi);

 /* Process the 'info' requirements. Only one image is generated */
         gamma_info_imp(&d, pp, pi);

         sequential_row(&d.this, pp, pi, -1, 0);

 if (!d.this.speed)
            gamma_image_validate(&d, pp, pi);
 else
            d.this.ps->validated = 1;
 }

      modifier_reset(d.pm);

 if (d.pm->log && !d.threshold_test && !d.this.speed)
         fprintf(stderr, "%d bit %s %s: max error %f (%.2g, %2g%%)\n",
            d.this.bit_depth, colour_types[d.this.colour_type], name,
            d.maxerrout, d.maxerrabs, 100*d.maxerrpc);

 /* Log the summary values too. */
 if (d.this.colour_type == 0 || d.this.colour_type == 4)
 {
 switch (d.this.bit_depth)
 {
 case 1:
 break;

 case 2:
 if (d.maxerrout > d.pm->error_gray_2)
               d.pm->error_gray_2 = d.maxerrout;

 break;

 case 4:
 if (d.maxerrout > d.pm->error_gray_4)
               d.pm->error_gray_4 = d.maxerrout;

 break;

 case 8:
 if (d.maxerrout > d.pm->error_gray_8)
               d.pm->error_gray_8 = d.maxerrout;

 break;

 case 16:
 if (d.maxerrout > d.pm->error_gray_16)
               d.pm->error_gray_16 = d.maxerrout;

 break;

 default:
            png_error(pp, "bad bit depth (internal: 1)");
 }
 }

 else if (d.this.colour_type == 2 || d.this.colour_type == 6)
 {
 switch (d.this.bit_depth)
 {
 case 8:

 if (d.maxerrout > d.pm->error_color_8)
               d.pm->error_color_8 = d.maxerrout;

 break;

 case 16:

 if (d.maxerrout > d.pm->error_color_16)
               d.pm->error_color_16 = d.maxerrout;

 break;

 default:
            png_error(pp, "bad bit depth (internal: 2)");
 }
 }

 else if (d.this.colour_type == 3)
 {
 if (d.maxerrout > d.pm->error_indexed)
            d.pm->error_indexed = d.maxerrout;
 }
 }

 Catch(fault)
      modifier_reset(voidcast(png_modifier*,(void*)fault));
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: gamma_end(png_structp ppIn, png_infop pi)
{
   png_const_structp pp = ppIn;
   gamma_display *dp = voidcast(gamma_display*, png_get_progressive_ptr(pp));

 if (!dp->this.speed)
      gamma_image_validate(dp, pp, pi);
 else
      dp->this.ps->validated = 1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: write_byte(struct file *file, int b)
 /* Write one byte to the output - this causes a fatal error if the write
    * fails and the read of this PNG file immediately terminates.  Just
    * increments the write count if there is no output file.
    */
{
 if (file->out != NULL)
 {
 if (putc(b, file->out) != b)
 {
         file->write_errno = errno;
         file->status_code |= WRITE_ERROR;
         stop(file, WRITE_ERROR_CODE, "write byte");
 }
 }

 ++(file->write_count);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static wifi_error wifi_start_rssi_monitoring(wifi_request_id id, wifi_interface_handle
                        iface, s8 max_rssi, s8 min_rssi, wifi_rssi_event_handler eh)
{
    ALOGD("Start RSSI monitor %d", id);
    wifi_handle handle = getWifiHandle(iface);
 SetRSSIMonitorCommand *cmd = new SetRSSIMonitorCommand(id, iface, max_rssi, min_rssi, eh);
    wifi_register_cmd(handle, id, cmd);

    wifi_error result = (wifi_error)cmd->start();
 if (result != WIFI_SUCCESS) {
        wifi_unregister_cmd(handle, id);
 }
 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IHEVCD_ERROR_T ihevcd_parse_slice_data(codec_t *ps_codec)
{

    IHEVCD_ERROR_T ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
    WORD32 end_of_slice_flag = 0;
 sps_t *ps_sps;
 pps_t *ps_pps;
 slice_header_t *ps_slice_hdr;
    WORD32 end_of_pic;
 tile_t *ps_tile, *ps_tile_prev;
    WORD32 i;
    WORD32 ctb_addr;
    WORD32 tile_idx;
    WORD32 cabac_init_idc;
    WORD32 ctb_size;
    WORD32 num_ctb_in_row;
    WORD32 num_min4x4_in_ctb;
    WORD32 slice_qp;
    WORD32 slice_start_ctb_idx;
    WORD32 tile_start_ctb_idx;


    ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr_base;
    ps_pps = ps_codec->s_parse.ps_pps_base;
    ps_sps = ps_codec->s_parse.ps_sps_base;

 /* Get current slice header, pps and sps */
    ps_slice_hdr += (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1));
    ps_pps  += ps_slice_hdr->i1_pps_id;
    ps_sps  += ps_pps->i1_sps_id;

 if(0 != ps_codec->s_parse.i4_cur_slice_idx)
 {
 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
            ps_codec->s_parse.i4_cur_independent_slice_idx++;
 if(MAX_SLICE_HDR_CNT == ps_codec->s_parse.i4_cur_independent_slice_idx)
                ps_codec->s_parse.i4_cur_independent_slice_idx = 0;
 }
 }


    ctb_size = 1 << ps_sps->i1_log2_ctb_size;
    num_min4x4_in_ctb = (ctb_size / 4) * (ctb_size / 4);
    num_ctb_in_row = ps_sps->i2_pic_wd_in_ctb;

 /* Update the parse context */
 if(0 == ps_codec->i4_slice_error)
 {
        ps_codec->s_parse.i4_ctb_x = ps_slice_hdr->i2_ctb_x;
        ps_codec->s_parse.i4_ctb_y = ps_slice_hdr->i2_ctb_y;
 }
    ps_codec->s_parse.ps_pps = ps_pps;
    ps_codec->s_parse.ps_sps = ps_sps;
    ps_codec->s_parse.ps_slice_hdr = ps_slice_hdr;

 /* Derive Tile positions for the current CTB */
 /* Change this to lookup if required */
    ihevcd_get_tile_pos(ps_pps, ps_sps, ps_codec->s_parse.i4_ctb_x,
                        ps_codec->s_parse.i4_ctb_y,
 &ps_codec->s_parse.i4_ctb_tile_x,
 &ps_codec->s_parse.i4_ctb_tile_y,
 &tile_idx);
    ps_codec->s_parse.ps_tile = ps_pps->ps_tile + tile_idx;
    ps_codec->s_parse.i4_cur_tile_idx = tile_idx;
    ps_tile = ps_codec->s_parse.ps_tile;
 if(tile_idx)
        ps_tile_prev = ps_tile - 1;
 else
        ps_tile_prev = ps_tile;

 /* If the present slice is dependent, then store the previous
     * independent slices' ctb x and y values for decoding process */
 if(0 == ps_codec->i4_slice_error)
 {
 if(1 == ps_slice_hdr->i1_dependent_slice_flag)
 {
 /*If slice is present at the start of a new tile*/
 if((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                ps_codec->s_parse.i4_ctb_slice_x = 0;
                ps_codec->s_parse.i4_ctb_slice_y = 0;
 }
 }

 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
            ps_codec->s_parse.i4_ctb_slice_x = 0;
            ps_codec->s_parse.i4_ctb_slice_y = 0;
 }
 }

 /* Frame level initializations */
 if((0 == ps_codec->s_parse.i4_ctb_y) &&
 (0 == ps_codec->s_parse.i4_ctb_x))
 {
        ret = ihevcd_parse_pic_init(ps_codec);
        RETURN_IF((ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS), ret);

        ps_codec->s_parse.pu4_pic_tu_idx[0] = 0;
        ps_codec->s_parse.pu4_pic_pu_idx[0] = 0;
        ps_codec->s_parse.i4_cur_independent_slice_idx = 0;
        ps_codec->s_parse.i4_ctb_tile_x = 0;
        ps_codec->s_parse.i4_ctb_tile_y = 0;
 }

 {
 /* Updating the poc list of current slice to ps_mv_buf */
 mv_buf_t *ps_mv_buf = ps_codec->s_parse.ps_cur_mv_buf;

 if(ps_slice_hdr->i1_num_ref_idx_l1_active != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                ps_mv_buf->l1_collocated_poc[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_pic_buf)->i4_abs_poc;
                ps_mv_buf->u1_l1_collocated_poc_lt[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_pic_buf)->u1_used_as_ref;
 }
 }

 if(ps_slice_hdr->i1_num_ref_idx_l0_active != 0)
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
                ps_mv_buf->l0_collocated_poc[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_pic_buf)->i4_abs_poc;
                ps_mv_buf->u1_l0_collocated_poc_lt[(ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1))][i] = ((pic_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_pic_buf)->u1_used_as_ref;
 }
 }
 }

 /*Initialize the low delay flag at the beginning of every slice*/
 if((0 == ps_codec->s_parse.i4_ctb_slice_x) || (0 == ps_codec->s_parse.i4_ctb_slice_y))
 {
 /* Lowdelay flag */
        WORD32 cur_poc, ref_list_poc, flag = 1;
        cur_poc = ps_slice_hdr->i4_abs_pic_order_cnt;
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l0_active; i++)
 {
            ref_list_poc = ((mv_buf_t *)ps_slice_hdr->as_ref_pic_list0[i].pv_mv_buf)->i4_abs_poc;
 if(ref_list_poc > cur_poc)
 {
                flag = 0;
 break;
 }
 }
 if(flag && (ps_slice_hdr->i1_slice_type == BSLICE))
 {
 for(i = 0; i < ps_slice_hdr->i1_num_ref_idx_l1_active; i++)
 {
                ref_list_poc = ((mv_buf_t *)ps_slice_hdr->as_ref_pic_list1[i].pv_mv_buf)->i4_abs_poc;
 if(ref_list_poc > cur_poc)
 {
                    flag = 0;
 break;
 }
 }
 }
        ps_slice_hdr->i1_low_delay_flag = flag;
 }

 /* initialize the cabac init idc based on slice type */
 if(ps_slice_hdr->i1_slice_type == ISLICE)
 {
        cabac_init_idc = 0;
 }
 else if(ps_slice_hdr->i1_slice_type == PSLICE)
 {
        cabac_init_idc = ps_slice_hdr->i1_cabac_init_flag ? 2 : 1;
 }
 else
 {
        cabac_init_idc = ps_slice_hdr->i1_cabac_init_flag ? 1 : 2;
 }

    slice_qp = ps_slice_hdr->i1_slice_qp_delta + ps_pps->i1_pic_init_qp;
    slice_qp = CLIP3(slice_qp, 0, 51);

 /*Update QP value for every indepndent slice or for every dependent slice that begins at the start of a new tile*/
 if((0 == ps_slice_hdr->i1_dependent_slice_flag) ||
 ((1 == ps_slice_hdr->i1_dependent_slice_flag) && ((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))))
 {
        ps_codec->s_parse.u4_qp = slice_qp;
 }

 /*Cabac init at the beginning of a slice*/
 if((1 == ps_slice_hdr->i1_dependent_slice_flag) && (!((ps_codec->s_parse.i4_ctb_tile_x == 0) && (ps_codec->s_parse.i4_ctb_tile_y == 0))))
 {
 if((0 == ps_pps->i1_entropy_coding_sync_enabled_flag) || (ps_pps->i1_entropy_coding_sync_enabled_flag && (0 != ps_codec->s_parse.i4_ctb_x)))
 {
            ihevcd_cabac_reset(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm);
 }
 }
 else if((0 == ps_pps->i1_entropy_coding_sync_enabled_flag) || (ps_pps->i1_entropy_coding_sync_enabled_flag && (0 != ps_codec->s_parse.i4_ctb_x)))
 {
        ret = ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm,
                                slice_qp,
                                cabac_init_idc,
 &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);
 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 {
            ps_codec->i4_slice_error = 1;
            end_of_slice_flag = 1;
            ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }
 }


 do
 {

 {
            WORD32 cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
 if(1 == ps_codec->i4_num_cores && 0 == cur_ctb_idx % RESET_TU_BUF_NCTB)
 {
                ps_codec->s_parse.ps_tu = ps_codec->s_parse.ps_pic_tu;
                ps_codec->s_parse.i4_pic_tu_idx = 0;
 }
 }

        end_of_pic = 0;
 /* Section:7.3.7 Coding tree unit syntax */
 /* coding_tree_unit() inlined here */
 /* If number of cores is greater than 1, then add job to the queue */
 /* At the start of ctb row parsing in a tile, queue a job for processing the current tile row */
        ps_codec->s_parse.i4_ctb_num_pcm_blks = 0;


 /*At the beginning of each tile-which is not the beginning of a slice, cabac context must be initialized.
         * Hence, check for the tile beginning here */
 if(((0 == ps_codec->s_parse.i4_ctb_tile_x) && (0 == ps_codec->s_parse.i4_ctb_tile_y))
 && (!((ps_tile->u1_pos_x == 0) && (ps_tile->u1_pos_y == 0)))
 && (!((0 == ps_codec->s_parse.i4_ctb_slice_x) && (0 == ps_codec->s_parse.i4_ctb_slice_y))))
 {
            slice_qp = ps_slice_hdr->i1_slice_qp_delta + ps_pps->i1_pic_init_qp;
            slice_qp = CLIP3(slice_qp, 0, 51);
            ps_codec->s_parse.u4_qp = slice_qp;

            ihevcd_get_tile_pos(ps_pps, ps_sps, ps_codec->s_parse.i4_ctb_x,
                                ps_codec->s_parse.i4_ctb_y,
 &ps_codec->s_parse.i4_ctb_tile_x,
 &ps_codec->s_parse.i4_ctb_tile_y,
 &tile_idx);

            ps_codec->s_parse.ps_tile = ps_pps->ps_tile + tile_idx;
            ps_codec->s_parse.i4_cur_tile_idx = tile_idx;
            ps_tile_prev = ps_tile - 1;

            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 /*For slices that span across multiple tiles*/
 if(slice_start_ctb_idx < tile_start_ctb_idx)
 { /* 2 Cases
             * 1 - slice spans across frame-width- but does not start from 1st column
             * 2 - Slice spans across multiple tiles anywhere is a frame
             */
                ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y - ps_slice_hdr->i2_ctb_y;
 if(!(((ps_slice_hdr->i2_ctb_x + ps_tile_prev->u2_wd) % ps_sps->i2_pic_wd_in_ctb) == ps_tile->u1_pos_x)) //Case 2
 {
 if(ps_slice_hdr->i2_ctb_y <= ps_tile->u1_pos_y)
 {
 if(ps_slice_hdr->i2_ctb_x > ps_tile->u1_pos_x)
 {
                            ps_codec->s_parse.i4_ctb_slice_y -= 1;
 }
 }
 }
 /*ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y - ps_slice_hdr->i2_ctb_y;
                if (ps_slice_hdr->i2_ctb_y <= ps_tile->u1_pos_y)
                {
                    if (ps_slice_hdr->i2_ctb_x > ps_tile->u1_pos_x )
                    {
                        ps_codec->s_parse.i4_ctb_slice_y -= 1 ;
                    }
                }*/
 }

 if(!ps_slice_hdr->i1_dependent_slice_flag)
 {
                ret = ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm,
                                        slice_qp,
                                        cabac_init_idc,
 &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);
 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 {
                    ps_codec->i4_slice_error = 1;
                    end_of_slice_flag = 1;
                    ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }

 }
 }
 /* If number of cores is greater than 1, then add job to the queue */
 /* At the start of ctb row parsing in a tile, queue a job for processing the current tile row */

 if(0 == ps_codec->s_parse.i4_ctb_tile_x)
 {

 if(1 < ps_codec->i4_num_cores)
 {
 proc_job_t s_job;
                IHEVCD_ERROR_T ret;
                s_job.i4_cmd    = CMD_PROCESS;
                s_job.i2_ctb_cnt = (WORD16)ps_tile->u2_wd;
                s_job.i2_ctb_x = (WORD16)ps_codec->s_parse.i4_ctb_x;
                s_job.i2_ctb_y = (WORD16)ps_codec->s_parse.i4_ctb_y;
                s_job.i2_slice_idx = (WORD16)ps_codec->s_parse.i4_cur_slice_idx;
                s_job.i4_tu_coeff_data_ofst = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data -
 (UWORD8 *)ps_codec->s_parse.pv_pic_tu_coeff_data;
                ret = ihevcd_jobq_queue((jobq_t *)ps_codec->s_parse.pv_proc_jobq, &s_job, sizeof(proc_job_t), 1);

 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 return ret;
 }
 else
 {
 process_ctxt_t *ps_proc = &ps_codec->as_process[0];
                WORD32 tu_coeff_data_ofst = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data -
 (UWORD8 *)ps_codec->s_parse.pv_pic_tu_coeff_data;

 /* If the codec is running in single core mode,
                 * initialize zeroth process context
                 * TODO: Dual core mode might need a different implementation instead of jobq
                 */

                ps_proc->i4_ctb_cnt = ps_tile->u2_wd;
                ps_proc->i4_ctb_x   = ps_codec->s_parse.i4_ctb_x;
                ps_proc->i4_ctb_y   = ps_codec->s_parse.i4_ctb_y;
                ps_proc->i4_cur_slice_idx = ps_codec->s_parse.i4_cur_slice_idx;

                ihevcd_init_proc_ctxt(ps_proc, tu_coeff_data_ofst);
 }
 }


 /* Restore cabac context model from top right CTB if entropy sync is enabled */
 if(ps_pps->i1_entropy_coding_sync_enabled_flag)
 {
 /*TODO Handle single CTB and top-right belonging to a different slice */
 if(0 == ps_codec->s_parse.i4_ctb_x)
 {
                WORD32 default_ctxt = 0;

 if((0 == ps_codec->s_parse.i4_ctb_slice_y) && (!ps_slice_hdr->i1_dependent_slice_flag))
                    default_ctxt = 1;
 if(1 == ps_sps->i2_pic_wd_in_ctb)
                    default_ctxt = 1;

                ps_codec->s_parse.u4_qp = slice_qp;
 if(default_ctxt)
 {
                    ret = ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm,
                                            slice_qp,
                                            cabac_init_idc,
 &gau1_ihevc_cab_ctxts[cabac_init_idc][slice_qp][0]);

 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 {
                        ps_codec->i4_slice_error = 1;
                        end_of_slice_flag = 1;
                        ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }
 }
 else
 {
                    ret = ihevcd_cabac_init(&ps_codec->s_parse.s_cabac,
 &ps_codec->s_parse.s_bitstrm,
                                            slice_qp,
                                            cabac_init_idc,
 (const UWORD8 *)&ps_codec->s_parse.s_cabac.au1_ctxt_models_sync);

 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 {
                        ps_codec->i4_slice_error = 1;
                        end_of_slice_flag = 1;
                        ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }
 }
 }
 }



 if(0 == ps_codec->i4_slice_error)
 {
 if(ps_slice_hdr->i1_slice_sao_luma_flag || ps_slice_hdr->i1_slice_sao_chroma_flag)
                ihevcd_parse_sao(ps_codec);
 }
 else
 {
 sao_t *ps_sao = ps_codec->s_parse.ps_pic_sao +
                            ps_codec->s_parse.i4_ctb_x +
                            ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 /* Default values */
            ps_sao->b3_y_type_idx = 0;
            ps_sao->b3_cb_type_idx = 0;
            ps_sao->b3_cr_type_idx = 0;
 }


 {
            WORD32 ctb_indx;
            ctb_indx = ps_codec->s_parse.i4_ctb_x + ps_sps->i2_pic_wd_in_ctb * ps_codec->s_parse.i4_ctb_y;
            ps_codec->s_parse.s_bs_ctxt.pu1_pic_qp_const_in_ctb[ctb_indx >> 3] |= (1 << (ctb_indx & 7));
 {
                UWORD16 *pu1_slice_idx = ps_codec->s_parse.pu1_slice_idx;
                pu1_slice_idx[ctb_indx] = ps_codec->s_parse.i4_cur_independent_slice_idx;
 }
 }

 if(0 == ps_codec->i4_slice_error)
 {
 tu_t *ps_tu = ps_codec->s_parse.ps_tu;
            WORD32 i4_tu_cnt = ps_codec->s_parse.s_cu.i4_tu_cnt;
            WORD32 i4_pic_tu_idx = ps_codec->s_parse.i4_pic_tu_idx;

 pu_t *ps_pu = ps_codec->s_parse.ps_pu;
            WORD32 i4_pic_pu_idx = ps_codec->s_parse.i4_pic_pu_idx;

            UWORD8 *pu1_tu_coeff_data = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data;

            ret = ihevcd_parse_coding_quadtree(ps_codec,
 (ps_codec->s_parse.i4_ctb_x << ps_sps->i1_log2_ctb_size),
 (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size),
                                               ps_sps->i1_log2_ctb_size,
 0);
 /* Check for error */

             if (ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
             {
                 /* Reset tu and pu parameters, and signal current ctb as skip */
                WORD32 pu_skip_wd, pu_skip_ht;
                WORD32 rows_remaining, cols_remaining;
                 WORD32 tu_coeff_data_reset_size;
 
                /* Set pu wd and ht based on whether the ctb is complete or not */
                rows_remaining = ps_sps->i2_pic_height_in_luma_samples
                                - (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size);
                pu_skip_ht = MIN(ctb_size, rows_remaining);
                cols_remaining = ps_sps->i2_pic_width_in_luma_samples
                                - (ps_codec->s_parse.i4_ctb_x << ps_sps->i1_log2_ctb_size);
                pu_skip_wd = MIN(ctb_size, cols_remaining);
                 ps_codec->s_parse.ps_tu = ps_tu;
                 ps_codec->s_parse.s_cu.i4_tu_cnt = i4_tu_cnt;
                 ps_codec->s_parse.i4_pic_tu_idx = i4_pic_tu_idx;


                 ps_codec->s_parse.ps_pu = ps_pu;
                 ps_codec->s_parse.i4_pic_pu_idx = i4_pic_pu_idx;
 
                ps_tu->b1_cb_cbf = 0;
                ps_tu->b1_cr_cbf = 0;
                ps_tu->b1_y_cbf = 0;
                ps_tu->b4_pos_x = 0;
                ps_tu->b4_pos_y = 0;
                ps_tu->b1_transquant_bypass = 0;
                ps_tu->b3_size = (ps_sps->i1_log2_ctb_size - 2);
                ps_tu->b7_qp = ps_codec->s_parse.u4_qp;
                ps_tu->b3_chroma_intra_mode_idx = INTRA_PRED_CHROMA_IDX_NONE;
                ps_tu->b6_luma_intra_mode   = INTRA_PRED_NONE;
                ps_tu->b1_first_tu_in_cu = 1;
                 tu_coeff_data_reset_size = (UWORD8 *)ps_codec->s_parse.pv_tu_coeff_data - pu1_tu_coeff_data;
                 memset(pu1_tu_coeff_data, 0, tu_coeff_data_reset_size);
                 ps_codec->s_parse.pv_tu_coeff_data = (void *)pu1_tu_coeff_data;
 
                ps_codec->s_parse.ps_tu++;
                ps_codec->s_parse.s_cu.i4_tu_cnt++;
                ps_codec->s_parse.i4_pic_tu_idx++;
                ps_codec->s_parse.s_cu.i4_pred_mode = PRED_MODE_SKIP;
                ps_codec->s_parse.s_cu.i4_part_mode = PART_2Nx2N;
                ps_pu->b2_part_idx = 0;
                ps_pu->b4_pos_x = 0;
                ps_pu->b4_pos_y = 0;
                ps_pu->b4_wd = (pu_skip_wd >> 2) - 1;
                ps_pu->b4_ht = (pu_skip_ht >> 2) - 1;
                ps_pu->b1_intra_flag = 0;
                ps_pu->b3_part_mode = ps_codec->s_parse.s_cu.i4_part_mode;
                ps_pu->b1_merge_flag = 1;
                ps_pu->b3_merge_idx = 0;
                ps_codec->s_parse.ps_pu++;
                ps_codec->s_parse.i4_pic_pu_idx++;
 
                 /* Set slice error to suppress further parsing and
                  * signal end of slice.
                 */
                ps_codec->i4_slice_error = 1;
                end_of_slice_flag = 1;
                ret = (IHEVCD_ERROR_T)IHEVCD_SUCCESS;
 }

         }
         else
         {
            tu_t *ps_tu = ps_codec->s_parse.ps_tu;
            pu_t *ps_pu = ps_codec->s_parse.ps_pu;
            WORD32 pu_skip_wd, pu_skip_ht;
            WORD32 rows_remaining, cols_remaining;
            /* Set pu wd and ht based on whether the ctb is complete or not */
            rows_remaining = ps_sps->i2_pic_height_in_luma_samples
                            - (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size);
            pu_skip_ht = MIN(ctb_size, rows_remaining);
            cols_remaining = ps_sps->i2_pic_width_in_luma_samples
                            - (ps_codec->s_parse.i4_ctb_x << ps_sps->i1_log2_ctb_size);
            pu_skip_wd = MIN(ctb_size, cols_remaining);
            ps_tu->b1_cb_cbf = 0;
            ps_tu->b1_cr_cbf = 0;
            ps_tu->b1_y_cbf = 0;
            ps_tu->b4_pos_x = 0;
            ps_tu->b4_pos_y = 0;
            ps_tu->b1_transquant_bypass = 0;
            ps_tu->b3_size = (ps_sps->i1_log2_ctb_size - 2);
            ps_tu->b7_qp = ps_codec->s_parse.u4_qp;
            ps_tu->b3_chroma_intra_mode_idx = INTRA_PRED_CHROMA_IDX_NONE;
            ps_tu->b6_luma_intra_mode   = INTRA_PRED_NONE;
            ps_tu->b1_first_tu_in_cu = 1;
            ps_codec->s_parse.ps_tu++;
            ps_codec->s_parse.s_cu.i4_tu_cnt++;
            ps_codec->s_parse.i4_pic_tu_idx++;
            ps_codec->s_parse.s_cu.i4_pred_mode = PRED_MODE_SKIP;
            ps_codec->s_parse.s_cu.i4_part_mode = PART_2Nx2N;
            ps_pu->b2_part_idx = 0;
            ps_pu->b4_pos_x = 0;
            ps_pu->b4_pos_y = 0;
            ps_pu->b4_wd = (pu_skip_wd >> 2) - 1;
            ps_pu->b4_ht = (pu_skip_ht >> 2) - 1;
            ps_pu->b1_intra_flag = 0;
            ps_pu->b3_part_mode = ps_codec->s_parse.s_cu.i4_part_mode;
            ps_pu->b1_merge_flag = 1;
            ps_pu->b3_merge_idx = 0;
            ps_codec->s_parse.ps_pu++;
            ps_codec->s_parse.i4_pic_pu_idx++;
         }
 
         if(0 == ps_codec->i4_slice_error)
            end_of_slice_flag = ihevcd_cabac_decode_terminate(&ps_codec->s_parse.s_cabac, &ps_codec->s_parse.s_bitstrm);

        AEV_TRACE("end_of_slice_flag", end_of_slice_flag, ps_codec->s_parse.s_cabac.u4_range);


 /* In case of tiles or entropy sync, terminate cabac and copy cabac context backed up at the end of top-right CTB */
 if(ps_pps->i1_tiles_enabled_flag || ps_pps->i1_entropy_coding_sync_enabled_flag)
 {
            WORD32 end_of_tile = 0;
            WORD32 end_of_tile_row = 0;

 /* Take a back up of cabac context models if entropy sync is enabled */
 if(ps_pps->i1_entropy_coding_sync_enabled_flag || ps_pps->i1_tiles_enabled_flag)
 {
 if(1 == ps_codec->s_parse.i4_ctb_x)
 {
                    WORD32 size = sizeof(ps_codec->s_parse.s_cabac.au1_ctxt_models);
                    memcpy(&ps_codec->s_parse.s_cabac.au1_ctxt_models_sync, &ps_codec->s_parse.s_cabac.au1_ctxt_models, size);
 }
 }

 /* Since tiles and entropy sync are not enabled simultaneously, the following will not result in any problems */
 if((ps_codec->s_parse.i4_ctb_tile_x + 1) == (ps_tile->u2_wd))
 {
                end_of_tile_row = 1;
 if((ps_codec->s_parse.i4_ctb_tile_y + 1) == ps_tile->u2_ht)
                    end_of_tile = 1;
 }
 if((0 == end_of_slice_flag) &&
 ((ps_pps->i1_tiles_enabled_flag && end_of_tile) ||
 (ps_pps->i1_entropy_coding_sync_enabled_flag && end_of_tile_row)))
 {
                WORD32 end_of_sub_stream_one_bit;
                end_of_sub_stream_one_bit = ihevcd_cabac_decode_terminate(&ps_codec->s_parse.s_cabac, &ps_codec->s_parse.s_bitstrm);
                AEV_TRACE("end_of_sub_stream_one_bit", end_of_sub_stream_one_bit, ps_codec->s_parse.s_cabac.u4_range);

 /* TODO: Remove the check for offset when HM is updated to include a byte unconditionally even for aligned location */
 /* For Ittiam streams this check should not be there, for HM9.1 streams this should be there */
 if(ps_codec->s_parse.s_bitstrm.u4_bit_ofst % 8)
                    ihevcd_bits_flush_to_byte_boundary(&ps_codec->s_parse.s_bitstrm);

                UNUSED(end_of_sub_stream_one_bit);
 }
 }
 {
            WORD32 ctb_indx;

            ctb_addr = ps_codec->s_parse.i4_ctb_y * num_ctb_in_row + ps_codec->s_parse.i4_ctb_x;

            ctb_indx = ++ctb_addr;

 /* Store pu_idx for next CTB in frame level pu_idx array */

 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                        ctb_indx = ctb_addr; //Next continuous ctb address
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                        ctb_indx = ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }

            ps_codec->s_parse.pu4_pic_pu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_pu_idx;
            ps_codec->s_parse.i4_next_pu_ctb_cnt = ctb_indx;

            ps_codec->s_parse.pu1_pu_map += num_min4x4_in_ctb;

 /* Store tu_idx for next CTB in frame level tu_idx array */
 if(1 == ps_codec->i4_num_cores)
 {
                ctb_indx = (0 == ctb_addr % RESET_TU_BUF_NCTB) ?
                                RESET_TU_BUF_NCTB : ctb_addr % RESET_TU_BUF_NCTB;

 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                    ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                            ctb_indx = (0 == ctb_addr % RESET_TU_BUF_NCTB) ?
                                            RESET_TU_BUF_NCTB : ctb_addr % RESET_TU_BUF_NCTB;
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                            ctb_indx =  ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }
                ps_codec->s_parse.i4_next_tu_ctb_cnt = ctb_indx;
                ps_codec->s_parse.pu4_pic_tu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_tu_idx;
 }
 else
 {
                ctb_indx = ctb_addr;
 if((ps_tile->u2_wd == (ps_codec->s_parse.i4_ctb_tile_x + 1)) && (ps_tile->u2_wd != ps_sps->i2_pic_wd_in_ctb))
 {
                    ctb_indx = (ps_sps->i2_pic_wd_in_ctb * (ps_codec->s_parse.i4_ctb_tile_y + 1 + ps_tile->u1_pos_y)) + ps_tile->u1_pos_x; //idx is the beginning of next row in current tile.
 if(ps_tile->u2_ht == (ps_codec->s_parse.i4_ctb_tile_y + 1))
 {
 if((ps_tile->u2_wd + ps_tile->u1_pos_x == ps_sps->i2_pic_wd_in_ctb) && ((ps_tile->u2_ht + ps_tile->u1_pos_y == ps_sps->i2_pic_ht_in_ctb)))
 {
                            ctb_indx = ctb_addr;
 }
 else //Not last tile's end , but a tile end
 {
 tile_t *ps_next_tile = ps_codec->s_parse.ps_tile + 1;
                            ctb_indx =  ps_next_tile->u1_pos_x + (ps_next_tile->u1_pos_y * ps_sps->i2_pic_wd_in_ctb); //idx is the beginning of first row in next tile.
 }
 }
 }
                ps_codec->s_parse.i4_next_tu_ctb_cnt = ctb_indx;
                ps_codec->s_parse.pu4_pic_tu_idx[ctb_indx] = ps_codec->s_parse.i4_pic_tu_idx;
 }
            ps_codec->s_parse.pu1_tu_map += num_min4x4_in_ctb;
 }


 if(ps_codec->i4_num_cores <= MV_PRED_NUM_CORES_THRESHOLD)
 {
 /*************************************************/
 /****************   MV pred **********************/
 /*************************************************/
            WORD8 u1_top_ctb_avail = 1;
            WORD8 u1_left_ctb_avail = 1;
            WORD8 u1_top_lt_ctb_avail = 1;
            WORD8 u1_top_rt_ctb_avail = 1;
            WORD16 i2_wd_in_ctb;

            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 if((slice_start_ctb_idx < tile_start_ctb_idx))
 {
                i2_wd_in_ctb = ps_sps->i2_pic_wd_in_ctb;
 }
 else
 {
                i2_wd_in_ctb = ps_tile->u2_wd;
 }
 /* slice and tile boundaries */
 if((0 == ps_codec->s_parse.i4_ctb_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                u1_top_ctb_avail = 0;
                u1_top_lt_ctb_avail = 0;
                u1_top_rt_ctb_avail = 0;
 }

 if((0 == ps_codec->s_parse.i4_ctb_x) || (0 == ps_codec->s_parse.i4_ctb_tile_x))
 {
                u1_left_ctb_avail = 0;
                u1_top_lt_ctb_avail = 0;
 if((0 == ps_codec->s_parse.i4_ctb_slice_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                    u1_top_ctb_avail = 0;
 if((i2_wd_in_ctb - 1) != ps_codec->s_parse.i4_ctb_slice_x) //TODO: For tile, not implemented
 {
                        u1_top_rt_ctb_avail = 0;
 }
 }
 }
 /*For slices not beginning at start of a ctb row*/
 else if(ps_codec->s_parse.i4_ctb_x > 0)
 {
 if((0 == ps_codec->s_parse.i4_ctb_slice_y) || (0 == ps_codec->s_parse.i4_ctb_tile_y))
 {
                    u1_top_ctb_avail = 0;
                    u1_top_lt_ctb_avail = 0;
 if(0 == ps_codec->s_parse.i4_ctb_slice_x)
 {
                        u1_left_ctb_avail = 0;
 }
 if((i2_wd_in_ctb - 1) != ps_codec->s_parse.i4_ctb_slice_x)
 {
                        u1_top_rt_ctb_avail = 0;
 }
 }
 else if((1 == ps_codec->s_parse.i4_ctb_slice_y) && (0 == ps_codec->s_parse.i4_ctb_slice_x))
 {
                    u1_top_lt_ctb_avail = 0;
 }
 }

 if(((ps_sps->i2_pic_wd_in_ctb - 1) == ps_codec->s_parse.i4_ctb_x) || ((ps_tile->u2_wd - 1) == ps_codec->s_parse.i4_ctb_tile_x))
 {
                u1_top_rt_ctb_avail = 0;
 }

 if(PSLICE == ps_slice_hdr->i1_slice_type
 || BSLICE == ps_slice_hdr->i1_slice_type)
 {
 mv_ctxt_t s_mv_ctxt;
 process_ctxt_t *ps_proc;
                UWORD32 *pu4_ctb_top_pu_idx;
                UWORD32 *pu4_ctb_left_pu_idx;
                UWORD32 *pu4_ctb_top_left_pu_idx;
                WORD32 i4_ctb_pu_cnt;
                WORD32 cur_ctb_idx;
                WORD32 next_ctb_idx;
                WORD32 cur_pu_idx;
                ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
                next_ctb_idx = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                i4_ctb_pu_cnt = ps_codec->s_parse.pu4_pic_pu_idx[next_ctb_idx]
 - ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];

                cur_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];

                pu4_ctb_top_pu_idx = ps_proc->pu4_pic_pu_idx_top
 + (ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE);
                pu4_ctb_left_pu_idx = ps_proc->pu4_pic_pu_idx_left;
                pu4_ctb_top_left_pu_idx = &ps_proc->u4_ctb_top_left_pu_idx;

 /* Initializing s_mv_ctxt */
 {
                    s_mv_ctxt.ps_pps = ps_pps;
                    s_mv_ctxt.ps_sps = ps_sps;
                    s_mv_ctxt.ps_slice_hdr = ps_slice_hdr;
                    s_mv_ctxt.i4_ctb_x = ps_codec->s_parse.i4_ctb_x;
                    s_mv_ctxt.i4_ctb_y = ps_codec->s_parse.i4_ctb_y;
                    s_mv_ctxt.ps_pu = &ps_codec->s_parse.ps_pic_pu[cur_pu_idx];
                    s_mv_ctxt.ps_pic_pu = ps_codec->s_parse.ps_pic_pu;
                    s_mv_ctxt.ps_tile = ps_tile;
                    s_mv_ctxt.pu4_pic_pu_idx_map = ps_proc->pu4_pic_pu_idx_map;
                    s_mv_ctxt.pu4_pic_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx;
                    s_mv_ctxt.pu1_pic_pu_map = ps_codec->s_parse.pu1_pic_pu_map;
                    s_mv_ctxt.i4_ctb_pu_cnt = i4_ctb_pu_cnt;
                    s_mv_ctxt.i4_ctb_start_pu_idx = cur_pu_idx;
                    s_mv_ctxt.u1_top_ctb_avail = u1_top_ctb_avail;
                    s_mv_ctxt.u1_top_rt_ctb_avail = u1_top_rt_ctb_avail;
                    s_mv_ctxt.u1_top_lt_ctb_avail = u1_top_lt_ctb_avail;
                    s_mv_ctxt.u1_left_ctb_avail = u1_left_ctb_avail;
 }

                ihevcd_get_mv_ctb(&s_mv_ctxt, pu4_ctb_top_pu_idx,
                                  pu4_ctb_left_pu_idx, pu4_ctb_top_left_pu_idx);

 }
 else
 {
                WORD32 num_minpu_in_ctb = (ctb_size / MIN_PU_SIZE) * (ctb_size / MIN_PU_SIZE);
                UWORD8 *pu1_pic_pu_map_ctb = ps_codec->s_parse.pu1_pic_pu_map +
 (ps_codec->s_parse.i4_ctb_x + ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb) * num_minpu_in_ctb;
 process_ctxt_t *ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                WORD32 row, col;
                WORD32 pu_cnt;
                WORD32 num_pu_per_ctb;
                WORD32 cur_ctb_idx;
                WORD32 next_ctb_idx;
                WORD32 ctb_start_pu_idx;
                UWORD32 *pu4_nbr_pu_idx = ps_proc->pu4_pic_pu_idx_map;
                WORD32 nbr_pu_idx_strd = MAX_CTB_SIZE / MIN_PU_SIZE + 2;
 pu_t *ps_pu;

 for(row = 0; row < ctb_size / MIN_PU_SIZE; row++)
 {
 for(col = 0; col < ctb_size / MIN_PU_SIZE; col++)
 {
                        pu1_pic_pu_map_ctb[row * ctb_size / MIN_PU_SIZE + col] = 0;
 }
 }


 /* Neighbor PU idx update inside CTB */
 /* 1byte per 4x4. Indicates the PU idx that 4x4 block belongs to */

                cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);
                next_ctb_idx = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                num_pu_per_ctb = ps_codec->s_parse.pu4_pic_pu_idx[next_ctb_idx]
 - ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                ctb_start_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                ps_pu = &ps_codec->s_parse.ps_pic_pu[ctb_start_pu_idx];

 for(pu_cnt = 0; pu_cnt < num_pu_per_ctb; pu_cnt++, ps_pu++)
 {
                    UWORD32 cur_pu_idx;
                    WORD32 pu_ht = (ps_pu->b4_ht + 1) << 2;
                    WORD32 pu_wd = (ps_pu->b4_wd + 1) << 2;

                    cur_pu_idx = ctb_start_pu_idx + pu_cnt;

 for(row = 0; row < pu_ht / MIN_PU_SIZE; row++)
 for(col = 0; col < pu_wd / MIN_PU_SIZE; col++)
                            pu4_nbr_pu_idx[(1 + ps_pu->b4_pos_x + col)
 + (1 + ps_pu->b4_pos_y + row)
 * nbr_pu_idx_strd] =
                                            cur_pu_idx;
 }

 /* Updating Top and Left pointers */
 {
                    WORD32 rows_remaining = ps_sps->i2_pic_height_in_luma_samples
 - (ps_codec->s_parse.i4_ctb_y << ps_sps->i1_log2_ctb_size);
                    WORD32 ctb_size_left = MIN(ctb_size, rows_remaining);

 /* Top Left */
 /* saving top left before updating top ptr, as updating top ptr will overwrite the top left for the next ctb */
                    ps_proc->u4_ctb_top_left_pu_idx = ps_proc->pu4_pic_pu_idx_top[(ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE) + ctb_size / MIN_PU_SIZE - 1];
 for(i = 0; i < ctb_size / MIN_PU_SIZE; i++)
 {
 /* Left */
 /* Last column of au4_nbr_pu_idx */
                        ps_proc->pu4_pic_pu_idx_left[i] = pu4_nbr_pu_idx[(ctb_size / MIN_PU_SIZE)
 + (i + 1) * nbr_pu_idx_strd];
 /* Top */
 /* Last row of au4_nbr_pu_idx */
                        ps_proc->pu4_pic_pu_idx_top[(ps_codec->s_parse.i4_ctb_x * ctb_size / MIN_PU_SIZE) + i] =
                                        pu4_nbr_pu_idx[(ctb_size_left / MIN_PU_SIZE) * nbr_pu_idx_strd + i + 1];

 }
 }
 }

 /*************************************************/
 /******************  BS, QP  *********************/
 /*************************************************/
 /* Check if deblock is disabled for the current slice or if it is disabled for the current picture
             * because of disable deblock api
             */
 if(0 == ps_codec->i4_disable_deblk_pic)
 {
 if((0 == ps_slice_hdr->i1_slice_disable_deblocking_filter_flag) &&
 (0 == ps_codec->i4_slice_error))
 {
                    WORD32 i4_ctb_tu_cnt;
                    WORD32 cur_ctb_idx, next_ctb_idx;
                    WORD32 cur_pu_idx;
                    WORD32 cur_tu_idx;
 process_ctxt_t *ps_proc;

                    ps_proc = &ps_codec->as_process[(ps_codec->i4_num_cores == 1) ? 1 : (ps_codec->i4_num_cores - 1)];
                    cur_ctb_idx = ps_codec->s_parse.i4_ctb_x
 + ps_codec->s_parse.i4_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

                    cur_pu_idx = ps_codec->s_parse.pu4_pic_pu_idx[cur_ctb_idx];
                    next_ctb_idx = ps_codec->s_parse.i4_next_tu_ctb_cnt;
 if(1 == ps_codec->i4_num_cores)
 {
                        i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                        ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];

                        cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx % RESET_TU_BUF_NCTB];
 }
 else
 {
                        i4_ctb_tu_cnt = ps_codec->s_parse.pu4_pic_tu_idx[next_ctb_idx] -
                                        ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];

                        cur_tu_idx = ps_codec->s_parse.pu4_pic_tu_idx[cur_ctb_idx];
 }

                    ps_codec->s_parse.s_bs_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
                    ps_codec->s_parse.s_bs_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
                    ps_codec->s_parse.s_bs_ctxt.ps_codec = ps_codec;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tu_cnt = i4_ctb_tu_cnt;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_x = ps_codec->s_parse.i4_ctb_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_y = ps_codec->s_parse.i4_ctb_y;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tile_x = ps_codec->s_parse.i4_ctb_tile_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_tile_y = ps_codec->s_parse.i4_ctb_tile_y;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_slice_x = ps_codec->s_parse.i4_ctb_slice_x;
                    ps_codec->s_parse.s_bs_ctxt.i4_ctb_slice_y = ps_codec->s_parse.i4_ctb_slice_y;
                    ps_codec->s_parse.s_bs_ctxt.ps_tu = &ps_codec->s_parse.ps_pic_tu[cur_tu_idx];
                    ps_codec->s_parse.s_bs_ctxt.ps_pu = &ps_codec->s_parse.ps_pic_pu[cur_pu_idx];
                    ps_codec->s_parse.s_bs_ctxt.pu4_pic_pu_idx_map = ps_proc->pu4_pic_pu_idx_map;
                    ps_codec->s_parse.s_bs_ctxt.i4_next_pu_ctb_cnt = ps_codec->s_parse.i4_next_pu_ctb_cnt;
                    ps_codec->s_parse.s_bs_ctxt.i4_next_tu_ctb_cnt = ps_codec->s_parse.i4_next_tu_ctb_cnt;
                    ps_codec->s_parse.s_bs_ctxt.pu1_slice_idx = ps_codec->s_parse.pu1_slice_idx;
                    ps_codec->s_parse.s_bs_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;
                    ps_codec->s_parse.s_bs_ctxt.ps_tile = ps_codec->s_parse.ps_tile;

 if(ISLICE == ps_slice_hdr->i1_slice_type)
 {
                        ihevcd_ctb_boundary_strength_islice(&ps_codec->s_parse.s_bs_ctxt);
 }
 else
 {
                        ihevcd_ctb_boundary_strength_pbslice(&ps_codec->s_parse.s_bs_ctxt);
 }
 }
 else
 {
                    WORD32 bs_strd = (ps_sps->i2_pic_wd_in_ctb + 1) * (ctb_size * ctb_size / 8 / 16);

                    UWORD32 *pu4_vert_bs = (UWORD32 *)((UWORD8 *)ps_codec->s_parse.s_bs_ctxt.pu4_pic_vert_bs +
                                    ps_codec->s_parse.i4_ctb_x * (ctb_size * ctb_size / 8 / 16) +
                                    ps_codec->s_parse.i4_ctb_y * bs_strd);
                    UWORD32 *pu4_horz_bs = (UWORD32 *)((UWORD8 *)ps_codec->s_parse.s_bs_ctxt.pu4_pic_horz_bs +
                                    ps_codec->s_parse.i4_ctb_x * (ctb_size * ctb_size / 8 / 16) +
                                    ps_codec->s_parse.i4_ctb_y * bs_strd);

                    memset(pu4_vert_bs, 0, (ctb_size / 8 + 1) * (ctb_size / 4) / 8 * 2);
                    memset(pu4_horz_bs, 0, (ctb_size / 8) * (ctb_size / 4) / 8 * 2);

 }
 }

 }


 /* Update the parse status map */
 {
 sps_t *ps_sps = ps_codec->s_parse.ps_sps;
            UWORD8 *pu1_buf;
            WORD32 idx;
            idx = (ps_codec->s_parse.i4_ctb_x);
            idx += ((ps_codec->s_parse.i4_ctb_y) * ps_sps->i2_pic_wd_in_ctb);
            pu1_buf = (ps_codec->pu1_parse_map + idx);
 *pu1_buf = 1;
 }

 /* Increment CTB x and y positions */
        ps_codec->s_parse.i4_ctb_tile_x++;
        ps_codec->s_parse.i4_ctb_x++;
        ps_codec->s_parse.i4_ctb_slice_x++;

 /*If tiles are enabled, handle the slice counters differently*/
 if(ps_pps->i1_tiles_enabled_flag)
 {
            tile_start_ctb_idx = ps_tile->u1_pos_x
 + ps_tile->u1_pos_y * (ps_sps->i2_pic_wd_in_ctb);

            slice_start_ctb_idx =  ps_slice_hdr->i2_ctb_x
 + ps_slice_hdr->i2_ctb_y * (ps_sps->i2_pic_wd_in_ctb);

 if((slice_start_ctb_idx < tile_start_ctb_idx))
 {
 if(ps_codec->s_parse.i4_ctb_slice_x == (ps_tile->u1_pos_x + ps_tile->u2_wd))
 {
 /* Reached end of slice row within a tile /frame */
                    ps_codec->s_parse.i4_ctb_slice_y++;
                    ps_codec->s_parse.i4_ctb_slice_x = ps_tile->u1_pos_x; //todo:Check
 }
 }
 else if(ps_codec->s_parse.i4_ctb_slice_x == (ps_tile->u2_wd))
 {
                ps_codec->s_parse.i4_ctb_slice_y++;
                ps_codec->s_parse.i4_ctb_slice_x = 0;
 }
 }
 else
 {
 if(ps_codec->s_parse.i4_ctb_slice_x == ps_tile->u2_wd)
 {
 /* Reached end of slice row within a tile /frame */
                ps_codec->s_parse.i4_ctb_slice_y++;
                ps_codec->s_parse.i4_ctb_slice_x = 0;
 }
 }


 if(ps_codec->s_parse.i4_ctb_tile_x == (ps_tile->u2_wd))
 {
 /* Reached end of tile row */
            ps_codec->s_parse.i4_ctb_tile_x = 0;
            ps_codec->s_parse.i4_ctb_x = ps_tile->u1_pos_x;

            ps_codec->s_parse.i4_ctb_tile_y++;
            ps_codec->s_parse.i4_ctb_y++;

 if(ps_codec->s_parse.i4_ctb_tile_y == (ps_tile->u2_ht))
 {
 /* Reached End of Tile */
                ps_codec->s_parse.i4_ctb_tile_y = 0;
                ps_codec->s_parse.i4_ctb_tile_x = 0;
                ps_codec->s_parse.ps_tile++;

 if((ps_tile->u2_ht + ps_tile->u1_pos_y  ==  ps_sps->i2_pic_ht_in_ctb) && (ps_tile->u2_wd + ps_tile->u1_pos_x  ==  ps_sps->i2_pic_wd_in_ctb))
 {
 /* Reached end of frame */
                    end_of_pic = 1;
                    ps_codec->s_parse.i4_ctb_x = 0;
                    ps_codec->s_parse.i4_ctb_y = ps_sps->i2_pic_ht_in_ctb;
 }
 else
 {
 /* Initialize ctb_x and ctb_y to start of next tile */
                    ps_tile = ps_codec->s_parse.ps_tile;
                    ps_codec->s_parse.i4_ctb_x = ps_tile->u1_pos_x;
                    ps_codec->s_parse.i4_ctb_y = ps_tile->u1_pos_y;
                    ps_codec->s_parse.i4_ctb_tile_y = 0;
                    ps_codec->s_parse.i4_ctb_tile_x = 0;
                    ps_codec->s_parse.i4_ctb_slice_x = ps_tile->u1_pos_x;
                    ps_codec->s_parse.i4_ctb_slice_y = ps_tile->u1_pos_y;

 }
 }

 }

        ps_codec->s_parse.i4_next_ctb_indx = ps_codec->s_parse.i4_ctb_x +
                        ps_codec->s_parse.i4_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 /* If the current slice is in error, check if the next slice's address
         * is reached and mark the end_of_slice flag */
 if(ps_codec->i4_slice_error)
 {
 slice_header_t *ps_slice_hdr_next = ps_slice_hdr + 1;
            WORD32 next_slice_addr = ps_slice_hdr_next->i2_ctb_x +
                            ps_slice_hdr_next->i2_ctb_y * ps_sps->i2_pic_wd_in_ctb;

 if(ps_codec->s_parse.i4_next_ctb_indx == next_slice_addr)
                end_of_slice_flag = 1;
 }

 /* If the codec is running in single core mode
         * then call process function for current CTB
         */
 if((1 == ps_codec->i4_num_cores) && (ps_codec->s_parse.i4_ctb_tile_x == 0))
 {
 process_ctxt_t *ps_proc = &ps_codec->as_process[0];
            ps_proc->i4_ctb_cnt = ps_proc->ps_tile->u2_wd;
            ihevcd_process(ps_proc);
 }

 /* If the bytes for the current slice are exhausted
         * set end_of_slice flag to 1
         * This slice will be treated as incomplete */
 if((UWORD8 *)ps_codec->s_parse.s_bitstrm.pu1_buf_max + BITSTRM_OFF_THRS <
 ((UWORD8 *)ps_codec->s_parse.s_bitstrm.pu4_buf + (ps_codec->s_parse.s_bitstrm.u4_bit_ofst / 8)))
 {

 if(0 == ps_codec->i4_slice_error)
                end_of_slice_flag = 1;
 }


 if(end_of_pic)
 break;
 } while(!end_of_slice_flag);

 /* Reset slice error */
    ps_codec->i4_slice_error = 0;

 /* Increment the slice index for parsing next slice */
 if(0 == end_of_pic)
 {
 while(1)
 {

            WORD32 parse_slice_idx;
            parse_slice_idx = ps_codec->s_parse.i4_cur_slice_idx;
            parse_slice_idx++;

 {
 /* If the next slice header is not initialized, update cur_slice_idx and break */
 if((1 == ps_codec->i4_num_cores) || (0 != (parse_slice_idx & (MAX_SLICE_HDR_CNT - 1))))
 {
                    ps_codec->s_parse.i4_cur_slice_idx = parse_slice_idx;
 break;
 }

 /* If the next slice header is initialised, wait for the parsed slices to be processed */
 else
 {
                    WORD32 ctb_indx = 0;

 while(ctb_indx != ps_sps->i4_pic_size_in_ctb)
 {
                        WORD32 parse_status = *(ps_codec->pu1_parse_map + ctb_indx);
 volatile WORD32 proc_status = *(ps_codec->pu1_proc_map + ctb_indx) & 1;

 if(parse_status == proc_status)
                            ctb_indx++;
 }
                    ps_codec->s_parse.i4_cur_slice_idx = parse_slice_idx;
 break;
 }

 }
 }

 }
 else
 {
#if FRAME_ILF_PAD
 if(FRAME_ILF_PAD && 1 == ps_codec->i4_num_cores)
 {
 if(ps_slice_hdr->i4_abs_pic_order_cnt == 0)
 {
                DUMP_PRE_ILF(ps_codec->as_process[0].pu1_cur_pic_luma,
                             ps_codec->as_process[0].pu1_cur_pic_chroma,
                             ps_sps->i2_pic_width_in_luma_samples,
                             ps_sps->i2_pic_height_in_luma_samples,
                             ps_codec->i4_strd);

                DUMP_BS(ps_codec->as_process[0].s_bs_ctxt.pu4_pic_vert_bs,
                        ps_codec->as_process[0].s_bs_ctxt.pu4_pic_horz_bs,
                        ps_sps->i2_pic_wd_in_ctb * (ctb_size * ctb_size / 8 / 16) * ps_sps->i2_pic_ht_in_ctb,
 (ps_sps->i2_pic_wd_in_ctb + 1) * (ctb_size * ctb_size / 8 / 16) * ps_sps->i2_pic_ht_in_ctb);

                DUMP_QP(ps_codec->as_process[0].s_bs_ctxt.pu1_pic_qp,
 (ps_sps->i2_pic_height_in_luma_samples * ps_sps->i2_pic_width_in_luma_samples) / (MIN_CU_SIZE * MIN_CU_SIZE));

                DUMP_QP_CONST_IN_CTB(ps_codec->as_process[0].s_bs_ctxt.pu1_pic_qp_const_in_ctb,
 (ps_sps->i2_pic_height_in_luma_samples * ps_sps->i2_pic_width_in_luma_samples) / (MIN_CTB_SIZE * MIN_CTB_SIZE) / 8);

                DUMP_NO_LOOP_FILTER(ps_codec->as_process[0].pu1_pic_no_loop_filter_flag,
 (ps_sps->i2_pic_width_in_luma_samples / MIN_CU_SIZE) * (ps_sps->i2_pic_height_in_luma_samples / MIN_CU_SIZE) / 8);

                DUMP_OFFSETS(ps_slice_hdr->i1_beta_offset_div2,
                             ps_slice_hdr->i1_tc_offset_div2,
                             ps_pps->i1_pic_cb_qp_offset,
                             ps_pps->i1_pic_cr_qp_offset);
 }
            ps_codec->s_parse.s_deblk_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
            ps_codec->s_parse.s_deblk_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
            ps_codec->s_parse.s_deblk_ctxt.ps_codec = ps_codec;
            ps_codec->s_parse.s_deblk_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;
            ps_codec->s_parse.s_deblk_ctxt.is_chroma_yuv420sp_vu = (ps_codec->e_ref_chroma_fmt == IV_YUV_420SP_VU);

            ps_codec->s_parse.s_sao_ctxt.ps_pps = ps_codec->s_parse.ps_pps;
            ps_codec->s_parse.s_sao_ctxt.ps_sps = ps_codec->s_parse.ps_sps;
            ps_codec->s_parse.s_sao_ctxt.ps_codec = ps_codec;
            ps_codec->s_parse.s_sao_ctxt.ps_slice_hdr = ps_codec->s_parse.ps_slice_hdr;

            ihevcd_ilf_pad_frame(&ps_codec->s_parse.s_deblk_ctxt, &ps_codec->s_parse.s_sao_ctxt);

 }
#endif
        ps_codec->s_parse.i4_end_of_frame = 1;
 }
 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: unsigned long long Track::GetUid() const
{
    return m_info.uid;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  int PreProcessingFx_ProcessReverse(effect_handle_t     self,
                                    audio_buffer_t    *inBuffer,
                                   audio_buffer_t    *outBuffer)
 {
     preproc_effect_t * effect = (preproc_effect_t *)self;
     int    status = 0;

 if (effect == NULL){
        ALOGW("PreProcessingFx_ProcessReverse() ERROR effect == NULL");
 return -EINVAL;
 }
 preproc_session_t * session = (preproc_session_t *)effect->session;

 if (inBuffer == NULL  || inBuffer->raw == NULL){
        ALOGW("PreProcessingFx_ProcessReverse() ERROR bad pointer");
 return -EINVAL;
 }

    session->revProcessedMsk |= (1<<effect->procId);



 if ((session->revProcessedMsk & session->revEnabledMsk) == session->revEnabledMsk) {
        effect->session->revProcessedMsk = 0;
 if (session->revResampler != NULL) {
 size_t fr = session->frameCount - session->framesRev;
 if (inBuffer->frameCount < fr) {
                fr = inBuffer->frameCount;
 }
 if (session->revBufSize < session->framesRev + fr) {
                session->revBufSize = session->framesRev + fr;
                session->revBuf = (int16_t *)realloc(session->revBuf,
                                  session->revBufSize * session->inChannelCount * sizeof(int16_t));
 }
            memcpy(session->revBuf + session->framesRev * session->inChannelCount,
                   inBuffer->s16,
                   fr * session->inChannelCount * sizeof(int16_t));

            session->framesRev += fr;
            inBuffer->frameCount = fr;
 if (session->framesRev < session->frameCount) {
 return 0;
 }
 spx_uint32_t frIn = session->framesRev;
 spx_uint32_t frOut = session->apmFrameCount;
 if (session->inChannelCount == 1) {
                speex_resampler_process_int(session->revResampler,
 0,
                                            session->revBuf,
 &frIn,
                                            session->revFrame->_payloadData,
 &frOut);
 } else {
                speex_resampler_process_interleaved_int(session->revResampler,
                                                        session->revBuf,
 &frIn,
                                                        session->revFrame->_payloadData,
 &frOut);
 }
            memcpy(session->revBuf,
                   session->revBuf + frIn * session->inChannelCount,
 (session->framesRev - frIn) * session->inChannelCount * sizeof(int16_t));
            session->framesRev -= frIn;
 } else {
 size_t fr = session->frameCount - session->framesRev;
 if (inBuffer->frameCount < fr) {
                fr = inBuffer->frameCount;
 }
            memcpy(session->revFrame->_payloadData + session->framesRev * session->inChannelCount,
                   inBuffer->s16,
                   fr * session->inChannelCount * sizeof(int16_t));
            session->framesRev += fr;
            inBuffer->frameCount = fr;
 if (session->framesRev < session->frameCount) {
 return 0;
 }
            session->framesRev = 0;
 }
        session->revFrame->_payloadDataLengthInSamples =
                session->apmFrameCount * session->inChannelCount;
        effect->session->apm->AnalyzeReverseStream(session->revFrame);
 return 0;
 } else {
 return -ENODATA;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int main(int argc, const char **argv)
 {
 int result = 1;

 if (argc == 3)
 {
      png_image image;

 /* Only the image structure version number needs to be set. */
      memset(&image, 0, sizeof image);
      image.version = PNG_IMAGE_VERSION;

 if (png_image_begin_read_from_file(&image, argv[1]))
 {
         png_bytep buffer;

 /* Change this to try different formats!  If you set a colormap format
          * then you must also supply a colormap below.
          */
         image.format = PNG_FORMAT_RGBA;

         buffer = malloc(PNG_IMAGE_SIZE(image));

 if (buffer != NULL)
 {
 if (png_image_finish_read(&image, NULL/*background*/, buffer,
 0/*row_stride*/, NULL/*colormap for PNG_FORMAT_FLAG_COLORMAP */))
 {
 if (png_image_write_to_file(&image, argv[2],
 0/*convert_to_8bit*/, buffer, 0/*row_stride*/,
                  NULL/*colormap*/))
                  result = 0;

 else
                  fprintf(stderr, "pngtopng: write %s: %s\n", argv[2],
                      image.message);

               free(buffer);
 }

 else
 {
               fprintf(stderr, "pngtopng: read %s: %s\n", argv[1],
                   image.message);

 /* This is the only place where a 'free' is required; libpng does
                * the cleanup on error and success, but in this case we couldn't
                * complete the read because of running out of memory.
                */
               png_image_free(&image);
 }
 }

 else
            fprintf(stderr, "pngtopng: out of memory: %lu bytes\n",
 (unsigned long)PNG_IMAGE_SIZE(image));
 }

 else
 /* Failed to read the first argument: */
         fprintf(stderr, "pngtopng: %s: %s\n", argv[1], image.message);
 }

 else
 /* Wrong number of arguments */
      fprintf(stderr, "pngtopng: usage: pngtopng input-file output-file\n");

 
    return result;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void Chapters::Atom::Init() {
  m_string_uid = NULL;
  m_uid = 0;
  m_start_timecode = -1;
  m_stop_timecode = -1;

  m_displays = NULL;
  m_displays_size = 0;
  m_displays_count = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int SoundPool::load(int fd, int64_t offset, int64_t length, int priority __unused)
 {
     ALOGV("load: fd=%d, offset=%" PRId64 ", length=%" PRId64 ", priority=%d",
             fd, offset, length, priority);
    Mutex::Autolock lock(&mLock);
    sp<Sample> sample = new Sample(++mNextSampleID, fd, offset, length);
    mSamples.add(sample->sampleID(), sample);
    doLoad(sample);
    return sample->sampleID();
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: eager_reader_t *eager_reader_new(
 int fd_to_read,
 const allocator_t *allocator,
 size_t buffer_size,
 size_t max_buffer_count,
 const char *thread_name) {

  assert(fd_to_read != INVALID_FD);
  assert(allocator != NULL);
  assert(buffer_size > 0);
  assert(max_buffer_count > 0);
  assert(thread_name != NULL && *thread_name != '\0');

 eager_reader_t *ret = osi_calloc(sizeof(eager_reader_t));
 if (!ret) {
    LOG_ERROR("%s unable to allocate memory for new eager_reader.", __func__);
 goto error;
 }

  ret->allocator = allocator;
  ret->inbound_fd = fd_to_read;

  ret->bytes_available_fd = eventfd(0, 0);
 if (ret->bytes_available_fd == INVALID_FD) {
    LOG_ERROR("%s unable to create output reading semaphore.", __func__);
 goto error;
 }

  ret->buffer_size = buffer_size;

  ret->buffers = fixed_queue_new(max_buffer_count);
 if (!ret->buffers) {
    LOG_ERROR("%s unable to create buffers queue.", __func__);
 goto error;
 }

  ret->inbound_read_thread = thread_new(thread_name);
 if (!ret->inbound_read_thread) {
    LOG_ERROR("%s unable to make reading thread.", __func__);
 goto error;
 }

  ret->inbound_read_object = reactor_register(
    thread_get_reactor(ret->inbound_read_thread),
    fd_to_read,
    ret,
    inbound_data_waiting,
    NULL
 );

 return ret;

error:;
  eager_reader_free(ret);
 return NULL;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t allocateBufferWithBackup(
            node_id node, OMX_U32 port_index, const sp<IMemory> &params,
            buffer_id *buffer, OMX_U32 allottedSize) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeInt32(port_index);
        data.writeStrongBinder(IInterface::asBinder(params));
        data.writeInt32(allottedSize);
        remote()->transact(ALLOC_BUFFER_WITH_BACKUP, data, &reply);

 status_t err = reply.readInt32();
 if (err != OK) {
 *buffer = 0;

 return err;
 }

 *buffer = (buffer_id)reply.readInt32();

 return err;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool write_hci_command(hci_packet_t type, const void *packet, size_t length) {
 int sock = socket(AF_INET, SOCK_STREAM, IPPROTO_TCP);
 if (sock == INVALID_FD)
 goto error;

 struct sockaddr_in addr;

   addr.sin_family = AF_INET;
   addr.sin_addr.s_addr = htonl(0x7F000001);
   addr.sin_port = htons(8873);
  if (connect(sock, (const struct sockaddr *)&addr, sizeof(addr)) == -1)
     goto error;
 
  if (send(sock, &type, 1, 0) != 1)
     goto error;
 
  if (send(sock, &length, 2, 0) != 2)
     goto error;
 
  if (send(sock, packet, length, 0) != (ssize_t)length)
     goto error;
 
   close(sock);
 return true;

error:;
  close(sock);
 return false;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void command_timed_out(UNUSED_ATTR void *context) {
  pthread_mutex_lock(&commands_pending_response_lock);

 if (list_is_empty(commands_pending_response)) {
    LOG_ERROR("%s with no commands pending response", __func__);
 } else {
 waiting_command_t *wait_entry = list_front(commands_pending_response);
    pthread_mutex_unlock(&commands_pending_response_lock);

    LOG_ERROR("%s hci layer timeout waiting for response to a command. opcode: 0x%x", __func__, wait_entry->opcode);

   }
 
   LOG_ERROR("%s restarting the bluetooth process.", __func__);
  usleep(10000);
   kill(getpid(), SIGKILL);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setupVideoDecoder(
 const char *mime, const sp<AMessage> &msg, bool haveNativeWindow) {
 int32_t width, height;
 if (!msg->findInt32("width", &width)
 || !msg->findInt32("height", &height)) {
 return INVALID_OPERATION;
 }

    OMX_VIDEO_CODINGTYPE compressionFormat;
 status_t err = GetVideoCodingTypeFromMime(mime, &compressionFormat);

 if (err != OK) {
 return err;
 }

    err = setVideoPortFormatType(
            kPortIndexInput, compressionFormat, OMX_COLOR_FormatUnused);

 if (err != OK) {
 return err;
 }

 int32_t tmp;
 if (msg->findInt32("color-format", &tmp)) {
        OMX_COLOR_FORMATTYPE colorFormat =
 static_cast<OMX_COLOR_FORMATTYPE>(tmp);
        err = setVideoPortFormatType(
                kPortIndexOutput, OMX_VIDEO_CodingUnused, colorFormat, haveNativeWindow);
 if (err != OK) {
            ALOGW("[%s] does not support color format %d",
                  mComponentName.c_str(), colorFormat);
            err = setSupportedOutputFormat(!haveNativeWindow /* getLegacyFlexibleFormat */);
 }
 } else {
        err = setSupportedOutputFormat(!haveNativeWindow /* getLegacyFlexibleFormat */);
 }

 if (err != OK) {
 return err;
 }

 int32_t frameRateInt;
 float frameRateFloat;
 if (!msg->findFloat("frame-rate", &frameRateFloat)) {
 if (!msg->findInt32("frame-rate", &frameRateInt)) {
            frameRateInt = -1;
 }
        frameRateFloat = (float)frameRateInt;
 }

    err = setVideoFormatOnPort(
            kPortIndexInput, width, height, compressionFormat, frameRateFloat);

 if (err != OK) {
 return err;
 }

    err = setVideoFormatOnPort(
            kPortIndexOutput, width, height, OMX_VIDEO_CodingUnused);

 if (err != OK) {
 return err;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void config_set_int(config_t *config, const char *section, const char *key, int value) {
  assert(config != NULL);
  assert(section != NULL);
  assert(key != NULL);

 char value_str[32] = { 0 };
  sprintf(value_str, "%d", value);
  config_set_string(config, section, key, value_str);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   virtual void FramePktHook(const vpx_codec_cx_pkt_t *pkt) {
    if (pkt->data.frame.flags & VPX_FRAME_IS_KEY) {
    }
  }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void InitOMXParams(T *params) {
    memset(params, 0, sizeof(T));
    params->nSize = sizeof(T);
    params->nVersion.s.nVersionMajor = 1;
    params->nVersion.s.nVersionMinor = 0;
    params->nVersion.s.nRevision = 0;
    params->nVersion.s.nStep = 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int vol_effect_process(effect_handle_t self,
 audio_buffer_t *in_buffer,
 audio_buffer_t *out_buffer)
{
 int status = 0;
    ALOGV("%s Called ", __func__);

 vol_listener_context_t *context = (vol_listener_context_t *)self;
    pthread_mutex_lock(&vol_listner_init_lock);

 if (context->state != VOL_LISTENER_STATE_ACTIVE) {
        ALOGE("%s: state is not active .. return error", __func__);
        status = -EINVAL;
 goto exit;
 }

 if (in_buffer->raw != out_buffer->raw) {
        memcpy(out_buffer->raw, in_buffer->raw, out_buffer->frameCount * 2 * sizeof(int16_t));
 } else {
        ALOGW("%s: something wrong, didn't handle in_buffer and out_buffer same address case",
              __func__);
 }

exit:
    pthread_mutex_unlock(&vol_listner_init_lock);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::clearStreamingRequest(int64_t *lastFrameNumber) {
    ATRACE_CALL();
 Mutex::Autolock il(mInterfaceLock);
 Mutex::Autolock l(mLock);

 switch (mStatus) {
 case STATUS_ERROR:
            CLOGE("Device has encountered a serious error");
 return INVALID_OPERATION;
 case STATUS_UNINITIALIZED:
            CLOGE("Device not initialized");
 return INVALID_OPERATION;
 case STATUS_UNCONFIGURED:
 case STATUS_CONFIGURED:
 case STATUS_ACTIVE:
 break;
 default:
            SET_ERR_L("Unexpected status: %d", mStatus);
 return INVALID_OPERATION;
 }
    ALOGV("Camera %d: Clearing repeating request", mId);

 return mRequestThread->clearRepeatingRequests(lastFrameNumber);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void btif_config_flush(void) {
  assert(config != NULL);
  assert(alarm_timer != NULL);

 
   alarm_cancel(alarm_timer);
 
  pthread_mutex_lock(&lock);
  config_save(config, CONFIG_FILE_PATH);
  pthread_mutex_unlock(&lock);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::Load(long long& pos, long& len) const
{
    assert(m_pSegment);
    assert(m_pos >= m_element_start);
 
    if (m_timecode >= 0)  //at least partially loaded
        return 0;
 
    assert(m_pos == m_element_start);
    assert(m_element_size < 0);
 
    IMkvReader* const pReader = m_pSegment->m_pReader;
 
    long long total, avail;
 
    const int status = pReader->Length(&total, &avail);
 
    if (status < 0)  //error
        return status;
 
    assert((total < 0) || (avail <= total));
    assert((total < 0) || (m_pos <= total));  //TODO: verify this
 
    pos = m_pos;
 
    long long cluster_size = -1;
    {
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        long long result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error or underflow
            return static_cast<long>(result);
        if (result > 0)  //underflow (weird)
            return E_BUFFER_NOT_FULL;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long id_ = ReadUInt(pReader, pos, len);
        if (id_ < 0)  //error
            return static_cast<long>(id_);
        if (id_ != 0x0F43B675)  //Cluster ID
            return E_FILE_FORMAT_INVALID;
        pos += len;  //consume id
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error
            return static_cast<long>(result);
        if (result > 0)  //weird
            return E_BUFFER_NOT_FULL;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long size = ReadUInt(pReader, pos, len);
        if (size < 0)  //error
            return static_cast<long>(cluster_size);
        if (size == 0)
            return E_FILE_FORMAT_INVALID;  //TODO: verify this
        pos += len;  //consume length of size of element
        const long long unknown_size = (1LL << (7 * len)) - 1;
        if (size != unknown_size)
            cluster_size = size;
     }
 
//// pos points to start of payload
 
 #if 0
     len = static_cast<long>(size_);

 if (cluster_stop > avail)

         return E_BUFFER_NOT_FULL;
 #endif
 
    long long timecode = -1;
    long long new_pos = -1;
    bool bBlock = false;
 
    long long cluster_stop = (cluster_size < 0) ? -1 : pos + cluster_size;
 
    for (;;)
    {
        if ((cluster_stop >= 0) && (pos >= cluster_stop))
            break;
 
 
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        long long result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error
            return static_cast<long>(result);
        if (result > 0)  //weird
            return E_BUFFER_NOT_FULL;
        if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long id = ReadUInt(pReader, pos, len);
        if (id < 0) //error
            return static_cast<long>(id);
        if (id == 0)
            return E_FILE_FORMAT_INVALID;
        if (id == 0x0F43B675)  //Cluster ID
            break;
        if (id == 0x0C53BB6B)  //Cues ID
            break;
        pos += len;  //consume ID field
        if ((pos + 1) > avail)
        {
            len = 1;
            return E_BUFFER_NOT_FULL;
        }
        result = GetUIntLength(pReader, pos, len);
        if (result < 0)  //error
            return static_cast<long>(result);
        if (result > 0)  //weird
            return E_BUFFER_NOT_FULL;
        if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > avail)
            return E_BUFFER_NOT_FULL;
        const long long size = ReadUInt(pReader, pos, len);
        if (size < 0)  //error
            return static_cast<long>(size);
        const long long unknown_size = (1LL << (7 * len)) - 1;
        if (size == unknown_size)
            return E_FILE_FORMAT_INVALID;
        pos += len;  //consume size field
        if ((cluster_stop >= 0) && (pos > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if (size == 0)  //weird
            continue;
        if ((cluster_stop >= 0) && ((pos + size) > cluster_stop))
            return E_FILE_FORMAT_INVALID;
        if (id == 0x67)  //TimeCode ID
        {
            len = static_cast<long>(size);
            if ((pos + size) > avail)
                return E_BUFFER_NOT_FULL;
            timecode = UnserializeUInt(pReader, pos, size);
            if (timecode < 0)  //error (or underflow)
                return static_cast<long>(timecode);
            new_pos = pos + size;
            if (bBlock)
                break;
        }
        else if (id == 0x20)  //BlockGroup ID
        {
            bBlock = true;
            break;
        }
        else if (id == 0x23)  //SimpleBlock ID
        {
            bBlock = true;
            break;
        }
        pos += size;  //consume payload
        assert((cluster_stop < 0) || (pos <= cluster_stop));
    }
    assert((cluster_stop < 0) || (pos <= cluster_stop));
    if (timecode < 0)  //no timecode found
        return E_FILE_FORMAT_INVALID;
    if (!bBlock)
        return E_FILE_FORMAT_INVALID;
    m_pos = new_pos;  //designates position just beyond timecode payload
    m_timecode = timecode;  // m_timecode >= 0 means we're partially loaded
    if (cluster_size >= 0)
        m_element_size = cluster_stop - m_element_start;
    return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: WORD32 ihevcd_rel_display_frame(iv_obj_t *ps_codec_obj,
 void *pv_api_ip,
 void *pv_api_op)
{

 ivd_rel_display_frame_ip_t *ps_dec_rel_disp_ip;
 ivd_rel_display_frame_op_t *ps_dec_rel_disp_op;

 codec_t *ps_codec = (codec_t *)ps_codec_obj->pv_codec_handle;

    ps_dec_rel_disp_ip = (ivd_rel_display_frame_ip_t *)pv_api_ip;
    ps_dec_rel_disp_op = (ivd_rel_display_frame_op_t *)pv_api_op;

    UNUSED(ps_dec_rel_disp_op);

 if(0 == ps_codec->i4_share_disp_buf)
 {
 return IV_SUCCESS;
 }

    ihevc_buf_mgr_release((buf_mgr_t *)ps_codec->pv_pic_buf_mgr, ps_dec_rel_disp_ip->u4_disp_buf_id, BUF_MGR_DISP);

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Chapters::Edition::GetAtomCount() const { return m_atoms_count; }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::internalPauseAndWaitLocked() {
    mRequestThread->setPaused(true);
    mPauseStateNotify = true;

    ALOGV("%s: Camera %d: Internal wait until idle", __FUNCTION__, mId);
 status_t res = waitUntilStateThenRelock(/*active*/ false, kShutdownTimeout);
 if (res != OK) {
        SET_ERR_L("Can't idle device in %f seconds!",
                kShutdownTimeout/1e9);
 }

 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Tags::SimpleTag::Parse(IMkvReader* pReader, long long pos,
 long long size) {
 const long long stop = pos + size;

 while (pos < stop) {
 long long id, size;

 long status = ParseElementHeader(pReader, pos, stop, id, size);

 if (status < 0) // error
 return status;

 if (size == 0) // weird
 continue;

 if (id == 0x5A3) { // TagName ID
      status = UnserializeString(pReader, pos, size, m_tag_name);

 if (status)
 return status;
 } else if (id == 0x487) { // TagString ID
      status = UnserializeString(pReader, pos, size, m_tag_string);

 if (status)
 return status;
 }

    pos += size;
 if (pos > stop)
 return E_FILE_FORMAT_INVALID;
 }

 if (pos != stop)
 return E_FILE_FORMAT_INVALID;
 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual status_t setCipherAlgorithm(Vector<uint8_t> const &sessionId,
 String8 const &algorithm) {
 Parcel data, reply;
        data.writeInterfaceToken(IDrm::getInterfaceDescriptor());

        writeVector(data, sessionId);
        data.writeString8(algorithm);
 status_t status = remote()->transact(SET_CIPHER_ALGORITHM, data, &reply);
 if (status != OK) {
 return status;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int get_vp9_frame_buffer(void *user_priv, size_t min_size,
 vpx_codec_frame_buffer_t *fb) {
 ExternalFrameBufferList *const fb_list =
 reinterpret_cast<ExternalFrameBufferList*>(user_priv);
 return fb_list->GetFreeFrameBuffer(min_size, fb);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_free_node_from_dpb(dpb_manager_t *ps_dpb_mgr,
                               UWORD32 u4_cur_pic_num,
                               UWORD8 u1_numRef_frames_for_seq)
{
    WORD32 i;
    UWORD8 u1_num_gaps = ps_dpb_mgr->u1_num_gaps;
 struct dpb_info_t *ps_next_dpb;
    UWORD8 u1_del_node = 1;
    WORD32 ret;

 if((ps_dpb_mgr->u1_num_st_ref_bufs + ps_dpb_mgr->u1_num_lt_ref_bufs
 + u1_num_gaps) == u1_numRef_frames_for_seq)
 {
        UWORD8 u1_new_node_flag = 1;
 if((0 == ps_dpb_mgr->u1_num_st_ref_bufs) && (0 == u1_num_gaps))
 {
 return ERROR_DBP_MANAGER_T;
 }

        ps_next_dpb = ps_dpb_mgr->ps_dpb_st_head;

 if(ps_dpb_mgr->u1_num_st_ref_bufs > 1)
 {
 if(ps_next_dpb->i4_frame_num == (WORD32)u4_cur_pic_num)
 {
 /* Incase of  filed pictures top_field has been allocated   */
 /* picture buffer and complementary bottom field pair comes */
 /* then the sliding window mechanism should not allocate a  */
 /* new node                                                 */
                u1_new_node_flag = 0;
 }

 for(i = 1; i < (ps_dpb_mgr->u1_num_st_ref_bufs - 1); i++)
 {
 if(ps_next_dpb == NULL)
 return ERROR_DBP_MANAGER_T;

 if(ps_next_dpb->i4_frame_num == (WORD32)u4_cur_pic_num)
 {
 /* Incase of  field pictures top_field has been allocated   */
 /* picture buffer and complementary bottom field pair comes */
 /* then the sliding window mechanism should not allocate a  */
 /* new node                                                 */
                    u1_new_node_flag = 0;
 }
                ps_next_dpb = ps_next_dpb->ps_prev_short;
 }

 if(ps_next_dpb->ps_prev_short->ps_prev_short != NULL)
 return ERROR_DBP_MANAGER_T;

 if(u1_new_node_flag)
 {
 if(u1_num_gaps)
 {
                    ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                        ps_next_dpb->ps_prev_short->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 }

 if(u1_del_node)
 {
                    ps_dpb_mgr->u1_num_st_ref_bufs--;
                    ps_next_dpb->ps_prev_short->u1_used_as_ref = UNUSED_FOR_REF;
                    ps_next_dpb->ps_prev_short->s_top_field.u1_reference_info =
                                    UNUSED_FOR_REF;
                    ps_next_dpb->ps_prev_short->s_bot_field.u1_reference_info =
                                    UNUSED_FOR_REF;
                    ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                ps_next_dpb->ps_prev_short->u1_buf_id);
                    ps_next_dpb->ps_prev_short->ps_pic_buf = NULL;
                    ps_next_dpb->ps_prev_short = NULL;
 }
 }
 }
 else
 {
 if(ps_dpb_mgr->u1_num_st_ref_bufs)
 {
                ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr,
                                                    ps_next_dpb->i4_frame_num,
 &u1_del_node);
 if(ret != OK)
 return ret;
 if((ps_next_dpb->i4_frame_num != (WORD32)u4_cur_pic_num)
 && u1_del_node)
 {
                    ps_dpb_mgr->u1_num_st_ref_bufs--;
                    ps_next_dpb->u1_used_as_ref = FALSE;
                    ps_next_dpb->s_top_field.u1_reference_info = UNUSED_FOR_REF;
                    ps_next_dpb->s_bot_field.u1_reference_info = UNUSED_FOR_REF;
                    ih264d_free_ref_pic_mv_bufs(ps_dpb_mgr->pv_codec_handle,
                                                ps_next_dpb->u1_buf_id);
                    ps_next_dpb->ps_pic_buf = NULL;
                    ps_next_dpb = NULL;
 }
 }
 else
 {
                ret = ih264d_delete_gap_frm_sliding(ps_dpb_mgr, INVALID_FRAME_NUM, &u1_del_node);
 if(ret != OK)
 return ret;
 if(u1_del_node)
 return ERROR_DBP_MANAGER_T;
 }
 }
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::GetLast(const BlockEntry*& pLast) const
{
    for (;;)
    {
        long long pos;
        long len;
        const long status = Parse(pos, len);
        if (status < 0)  //error
        {
            pLast = NULL;
            return status;
        }
        if (status > 0)  //no new block
            break;
    }
    if (m_entries_count <= 0)
    {
        pLast = NULL;
        return 0;
    }
    assert(m_entries);
    const long idx = m_entries_count - 1;
    pLast = m_entries[idx];
    assert(pLast);
     return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: WORD32 ih264d_parse_decode_slice(UWORD8 u1_is_idr_slice,
                                 UWORD8 u1_nal_ref_idc,
 dec_struct_t *ps_dec /* Decoder parameters */
 )
{
 dec_bit_stream_t * ps_bitstrm = ps_dec->ps_bitstrm;
 dec_pic_params_t *ps_pps;
 dec_seq_params_t *ps_seq;
 dec_slice_params_t *ps_cur_slice = ps_dec->ps_cur_slice;
 pocstruct_t s_tmp_poc;
    WORD32 i_delta_poc[2];
    WORD32 i4_poc = 0;
    UWORD16 u2_first_mb_in_slice, u2_frame_num;
    UWORD8 u1_field_pic_flag, u1_redundant_pic_cnt = 0, u1_slice_type;
    UWORD32 u4_idr_pic_id = 0;
    UWORD8 u1_bottom_field_flag, u1_pic_order_cnt_type;

    UWORD8 u1_nal_unit_type;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    WORD8 i1_is_end_of_poc;

    WORD32 ret, end_of_frame;
    WORD32 prev_slice_err, num_mb_skipped;
    UWORD8 u1_mbaff;
 pocstruct_t *ps_cur_poc;

    UWORD32 u4_temp;
    WORD32 i_temp;
    UWORD32 u4_call_end_of_pic = 0;

 /* read FirstMbInSlice  and slice type*/
    ps_dec->ps_dpb_cmds->u1_dpb_commands_read_slc = 0;
    u2_first_mb_in_slice = ih264d_uev(pu4_bitstrm_ofst,
                                     pu4_bitstrm_buf);
 if(u2_first_mb_in_slice
 > (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs))
 {

 return ERROR_CORRUPTED_SLICE;
 }

 /*we currently don not support ASO*/
 if(((u2_first_mb_in_slice << ps_cur_slice->u1_mbaff_frame_flag)
 <= ps_dec->u2_cur_mb_addr) && (ps_dec->u4_first_slice_in_pic == 0))
 {
 return ERROR_CORRUPTED_SLICE;
 }

    COPYTHECONTEXT("SH: first_mb_in_slice",u2_first_mb_in_slice);

    u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);

 if(u4_temp > 9)
 return ERROR_INV_SLC_TYPE_T;

    u1_slice_type = u4_temp;
    COPYTHECONTEXT("SH: slice_type",(u1_slice_type));
    ps_dec->u1_sl_typ_5_9 = 0;
 /* Find Out the Slice Type is 5 to 9 or not then Set the Flag   */
 /* u1_sl_typ_5_9 = 1 .Which tells that all the slices in the Pic*/
 /* will be of same type of current                            */
 if(u1_slice_type > 4)
 {
        u1_slice_type -= 5;
        ps_dec->u1_sl_typ_5_9 = 1;
 }

 {
        UWORD32 skip;

 if((ps_dec->i4_app_skip_mode == IVD_SKIP_PB)
 || (ps_dec->i4_dec_skip_mode == IVD_SKIP_PB))
 {
            UWORD32 u4_bit_stream_offset = 0;

 if(ps_dec->u1_nal_unit_type == IDR_SLICE_NAL)
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else if((I_SLICE == u1_slice_type)
 && (1 >= ps_dec->ps_cur_sps->u1_num_ref_frames))
 {
                skip = 0;

                ps_dec->i4_dec_skip_mode = IVD_SKIP_NONE;
 }
 else
 {
                skip = 1;
 }

 /* If one frame worth of data is already skipped, do not skip the next one */
 if((0 == u2_first_mb_in_slice) && (1 == ps_dec->u4_prev_nal_skipped))
 {
                skip = 0;
 }

 if(skip)
 {
                ps_dec->u4_prev_nal_skipped = 1;
                ps_dec->i4_dec_skip_mode = IVD_SKIP_PB;
 return 0;
 }
 else
 {
 /* If the previous NAL was skipped, then
                 do not process that buffer in this call.
                 Return to app and process it in the next call.
                 This is necessary to handle cases where I/IDR is not complete in
                 the current buffer and application intends to fill the remaining part of the bitstream
                 later. This ensures we process only frame worth of data in every call */
 if(1 == ps_dec->u4_prev_nal_skipped)
 {
                    ps_dec->u4_return_to_app = 1;
 return 0;
 }
 }
 }

 }

 
     u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
     if(u4_temp & MASK_ERR_PIC_SET_ID)
        return ERROR_INV_SPS_PPS_T;
     /* discard slice if pic param is invalid */
     COPYTHECONTEXT("SH: pic_parameter_set_id", u4_temp);
     ps_pps = &ps_dec->ps_pps[u4_temp];
     if(FALSE == ps_pps->u1_is_valid)
     {
        return ERROR_INV_SPS_PPS_T;
     }
     ps_seq = ps_pps->ps_sps;
     if(!ps_seq)
        return ERROR_INV_SPS_PPS_T;
     if(FALSE == ps_seq->u1_is_valid)
        return ERROR_INV_SPS_PPS_T;
 
     /* Get the frame num */
     u2_frame_num = ih264d_get_bits_h264(ps_bitstrm,
                                         ps_seq->u1_bits_in_frm_num);

    COPYTHECONTEXT("SH: frame_num", u2_frame_num);

 /* Get the field related flags  */
 if(!ps_seq->u1_frame_mbs_only_flag)
 {

        u1_field_pic_flag = ih264d_get_bit_h264(ps_bitstrm);
        COPYTHECONTEXT("SH: field_pic_flag", u1_field_pic_flag);
        u1_bottom_field_flag = 0;

 if(u1_field_pic_flag)
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan_fld;
            u1_bottom_field_flag = ih264d_get_bit_h264(ps_bitstrm);
            COPYTHECONTEXT("SH: bottom_field_flag", u1_bottom_field_flag);

 }
 else
 {
            ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }
 }
 else
 {
        u1_field_pic_flag = 0;
        u1_bottom_field_flag = 0;

        ps_dec->pu1_inv_scan = (UWORD8 *)gau1_ih264d_inv_scan;
 }

    u1_nal_unit_type = SLICE_NAL;
 if(u1_is_idr_slice)
 {
 if(0 == u1_field_pic_flag)
 {
            ps_dec->u1_top_bottom_decoded = TOP_FIELD_ONLY | BOT_FIELD_ONLY;
 }
        u1_nal_unit_type = IDR_SLICE_NAL;

         u4_idr_pic_id = ih264d_uev(pu4_bitstrm_ofst,
                                    pu4_bitstrm_buf);
         if(u4_idr_pic_id > 65535)
            return ERROR_INV_SPS_PPS_T;
         COPYTHECONTEXT("SH:  ", u4_idr_pic_id);
     }
 
 /* read delta pic order count information*/
    i_delta_poc[0] = i_delta_poc[1] = 0;
    s_tmp_poc.i4_pic_order_cnt_lsb = 0;
    s_tmp_poc.i4_delta_pic_order_cnt_bottom = 0;
    u1_pic_order_cnt_type = ps_seq->u1_pic_order_cnt_type;
 if(u1_pic_order_cnt_type == 0)
 {
        i_temp = ih264d_get_bits_h264(

                         ps_bitstrm,
                         ps_seq->u1_log2_max_pic_order_cnt_lsb_minus);
         if(i_temp < 0 || i_temp >= ps_seq->i4_max_pic_order_cntLsb)
            return ERROR_INV_SPS_PPS_T;
         s_tmp_poc.i4_pic_order_cnt_lsb = i_temp;
         COPYTHECONTEXT("SH: pic_order_cnt_lsb", s_tmp_poc.i4_pic_order_cnt_lsb);
 
 if((ps_pps->u1_pic_order_present_flag == 1) && (!u1_field_pic_flag))
 {
            s_tmp_poc.i4_delta_pic_order_cnt_bottom = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt_bottom",
                            s_tmp_poc.i4_delta_pic_order_cnt_bottom);
 }
 }

    s_tmp_poc.i4_delta_pic_order_cnt[0] = 0;
    s_tmp_poc.i4_delta_pic_order_cnt[1] = 0;
 if(u1_pic_order_cnt_type == 1
 && (!ps_seq->u1_delta_pic_order_always_zero_flag))
 {
        s_tmp_poc.i4_delta_pic_order_cnt[0] = ih264d_sev(pu4_bitstrm_ofst,
                                                         pu4_bitstrm_buf);
        COPYTHECONTEXT("SH: delta_pic_order_cnt[0]",
                        s_tmp_poc.i4_delta_pic_order_cnt[0]);

 if(ps_pps->u1_pic_order_present_flag && !u1_field_pic_flag)
 {
            s_tmp_poc.i4_delta_pic_order_cnt[1] = ih264d_sev(
                            pu4_bitstrm_ofst, pu4_bitstrm_buf);
            COPYTHECONTEXT("SH: delta_pic_order_cnt[1]",
                            s_tmp_poc.i4_delta_pic_order_cnt[1]);
 }
 }

 if(ps_pps->u1_redundant_pic_cnt_present_flag)

     {
         u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
         if(u4_temp > MAX_REDUNDANT_PIC_CNT)
            return ERROR_INV_SPS_PPS_T;
         u1_redundant_pic_cnt = u4_temp;
         COPYTHECONTEXT("SH: redundant_pic_cnt", u1_redundant_pic_cnt);
     }

 /*--------------------------------------------------------------------*/
 /* Check if the slice is part of new picture                          */
 /*--------------------------------------------------------------------*/
    i1_is_end_of_poc = 0;
 if(!ps_dec->u1_first_slice_in_stream)
 {
        i1_is_end_of_poc = ih264d_is_end_of_pic(u2_frame_num, u1_nal_ref_idc,
 &s_tmp_poc, &ps_dec->s_cur_pic_poc,
                                            ps_cur_slice, u1_pic_order_cnt_type,
                                            u1_nal_unit_type, u4_idr_pic_id,
                                            u1_field_pic_flag,
                                            u1_bottom_field_flag);

 /* since we support only Full frame decode, every new process should
         * process a new pic
         */
 if((ps_dec->u4_first_slice_in_pic == 2) && (i1_is_end_of_poc == 0))
 {
 /* if it is the first slice is process call ,it should be a new frame. If it is not
             * reject current pic and dont add it to dpb
             */
            ps_dec->ps_dec_err_status->u1_err_flag |= REJECT_CUR_PIC;
            i1_is_end_of_poc = 1;
 }
 else
 {
 /* reset REJECT_CUR_PIC */
            ps_dec->ps_dec_err_status->u1_err_flag &= MASK_REJECT_CUR_PIC;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Check for error in slice and parse the missing/corrupted MB's      */
 /* as skip-MB's in an inserted P-slice                                */
 /*--------------------------------------------------------------------*/
    u1_mbaff = ps_seq->u1_mb_aff_flag && (!u1_field_pic_flag);
    prev_slice_err = 0;

 if(i1_is_end_of_poc || ps_dec->u1_first_slice_in_stream)
 {
 if(u2_frame_num != ps_dec->u2_prv_frame_num
 && ps_dec->u1_top_bottom_decoded != 0
 && ps_dec->u1_top_bottom_decoded
 != (TOP_FIELD_ONLY | BOT_FIELD_ONLY))
 {
            ps_dec->u1_dangling_field = 1;
 if(ps_dec->u4_first_slice_in_pic)
 {
                prev_slice_err = 1;
 }
 else
 {
                prev_slice_err = 2;
 }

 if(ps_dec->u1_top_bottom_decoded ==TOP_FIELD_ONLY)
                ps_cur_slice->u1_bottom_field_flag = 1;
 else
                ps_cur_slice->u1_bottom_field_flag = 0;

            num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &ps_dec->s_cur_pic_poc;

            u1_is_idr_slice = ps_cur_slice->u1_nal_unit_type == IDR_SLICE_NAL;
 }
 else if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice > 0)
 {
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
                ps_cur_poc = &s_tmp_poc;

                ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
                ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
                ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
                ps_cur_slice->i4_pic_order_cnt_lsb =
                        s_tmp_poc.i4_pic_order_cnt_lsb;
                ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
                ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
                ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
                ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;
                ps_cur_slice->u1_mbaff_frame_flag = ps_seq->u1_mb_aff_flag
 && (!u1_field_pic_flag);
 }
 }
 else
 {

 if(ps_dec->u4_first_slice_in_pic)
 {
 /* if valid slice header is not decoded do start of pic processing
                 * since in the current process call, frame num is not updated in the slice structure yet
                 * ih264d_is_end_of_pic is checked with valid frame num of previous process call,
                 * although i1_is_end_of_poc is set there could be  more slices in the frame,
                 * so conceal only till cur slice */
                prev_slice_err = 1;
                num_mb_skipped = u2_first_mb_in_slice << u1_mbaff;
 }
 else
 {
 /* since i1_is_end_of_poc is set ,means new frame num is encountered. so conceal the current frame
                 * completely */
                prev_slice_err = 2;
                num_mb_skipped = (ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 - ps_dec->u2_total_mbs_coded;
 }
            ps_cur_poc = &s_tmp_poc;
 }
 }
 else
 {
 if((u2_first_mb_in_slice << u1_mbaff) > ps_dec->u2_total_mbs_coded)
 {
            prev_slice_err = 2;
            num_mb_skipped = (u2_first_mb_in_slice << u1_mbaff)
 - ps_dec->u2_total_mbs_coded;
            ps_cur_poc = &s_tmp_poc;
 }
 else if((u2_first_mb_in_slice << u1_mbaff) < ps_dec->u2_total_mbs_coded)
 {
 return ERROR_CORRUPTED_SLICE;
 }
 }

 if(prev_slice_err)
 {
        ret = ih264d_mark_err_slice_skip(ps_dec, num_mb_skipped, u1_is_idr_slice, u2_frame_num, ps_cur_poc, prev_slice_err);

 if(ps_dec->u1_dangling_field == 1)
 {
            ps_dec->u1_second_field = 1 - ps_dec->u1_second_field;
            ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
            ps_dec->u2_prv_frame_num = u2_frame_num;
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_DANGLING_FIELD_IN_PIC;
 }

 if(prev_slice_err == 2)
 {
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_INCOMPLETE_FRAME;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
 /* return if all MBs in frame are parsed*/
            ps_dec->u1_first_slice_in_stream = 0;
 return ERROR_IN_LAST_SLICE_OF_PIC;
 }

 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
            ih264d_err_pic_dispbuf_mgr(ps_dec);
 return ERROR_NEW_FRAME_EXPECTED;
 }

 if(ret != OK)
 return ret;

        i1_is_end_of_poc = 0;
 }

 if (ps_dec->u4_first_slice_in_pic == 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

 if((ps_dec->u1_separate_parse == 0) && (ps_dec->u4_first_slice_in_pic == 0))
 {
        ps_dec->ps_decode_cur_slice++;
 }
    ps_dec->u1_slice_header_done = 0;

 /*--------------------------------------------------------------------*/
 /* If the slice is part of new picture, do End of Pic processing.     */
 /*--------------------------------------------------------------------*/
 if(!ps_dec->u1_first_slice_in_stream)
 {
        UWORD8 uc_mbs_exceed = 0;

 if(ps_dec->u2_total_mbs_coded
 == (ps_dec->ps_cur_sps->u2_max_mb_addr + 1))
 {
 /*u2_total_mbs_coded is forced  to u2_max_mb_addr+ 1 at the end of decode ,so
             ,if it is first slice in pic dont consider u2_total_mbs_coded to detect new picture */
 if(ps_dec->u4_first_slice_in_pic == 0)
                uc_mbs_exceed = 1;
 }

 if(i1_is_end_of_poc || uc_mbs_exceed)
 {

 if(1 == ps_dec->u1_last_pic_not_decoded)
 {
                ret = ih264d_end_of_pic_dispbuf_mgr(ps_dec);

 if(ret != OK)
 return ret;

                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
 if(ret != OK)
 return ret;
#if WIN32
                H264_DEC_DEBUG_PRINT(" ------ PIC SKIPPED ------\n");
#endif
 return RET_LAST_SKIP;
 }
 else
 {
                ret = ih264d_end_of_pic(ps_dec, u1_is_idr_slice, u2_frame_num);
 if(ret != OK)
 return ret;
 }

 }
 }

 if(u1_field_pic_flag)
 {
        ps_dec->u2_prv_frame_num = u2_frame_num;
 }

 if(ps_cur_slice->u1_mmco_equalto5)
 {
        WORD32 i4_temp_poc;
        WORD32 i4_top_field_order_poc, i4_bot_field_order_poc;

 if(!ps_cur_slice->u1_field_pic_flag) // or a complementary field pair
 {
            i4_top_field_order_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
            i4_bot_field_order_poc =
                            ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
            i4_temp_poc = MIN(i4_top_field_order_poc,
                                     i4_bot_field_order_poc);
 }
 else if(!ps_cur_slice->u1_bottom_field_flag)
            i4_temp_poc = ps_dec->ps_cur_pic->i4_top_field_order_cnt;
 else
            i4_temp_poc = ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;

        ps_dec->ps_cur_pic->i4_top_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_top_field_order_cnt;
        ps_dec->ps_cur_pic->i4_bottom_field_order_cnt = i4_temp_poc
 - ps_dec->ps_cur_pic->i4_bottom_field_order_cnt;
        ps_dec->ps_cur_pic->i4_poc = i4_temp_poc;
        ps_dec->ps_cur_pic->i4_avg_poc = i4_temp_poc;
 }
 if(ps_dec->u4_first_slice_in_pic == 2)
 {
        ret = ih264d_decode_pic_order_cnt(u1_is_idr_slice, u2_frame_num,
 &ps_dec->s_prev_pic_poc,
 &s_tmp_poc, ps_cur_slice, ps_pps,
                                          u1_nal_ref_idc,
                                          u1_bottom_field_flag,
                                          u1_field_pic_flag, &i4_poc);
 if(ret != OK)
 return ret;
 /* Display seq no calculations */
 if(i4_poc >= ps_dec->i4_max_poc)
            ps_dec->i4_max_poc = i4_poc;
 /* IDR Picture or POC wrap around */
 if(i4_poc == 0)
 {
            ps_dec->i4_prev_max_display_seq = ps_dec->i4_prev_max_display_seq
 + ps_dec->i4_max_poc
 + ps_dec->u1_max_dec_frame_buffering + 1;
            ps_dec->i4_max_poc = 0;
 }
 }

 /*--------------------------------------------------------------------*/
 /* Copy the values read from the bitstream to the slice header and then*/
 /* If the slice is first slice in picture, then do Start of Picture   */
 /* processing.                                                        */
 /*--------------------------------------------------------------------*/
    ps_cur_slice->i4_delta_pic_order_cnt[0] = i_delta_poc[0];
    ps_cur_slice->i4_delta_pic_order_cnt[1] = i_delta_poc[1];
    ps_cur_slice->u4_idr_pic_id = u4_idr_pic_id;
    ps_cur_slice->u2_first_mb_in_slice = u2_first_mb_in_slice;
    ps_cur_slice->u1_field_pic_flag = u1_field_pic_flag;
    ps_cur_slice->u1_bottom_field_flag = u1_bottom_field_flag;
    ps_cur_slice->u1_slice_type = u1_slice_type;
    ps_cur_slice->i4_pic_order_cnt_lsb = s_tmp_poc.i4_pic_order_cnt_lsb;

    ps_cur_slice->u1_nal_unit_type = u1_nal_unit_type;
    ps_cur_slice->u1_redundant_pic_cnt = u1_redundant_pic_cnt;
    ps_cur_slice->u1_nal_ref_idc = u1_nal_ref_idc;
    ps_cur_slice->u1_pic_order_cnt_type = u1_pic_order_cnt_type;

 if(ps_seq->u1_frame_mbs_only_flag)
        ps_cur_slice->u1_direct_8x8_inference_flag =
                        ps_seq->u1_direct_8x8_inference_flag;
 else
        ps_cur_slice->u1_direct_8x8_inference_flag = 1;

 if(u1_slice_type == B_SLICE)
 {
        ps_cur_slice->u1_direct_spatial_mv_pred_flag = ih264d_get_bit_h264(
                        ps_bitstrm);
        COPYTHECONTEXT("SH: direct_spatial_mv_pred_flag",
                        ps_cur_slice->u1_direct_spatial_mv_pred_flag);

 if(ps_cur_slice->u1_direct_spatial_mv_pred_flag)
            ps_cur_slice->pf_decodeDirect = ih264d_decode_spatial_direct;
 else
            ps_cur_slice->pf_decodeDirect = ih264d_decode_temporal_direct;
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaffB;
 }
 else
 {
 if(!((ps_pps->ps_sps->u1_mb_aff_flag) && (!u1_field_pic_flag)))
            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
 }

 if(ps_dec->u4_first_slice_in_pic == 2)
 {
 if(u2_first_mb_in_slice == 0)
 {
            ret = ih264d_start_of_pic(ps_dec, i4_poc, &s_tmp_poc, u2_frame_num, ps_pps);
 if(ret != OK)
 return ret;
 }

        ps_dec->u4_output_present = 0;

 {
            ih264d_get_next_display_field(ps_dec,
                                          ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
             hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                ps_dec->u4_output_present = 1;
 }
 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                ps_dec->u4_start_recon_deblk = 0;
                ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }

 }

 /* INITIALIZATION of fn ptrs for MC and formMbPartInfo functions */
 {
        UWORD8 uc_nofield_nombaff;



        uc_nofield_nombaff = ((ps_dec->ps_cur_slice->u1_field_pic_flag == 0)
 && (ps_dec->ps_cur_slice->u1_mbaff_frame_flag == 0)
 && (u1_slice_type != B_SLICE)
 && (ps_dec->ps_cur_pps->u1_wted_pred_flag == 0));

 /* Initialise MC and formMbPartInfo fn ptrs one time based on profile_idc */

 if(uc_nofield_nombaff)
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;
 }
 else
 {
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_mp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_mp;
 }


 }

 /*
     * Decide whether to decode the current picture or not
     */
 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if(ps_err->u4_frm_sei_sync == u2_frame_num)
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
            ps_err->u4_frm_sei_sync = SYNC_FRM_DEFAULT;
 }
        ps_err->u4_cur_frm = u2_frame_num;
 }

 /* Decision for decoding if the picture is to be skipped */
 {
        WORD32 i4_skip_b_pic, i4_skip_p_pic;

        i4_skip_b_pic = (ps_dec->u4_skip_frm_mask & B_SLC_BIT)
 && (B_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

        i4_skip_p_pic = (ps_dec->u4_skip_frm_mask & P_SLC_BIT)
 && (P_SLICE == u1_slice_type) && (0 == u1_nal_ref_idc);

 /**************************************************************/
 /* Skip the B picture if skip mask is set for B picture and   */
 /* Current B picture is a non reference B picture or there is */
 /* no user for reference B picture                            */
 /**************************************************************/
 if(i4_skip_b_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
 /* Don't decode the picture in SKIP-B mode if that picture is B */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 /**************************************************************/
 /* Skip the P picture if skip mask is set for P picture and   */
 /* Current P picture is a non reference P picture or there is */
 /* no user for reference P picture                            */
 /**************************************************************/
 if(i4_skip_p_pic)
 {
            ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
 /* Don't decode the picture in SKIP-P mode if that picture is P */
 /* and also it is not to be used as a reference picture         */
            ps_dec->u1_last_pic_not_decoded = 1;

 return OK;
 }
 }

 {
        UWORD16 u2_mb_x, u2_mb_y;

        ps_dec->i4_submb_ofst = ((u2_first_mb_in_slice
 << ps_cur_slice->u1_mbaff_frame_flag) * SUB_BLK_SIZE)
 - SUB_BLK_SIZE;
 if(u2_first_mb_in_slice)
 {
            UWORD8 u1_mb_aff;
            UWORD8 u1_field_pic;
            UWORD16 u2_frm_wd_in_mbs;
            u2_frm_wd_in_mbs = ps_seq->u2_frm_wd_in_mbs;
            u1_mb_aff = ps_cur_slice->u1_mbaff_frame_flag;
            u1_field_pic = ps_cur_slice->u1_field_pic_flag;

 {
                UWORD32 x_offset;
                UWORD32 y_offset;
                UWORD32 u4_frame_stride;
 tfr_ctxt_t *ps_trns_addr; // = &ps_dec->s_tran_addrecon_parse;

 if(ps_dec->u1_separate_parse)
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                    ps_trns_addr = &ps_dec->s_tran_addrecon;
 }
                u2_mb_x = MOD(u2_first_mb_in_slice, u2_frm_wd_in_mbs);
                u2_mb_y = DIV(u2_first_mb_in_slice, u2_frm_wd_in_mbs);

                u2_mb_y <<= u1_mb_aff;

 if((u2_mb_x > u2_frm_wd_in_mbs - 1)
 || (u2_mb_y > ps_dec->u2_frm_ht_in_mbs - 1))
 {
 return ERROR_CORRUPTED_SLICE;
 }

                u4_frame_stride = ps_dec->u2_frm_wd_y << u1_field_pic;
                x_offset = u2_mb_x << 4;
                y_offset = (u2_mb_y * u4_frame_stride) << 4;

                ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1 + x_offset
 + y_offset;

                u4_frame_stride = ps_dec->u2_frm_wd_uv << u1_field_pic;
                x_offset >>= 1;
                y_offset = (u2_mb_y * u4_frame_stride) << 3;

                x_offset *= YUV420SP_FACTOR;

                ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2 + x_offset
 + y_offset;
                ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3 + x_offset
 + y_offset;

                ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
                ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
                ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;


 if(ps_dec->u1_separate_parse == 1)
 {
                    ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }
 else
 {
                        ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic
 + (u2_first_mb_in_slice << u1_mb_aff);
 }

                ps_dec->u2_cur_mb_addr = (u2_first_mb_in_slice << u1_mb_aff);

                ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv
 + ((u2_first_mb_in_slice << u1_mb_aff) << 4);
 }
 }
 else
 {
 tfr_ctxt_t *ps_trns_addr;

 if(ps_dec->u1_separate_parse)
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon_parse;
 }
 else
 {
                ps_trns_addr = &ps_dec->s_tran_addrecon;
 }

            u2_mb_x = 0xffff;
            u2_mb_y = 0;
            ps_dec->u2_cur_mb_addr = 0;
            ps_dec->ps_deblk_mbn = ps_dec->ps_deblk_pic;
            ps_dec->ps_mv_cur = ps_dec->s_cur_pic.ps_mv;
            ps_trns_addr->pu1_dest_y = ps_dec->s_cur_pic.pu1_buf1;
            ps_trns_addr->pu1_dest_u = ps_dec->s_cur_pic.pu1_buf2;
            ps_trns_addr->pu1_dest_v = ps_dec->s_cur_pic.pu1_buf3;

            ps_trns_addr->pu1_mb_y = ps_trns_addr->pu1_dest_y;
            ps_trns_addr->pu1_mb_u = ps_trns_addr->pu1_dest_u;
            ps_trns_addr->pu1_mb_v = ps_trns_addr->pu1_dest_v;

 }

        ps_dec->ps_part = ps_dec->ps_parse_part_params;

        ps_dec->u2_mbx =
 (MOD(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby =
 (DIV(u2_first_mb_in_slice - 1, ps_seq->u2_frm_wd_in_mbs));
        ps_dec->u2_mby <<= ps_cur_slice->u1_mbaff_frame_flag;
        ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
        ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
 }

 /* RBSP stop bit is used for CABAC decoding*/
    ps_bitstrm->u4_max_ofst += ps_dec->ps_cur_pps->u1_entropy_coding_mode;

    ps_dec->u1_B = (u1_slice_type == B_SLICE);
    ps_dec->u4_next_mb_skip = 0;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice =
                    ps_dec->ps_cur_slice->u2_first_mb_in_slice;
    ps_dec->ps_parse_cur_slice->slice_type =
                    ps_dec->ps_cur_slice->u1_slice_type;


    ps_dec->u4_start_recon_deblk = 1;
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = ( void *)pu1_buf;
 }

 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 if(u1_slice_type == I_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= I_SLC_BIT;

        ret = ih264d_parse_islice(ps_dec, u2_first_mb_in_slice);

 if(ps_dec->i4_pic_type != B_SLICE && ps_dec->i4_pic_type != P_SLICE)
            ps_dec->i4_pic_type = I_SLICE;

 }
 else if(u1_slice_type == P_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= P_SLC_BIT;
        ret = ih264d_parse_pslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
 if(ps_dec->i4_pic_type != B_SLICE)
            ps_dec->i4_pic_type = P_SLICE;
 }
 else if(u1_slice_type == B_SLICE)
 {
        ps_dec->ps_cur_pic->u4_pack_slc_typ |= B_SLC_BIT;
        ret = ih264d_parse_bslice(ps_dec, u2_first_mb_in_slice);
        ps_dec->u1_pr_sl_type = u1_slice_type;
        ps_dec->i4_pic_type = B_SLICE;
 }
 else
 return ERROR_INV_SLC_TYPE_T;

 if(ps_dec->u1_slice_header_done)
 {
 /* set to zero to indicate a valid slice has been decoded */
 /* first slice header successfully decoded */
        ps_dec->u4_first_slice_in_pic = 0;
        ps_dec->u1_first_slice_in_stream = 0;
 }

 if(ret != OK)
 return ret;

 /* storing last Mb X and MbY of the slice */
    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 /* End of Picture detection */

 if(ps_dec->u2_total_mbs_coded >= (ps_seq->u2_max_mb_addr + 1))
 {
        ps_dec->u1_pic_decode_done = 1;

 }

 {
 dec_err_status_t * ps_err = ps_dec->ps_dec_err_status;
 if((ps_err->u1_err_flag & REJECT_PB_PICS)
 && (ps_err->u1_cur_pic_type == PIC_TYPE_I))
 {
            ps_err->u1_err_flag = ACCEPT_ALL_PICS;
 }
 }

    PRINT_BIN_BIT_RATIO(ps_dec)

 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  virtual ssize_t decrypt(const uint8_t key[16], const uint8_t iv[16],
 CryptoPlugin::Mode mode, const CryptoPlugin::Pattern &pattern,
 const SourceBuffer &source, size_t offset,
 const CryptoPlugin::SubSample *subSamples, size_t numSubSamples,
 const DestinationBuffer &destination, AString *errorDetailMsg) {
 Parcel data, reply;
        data.writeInterfaceToken(ICrypto::getInterfaceDescriptor());
        data.writeInt32(mode);
        data.writeInt32(pattern.mEncryptBlocks);
        data.writeInt32(pattern.mSkipBlocks);

 static const uint8_t kDummy[16] = { 0 };

 if (key == NULL) {
            key = kDummy;
 }

 if (iv == NULL) {
            iv = kDummy;
 }

        data.write(key, 16);
        data.write(iv, 16);

 size_t totalSize = 0;
 for (size_t i = 0; i < numSubSamples; ++i) {
            totalSize += subSamples[i].mNumBytesOfEncryptedData;
            totalSize += subSamples[i].mNumBytesOfClearData;
 }

        data.writeInt32(totalSize);
        data.writeStrongBinder(IInterface::asBinder(source.mSharedMemory));
        data.writeInt32(source.mHeapSeqNum);
        data.writeInt32(offset);

        data.writeInt32(numSubSamples);
        data.write(subSamples, sizeof(CryptoPlugin::SubSample) * numSubSamples);

        data.writeInt32((int32_t)destination.mType);
 if (destination.mType == kDestinationTypeNativeHandle) {
 if (destination.mHandle == NULL) {
 return BAD_VALUE;
 }
            data.writeNativeHandle(destination.mHandle);
 } else {
 if (destination.mSharedMemory == NULL) {
 return BAD_VALUE;
 }
            data.writeStrongBinder(IInterface::asBinder(destination.mSharedMemory));
 }

        remote()->transact(DECRYPT, data, &reply);

 ssize_t result = reply.readInt32();

 if (isCryptoError(result)) {
 AString msg = reply.readCString();
 if (errorDetailMsg) {
 *errorDetailMsg = msg;
 }
 }

 return result;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Segment::ParseHeaders() {
 long long total, available;

 const int status = m_pReader->Length(&total, &available);


   if (status < 0)  // error
     return status;
 
  assert((total < 0) || (available <= total));
 
   const long long segment_stop = (m_size < 0) ? -1 : m_start + m_size;
  assert((segment_stop < 0) || (total < 0) || (segment_stop <= total));
  assert((segment_stop < 0) || (m_pos <= segment_stop));
 
   for (;;) {
     if ((total >= 0) && (m_pos >= total))
 break;

 if ((segment_stop >= 0) && (m_pos >= segment_stop))
 break;


     long long pos = m_pos;
     const long long element_start = pos;
 
     if ((pos + 1) > available)
       return (pos + 1);
 
 long len;
 long long result = GetUIntLength(m_pReader, pos, len);


     if (result < 0)  // error
       return result;
 
    if (result > 0)  // underflow (weird)
       return (pos + 1);
 
     if ((segment_stop >= 0) && ((pos + len) > segment_stop))
       return E_FILE_FORMAT_INVALID;

 if ((pos + len) > available)

       return pos + len;
 
     const long long idpos = pos;
    const long long id = ReadUInt(m_pReader, idpos, len);
 
    if (id < 0)  // error
      return id;
 
     if (id == 0x0F43B675)  // Cluster ID
       break;

    pos += len; // consume ID

 if ((pos + 1) > available)
 return (pos + 1);

    result = GetUIntLength(m_pReader, pos, len);


     if (result < 0)  // error
       return result;
 
    if (result > 0)  // underflow (weird)
       return (pos + 1);
 
     if ((segment_stop >= 0) && ((pos + len) > segment_stop))
       return E_FILE_FORMAT_INVALID;

 if ((pos + len) > available)
 return pos + len;

 
     const long long size = ReadUInt(m_pReader, pos, len);
 
    if (size < 0)  // error
       return size;
 
     pos += len;  // consume length of size of element
 
     const long long element_size = size + pos - element_start;
 

 if ((segment_stop >= 0) && ((pos + size) > segment_stop))
 return E_FILE_FORMAT_INVALID;


 if ((pos + size) > available)
 return pos + size;

 if (id == 0x0549A966) { // Segment Info ID
 if (m_pInfo)
 return E_FILE_FORMAT_INVALID;

      m_pInfo = new (std::nothrow)
 SegmentInfo(this, pos, size, element_start, element_size);

 if (m_pInfo == NULL)
 return -1;

 const long status = m_pInfo->Parse();

 if (status)
 return status;
 } else if (id == 0x0654AE6B) { // Tracks ID
 if (m_pTracks)
 return E_FILE_FORMAT_INVALID;

      m_pTracks = new (std::nothrow)
 Tracks(this, pos, size, element_start, element_size);

 if (m_pTracks == NULL)
 return -1;

 const long status = m_pTracks->Parse();

 if (status)
 return status;
 } else if (id == 0x0C53BB6B) { // Cues ID
 if (m_pCues == NULL) {
        m_pCues = new (std::nothrow)
 Cues(this, pos, size, element_start, element_size);

 if (m_pCues == NULL)
 return -1;
 }
 } else if (id == 0x014D9B74) { // SeekHead ID
 if (m_pSeekHead == NULL) {
        m_pSeekHead = new (std::nothrow)
 SeekHead(this, pos, size, element_start, element_size);

 if (m_pSeekHead == NULL)
 return -1;

 const long status = m_pSeekHead->Parse();

 if (status)
 return status;
 }
 } else if (id == 0x0043A770) { // Chapters ID
 if (m_pChapters == NULL) {
        m_pChapters = new (std::nothrow)
 Chapters(this, pos, size, element_start, element_size);

 if (m_pChapters == NULL)
 return -1;

 const long status = m_pChapters->Parse();


         if (status)
           return status;
       }
     }
 
     m_pos = pos + size;  // consume payload
   }
 
  assert((segment_stop < 0) || (m_pos <= segment_stop));
 
   if (m_pInfo == NULL)  // TODO: liberalize this behavior
     return E_FILE_FORMAT_INVALID;

 if (m_pTracks == NULL)
 return E_FILE_FORMAT_INVALID;

 return 0; // success
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void Downmix_foldFromQuad(int16_t *pSrc, int16_t*pDst, size_t numFrames, bool accumulate) {
 if (accumulate) {
 while (numFrames) {
            pDst[0] = clamp16(pDst[0] + ((pSrc[0] + pSrc[2]) >> 1));
            pDst[1] = clamp16(pDst[1] + ((pSrc[1] + pSrc[3]) >> 1));
            pSrc += 4;
            pDst += 2;
            numFrames--;
 }
 } else { // same code as above but without adding and clamping pDst[i] to itself
 while (numFrames) {
            pDst[0] = clamp16((pSrc[0] + pSrc[2]) >> 1);
            pDst[1] = clamp16((pSrc[1] + pSrc[3]) >> 1);
            pSrc += 4;
            pDst += 2;
            numFrames--;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  int main(int argc, char **argv)
 {
    FILE                *infile, *outfile[NUM_ENCODERS];
     vpx_codec_ctx_t      codec[NUM_ENCODERS];
     vpx_codec_enc_cfg_t  cfg[NUM_ENCODERS];
    vpx_codec_pts_t      frame_cnt = 0;
     vpx_image_t          raw[NUM_ENCODERS];
     vpx_codec_err_t      res[NUM_ENCODERS];
 
     int                  i;
     long                 width;
     long                 height;
     int                  frame_avail;
     int                  got_data;
     int                  flags = 0;
 
     /*Currently, only realtime mode is supported in multi-resolution encoding.*/
     int                  arg_deadline = VPX_DL_REALTIME;

 /* Set show_psnr to 1/0 to show/not show PSNR. Choose show_psnr=0 if you

        don't need to know PSNR, which will skip PSNR calculation and save
        encoding time. */
     int                  show_psnr = 0;
     uint64_t             psnr_sse_total[NUM_ENCODERS] = {0};
     uint64_t             psnr_samples_total[NUM_ENCODERS] = {0};
     double               psnr_totals[NUM_ENCODERS][4] = {{0,0}};
     int                  psnr_count[NUM_ENCODERS] = {0};
 
     /* Set the required target bitrates for each resolution level.
      * If target bitrate for highest-resolution level is set to 0,
      * (i.e. target_bitrate[0]=0), we skip encoding at that level.
      */
     unsigned int         target_bitrate[NUM_ENCODERS]={1000, 500, 100};
     /* Enter the frame rate of the input video */
     int                  framerate = 30;
     /* Set down-sampling factor for each resolution level.
        dsf[0] controls down sampling from level 0 to level 1;
        dsf[1] controls down sampling from level 1 to level 2;
        dsf[2] is not used. */
     vpx_rational_t dsf[NUM_ENCODERS] = {{2, 1}, {2, 1}, {1, 1}};
 
    if(argc!= (5+NUM_ENCODERS))
        die("Usage: %s <width> <height> <infile> <outfile(s)> <output psnr?>\n",
             argv[0]);
 
     printf("Using %s\n",vpx_codec_iface_name(interface));
 
     width = strtol(argv[1], NULL, 0);
     height = strtol(argv[2], NULL, 0);
 
     if(width < 16 || width%2 || height <16 || height%2)
         die("Invalid resolution: %ldx%ld", width, height);
 
     /* Open input video file for encoding */
    if(!(infile = fopen(argv[3], "rb")))
        die("Failed to open %s for reading", argv[3]);
 
     /* Open output file for each encoder to output bitstreams */
     for (i=0; i< NUM_ENCODERS; i++)
 {
 if(!target_bitrate[i])
 {
            outfile[i] = NULL;

             continue;
         }
 
        if(!(outfile[i] = fopen(argv[i+4], "wb")))
             die("Failed to open %s for writing", argv[i+4]);
     }
 
    show_psnr = strtol(argv[NUM_ENCODERS + 4], NULL, 0);
 
     /* Populate default encoder configuration */
     for (i=0; i< NUM_ENCODERS; i++)
 {
        res[i] = vpx_codec_enc_config_default(interface, &cfg[i], 0);
 if(res[i]) {
            printf("Failed to get config: %s\n", vpx_codec_err_to_string(res[i]));
 return EXIT_FAILURE;
 }
 }

 /*
     * Update the default configuration according to needs of the application.
     */

     /* Highest-resolution encoder settings */
     cfg[0].g_w = width;
     cfg[0].g_h = height;
    cfg[0].g_threads = 1;                           /* number of threads used */
    cfg[0].rc_dropframe_thresh = 30;
     cfg[0].rc_end_usage = VPX_CBR;
     cfg[0].rc_resize_allowed = 0;
    cfg[0].rc_min_quantizer = 4;
     cfg[0].rc_max_quantizer = 56;
    cfg[0].rc_undershoot_pct = 98;
    cfg[0].rc_overshoot_pct = 100;
     cfg[0].rc_buf_initial_sz = 500;
     cfg[0].rc_buf_optimal_sz = 600;
     cfg[0].rc_buf_sz = 1000;
    cfg[0].g_error_resilient = 1; /* Enable error resilient mode */
    cfg[0].g_lag_in_frames   = 0;

 /* Disable automatic keyframe placement */

     /* Note: These 3 settings are copied to all levels. But, except the lowest
      * resolution level, all other levels are set to VPX_KF_DISABLED internally.
      */
     cfg[0].kf_min_dist = 3000;
     cfg[0].kf_max_dist = 3000;

    cfg[0].rc_target_bitrate = target_bitrate[0]; /* Set target bitrate */
    cfg[0].g_timebase.num = 1; /* Set fps */
    cfg[0].g_timebase.den = framerate;

 /* Other-resolution encoder settings */
 for (i=1; i< NUM_ENCODERS; i++)

     {
         memcpy(&cfg[i], &cfg[0], sizeof(vpx_codec_enc_cfg_t));
 
        cfg[i].g_threads = 1;                       /* number of threads used */
         cfg[i].rc_target_bitrate = target_bitrate[i];
 
         /* Note: Width & height of other-resolution encoders are calculated
         * from the highest-resolution encoder's size and the corresponding
         * down_sampling_factor.
         */
 {
 unsigned int iw = cfg[i-1].g_w*dsf[i-1].den + dsf[i-1].num - 1;
 unsigned int ih = cfg[i-1].g_h*dsf[i-1].den + dsf[i-1].num - 1;
            cfg[i].g_w = iw/dsf[i-1].num;
            cfg[i].g_h = ih/dsf[i-1].num;
 }

 /* Make width & height to be multiplier of 2. */
 if((cfg[i].g_w)%2)cfg[i].g_w++;

         if((cfg[i].g_h)%2)cfg[i].g_h++;
     }
 
     /* Allocate image for each encoder */
     for (i=0; i< NUM_ENCODERS; i++)
         if(!vpx_img_alloc(&raw[i], VPX_IMG_FMT_I420, cfg[i].g_w, cfg[i].g_h, 32))
            die("Failed to allocate image", cfg[i].g_w, cfg[i].g_h);

 if (raw[0].stride[VPX_PLANE_Y] == raw[0].d_w)
        read_frame_p = read_frame;
 else
        read_frame_p = read_frame_by_row;

 for (i=0; i< NUM_ENCODERS; i++)

         if(outfile[i])
             write_ivf_file_header(outfile[i], &cfg[i], 0);
 
     /* Initialize multi-encoder */
     if(vpx_codec_enc_init_multi(&codec[0], interface, &cfg[0], NUM_ENCODERS,
                                 (show_psnr ? VPX_CODEC_USE_PSNR : 0), &dsf[0]))
        die_codec(&codec[0], "Failed to initialize encoder");

 /* The extra encoding configuration parameters can be set as follows. */
 /* Set encoding speed */

     for ( i=0; i<NUM_ENCODERS; i++)
     {
         int speed = -6;
         if(vpx_codec_control(&codec[i], VP8E_SET_CPUUSED, speed))
             die_codec(&codec[i], "Failed to set cpu_used");
     }
 
    /* Set static threshold. */
     for ( i=0; i<NUM_ENCODERS; i++)
     {
        unsigned int static_thresh = 1;
        if(vpx_codec_control(&codec[i], VP8E_SET_STATIC_THRESHOLD, static_thresh))
             die_codec(&codec[i], "Failed to set static threshold");
     }
 
 /* Set NOISE_SENSITIVITY to do TEMPORAL_DENOISING */
 /* Enable denoising for the highest-resolution encoder. */
 if(vpx_codec_control(&codec[0], VP8E_SET_NOISE_SENSITIVITY, 1))
        die_codec(&codec[0], "Failed to set noise_sensitivity");
 for ( i=1; i< NUM_ENCODERS; i++)
 {
 if(vpx_codec_control(&codec[i], VP8E_SET_NOISE_SENSITIVITY, 0))

             die_codec(&codec[i], "Failed to set noise_sensitivity");
     }
 
 
     frame_avail = 1;
     got_data = 0;

 while(frame_avail || got_data)
 {
 vpx_codec_iter_t iter[NUM_ENCODERS]={NULL};
 const vpx_codec_cx_pkt_t *pkt[NUM_ENCODERS];

        flags = 0;
        frame_avail = read_frame_p(infile, &raw[0]);

 if(frame_avail)
 {
 for ( i=1; i<NUM_ENCODERS; i++)
 {
 /*Scale the image down a number of times by downsampling factor*/
 /* FilterMode 1 or 2 give better psnr than FilterMode 0. */
                I420Scale(raw[i-1].planes[VPX_PLANE_Y], raw[i-1].stride[VPX_PLANE_Y],
                          raw[i-1].planes[VPX_PLANE_U], raw[i-1].stride[VPX_PLANE_U],
                          raw[i-1].planes[VPX_PLANE_V], raw[i-1].stride[VPX_PLANE_V],
                          raw[i-1].d_w, raw[i-1].d_h,
                          raw[i].planes[VPX_PLANE_Y], raw[i].stride[VPX_PLANE_Y],

                           raw[i].planes[VPX_PLANE_U], raw[i].stride[VPX_PLANE_U],
                           raw[i].planes[VPX_PLANE_V], raw[i].stride[VPX_PLANE_V],
                           raw[i].d_w, raw[i].d_h, 1);
             }
         }
 
        /* Encode each frame at multi-levels */
        if(vpx_codec_encode(&codec[0], frame_avail? &raw[0] : NULL,
            frame_cnt, 1, flags, arg_deadline))
            die_codec(&codec[0], "Failed to encode frame");
 
         for (i=NUM_ENCODERS-1; i>=0 ; i--)
         {
             got_data = 0;
             while( (pkt[i] = vpx_codec_get_cx_data(&codec[i], &iter[i])) )
             {
                 got_data = 1;
 switch(pkt[i]->kind) {
 case VPX_CODEC_CX_FRAME_PKT:
                        write_ivf_frame_header(outfile[i], pkt[i]);
 (void) fwrite(pkt[i]->data.frame.buf, 1,
                                      pkt[i]->data.frame.sz, outfile[i]);
 break;
 case VPX_CODEC_PSNR_PKT:
 if (show_psnr)
 {
 int j;

                            psnr_sse_total[i] += pkt[i]->data.psnr.sse[0];

                             psnr_samples_total[i] += pkt[i]->data.psnr.samples[0];
                             for (j = 0; j < 4; j++)
                             {
                             }
                             psnr_count[i]++;
 }

 break;
 default:

                         break;
                 }
                 printf(pkt[i]->kind == VPX_CODEC_CX_FRAME_PKT
                       && (pkt[i]->data.frame.flags & VPX_FRAME_IS_KEY)? "K":".");
                 fflush(stdout);
             }
         }
         frame_cnt++;
     }
     printf("\n");
 
     fclose(infile);
 
    printf("Processed %ld frames.\n",(long int)frame_cnt-1);
 for (i=0; i< NUM_ENCODERS; i++)
 {
 /* Calculate PSNR and print it out */
 if ( (show_psnr) && (psnr_count[i]>0) )
 {
 int j;
 double ovpsnr = sse_to_psnr(psnr_samples_total[i], 255.0,
                                        psnr_sse_total[i]);

            fprintf(stderr, "\n ENC%d PSNR (Overall/Avg/Y/U/V)", i);

            fprintf(stderr, " %.3lf", ovpsnr);
 for (j = 0; j < 4; j++)
 {
                fprintf(stderr, " %.3lf", psnr_totals[i][j]/psnr_count[i]);
 }
 }

 if(vpx_codec_destroy(&codec[i]))
            die_codec(&codec[i], "Failed to destroy codec");

        vpx_img_free(&raw[i]);

 if(!outfile[i])
 continue;

 /* Try to rewrite the file header with the actual frame count */
 if(!fseek(outfile[i], 0, SEEK_SET))
            write_ivf_file_header(outfile[i], &cfg[i], frame_cnt-1);
        fclose(outfile[i]);
 }
    printf("\n");

 return EXIT_SUCCESS;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: WORD32 ih264d_parse_islice(dec_struct_t *ps_dec,
                            UWORD16 u2_first_mb_in_slice)
{
 dec_pic_params_t * ps_pps = ps_dec->ps_cur_pps;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_dec->ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_dec->ps_bitstrm->u4_ofst;
    UWORD32 u4_temp;
    WORD32 i_temp;
    WORD32 ret;

 /*--------------------------------------------------------------------*/
 /* Read remaining contents of the slice header                        */
 /*--------------------------------------------------------------------*/
 /* dec_ref_pic_marking function */
 /* G050 */
 if(ps_slice->u1_nal_ref_idc != 0)
 {
 if(!ps_dec->ps_dpb_cmds->u1_dpb_commands_read)
 {
            i_temp = ih264d_read_mmco_commands(ps_dec);
 if (i_temp < 0)
 {
 return ERROR_DBP_MANAGER_T;
 }
            ps_dec->u4_bitoffset = i_temp;
 }
 else
            ps_dec->ps_bitstrm->u4_ofst += ps_dec->u4_bitoffset;
 }
 /* G050 */

 /* Read slice_qp_delta */
    i_temp = ps_pps->u1_pic_init_qp
 + ih264d_sev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
 if((i_temp < 0) || (i_temp > 51))
 return ERROR_INV_RANGE_QP_T;
    ps_slice->u1_slice_qp = i_temp;
    COPYTHECONTEXT("SH: slice_qp_delta",
                    ps_slice->u1_slice_qp - ps_pps->u1_pic_init_qp);

 if(ps_pps->u1_deblocking_filter_parameters_present_flag == 1)
 {
        u4_temp = ih264d_uev(pu4_bitstrm_ofst, pu4_bitstrm_buf);
        COPYTHECONTEXT("SH: disable_deblocking_filter_idc", u4_temp);

 if(u4_temp > SLICE_BOUNDARY_DBLK_DISABLED)
 {
 return ERROR_INV_SLICE_HDR_T;
 }
        ps_slice->u1_disable_dblk_filter_idc = u4_temp;
 if(u4_temp != 1)
 {
            i_temp = ih264d_sev(pu4_bitstrm_ofst, pu4_bitstrm_buf)
 << 1;
 if((MIN_DBLK_FIL_OFF > i_temp) || (i_temp > MAX_DBLK_FIL_OFF))
 {
 return ERROR_INV_SLICE_HDR_T;
 }
            ps_slice->i1_slice_alpha_c0_offset = i_temp;
            COPYTHECONTEXT("SH: slice_alpha_c0_offset_div2",
                            ps_slice->i1_slice_alpha_c0_offset >> 1);

            i_temp = ih264d_sev(pu4_bitstrm_ofst, pu4_bitstrm_buf)
 << 1;
 if((MIN_DBLK_FIL_OFF > i_temp) || (i_temp > MAX_DBLK_FIL_OFF))
 {
 return ERROR_INV_SLICE_HDR_T;
 }
            ps_slice->i1_slice_beta_offset = i_temp;
            COPYTHECONTEXT("SH: slice_beta_offset_div2",
                            ps_slice->i1_slice_beta_offset >> 1);

 }
 else
 {
            ps_slice->i1_slice_alpha_c0_offset = 0;
            ps_slice->i1_slice_beta_offset = 0;
 }
 }
 else
 {
        ps_slice->u1_disable_dblk_filter_idc = 0;
        ps_slice->i1_slice_alpha_c0_offset = 0;
        ps_slice->i1_slice_beta_offset = 0;
 }

 /* Initialization to check if number of motion vector per 2 Mbs */
 /* are exceeding the range or not */
    ps_dec->u2_mv_2mb[0] = 0;
    ps_dec->u2_mv_2mb[1] = 0;


 /*set slice header cone to 2 ,to indicate  correct header*/
    ps_dec->u1_slice_header_done = 2;

 if(ps_pps->u1_entropy_coding_mode)
 {
        SWITCHOFFTRACE; SWITCHONTRACECABAC;
 if(ps_dec->ps_cur_slice->u1_mbaff_frame_flag)
 {
            ps_dec->pf_get_mb_info = ih264d_get_mb_info_cabac_mbaff;
 }
 else
            ps_dec->pf_get_mb_info = ih264d_get_mb_info_cabac_nonmbaff;

        ret = ih264d_parse_islice_data_cabac(ps_dec, ps_slice,
                                             u2_first_mb_in_slice);
 if(ret != OK)
 return ret;
        SWITCHONTRACE; SWITCHOFFTRACECABAC;
 }
 else
 {
 if(ps_dec->ps_cur_slice->u1_mbaff_frame_flag)
 {
            ps_dec->pf_get_mb_info = ih264d_get_mb_info_cavlc_mbaff;
 }
 else
            ps_dec->pf_get_mb_info = ih264d_get_mb_info_cavlc_nonmbaff;
        ret = ih264d_parse_islice_data_cavlc(ps_dec, ps_slice,
                                       u2_first_mb_in_slice);
 if(ret != OK)
 return ret;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX *OMXNodeInstance::owner() {
 return mOwner;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool OMX::CallbackDispatcher::loop() {
 for (;;) {
        std::list<omx_message> messages;

 {
 Mutex::Autolock autoLock(mLock);
 while (!mDone && mQueue.empty()) {
                mQueueChanged.wait(mLock);
 }

 if (mDone) {
 break;
 }

            messages.swap(mQueue);
 }

        dispatch(messages);
 }

 return false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static EAS_RESULT Parse_lart (SDLS_SYNTHESIZER_DATA *pDLSData, EAS_I32 pos, EAS_I32 size, S_DLS_ART_VALUES *pArt)
{
    EAS_RESULT result;
    EAS_U32 temp;
    EAS_I32 endChunk;
    EAS_I32 chunkPos;
    EAS_I32 art1Pos;
    EAS_I32 art2Pos;

 /* seek to start of chunk */
 if ((result = EAS_HWFileSeek(pDLSData->hwInstData, pDLSData->fileHandle, pos)) != EAS_SUCCESS)
 return result;

 /* no articulation chunks yet */
    art1Pos = art2Pos = 0;

 /* read to end of chunk */
    endChunk = pos + size;
 while (pos < endChunk)
 {
        chunkPos = pos;

 /* get the next chunk type */
 if ((result = NextChunk(pDLSData, &pos, &temp, &size)) != EAS_SUCCESS)
 return result;

 /* parse useful chunks */
 switch (temp)
 {
 case CHUNK_CDL:
 if ((result = Parse_cdl(pDLSData, size, &temp)) != EAS_SUCCESS)
 return result;

 /* if conditional chunk evaluates false, skip this list */
 if (!temp)
 return EAS_SUCCESS;
 break;

 case CHUNK_ART1:
                art1Pos = chunkPos + 8;
 break;

 case CHUNK_ART2:
                art2Pos = chunkPos + 8;
 break;

 default:
 break;

 }
 }

 if (art1Pos)
 {
 if ((result = Parse_art(pDLSData, art1Pos, pArt)) != EAS_SUCCESS)
 return result;
 }

 if (art2Pos)
 {
 if ((result = Parse_art(pDLSData, art2Pos, pArt)) != EAS_SUCCESS)
 return result;
 }

 return EAS_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t acquireBuffer(BufferItem *buffer, nsecs_t presentWhen,
 uint64_t maxFrameNumber) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeInt64(presentWhen);
        data.writeUint64(maxFrameNumber);
 status_t result = remote()->transact(ACQUIRE_BUFFER, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
        result = reply.read(*buffer);
 if (result != NO_ERROR) {
 return result;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int uipc_start_main_server_thread(void)
{
    uipc_main.running = 1;

 if (pthread_create(&uipc_main.tid, (const pthread_attr_t *) NULL, (void*)uipc_read_task, NULL) < 0)
 {
        BTIF_TRACE_ERROR("uipc_thread_create pthread_create failed:%d", errno);
 return -1;
 }

 return 0;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void format_init(format_list *pf)
{
 int i;
 for (i=0; i<FORMAT_SET_COUNT; ++i)
      pf->bits[i] = 0; /* All off */
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AudioFlinger::EffectChain::setEffectSuspended_l(
 const effect_uuid_t *type, bool suspend)
{
    sp<SuspendedEffectDesc> desc;
 ssize_t index = mSuspendedEffects.indexOfKey(type->timeLow);
 if (suspend) {
 if (index >= 0) {
            desc = mSuspendedEffects.valueAt(index);
 } else {
            desc = new SuspendedEffectDesc();
            desc->mType = *type;
            mSuspendedEffects.add(type->timeLow, desc);
            ALOGV("setEffectSuspended_l() add entry for %08x", type->timeLow);
 }
 if (desc->mRefCount++ == 0) {
            sp<EffectModule> effect = getEffectIfEnabled(type);
 if (effect != 0) {
                desc->mEffect = effect;
                effect->setSuspended(true);
                effect->setEnabled(false);
 }
 }
 } else {
 if (index < 0) {
 return;
 }
        desc = mSuspendedEffects.valueAt(index);
 if (desc->mRefCount <= 0) {
            ALOGW("setEffectSuspended_l() restore refcount should not be 0 %d", desc->mRefCount);
            desc->mRefCount = 1;
 }
 if (--desc->mRefCount == 0) {
            ALOGV("setEffectSuspended_l() remove entry for %08x", mSuspendedEffects.keyAt(index));
 if (desc->mEffect != 0) {
                sp<EffectModule> effect = desc->mEffect.promote();
 if (effect != 0) {
                    effect->setSuspended(false);
                    effect->lock();
 EffectHandle *handle = effect->controlHandle_l();
 if (handle != NULL && !handle->destroyed_l()) {
                        effect->setEnabled_l(handle->enabled());
 }
                    effect->unlock();
 }
                desc->mEffect.clear();
 }
            mSuspendedEffects.removeItemsAt(index);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_get_pic_mv_bank_size(WORD32 num_luma_samples)
{
    WORD32 size;

    WORD32 pic_size;

    WORD32 mv_bank_size;
    WORD32 num_pu;
    WORD32 num_ctb;
    pic_size = num_luma_samples;


    num_pu = pic_size / (MIN_PU_SIZE * MIN_PU_SIZE);
    num_ctb = pic_size / (MIN_CTB_SIZE * MIN_CTB_SIZE);

    mv_bank_size = 0;

 /* Size for storing pu_t start index each CTB */
 /* One extra entry is needed to compute number of PUs in the last CTB */
    mv_bank_size += (num_ctb + 1) * sizeof(WORD32);

 /* Size for pu_map */
    mv_bank_size += num_pu;

 /* Size for storing pu_t for each PU */
    mv_bank_size += num_pu * sizeof(pu_t);

 /* Size for storing slice_idx for each CTB */
    mv_bank_size += ALIGN4(num_ctb * sizeof(UWORD16));

    size =  mv_bank_size;
 return size;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::read(
 MediaBuffer **out, const ReadOptions *options) {
 Mutex::Autolock autoLock(mLock);

    CHECK(mStarted);

 if (mFirstMoofOffset > 0) {
 return fragmentedRead(out, options);
 }

 *out = NULL;

 int64_t targetSampleTimeUs = -1;

 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if (options && options->getSeekTo(&seekTimeUs, &mode)) {
 uint32_t findFlags = 0;
 switch (mode) {
 case ReadOptions::SEEK_PREVIOUS_SYNC:
                findFlags = SampleTable::kFlagBefore;
 break;
 case ReadOptions::SEEK_NEXT_SYNC:
                findFlags = SampleTable::kFlagAfter;
 break;
 case ReadOptions::SEEK_CLOSEST_SYNC:
 case ReadOptions::SEEK_CLOSEST:
                findFlags = SampleTable::kFlagClosest;
 break;
 default:
                CHECK(!"Should not be here.");
 break;
 }

 uint32_t sampleIndex;
 status_t err = mSampleTable->findSampleAtTime(
                seekTimeUs, 1000000, mTimescale,
 &sampleIndex, findFlags);

 if (mode == ReadOptions::SEEK_CLOSEST) {
            findFlags = SampleTable::kFlagBefore;
 }

 uint32_t syncSampleIndex;
 if (err == OK) {
            err = mSampleTable->findSyncSampleNear(
                    sampleIndex, &syncSampleIndex, findFlags);
 }

 uint32_t sampleTime;
 if (err == OK) {
            err = mSampleTable->getMetaDataForSample(
                    sampleIndex, NULL, NULL, &sampleTime);
 }

 if (err != OK) {
 if (err == ERROR_OUT_OF_RANGE) {
                err = ERROR_END_OF_STREAM;
 }
            ALOGV("end of stream");
 return err;
 }

 if (mode == ReadOptions::SEEK_CLOSEST) {
            targetSampleTimeUs = (sampleTime * 1000000ll) / mTimescale;
 }

#if 0
 uint32_t syncSampleTime;
        CHECK_EQ(OK, mSampleTable->getMetaDataForSample(
                    syncSampleIndex, NULL, NULL, &syncSampleTime));

        ALOGI("seek to time %lld us => sample at time %lld us, "
 "sync sample at time %lld us",
             seekTimeUs,
             sampleTime * 1000000ll / mTimescale,
             syncSampleTime * 1000000ll / mTimescale);
#endif

        mCurrentSampleIndex = syncSampleIndex;
 if (mBuffer != NULL) {
            mBuffer->release();
            mBuffer = NULL;
 }

 }

 off64_t offset;
 size_t size;
 uint32_t cts, stts;
 bool isSyncSample;
 bool newBuffer = false;
 if (mBuffer == NULL) {
        newBuffer = true;

 status_t err =
            mSampleTable->getMetaDataForSample(
                    mCurrentSampleIndex, &offset, &size, &cts, &isSyncSample, &stts);

 if (err != OK) {
 return err;
 }

        err = mGroup->acquire_buffer(&mBuffer);

 if (err != OK) {
            CHECK(mBuffer == NULL);
 return err;
 }
 }

 if ((!mIsAVC && !mIsHEVC) || mWantsNALFragments) {
 if (newBuffer) {
 ssize_t num_bytes_read =
                mDataSource->readAt(offset, (uint8_t *)mBuffer->data(), size);

 if (num_bytes_read < (ssize_t)size) {
                mBuffer->release();
                mBuffer = NULL;

 return ERROR_IO;
 }

            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);
            mBuffer->meta_data()->clear();
            mBuffer->meta_data()->setInt64(
                    kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
            mBuffer->meta_data()->setInt64(
                    kKeyDuration, ((int64_t)stts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
                mBuffer->meta_data()->setInt64(
                        kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
                mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;
 }

 if (!mIsAVC && !mIsHEVC) {
 *out = mBuffer;
            mBuffer = NULL;

 return OK;
 }


        CHECK(mBuffer->range_length() >= mNALLengthSize);

 const uint8_t *src =
 (const uint8_t *)mBuffer->data() + mBuffer->range_offset();

 size_t nal_size = parseNALSize(src);
 if (mBuffer->range_length() < mNALLengthSize + nal_size) {
            ALOGE("incomplete NAL unit.");

            mBuffer->release();
            mBuffer = NULL;

 return ERROR_MALFORMED;
 }

 MediaBuffer *clone = mBuffer->clone();
        CHECK(clone != NULL);
        clone->set_range(mBuffer->range_offset() + mNALLengthSize, nal_size);

        CHECK(mBuffer != NULL);
        mBuffer->set_range(
                mBuffer->range_offset() + mNALLengthSize + nal_size,
                mBuffer->range_length() - mNALLengthSize - nal_size);

 if (mBuffer->range_length() == 0) {
            mBuffer->release();
            mBuffer = NULL;
 }

 *out = clone;

 return OK;
 } else {
 ssize_t num_bytes_read = 0;
 int32_t drm = 0;
 bool usesDRM = (mFormat->findInt32(kKeyIsDRM, &drm) && drm != 0);
 if (usesDRM) {
            num_bytes_read =
                mDataSource->readAt(offset, (uint8_t*)mBuffer->data(), size);
 } else {
            num_bytes_read = mDataSource->readAt(offset, mSrcBuffer, size);
 }

 if (num_bytes_read < (ssize_t)size) {
            mBuffer->release();
            mBuffer = NULL;

 return ERROR_IO;
 }

 if (usesDRM) {
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);

 } else {
 uint8_t *dstData = (uint8_t *)mBuffer->data();
 size_t srcOffset = 0;

             size_t dstOffset = 0;
 
             while (srcOffset < size) {
                bool isMalFormed = (srcOffset + mNALLengthSize > size);
                 size_t nalLength = 0;
                 if (!isMalFormed) {
                     nalLength = parseNALSize(&mSrcBuffer[srcOffset]);
                     srcOffset += mNALLengthSize;
                    isMalFormed = srcOffset + nalLength > size;
                 }
 
                 if (isMalFormed) {
                    ALOGE("Video is malformed");
                    mBuffer->release();
                    mBuffer = NULL;
 return ERROR_MALFORMED;
 }

 if (nalLength == 0) {
 continue;
 }

                CHECK(dstOffset + 4 <= mBuffer->size());

                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 1;
                memcpy(&dstData[dstOffset], &mSrcBuffer[srcOffset], nalLength);
                srcOffset += nalLength;
                dstOffset += nalLength;
 }
            CHECK_EQ(srcOffset, size);
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, dstOffset);
 }

        mBuffer->meta_data()->clear();
        mBuffer->meta_data()->setInt64(
                kKeyTime, ((int64_t)cts * 1000000) / mTimescale);
        mBuffer->meta_data()->setInt64(
                kKeyDuration, ((int64_t)stts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
            mBuffer->meta_data()->setInt64(
                    kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
            mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;

 *out = mBuffer;
        mBuffer = NULL;

 return OK;
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Parcel::writeBlob(size_t len, WritableBlob* outBlob)
{
 status_t status;

 if (!mAllowFds || len <= IN_PLACE_BLOB_LIMIT) {
        ALOGV("writeBlob: write in place");
        status = writeInt32(0);
 if (status) return status;

 void* ptr = writeInplace(len);
 if (!ptr) return NO_MEMORY;

        outBlob->init(false /*mapped*/, ptr, len);
 return NO_ERROR;
 }

    ALOGV("writeBlob: write to ashmem");
 int fd = ashmem_create_region("Parcel Blob", len);
 if (fd < 0) return NO_MEMORY;

 int result = ashmem_set_prot_region(fd, PROT_READ | PROT_WRITE);
 if (result < 0) {
        status = result;
 } else {
 void* ptr = ::mmap(NULL, len, PROT_READ | PROT_WRITE, MAP_SHARED, fd, 0);
 if (ptr == MAP_FAILED) {
            status = -errno;
 } else {
            result = ashmem_set_prot_region(fd, PROT_READ);
 if (result < 0) {
                status = result;
 } else {
                status = writeInt32(1);
 if (!status) {
                    status = writeFileDescriptor(fd, true /*takeOwnership*/);
 if (!status) {
                        outBlob->init(true /*mapped*/, ptr, len);
 return NO_ERROR;
 }
 }
 }
 }
 ::munmap(ptr, len);
 }
 ::close(fd);
 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::finishPrepareAsync() {
 status_t err = startSources();
 if (err != OK) {
        ALOGE("Failed to init start data source!");
        notifyPreparedAndCleanup(err);
 return;
 }

 if (mIsStreaming) {
        mPrepareBuffering = true;

        ensureCacheIsFetching();
        restartPollBuffering();
 } else {
        notifyPrepared();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_markltr(OMX_U32 frameIdx)
{
    DEBUG_PRINT_LOW("venc_set_goldenframe");
 int rc = true;
 struct v4l2_control control;

    control.id = V4L2_CID_MPEG_VIDC_VIDEO_MARKLTRFRAME;
    control.value = frameIdx;

    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);
 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set ltrmode %d", rc);
 return false;
 }

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%x, val=%d",
                    control.id, control.value);
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void CopyElements(Handle<FixedArrayBase> source, ElementsKind source_kind,
 Handle<FixedArrayBase> destination, int size) {
 Subclass::CopyElementsImpl(*source, 0, *destination, source_kind, 0,
                               kPackedSizeNotKnown, size);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void CodecHandler::onMessageReceived(const sp<AMessage> &msg) {

 switch (msg->what()) {
 case kWhatRequestActivityNotifications:
 {
 if (mCodec->mRequestedActivityNotification) {
 break;
 }

            mCodec->mCodec->requestActivityNotification(mCodec->mActivityNotification);
            mCodec->mRequestedActivityNotification = true;
 break;
 }

 case kWhatActivityNotify:
 {
 {
 int32_t generation;
                msg->findInt32("generation", &generation);

 if (generation != mCodec->mGeneration) {
 break;
 }

                mCodec->mRequestedActivityNotification = false;
 }

 if (mCodec->mCallback) {
                mCodec->mCallback(mCodec, mCodec->mCallbackUserData);
 }
 break;
 }

 case kWhatAsyncNotify:
 {
 int32_t cbID;
 if (!msg->findInt32("callbackID", &cbID)) {
                 ALOGE("kWhatAsyncNotify: callbackID is expected.");
 break;
 }

             ALOGV("kWhatAsyncNotify: cbID = %d", cbID);

 switch (cbID) {
 case MediaCodec::CB_INPUT_AVAILABLE:
 {
 int32_t index;
 if (!msg->findInt32("index", &index)) {
                         ALOGE("CB_INPUT_AVAILABLE: index is expected.");
 break;
 }

 Mutex::Autolock _l(mCodec->mAsyncCallbackLock);
 if (mCodec->mAsyncCallbackUserData != NULL
 || mCodec->mAsyncCallback.onAsyncInputAvailable != NULL) {
                         mCodec->mAsyncCallback.onAsyncInputAvailable(
                                 mCodec,
                                 mCodec->mAsyncCallbackUserData,
                                 index);
 }

 break;
 }

 case MediaCodec::CB_OUTPUT_AVAILABLE:
 {
 int32_t index;
 size_t offset;
 size_t size;
 int64_t timeUs;
 int32_t flags;

 if (!msg->findInt32("index", &index)) {
                         ALOGE("CB_OUTPUT_AVAILABLE: index is expected.");
 break;
 }
 if (!msg->findSize("offset", &offset)) {
                         ALOGE("CB_OUTPUT_AVAILABLE: offset is expected.");
 break;
 }
 if (!msg->findSize("size", &size)) {
                         ALOGE("CB_OUTPUT_AVAILABLE: size is expected.");
 break;
 }
 if (!msg->findInt64("timeUs", &timeUs)) {
                         ALOGE("CB_OUTPUT_AVAILABLE: timeUs is expected.");
 break;
 }
 if (!msg->findInt32("flags", &flags)) {
                         ALOGE("CB_OUTPUT_AVAILABLE: flags is expected.");
 break;
 }

 AMediaCodecBufferInfo bufferInfo = {
 (int32_t)offset,
 (int32_t)size,
                         timeUs,
 (uint32_t)flags};

 Mutex::Autolock _l(mCodec->mAsyncCallbackLock);
 if (mCodec->mAsyncCallbackUserData != NULL
 || mCodec->mAsyncCallback.onAsyncOutputAvailable != NULL) {
                         mCodec->mAsyncCallback.onAsyncOutputAvailable(
                                 mCodec,
                                 mCodec->mAsyncCallbackUserData,
                                 index,
 &bufferInfo);
 }

 break;
 }

 case MediaCodec::CB_OUTPUT_FORMAT_CHANGED:
 {
                     sp<AMessage> format;
 if (!msg->findMessage("format", &format)) {
                         ALOGE("CB_OUTPUT_FORMAT_CHANGED: format is expected.");
 break;
 }

 AMediaFormat *aMediaFormat = AMediaFormat_fromMsg(&format);

 Mutex::Autolock _l(mCodec->mAsyncCallbackLock);
 if (mCodec->mAsyncCallbackUserData != NULL
 || mCodec->mAsyncCallback.onAsyncFormatChanged != NULL) {
                         mCodec->mAsyncCallback.onAsyncFormatChanged(
                                 mCodec,
                                 mCodec->mAsyncCallbackUserData,
                                 aMediaFormat);
 }

 break;
 }

 case MediaCodec::CB_ERROR:
 {
 status_t err;
 int32_t actionCode;
 AString detail;
 if (!msg->findInt32("err", &err)) {
                         ALOGE("CB_ERROR: err is expected.");
 break;
 }
 if (!msg->findInt32("action", &actionCode)) {
                         ALOGE("CB_ERROR: action is expected.");
 break;
 }
                     msg->findString("detail", &detail);
                     ALOGE("Decoder reported error(0x%x), actionCode(%d), detail(%s)",
                           err, actionCode, detail.c_str());

 Mutex::Autolock _l(mCodec->mAsyncCallbackLock);
 if (mCodec->mAsyncCallbackUserData != NULL
 || mCodec->mAsyncCallback.onAsyncError != NULL) {
                         mCodec->mAsyncCallback.onAsyncError(
                                 mCodec,
                                 mCodec->mAsyncCallbackUserData,
                                 translate_error(err),
                                 actionCode,
                                 detail.c_str());
 }

 break;
 }

 default:
 {
                     ALOGE("kWhatAsyncNotify: callbackID(%d) is unexpected.", cbID);
 break;
 }
 }
 break;
 }

 case kWhatStopActivityNotifications:
 {
            sp<AReplyToken> replyID;
            msg->senderAwaitsResponse(&replyID);

            mCodec->mGeneration++;
            mCodec->mRequestedActivityNotification = false;

            sp<AMessage> response = new AMessage;
            response->postReply(replyID);
 break;
 }

 default:
            ALOGE("shouldn't be here");
 break;
 }

}

Labels: No
----------------lora model----------------
Response: MediaCodec::CodecHandler::onMessageReceived(const sp<AMessage> &msg) {
    ALOGV("onMessageReceived: msg->what()=%d", msg->what());
 CodecHandler::onMessageReceivedHelper(msg);
}</s>


Instruction: 
Input: void install_local_socket(asocket* s) {
    std::lock_guard<std::recursive_mutex> lock(local_socket_list_lock);

    s->id = local_socket_next_id++;

 if (local_socket_next_id == 0) {
        fatal("local socket id overflow");
 }

    insert_local_socket(s, &local_socket_list);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_dm_update_ble_remote_properties( BD_ADDR bd_addr, BD_NAME bd_name,
                                           tBT_DEVICE_TYPE dev_type)
{
   btif_update_remote_properties(bd_addr,bd_name,NULL,dev_type);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t Parcel::dataAvail() const
{
 return dataSize() - dataPosition();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean Region_isRect(JNIEnv* env, jobject region) {
 bool result = GetSkRegion(env, region)->isRect();
 return boolTojboolean(result);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t Parcel::dataAvail() const
{
 size_t result = dataSize() - dataPosition();
 if (result > INT32_MAX) {
        abort();
 }
 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ID3::Iterator::getstring(String8 *id, bool otherdata) const {
    id->setTo("");

 const uint8_t *frameData = mFrameData;
 if (frameData == NULL) {
 return;
 }

 uint8_t encoding = *frameData;

 if (mParent.mVersion == ID3_V1 || mParent.mVersion == ID3_V1_1) {
 if (mOffset == 126 || mOffset == 127) {
 char tmp[16];
            snprintf(tmp, sizeof(tmp), "%d", (int)*frameData);

            id->setTo(tmp);
 return;
 }

        id->setTo((const char*)frameData, mFrameSize);
 return;
 }

 if (mFrameSize < getHeaderLength() + 1) {
 return;
 }
 size_t n = mFrameSize - getHeaderLength() - 1;
 if (otherdata) {
 if (n < 5) {
 return;
 }
        frameData += 4;
 int32_t i = n - 4;
 while(--i >= 0 && *++frameData != 0) ;
 int skipped = (frameData - mFrameData);
 if (skipped >= (int)n) {
 return;
 }
        n -= skipped;
 }

 if (n <= 0) {
 return;
 }

 if (encoding == 0x00) {
        id->setTo((const char*)frameData + 1, n);
 } else if (encoding == 0x03) {
        id->setTo((const char *)(frameData + 1), n);
 } else if (encoding == 0x02) {
 int len = n / 2;
 const char16_t *framedata = (const char16_t *) (frameData + 1);
 char16_t *framedatacopy = NULL;
#if BYTE_ORDER == LITTLE_ENDIAN
 if (len > 0) {
            framedatacopy = new (std::nothrow) char16_t[len];
 if (framedatacopy == NULL) {
 return;
 }
 for (int i = 0; i < len; i++) {
                framedatacopy[i] = bswap_16(framedata[i]);
 }
            framedata = framedatacopy;
 }
#endif
        id->setTo(framedata, len);
 if (framedatacopy != NULL) {
 delete[] framedatacopy;
 }
 } else if (encoding == 0x01) {
 int len = n / 2;
 const char16_t *framedata = (const char16_t *) (frameData + 1);
 char16_t *framedatacopy = NULL;
 if (*framedata == 0xfffe) {
 if (len <= 1) {
 return; // nothing after the marker
 }
            framedatacopy = new (std::nothrow) char16_t[len];
 if (framedatacopy == NULL) {
 return;
 }
 for (int i = 0; i < len; i++) {
                framedatacopy[i] = bswap_16(framedata[i]);
 }
            framedata = framedatacopy;
            framedata++;
            len--;
 } else if (*framedata == 0xfeff) {
 if (len <= 1) {
 return; // nothing after the marker
 }
            framedata++;
            len--;
 }

 bool eightBit = true;
 for (int i = 0; i < len; i++) {
 if (framedata[i] > 0xff) {
                eightBit = false;
 break;
 }
 }
 if (eightBit) {
 char *frame8 = new (std::nothrow) char[len];
 if (frame8 != NULL) {
 for (int i = 0; i < len; i++) {
                    frame8[i] = framedata[i];
 }
                id->setTo(frame8, len);
 delete [] frame8;
 } else {
                id->setTo(framedata, len);
 }
 } else {
            id->setTo(framedata, len);
 }

 if (framedatacopy != NULL) {
 delete[] framedatacopy;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t HevcParameterSets::parseVps(const uint8_t* data, size_t size) {
 NALBitReader reader(data, size);
    reader.skipBits(4);
    reader.skipBits(1);
    reader.skipBits(1);
    reader.skipBits(6);
    reader.skipBits(1);
    reader.skipBits(16);

 if (reader.atLeastNumBitsLeft(96)) {
        mParams.add(kGeneralProfileSpace, reader.getBits(2));
        mParams.add(kGeneralTierFlag, reader.getBits(1));
        mParams.add(kGeneralProfileIdc, reader.getBits(5));
        mParams.add(kGeneralProfileCompatibilityFlags, reader.getBits(32));
        mParams.add(
                kGeneralConstraintIndicatorFlags,
 ((uint64_t)reader.getBits(16) << 32) | reader.getBits(32));
        mParams.add(kGeneralLevelIdc, reader.getBits(8));
 } else {
        reader.skipBits(96);
 }

 return reader.overRead() ? ERROR_MALFORMED : OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8 String8::formatV(const char* fmt, va_list args)
{
 String8 result;
    result.appendFormatV(fmt, args);
 return result;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: png_pass_col_shift(int pass)
{
 int x, y, base=(-1), inc=8;
 ++pass;
 for (x=0; x<8; ++x) for (y=0; y<8; ++y) if (adam7[y][x] == pass)
 {
 if (base == (-1))
         base = x;
 else if (base == x)
 {}
 else if (inc == x-base)
         base=x;
 else if (inc == 8)
         inc = x-base, base=x;
 else if (inc != x-base)
 return 0xff; /* error - more than one 'inc' value! */
 }

 if (base == (-1)) return 0xfe; /* error - no row in pass! */

 /* The shift is always 1, 2 or 3 - no pass has all the rows! */
 switch (inc)
 {
case 1: return 0; /* pass 7 has all the columns */
case 2: return 1;
case 4: return 2;
case 8: return 3;
default: break;
 }

 /* error - unrecognized 'inc' */
 return (inc << 8) + 0xfd;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8 CameraClient::getParameters() const {
 Mutex::Autolock lock(mLock);
 if (checkPidAndHardware() != NO_ERROR) return String8();

 String8 params(mHardware->getParameters().flatten());
    LOG1("getParameters (pid %d) (%s)", getCallingPid(), params.string());
 return params;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int connectSocketNative(JNIEnv *env, jobject object, jbyteArray address, jint type,
                                   jbyteArray uuidObj, jint channel, jint flag) {
    jbyte *addr = NULL, *uuid = NULL;
 int socket_fd;
 bt_status_t status;

 if (!sBluetoothSocketInterface) return -1;

    addr = env->GetByteArrayElements(address, NULL);
 if (!addr) {
        ALOGE("failed to get Bluetooth device address");
 goto Fail;
 }

 if(uuidObj != NULL) {
        uuid = env->GetByteArrayElements(uuidObj, NULL);
 if (!uuid) {
            ALOGE("failed to get uuid");
 goto Fail;
 }
 }

 if ( (status = sBluetoothSocketInterface->connect((bt_bdaddr_t *) addr, (btsock_type_t) type,
 (const uint8_t*) uuid, channel, &socket_fd, flag)) != BT_STATUS_SUCCESS) {
        ALOGE("Socket connection failed: %d", status);
 goto Fail;
 }


 if (socket_fd < 0) {
        ALOGE("Fail to create file descriptor on socket fd");
 goto Fail;
 }
    env->ReleaseByteArrayElements(address, addr, 0);
    env->ReleaseByteArrayElements(uuidObj, uuid, 0);
 return socket_fd;

Fail:
 if (addr) env->ReleaseByteArrayElements(address, addr, 0);
 if (uuid) env->ReleaseByteArrayElements(uuidObj, uuid, 0);

 return -1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const btrc_interface_t *btif_rc_get_interface(void)
{
    BTIF_TRACE_EVENT("%s", __FUNCTION__);
 return &bt_rc_interface;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool underQTMetaPath(const Vector<uint32_t> &path, int32_t depth) {
 return path.size() >= 2
 && path[0] == FOURCC('m', 'o', 'o', 'v')
 && path[1] == FOURCC('m', 'e', 't', 'a')
 && (depth == 2
 || (depth == 3
 && (path[2] == FOURCC('h', 'd', 'l', 'r')
 ||  path[2] == FOURCC('i', 'l', 's', 't')
 ||  path[2] == FOURCC('k', 'e', 'y', 's'))));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void RunTest() {
 {
      SCOPED_TRACE("DC_PRED");
 FillRandom();
 Predict(DC_PRED);
 CheckDCPrediction();
 }
 {
      SCOPED_TRACE("DC_PRED LEFT");
 FillRandom();
 SetLeftUnavailable();
 Predict(DC_PRED);
 CheckDCPrediction();
 }
 {
      SCOPED_TRACE("DC_PRED TOP");
 FillRandom();
 SetTopUnavailable();
 Predict(DC_PRED);
 CheckDCPrediction();
 }
 {
      SCOPED_TRACE("DC_PRED TOP_LEFT");
 FillRandom();
 SetTopLeftUnavailable();
 Predict(DC_PRED);
 CheckDCPrediction();
 }
 {
      SCOPED_TRACE("H_PRED");
 FillRandom();
 Predict(H_PRED);
 CheckHPrediction();
 }
 {
      SCOPED_TRACE("V_PRED");
 FillRandom();
 Predict(V_PRED);
 CheckVPrediction();
 }
 {
      SCOPED_TRACE("TM_PRED");
 FillRandom();
 Predict(TM_PRED);
 CheckTMPrediction();
 }
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static OMX_ERRORTYPE unsubscribe_to_events(int fd)
{
    OMX_ERRORTYPE eRet = OMX_ErrorNone;
 struct v4l2_event_subscription sub;
 int array_sz = sizeof(event_type)/sizeof(int);
 int i,rc;

 if (fd < 0) {
       DEBUG_PRINT_ERROR("Invalid input: %d", fd);
 return OMX_ErrorBadParameter;
 }

 for (i = 0; i < array_sz; ++i) {
        memset(&sub, 0, sizeof(sub));
        sub.type = event_type[i];
        rc = ioctl(fd, VIDIOC_UNSUBSCRIBE_EVENT, &sub);

 if (rc) {
           DEBUG_PRINT_ERROR("Failed to unsubscribe event: 0x%x", sub.type);
 break;
 }
 }

 return eRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_calibrate_gop()
{
 int ratio, sub_gop_size, gop_size, nPframes, nBframes, nLayers;
 int num_sub_gops_in_a_gop;
    nPframes = intra_period.num_pframes;
    nBframes = intra_period.num_bframes;
    nLayers = hier_layers.numlayers;

 if (!nPframes) {
        DEBUG_PRINT_ERROR("nPframes should be non-zero\n");
 return false;
 }

 if (nLayers > 1) { /*Multi-layer encoding*/
        sub_gop_size = 1 << (nLayers - 1);
 /* Actual GOP definition is nPframes + nBframes + 1 but for the sake of
         * below calculations we are ignoring +1 . Ignoring +1 in below
         * calculations is not a mistake but intentional.
         */
        gop_size = MAX(sub_gop_size, ROUND(nPframes + nBframes, sub_gop_size));
        num_sub_gops_in_a_gop = gop_size/sub_gop_size;
 if (nBframes) { /*Hier-B case*/
 /*
            * Frame Type--> I  B  B  B  P  B  B  B  P  I  B  B  P ...
            * Layer -->     0  2  1  2  0  2  1  2  0  0  2  1  2 ...
            * nPframes = 2, nBframes = 6, nLayers = 3
            *
            * Intention is to keep the intraperiod as close as possible to what is desired
            * by the client while adjusting nPframes and nBframes to meet other constraints.
            * eg1: Input by client: nPframes =  9, nBframes = 14, nLayers = 2
            *    Output of this fn: nPframes = 12, nBframes = 12, nLayers = 2
            *
            * eg2: Input by client: nPframes = 9, nBframes = 4, nLayers = 2
            *    Output of this fn: nPframes = 7, nBframes = 7, nLayers = 2
            */
            nPframes = num_sub_gops_in_a_gop;
            nBframes = gop_size - nPframes;
 } else { /*Hier-P case*/
 /*
            * Frame Type--> I  P  P  P  P  P  P  P  I  P  P  P  P ...
            * Layer-->      0  2  1  2  0  2  1  2  0  2  1  2  0 ...
            * nPframes =  7, nBframes = 0, nLayers = 3
            *
            * Intention is to keep the intraperiod as close as possible to what is desired
            * by the client while adjusting nPframes and nBframes to meet other constraints.
            * eg1: Input by client: nPframes = 9, nBframes = 0, nLayers = 3
            *    Output of this fn: nPframes = 7, nBframes = 0, nLayers = 3
            *
            * eg2: Input by client: nPframes = 10, nBframes = 0, nLayers = 3
            *     Output of this fn:nPframes = 12, nBframes = 0, nLayers = 3
            */
            nPframes = gop_size - 1;
 }
 } else { /*Single-layer encoding*/
 if (nBframes) {
 /* I  P  B  B  B  P  B  B  B   P   B   B   B   I   P   B   B...
            *  1  2  3  4  5  6  7  8  9  10  11  12  13  14  15  16  17...
            * nPframes = 3, nBframes = 9, nLayers = 0
            *
            * ratio is rounded,
            * eg1: nPframes = 9, nBframes = 11 => ratio = 1
            * eg2: nPframes = 9, nBframes = 16 => ratio = 2
            */
            ratio = MAX(1, MIN((nBframes + (nPframes >> 1))/nPframes, 3));
            nBframes = ratio * nPframes;
 }
 }
    DEBUG_PRINT_LOW("P/B Frames changed from: %ld/%ld to %d/%d",
        intra_period.num_pframes, intra_period.num_bframes, nPframes, nBframes);
    intra_period.num_pframes = nPframes;
    intra_period.num_bframes = nBframes;
    hier_layers.numlayers = nLayers;
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IV_API_CALL_STATUS_T impeg2d_api_check_struct_sanity(iv_obj_t *ps_handle,
 void *pv_api_ip,
 void *pv_api_op)
{
    WORD32  i4_cmd;
    UWORD32 *pu4_api_ip;
    UWORD32 *pu4_api_op;
    WORD32 i,j;

 if(NULL == pv_api_op)
 return(IV_FAIL);

 if(NULL == pv_api_ip)
 return(IV_FAIL);

    pu4_api_ip  = (UWORD32 *)pv_api_ip;
    pu4_api_op  = (UWORD32 *)pv_api_op;
    i4_cmd = (IVD_API_COMMAND_TYPE_T)*(pu4_api_ip + 1);

 /* error checks on handle */
 switch(i4_cmd)
 {
 case IV_CMD_GET_NUM_MEM_REC:
 case IV_CMD_FILL_NUM_MEM_REC:
 break;
 case IV_CMD_INIT:
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 break;
 case IVD_CMD_GET_DISPLAY_FRAME:
 case IVD_CMD_VIDEO_DECODE:
 case IV_CMD_RETRIEVE_MEMREC:
 case IVD_CMD_SET_DISPLAY_FRAME:
 case IVD_CMD_REL_DISPLAY_FRAME:
 case IVD_CMD_VIDEO_CTL:
 {
 if(ps_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->u4_size != sizeof(iv_obj_t))
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_HANDLE_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_handle->pv_fxns != impeg2d_api_function)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }

 if(ps_handle->pv_codec_handle == NULL)
 {
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_HANDLE_NULL;
 return IV_FAIL;
 }
 }
 break;
 default:
 *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_INVALID_API_CMD;
 return IV_FAIL;
 }

 switch(i4_cmd)
 {
 case IV_CMD_GET_NUM_MEM_REC:
 {
 impeg2d_num_mem_rec_ip_t *ps_ip = (impeg2d_num_mem_rec_ip_t *)pv_api_ip;
 impeg2d_num_mem_rec_op_t *ps_op = (impeg2d_num_mem_rec_op_t *)pv_api_op;
                ps_op->s_ivd_num_mem_rec_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_num_mem_rec_ip_t.u4_size != sizeof(impeg2d_num_mem_rec_ip_t))
 {
                    ps_op->s_ivd_num_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_num_mem_rec_op_t.u4_size != sizeof(impeg2d_num_mem_rec_op_t))
 {
                    ps_op->s_ivd_num_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_num_mem_rec_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }
 }
 break;
 case IV_CMD_FILL_NUM_MEM_REC:
 {
 impeg2d_fill_mem_rec_ip_t *ps_ip = (impeg2d_fill_mem_rec_ip_t *)pv_api_ip;
 impeg2d_fill_mem_rec_op_t *ps_op = (impeg2d_fill_mem_rec_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;

                ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_fill_mem_rec_ip_t.u4_size != sizeof(impeg2d_fill_mem_rec_ip_t))
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_fill_mem_rec_op_t.u4_size != sizeof(impeg2d_fill_mem_rec_op_t))
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd < MIN_WIDTH)
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_REQUESTED_WIDTH_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd > MAX_WIDTH)
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_REQUESTED_WIDTH_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht < MIN_HEIGHT)
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_REQUESTED_HEIGHT_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht > MAX_HEIGHT)
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_REQUESTED_HEIGHT_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(NULL == ps_ip->s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location)
 {
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_NUM_REC_NOT_SUFFICIENT;
 return(IV_FAIL);
 }

 /* check memrecords sizes are correct */
                ps_mem_rec  = ps_ip->s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location;
 for(i=0;i<NUM_MEM_RECORDS;i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                        ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_fill_mem_rec_op_t.u4_error_code |= IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 }
 break;

 case IV_CMD_INIT:
 {
 impeg2d_init_ip_t *ps_ip = (impeg2d_init_ip_t *)pv_api_ip;
 impeg2d_init_op_t *ps_op = (impeg2d_init_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;
                UWORD32 u4_tot_num_mem_recs;

                ps_op->s_ivd_init_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_init_ip_t.u4_size != sizeof(impeg2d_init_ip_t))
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_init_op_t.u4_size != sizeof(impeg2d_init_op_t))
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

                u4_tot_num_mem_recs = NUM_MEM_RECORDS;




 if(ps_ip->s_ivd_init_ip_t.u4_num_mem_rec > u4_tot_num_mem_recs)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_NOT_SUFFICIENT;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_frm_max_wd < MIN_WIDTH)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_WIDTH_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_frm_max_wd > MAX_WIDTH)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_WIDTH_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_frm_max_ht < MIN_HEIGHT)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_HEIGHT_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_init_ip_t.u4_frm_max_ht > MAX_HEIGHT)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_HEIGHT_NOT_SUPPPORTED;
 return(IV_FAIL);
 }

 if(NULL == ps_ip->s_ivd_init_ip_t.pv_mem_rec_location)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_NUM_REC_NOT_SUFFICIENT;
 return(IV_FAIL);
 }

 if((ps_ip->s_ivd_init_ip_t.e_output_format != IV_YUV_420P) &&
 (ps_ip->s_ivd_init_ip_t.e_output_format != IV_YUV_422ILE)&&(ps_ip->s_ivd_init_ip_t.e_output_format != IV_YUV_420SP_UV)&&(ps_ip->s_ivd_init_ip_t.e_output_format != IV_YUV_420SP_VU))
 {
                    ps_op->s_ivd_init_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_COL_FMT_NOT_SUPPORTED;
 return(IV_FAIL);
 }

 /* verify number of mem records */
 if(ps_ip->s_ivd_init_ip_t.u4_num_mem_rec < NUM_MEM_RECORDS)
 {
                    ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_NOT_SUFFICIENT;
 return IV_FAIL;
 }

                ps_mem_rec  = ps_ip->s_ivd_init_ip_t.pv_mem_rec_location;
 /* verify wether first memrecord is handle or not */
 /*
                if(ps_mem_rec->pv_base != ps_handle)
                {
                    ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INVALID_HANDLE;
                    return IV_FAIL;
                }
*/
 /* check memrecords sizes are correct */
 for(i=0;i < (WORD32)ps_ip->s_ivd_init_ip_t.u4_num_mem_rec ; i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                        ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_init_op_t.u4_error_code |= IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }

 /* verify memtabs for overlapping regions */
 {
                    UWORD8 *pau1_start[NUM_MEM_RECORDS];
                    UWORD8 *pau1_end[NUM_MEM_RECORDS];


                    pau1_start[0] = (UWORD8 *)(ps_mem_rec[0].pv_base);
                    pau1_end[0] = (UWORD8 *)(ps_mem_rec[0].pv_base) + ps_mem_rec[0].u4_mem_size - 1;
 for(i = 1; i < (WORD32)ps_ip->s_ivd_init_ip_t.u4_num_mem_rec; i++)
 {
 /* This array is populated to check memtab overlapp */
                        pau1_start[i] = (UWORD8 *)(ps_mem_rec[i].pv_base);
                        pau1_end[i] = (UWORD8 *)(ps_mem_rec[i].pv_base) + ps_mem_rec[i].u4_mem_size - 1;

 for(j = 0; j < i; j++)
 {
 if((pau1_start[i] >= pau1_start[j]) && (pau1_start[i] <= pau1_end[j]))
 {
                                ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
 return IV_FAIL;
 }

 if((pau1_end[i] >= pau1_start[j]) && (pau1_end[i] <= pau1_end[j]))
 {
                                ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
 return IV_FAIL;
 }

 if((pau1_start[i] < pau1_start[j]) && (pau1_end[i] > pau1_end[j]))
 {
                                ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_OVERLAP_ERR;
 return IV_FAIL;
 }
 }
 }
 }




 {
 iv_mem_rec_t    as_mem_rec_ittiam_api[NUM_MEM_RECORDS];

 impeg2d_fill_mem_rec_ip_t s_fill_mem_rec_ip;
 impeg2d_fill_mem_rec_op_t s_fill_mem_rec_op;
                    IV_API_CALL_STATUS_T e_status;
                    WORD32 i4_num_memrec;
 {

 iv_num_mem_rec_ip_t s_no_of_mem_rec_query_ip;
 iv_num_mem_rec_op_t s_no_of_mem_rec_query_op;


                        s_no_of_mem_rec_query_ip.u4_size = sizeof(iv_num_mem_rec_ip_t);
                        s_no_of_mem_rec_query_op.u4_size = sizeof(iv_num_mem_rec_op_t);

                        s_no_of_mem_rec_query_ip.e_cmd   = IV_CMD_GET_NUM_MEM_REC;
                        impeg2d_api_function(NULL,
 (void *)&s_no_of_mem_rec_query_ip,
 (void *)&s_no_of_mem_rec_query_op);

                        i4_num_memrec  = s_no_of_mem_rec_query_op.u4_num_mem_rec;



 }


 /* initialize mem records array with sizes */
 for(i = 0; i < i4_num_memrec; i++)
 {
                        as_mem_rec_ittiam_api[i].u4_size = sizeof(iv_mem_rec_t);
 }

                    s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_size                   = sizeof(impeg2d_fill_mem_rec_ip_t);
                    s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.e_cmd                     = IV_CMD_FILL_NUM_MEM_REC;
                    s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_wd             = ps_ip->s_ivd_init_ip_t.u4_frm_max_wd;
                    s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.u4_max_frm_ht             = ps_ip->s_ivd_init_ip_t.u4_frm_max_ht;
                    s_fill_mem_rec_ip.s_ivd_fill_mem_rec_ip_t.pv_mem_rec_location       = as_mem_rec_ittiam_api;
                    s_fill_mem_rec_ip.u4_share_disp_buf                                 = ps_ip->u4_share_disp_buf;
                    s_fill_mem_rec_ip.e_output_format                                   = ps_ip->s_ivd_init_ip_t.e_output_format;
                    s_fill_mem_rec_op.s_ivd_fill_mem_rec_op_t.u4_size                   = sizeof(impeg2d_fill_mem_rec_op_t);


                    e_status = impeg2d_api_function(NULL,
 (void *)&s_fill_mem_rec_ip,
 (void *)&s_fill_mem_rec_op);
 if(IV_FAIL == e_status)
 {
                        ps_op->s_ivd_init_op_t.u4_error_code = s_fill_mem_rec_op.s_ivd_fill_mem_rec_op_t.u4_error_code;
 return(IV_FAIL);
 }



 for(i = 0; i < i4_num_memrec; i ++)
 {
 if(ps_mem_rec[i].pv_base == NULL)
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_BASE_NULL;
 return IV_FAIL;
 }
#ifdef CHECK_ALIGN

 if((UWORD32)(ps_mem_rec[i].pv_base) & (ps_mem_rec[i].u4_mem_alignment - 1))
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_ALIGNMENT_ERR;
 return IV_FAIL;
 }
#endif //CHECK_ALIGN
 if(ps_mem_rec[i].u4_mem_alignment != as_mem_rec_ittiam_api[i].u4_mem_alignment)
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_ALIGNMENT_ERR;
 return IV_FAIL;
 }

 if(ps_mem_rec[i].u4_mem_size < as_mem_rec_ittiam_api[i].u4_mem_size)
 {
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_INSUFFICIENT_SIZE;
 return IV_FAIL;
 }

 if(ps_mem_rec[i].e_mem_type != as_mem_rec_ittiam_api[i].e_mem_type)
 {
 if (IV_EXTERNAL_CACHEABLE_SCRATCH_MEM == as_mem_rec_ittiam_api[i].e_mem_type)
 {
 if (IV_EXTERNAL_CACHEABLE_PERSISTENT_MEM == ps_mem_rec[i].e_mem_type)
 {
 continue;
 }
 }
                            ps_op->s_ivd_init_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_init_op_t.u4_error_code |= IVD_INIT_DEC_MEM_REC_INCORRECT_TYPE;
 return IV_FAIL;
 }
 }
 }


 }
 break;

 case IVD_CMD_GET_DISPLAY_FRAME:
 {
 impeg2d_get_display_frame_ip_t *ps_ip = (impeg2d_get_display_frame_ip_t *)pv_api_ip;
 impeg2d_get_display_frame_op_t *ps_op = (impeg2d_get_display_frame_op_t *)pv_api_op;

                ps_op->s_ivd_get_display_frame_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_get_display_frame_ip_t.u4_size != sizeof(impeg2d_get_display_frame_ip_t))
 {
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_get_display_frame_op_t.u4_size != sizeof(impeg2d_get_display_frame_op_t))
 {
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_get_display_frame_ip_t.s_out_buffer.u4_num_bufs == 0)
 {
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0; i< (WORD32)ps_ip->s_ivd_get_display_frame_ip_t.s_out_buffer.u4_num_bufs;i++)
 {
 if(ps_ip->s_ivd_get_display_frame_ip_t.s_out_buffer.pu1_bufs[i] == NULL)
 {
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_ip->s_ivd_get_display_frame_ip_t.s_out_buffer.u4_min_out_buf_size[i] == 0)
 {
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 /*
                    if(ps_ip->s_ivd_get_display_frame_ip_t.s_out_buffer.u4_min_out_buf_size[i] == 0)
                    {
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_get_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
                        return IV_FAIL;
                    }
                    */
 }
 }
 break;
 case IVD_CMD_REL_DISPLAY_FRAME:
 {
 impeg2d_rel_display_frame_ip_t *ps_ip = (impeg2d_rel_display_frame_ip_t *)pv_api_ip;
 impeg2d_rel_display_frame_op_t *ps_op = (impeg2d_rel_display_frame_op_t *)pv_api_op;

                ps_op->s_ivd_rel_display_frame_op_t.u4_error_code = 0;

 if ((ps_ip->s_ivd_rel_display_frame_ip_t.u4_size != sizeof(impeg2d_rel_display_frame_ip_t))
 && (ps_ip->s_ivd_rel_display_frame_ip_t.u4_size != sizeof(ivd_rel_display_frame_ip_t)))
 {
                    ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if((ps_op->s_ivd_rel_display_frame_op_t.u4_size != sizeof(impeg2d_rel_display_frame_op_t)) &&
 (ps_op->s_ivd_rel_display_frame_op_t.u4_size != sizeof(ivd_rel_display_frame_op_t)))
 {
                    ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_rel_display_frame_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 }
 break;


 case IVD_CMD_SET_DISPLAY_FRAME:
 {
 impeg2d_set_display_frame_ip_t *ps_ip = (impeg2d_set_display_frame_ip_t *)pv_api_ip;
 impeg2d_set_display_frame_op_t *ps_op = (impeg2d_set_display_frame_op_t *)pv_api_op;
                UWORD32 j, i;

                ps_op->s_ivd_set_display_frame_op_t.u4_error_code = 0;

 if ((ps_ip->s_ivd_set_display_frame_ip_t.u4_size != sizeof(impeg2d_set_display_frame_ip_t))
 && (ps_ip->s_ivd_set_display_frame_ip_t.u4_size != sizeof(ivd_set_display_frame_ip_t)))
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if((ps_op->s_ivd_set_display_frame_op_t.u4_size != sizeof(impeg2d_set_display_frame_op_t)) &&
 (ps_op->s_ivd_set_display_frame_op_t.u4_size != sizeof(ivd_set_display_frame_op_t)))
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs == 0)
 {
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(j = 0; j < ps_ip->s_ivd_set_display_frame_ip_t.num_disp_bufs; j++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs == 0)
 {
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i=0;i< ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_num_bufs;i++)
 {
 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].pu1_bufs[i] == NULL)
 {
                            ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_ip->s_ivd_set_display_frame_ip_t.s_disp_buffer[j].u4_min_out_buf_size[i] == 0)
 {
                            ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->s_ivd_set_display_frame_op_t.u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_DECODE:
 {
 impeg2d_video_decode_ip_t *ps_ip = (impeg2d_video_decode_ip_t *)pv_api_ip;
 impeg2d_video_decode_op_t *ps_op = (impeg2d_video_decode_op_t *)pv_api_op;

                ps_op->s_ivd_video_decode_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_video_decode_ip_t.u4_size != sizeof(impeg2d_video_decode_ip_t))
 {
                    ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_video_decode_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_video_decode_op_t.u4_size != sizeof(impeg2d_video_decode_op_t))
 {
                    ps_op->s_ivd_video_decode_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_video_decode_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 }
 break;

 case IV_CMD_RETRIEVE_MEMREC:
 {
 impeg2d_retrieve_mem_rec_ip_t *ps_ip = (impeg2d_retrieve_mem_rec_ip_t *)pv_api_ip;
 impeg2d_retrieve_mem_rec_op_t *ps_op = (impeg2d_retrieve_mem_rec_op_t *)pv_api_op;
 iv_mem_rec_t *ps_mem_rec;

                ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_retrieve_mem_rec_ip_t.u4_size != sizeof(impeg2d_retrieve_mem_rec_ip_t))
 {
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

 if(ps_op->s_ivd_retrieve_mem_rec_op_t.u4_size != sizeof(impeg2d_retrieve_mem_rec_op_t))
 {
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                    ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return(IV_FAIL);
 }

                ps_mem_rec  = ps_ip->s_ivd_retrieve_mem_rec_ip_t.pv_mem_rec_location;
 /* check memrecords sizes are correct */
 for(i=0;i < NUM_MEM_RECORDS ; i++)
 {
 if(ps_mem_rec[i].u4_size != sizeof(iv_mem_rec_t))
 {
                        ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                        ps_op->s_ivd_retrieve_mem_rec_op_t.u4_error_code |= IVD_MEM_REC_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 }
 break;

 case IVD_CMD_VIDEO_CTL:
 {
                UWORD32 *pu4_ptr_cmd;
                UWORD32 u4_sub_command;

                pu4_ptr_cmd = (UWORD32 *)pv_api_ip;
                pu4_ptr_cmd += 2;
                u4_sub_command = *pu4_ptr_cmd;

 switch(u4_sub_command)
 {
 case IVD_CMD_CTL_SETPARAMS:
 {
 impeg2d_ctl_set_config_ip_t *ps_ip;
 impeg2d_ctl_set_config_op_t *ps_op;
                            ps_ip = (impeg2d_ctl_set_config_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_set_config_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_set_config_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_ctl_set_config_ip_t.u4_size != sizeof(impeg2d_ctl_set_config_ip_t))
 {
                                ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 case IVD_CMD_CTL_SETDEFAULT:
 {
 impeg2d_ctl_set_config_op_t *ps_op;
                            ps_op = (impeg2d_ctl_set_config_op_t *)pv_api_op;
                            ps_op->s_ivd_ctl_set_config_op_t.u4_error_code   = 0;

 if(ps_op->s_ivd_ctl_set_config_op_t.u4_size != sizeof(impeg2d_ctl_set_config_op_t))
 {
                                ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_set_config_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETPARAMS:
 {
 impeg2d_ctl_getstatus_ip_t *ps_ip;
 impeg2d_ctl_getstatus_op_t *ps_op;

                            ps_ip = (impeg2d_ctl_getstatus_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_getstatus_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code   = 0;

 if(ps_ip->s_ivd_ctl_getstatus_ip_t.u4_size != sizeof(impeg2d_ctl_getstatus_ip_t))
 {
                                ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getstatus_op_t.u4_size != sizeof(impeg2d_ctl_getstatus_op_t))
 {
                                ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getstatus_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETBUFINFO:
 {
 impeg2d_ctl_getbufinfo_ip_t *ps_ip;
 impeg2d_ctl_getbufinfo_op_t *ps_op;
                            ps_ip = (impeg2d_ctl_getbufinfo_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_getbufinfo_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code  = 0;

 if(ps_ip->s_ivd_ctl_getbufinfo_ip_t.u4_size != sizeof(impeg2d_ctl_getbufinfo_ip_t))
 {
                                ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getbufinfo_op_t.u4_size != sizeof(impeg2d_ctl_getbufinfo_op_t))
 {
                                ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getbufinfo_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_GETVERSION:
 {
 impeg2d_ctl_getversioninfo_ip_t *ps_ip;
 impeg2d_ctl_getversioninfo_op_t *ps_op;
                            ps_ip = (impeg2d_ctl_getversioninfo_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_getversioninfo_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code  = 0;

 if(ps_ip->s_ivd_ctl_getversioninfo_ip_t.u4_size != sizeof(impeg2d_ctl_getversioninfo_ip_t))
 {
                                ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_getversioninfo_op_t.u4_size != sizeof(impeg2d_ctl_getversioninfo_op_t))
 {
                                ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_getversioninfo_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_FLUSH:
 {
 impeg2d_ctl_flush_ip_t *ps_ip;
 impeg2d_ctl_flush_op_t *ps_op;
                            ps_ip = (impeg2d_ctl_flush_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_flush_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_flush_op_t.u4_error_code = 0;

 if(ps_ip->s_ivd_ctl_flush_ip_t.u4_size != sizeof(impeg2d_ctl_flush_ip_t))
 {
                                ps_op->s_ivd_ctl_flush_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_flush_op_t.u4_size != sizeof(impeg2d_ctl_flush_op_t))
 {
                                ps_op->s_ivd_ctl_flush_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_flush_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IVD_CMD_CTL_RESET:
 {
 impeg2d_ctl_reset_ip_t *ps_ip;
 impeg2d_ctl_reset_op_t *ps_op;
                            ps_ip = (impeg2d_ctl_reset_ip_t *)pv_api_ip;
                            ps_op = (impeg2d_ctl_reset_op_t *)pv_api_op;

                            ps_op->s_ivd_ctl_reset_op_t.u4_error_code    = 0;

 if(ps_ip->s_ivd_ctl_reset_ip_t.u4_size != sizeof(impeg2d_ctl_reset_ip_t))
 {
                                ps_op->s_ivd_ctl_reset_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 if(ps_op->s_ivd_ctl_reset_op_t.u4_size != sizeof(impeg2d_ctl_reset_op_t))
 {
                                ps_op->s_ivd_ctl_reset_op_t.u4_error_code  |= 1 << IVD_UNSUPPORTEDPARAM;
                                ps_op->s_ivd_ctl_reset_op_t.u4_error_code |= IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }
 }
 break;

 case IMPEG2D_CMD_CTL_GET_BUFFER_DIMENSIONS:
 {
 impeg2d_ctl_get_frame_dimensions_ip_t *ps_ip;
 impeg2d_ctl_get_frame_dimensions_op_t *ps_op;

                        ps_ip =
 (impeg2d_ctl_get_frame_dimensions_ip_t *)pv_api_ip;
                        ps_op =
 (impeg2d_ctl_get_frame_dimensions_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(impeg2d_ctl_get_frame_dimensions_ip_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(impeg2d_ctl_get_frame_dimensions_op_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 case IMPEG2D_CMD_CTL_GET_SEQ_INFO:
 {
 impeg2d_ctl_get_seq_info_ip_t *ps_ip;
 impeg2d_ctl_get_seq_info_op_t *ps_op;

                        ps_ip =
 (impeg2d_ctl_get_seq_info_ip_t *)pv_api_ip;
                        ps_op =
 (impeg2d_ctl_get_seq_info_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(impeg2d_ctl_get_seq_info_ip_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(impeg2d_ctl_get_seq_info_op_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 case IMPEG2D_CMD_CTL_SET_NUM_CORES:
 {
 impeg2d_ctl_set_num_cores_ip_t *ps_ip;
 impeg2d_ctl_set_num_cores_op_t *ps_op;

                        ps_ip = (impeg2d_ctl_set_num_cores_ip_t *)pv_api_ip;
                        ps_op = (impeg2d_ctl_set_num_cores_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(impeg2d_ctl_set_num_cores_ip_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(impeg2d_ctl_set_num_cores_op_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

#ifdef MULTICORE
 if((ps_ip->u4_num_cores < 1) || (ps_ip->u4_num_cores > MAX_THREADS))
#else
 if(ps_ip->u4_num_cores != 1)
#endif
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
 return IV_FAIL;
 }
 break;
 }
 case IMPEG2D_CMD_CTL_SET_PROCESSOR:
 {
 impeg2d_ctl_set_processor_ip_t *ps_ip;
 impeg2d_ctl_set_processor_op_t *ps_op;

                        ps_ip = (impeg2d_ctl_set_processor_ip_t *)pv_api_ip;
                        ps_op = (impeg2d_ctl_set_processor_op_t *)pv_api_op;

 if(ps_ip->u4_size
 != sizeof(impeg2d_ctl_set_processor_ip_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_IP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 if(ps_op->u4_size
 != sizeof(impeg2d_ctl_set_processor_op_t))
 {
                            ps_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                            ps_op->u4_error_code |=
                                            IVD_OP_API_STRUCT_SIZE_INCORRECT;
 return IV_FAIL;
 }

 break;
 }
 default:
 break;

 }
 }
 break;

 default:
 { *(pu4_api_op + 1) |= 1 << IVD_UNSUPPORTEDPARAM;
 *(pu4_api_op + 1) |= IVD_UNSUPPORTED_API_CMD;
 return IV_FAIL;
 }


 }

 return IV_SUCCESS;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: xmlParse3986Host(xmlURIPtr uri, const char **str)
{
 const char *cur = *str;
 const char *host;

    host = cur;
 /*
     * IPv6 and future adressing scheme are enclosed between brackets
     */
 if (*cur == '[') {
        cur++;
 while ((*cur != ']') && (*cur != 0))
	    cur++;
 if (*cur != ']')
 return(1);
	cur++;
 goto found;
 }
 /*
     * try to parse an IPv4
     */
 if (ISA_DIGIT(cur)) {
 if (xmlParse3986DecOctet(&cur) != 0)
 goto not_ipv4;
 if (*cur != '.')
 goto not_ipv4;
	cur++;
 if (xmlParse3986DecOctet(&cur) != 0)
 goto not_ipv4;
 if (*cur != '.')
 goto not_ipv4;
 if (xmlParse3986DecOctet(&cur) != 0)
 goto not_ipv4;
 if (*cur != '.')
 goto not_ipv4;
 if (xmlParse3986DecOctet(&cur) != 0)
 goto not_ipv4;
 goto found;
not_ipv4:
        cur = *str;
 }
 /*
     * then this should be a hostname which can be empty
     */
 while (ISA_UNRESERVED(cur) || ISA_PCT_ENCODED(cur) || ISA_SUB_DELIM(cur))
        NEXT(cur);
found:
 if (uri != NULL) {
 if (uri->authority != NULL) xmlFree(uri->authority);
	uri->authority = NULL;
 if (uri->server != NULL) xmlFree(uri->server);
 if (cur != host) {
 if (uri->cleanup & 2)
		uri->server = STRNDUP(host, cur - host);
 else
		uri->server = xmlURIUnescapeString(host, cur - host, NULL);
 } else
	    uri->server = NULL;
 }
 *str = cur;
 return(0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: EBMLHeader::EBMLHeader() :
    m_docType(NULL)
{
    Init();
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_hl_display_bt_bda(bt_bdaddr_t *bd_addr){
    BTIF_TRACE_DEBUG("DB [%02x:%02x:%02x:%02x:%02x:%02x]",
                      bd_addr->address[0],   bd_addr->address[1], bd_addr->address[2],
                      bd_addr->address[3],  bd_addr->address[4],   bd_addr->address[5]);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void print_type(char *type, struct pid_info_t* info)
{
 static ssize_t link_dest_size;
 static char link_dest[PATH_MAX];

    strlcat(info->path, type, sizeof(info->path));
 if ((link_dest_size = readlink(info->path, link_dest, sizeof(link_dest)-1)) < 0) {
 if (errno == ENOENT)
 goto out;

        snprintf(link_dest, sizeof(link_dest), "%s (readlink: %s)", info->path, strerror(errno));
 } else {
        link_dest[link_dest_size] = '\0';
 }

 if (!strcmp(link_dest, "/"))
 goto out;

    printf("%-9s %5d %10s %4s %9s %18s %9s %10s %s\n",
            info->cmdline, info->pid, info->user, type,
 "???", "???", "???", "???", link_dest);

out:
    info->path[info->parent_length] = '\0';
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_report_audio_state(btav_audio_state_t state,
 RawAddress* bd_addr) {
 if (bt_av_sink_callbacks != NULL) {
    HAL_CBACK(bt_av_sink_callbacks, audio_state_cb, state, bd_addr);
 } else if (bt_av_src_callbacks != NULL) {
    HAL_CBACK(bt_av_src_callbacks, audio_state_cb, state, bd_addr);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool BlockEntry::EOS() const { return (GetKind() == kBlockEOS); }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void parseVorbisComment(
 const sp<MetaData> &fileMeta, const char *comment, size_t commentLength)
{
 struct {
 const char *const mTag;
 uint32_t mKey;
 } kMap[] = {
 { "TITLE", kKeyTitle },
 { "ARTIST", kKeyArtist },
 { "ALBUMARTIST", kKeyAlbumArtist },
 { "ALBUM ARTIST", kKeyAlbumArtist },
 { "COMPILATION", kKeyCompilation },
 { "ALBUM", kKeyAlbum },
 { "COMPOSER", kKeyComposer },
 { "GENRE", kKeyGenre },
 { "AUTHOR", kKeyAuthor },
 { "TRACKNUMBER", kKeyCDTrackNumber },
 { "DISCNUMBER", kKeyDiscNumber },
 { "DATE", kKeyDate },
 { "YEAR", kKeyYear },
 { "LYRICIST", kKeyWriter },
 { "METADATA_BLOCK_PICTURE", kKeyAlbumArt },
 { "ANDROID_LOOP", kKeyAutoLoop },
 };

 for (size_t j = 0; j < sizeof(kMap) / sizeof(kMap[0]); ++j) {
 size_t tagLen = strlen(kMap[j].mTag);
 if (!strncasecmp(kMap[j].mTag, comment, tagLen)
 && comment[tagLen] == '=') {
 if (kMap[j].mKey == kKeyAlbumArt) {
                    extractAlbumArt(
                            fileMeta,
 &comment[tagLen + 1],
                            commentLength - tagLen - 1);
 } else if (kMap[j].mKey == kKeyAutoLoop) {
 if (!strcasecmp(&comment[tagLen + 1], "true")) {
                        fileMeta->setInt32(kKeyAutoLoop, true);
 }
 } else {
                    fileMeta->setCString(kMap[j].mKey, &comment[tagLen + 1]);
 }
 }
 }

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bt_status_t connect( bt_bdaddr_t *bd_addr)
{
 if(btif_hh_cb.status != BTIF_HH_DEV_CONNECTING)
 {
        btif_transfer_context(btif_hh_handle_evt, BTIF_HH_CONNECT_REQ_EVT,
 (char*)bd_addr, sizeof(bt_bdaddr_t), NULL);
 return BT_STATUS_SUCCESS;
 }
 else
 return BT_STATUS_BUSY;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SoftAACEncoder::SoftAACEncoder(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SimpleSoftOMXComponent(name, callbacks, appData, component),
      mEncoderHandle(NULL),
      mApiHandle(NULL),
      mMemOperator(NULL),
      mNumChannels(1),
      mSampleRate(44100),
      mBitRate(0),
      mSentCodecSpecificData(false),
      mInputSize(0),
      mInputFrame(NULL),
      mInputTimeUs(-1ll),
      mSawInputEOS(false),
      mSignalledError(false) {
    initPorts();
    CHECK_EQ(initEncoder(), (status_t)OK);

    setAudioParams();

 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaHTTP::reconnectAtOffset(off64_t offset) {
 return connect(mLastURI.c_str(), &mLastHeaders, offset);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t getExtensionIndex(
            node_id node,
 const char *parameter_name,
            OMX_INDEXTYPE *index) {
 Parcel data, reply;
        data.writeInterfaceToken(IOMX::getInterfaceDescriptor());
        data.writeInt32((int32_t)node);
        data.writeCString(parameter_name);

        remote()->transact(GET_EXTENSION_INDEX, data, &reply);

 status_t err = reply.readInt32();
 if (err == OK) {
 *index = static_cast<OMX_INDEXTYPE>(reply.readInt32());
 } else {
 *index = OMX_IndexComponentStartUnused;
 }

 return err;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_hl_send_setup_connecting_cb(UINT8 app_idx, UINT8 mcl_idx){
 btif_hl_pending_chan_cb_t *p_pcb = BTIF_HL_GET_PCB_PTR(app_idx, mcl_idx);
 bt_bdaddr_t                 bd_addr;
 int                         app_id = (int) btif_hl_get_app_id(p_pcb->channel_id);

    btif_hl_copy_bda(&bd_addr, p_pcb->bd_addr);

 if (p_pcb->in_use && p_pcb->cb_state == BTIF_HL_CHAN_CB_STATE_CONNECTING_PENDING)
 {
        BTIF_TRACE_DEBUG("%s",__FUNCTION__);
        BTIF_TRACE_DEBUG("call channel state callback  channel_id=0x%08x mdep_cfg_idx=%d state=%d fd=%d",p_pcb->channel_id,
                          p_pcb->mdep_cfg_idx, BTHL_CONN_STATE_CONNECTING, 0);
        btif_hl_display_bt_bda(&bd_addr);

        BTIF_HL_CALL_CBACK(bt_hl_callbacks, channel_state_cb, app_id,
 &bd_addr, p_pcb->mdep_cfg_idx,
                           p_pcb->channel_id, BTHL_CONN_STATE_CONNECTING, 0 );
        btif_hl_set_chan_cb_state(app_idx, mcl_idx, BTIF_HL_CHAN_CB_STATE_CONNECTED_PENDING);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_sev(UWORD32 *pu4_bitstrm_ofst, UWORD32 *pu4_bitstrm_buf)
{
    UWORD32 u4_bitstream_offset = *pu4_bitstrm_ofst;
    UWORD32 u4_word, u4_ldz, u4_abs_val;

 /***************************************************************/
 /* Find leading zeros in next 32 bits                          */
 /***************************************************************/
    NEXTBITS_32(u4_word, u4_bitstream_offset, pu4_bitstrm_buf);
    u4_ldz = CLZ(u4_word);

 /* Flush the ps_bitstrm */
    u4_bitstream_offset += (u4_ldz + 1);

 /* Read the suffix from the ps_bitstrm */
    u4_word = 0;
 if(u4_ldz)
        GETBITS(u4_word, u4_bitstream_offset, pu4_bitstrm_buf, u4_ldz);

 *pu4_bitstrm_ofst = u4_bitstream_offset;
    u4_abs_val = ((1 << u4_ldz) + u4_word) >> 1;

 if(u4_word & 0x1)
 return (-(WORD32)u4_abs_val);
 else
 return (u4_abs_val);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<NativeHandle> BufferQueueConsumer::getSidebandStream() const {
 return mCore->mSidebandStream;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Segment::PreloadCluster(Cluster* pCluster, ptrdiff_t idx)
{
    assert(pCluster);
    assert(pCluster->m_index < 0);
    assert(idx >= m_clusterCount);
    const long count = m_clusterCount + m_clusterPreloadCount;
    long& size = m_clusterSize;
    assert(size >= count);
    if (count >= size)
    {
        const long n = (size <= 0) ? 2048 : 2*size;
        Cluster** const qq = new Cluster*[n];
        Cluster** q = qq;
        Cluster** p = m_clusters;
        Cluster** const pp = p + count;
        while (p != pp)
            *q++ = *p++;
        delete[] m_clusters;
        m_clusters = qq;
        size = n;
    }
     assert(m_clusters);
 
    Cluster** const p = m_clusters + idx;
 
    Cluster** q = m_clusters + count;
    assert(q >= p);
     assert(q < (m_clusters + size));
 
    while (q > p)
    {
        Cluster** const qq = q - 1;
        assert((*qq)->m_index < 0);
 
        *q = *qq;
        q = qq;
     }
 
    m_clusters[idx] = pCluster;
    ++m_clusterPreloadCount;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  virtual void EndPassHook(void) {
 for (int layer = 0; layer < static_cast<int>(cfg_.ts_number_layers);
 ++layer) {
      duration_ = (last_pts_ + 1) * timebase_;
 if (bits_total_[layer]) {
        effective_datarate_[layer] = (bits_total_[layer] / 1000.0) / duration_;
 }
 }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uarb_mult32(uarb acc, int a_digits, uarb num, int n_digits, png_uint_32 val)
 /* calculate acc += num * val, 'val' may be any 32-bit value, 'acc' and 'num'
    * may be any value, returns the number of digits in 'acc'.
    */
{
 if (n_digits > 0 && val > 0)
 {
      a_digits = uarb_mult_digit(acc, a_digits, num, n_digits,
 (png_uint_16)(val & 0xffff));

 /* Because n_digits and val are >0 the following must be true: */
      assert(a_digits > 0);

      val >>= 16;
 if (val > 0)
         a_digits = uarb_mult_digit(acc+1, a_digits-1, num, n_digits,
 (png_uint_16)val) + 1;
 }

 return a_digits;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t GraphicBuffer::initCheck() const {
 return mInitCheck;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int dexOptMkdir(const char*  path, int mode)
{
#ifdef _WIN32
 return mkdir(path);
#else
 return mkdir(path, mode);
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Track::VetEntry(const BlockEntry* pBlockEntry) const
{
    assert(pBlockEntry);
    const Block* const pBlock = pBlockEntry->GetBlock();
    assert(pBlock);
    assert(pBlock->GetTrackNumber() == m_info.number);
    if (!pBlock || pBlock->GetTrackNumber() != m_info.number)
        return false;
 
 
    return true;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: const Cluster* Segment::FindOrPreloadCluster(long long requested_pos) {
 if (requested_pos < 0)
 return 0;

 Cluster** const ii = m_clusters;
 Cluster** i = ii;

 const long count = m_clusterCount + m_clusterPreloadCount;

 Cluster** const jj = ii + count;
 Cluster** j = jj;

 while (i < j) {

 Cluster** const k = i + (j - i) / 2;
    assert(k < jj);

 Cluster* const pCluster = *k;
    assert(pCluster);


 const long long pos = pCluster->GetPosition();
    assert(pos >= 0);

 if (pos < requested_pos)
      i = k + 1;
 else if (pos > requested_pos)
      j = k;
 else
 return pCluster;
 }

  assert(i == j);

 
   Cluster* const pCluster = Cluster::Create(this, -1, requested_pos);
  assert(pCluster);
 
   const ptrdiff_t idx = i - m_clusters;
 
  PreloadCluster(pCluster, idx);
   assert(m_clusters);
   assert(m_clusterPreloadCount > 0);
   assert(m_clusters[idx] == pCluster);

 return pCluster;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: deinterlace_row(png_bytep buffer, png_const_bytep row,
   unsigned int pixel_size, png_uint_32 w, int pass)
{
   /* The inverse of the above, 'row' is part of row 'y' of the output image,
    * in 'buffer'.  The image is 'w' wide and this is pass 'pass', distribute
    * the pixels of row into buffer and return the number written (to allow
    * this to be checked).
    */
   png_uint_32 xin, xout, xstep;
   xout = PNG_PASS_START_COL(pass);
   xstep = 1U<<PNG_PASS_COL_SHIFT(pass);
   for (xin=0; xout<w; xout+=xstep)
   {
      pixel_copy(buffer, xout, row, xin, pixel_size);
      ++xin;
   }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  void updateProgramMapPID(unsigned programMapPID) {
        mProgramMapPID = programMapPID;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void AudioFlinger::EffectHandle::dumpToBuffer(char* buffer, size_t size)
{
 bool locked = mCblk != NULL && AudioFlinger::dumpTryLock(mCblk->lock);

    snprintf(buffer, size, "\t\t\t%5d    %5d  %3s    %3s  %5u  %5u\n",
 (mClient == 0) ? getpid_cached : mClient->pid(),
            mPriority,
            mHasControl ? "yes" : "no",
            locked ? "yes" : "no",
            mCblk ? mCblk->clientIndex : 0,
            mCblk ? mCblk->serverIndex : 0
 );

 if (locked) {
        mCblk->lock.unlock();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: uint32_t get_int(char **p, int DefaultValue)
{
 uint32_t Value = 0;
 unsigned char UseDefault;

 UseDefault = 1;
  skip_blanks(p);

 while ( ((**p)<= '9' && (**p)>= '0') )
 {
 Value = Value * 10 + (**p) - '0';
 UseDefault = 0;
 (*p)++;
 }

 if (UseDefault)
 return DefaultValue;
 else
 return Value;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void utf16_to_utf8(const char16_t* src, size_t src_len, char* dst)
 {
     if (src == NULL || src_len == 0 || dst == NULL) {
         return;
 }

 const char16_t* cur_utf16 = src;
 const char16_t* const end_utf16 = src + src_len;
 char *cur = dst;
 while (cur_utf16 < end_utf16) {
 char32_t utf32;
 if((*cur_utf16 & 0xFC00) == 0xD800 && (cur_utf16 + 1) < end_utf16
 && (*(cur_utf16 + 1) & 0xFC00) == 0xDC00) {
            utf32 = (*cur_utf16++ - 0xD800) << 10;
            utf32 |= *cur_utf16++ - 0xDC00;
            utf32 += 0x10000;
 } else {

             utf32 = (char32_t) *cur_utf16++;
         }
         const size_t len = utf32_codepoint_utf8_length(utf32);
         utf32_codepoint_to_utf8((uint8_t*)cur, utf32, len);
         cur += len;
     }
     *cur = '\0';
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::InputState::addKeyMemento(const KeyEntry* entry, int32_t flags) {
    mKeyMementos.push();
 KeyMemento& memento = mKeyMementos.editTop();
    memento.deviceId = entry->deviceId;
    memento.source = entry->source;
    memento.keyCode = entry->keyCode;
    memento.scanCode = entry->scanCode;
    memento.metaState = entry->metaState;
    memento.flags = flags;
    memento.downTime = entry->downTime;
    memento.policyFlags = entry->policyFlags;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::KeyEntry::KeyEntry(nsecs_t eventTime,
 int32_t deviceId, uint32_t source, uint32_t policyFlags, int32_t action,
 int32_t flags, int32_t keyCode, int32_t scanCode, int32_t metaState,
 int32_t repeatCount, nsecs_t downTime) :
 EventEntry(TYPE_KEY, eventTime, policyFlags),
        deviceId(deviceId), source(source), action(action), flags(flags),
        keyCode(keyCode), scanCode(scanCode), metaState(metaState),
        repeatCount(repeatCount), downTime(downTime),
        syntheticRepeat(false), interceptKeyResult(KeyEntry::INTERCEPT_KEY_RESULT_UNKNOWN),
        interceptKeyWakeupTime(0) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: SimpleSoftOMXComponent::SimpleSoftOMXComponent(
 const char *name,
 const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData,
        OMX_COMPONENTTYPE **component)
 : SoftOMXComponent(name, callbacks, appData, component),
      mLooper(new ALooper),
      mHandler(new AHandlerReflector<SimpleSoftOMXComponent>(this)),
      mState(OMX_StateLoaded),
      mTargetState(OMX_StateLoaded) {
    mLooper->setName(name);
    mLooper->registerHandler(mHandler);

    mLooper->start(
 false, // runOnCallingThread
 false, // canCallJava
            ANDROID_PRIORITY_FOREGROUND);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Source::fragmentedRead(
 MediaBuffer **out, const ReadOptions *options) {

    ALOGV("MPEG4Source::fragmentedRead");

    CHECK(mStarted);

 *out = NULL;

 int64_t targetSampleTimeUs = -1;

 int64_t seekTimeUs;
 ReadOptions::SeekMode mode;
 if (options && options->getSeekTo(&seekTimeUs, &mode)) {

 int numSidxEntries = mSegments.size();
 if (numSidxEntries != 0) {
 int64_t totalTime = 0;
 off64_t totalOffset = mFirstMoofOffset;
 for (int i = 0; i < numSidxEntries; i++) {
 const SidxEntry *se = &mSegments[i];
 if (totalTime + se->mDurationUs > seekTimeUs) {
 if ((mode == ReadOptions::SEEK_NEXT_SYNC) ||
 (mode == ReadOptions::SEEK_CLOSEST_SYNC &&
 (seekTimeUs - totalTime) > (totalTime + se->mDurationUs - seekTimeUs))) {
                        totalTime += se->mDurationUs;
                        totalOffset += se->mSize;
 }
 break;
 }
                totalTime += se->mDurationUs;
                totalOffset += se->mSize;
 }
        mCurrentMoofOffset = totalOffset;
        mCurrentSamples.clear();
        mCurrentSampleIndex = 0;
        parseChunk(&totalOffset);
        mCurrentTime = totalTime * mTimescale / 1000000ll;
 }

 if (mBuffer != NULL) {
            mBuffer->release();
            mBuffer = NULL;
 }

 }

 off64_t offset = 0;
 size_t size;
 uint32_t cts = 0;
 bool isSyncSample = false;
 bool newBuffer = false;
 if (mBuffer == NULL) {
        newBuffer = true;

 if (mCurrentSampleIndex >= mCurrentSamples.size()) {
 Sample lastSample = mCurrentSamples[mCurrentSamples.size() - 1];
 off64_t nextMoof = mNextMoofOffset; // lastSample.offset + lastSample.size;
            mCurrentMoofOffset = nextMoof;
            mCurrentSamples.clear();
            mCurrentSampleIndex = 0;
            parseChunk(&nextMoof);
 if (mCurrentSampleIndex >= mCurrentSamples.size()) {
 return ERROR_END_OF_STREAM;
 }
 }

 const Sample *smpl = &mCurrentSamples[mCurrentSampleIndex];
        offset = smpl->offset;
        size = smpl->size;
        cts = mCurrentTime;
        mCurrentTime += smpl->duration;
        isSyncSample = (mCurrentSampleIndex == 0); // XXX

 status_t err = mGroup->acquire_buffer(&mBuffer);

 if (err != OK) {
            CHECK(mBuffer == NULL);
            ALOGV("acquire_buffer returned %d", err);
 return err;
 }
 if (size > mBuffer->size()) {
            ALOGE("buffer too small: %zu > %zu", size, mBuffer->size());
 return ERROR_BUFFER_TOO_SMALL;
 }
 }

 const Sample *smpl = &mCurrentSamples[mCurrentSampleIndex];
 const sp<MetaData> bufmeta = mBuffer->meta_data();
    bufmeta->clear();
 if (smpl->encryptedsizes.size()) {
        bufmeta->setData(kKeyPlainSizes, 0,
                smpl->clearsizes.array(), smpl->clearsizes.size() * 4);
        bufmeta->setData(kKeyEncryptedSizes, 0,
                smpl->encryptedsizes.array(), smpl->encryptedsizes.size() * 4);
        bufmeta->setData(kKeyCryptoIV, 0, smpl->iv, 16); // use 16 or the actual size?
        bufmeta->setInt32(kKeyCryptoDefaultIVSize, mDefaultIVSize);
        bufmeta->setInt32(kKeyCryptoMode, mCryptoMode);
        bufmeta->setData(kKeyCryptoKey, 0, mCryptoKey, 16);
 }

 if (!mIsAVC || mWantsNALFragments) {
 if (newBuffer) {
 if (!isInRange((size_t)0u, mBuffer->size(), size)) {
                mBuffer->release();
                mBuffer = NULL;

                ALOGE("fragmentedRead ERROR_MALFORMED size %zu", size);
 return ERROR_MALFORMED;
 }

 ssize_t num_bytes_read =
                mDataSource->readAt(offset, (uint8_t *)mBuffer->data(), size);

 if (num_bytes_read < (ssize_t)size) {
                mBuffer->release();
                mBuffer = NULL;

                ALOGE("i/o error");
 return ERROR_IO;
 }

            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);
            mBuffer->meta_data()->setInt64(
                    kKeyTime, ((int64_t)cts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
                mBuffer->meta_data()->setInt64(
                        kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
                mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;
 }

 if (!mIsAVC) {
 *out = mBuffer;
            mBuffer = NULL;

 return OK;
 }


        CHECK(mBuffer->range_length() >= mNALLengthSize);

 const uint8_t *src =
 (const uint8_t *)mBuffer->data() + mBuffer->range_offset();

 size_t nal_size = parseNALSize(src);
 if (mNALLengthSize > SIZE_MAX - nal_size) {
            ALOGE("b/24441553, b/24445122");
 }

 if (mBuffer->range_length() - mNALLengthSize < nal_size) {
            ALOGE("incomplete NAL unit.");

            mBuffer->release();
            mBuffer = NULL;

 return ERROR_MALFORMED;
 }

 MediaBuffer *clone = mBuffer->clone();
        CHECK(clone != NULL);
        clone->set_range(mBuffer->range_offset() + mNALLengthSize, nal_size);

        CHECK(mBuffer != NULL);
        mBuffer->set_range(
                mBuffer->range_offset() + mNALLengthSize + nal_size,
                mBuffer->range_length() - mNALLengthSize - nal_size);

 if (mBuffer->range_length() == 0) {
            mBuffer->release();
            mBuffer = NULL;
 }

 *out = clone;

 return OK;
 } else {
        ALOGV("whole NAL");
 ssize_t num_bytes_read = 0;
 int32_t drm = 0;
 bool usesDRM = (mFormat->findInt32(kKeyIsDRM, &drm) && drm != 0);
 void *data = NULL;
 bool isMalFormed = false;
 if (usesDRM) {
 if (mBuffer == NULL || !isInRange((size_t)0u, mBuffer->size(), size)) {
                isMalFormed = true;
 } else {
                data = mBuffer->data();
 }
 } else {
 int32_t max_size;
 if (mFormat == NULL
 || !mFormat->findInt32(kKeyMaxInputSize, &max_size)
 || !isInRange((size_t)0u, (size_t)max_size, size)) {
                isMalFormed = true;
 } else {
                data = mSrcBuffer;
 }
 }

 if (isMalFormed || data == NULL) {
            ALOGE("isMalFormed size %zu", size);
 if (mBuffer != NULL) {
                mBuffer->release();
                mBuffer = NULL;
 }
 return ERROR_MALFORMED;
 }
        num_bytes_read = mDataSource->readAt(offset, data, size);

 if (num_bytes_read < (ssize_t)size) {
            mBuffer->release();
            mBuffer = NULL;

            ALOGE("i/o error");
 return ERROR_IO;
 }

 if (usesDRM) {
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, size);

 } else {
 uint8_t *dstData = (uint8_t *)mBuffer->data();
 size_t srcOffset = 0;
 size_t dstOffset = 0;

 while (srcOffset < size) {
                isMalFormed = !isInRange((size_t)0u, size, srcOffset, mNALLengthSize);
 size_t nalLength = 0;
 if (!isMalFormed) {
                    nalLength = parseNALSize(&mSrcBuffer[srcOffset]);
                    srcOffset += mNALLengthSize;
                    isMalFormed = !isInRange((size_t)0u, size, srcOffset, nalLength)
 || !isInRange((size_t)0u, mBuffer->size(), dstOffset, (size_t)4u)
 || !isInRange((size_t)0u, mBuffer->size(), dstOffset + 4, nalLength);
 }

 if (isMalFormed) {
                    ALOGE("Video is malformed; nalLength %zu", nalLength);
                    mBuffer->release();
                    mBuffer = NULL;
 return ERROR_MALFORMED;
 }

 if (nalLength == 0) {

                     continue;
                 }
 
                CHECK(dstOffset + 4 <= mBuffer->size());
 
                 dstData[dstOffset++] = 0;
                 dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 0;
                dstData[dstOffset++] = 1;
                memcpy(&dstData[dstOffset], &mSrcBuffer[srcOffset], nalLength);
                srcOffset += nalLength;
                dstOffset += nalLength;
 }
            CHECK_EQ(srcOffset, size);
            CHECK(mBuffer != NULL);
            mBuffer->set_range(0, dstOffset);
 }

        mBuffer->meta_data()->setInt64(
                kKeyTime, ((int64_t)cts * 1000000) / mTimescale);

 if (targetSampleTimeUs >= 0) {
            mBuffer->meta_data()->setInt64(
                    kKeyTargetTime, targetSampleTimeUs);
 }

 if (isSyncSample) {
            mBuffer->meta_data()->setInt32(kKeyIsSyncFrame, 1);
 }

 ++mCurrentSampleIndex;

 *out = mBuffer;
        mBuffer = NULL;

 return OK;
 }
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t Parcel::writeStrongBinderVector(const std::unique_ptr<std::vector<sp<IBinder>>>& val)
{
 return writeNullableTypedVector(val, &Parcel::writeStrongBinder);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void RilSapSocket::sendDisconnect() {
 size_t encoded_size = 0;
 uint32_t written_size;
 size_t buffer_size = 0;
 pb_ostream_t ostream;
 bool success = false;

    RIL_SIM_SAP_DISCONNECT_REQ disconnectReq;


    if ((success = pb_get_encoded_size(&encoded_size, RIL_SIM_SAP_DISCONNECT_REQ_fields,
         &disconnectReq)) && encoded_size <= INT32_MAX) {
         buffer_size = encoded_size + sizeof(uint32_t);
        uint8_t buffer[buffer_size];
         written_size = htonl((uint32_t) encoded_size);
         ostream = pb_ostream_from_buffer(buffer, buffer_size);
         pb_write(&ostream, (uint8_t *)&written_size, sizeof(written_size));
        success = pb_encode(&ostream, RIL_SIM_SAP_DISCONNECT_REQ_fields, buffer);

 if(success) {
 pb_bytes_array_t *payload = (pb_bytes_array_t *)calloc(1,
 sizeof(pb_bytes_array_t) + written_size);
 if (!payload) {
                RLOGE("sendDisconnect: OOM");
 return;
 }
            memcpy(payload->bytes, buffer, written_size);
            payload->size = written_size;
 MsgHeader *hdr = (MsgHeader *)malloc(sizeof(MsgHeader));
 if (!hdr) {
                RLOGE("sendDisconnect: OOM");
                free(payload);
 return;
 }
            hdr->payload = payload;
            hdr->type = MsgType_REQUEST;
            hdr->id = MsgId_RIL_SIM_SAP_DISCONNECT;
            hdr->error = Error_RIL_E_SUCCESS;
            dispatchDisconnect(hdr);
 }

         else {
             RLOGE("Encode failed in send disconnect!");
         }
     }
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: image_transform_png_set_expand_set(PNG_CONST image_transform *this,
     transform_display *that, png_structp pp, png_infop pi)
 {
    png_set_expand(pp);
    this->next->set(this->next, that, pp, pi);
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t OMXNodeInstance::setConfig(
        OMX_INDEXTYPE index, const void *params, size_t size) {
 Mutex::Autolock autoLock(mLock);
    OMX_INDEXEXTTYPE extIndex = (OMX_INDEXEXTTYPE)index;
    CLOG_CONFIG(setConfig, "%s(%#x), %zu@%p)", asString(extIndex), index, size, params);

    OMX_ERRORTYPE err = OMX_SetConfig(
            mHandle, index, const_cast<void *>(params));
    CLOG_IF_ERROR(setConfig, err, "%s(%#x)", asString(extIndex), index);
 return StatusFromOMXError(err);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int Volume_setParameter (EffectContext *pContext, void *pParam, void *pValue){
 int      status = 0;
 int16_t  level;
 int16_t  position;
 uint32_t mute;
 uint32_t positionEnabled;
 int32_t *pParamTemp = (int32_t *)pParam;
 int32_t param = *pParamTemp++;


 switch (param){
 case VOLUME_PARAM_LEVEL:
            level = *(int16_t *)pValue;
            status = VolumeSetVolumeLevel(pContext, (int16_t)level);
 break;

 case VOLUME_PARAM_MUTE:
            mute = *(uint32_t *)pValue;
            status = VolumeSetMute(pContext, mute);
 break;

 case VOLUME_PARAM_ENABLESTEREOPOSITION:
            positionEnabled = *(uint32_t *)pValue;
            status = VolumeEnableStereoPosition(pContext, positionEnabled);
            status = VolumeSetStereoPosition(pContext, pContext->pBundledContext->positionSaved);
 break;

 case VOLUME_PARAM_STEREOPOSITION:
            position = *(int16_t *)pValue;
            status = VolumeSetStereoPosition(pContext, (int16_t)position);
 break;

 default:
            ALOGV("\tLVM_ERROR : Volume_setParameter() invalid param %d", param);
 break;
 }

 return status;
} /* end Volume_setParameter */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_free_buf(void *buf_addr, unsigned port)
{
 struct pmem *pmem_tmp;
 struct venc_bufferpayload dev_buffer;

    memset(&dev_buffer, 0, sizeof(dev_buffer));
    pmem_tmp = (struct pmem *)buf_addr;

 if (port == PORT_INDEX_IN) {
        dev_buffer.pbuffer = (OMX_U8 *)pmem_tmp->buffer;
        dev_buffer.fd  = pmem_tmp->fd;
        dev_buffer.maped_size = pmem_tmp->size;
        dev_buffer.sz = pmem_tmp->size;
        dev_buffer.offset = pmem_tmp->offset;
        DEBUG_PRINT_LOW("venc_free_buf:pbuffer = %p,fd = %x, offset = %d, maped_size = %d", \
                dev_buffer.pbuffer, \
                dev_buffer.fd, \
                dev_buffer.offset, \
                dev_buffer.maped_size);

 } else if (port == PORT_INDEX_OUT) {
        dev_buffer.pbuffer = (OMX_U8 *)pmem_tmp->buffer;
        dev_buffer.fd  = pmem_tmp->fd;
        dev_buffer.sz = pmem_tmp->size;
        dev_buffer.maped_size = pmem_tmp->size;
        dev_buffer.offset = pmem_tmp->offset;

        DEBUG_PRINT_LOW("venc_free_buf:pbuffer = %p,fd = %x, offset = %d, maped_size = %d", \
                dev_buffer.pbuffer, \
                dev_buffer.fd, \
                dev_buffer.offset, \
                dev_buffer.maped_size);
 } else {
        DEBUG_PRINT_ERROR("ERROR: venc_free_buf:Invalid Port Index ");
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ProCamera2Client::detachDevice() {
 if (mDevice == 0) return;

    ALOGV("Camera %d: Stopping processors", mCameraId);

    mFrameProcessor->removeListener(FRAME_PROCESSOR_LISTENER_MIN_ID,
                                    FRAME_PROCESSOR_LISTENER_MAX_ID,
 /*listener*/this);
    mFrameProcessor->requestExit();
    ALOGV("Camera %d: Waiting for threads", mCameraId);
    mFrameProcessor->join();
    ALOGV("Camera %d: Disconnecting device", mCameraId);

 {
        mDevice->clearStreamingRequest();

 status_t code;
 if ((code = mDevice->waitUntilDrained()) != OK) {
            ALOGE("%s: waitUntilDrained failed with code 0x%x", __FUNCTION__,
                  code);
 }
 }

 Camera2ClientBase::detachDevice();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void decode_macroblock(VP8D_COMP *pbi, MACROBLOCKD *xd,
 unsigned int mb_idx)
{
    MB_PREDICTION_MODE mode;
 int i;
#if CONFIG_ERROR_CONCEALMENT
 int corruption_detected = 0;
#else
 (void)mb_idx;
#endif

 if (xd->mode_info_context->mbmi.mb_skip_coeff)
 {
        vp8_reset_mb_tokens_context(xd);
 }
 else if (!vp8dx_bool_error(xd->current_bc))
 {
 int eobtotal;
        eobtotal = vp8_decode_mb_tokens(pbi, xd);

 /* Special case:  Force the loopfilter to skip when eobtotal is zero */
        xd->mode_info_context->mbmi.mb_skip_coeff = (eobtotal==0);
 }

    mode = xd->mode_info_context->mbmi.mode;

 if (xd->segmentation_enabled)
        vp8_mb_init_dequantizer(pbi, xd);


#if CONFIG_ERROR_CONCEALMENT

 if(pbi->ec_active)
 {
 int throw_residual;
 /* When we have independent partitions we can apply residual even
         * though other partitions within the frame are corrupt.
         */
        throw_residual = (!pbi->independent_partitions &&
                          pbi->frame_corrupt_residual);
        throw_residual = (throw_residual || vp8dx_bool_error(xd->current_bc));

 if ((mb_idx >= pbi->mvs_corrupt_from_mb || throw_residual))
 {
 /* MB with corrupt residuals or corrupt mode/motion vectors.
             * Better to use the predictor as reconstruction.
             */
            pbi->frame_corrupt_residual = 1;
            memset(xd->qcoeff, 0, sizeof(xd->qcoeff));
            vp8_conceal_corrupt_mb(xd);


            corruption_detected = 1;

 /* force idct to be skipped for B_PRED and use the
             * prediction only for reconstruction
             * */
            memset(xd->eobs, 0, 25);
 }
 }
#endif

 /* do prediction */
 if (xd->mode_info_context->mbmi.ref_frame == INTRA_FRAME)
 {
        vp8_build_intra_predictors_mbuv_s(xd,
                                          xd->recon_above[1],
                                          xd->recon_above[2],
                                          xd->recon_left[1],
                                          xd->recon_left[2],
                                          xd->recon_left_stride[1],
                                          xd->dst.u_buffer, xd->dst.v_buffer,
                                          xd->dst.uv_stride);

 if (mode != B_PRED)
 {
            vp8_build_intra_predictors_mby_s(xd,
                                                 xd->recon_above[0],
                                                 xd->recon_left[0],
                                                 xd->recon_left_stride[0],
                                                 xd->dst.y_buffer,
                                                 xd->dst.y_stride);
 }
 else
 {
 short *DQC = xd->dequant_y1;
 int dst_stride = xd->dst.y_stride;

 /* clear out residual eob info */
 if(xd->mode_info_context->mbmi.mb_skip_coeff)
                memset(xd->eobs, 0, 25);

            intra_prediction_down_copy(xd, xd->recon_above[0] + 16);

 for (i = 0; i < 16; i++)
 {
                BLOCKD *b = &xd->block[i];
 unsigned char *dst = xd->dst.y_buffer + b->offset;
                B_PREDICTION_MODE b_mode =
                    xd->mode_info_context->bmi[i].as_mode;
 unsigned char *Above = dst - dst_stride;
 unsigned char *yleft = dst - 1;
 int left_stride = dst_stride;
 unsigned char top_left = Above[-1];

                vp8_intra4x4_predict(Above, yleft, left_stride, b_mode,
                                     dst, dst_stride, top_left);

 if (xd->eobs[i])
 {
 if (xd->eobs[i] > 1)
 {
                    vp8_dequant_idct_add(b->qcoeff, DQC, dst, dst_stride);
 }
 else
 {
                        vp8_dc_only_idct_add
 (b->qcoeff[0] * DQC[0],
                                dst, dst_stride,
                                dst, dst_stride);
                        memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }
 }
 }
 }
 }
 else
 {
        vp8_build_inter_predictors_mb(xd);
 }


#if CONFIG_ERROR_CONCEALMENT
 if (corruption_detected)
 {
 return;
 }
#endif

 if(!xd->mode_info_context->mbmi.mb_skip_coeff)
 {
 /* dequantization and idct */
 if (mode != B_PRED)
 {
 short *DQC = xd->dequant_y1;

 if (mode != SPLITMV)
 {
                BLOCKD *b = &xd->block[24];

 /* do 2nd order transform on the dc block */
 if (xd->eobs[24] > 1)
 {
                    vp8_dequantize_b(b, xd->dequant_y2);

                    vp8_short_inv_walsh4x4(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 16 * sizeof(b->qcoeff[0]));
 }
 else
 {
                    b->dqcoeff[0] = b->qcoeff[0] * xd->dequant_y2[0];
                    vp8_short_inv_walsh4x4_1(&b->dqcoeff[0],
                        xd->qcoeff);
                    memset(b->qcoeff, 0, 2 * sizeof(b->qcoeff[0]));
 }

 /* override the dc dequant constant in order to preserve the
                 * dc components
                 */
                DQC = xd->dequant_y1_dc;
 }

            vp8_dequant_idct_add_y_block
 (xd->qcoeff, DQC,
                             xd->dst.y_buffer,
                             xd->dst.y_stride, xd->eobs);
 }

        vp8_dequant_idct_add_uv_block
 (xd->qcoeff+16*16, xd->dequant_uv,
                         xd->dst.u_buffer, xd->dst.v_buffer,
                         xd->dst.uv_stride, xd->eobs+16);
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: BOOLEAN btif_rc_get_connected_peer(BD_ADDR peer_addr)
{
 if (btif_rc_cb.rc_connected == TRUE) {
        bdcpy(peer_addr, btif_rc_cb.rc_addr);
 return TRUE;
 }
 return FALSE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: make_random_bytes(png_uint_32* seed, void* pv, size_t size)
{
   png_uint_32 u0 = seed[0], u1 = seed[1];
   png_bytep bytes = voidcast(png_bytep, pv);

 /* There are thirty three bits, the next bit in the sequence is bit-33 XOR
    * bit-20.  The top 1 bit is in u1, the bottom 32 are in u0.
    */
 size_t i;
 for (i=0; i<size; ++i)
 {
 /* First generate 8 new bits then shift them in at the end. */
      png_uint_32 u = ((u0 >> (20-8)) ^ ((u1 << 7) | (u0 >> (32-7)))) & 0xff;
      u1 <<= 8;
      u1 |= u0 >> 24;
      u0 <<= 8;
      u0 |= u;
 *bytes++ = (png_byte)u;
 }

   seed[0] = u0;
   seed[1] = u1;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static Maybe<bool> IncludesValueSlowPath(Isolate* isolate,
 Handle<JSObject> receiver,
 Handle<Object> value,
 uint32_t start_from, uint32_t length) {
 bool search_for_hole = value->IsUndefined(isolate);
 for (uint32_t k = start_from; k < length; ++k) {
 LookupIterator it(isolate, receiver, k);
 if (!it.IsFound()) {
 if (search_for_hole) return Just(true);
 continue;
 }
 Handle<Object> element_k;
    ASSIGN_RETURN_ON_EXCEPTION_VALUE(isolate, element_k,
 Object::GetProperty(&it), Nothing<bool>());

 if (value->SameValueZero(*element_k)) return Just(true);
 }

 return Just(false);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static void SetLengthImpl(Isolate* isolate, Handle<JSArray> array,
 uint32_t length,
 Handle<FixedArrayBase> backing_store) {
    UNREACHABLE();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_get_output_log_flag()
{
 return (m_debug.out_buffer_log == 1);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_parse_buffering_period(buf_period_t *ps_buf_prd,
 dec_bit_stream_t *ps_bitstrm,
 dec_struct_t *ps_dec)
{
    UWORD8 u1_seq_parameter_set_id;
 dec_seq_params_t *ps_seq;
    UWORD8 u1_nal_hrd_present, u1_vcl_hrd_present;
    UWORD32 i;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UNUSED(ps_buf_prd);
    u1_seq_parameter_set_id = ih264d_uev(pu4_bitstrm_ofst,
                                         pu4_bitstrm_buf);
 if(u1_seq_parameter_set_id >= MAX_NUM_SEQ_PARAMS)
 return ERROR_INVALID_SEQ_PARAM;
    ps_seq = &ps_dec->ps_sps[u1_seq_parameter_set_id];
 if(TRUE != ps_seq->u1_is_valid)
 return (-1);

    ps_dec->ps_sei->u1_seq_param_set_id = u1_seq_parameter_set_id;
    ps_dec->ps_cur_sps = ps_seq;
 if(FALSE == ps_seq->u1_is_valid)
 return ERROR_INVALID_SEQ_PARAM;
 if(1 == ps_seq->u1_vui_parameters_present_flag)
 {
        u1_nal_hrd_present = ps_seq->s_vui.u1_nal_hrd_params_present;
 if(u1_nal_hrd_present)
 {
 for(i = 0; i < ps_seq->s_vui.s_nal_hrd.u4_cpb_cnt; i++)
 {
                ih264d_get_bits_h264(
                                ps_bitstrm,
                                ps_seq->s_vui.s_nal_hrd.u1_initial_cpb_removal_delay);
                ih264d_get_bits_h264(
                                ps_bitstrm,
                                ps_seq->s_vui.s_nal_hrd.u1_initial_cpb_removal_delay);
 }
 }

        u1_vcl_hrd_present = ps_seq->s_vui.u1_vcl_hrd_params_present;
 if(u1_vcl_hrd_present)
 {
 for(i = 0; i < ps_seq->s_vui.s_vcl_hrd.u4_cpb_cnt; i++)
 {
                ih264d_get_bits_h264(
                                ps_bitstrm,
                                ps_seq->s_vui.s_vcl_hrd.u1_initial_cpb_removal_delay);
                ih264d_get_bits_h264(
                                ps_bitstrm,
                                ps_seq->s_vui.s_vcl_hrd.u1_initial_cpb_removal_delay);
 }
 }
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Chapters::Edition::ShallowCopy(Edition& rhs) const {
  rhs.m_atoms = m_atoms;
  rhs.m_atoms_size = m_atoms_size;
  rhs.m_atoms_count = m_atoms_count;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const char* dump_av_sm_event_name(btif_av_sm_event_t event) {
 switch ((int)event) {
    CASE_RETURN_STR(BTA_AV_ENABLE_EVT)
    CASE_RETURN_STR(BTA_AV_REGISTER_EVT)
    CASE_RETURN_STR(BTA_AV_OPEN_EVT)
    CASE_RETURN_STR(BTA_AV_CLOSE_EVT)
    CASE_RETURN_STR(BTA_AV_START_EVT)
    CASE_RETURN_STR(BTA_AV_STOP_EVT)
    CASE_RETURN_STR(BTA_AV_PROTECT_REQ_EVT)
    CASE_RETURN_STR(BTA_AV_PROTECT_RSP_EVT)
    CASE_RETURN_STR(BTA_AV_RC_OPEN_EVT)
    CASE_RETURN_STR(BTA_AV_RC_CLOSE_EVT)
    CASE_RETURN_STR(BTA_AV_RC_BROWSE_OPEN_EVT)
    CASE_RETURN_STR(BTA_AV_RC_BROWSE_CLOSE_EVT)
    CASE_RETURN_STR(BTA_AV_REMOTE_CMD_EVT)
    CASE_RETURN_STR(BTA_AV_REMOTE_RSP_EVT)
    CASE_RETURN_STR(BTA_AV_VENDOR_CMD_EVT)
    CASE_RETURN_STR(BTA_AV_VENDOR_RSP_EVT)
    CASE_RETURN_STR(BTA_AV_RECONFIG_EVT)
    CASE_RETURN_STR(BTA_AV_SUSPEND_EVT)
    CASE_RETURN_STR(BTA_AV_PENDING_EVT)
    CASE_RETURN_STR(BTA_AV_META_MSG_EVT)
    CASE_RETURN_STR(BTA_AV_REJECT_EVT)
    CASE_RETURN_STR(BTA_AV_RC_FEAT_EVT)
    CASE_RETURN_STR(BTA_AV_OFFLOAD_START_RSP_EVT)
    CASE_RETURN_STR(BTIF_SM_ENTER_EVT)
    CASE_RETURN_STR(BTIF_SM_EXIT_EVT)
    CASE_RETURN_STR(BTIF_AV_CONNECT_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_DISCONNECT_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_START_STREAM_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_STOP_STREAM_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_SUSPEND_STREAM_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_SOURCE_CONFIG_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_SOURCE_CONFIG_UPDATED_EVT)
    CASE_RETURN_STR(BTIF_AV_SINK_CONFIG_REQ_EVT)
    CASE_RETURN_STR(BTIF_AV_OFFLOAD_START_REQ_EVT)
 default:
 return "UNKNOWN_EVENT";
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: android::SoftOMXComponent *createSoftOMXComponent(
 const char *name, const OMX_CALLBACKTYPE *callbacks,
        OMX_PTR appData, OMX_COMPONENTTYPE **component) {
 return new android::SoftFlacEncoder(name, callbacks, appData, component);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ihevcd_decode(iv_obj_t *ps_codec_obj, void *pv_api_ip, void *pv_api_op)
{
    WORD32 ret = IV_SUCCESS;
 codec_t *ps_codec = (codec_t *)(ps_codec_obj->pv_codec_handle);
 ivd_video_decode_ip_t *ps_dec_ip;
 ivd_video_decode_op_t *ps_dec_op;

    WORD32 proc_idx = 0;
    WORD32 prev_proc_idx = 0;

 /* Initialize error code */
    ps_codec->i4_error_code = 0;

    ps_dec_ip = (ivd_video_decode_ip_t *)pv_api_ip;
    ps_dec_op = (ivd_video_decode_op_t *)pv_api_op;

 {
        UWORD32 u4_size = ps_dec_op->u4_size;
        memset(ps_dec_op, 0, sizeof(ivd_video_decode_op_t));
        ps_dec_op->u4_size = u4_size; //Restore size field
 }
 if(ps_codec->i4_init_done != 1)
 {
        ps_dec_op->u4_error_code |= 1 << IVD_FATALERROR;
        ps_dec_op->u4_error_code |= IHEVCD_INIT_NOT_DONE;
 return IV_FAIL;
 }

 if(ps_codec->u4_pic_cnt >= NUM_FRAMES_LIMIT)
 {
        ps_dec_op->u4_error_code |= 1 << IVD_FATALERROR;
        ps_dec_op->u4_error_code |= IHEVCD_NUM_FRAMES_LIMIT_REACHED;
 return IV_FAIL;
 }

 /* If reset flag is set, flush the existing buffers */
 if(ps_codec->i4_reset_flag)
 {
        ps_codec->i4_flush_mode = 1;
 }

 /*Data memory barries instruction,so that bitstream write by the application is complete*/
 /* In case the decoder is not in flush mode check for input buffer validity */
 if(0 == ps_codec->i4_flush_mode)
 {
 if(ps_dec_ip->pv_stream_buffer == NULL)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_FRM_BS_BUF_NULL;
 return IV_FAIL;
 }
 if(ps_dec_ip->u4_num_Bytes <= MIN_START_CODE_LEN)
 {
 if((WORD32)ps_dec_ip->u4_num_Bytes > 0)
                ps_dec_op->u4_num_bytes_consumed = ps_dec_ip->u4_num_Bytes;
 else
                ps_dec_op->u4_num_bytes_consumed = 0;

            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DEC_NUMBYTES_INV;
 return IV_FAIL;

 }
 }

#ifdef APPLY_CONCEALMENT
 {
        WORD32 num_mbs;

        num_mbs = (ps_codec->i4_wd * ps_codec->i4_ht + 255) >> 8;
 /* Reset MB Count at the beginning of every process call */
        ps_codec->mb_count = 0;
        memset(ps_codec->mb_map, 0, ((num_mbs + 7) >> 3));
 }
#endif

 if(0 == ps_codec->i4_share_disp_buf && ps_codec->i4_header_mode == 0)
 {
        UWORD32 i;
 if(ps_dec_ip->s_out_buffer.u4_num_bufs == 0)
 {
            ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
            ps_dec_op->u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUFS;
 return IV_FAIL;
 }

 for(i = 0; i < ps_dec_ip->s_out_buffer.u4_num_bufs; i++)
 {
 if(ps_dec_ip->s_out_buffer.pu1_bufs[i] == NULL)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |= IVD_DISP_FRM_OP_BUF_NULL;
 return IV_FAIL;
 }

 if(ps_dec_ip->s_out_buffer.u4_min_out_buf_size[i] == 0)
 {
                ps_dec_op->u4_error_code |= 1 << IVD_UNSUPPORTEDPARAM;
                ps_dec_op->u4_error_code |= IVD_DISP_FRM_ZERO_OP_BUF_SIZE;
 return IV_FAIL;
 }
 }
 }

    ps_codec->ps_out_buffer = &ps_dec_ip->s_out_buffer;
    ps_codec->u4_ts = ps_dec_ip->u4_ts;
 if(ps_codec->i4_flush_mode)
 {

        ps_dec_op->u4_pic_wd = ps_codec->i4_disp_wd;
        ps_dec_op->u4_pic_ht = ps_codec->i4_disp_ht;

        ps_dec_op->u4_new_seq = 0;

        ps_codec->ps_disp_buf = (pic_buf_t *)ihevc_disp_mgr_get(
 (disp_mgr_t *)ps_codec->pv_disp_buf_mgr, &ps_codec->i4_disp_buf_id);
 /* In case of non-shared mode, then convert/copy the frame to output buffer */
 /* Only if the codec is in non-shared mode or in shared mode but needs 420P output */
 if((ps_codec->ps_disp_buf)
 && ((0 == ps_codec->i4_share_disp_buf)
 || (IV_YUV_420P
 == ps_codec->e_chroma_fmt)))
 {

 process_ctxt_t *ps_proc = &ps_codec->as_process[prev_proc_idx];
 if(0 == ps_proc->i4_init_done)
 {
                ihevcd_init_proc_ctxt(ps_proc, 0);
 }

 /* Set remaining number of rows to be processed */
            ret = ihevcd_fmt_conv(ps_codec, &ps_codec->as_process[prev_proc_idx],
                                  ps_dec_ip->s_out_buffer.pu1_bufs[0],
                                  ps_dec_ip->s_out_buffer.pu1_bufs[1],
                                  ps_dec_ip->s_out_buffer.pu1_bufs[2], 0,
                                  ps_codec->i4_disp_ht);

            ihevc_buf_mgr_release((buf_mgr_t *)ps_codec->pv_pic_buf_mgr,
                                  ps_codec->i4_disp_buf_id, BUF_MGR_DISP);
 }

        ihevcd_fill_outargs(ps_codec, ps_dec_ip, ps_dec_op);

 if(1 == ps_dec_op->u4_output_present)
 {
            WORD32 xpos = ps_codec->i4_disp_wd - 32 - LOGO_WD;
            WORD32 ypos = ps_codec->i4_disp_ht - 32 - LOGO_HT;

 if(ypos < 0)
                ypos = 0;

 if(xpos < 0)
                xpos = 0;

            INSERT_LOGO(ps_dec_ip->s_out_buffer.pu1_bufs[0],
                        ps_dec_ip->s_out_buffer.pu1_bufs[1],
                        ps_dec_ip->s_out_buffer.pu1_bufs[2], ps_codec->i4_disp_strd,
                        xpos,
                        ypos,
                        ps_codec->e_chroma_fmt,
                        ps_codec->i4_disp_wd,
                        ps_codec->i4_disp_ht);
 }


 if(NULL == ps_codec->ps_disp_buf)
 {
 /* If in flush mode and there are no more buffers to flush,
             * check for the reset flag and reset the decoder */
 if(ps_codec->i4_reset_flag)
 {
                ihevcd_init(ps_codec);
 }
 return (IV_FAIL);
 }

 return (IV_SUCCESS);

 }
 /* In case of shared mode, check if there is a free buffer for reconstruction */
 if((0 == ps_codec->i4_header_mode) && (1 == ps_codec->i4_share_disp_buf))
 {
        WORD32 buf_status;
        buf_status = 1;
 if(ps_codec->pv_pic_buf_mgr)
            buf_status = ihevc_buf_mgr_check_free((buf_mgr_t *)ps_codec->pv_pic_buf_mgr);

 /* If there is no free buffer, then return with an error code */
 if(0 == buf_status)
 {
            ps_dec_op->u4_error_code = IVD_DEC_REF_BUF_NULL;
            ps_dec_op->u4_error_code |= (1 << IVD_UNSUPPORTEDPARAM);
 return IV_FAIL;
 }
 }
    ps_codec->i4_bytes_remaining = ps_dec_ip->u4_num_Bytes;
    ps_codec->pu1_inp_bitsbuf = (UWORD8 *)ps_dec_ip->pv_stream_buffer;
    ps_codec->s_parse.i4_end_of_frame = 0;

    ps_codec->i4_pic_present = 0;
    ps_codec->i4_slice_error = 0;
    ps_codec->ps_disp_buf = NULL;

 if(ps_codec->i4_num_cores > 1)
 {
        ithread_set_affinity(0);
 }
 while(MIN_START_CODE_LEN < ps_codec->i4_bytes_remaining)
 {
        WORD32 nal_len;
        WORD32 nal_ofst;
        WORD32 bits_len;

 if(ps_codec->i4_slice_error)
 {
 slice_header_t *ps_slice_hdr_next = ps_codec->s_parse.ps_slice_hdr_base + (ps_codec->s_parse.i4_cur_slice_idx & (MAX_SLICE_HDR_CNT - 1));
            WORD32 next_slice_addr = ps_slice_hdr_next->i2_ctb_x +
                            ps_slice_hdr_next->i2_ctb_y * ps_codec->s_parse.ps_sps->i2_pic_wd_in_ctb;
 if(ps_codec->s_parse.i4_next_ctb_indx == next_slice_addr)
                ps_codec->i4_slice_error = 0;
 }

 if(ps_codec->pu1_bitsbuf_dynamic)
 {
            ps_codec->pu1_bitsbuf = ps_codec->pu1_bitsbuf_dynamic;
            ps_codec->u4_bitsbuf_size = ps_codec->u4_bitsbuf_size_dynamic;
 }
 else
 {
            ps_codec->pu1_bitsbuf = ps_codec->pu1_bitsbuf_static;
            ps_codec->u4_bitsbuf_size = ps_codec->u4_bitsbuf_size_static;
 }

        nal_ofst = ihevcd_nal_search_start_code(ps_codec->pu1_inp_bitsbuf,
                                                ps_codec->i4_bytes_remaining);

        ps_codec->i4_nal_ofst = nal_ofst;
 {
            WORD32 bytes_remaining = ps_codec->i4_bytes_remaining - nal_ofst;

            bytes_remaining = MIN((UWORD32)bytes_remaining, ps_codec->u4_bitsbuf_size);
            ihevcd_nal_remv_emuln_bytes(ps_codec->pu1_inp_bitsbuf + nal_ofst,
                                        ps_codec->pu1_bitsbuf,
                                        bytes_remaining,
 &nal_len, &bits_len);

 /* Decoder may read upto 8 extra bytes at the end of frame */
 /* These are not used, but still set them to zero to avoid uninitialized reads */
 if(bits_len < (WORD32)(ps_codec->u4_bitsbuf_size - 8))
 {
                memset(ps_codec->pu1_bitsbuf + bits_len, 0, 2 * sizeof(UWORD32));
 }
 }
 /* This may be used to update the offsets for tiles and entropy sync row offsets */
        ps_codec->i4_num_emln_bytes = nal_len - bits_len;
        ps_codec->i4_nal_len = nal_len;

        ihevcd_bits_init(&ps_codec->s_parse.s_bitstrm, ps_codec->pu1_bitsbuf,
                         bits_len);

        ret = ihevcd_nal_unit(ps_codec);

 /* If the frame is incomplete and
         * the bytes remaining is zero or a header is received,
         * complete the frame treating it to be in error */
 if(ps_codec->i4_pic_present &&
 (ps_codec->s_parse.i4_next_ctb_indx != ps_codec->s_parse.ps_sps->i4_pic_size_in_ctb))
 {
 if((ps_codec->i4_bytes_remaining - (nal_len + nal_ofst) <= MIN_START_CODE_LEN) ||
 (ps_codec->i4_header_in_slice_mode))
 {
 slice_header_t *ps_slice_hdr_next;

                ps_codec->s_parse.i4_cur_slice_idx--;
 if(ps_codec->s_parse.i4_cur_slice_idx < 0)
                    ps_codec->s_parse.i4_cur_slice_idx = 0;

                ps_slice_hdr_next = ps_codec->s_parse.ps_slice_hdr_base + ((ps_codec->s_parse.i4_cur_slice_idx + 1) & (MAX_SLICE_HDR_CNT - 1));
                ps_slice_hdr_next->i2_ctb_x = 0;
                ps_slice_hdr_next->i2_ctb_y = ps_codec->s_parse.ps_sps->i2_pic_ht_in_ctb;
                ps_codec->i4_slice_error = 1;
 continue;
 }
 }

 
         if(IHEVCD_IGNORE_SLICE == ret)
         {
             ps_codec->pu1_inp_bitsbuf += (nal_ofst + nal_len);
             ps_codec->i4_bytes_remaining -= (nal_ofst + nal_len);
 
 continue;
 }

 if((IVD_RES_CHANGED == ret) ||
 (IHEVCD_UNSUPPORTED_DIMENSIONS == ret))
 {
 break;
 }

 /* Update bytes remaining and bytes consumed and input bitstream pointer */
 /* Do not consume the NAL in the following cases */
 /* Slice header reached during header decode mode */
 /* TODO: Next picture's slice reached */
 if(ret != IHEVCD_SLICE_IN_HEADER_MODE)
 {
 if((0 == ps_codec->i4_slice_error) ||
 (ps_codec->i4_bytes_remaining - (nal_len + nal_ofst) <= MIN_START_CODE_LEN))
 {
                ps_codec->pu1_inp_bitsbuf += (nal_ofst + nal_len);
                ps_codec->i4_bytes_remaining -= (nal_ofst + nal_len);
 }
 if(ret != IHEVCD_SUCCESS)
 break;

 if(ps_codec->s_parse.i4_end_of_frame)
 break;
 }
 else
 {
            ret = IHEVCD_SUCCESS;
 break;
 }

 /* Allocate dynamic bitstream buffer once SPS is decoded */
 if((ps_codec->u4_allocate_dynamic_done == 0) && ps_codec->i4_sps_done)
 {
            WORD32 ret;
            ret = ihevcd_allocate_dynamic_bufs(ps_codec);
 if(ret != IV_SUCCESS)
 {
 /* Free any dynamic buffers that are allocated */
                ihevcd_free_dynamic_bufs(ps_codec);
                ps_codec->i4_error_code = IVD_MEM_ALLOC_FAILED;
                ps_dec_op->u4_error_code |= 1 << IVD_FATALERROR;
                ps_dec_op->u4_error_code |= IVD_MEM_ALLOC_FAILED;

 return IV_FAIL;
 }
 }

        BREAK_AFTER_SLICE_NAL();
 }

 if((ps_codec->u4_pic_cnt == 0) && (ret != IHEVCD_SUCCESS))
 {
        ps_codec->i4_error_code = ret;

        ihevcd_fill_outargs(ps_codec, ps_dec_ip, ps_dec_op);
 return IV_FAIL;
 }

 if(1 == ps_codec->i4_pic_present)
 {
        WORD32 i;
 sps_t *ps_sps = ps_codec->s_parse.ps_sps;
        ps_codec->i4_first_pic_done = 1;

 /*TODO temporary fix: end_of_frame is checked before adding format conversion to job queue         */
 if(ps_codec->i4_num_cores > 1 && ps_codec->s_parse.i4_end_of_frame)
 {

 /* Add job queue for format conversion / frame copy for each ctb row */
 /* Only if the codec is in non-shared mode or in shared mode but needs 420P output */
 process_ctxt_t *ps_proc;

 /* i4_num_cores - 1 contexts are currently being used by other threads */
            ps_proc = &ps_codec->as_process[ps_codec->i4_num_cores - 1];

 if((ps_codec->ps_disp_buf) &&
 ((0 == ps_codec->i4_share_disp_buf) || (IV_YUV_420P == ps_codec->e_chroma_fmt)))
 {
 /* If format conversion jobs were not issued in pic_init() add them here */
 if((0 == ps_codec->u4_enable_fmt_conv_ahead) ||
 (ps_codec->i4_disp_buf_id == ps_proc->i4_cur_pic_buf_id))
 for(i = 0; i < ps_sps->i2_pic_ht_in_ctb; i++)
 {
 proc_job_t s_job;
                        IHEVCD_ERROR_T ret;
                        s_job.i4_cmd = CMD_FMTCONV;
                        s_job.i2_ctb_cnt = 0;
                        s_job.i2_ctb_x = 0;
                        s_job.i2_ctb_y = i;
                        s_job.i2_slice_idx = 0;
                        s_job.i4_tu_coeff_data_ofst = 0;
                        ret = ihevcd_jobq_queue((jobq_t *)ps_codec->s_parse.pv_proc_jobq,
 &s_job, sizeof(proc_job_t), 1);
 if(ret != (IHEVCD_ERROR_T)IHEVCD_SUCCESS)
 return (WORD32)ret;
 }
 }
 /* Reached end of frame : Signal terminate */
 /* The terminate flag is checked only after all the jobs are dequeued */
            ret = ihevcd_jobq_terminate((jobq_t *)ps_codec->s_parse.pv_proc_jobq);

 while(1)
 {
                IHEVCD_ERROR_T ret;
 proc_job_t s_job;
 process_ctxt_t *ps_proc;

 /* i4_num_cores - 1 contexts are currently being used by other threads */
                ps_proc = &ps_codec->as_process[ps_codec->i4_num_cores - 1];

                ret = ihevcd_jobq_dequeue((jobq_t *)ps_proc->pv_proc_jobq, &s_job,
 sizeof(proc_job_t), 1);
 if((IHEVCD_ERROR_T)IHEVCD_SUCCESS != ret)
 break;

                ps_proc->i4_ctb_cnt = s_job.i2_ctb_cnt;
                ps_proc->i4_ctb_x = s_job.i2_ctb_x;
                ps_proc->i4_ctb_y = s_job.i2_ctb_y;
                ps_proc->i4_cur_slice_idx = s_job.i2_slice_idx;

 if(CMD_PROCESS == s_job.i4_cmd)
 {
                    ihevcd_init_proc_ctxt(ps_proc, s_job.i4_tu_coeff_data_ofst);

                    ihevcd_process(ps_proc);
 }
 else if(CMD_FMTCONV == s_job.i4_cmd)
 {
 sps_t *ps_sps = ps_codec->s_parse.ps_sps;
                    WORD32 num_rows = 1 << ps_sps->i1_log2_ctb_size;
 if(0 == ps_proc->i4_init_done)
 {
                        ihevcd_init_proc_ctxt(ps_proc, 0);
 }

                    num_rows = MIN(num_rows, (ps_codec->i4_disp_ht - (s_job.i2_ctb_y << ps_sps->i1_log2_ctb_size)));
 if(num_rows < 0)
                        num_rows = 0;

                    ihevcd_fmt_conv(ps_codec, ps_proc,
                                    ps_dec_ip->s_out_buffer.pu1_bufs[0],
                                    ps_dec_ip->s_out_buffer.pu1_bufs[1],
                                    ps_dec_ip->s_out_buffer.pu1_bufs[2],
                                    s_job.i2_ctb_y << ps_sps->i1_log2_ctb_size,
                                    num_rows);
 }
 }
 }
 /* In case of non-shared mode and while running in single core mode, then convert/copy the frame to output buffer */
 /* Only if the codec is in non-shared mode or in shared mode but needs 420P output */
 else if((ps_codec->ps_disp_buf) && ((0 == ps_codec->i4_share_disp_buf) ||
 (IV_YUV_420P == ps_codec->e_chroma_fmt)) &&
 (ps_codec->s_parse.i4_end_of_frame))
 {
 process_ctxt_t *ps_proc = &ps_codec->as_process[proc_idx];
 /* Set remaining number of rows to be processed */
            ps_codec->s_fmt_conv.i4_num_rows = ps_codec->i4_disp_ht
 - ps_codec->s_fmt_conv.i4_cur_row;
 if(0 == ps_proc->i4_init_done)
 {
                ihevcd_init_proc_ctxt(ps_proc, 0);
 }

 if(ps_codec->s_fmt_conv.i4_num_rows < 0)
                ps_codec->s_fmt_conv.i4_num_rows = 0;

            ret = ihevcd_fmt_conv(ps_codec, ps_proc,
                                  ps_dec_ip->s_out_buffer.pu1_bufs[0],
                                  ps_dec_ip->s_out_buffer.pu1_bufs[1],
                                  ps_dec_ip->s_out_buffer.pu1_bufs[2],
                                  ps_codec->s_fmt_conv.i4_cur_row,
                                  ps_codec->s_fmt_conv.i4_num_rows);
            ps_codec->s_fmt_conv.i4_cur_row += ps_codec->s_fmt_conv.i4_num_rows;

 }


        DEBUG_DUMP_MV_MAP(ps_codec);

 /* Mark MV Buf as needed for reference */
        ihevc_buf_mgr_set_status((buf_mgr_t *)ps_codec->pv_mv_buf_mgr,
                                 ps_codec->as_process[proc_idx].i4_cur_mv_bank_buf_id,
                                 BUF_MGR_REF);

 /* Mark pic buf as needed for reference */
        ihevc_buf_mgr_set_status((buf_mgr_t *)ps_codec->pv_pic_buf_mgr,
                                 ps_codec->as_process[proc_idx].i4_cur_pic_buf_id,
                                 BUF_MGR_REF);

 /* Mark pic buf as needed for display */
        ihevc_buf_mgr_set_status((buf_mgr_t *)ps_codec->pv_pic_buf_mgr,
                                 ps_codec->as_process[proc_idx].i4_cur_pic_buf_id,
                                 BUF_MGR_DISP);

 /* Insert the current picture as short term reference */
        ihevc_dpb_mgr_insert_ref((dpb_mgr_t *)ps_codec->pv_dpb_mgr,
                                 ps_codec->as_process[proc_idx].ps_cur_pic,
                                 ps_codec->as_process[proc_idx].i4_cur_pic_buf_id);

 /* If a frame was displayed (in non-shared mode), then release it from display manager */
 if((0 == ps_codec->i4_share_disp_buf) && (ps_codec->ps_disp_buf))
            ihevc_buf_mgr_release((buf_mgr_t *)ps_codec->pv_pic_buf_mgr,
                                  ps_codec->i4_disp_buf_id, BUF_MGR_DISP);

 /* Wait for threads */
 for(i = 0; i < (ps_codec->i4_num_cores - 1); i++)
 {
 if(ps_codec->ai4_process_thread_created[i])
 {
                ithread_join(ps_codec->apv_process_thread_handle[i], NULL);
                ps_codec->ai4_process_thread_created[i] = 0;
 }
 }

        DEBUG_VALIDATE_PADDED_REGION(&ps_codec->as_process[proc_idx]);
 if(ps_codec->u4_pic_cnt > 0)
 {
            DEBUG_DUMP_PIC_PU(ps_codec);
 }
        DEBUG_DUMP_PIC_BUFFERS(ps_codec);

 /* Increment the number of pictures decoded */
        ps_codec->u4_pic_cnt++;
 }
    ihevcd_fill_outargs(ps_codec, ps_dec_ip, ps_dec_op);

 if(1 == ps_dec_op->u4_output_present)
 {
        WORD32 xpos = ps_codec->i4_disp_wd - 32 - LOGO_WD;
        WORD32 ypos = ps_codec->i4_disp_ht - 32 - LOGO_HT;

 if(ypos < 0)
            ypos = 0;

 if(xpos < 0)
            xpos = 0;

        INSERT_LOGO(ps_dec_ip->s_out_buffer.pu1_bufs[0],
                    ps_dec_ip->s_out_buffer.pu1_bufs[1],
                    ps_dec_ip->s_out_buffer.pu1_bufs[2], ps_codec->i4_disp_strd,
                    xpos,
                    ypos,
                    ps_codec->e_chroma_fmt,
                    ps_codec->i4_disp_wd,
                    ps_codec->i4_disp_ht);
 }


 return ret;
}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: IMPEG2D_ERROR_CODES_T impeg2d_init_video_state(dec_state_t *ps_dec, e_video_type_t e_video_type)
{
 /*-----------------------------------------------------------------------*/
 /* Bit Stream  that conforms to MPEG-1 <ISO/IEC 11172-2> standard        */
 /*-----------------------------------------------------------------------*/
 if(e_video_type == MPEG_1_VIDEO)
 {
        ps_dec->u2_is_mpeg2 = 0;

 /*-------------------------------------------------------------------*/
 /* force MPEG-1 parameters for proper decoder behavior               */
 /* see ISO/IEC 13818-2 section D.9.14                                */
 /*-------------------------------------------------------------------*/
        ps_dec->u2_progressive_sequence         = 1;
        ps_dec->u2_intra_dc_precision           = 0;
        ps_dec->u2_picture_structure            = FRAME_PICTURE;
        ps_dec->u2_frame_pred_frame_dct         = 1;
        ps_dec->u2_concealment_motion_vectors   = 0;
        ps_dec->u2_q_scale_type                 = 0;
        ps_dec->u2_intra_vlc_format             = 0;
        ps_dec->u2_alternate_scan               = 0;
        ps_dec->u2_repeat_first_field           = 0;
        ps_dec->u2_progressive_frame            = 1;
        ps_dec->u2_frame_rate_extension_n       = 0;
        ps_dec->u2_frame_rate_extension_d       = 0;

        ps_dec->pf_vld_inv_quant                  = impeg2d_vld_inv_quant_mpeg1;
 /*-------------------------------------------------------------------*/
 /* Setting of parameters other than those mentioned in MPEG2 standard*/
 /* but used in decoding process.                                     */
 /*-------------------------------------------------------------------*/
 }
 /*-----------------------------------------------------------------------*/
 /* Bit Stream  that conforms to MPEG-2                                   */
 /*-----------------------------------------------------------------------*/
 else
 {
        ps_dec->u2_is_mpeg2                  = 1;
        ps_dec->u2_full_pel_forw_vector   = 0;
        ps_dec->u2_forw_f_code            = 7;
        ps_dec->u2_full_pel_back_vector   = 0;
        ps_dec->u2_back_f_code            = 7;
        ps_dec->pf_vld_inv_quant       = impeg2d_vld_inv_quant_mpeg2;


 }


    impeg2d_init_function_ptr(ps_dec);

 /* Set the frame Width and frame Height */
    ps_dec->u2_frame_height        = ALIGN16(ps_dec->u2_vertical_size);
    ps_dec->u2_frame_width         = ALIGN16(ps_dec->u2_horizontal_size);
    ps_dec->u2_num_horiz_mb         = (ps_dec->u2_horizontal_size + 15) >> 4;
 if (ps_dec->u2_frame_height > ps_dec->u2_create_max_height || ps_dec->u2_frame_width > ps_dec->u2_create_max_width)
 {
 return IMPEG2D_PIC_SIZE_NOT_SUPPORTED;
 }

    ps_dec->u2_num_flds_decoded = 0;

 /* Calculate the frame period */
 {
        UWORD32 numer;
        UWORD32 denom;
        numer = (UWORD32)gau2_impeg2_frm_rate_code[ps_dec->u2_frame_rate_code][1] *
 (UWORD32)(ps_dec->u2_frame_rate_extension_d + 1);

        denom = (UWORD32)gau2_impeg2_frm_rate_code[ps_dec->u2_frame_rate_code][0] *
 (UWORD32)(ps_dec->u2_frame_rate_extension_n + 1);
        ps_dec->u2_framePeriod = (numer * 1000 * 100) / denom;
 }


 if(VERTICAL_SCAN == ps_dec->u2_alternate_scan)
 {
    ps_dec->pu1_inv_scan_matrix = (UWORD8 *)gau1_impeg2_inv_scan_vertical;
 }
 else
 {
    ps_dec->pu1_inv_scan_matrix = (UWORD8 *)gau1_impeg2_inv_scan_zig_zag;
 }
 return (IMPEG2D_ERROR_CODES_T)IVD_ERROR_NONE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: VOID ixheaacd_shiftrountine(WORD32 *qmf_real, WORD32 *qmf_imag, WORD32 len,
                            WORD32 common_shift) {
  WORD32 treal, timag;
  WORD32 j;

 if (common_shift < 0) {
    WORD32 cshift = -common_shift;
    cshift = ixheaacd_min32(cshift, 31);
 for (j = len - 1; j >= 0; j--) {
      treal = *qmf_real;
      timag = *qmf_imag;

      treal = (ixheaacd_shr32(treal, cshift));
      timag = (ixheaacd_shr32(timag, cshift));

 *qmf_real++ = treal;
 *qmf_imag++ = timag;
 }
 } else {
 for (j = len - 1; j >= 0; j--) {
      treal = (ixheaacd_shl32_sat(*qmf_real, common_shift));
      timag = (ixheaacd_shl32_sat(*qmf_imag, common_shift));
 *qmf_real++ = treal;
 *qmf_imag++ = timag;
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void lbl_destroy()
{
    pthread_mutex_destroy(&(device.lbllock));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ATSParser::feedTSPacket(const void *data, size_t size,
 SyncEvent *event) {
 if (size != kTSPacketSize) {
        ALOGE("Wrong TS packet size");
 return BAD_VALUE;
 }

 ABitReader br((const uint8_t *)data, kTSPacketSize);
 return parseTS(&br, event);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int Downmix_Command(effect_handle_t self, uint32_t cmdCode, uint32_t cmdSize,
 void *pCmdData, uint32_t *replySize, void *pReplyData) {

 downmix_module_t *pDwmModule = (downmix_module_t *) self;
 downmix_object_t *pDownmixer;

 if (pDwmModule == NULL || pDwmModule->context.state == DOWNMIX_STATE_UNINITIALIZED) {
 return -EINVAL;
 }

    pDownmixer = (downmix_object_t*) &pDwmModule->context;

    ALOGV("Downmix_Command command %" PRIu32 " cmdSize %" PRIu32, cmdCode, cmdSize);

 switch (cmdCode) {
 case EFFECT_CMD_INIT:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 *(int *) pReplyData = Downmix_Init(pDwmModule);
 break;

 case EFFECT_CMD_SET_CONFIG:
 if (pCmdData == NULL || cmdSize != sizeof(effect_config_t)
 || pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 *(int *) pReplyData = Downmix_Configure(pDwmModule,
 (effect_config_t *)pCmdData, false);
 break;

 case EFFECT_CMD_RESET:
 Downmix_Reset(pDownmixer, false);
 break;

 case EFFECT_CMD_GET_PARAM:
        ALOGV("Downmix_Command EFFECT_CMD_GET_PARAM pCmdData %p, *replySize %" PRIu32 ", pReplyData: %p",
                pCmdData, *replySize, pReplyData);
 if (pCmdData == NULL || cmdSize < (int)(sizeof(effect_param_t) + sizeof(int32_t)) ||
                pReplyData == NULL || replySize == NULL ||
 *replySize < (int) sizeof(effect_param_t) + 2 * sizeof(int32_t)) {
 return -EINVAL;
 }
 effect_param_t *rep = (effect_param_t *) pReplyData;
        memcpy(pReplyData, pCmdData, sizeof(effect_param_t) + sizeof(int32_t));
        ALOGV("Downmix_Command EFFECT_CMD_GET_PARAM param %" PRId32 ", replySize %" PRIu32,
 *(int32_t *)rep->data, rep->vsize);
        rep->status = Downmix_getParameter(pDownmixer, *(int32_t *)rep->data, &rep->vsize,
                rep->data + sizeof(int32_t));
 *replySize = sizeof(effect_param_t) + sizeof(int32_t) + rep->vsize;
 break;

 case EFFECT_CMD_SET_PARAM:
        ALOGV("Downmix_Command EFFECT_CMD_SET_PARAM cmdSize %d pCmdData %p, *replySize %" PRIu32
 ", pReplyData %p", cmdSize, pCmdData, *replySize, pReplyData);
 if (pCmdData == NULL || (cmdSize < (int)(sizeof(effect_param_t) + sizeof(int32_t)))
 || pReplyData == NULL || replySize == NULL || *replySize != (int)sizeof(int32_t)) {

             return -EINVAL;
         }
         effect_param_t *cmd = (effect_param_t *) pCmdData;
         *(int *)pReplyData = Downmix_setParameter(pDownmixer, *(int32_t *)cmd->data,
                 cmd->vsize, cmd->data + sizeof(int32_t));
         break;

 case EFFECT_CMD_SET_PARAM_DEFERRED:
        ALOGW("Downmix_Command command EFFECT_CMD_SET_PARAM_DEFERRED not supported, FIXME");
 break;

 case EFFECT_CMD_SET_PARAM_COMMIT:
        ALOGW("Downmix_Command command EFFECT_CMD_SET_PARAM_COMMIT not supported, FIXME");
 break;

 case EFFECT_CMD_ENABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 if (pDownmixer->state != DOWNMIX_STATE_INITIALIZED) {
 return -ENOSYS;
 }
        pDownmixer->state = DOWNMIX_STATE_ACTIVE;
        ALOGV("EFFECT_CMD_ENABLE() OK");
 *(int *)pReplyData = 0;
 break;

 case EFFECT_CMD_DISABLE:
 if (pReplyData == NULL || replySize == NULL || *replySize != sizeof(int)) {
 return -EINVAL;
 }
 if (pDownmixer->state != DOWNMIX_STATE_ACTIVE) {
 return -ENOSYS;
 }
        pDownmixer->state = DOWNMIX_STATE_INITIALIZED;
        ALOGV("EFFECT_CMD_DISABLE() OK");
 *(int *)pReplyData = 0;
 break;

 case EFFECT_CMD_SET_DEVICE:
 if (pCmdData == NULL || cmdSize != (int)sizeof(uint32_t)) {
 return -EINVAL;
 }
        ALOGV("Downmix_Command EFFECT_CMD_SET_DEVICE: 0x%08" PRIx32, *(uint32_t *)pCmdData);
 break;

 case EFFECT_CMD_SET_VOLUME: {
 if (pCmdData == NULL || cmdSize != (int)sizeof(uint32_t) * 2) {
 return -EINVAL;
 }
        ALOGW("Downmix_Command command EFFECT_CMD_SET_VOLUME not supported, FIXME");
 float left = (float)(*(uint32_t *)pCmdData) / (1 << 24);
 float right = (float)(*((uint32_t *)pCmdData + 1)) / (1 << 24);
        ALOGV("Downmix_Command EFFECT_CMD_SET_VOLUME: left %f, right %f ", left, right);
 break;
 }

 case EFFECT_CMD_SET_AUDIO_MODE:
 if (pCmdData == NULL || cmdSize != (int)sizeof(uint32_t)) {
 return -EINVAL;
 }
        ALOGV("Downmix_Command EFFECT_CMD_SET_AUDIO_MODE: %" PRIu32, *(uint32_t *)pCmdData);
 break;

 case EFFECT_CMD_SET_CONFIG_REVERSE:
 case EFFECT_CMD_SET_INPUT_DEVICE:
 break;

 default:
        ALOGW("Downmix_Command invalid command %" PRIu32, cmdCode);
 return -EINVAL;
 }

 return 0;
}

Labels: Yes
----------------lora model----------------
Response: bool Downmix_Command(effect_handle_t self, uint32_t cmdCode, uint32_t cmdSize,
 void *pCmdData, uint32_t *replySize, void *pReplyData) {
    ALOGV("Downmix_Command cmdCode %" PRIu32, cmdCode);

    downmix_module_t *pDwmModule = (downmix_module_t *) self;

 switch (cmdCode) {
 case EFFECT_CMD_INIT:
            ALOGV("Downmix_Command EFFECT_CMD_INIT");
 break;

 case EFFECT_CMD_SET_PARAM:
            ALOGV("Downmix_Command EFFECT_CMD_SET_PARAM");
 break;

 case EFFECT_CMD_GET_PARAM:
            ALOGV("Downmix_Command EFFECT_CMD_GET_PARAM");
 break;

 case EFFECT_CMD_SET_PARAM_DEFERRED:
            ALOGW("Downmix_Command EFF


Instruction: 
Input: void ih264d_free_ref_pic_mv_bufs(void* pv_dec, UWORD8 pic_buf_id)
{
 dec_struct_t *ps_dec = (dec_struct_t *)pv_dec;

 if((pic_buf_id == ps_dec->u1_pic_buf_id) &&
                    ps_dec->ps_cur_slice->u1_field_pic_flag &&
 (ps_dec->u1_top_bottom_decoded == 0))
 {
 return;
 }

    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_pic_buf_mgr,
                          pic_buf_id,
                          BUF_MGR_REF);
    ih264_buf_mgr_release((buf_mgr_t *)ps_dec->pv_mv_buf_mgr,
                          ps_dec->au1_pic_buf_id_mv_buf_id_map[pic_buf_id],
                          BUF_MGR_REF);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_color_align(OMX_BUFFERHEADERTYPE *buffer,
        OMX_U32 width, OMX_U32 height)
{
    OMX_U32 y_stride = VENUS_Y_STRIDE(COLOR_FMT_NV12, width),
            y_scanlines = VENUS_Y_SCANLINES(COLOR_FMT_NV12, height),
            uv_stride = VENUS_UV_STRIDE(COLOR_FMT_NV12, width),
            uv_scanlines = VENUS_UV_SCANLINES(COLOR_FMT_NV12, height),
            src_chroma_offset = width * height;

 if (buffer->nAllocLen >= VENUS_BUFFER_SIZE(COLOR_FMT_NV12, width, height)) {
        OMX_U8* src_buf = buffer->pBuffer, *dst_buf = buffer->pBuffer;
        src_buf += width * height;
        dst_buf += y_stride * y_scanlines;
 for (int line = height / 2 - 1; line >= 0; --line) {
            memmove(dst_buf + line * uv_stride,
                    src_buf + line * width,
                    width);
 }

        dst_buf = src_buf = buffer->pBuffer;
 for (int line = height - 1; line > 0; --line) {
            memmove(dst_buf + line * y_stride,
                    src_buf + line * width,
                    width);
 }
 } else {
        DEBUG_PRINT_ERROR("Failed to align Chroma. from %u to %u : \
 Insufficient bufferLen=%u v/s Required=%u",
 (unsigned int)(width*height), (unsigned int)src_chroma_offset, (unsigned int)buffer->nAllocLen,
                VENUS_BUFFER_SIZE(COLOR_FMT_NV12, width, height));
 return false;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int xmlSAXUserParseMemory(xmlSAXHandlerPtr sax, void *user_data,
 const char *buffer, int size) {
 int ret = 0;
    xmlParserCtxtPtr ctxt;

    xmlInitParser();

    ctxt = xmlCreateMemoryParserCtxt(buffer, size);
 if (ctxt == NULL) return -1;
 if (ctxt->sax != (xmlSAXHandlerPtr) &xmlDefaultSAXHandler)
        xmlFree(ctxt->sax);
    ctxt->sax = sax;
    xmlDetectSAX2(ctxt);

 if (user_data != NULL)
	ctxt->userData = user_data;

    xmlParseDocument(ctxt);

 if (ctxt->wellFormed)
	ret = 0;
 else {
 if (ctxt->errNo != 0)
	    ret = ctxt->errNo;
 else
	    ret = -1;
 }
 if (sax != NULL)
        ctxt->sax = NULL;
 if (ctxt->myDoc != NULL) {
        xmlFreeDoc(ctxt->myDoc);
	ctxt->myDoc = NULL;
 }
    xmlFreeParserCtxt(ctxt);

 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void png_fixed_warning(png_const_structrp png_ptr, png_const_charp msg)
{
   fprintf(stderr, "overflow in: %s\n", msg);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t OMXCodec::waitForBufferFilled_l() {

 if (mIsEncoder) {
 return mBufferFilled.wait(mLock);
 }
 status_t err = mBufferFilled.waitRelative(mLock, kBufferFilledEventTimeOutNs);
 if (err != OK) {
        CODEC_LOGE("Timed out waiting for output buffers: %zu/%zu",
            countBuffersWeOwn(mPortBuffers[kPortIndexInput]),
            countBuffersWeOwn(mPortBuffers[kPortIndexOutput]));
 }
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::LoadedState::onShutdown(bool keepComponentAllocated) {
 if (!keepComponentAllocated) {
 (void)mCodec->mOMX->freeNode(mCodec->mNode);

        mCodec->changeState(mCodec->mUninitializedState);
 }

 if (mCodec->mExplicitShutdown) {
        sp<AMessage> notify = mCodec->mNotify->dup();
        notify->setInt32("what", CodecBase::kWhatShutdownCompleted);
        notify->post();
        mCodec->mExplicitShutdown = false;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: media_status_t AMediaCodec_signalEndOfInputStream(AMediaCodec *mData) {

 if (mData == NULL) {
 return AMEDIA_ERROR_INVALID_PARAMETER;
 }

 status_t err = mData->mCodec->signalEndOfInputStream();
 if (err == INVALID_OPERATION) {
 return AMEDIA_ERROR_INVALID_OPERATION;
 }

 return translate_error(err);

}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_vdec::fill_this_buffer(OMX_IN OMX_HANDLETYPE  hComp,
        OMX_IN OMX_BUFFERHEADERTYPE* buffer)
{
 unsigned nPortIndex = 0;
 if (dynamic_buf_mode) {
 private_handle_t *handle = NULL;
 struct VideoDecoderOutputMetaData *meta;
 unsigned int nPortIndex = 0;

 if (!buffer || !buffer->pBuffer) {
            DEBUG_PRINT_ERROR("%s: invalid params: %p", __FUNCTION__, buffer);
 return OMX_ErrorBadParameter;
 }

        meta = (struct VideoDecoderOutputMetaData *)buffer->pBuffer;
        handle = (private_handle_t *)meta->pHandle;
        DEBUG_PRINT_LOW("FTB: metabuf: %p buftype: %d bufhndl: %p ", meta, meta->eType, meta->pHandle);

 if (!handle) {
            DEBUG_PRINT_ERROR("FTB: Error: IL client passed an invalid buf handle - %p", handle);
 return OMX_ErrorBadParameter;
 }

        nPortIndex = buffer-((OMX_BUFFERHEADERTYPE *)client_buffers.get_il_buf_hdr());
        drv_ctx.ptr_outputbuffer[nPortIndex].pmem_fd = handle->fd;
        drv_ctx.ptr_outputbuffer[nPortIndex].bufferaddr = (OMX_U8*) buffer;

        native_buffer[nPortIndex].privatehandle = handle;
        native_buffer[nPortIndex].nativehandle = handle;

        buffer->nFilledLen = 0;
        buffer->nAllocLen = handle->size;
 }


 if (m_state == OMX_StateInvalid) {
        DEBUG_PRINT_ERROR("FTB in Invalid State");
 return OMX_ErrorInvalidState;
 }

 if (!m_out_bEnabled) {
        DEBUG_PRINT_ERROR("ERROR:FTB incorrect state operation, output port is disabled.");
 return OMX_ErrorIncorrectStateOperation;
 }

    nPortIndex = buffer - client_buffers.get_il_buf_hdr();
 if (buffer == NULL ||
 (nPortIndex >= drv_ctx.op_buf.actualcount)) {
        DEBUG_PRINT_ERROR("FTB: ERROR: invalid buffer index, nPortIndex %u bufCount %u",
            nPortIndex, drv_ctx.op_buf.actualcount);
 return OMX_ErrorBadParameter;
 }

 if (buffer->nOutputPortIndex != OMX_CORE_OUTPUT_PORT_INDEX) {
        DEBUG_PRINT_ERROR("ERROR:FTB invalid port in header %u", (unsigned int)buffer->nOutputPortIndex);
 return OMX_ErrorBadPortIndex;
 }

    DEBUG_PRINT_LOW("[FTB] bufhdr = %p, bufhdr->pBuffer = %p", buffer, buffer->pBuffer);
    post_event((unsigned long) hComp, (unsigned long)buffer, m_fill_output_msg);
 return OMX_ErrorNone;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Block* BlockGroup::GetBlock() const
{
    return &m_block;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: IPCThreadState* IPCThreadState::self()
{
 if (gHaveTLS) {
restart:
 const pthread_key_t k = gTLS;
 IPCThreadState* st = (IPCThreadState*)pthread_getspecific(k);
 if (st) return st;
 return new IPCThreadState;
 }
 
 if (gShutdown) return NULL;
 
    pthread_mutex_lock(&gTLSMutex);
 if (!gHaveTLS) {
 if (pthread_key_create(&gTLS, threadDestructor) != 0) {
            pthread_mutex_unlock(&gTLSMutex);
 return NULL;
 }
        gHaveTLS = true;
 }
    pthread_mutex_unlock(&gTLSMutex);
 goto restart;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  virtual status_t setTransformHint(uint32_t hint) {
 Parcel data, reply;
        data.writeInterfaceToken(IGraphicBufferConsumer::getInterfaceDescriptor());
        data.writeUint32(hint);
 status_t result = remote()->transact(SET_TRANSFORM_HINT, data, &reply);
 if (result != NO_ERROR) {
 return result;
 }
 return reply.readInt32();
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_av_move_idle(RawAddress bd_addr) {
 /* inform the application that ACL is disconnected and move to idle state */
 btif_sm_state_t state = btif_sm_get_state(btif_av_cb.sm_handle);
  BTIF_TRACE_WARNING("%s: ACL Disconnected state %d bd_addr=%s peer_bda=%s",
                     __func__, state, bd_addr.ToString().c_str(),
                     btif_av_cb.peer_bda.ToString().c_str());

 if (state == BTIF_AV_STATE_OPENING && (bd_addr == btif_av_cb.peer_bda)) {
    BTIF_TRACE_DEBUG(
 "%s: Moving State from Opening to Idle due to ACL disconnect",
        __func__);
    btif_report_connection_state(BTAV_CONNECTION_STATE_DISCONNECTED,
 &(btif_av_cb.peer_bda));
    btif_sm_change_state(btif_av_cb.sm_handle, BTIF_AV_STATE_IDLE);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long CuePoint::GetTimeCode() const
{
    return m_timecode;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: size_t IGraphicBufferProducer::QueueBufferInput::getFdCount() const {
 return fence->getFdCount();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long BlockGroup::Parse() {
 const long status = m_block.Parse(m_pCluster);

 if (status)
 return status;

  m_block.SetKey((m_prev > 0) && (m_next <= 0));


   return 0;
 }

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: WORD32 ih264d_insert_pic_in_display_list(dpb_manager_t *ps_dpb_mgr,
                                         UWORD8 u1_buf_id,
                                         WORD32 i4_display_poc,
                                         UWORD32 u4_frame_num)
{
    WORD8 i;
    WORD32 (*i4_poc_buf_id_map)[3] = ps_dpb_mgr->ai4_poc_buf_id_map;

 for(i = 0; i < MAX_FRAMES; i++)
 {
 /* Find an empty slot */
 if(i4_poc_buf_id_map[i][0] == -1)
 {
 if(GAP_FRAME_NUM == i4_poc_buf_id_map[i][2])
                ps_dpb_mgr->i1_gaps_deleted--;
 else
                ps_dpb_mgr->i1_poc_buf_id_entries++;

            i4_poc_buf_id_map[i][0] = u1_buf_id;
            i4_poc_buf_id_map[i][1] = i4_display_poc;
            i4_poc_buf_id_map[i][2] = u4_frame_num;

 break;
 }
 }

 if(MAX_FRAMES == i)
 {

        UWORD32 i4_error_code;
        i4_error_code = ERROR_GAPS_IN_FRM_NUM;
 return i4_error_code;
 }
 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void btif_disable_bluetooth_evt(void)
{
    BTIF_TRACE_DEBUG("%s", __FUNCTION__);

#if (defined(HCILP_INCLUDED) && HCILP_INCLUDED == TRUE)
    bte_main_enable_lpm(FALSE);
#endif

#if (BLE_INCLUDED == TRUE)
     BTA_VendorCleanup();
#endif

     bte_main_disable();

 /* callback to HAL */
    future_ready(stack_manager_get_hack_future(), FUTURE_SUCCESS);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_subframe_lpc_(FLAC__StreamDecoder *decoder, unsigned channel, unsigned bps, const unsigned order, FLAC__bool do_full_decode)
{
	FLAC__Subframe_LPC *subframe = &decoder->private_->frame.subframes[channel].data.lpc;
	FLAC__int32 i32;
	FLAC__uint32 u32;
 unsigned u;

	decoder->private_->frame.subframes[channel].type = FLAC__SUBFRAME_TYPE_LPC;

	subframe->residual = decoder->private_->residual[channel];
	subframe->order = order;

 /* read warm-up samples */
 for(u = 0; u < order; u++) {
 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i32, bps))
 return false; /* read_callback_ sets the state for us */
		subframe->warmup[u] = i32;
 }

 /* read qlp coeff precision */
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &u32, FLAC__SUBFRAME_LPC_QLP_COEFF_PRECISION_LEN))
 return false; /* read_callback_ sets the state for us */
 if(u32 == (1u << FLAC__SUBFRAME_LPC_QLP_COEFF_PRECISION_LEN) - 1) {
		send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_LOST_SYNC);
		decoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;
 return true;
 }
	subframe->qlp_coeff_precision = u32+1;

 /* read qlp shift */
 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i32, FLAC__SUBFRAME_LPC_QLP_SHIFT_LEN))
 return false; /* read_callback_ sets the state for us */
	subframe->quantization_level = i32;

 /* read quantized lp coefficiencts */
 for(u = 0; u < order; u++) {
 if(!FLAC__bitreader_read_raw_int32(decoder->private_->input, &i32, subframe->qlp_coeff_precision))
 return false; /* read_callback_ sets the state for us */
		subframe->qlp_coeff[u] = i32;
 }

 /* read entropy coding method info */
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &u32, FLAC__ENTROPY_CODING_METHOD_TYPE_LEN))
 return false; /* read_callback_ sets the state for us */
	subframe->entropy_coding_method.type = (FLAC__EntropyCodingMethodType)u32;
 switch(subframe->entropy_coding_method.type) {
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE:
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2:
 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &u32, FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE_ORDER_LEN))
 return false; /* read_callback_ sets the state for us */
			subframe->entropy_coding_method.data.partitioned_rice.order = u32;
			subframe->entropy_coding_method.data.partitioned_rice.contents = &decoder->private_->partitioned_rice_contents[channel];
 break;
 default:
			send_error_to_client_(decoder, FLAC__STREAM_DECODER_ERROR_STATUS_UNPARSEABLE_STREAM);
			decoder->protected_->state = FLAC__STREAM_DECODER_SEARCH_FOR_FRAME_SYNC;
 return true;
 }

 /* read residual */
 switch(subframe->entropy_coding_method.type) {
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE:
 case FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2:
 if(!read_residual_partitioned_rice_(decoder, order, subframe->entropy_coding_method.data.partitioned_rice.order, &decoder->private_->partitioned_rice_contents[channel], decoder->private_->residual[channel], /*is_extended=*/subframe->entropy_coding_method.type == FLAC__ENTROPY_CODING_METHOD_PARTITIONED_RICE2))
 return false;
 break;
 default:
			FLAC__ASSERT(0);
 }

 /* decode the subframe */
 if(do_full_decode) {
		memcpy(decoder->private_->output[channel], subframe->warmup, sizeof(FLAC__int32) * order);
 /*@@@@@@ technically not pessimistic enough, should be more like
		if( (FLAC__uint64)order * ((((FLAC__uint64)1)<<bps)-1) * ((1<<subframe->qlp_coeff_precision)-1) < (((FLAC__uint64)-1) << 32) )
		*/
 if(bps + subframe->qlp_coeff_precision + FLAC__bitmath_ilog2(order) <= 32)
 if(bps <= 16 && subframe->qlp_coeff_precision <= 16)
				decoder->private_->local_lpc_restore_signal_16bit(decoder->private_->residual[channel], decoder->private_->frame.header.blocksize-order, subframe->qlp_coeff, order, subframe->quantization_level, decoder->private_->output[channel]+order);
 else
				decoder->private_->local_lpc_restore_signal(decoder->private_->residual[channel], decoder->private_->frame.header.blocksize-order, subframe->qlp_coeff, order, subframe->quantization_level, decoder->private_->output[channel]+order);
 else
			decoder->private_->local_lpc_restore_signal_64bit(decoder->private_->residual[channel], decoder->private_->frame.header.blocksize-order, subframe->qlp_coeff, order, subframe->quantization_level, decoder->private_->output[channel]+order);
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int validate_camera_metadata_structure(const camera_metadata_t *metadata,
 const size_t *expected_size) {

 if (metadata == NULL) {
        ALOGE("%s: metadata is null!", __FUNCTION__);
 return ERROR;
 }

 {
 static const struct {
 const char *name;
 size_t alignment;
 } alignments[] = {
 {
 .name = "camera_metadata",
 .alignment = METADATA_ALIGNMENT
 },
 {
 .name = "camera_metadata_buffer_entry",
 .alignment = ENTRY_ALIGNMENT
 },
 {
 .name = "camera_metadata_data",
 .alignment = DATA_ALIGNMENT
 },
 };

 for (size_t i = 0; i < sizeof(alignments)/sizeof(alignments[0]); ++i) {
 uintptr_t aligned_ptr = ALIGN_TO(metadata, alignments[i].alignment);

 if ((uintptr_t)metadata != aligned_ptr) {
                ALOGE("%s: Metadata pointer is not aligned (actual %p, "
 "expected %p) to type %s",
                      __FUNCTION__, metadata,
 (void*)aligned_ptr, alignments[i].name);
 return ERROR;
 }
 }
 }

 /**
     * Check that the metadata contents are correct
     */

 if (expected_size != NULL && metadata->size > *expected_size) {
        ALOGE("%s: Metadata size (%" PRIu32 ") should be <= expected size (%zu)",
              __FUNCTION__, metadata->size, *expected_size);
 return ERROR;
 }

 if (metadata->entry_count > metadata->entry_capacity) {
        ALOGE("%s: Entry count (%" PRIu32 ") should be <= entry capacity "
 "(%" PRIu32 ")",
              __FUNCTION__, metadata->entry_count, metadata->entry_capacity);

         return ERROR;
     }
 
    const metadata_uptrdiff_t entries_end =
        metadata->entries_start + metadata->entry_capacity;
     if (entries_end < metadata->entries_start || // overflow check
         entries_end > metadata->data_start) {
 
        ALOGE("%s: Entry start + capacity (%" PRIu32 ") should be <= data start "
 "(%" PRIu32 ")",
               __FUNCTION__,
 (metadata->entries_start + metadata->entry_capacity),
              metadata->data_start);
 return ERROR;
 }

 const metadata_uptrdiff_t data_end =
        metadata->data_start + metadata->data_capacity;
 if (data_end < metadata->data_start || // overflow check
        data_end > metadata->size) {

        ALOGE("%s: Data start + capacity (%" PRIu32 ") should be <= total size "
 "(%" PRIu32 ")",
               __FUNCTION__,
 (metadata->data_start + metadata->data_capacity),
              metadata->size);
 return ERROR;
 }

 const metadata_size_t entry_count = metadata->entry_count;
 camera_metadata_buffer_entry_t *entries = get_entries(metadata);

 for (size_t i = 0; i < entry_count; ++i) {

 if ((uintptr_t)&entries[i] != ALIGN_TO(&entries[i], ENTRY_ALIGNMENT)) {
            ALOGE("%s: Entry index %zu had bad alignment (address %p),"
 " expected alignment %zu",
                  __FUNCTION__, i, &entries[i], ENTRY_ALIGNMENT);
 return ERROR;
 }

 camera_metadata_buffer_entry_t entry = entries[i];

 if (entry.type >= NUM_TYPES) {
            ALOGE("%s: Entry index %zu had a bad type %d",
                  __FUNCTION__, i, entry.type);
 return ERROR;
 }

 uint32_t tag_section = entry.tag >> 16;
 int tag_type = get_camera_metadata_tag_type(entry.tag);
 if (tag_type != (int)entry.type && tag_section < VENDOR_SECTION) {
            ALOGE("%s: Entry index %zu had tag type %d, but the type was %d",
                  __FUNCTION__, i, tag_type, entry.type);
 return ERROR;
 }

 size_t data_size;
 if (validate_and_calculate_camera_metadata_entry_data_size(&data_size, entry.type,
                entry.count) != OK) {
            ALOGE("%s: Entry data size is invalid. type: %u count: %u", __FUNCTION__, entry.type,
                    entry.count);
 return ERROR;
 }

 if (data_size != 0) {
 camera_metadata_data_t *data =
 (camera_metadata_data_t*) (get_data(metadata) +
                                               entry.data.offset);

 if ((uintptr_t)data != ALIGN_TO(data, DATA_ALIGNMENT)) {
                ALOGE("%s: Entry index %zu had bad data alignment (address %p),"
 " expected align %zu, (tag name %s, data size %zu)",
                      __FUNCTION__, i, data, DATA_ALIGNMENT,
                      get_camera_metadata_tag_name(entry.tag) ?: "unknown",
                      data_size);
 return ERROR;
 }

 size_t data_entry_end = entry.data.offset + data_size;
 if (data_entry_end < entry.data.offset || // overflow check
                data_entry_end > metadata->data_capacity) {

                ALOGE("%s: Entry index %zu data ends (%zu) beyond the capacity "
 "%" PRIu32, __FUNCTION__, i, data_entry_end,
                      metadata->data_capacity);
 return ERROR;
 }

 } else if (entry.count == 0) {
 if (entry.data.offset != 0) {
                ALOGE("%s: Entry index %zu had 0 items, but offset was non-0 "
 "(%" PRIu32 "), tag name: %s", __FUNCTION__, i, entry.data.offset,
                        get_camera_metadata_tag_name(entry.tag) ?: "unknown");
 return ERROR;
 }
 } // else data stored inline, so we look at value which can be anything.
 }

 return OK;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool ASessionDescription::setTo(const void *data, size_t size) {
    mIsValid = parse(data, size);

 if (!mIsValid) {
        mTracks.clear();
        mFormats.clear();
 }

 return mIsValid;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXCodec::setAMRFormat(bool isWAMR, int32_t bitRate) {
    OMX_U32 portIndex = mIsEncoder ? kPortIndexOutput : kPortIndexInput;

    OMX_AUDIO_PARAM_AMRTYPE def;
 InitOMXParams(&def);
    def.nPortIndex = portIndex;

 status_t err =
        mOMX->getParameter(mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));

    CHECK_EQ(err, (status_t)OK);

    def.eAMRFrameFormat = OMX_AUDIO_AMRFrameFormatFSF;

    def.eAMRBandMode = pickModeFromBitRate(isWAMR, bitRate);
    err = mOMX->setParameter(mNode, OMX_IndexParamAudioAmr, &def, sizeof(def));
    CHECK_EQ(err, (status_t)OK);


 if (mIsEncoder) {
        sp<MetaData> format = mSource->getFormat();
 int32_t sampleRate;
 int32_t numChannels;
        CHECK(format->findInt32(kKeySampleRate, &sampleRate));
        CHECK(format->findInt32(kKeyChannelCount, &numChannels));

        setRawAudioFormat(kPortIndexInput, sampleRate, numChannels);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: Track::~Track() {
 Info& info = const_cast<Info&>(m_info);
  info.Clear();

 ContentEncoding** i = content_encoding_entries_;
 ContentEncoding** const j = content_encoding_entries_end_;

 while (i != j) {
 ContentEncoding* const encoding = *i++;
 delete encoding;
 }

 delete[] content_encoding_entries_;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: modifier_color_encoding_is_sRGB(PNG_CONST png_modifier *pm)
 {
    return pm->current_encoding != 0 && pm->current_encoding == pm->encodings &&
       pm->current_encoding->gamma == pm->current_gamma;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: status_t BufferQueueConsumer::setMaxAcquiredBufferCount(
 int maxAcquiredBuffers) {
    ATRACE_CALL();

 if (maxAcquiredBuffers < 1 ||
            maxAcquiredBuffers > BufferQueueCore::MAX_MAX_ACQUIRED_BUFFERS) {
        BQ_LOGE("setMaxAcquiredBufferCount: invalid count %d",
                maxAcquiredBuffers);
 return BAD_VALUE;
 }

 Mutex::Autolock lock(mCore->mMutex);

 if (mCore->mConnectedApi != BufferQueueCore::NO_CONNECTED_API) {
        BQ_LOGE("setMaxAcquiredBufferCount: producer is already connected");
 return INVALID_OPERATION;
 }

    BQ_LOGV("setMaxAcquiredBufferCount: %d", maxAcquiredBuffers);
    mCore->mMaxAcquiredBufferCount = maxAcquiredBuffers;
 return NO_ERROR;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC_API FLAC__bool FLAC__stream_decoder_set_metadata_respond_all(FLAC__StreamDecoder *decoder)
{
 unsigned i;
	FLAC__ASSERT(0 != decoder);
	FLAC__ASSERT(0 != decoder->private_);
	FLAC__ASSERT(0 != decoder->protected_);
 if(decoder->protected_->state != FLAC__STREAM_DECODER_UNINITIALIZED)
 return false;
 for(i = 0; i < sizeof(decoder->private_->metadata_filter) / sizeof(decoder->private_->metadata_filter[0]); i++)
		decoder->private_->metadata_filter[i] = true;
	decoder->private_->metadata_filter_ids_count = 0;
 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t Parcel::getBlobAshmemSize() const
{
 return mOpenAshmemSize;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void execute_storage_request(UINT16 event, char *p_param)
{
 bt_status_t status = BT_STATUS_SUCCESS;

    BTIF_TRACE_EVENT("execute storage request event : %d", event);

 switch(event)
 {
 case BTIF_CORE_STORAGE_ADAPTER_WRITE:
 {
 btif_storage_req_t *p_req = (btif_storage_req_t*)p_param;
 bt_property_t *p_prop = &(p_req->write_req.prop);
            BTIF_TRACE_EVENT("type: %d, len %d, 0x%x", p_prop->type,
                               p_prop->len, p_prop->val);

            status = btif_storage_set_adapter_property(p_prop);
            HAL_CBACK(bt_hal_cbacks, adapter_properties_cb, status, 1, p_prop);
 } break;

 case BTIF_CORE_STORAGE_ADAPTER_READ:
 {
 btif_storage_req_t *p_req = (btif_storage_req_t*)p_param;
 char buf[512];
 bt_property_t prop;
            prop.type = p_req->read_req.type;
            prop.val = (void*)buf;
            prop.len = sizeof(buf);
 if (prop.type == BT_PROPERTY_LOCAL_LE_FEATURES)
 {
 #if (BLE_INCLUDED == TRUE)
                tBTM_BLE_VSC_CB cmn_vsc_cb;
 bt_local_le_features_t local_le_features;

 /* LE features are not stored in storage. Should be retrived from stack */
                BTM_BleGetVendorCapabilities(&cmn_vsc_cb);
                local_le_features.local_privacy_enabled = BTM_BleLocalPrivacyEnabled();

                prop.len = sizeof (bt_local_le_features_t);
 if (cmn_vsc_cb.filter_support == 1)
                    local_le_features.max_adv_filter_supported = cmn_vsc_cb.max_filter;
 else
                    local_le_features.max_adv_filter_supported = 0;
                local_le_features.max_adv_instance = cmn_vsc_cb.adv_inst_max;
                local_le_features.max_irk_list_size = cmn_vsc_cb.max_irk_list_sz;
                local_le_features.rpa_offload_supported = cmn_vsc_cb.rpa_offloading;
                local_le_features.scan_result_storage_size = cmn_vsc_cb.tot_scan_results_strg;
                local_le_features.activity_energy_info_supported = cmn_vsc_cb.energy_support;
                local_le_features.version_supported = cmn_vsc_cb.version_supported;
                local_le_features.total_trackable_advertisers =
                    cmn_vsc_cb.total_trackable_advertisers;

                local_le_features.extended_scan_support = cmn_vsc_cb.extended_scan_support > 0;
                local_le_features.debug_logging_supported = cmn_vsc_cb.debug_logging_supported > 0;
                memcpy(prop.val, &local_le_features, prop.len);
 #endif
 }
 else
 {
                status = btif_storage_get_adapter_property(&prop);
 }
            HAL_CBACK(bt_hal_cbacks, adapter_properties_cb, status, 1, &prop);
 } break;

 case BTIF_CORE_STORAGE_ADAPTER_READ_ALL:
 {
            status = btif_in_get_adapter_properties();
 } break;

 case BTIF_CORE_STORAGE_NOTIFY_STATUS:
 {
            HAL_CBACK(bt_hal_cbacks, adapter_properties_cb, status, 0, NULL);
 } break;

 default:
            BTIF_TRACE_ERROR("%s invalid event id (%d)", __FUNCTION__, event);
 break;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool OMXCodec::findCodecQuirks(const char *componentName, uint32_t *quirks) {
 const sp<IMediaCodecList> list = MediaCodecList::getInstance();
 if (list == NULL) {
 return false;
 }

 ssize_t index = list->findCodecByName(componentName);

 if (index < 0) {
 return false;
 }

 const sp<MediaCodecInfo> info = list->getCodecInfo(index);
    CHECK(info != NULL);
 *quirks = getComponentQuirks(info);

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlNewBlanksWrapperInputStream(xmlParserCtxtPtr ctxt, xmlEntityPtr entity) {
    xmlParserInputPtr input;
    xmlChar *buffer;
 size_t length;
 if (entity == NULL) {
	xmlFatalErr(ctxt, XML_ERR_INTERNAL_ERROR,
 "xmlNewBlanksWrapperInputStream entity\n");
 return(NULL);
 }
 if (xmlParserDebugEntities)
	xmlGenericError(xmlGenericErrorContext,
 "new blanks wrapper for entity: %s\n", entity->name);
    input = xmlNewInputStream(ctxt);
 if (input == NULL) {
 return(NULL);
 }
    length = xmlStrlen(entity->name) + 5;
    buffer = xmlMallocAtomic(length);
 if (buffer == NULL) {
	xmlErrMemory(ctxt, NULL);
        xmlFree(input);
 return(NULL);
 }
    buffer [0] = ' ';
    buffer [1] = '%';
    buffer [length-3] = ';';
    buffer [length-2] = ' ';
    buffer [length-1] = 0;
    memcpy(buffer + 2, entity->name, length - 5);
    input->free = deallocblankswrapper;
    input->base = buffer;
    input->cur = buffer;
    input->length = length;
    input->end = &buffer[length];
 return(input);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  double GetAverageMismatchPsnr() const {
 if (mismatch_nframes_)
 return mismatch_psnr_ / mismatch_nframes_;
 return 0.0;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool read_metadata_seektable_(FLAC__StreamDecoder *decoder, FLAC__bool is_last, unsigned length)
{
	FLAC__uint32 i, x;
	FLAC__uint64 xx;

	FLAC__ASSERT(FLAC__bitreader_is_consumed_byte_aligned(decoder->private_->input));

	decoder->private_->seek_table.type = FLAC__METADATA_TYPE_SEEKTABLE;
	decoder->private_->seek_table.is_last = is_last;
	decoder->private_->seek_table.length = length;

	decoder->private_->seek_table.data.seek_table.num_points = length / FLAC__STREAM_METADATA_SEEKPOINT_LENGTH;

 /* use realloc since we may pass through here several times (e.g. after seeking) */
 if(0 == (decoder->private_->seek_table.data.seek_table.points = safe_realloc_mul_2op_(decoder->private_->seek_table.data.seek_table.points, decoder->private_->seek_table.data.seek_table.num_points, /*times*/sizeof(FLAC__StreamMetadata_SeekPoint)))) {
		decoder->protected_->state = FLAC__STREAM_DECODER_MEMORY_ALLOCATION_ERROR;
 return false;
 }
 for(i = 0; i < decoder->private_->seek_table.data.seek_table.num_points; i++) {
 if(!FLAC__bitreader_read_raw_uint64(decoder->private_->input, &xx, FLAC__STREAM_METADATA_SEEKPOINT_SAMPLE_NUMBER_LEN))
 return false; /* read_callback_ sets the state for us */
		decoder->private_->seek_table.data.seek_table.points[i].sample_number = xx;

 if(!FLAC__bitreader_read_raw_uint64(decoder->private_->input, &xx, FLAC__STREAM_METADATA_SEEKPOINT_STREAM_OFFSET_LEN))
 return false; /* read_callback_ sets the state for us */
		decoder->private_->seek_table.data.seek_table.points[i].stream_offset = xx;

 if(!FLAC__bitreader_read_raw_uint32(decoder->private_->input, &x, FLAC__STREAM_METADATA_SEEKPOINT_FRAME_SAMPLES_LEN))
 return false; /* read_callback_ sets the state for us */
		decoder->private_->seek_table.data.seek_table.points[i].frame_samples = x;
 }
	length -= (decoder->private_->seek_table.data.seek_table.num_points * FLAC__STREAM_METADATA_SEEKPOINT_LENGTH);
 /* if there is a partial point left, skip over it */
 if(length > 0) {
 /*@@@ do a send_error_to_client_() here?  there's an argument for either way */
 if(!FLAC__bitreader_skip_byte_block_aligned_no_crc(decoder->private_->input, length))
 return false; /* read_callback_ sets the state for us */
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Reverb_free(ReverbContext *pContext){

    LVREV_ReturnStatus_en     LvmStatus=LVREV_SUCCESS; /* Function call status */
    LVREV_ControlParams_st    params; /* Control Parameters */
    LVREV_MemoryTable_st      MemTab;

 /* Free the algorithm memory */
 LvmStatus = LVREV_GetMemoryTable(pContext->hInstance,
 &MemTab,
                                   LVM_NULL);

    LVM_ERROR_CHECK(LvmStatus, "LVM_GetMemoryTable", "Reverb_free")

 for (int i=0; i<LVM_NR_MEMORY_REGIONS; i++){
 if (MemTab.Region[i].Size != 0){
 if (MemTab.Region[i].pBaseAddress != NULL){
                ALOGV("\tfree() - START freeing %" PRIu32 " bytes for region %u at %p\n",
 MemTab.Region[i].Size, i, MemTab.Region[i].pBaseAddress);

                free(MemTab.Region[i].pBaseAddress);

                ALOGV("\tfree() - END   freeing %" PRIu32 " bytes for region %u at %p\n",
 MemTab.Region[i].Size, i, MemTab.Region[i].pBaseAddress);
 }else{
                ALOGV("\tLVM_ERROR : free() - trying to free with NULL pointer %" PRIu32 " bytes "
 "for region %u at %p ERROR\n",
 MemTab.Region[i].Size, i, MemTab.Region[i].pBaseAddress);
 }
 }
 }
} /* end Reverb_free */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_intra_refresh(OMX_VIDEO_INTRAREFRESHTYPE ir_mode, OMX_U32 irMBs)
{
 bool status = true;
 int rc;
 struct v4l2_control control_mode,control_mbs;
    control_mode.id = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_MODE;

 if (irMBs == 0 || ir_mode == OMX_VIDEO_IntraRefreshMax) {
        control_mode.value = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_NONE;
 return status;
 } else if ((ir_mode == OMX_VIDEO_IntraRefreshCyclic) &&
 (irMBs < ((m_sVenc_cfg.dvs_width * m_sVenc_cfg.dvs_height)>>8))) {
        control_mode.value = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_CYCLIC;
        control_mbs.id=V4L2_CID_MPEG_VIDC_VIDEO_CIR_MBS;
        control_mbs.value=irMBs;
 } else if ((ir_mode == OMX_VIDEO_IntraRefreshAdaptive) &&
 (irMBs < ((m_sVenc_cfg.dvs_width * m_sVenc_cfg.dvs_height)>>8))) {
        control_mode.value = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_ADAPTIVE;
        control_mbs.id=V4L2_CID_MPEG_VIDC_VIDEO_AIR_MBS;
        control_mbs.value=irMBs;
 } else if ((ir_mode == OMX_VIDEO_IntraRefreshBoth) &&
 (irMBs < ((m_sVenc_cfg.dvs_width * m_sVenc_cfg.dvs_height)>>8))) {
        control_mode.value = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_CYCLIC_ADAPTIVE;
 } else if ((ir_mode == OMX_VIDEO_IntraRefreshRandom) &&
 (irMBs < ((m_sVenc_cfg.dvs_width * m_sVenc_cfg.dvs_height)>>8))) {
        control_mode.value = V4L2_CID_MPEG_VIDC_VIDEO_INTRA_REFRESH_RANDOM;
        control_mbs.id = V4L2_CID_MPEG_VIDC_VIDEO_AIR_MBS;
        control_mbs.value = irMBs;
 } else {
        DEBUG_PRINT_ERROR("ERROR: Invalid IntraRefresh Parameters:"
 "mb count: %u, mb mode:%d", (unsigned int)irMBs, ir_mode);
 return false;
 }

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%u, val=%d", control_mode.id, control_mode.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control_mode);

 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control_mode.id, control_mode.value);

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control_mbs.id, control_mbs.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control_mbs);

 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control_mbs.id, control_mbs.value);

    intra_refresh.irmode = control_mode.value;
    intra_refresh.mbcount = control_mbs.value;

 return status;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int process( LVM_INT16     *pIn,
             LVM_INT16     *pOut,
 int           frameCount,
 ReverbContext *pContext){

    LVM_INT16               samplesPerFrame = 1;
    LVREV_ReturnStatus_en   LvmStatus = LVREV_SUCCESS; /* Function call status */
    LVM_INT16 *OutFrames16;


 if (pContext->config.inputCfg.channels == AUDIO_CHANNEL_OUT_STEREO) {
        samplesPerFrame = 2;
 } else if (pContext->config.inputCfg.channels != AUDIO_CHANNEL_OUT_MONO) {
        ALOGV("\tLVREV_ERROR : process invalid PCM format");
 return -EINVAL;
 }

 OutFrames16 = (LVM_INT16 *)pContext->OutFrames32;

 if((pContext->InFrames32 == NULL)||(pContext->OutFrames32 == NULL)){
        ALOGV("\tLVREV_ERROR : process failed to allocate memory for temporary buffers ");
 return -EINVAL;
 }

 #ifdef LVM_PCM
    fwrite(pIn, frameCount*sizeof(LVM_INT16)*samplesPerFrame, 1, pContext->PcmInPtr);
    fflush(pContext->PcmInPtr);
 #endif

 if (pContext->preset && pContext->nextPreset != pContext->curPreset) {
 Reverb_LoadPreset(pContext);
 }



 if (pContext->auxiliary) {
 for(int i=0; i<frameCount*samplesPerFrame; i++){
            pContext->InFrames32[i] = (LVM_INT32)pIn[i]<<8;
 }
 } else {
 for (int i = 0; i < frameCount; i++) {
            pContext->InFrames32[2*i] = (pIn[2*i] * REVERB_SEND_LEVEL) >> 4; // <<8 + >>12
            pContext->InFrames32[2*i+1] = (pIn[2*i+1] * REVERB_SEND_LEVEL) >> 4; // <<8 + >>12
 }
 }

 if (pContext->preset && pContext->curPreset == REVERB_PRESET_NONE) {
        memset(pContext->OutFrames32, 0, frameCount * sizeof(LVM_INT32) * 2); //always stereo here
 } else {
 if(pContext->bEnabled == LVM_FALSE && pContext->SamplesToExitCount > 0) {
            memset(pContext->InFrames32,0,frameCount * sizeof(LVM_INT32) * samplesPerFrame);
            ALOGV("\tZeroing %d samples per frame at the end of call", samplesPerFrame);
 }

 /* Process the samples, producing a stereo output */
 LvmStatus = LVREV_Process(pContext->hInstance, /* Instance handle */
                                  pContext->InFrames32, /* Input buffer */
                                  pContext->OutFrames32, /* Output buffer */
                                  frameCount); /* Number of samples to read */
 }

    LVM_ERROR_CHECK(LvmStatus, "LVREV_Process", "process")
 if(LvmStatus != LVREV_SUCCESS) return -EINVAL;

 if (pContext->auxiliary) {
 for (int i=0; i < frameCount*2; i++) { //always stereo here
 OutFrames16[i] = clamp16(pContext->OutFrames32[i]>>8);
 }
 } else {
 for (int i=0; i < frameCount*2; i++) { //always stereo here
 OutFrames16[i] = clamp16((pContext->OutFrames32[i]>>8) + (LVM_INT32)pIn[i]);
 }

 if ((pContext->leftVolume != pContext->prevLeftVolume ||
                pContext->rightVolume != pContext->prevRightVolume) &&
                pContext->volumeMode == REVERB_VOLUME_RAMP) {
            LVM_INT32 vl = (LVM_INT32)pContext->prevLeftVolume << 16;
            LVM_INT32 incl = (((LVM_INT32)pContext->leftVolume << 16) - vl) / frameCount;
            LVM_INT32 vr = (LVM_INT32)pContext->prevRightVolume << 16;
            LVM_INT32 incr = (((LVM_INT32)pContext->rightVolume << 16) - vr) / frameCount;

 for (int i = 0; i < frameCount; i++) {
 OutFrames16[2*i] =
                        clamp16((LVM_INT32)((vl >> 16) * OutFrames16[2*i]) >> 12);
 OutFrames16[2*i+1] =
                        clamp16((LVM_INT32)((vr >> 16) * OutFrames16[2*i+1]) >> 12);

                vl += incl;
                vr += incr;
 }

            pContext->prevLeftVolume = pContext->leftVolume;
            pContext->prevRightVolume = pContext->rightVolume;
 } else if (pContext->volumeMode != REVERB_VOLUME_OFF) {
 if (pContext->leftVolume != REVERB_UNIT_VOLUME ||
                pContext->rightVolume != REVERB_UNIT_VOLUME) {
 for (int i = 0; i < frameCount; i++) {
 OutFrames16[2*i] =
                            clamp16((LVM_INT32)(pContext->leftVolume * OutFrames16[2*i]) >> 12);
 OutFrames16[2*i+1] =
                            clamp16((LVM_INT32)(pContext->rightVolume * OutFrames16[2*i+1]) >> 12);
 }
 }
            pContext->prevLeftVolume = pContext->leftVolume;
            pContext->prevRightVolume = pContext->rightVolume;
            pContext->volumeMode = REVERB_VOLUME_RAMP;
 }
 }

 #ifdef LVM_PCM
    fwrite(OutFrames16, frameCount*sizeof(LVM_INT16)*2, 1, pContext->PcmOutPtr);
    fflush(pContext->PcmOutPtr);
 #endif

 if (pContext->config.outputCfg.accessMode == EFFECT_BUFFER_ACCESS_ACCUMULATE){
 for (int i=0; i<frameCount*2; i++){ //always stereo here
            pOut[i] = clamp16((int32_t)pOut[i] + (int32_t)OutFrames16[i]);
 }
 }else{
        memcpy(pOut, OutFrames16, frameCount*sizeof(LVM_INT16)*2);
 }

 return 0;
} /* end process */

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: size_t IMemory::size() const {
 size_t size;
    getMemory(NULL, &size);
 return size;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ACodec::ExecutingState::resume() {
 if (mActive) {
        ALOGV("[%s] We're already active, no need to resume.", mCodec->mComponentName.c_str());
 return;
 }

    submitOutputBuffers();

 if (mCodec->mBuffers[kPortIndexInput].size() == 0u) {
        ALOGW("[%s] we don't have any input buffers to resume", mCodec->mComponentName.c_str());
 }

 for (size_t i = 0; i < mCodec->mBuffers[kPortIndexInput].size(); i++) {
 BufferInfo *info = &mCodec->mBuffers[kPortIndexInput].editItemAt(i);
 if (info->mStatus == BufferInfo::OWNED_BY_US) {
            postFillThisBuffer(info);
 }
 }

    mActive = true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static Handle<SeededNumberDictionary> NormalizeImpl(
 Handle<JSObject> object, Handle<FixedArrayBase> store) {
 Isolate* isolate = store->GetIsolate();
 ElementsKind kind = Subclass::kind();

 if (IsFastSmiOrObjectElementsKind(kind)) {
      isolate->UpdateArrayProtectorOnNormalizeElements(object);
 }

 int capacity = object->GetFastElementsUsage();
 Handle<SeededNumberDictionary> dictionary =
 SeededNumberDictionary::New(isolate, capacity);

 PropertyDetails details = PropertyDetails::Empty();
 int j = 0;
 for (int i = 0; j < capacity; i++) {
 if (IsHoleyElementsKind(kind)) {
 if (BackingStore::cast(*store)->is_the_hole(isolate, i)) continue;
 }
 Handle<Object> value = Subclass::GetImpl(isolate, *store, i);
      dictionary = SeededNumberDictionary::AddNumberEntry(dictionary, i, value,
                                                          details, object);
      j++;
 }
 return dictionary;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static audio_format_t out_get_format(const struct audio_stream *stream)
{
 struct a2dp_stream_out *out = (struct a2dp_stream_out *)stream;
    DEBUG("format 0x%x", out->common.cfg.format);
 return out->common.cfg.format;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int process_cmd_sock(int h)

 {
     sock_cmd_t cmd = {-1, 0, 0, 0, 0};
     int fd = ts[h].cmd_fdr;
    if(recv(fd, &cmd, sizeof(cmd), MSG_WAITALL) != sizeof(cmd))
     {
         APPL_TRACE_ERROR("recv cmd errno:%d", errno);
         return FALSE;
 }
    APPL_TRACE_DEBUG("cmd.id:%d", cmd.id);
 switch(cmd.id)
 {
 case CMD_ADD_FD:
            add_poll(h, cmd.fd, cmd.type, cmd.flags, cmd.user_id);
 break;
 case CMD_REMOVE_FD:
 for (int i = 1; i < MAX_POLL; ++i)
 {
 poll_slot_t *poll_slot = &ts[h].ps[i];
 if (poll_slot->pfd.fd == cmd.fd)
 {
                    remove_poll(h, poll_slot, poll_slot->flags);
 break;
 }
 }
            close(cmd.fd);
 break;
 case CMD_WAKEUP:
 break;
 case CMD_USER_PRIVATE:
            asrt(ts[h].cmd_callback);
 if(ts[h].cmd_callback)
                ts[h].cmd_callback(fd, cmd.type, cmd.flags, cmd.user_id);
 break;
 case CMD_EXIT:
 return FALSE;
 default:
            APPL_TRACE_DEBUG("unknown cmd: %d", cmd.id);
 break;
 }
 return TRUE;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool Block::IsInvisible() const
{
    return bool(int(m_flags & 0x08) != 0);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: const Tags::SimpleTag* Tags::Tag::GetSimpleTag(int index) const {
 if (index < 0)
 return NULL;

 if (index >= m_simple_tags_count)
 return NULL;

 return m_simple_tags + index;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void RunExtremalCheck() {

     ACMRandom rnd(ACMRandom::DeterministicSeed());
     int max_error = 0;
     int total_error = 0;
     const int count_test_block = 100000;
    DECLARE_ALIGNED_ARRAY(16, int16_t, test_input_block, 64);
    DECLARE_ALIGNED_ARRAY(16, int16_t, test_temp_block, 64);
    DECLARE_ALIGNED_ARRAY(16, uint8_t, dst, 64);
    DECLARE_ALIGNED_ARRAY(16, uint8_t, src, 64);
 
     for (int i = 0; i < count_test_block; ++i) {
       for (int j = 0; j < 64; ++j) {
        src[j] = rnd.Rand8() % 2 ? 255 : 0;
        dst[j] = src[j] > 0 ? 0 : 255;
        test_input_block[j] = src[j] - dst[j];
       }
 
      REGISTER_STATE_CHECK(
           RunFwdTxfm(test_input_block, test_temp_block, pitch_));
      REGISTER_STATE_CHECK(
          RunInvTxfm(test_temp_block, dst, pitch_));
 
       for (int j = 0; j < 64; ++j) {
         const int diff = dst[j] - src[j];
         const int error = diff * diff;
         if (max_error < error)
           max_error = error;
         total_error += error;
       }
 
      EXPECT_GE(1, max_error)
           << "Error: Extremal 8x8 FDCT/IDCT or FHT/IHT has"
           << "an individual roundtrip error > 1";
 
      EXPECT_GE(count_test_block/5, total_error)
           << "Error: Extremal 8x8 FDCT/IDCT or FHT/IHT has average"
           << " roundtrip error > 1/5 per block";
     }
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static bool checkPermission(const char* permissionString) {
 if (getpid() == IPCThreadState::self()->getCallingPid()) return true;
 bool ok = checkCallingPermission(String16(permissionString));
 if (!ok) ALOGE("Request requires %s", permissionString);
 return ok;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: png_init_filter_functions_neon(png_structp pp, unsigned int bpp)
{
 /* The switch statement is compiled in for ARM_NEON_API, the call to
    * png_have_neon is compiled in for ARM_NEON_CHECK.  If both are defined
    * the check is only performed if the API has not set the NEON option on
    * or off explicitly.  In this case the check controls what happens.
    *
    * If the CHECK is not compiled in and the option is UNSET the behavior prior
    * to 1.6.7 was to use the NEON code - this was a bug caused by having the
    * wrong order of the 'ON' and 'default' cases.  UNSET now defaults to OFF,
    * as documented in png.h
    */
#ifdef PNG_ARM_NEON_API_SUPPORTED
 switch ((pp->options >> PNG_ARM_NEON) & 3)
 {
 case PNG_OPTION_UNSET:
 /* Allow the run-time check to execute if it has been enabled -
          * thus both API and CHECK can be turned on.  If it isn't supported
          * this case will fall through to the 'default' below, which just
          * returns.
          */
#endif /* PNG_ARM_NEON_API_SUPPORTED */
#ifdef PNG_ARM_NEON_CHECK_SUPPORTED
 {
 static volatile sig_atomic_t no_neon = -1; /* not checked */

 if (no_neon < 0)
               no_neon = !png_have_neon(pp);

 if (no_neon)
 return;
 }
#ifdef PNG_ARM_NEON_API_SUPPORTED
 break;
#endif
#endif /* PNG_ARM_NEON_CHECK_SUPPORTED */

#ifdef PNG_ARM_NEON_API_SUPPORTED
 default: /* OFF or INVALID */
 return;

 case PNG_OPTION_ON:
 /* Option turned on */
 break;
 }
#endif

 /* IMPORTANT: any new external functions used here must be declared using
    * PNG_INTERNAL_FUNCTION in ../pngpriv.h.  This is required so that the
    * 'prefix' option to configure works:
    *
    *    ./configure --with-libpng-prefix=foobar_
    *
    * Verify you have got this right by running the above command, doing a build
    * and examining pngprefix.h; it must contain a #define for every external
    * function you add.  (Notice that this happens automatically for the
    * initialization function.)
    */
   pp->read_filter[PNG_FILTER_VALUE_UP-1] = png_read_filter_row_up_neon;

 if (bpp == 3)
 {
      pp->read_filter[PNG_FILTER_VALUE_SUB-1] = png_read_filter_row_sub3_neon;
      pp->read_filter[PNG_FILTER_VALUE_AVG-1] = png_read_filter_row_avg3_neon;
      pp->read_filter[PNG_FILTER_VALUE_PAETH-1] =
         png_read_filter_row_paeth3_neon;
 }

 else if (bpp == 4)
 {
      pp->read_filter[PNG_FILTER_VALUE_SUB-1] = png_read_filter_row_sub4_neon;
      pp->read_filter[PNG_FILTER_VALUE_AVG-1] = png_read_filter_row_avg4_neon;
      pp->read_filter[PNG_FILTER_VALUE_PAETH-1] =
          png_read_filter_row_paeth4_neon;

    }
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static size_t StringSize(const uint8_t *start, uint8_t encoding) {
 if (encoding == 0x00 || encoding == 0x03) {
 return strlen((const char *)start) + 1;
 }

 size_t n = 0;
 while (start[n] != '\0' || start[n + 1] != '\0') {
        n += 2;
 }

 return n + 2;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long long Segment::CreateInstance(
    IMkvReader* pReader,
    long long pos,
    Segment*& pSegment)
{
    assert(pReader);
    assert(pos >= 0);
 
    pSegment = NULL;
 
    long long total, available;
 
    const long status = pReader->Length(&total, &available);
 
    if (status < 0) //error
        return status;
 
    if (available < 0)
         return -1;
 
    if ((total >= 0) && (available > total))
         return -1;
 
 
    for (;;)
    {
        if ((total >= 0) && (pos >= total))
            return E_FILE_FORMAT_INVALID;
        long len;
        long long result = GetUIntLength(pReader, pos, len);
        if (result)  //error, or too few available bytes
            return result;
        if ((total >= 0) && ((pos + len) > total))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > available)
            return pos + len;
        const long long idpos = pos;
        const long long id = ReadUInt(pReader, pos, len);
        if (id < 0)  //error
            return id;
        pos += len;  //consume ID
        result = GetUIntLength(pReader, pos, len);
        if (result)  //error, or too few available bytes
            return result;
        if ((total >= 0) && ((pos + len) > total))
            return E_FILE_FORMAT_INVALID;
        if ((pos + len) > available)
            return pos + len;
        long long size = ReadUInt(pReader, pos, len);
        if (size < 0)  //error
            return size;
        pos += len;  //consume length of size of element
        const long long unknown_size = (1LL << (7 * len)) - 1;
        if (id == 0x08538067)  //Segment ID
        {
            if (size == unknown_size)
                size = -1;
            else if (total < 0)
                size = -1;
            else if ((pos + size) > total)
                size = -1;
            pSegment = new (std::nothrow) Segment(
                                            pReader,
                                            idpos,
                                            pos,
                                            size);
            if (pSegment == 0)
                return -1;  //generic error
            return 0;    //success
        }
        if (size == unknown_size)
            return E_FILE_FORMAT_INVALID;
        if ((total >= 0) && ((pos + size) > total))
            return E_FILE_FORMAT_INVALID;
        if ((pos + size) > available)
            return pos + size;
        pos += size;  //consume payload
    }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static void setLogLevel(int level) {
    android_atomic_write(level, &gLogLevel);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  bool InputWindowInfo::isTrustedOverlay() const {
     return layoutParamsType == TYPE_INPUT_METHOD
             || layoutParamsType == TYPE_INPUT_METHOD_DIALOG
             || layoutParamsType == TYPE_MAGNIFICATION_OVERLAY
             || layoutParamsType == TYPE_SECURE_SYSTEM_OVERLAY;
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::Load(long long& pos, long& len) const {
  assert(m_pSegment);
  assert(m_pos >= m_element_start);

 if (m_timecode >= 0) // at least partially loaded
 return 0;

  assert(m_pos == m_element_start);
  assert(m_element_size < 0);

 IMkvReader* const pReader = m_pSegment->m_pReader;

 long long total, avail;

 const int status = pReader->Length(&total, &avail);

 if (status < 0) // error
 return status;

  assert((total < 0) || (avail <= total));
  assert((total < 0) || (m_pos <= total)); // TODO: verify this

  pos = m_pos;

 long long cluster_size = -1;

 {
 if ((pos + 1) > avail) {
      len = 1;
 return E_BUFFER_NOT_FULL;
 }

 long long result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error or underflow
 return static_cast<long>(result);

 if (result > 0) // underflow (weird)
 return E_BUFFER_NOT_FULL;


 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 const long long id_ = ReadUInt(pReader, pos, len);

 if (id_ < 0) // error
 return static_cast<long>(id_);

 if (id_ != 0x0F43B675) // Cluster ID
 return E_FILE_FORMAT_INVALID;

    pos += len; // consume id


 if ((pos + 1) > avail) {
      len = 1;
 return E_BUFFER_NOT_FULL;
 }

    result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error
 return static_cast<long>(result);

 if (result > 0) // weird
 return E_BUFFER_NOT_FULL;


 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 const long long size = ReadUInt(pReader, pos, len);

 if (size < 0) // error
 return static_cast<long>(cluster_size);

 if (size == 0)
 return E_FILE_FORMAT_INVALID; // TODO: verify this

    pos += len; // consume length of size of element

 const long long unknown_size = (1LL << (7 * len)) - 1;

 if (size != unknown_size)
      cluster_size = size;
 }

 long long timecode = -1;
 long long new_pos = -1;
 bool bBlock = false;

 long long cluster_stop = (cluster_size < 0) ? -1 : pos + cluster_size;

 for (;;) {
 if ((cluster_stop >= 0) && (pos >= cluster_stop))
 break;


 if ((pos + 1) > avail) {
      len = 1;
 return E_BUFFER_NOT_FULL;
 }

 long long result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error
 return static_cast<long>(result);

 if (result > 0) // weird
 return E_BUFFER_NOT_FULL;

 if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 const long long id = ReadUInt(pReader, pos, len);

 if (id < 0) // error
 return static_cast<long>(id);

 if (id == 0)
 return E_FILE_FORMAT_INVALID;


 if (id == 0x0F43B675) // Cluster ID
 break;

 if (id == 0x0C53BB6B) // Cues ID
 break;

    pos += len; // consume ID field


 if ((pos + 1) > avail) {
      len = 1;
 return E_BUFFER_NOT_FULL;
 }

    result = GetUIntLength(pReader, pos, len);

 if (result < 0) // error
 return static_cast<long>(result);

 if (result > 0) // weird
 return E_BUFFER_NOT_FULL;

 if ((cluster_stop >= 0) && ((pos + len) > cluster_stop))
 return E_FILE_FORMAT_INVALID;

 if ((pos + len) > avail)
 return E_BUFFER_NOT_FULL;

 const long long size = ReadUInt(pReader, pos, len);

 if (size < 0) // error
 return static_cast<long>(size);

 const long long unknown_size = (1LL << (7 * len)) - 1;

 if (size == unknown_size)
 return E_FILE_FORMAT_INVALID;

    pos += len; // consume size field

 if ((cluster_stop >= 0) && (pos > cluster_stop))
 return E_FILE_FORMAT_INVALID;


 if (size == 0) // weird
 continue;

 if ((cluster_stop >= 0) && ((pos + size) > cluster_stop))
 return E_FILE_FORMAT_INVALID;

 if (id == 0x67) { // TimeCode ID
      len = static_cast<long>(size);

 if ((pos + size) > avail)
 return E_BUFFER_NOT_FULL;

      timecode = UnserializeUInt(pReader, pos, size);

 if (timecode < 0) // error (or underflow)
 return static_cast<long>(timecode);

      new_pos = pos + size;

 if (bBlock)
 break;
 } else if (id == 0x20) { // BlockGroup ID
      bBlock = true;
 break;
 } else if (id == 0x23) { // SimpleBlock ID
      bBlock = true;
 break;
 }

    pos += size; // consume payload
 if (cluster_stop >= 0 && pos > cluster_stop)
 return E_FILE_FORMAT_INVALID;
 }

 if (cluster_stop >= 0 && pos > cluster_stop)
 return E_FILE_FORMAT_INVALID;

 if (timecode < 0) // no timecode found
 return E_FILE_FORMAT_INVALID;

 if (!bBlock)
 return E_FILE_FORMAT_INVALID;

  m_pos = new_pos; // designates position just beyond timecode payload
  m_timecode = timecode; // m_timecode >= 0 means we're partially loaded

 if (cluster_size >= 0)
    m_element_size = cluster_stop - m_element_start;

 return 0;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: bool venc_dev::venc_set_session_qp(OMX_U32 i_frame_qp, OMX_U32 p_frame_qp,OMX_U32 b_frame_qp)
{
 int rc;
 struct v4l2_control control;

    control.id = V4L2_CID_MPEG_VIDEO_H264_I_FRAME_QP;
    control.value = i_frame_qp;

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);
    session_qp.iframeqp = control.value;

    control.id = V4L2_CID_MPEG_VIDEO_H264_P_FRAME_QP;
    control.value = p_frame_qp;

    DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
    rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
        DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

    DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);

    session_qp.pframeqp = control.value;

 if ((codec_profile.profile == V4L2_MPEG_VIDEO_H264_PROFILE_MAIN) ||
 (codec_profile.profile == V4L2_MPEG_VIDEO_H264_PROFILE_HIGH)) {

        control.id = V4L2_CID_MPEG_VIDEO_H264_B_FRAME_QP;
        control.value = b_frame_qp;

        DEBUG_PRINT_LOW("Calling IOCTL set control for id=%d, val=%d", control.id, control.value);
        rc = ioctl(m_nDriver_fd, VIDIOC_S_CTRL, &control);

 if (rc) {
            DEBUG_PRINT_ERROR("Failed to set control");
 return false;
 }

        DEBUG_PRINT_LOW("Success IOCTL set control for id=%d, value=%d", control.id, control.value);

        session_qp.bframeqp = control.value;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static bool has_byte(const eager_reader_t *reader) {
  assert(reader != NULL);

  fd_set read_fds;
  FD_ZERO(&read_fds);
  FD_SET(reader->bytes_available_fd, &read_fds);

 struct timeval timeout;

   timeout.tv_sec = 0;
   timeout.tv_usec = 0;
 
  select(reader->bytes_available_fd + 1, &read_fds, NULL, NULL, &timeout);
   return FD_ISSET(reader->bytes_available_fd, &read_fds);
 }

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static int out_set_parameters(struct audio_stream *stream, const char *kvpairs)
{
 struct stream_out *out = (struct stream_out *)stream;
 struct audio_device *adev = out->dev;
 struct audio_usecase *usecase;
 struct listnode *node;
 struct str_parms *parms;
 char value[32];
 int ret, val = 0;
 bool devices_changed;
 struct pcm_device *pcm_device;
 struct pcm_device_profile *pcm_profile;
#ifdef PREPROCESSING_ENABLED
 struct stream_in *in = NULL; /* if non-NULL, then force input to standby */
#endif

    ALOGV("%s: enter: usecase(%d: %s) kvpairs: %s out->devices(%d) adev->mode(%d)",
          __func__, out->usecase, use_case_table[out->usecase], kvpairs, out->devices, adev->mode);
    parms = str_parms_create_str(kvpairs);
    ret = str_parms_get_str(parms, AUDIO_PARAMETER_STREAM_ROUTING, value, sizeof(value));
 if (ret >= 0) {
        val = atoi(value);
        pthread_mutex_lock(&adev->lock_inputs);
        lock_output_stream(out);
        pthread_mutex_lock(&adev->lock);
#ifdef PREPROCESSING_ENABLED
 if (((int)out->devices != val) && (val != 0) && (!out->standby) &&
 (out->usecase == USECASE_AUDIO_PLAYBACK)) {
 /* reset active input:
             *  - to attach the echo reference
             *  - because a change in output device may change mic settings */
 if (adev->active_input && (adev->active_input->source == AUDIO_SOURCE_VOICE_COMMUNICATION ||
                    adev->active_input->source == AUDIO_SOURCE_MIC)) {
                in = adev->active_input;
 }
 }
#endif
 if (val != 0) {
            devices_changed = out->devices != (audio_devices_t)val;
            out->devices = val;

 if (!out->standby) {
 if (devices_changed)
                    do_out_standby_l(out);
 else
                    select_devices(adev, out->usecase);
 }

 if ((adev->mode == AUDIO_MODE_IN_CALL) && !adev->in_call &&
 (out == adev->primary_output)) {
                start_voice_call(adev);
 } else if ((adev->mode == AUDIO_MODE_IN_CALL) && adev->in_call &&
 (out == adev->primary_output)) {
                select_devices(adev, USECASE_VOICE_CALL);
 }
 }

 if ((adev->mode == AUDIO_MODE_NORMAL) && adev->in_call &&
 (out == adev->primary_output)) {
            stop_voice_call(adev);
 }
        pthread_mutex_unlock(&adev->lock);
        pthread_mutex_unlock(&out->lock);
#ifdef PREPROCESSING_ENABLED
 if (in) {
 /* The lock on adev->lock_inputs prevents input stream from being closed */
            lock_input_stream(in);
            pthread_mutex_lock(&adev->lock);
            LOG_ALWAYS_FATAL_IF(in != adev->active_input);
            do_in_standby_l(in);
            pthread_mutex_unlock(&adev->lock);
            pthread_mutex_unlock(&in->lock);
 }
#endif
        pthread_mutex_unlock(&adev->lock_inputs);
 }

    str_parms_destroy(parms);
    ALOGV("%s: exit: code(%d)", __func__, ret);
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void InputDispatcher::setInjectionResultLocked(EventEntry* entry, int32_t injectionResult) {
 InjectionState* injectionState = entry->injectionState;
 if (injectionState) {
#if DEBUG_INJECTION
        ALOGD("Setting input event injection result to %d.  "
 "injectorPid=%d, injectorUid=%d",
                 injectionResult, injectionState->injectorPid, injectionState->injectorUid);
#endif

 if (injectionState->injectionIsAsync
 && !(entry->policyFlags & POLICY_FLAG_FILTERED)) {
 switch (injectionResult) {
 case INPUT_EVENT_INJECTION_SUCCEEDED:
                ALOGV("Asynchronous input event injection succeeded.");
 break;
 case INPUT_EVENT_INJECTION_FAILED:
                ALOGW("Asynchronous input event injection failed.");
 break;
 case INPUT_EVENT_INJECTION_PERMISSION_DENIED:
                ALOGW("Asynchronous input event injection permission denied.");
 break;
 case INPUT_EVENT_INJECTION_TIMED_OUT:
                ALOGW("Asynchronous input event injection timed out.");
 break;
 }
 }

        injectionState->injectionResult = injectionResult;
        mInjectionResultAvailableCondition.broadcast();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4Extractor::updateAudioTrackInfoFromESDS_MPEG4Audio(
 const void *esds_data, size_t esds_size) {
    ESDS esds(esds_data, esds_size);

 uint8_t objectTypeIndication;
 if (esds.getObjectTypeIndication(&objectTypeIndication) != OK) {
 return ERROR_MALFORMED;
 }

 if (objectTypeIndication == 0xe1) {
 if (mLastTrack == NULL)
 return ERROR_MALFORMED;

        mLastTrack->meta->setCString(kKeyMIMEType, MEDIA_MIMETYPE_AUDIO_QCELP);
 return OK;
 }

 if (objectTypeIndication  == 0x6b) {
        ALOGE("MP3 track in MP4/3GPP file is not supported");
 return ERROR_UNSUPPORTED;
 }

 const uint8_t *csd;
 size_t csd_size;
 if (esds.getCodecSpecificInfo(
 (const void **)&csd, &csd_size) != OK) {
 return ERROR_MALFORMED;
 }

 if (kUseHexDump) {
        printf("ESD of size %zu\n", csd_size);
        hexdump(csd, csd_size);
 }

 if (csd_size == 0) {

 return OK;
 }

 if (csd_size < 2) {
 return ERROR_MALFORMED;
 }

 static uint32_t kSamplingRate[] = {
 96000, 88200, 64000, 48000, 44100, 32000, 24000, 22050,
 16000, 12000, 11025, 8000, 7350
 };

 ABitReader br(csd, csd_size);
 uint32_t objectType = br.getBits(5);

 if (objectType == 31) { // AAC-ELD => additional 6 bits
        objectType = 32 + br.getBits(6);
 }

 if (mLastTrack == NULL)
 return ERROR_MALFORMED;

    mLastTrack->meta->setInt32(kKeyAACAOT, objectType);

 uint32_t freqIndex = br.getBits(4);

 int32_t sampleRate = 0;
 int32_t numChannels = 0;
 if (freqIndex == 15) {
 if (br.numBitsLeft() < 28) return ERROR_MALFORMED;
        sampleRate = br.getBits(24);
        numChannels = br.getBits(4);
 } else {
 if (br.numBitsLeft() < 4) return ERROR_MALFORMED;
        numChannels = br.getBits(4);

 if (freqIndex == 13 || freqIndex == 14) {
 return ERROR_MALFORMED;
 }

        sampleRate = kSamplingRate[freqIndex];
 }

 if (objectType == AOT_SBR || objectType == AOT_PS) {//SBR specific config per 14496-3 table 1.13
 if (br.numBitsLeft() < 4) return ERROR_MALFORMED;
 uint32_t extFreqIndex = br.getBits(4);
 int32_t extSampleRate __unused;
 if (extFreqIndex == 15) {
 if (csd_size < 8) {
 return ERROR_MALFORMED;
 }
 if (br.numBitsLeft() < 24) return ERROR_MALFORMED;
            extSampleRate = br.getBits(24);
 } else {
 if (extFreqIndex == 13 || extFreqIndex == 14) {
 return ERROR_MALFORMED;
 }
            extSampleRate = kSamplingRate[extFreqIndex];
 }
 }

 switch (numChannels) {
 case 0:
 case 1:// FC
 case 2:// FL FR
 case 3:// FC, FL FR
 case 4:// FC, FL FR, RC
 case 5:// FC, FL FR, SL SR
 case 6:// FC, FL FR, SL SR, LFE
 break;
 case 11:// FC, FL FR, SL SR, RC, LFE
            numChannels = 7;
 break;
 case 7: // FC, FCL FCR, FL FR, SL SR, LFE
 case 12:// FC, FL  FR,  SL SR, RL RR, LFE
 case 14:// FC, FL  FR,  SL SR, LFE, FHL FHR
            numChannels = 8;
 break;
 default:
 return ERROR_UNSUPPORTED;
 }

 {
 if (objectType == AOT_SBR || objectType == AOT_PS) {
 if (br.numBitsLeft() < 5) return ERROR_MALFORMED;
            objectType = br.getBits(5);

 if (objectType == AOT_ESCAPE) {
 if (br.numBitsLeft() < 6) return ERROR_MALFORMED;
                objectType = 32 + br.getBits(6);
 }
 }
 if (objectType == AOT_AAC_LC || objectType == AOT_ER_AAC_LC ||
                objectType == AOT_ER_AAC_LD || objectType == AOT_ER_AAC_SCAL ||
                objectType == AOT_ER_BSAC) {
 if (br.numBitsLeft() < 2) return ERROR_MALFORMED;
 const int32_t frameLengthFlag __unused = br.getBits(1);

 const int32_t dependsOnCoreCoder = br.getBits(1);

 if (dependsOnCoreCoder ) {
 if (br.numBitsLeft() < 14) return ERROR_MALFORMED;
 const int32_t coreCoderDelay __unused = br.getBits(14);
 }

 int32_t extensionFlag = -1;
 if (br.numBitsLeft() > 0) {
                extensionFlag = br.getBits(1);
 } else {
 switch (objectType) {
 case AOT_AAC_LC:
                    extensionFlag = 0;
 break;
 case AOT_ER_AAC_LC:
 case AOT_ER_AAC_SCAL:
 case AOT_ER_BSAC:
 case AOT_ER_AAC_LD:
                    extensionFlag = 1;
 break;
 default:
 return ERROR_MALFORMED;
 break;
 }
                ALOGW("csd missing extension flag; assuming %d for object type %u.",
                        extensionFlag, objectType);
 }

 if (numChannels == 0) {
 int32_t channelsEffectiveNum = 0;
 int32_t channelsNum = 0;
 if (br.numBitsLeft() < 32) {
 return ERROR_MALFORMED;
 }
 const int32_t ElementInstanceTag __unused = br.getBits(4);
 const int32_t Profile __unused = br.getBits(2);
 const int32_t SamplingFrequencyIndex __unused = br.getBits(4);
 const int32_t NumFrontChannelElements = br.getBits(4);
 const int32_t NumSideChannelElements = br.getBits(4);
 const int32_t NumBackChannelElements = br.getBits(4);
 const int32_t NumLfeChannelElements = br.getBits(2);
 const int32_t NumAssocDataElements __unused = br.getBits(3);
 const int32_t NumValidCcElements __unused = br.getBits(4);

 const int32_t MonoMixdownPresent = br.getBits(1);

 if (MonoMixdownPresent != 0) {
 if (br.numBitsLeft() < 4) return ERROR_MALFORMED;
 const int32_t MonoMixdownElementNumber __unused = br.getBits(4);
 }

 if (br.numBitsLeft() < 1) return ERROR_MALFORMED;
 const int32_t StereoMixdownPresent = br.getBits(1);
 if (StereoMixdownPresent != 0) {
 if (br.numBitsLeft() < 4) return ERROR_MALFORMED;
 const int32_t StereoMixdownElementNumber __unused = br.getBits(4);
 }

 if (br.numBitsLeft() < 1) return ERROR_MALFORMED;
 const int32_t MatrixMixdownIndexPresent = br.getBits(1);
 if (MatrixMixdownIndexPresent != 0) {
 if (br.numBitsLeft() < 3) return ERROR_MALFORMED;
 const int32_t MatrixMixdownIndex __unused = br.getBits(2);
 const int32_t PseudoSurroundEnable __unused = br.getBits(1);
 }

 int i;
 for (i=0; i < NumFrontChannelElements; i++) {
 if (br.numBitsLeft() < 5) return ERROR_MALFORMED;
 const int32_t FrontElementIsCpe = br.getBits(1);
 const int32_t FrontElementTagSelect __unused = br.getBits(4);
                    channelsNum += FrontElementIsCpe ? 2 : 1;
 }

 for (i=0; i < NumSideChannelElements; i++) {
 if (br.numBitsLeft() < 5) return ERROR_MALFORMED;
 const int32_t SideElementIsCpe = br.getBits(1);
 const int32_t SideElementTagSelect __unused = br.getBits(4);
                    channelsNum += SideElementIsCpe ? 2 : 1;
 }

 for (i=0; i < NumBackChannelElements; i++) {
 if (br.numBitsLeft() < 5) return ERROR_MALFORMED;
 const int32_t BackElementIsCpe = br.getBits(1);
 const int32_t BackElementTagSelect __unused = br.getBits(4);
                    channelsNum += BackElementIsCpe ? 2 : 1;
 }
                channelsEffectiveNum = channelsNum;

 for (i=0; i < NumLfeChannelElements; i++) {
 if (br.numBitsLeft() < 4) return ERROR_MALFORMED;
 const int32_t LfeElementTagSelect __unused = br.getBits(4);
                    channelsNum += 1;
 }
                ALOGV("mpeg4 audio channelsNum = %d", channelsNum);
                ALOGV("mpeg4 audio channelsEffectiveNum = %d", channelsEffectiveNum);
                numChannels = channelsNum;
 }
 }
 }

 if (numChannels == 0) {
 return ERROR_UNSUPPORTED;
 }

 if (mLastTrack == NULL)
 return ERROR_MALFORMED;

 int32_t prevSampleRate;
    CHECK(mLastTrack->meta->findInt32(kKeySampleRate, &prevSampleRate));

 if (prevSampleRate != sampleRate) {
        ALOGV("mpeg4 audio sample rate different from previous setting. "
 "was: %d, now: %d", prevSampleRate, sampleRate);
 }

    mLastTrack->meta->setInt32(kKeySampleRate, sampleRate);

 int32_t prevChannelCount;
    CHECK(mLastTrack->meta->findInt32(kKeyChannelCount, &prevChannelCount));

 if (prevChannelCount != numChannels) {
        ALOGV("mpeg4 audio channel count different from previous setting. "
 "was: %d, now: %d", prevChannelCount, numChannels);
 }

    mLastTrack->meta->setInt32(kKeyChannelCount, numChannels);

 return OK;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: void ACodec::FlushingState::stateEntered() {
    ALOGV("[%s] Now Flushing", mCodec->mComponentName.c_str());

    mFlushComplete[kPortIndexInput] = mFlushComplete[kPortIndexOutput] = false;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static uint32_t readU32(const uint8_t* data, size_t offset) {
 return ((uint32_t)data[offset]) << 24 | ((uint32_t)data[offset + 1]) << 16 |
 ((uint32_t)data[offset + 2]) << 8 | ((uint32_t)data[offset + 3]);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool FLACParser::eof_callback(
 const FLAC__StreamDecoder * /* decoder */, void *client_data)
{
 return ((FLACParser *) client_data)->eofCallback();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: gpc_pre(Pixel *out, const Pixel *in, const Background *back)
{
 (void)back;

   out->r = ilineara(in->r, in->a);

 if (in->g == in->r)
 {
      out->g = out->r;

 if (in->b == in->r)
         out->b = out->r;

 else
         out->b = ilineara(in->b, in->a);
 }

 else
 {
      out->g = ilineara(in->g, in->a);

 if (in->b == in->r)
         out->b = out->r;

 else if (in->b == in->g)
         out->b = out->g;

 else
         out->b = ilineara(in->b, in->a);
 }

   out->a = in->a * 257;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_dm_pin_req_evt(tBTA_DM_PIN_REQ *p_pin_req)
{
 bt_bdaddr_t bd_addr;
 bt_bdname_t bd_name;
    UINT32 cod;
 bt_pin_code_t pin_code;
 int dev_type;

 /* Remote properties update */
 if (!btif_get_device_type(p_pin_req->bd_addr, &dev_type))
 {
        dev_type = BT_DEVICE_TYPE_BREDR;
 }
    btif_update_remote_properties(p_pin_req->bd_addr, p_pin_req->bd_name,
                                  p_pin_req->dev_class, (tBT_DEVICE_TYPE) dev_type);

    bdcpy(bd_addr.address, p_pin_req->bd_addr);
    memcpy(bd_name.name, p_pin_req->bd_name, BD_NAME_LEN);

    bond_state_changed(BT_STATUS_SUCCESS, &bd_addr, BT_BOND_STATE_BONDING);

    cod = devclass2uint(p_pin_req->dev_class);

 if (cod == 0) {
        BTIF_TRACE_DEBUG("%s cod is 0, set as unclassified", __func__);
        cod = COD_UNCLASSIFIED;
 }

 /* check for auto pair possiblity only if bond was initiated by local device */
 if (pairing_cb.is_local_initiated && (p_pin_req->min_16_digit == FALSE))
 {
 if (check_cod(&bd_addr, COD_AV_HEADSETS) ||
            check_cod(&bd_addr, COD_AV_HANDSFREE) ||
            check_cod(&bd_addr, COD_AV_HEADPHONES) ||
            check_cod(&bd_addr, COD_AV_PORTABLE_AUDIO) ||
            check_cod(&bd_addr, COD_AV_HIFI_AUDIO) ||
            check_cod(&bd_addr, COD_HID_POINTING))
 {
            BTIF_TRACE_DEBUG("%s()cod matches for auto pair", __FUNCTION__);
 /*  Check if this device can be auto paired  */
 if ((btif_storage_is_device_autopair_blacklisted(&bd_addr) == FALSE) &&
 (pairing_cb.autopair_attempts == 0))
 {
                BTIF_TRACE_DEBUG("%s() Attempting auto pair", __FUNCTION__);
                pin_code.pin[0] = 0x30;
                pin_code.pin[1] = 0x30;
                pin_code.pin[2] = 0x30;
                pin_code.pin[3] = 0x30;

                pairing_cb.autopair_attempts++;
                BTA_DmPinReply( (UINT8*)bd_addr.address, TRUE, 4, pin_code.pin);
 return;
 }
 }
 else if (check_cod(&bd_addr, COD_HID_KEYBOARD) ||
                 check_cod(&bd_addr, COD_HID_COMBO))
 {
 if(( btif_storage_is_fixed_pin_zeros_keyboard (&bd_addr) == TRUE) &&
 (pairing_cb.autopair_attempts == 0))
 {
                BTIF_TRACE_DEBUG("%s() Attempting auto pair", __FUNCTION__);
                pin_code.pin[0] = 0x30;
                pin_code.pin[1] = 0x30;
                pin_code.pin[2] = 0x30;
                pin_code.pin[3] = 0x30;

                pairing_cb.autopair_attempts++;
                BTA_DmPinReply( (UINT8*)bd_addr.address, TRUE, 4, pin_code.pin);
 return;
 }
 }
 }
    HAL_CBACK(bt_hal_cbacks, pin_request_cb,
 &bd_addr, &bd_name, cod, p_pin_req->min_16_digit);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int omx_venc::dev_handle_extradata(void *buffer, int index)
{
 return handle->handle_extradata(buffer, index);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: BufferQueueConsumer::~BufferQueueConsumer() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual void SetUp() {
    vp9_worker_init(&worker_);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void impeg2d_flush_ext_and_user_data(dec_state_t *ps_dec)
{
    UWORD32 u4_start_code;
 stream_t *ps_stream;


     ps_stream    = &ps_dec->s_bit_stream;
     u4_start_code = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);
 
    while(u4_start_code == EXTENSION_START_CODE || u4_start_code == USER_DATA_START_CODE)
     {
         impeg2d_bit_stream_flush(ps_stream,START_CODE_LEN);
        while(impeg2d_bit_stream_nxt(ps_stream,START_CODE_PREFIX_LEN) != START_CODE_PREFIX)
         {
             impeg2d_bit_stream_flush(ps_stream,8);
         }
        u4_start_code = impeg2d_bit_stream_nxt(ps_stream,START_CODE_LEN);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool mkvparser::Match(
    IMkvReader* pReader,
    long long& pos,
    unsigned long id_,
    long long& val)
{
    assert(pReader);
    assert(pos >= 0);
 
    long long total, available;
 
    const long status = pReader->Length(&total, &available);
    assert(status >= 0);
    assert((total < 0) || (available <= total));
    if (status < 0)
        return false;
 
    long len;
 
    const long long id = ReadUInt(pReader, pos, len);
    assert(id >= 0);
    assert(len > 0);
    assert(len <= 8);
    assert((pos + len) <= available);
 
    if ((unsigned long)id != id_)
        return false;
 
    pos += len;  //consume id
 
    const long long size = ReadUInt(pReader, pos, len);
    assert(size >= 0);
    assert(size <= 8);
    assert(len > 0);
    assert(len <= 8);
    assert((pos + len) <= available);
 
    pos += len;  //consume length of size of payload
 
    val = UnserializeUInt(pReader, pos, size);
    assert(val >= 0);
 
    pos += size;  //consume size of payload
    return true;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void NuPlayer::NuPlayerStreamListener::start() {
 for (size_t i = 0; i < kNumBuffers; ++i) {
        mSource->onBufferAvailable(i);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void derive_permissions_recursive_locked(struct fuse* fuse, struct node *parent) {
 struct node *node;
 for (node = parent->child; node; node = node->next) {
        derive_permissions_locked(fuse, parent, node);
 if (node->child) {
            derive_permissions_recursive_locked(fuse, node);
 }
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: char16_t* utf8_to_utf16_no_null_terminator(const uint8_t* u8str, size_t u8len, char16_t* u16str)
{
 const uint8_t* const u8end = u8str + u8len;
 const uint8_t* u8cur = u8str;
 char16_t* u16cur = u16str;

 while (u8cur < u8end) {
 size_t u8len = utf8_codepoint_len(*u8cur);
 uint32_t codepoint = utf8_to_utf32_codepoint(u8cur, u8len);

 if (codepoint <= 0xFFFF) {
 *u16cur++ = (char16_t) codepoint;
 } else {
            codepoint = codepoint - 0x10000;
 *u16cur++ = (char16_t) ((codepoint >> 10) + 0xD800);
 *u16cur++ = (char16_t) ((codepoint & 0x3FF) + 0xDC00);
 }

        u8cur += u8len;
 }
 return u16cur;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE omx_vdec::free_input_buffer(OMX_BUFFERHEADERTYPE *bufferHdr)
{
 unsigned int index = 0;
 if (bufferHdr == NULL || m_inp_mem_ptr == NULL) {
 return OMX_ErrorBadParameter;
 }


     index = bufferHdr - m_inp_mem_ptr;
     DEBUG_PRINT_LOW("Free Input Buffer index = %d",index);
 
     if (index < drv_ctx.ip_buf.actualcount && drv_ctx.ptr_inputbuffer) {
         DEBUG_PRINT_LOW("Free Input Buffer index = %d",index);
         if (drv_ctx.ptr_inputbuffer[index].pmem_fd > 0) {
 struct vdec_setbuffer_cmd setbuffers;
            setbuffers.buffer_type = VDEC_BUFFER_TYPE_INPUT;
            memcpy (&setbuffers.buffer,&drv_ctx.ptr_inputbuffer[index],
 sizeof (vdec_bufferpayload));
 if (!secure_mode) {
                DEBUG_PRINT_LOW("unmap the input buffer fd=%d",
                        drv_ctx.ptr_inputbuffer[index].pmem_fd);
                DEBUG_PRINT_LOW("unmap the input buffer size=%u  address = %p",
 (unsigned int)drv_ctx.ptr_inputbuffer[index].mmaped_size,
                        drv_ctx.ptr_inputbuffer[index].bufferaddr);
                munmap (drv_ctx.ptr_inputbuffer[index].bufferaddr,
                        drv_ctx.ptr_inputbuffer[index].mmaped_size);
 }
            close (drv_ctx.ptr_inputbuffer[index].pmem_fd);
            drv_ctx.ptr_inputbuffer[index].pmem_fd = -1;
 if (m_desc_buffer_ptr && m_desc_buffer_ptr[index].buf_addr) {
                free(m_desc_buffer_ptr[index].buf_addr);
                m_desc_buffer_ptr[index].buf_addr = NULL;
                m_desc_buffer_ptr[index].desc_data_size = 0;
 }
#ifdef USE_ION
            free_ion_memory(&drv_ctx.ip_buf_ion_info[index]);
#endif
 }
 }

 return OMX_ErrorNone;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t NuMediaExtractor::getSampleMeta(sp<MetaData> *sampleMeta) {
 Mutex::Autolock autoLock(mLock);

 *sampleMeta = NULL;

 ssize_t minIndex = fetchTrackSamples();

 if (minIndex < 0) {
 return ERROR_END_OF_STREAM;
 }

 TrackInfo *info = &mSelectedTracks.editItemAt(minIndex);
 *sampleMeta = info->mSample->meta_data();

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  static PropertyDetails GetDetailsImpl(JSObject* holder, uint32_t entry) {
 FixedArray* parameter_map = FixedArray::cast(holder->elements());
 uint32_t length = parameter_map->length() - 2;
 if (entry < length) {
 return PropertyDetails(kData, NONE, 0, PropertyCellType::kNoCell);
 }
 FixedArray* arguments = FixedArray::cast(parameter_map->get(1));
 return ArgumentsAccessor::GetDetailsImpl(arguments, entry - length);
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SimpleSoftOMXComponent::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamPortDefinition:
 {

             OMX_PARAM_PORTDEFINITIONTYPE *defParams =
                 (OMX_PARAM_PORTDEFINITIONTYPE *)params;
 
             if (defParams->nPortIndex >= mPorts.size()) {
                 return OMX_ErrorBadPortIndex;
             }
 if (defParams->nSize != sizeof(OMX_PARAM_PORTDEFINITIONTYPE)) {
 return OMX_ErrorUnsupportedSetting;
 }

 PortInfo *port =
 &mPorts.editItemAt(defParams->nPortIndex);

 if (defParams->nBufferSize > port->mDef.nBufferSize) {
                port->mDef.nBufferSize = defParams->nBufferSize;
 }

 if (defParams->nBufferCountActual < port->mDef.nBufferCountMin) {
                ALOGW("component requires at least %u buffers (%u requested)",
                        port->mDef.nBufferCountMin, defParams->nBufferCountActual);
 return OMX_ErrorUnsupportedSetting;
 }

            port->mDef.nBufferCountActual = defParams->nBufferCountActual;
 return OMX_ErrorNone;
 }

 default:
 return OMX_ErrorUnsupportedIndex;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::setDataSource(const sp<IStreamSource> &source)

 {
     ALOGV("setDataSource");
     status_t err = UNKNOWN_ERROR;
    const sp<IMediaPlayerService>& service(getMediaPlayerService());
     if (service != 0) {
         sp<IMediaPlayer> player(service->create(this, mAudioSessionId));
         if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
 (NO_ERROR != player->setDataSource(source))) {
            player.clear();
 }
        err = attachNewPlayer(player);
 }
 return err;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: display_rc(const display *d, int strict)
{
 return d->error_count + (strict ? d->warning_count : 0);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void rfc_send_sabme(tRFC_MCB* p_mcb, uint8_t dlci) {
 uint8_t* p_data;
 uint8_t cr = RFCOMM_CR(p_mcb->is_initiator, true);
  BT_HDR* p_buf = (BT_HDR*)osi_malloc(RFCOMM_CMD_BUF_SIZE);

  p_buf->offset = L2CAP_MIN_OFFSET;
  p_data = (uint8_t*)(p_buf + 1) + L2CAP_MIN_OFFSET;

 /* SABME frame, command, PF = 1, dlci */
 *p_data++ = RFCOMM_EA | cr | (dlci << RFCOMM_SHIFT_DLCI);
 *p_data++ = RFCOMM_SABME | RFCOMM_PF;
 *p_data++ = RFCOMM_EA | 0;

 *p_data =
      RFCOMM_SABME_FCS((uint8_t*)(p_buf + 1) + L2CAP_MIN_OFFSET, cr, dlci);

  p_buf->len = 4;

  rfc_check_send_cmd(p_mcb, p_buf);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: long Cluster::GetFirst(const BlockEntry*& pFirst) const
{
    if (m_entries_count <= 0)
    {
        long long pos;
        long len;
        const long status = Parse(pos, len);
        if (status < 0)  //error
        {
            pFirst = NULL;
            return status;
        }
        if (m_entries_count <= 0)  //empty cluster
        {
            pFirst = NULL;
            return 0;
        }
    }
    assert(m_entries);
    pFirst = m_entries[0];
    assert(pFirst);
    return 0;  //success
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: OMX_ERRORTYPE  omx_video::component_tunnel_request(OMX_IN OMX_HANDLETYPE  hComp,
        OMX_IN OMX_U32                        port,
        OMX_IN OMX_HANDLETYPE        peerComponent,
        OMX_IN OMX_U32                    peerPort,
        OMX_INOUT OMX_TUNNELSETUPTYPE* tunnelSetup)
{
 (void) hComp, (void) port, (void) peerComponent, (void) peerPort, (void) tunnelSetup;
    DEBUG_PRINT_ERROR("ERROR: component_tunnel_request Not Implemented");
 return OMX_ErrorNotImplemented;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dispatchCarrierRestrictions(Parcel &p, RequestInfo *pRI) {
    RIL_CarrierRestrictions cr;
    RIL_Carrier * allowed_carriers = NULL;
    RIL_Carrier * excluded_carriers = NULL;
 int32_t t;
 status_t status;

    memset(&cr, 0, sizeof(RIL_CarrierRestrictions));

 if (s_callbacks.version < 14) {
        RLOGE("Unsuppoted RIL version %d, min version expected %d",
              s_callbacks.version, 14);
        RIL_onRequestComplete(pRI, RIL_E_REQUEST_NOT_SUPPORTED, NULL, 0);
 return;
 }

    status = p.readInt32(&t);
 if (status != NO_ERROR) {
 goto invalid;
 }
    allowed_carriers = (RIL_Carrier *)calloc(t, sizeof(RIL_Carrier));
 if (allowed_carriers == NULL) {
        RLOGE("Memory allocation failed for request %s", requestToString(pRI->pCI->requestNumber));
 goto exit;
 }
    cr.len_allowed_carriers = t;
    cr.allowed_carriers = allowed_carriers;

    status = p.readInt32(&t);
 if (status != NO_ERROR) {
 goto invalid;
 }
    excluded_carriers = (RIL_Carrier *)calloc(t, sizeof(RIL_Carrier));
 if (excluded_carriers == NULL) {
        RLOGE("Memory allocation failed for request %s", requestToString(pRI->pCI->requestNumber));
 goto exit;
 }
    cr.len_excluded_carriers = t;
    cr.excluded_carriers = excluded_carriers;

    startRequest;
    appendPrintBuf("%s len_allowed_carriers:%d, len_excluded_carriers:%d,",
                   printBuf, cr.len_allowed_carriers, cr.len_excluded_carriers);

    appendPrintBuf("%s allowed_carriers:", printBuf);
 for (int32_t i = 0; i < cr.len_allowed_carriers; i++) {
        RIL_Carrier *p_cr = allowed_carriers + i;
        p_cr->mcc = strdupReadString(p);
        p_cr->mnc = strdupReadString(p);
        status = p.readInt32(&t);
        p_cr->match_type = static_cast<RIL_CarrierMatchType>(t);
 if (status != NO_ERROR) {
 goto invalid;
 }
        p_cr->match_data = strdupReadString(p);
        appendPrintBuf("%s [%d mcc:%s, mnc:%s, match_type:%d, match_data:%s],",
                       printBuf, i, p_cr->mcc, p_cr->mnc, p_cr->match_type, p_cr->match_data);
 }

 for (int32_t i = 0; i < cr.len_excluded_carriers; i++) {
        RIL_Carrier *p_cr = excluded_carriers + i;
        p_cr->mcc = strdupReadString(p);
        p_cr->mnc = strdupReadString(p);
        status = p.readInt32(&t);
        p_cr->match_type = static_cast<RIL_CarrierMatchType>(t);
 if (status != NO_ERROR) {
 goto invalid;
 }
        p_cr->match_data = strdupReadString(p);
        appendPrintBuf("%s [%d mcc:%s, mnc:%s, match_type:%d, match_data:%s],",
                       printBuf, i, p_cr->mcc, p_cr->mnc, p_cr->match_type, p_cr->match_data);
 }

    closeRequest;
    printRequest(pRI->token, pRI->pCI->requestNumber);

    CALL_ONREQUEST(pRI->pCI->requestNumber,
 &cr,
 sizeof(RIL_CarrierRestrictions),
                pRI, pRI->socket_id);

 goto exit;

invalid:
    invalidCommandBlock(pRI);
    RIL_onRequestComplete(pRI, RIL_E_INVALID_ARGUMENTS, NULL, 0);
exit:
 if (allowed_carriers != NULL) {
        free(allowed_carriers);
 }
 if (excluded_carriers != NULL) {
        free(excluded_carriers);
 }
 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: netdutils::Status XfrmController::updateSecurityAssociation(const XfrmSaInfo& record,
 const XfrmSocket& sock) {
    xfrm_usersa_info usersa{};
    nlattr_algo_crypt crypt{};
    nlattr_algo_auth auth{};
    nlattr_algo_aead aead{};
    nlattr_xfrm_mark xfrmmark{};
    nlattr_xfrm_output_mark xfrmoutputmark{};
    nlattr_encap_tmpl encap{};

 enum {
        NLMSG_HDR,
        USERSA,
        USERSA_PAD,
        CRYPT,
        CRYPT_PAD,
        AUTH,
        AUTH_PAD,
        AEAD,
        AEAD_PAD,
        MARK,
        MARK_PAD,
        OUTPUT_MARK,
        OUTPUT_MARK_PAD,
        ENCAP,
        ENCAP_PAD,
 };

    std::vector<iovec> iov = {
 {NULL, 0}, // reserved for the eventual addition of a NLMSG_HDR
 {&usersa, 0}, // main usersa_info struct
 {kPadBytes, 0}, // up to NLMSG_ALIGNTO pad bytes of padding
 {&crypt, 0}, // adjust size if crypt algo is present
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 {&auth, 0}, // adjust size if auth algo is present
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 {&aead, 0}, // adjust size if aead algo is present
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 {&xfrmmark, 0}, // adjust size if xfrm mark is present
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 {&xfrmoutputmark, 0}, // adjust size if xfrm output mark is present
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 {&encap, 0}, // adjust size if encapsulating
 {kPadBytes, 0}, // up to NLATTR_ALIGNTO pad bytes
 };

 if (!record.aead.name.empty() && (!record.auth.name.empty() || !record.crypt.name.empty())) {
 return netdutils::statusFromErrno(EINVAL, "Invalid xfrm algo selection; AEAD is mutually "
 "exclusive with both Authentication and "
 "Encryption");
 }

 if (record.aead.key.size() > MAX_KEY_LENGTH || record.auth.key.size() > MAX_KEY_LENGTH ||
        record.crypt.key.size() > MAX_KEY_LENGTH) {
 return netdutils::statusFromErrno(EINVAL, "Key length invalid; exceeds MAX_KEY_LENGTH");
 }

 int len;
    len = iov[USERSA].iov_len = fillUserSaInfo(record, &usersa);
    iov[USERSA_PAD].iov_len = NLMSG_ALIGN(len) - len;

    len = iov[CRYPT].iov_len = fillNlAttrXfrmAlgoEnc(record.crypt, &crypt);
    iov[CRYPT_PAD].iov_len = NLA_ALIGN(len) - len;

    len = iov[AUTH].iov_len = fillNlAttrXfrmAlgoAuth(record.auth, &auth);
    iov[AUTH_PAD].iov_len = NLA_ALIGN(len) - len;

    len = iov[AEAD].iov_len = fillNlAttrXfrmAlgoAead(record.aead, &aead);
    iov[AEAD_PAD].iov_len = NLA_ALIGN(len) - len;

    len = iov[MARK].iov_len = fillNlAttrXfrmMark(record, &xfrmmark);
    iov[MARK_PAD].iov_len = NLA_ALIGN(len) - len;

    len = iov[OUTPUT_MARK].iov_len = fillNlAttrXfrmOutputMark(record.netId, &xfrmoutputmark);
    iov[OUTPUT_MARK_PAD].iov_len = NLA_ALIGN(len) - len;

    len = iov[ENCAP].iov_len = fillNlAttrXfrmEncapTmpl(record, &encap);
    iov[ENCAP_PAD].iov_len = NLA_ALIGN(len) - len;

 return sock.sendMessage(XFRM_MSG_UPDSA, NETLINK_REQUEST_FLAGS, 0, &iov);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void smp_start_enc(tSMP_CB* p_cb, tSMP_INT_DATA* p_data) {
  tBTM_STATUS cmd;

  SMP_TRACE_DEBUG("%s", __func__);
 if (p_data != NULL)
    cmd = btm_ble_start_encrypt(p_cb->pairing_bda, true, p_data->key.p_data);
 else
    cmd = btm_ble_start_encrypt(p_cb->pairing_bda, false, NULL);

 if (cmd != BTM_CMD_STARTED && cmd != BTM_BUSY) {
    tSMP_INT_DATA smp_int_data;
    smp_int_data.status = SMP_ENC_FAIL;
    smp_sm_event(p_cb, SMP_AUTH_CMPL_EVT, &smp_int_data);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftRaw::initPorts() {
    OMX_PARAM_PORTDEFINITIONTYPE def;
 InitOMXParams(&def);

    def.nPortIndex = 0;
    def.eDir = OMX_DirInput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 32 * 1024;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 1;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);

    def.nPortIndex = 1;
    def.eDir = OMX_DirOutput;
    def.nBufferCountMin = kNumBuffers;
    def.nBufferCountActual = def.nBufferCountMin;
    def.nBufferSize = 32 * 1024;
    def.bEnabled = OMX_TRUE;
    def.bPopulated = OMX_FALSE;
    def.eDomain = OMX_PortDomainAudio;
    def.bBuffersContiguous = OMX_FALSE;
    def.nBufferAlignment = 2;

    def.format.audio.cMIMEType = const_cast<char *>("audio/raw");
    def.format.audio.pNativeRender = NULL;
    def.format.audio.bFlagErrorConcealment = OMX_FALSE;
    def.format.audio.eEncoding = OMX_AUDIO_CodingPCM;

    addPort(def);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: ANativeWindowBuffer* GraphicBuffer::getNativeBuffer() const
{
    LOG_ALWAYS_FATAL_IF(this == NULL, "getNativeBuffer() called on NULL GraphicBuffer");
 return static_cast<ANativeWindowBuffer*>(
 const_cast<GraphicBuffer*>(this));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Parcel::readInt64Vector(std::vector<int64_t>* val) const {
 return readTypedVector(val, &Parcel::readInt64);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t CameraClient::cancelAutoFocus() {
    LOG1("cancelAutoFocus (pid %d)", getCallingPid());

 Mutex::Autolock lock(mLock);
 status_t result = checkPidAndHardware();
 if (result != NO_ERROR) return result;

 return mHardware->cancelAutoFocus();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: sp<MetaData> OMXCodec::getFormat() {
 Mutex::Autolock autoLock(mLock);

 return mOutputFormat;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t ctrl_set_postproc(vpx_codec_alg_priv_t *ctx,
                                         va_list args) {
#if CONFIG_VP9_POSTPROC
 vp8_postproc_cfg_t *data = va_arg(args, vp8_postproc_cfg_t *);

 if (data) {
    ctx->postproc_cfg_set = 1;
    ctx->postproc_cfg = *((vp8_postproc_cfg_t *)data);
 return VPX_CODEC_OK;
 } else {
 return VPX_CODEC_INVALID_PARAM;
 }
#else
 (void)ctx;
 (void)args;
 return VPX_CODEC_INCAPABLE;
#endif
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool venc_dev::venc_set_config(void *configData, OMX_INDEXTYPE index)
{

    DEBUG_PRINT_LOW("Inside venc_set_config");

 switch ((int)index) {
 case OMX_IndexConfigVideoBitrate:
 {
                OMX_VIDEO_CONFIG_BITRATETYPE *bit_rate = (OMX_VIDEO_CONFIG_BITRATETYPE *)
                    configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_IndexConfigVideoBitrate");

 if (bit_rate->nPortIndex == (OMX_U32)PORT_INDEX_OUT) {
 if (venc_set_target_bitrate(bit_rate->nEncodeBitrate, 1) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Setting Target Bit rate failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_IndexConfigVideoBitrate");
 }

 break;
 }
 case OMX_IndexConfigVideoFramerate:
 {
                OMX_CONFIG_FRAMERATETYPE *frame_rate = (OMX_CONFIG_FRAMERATETYPE *)
                    configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_IndexConfigVideoFramerate");

 if (frame_rate->nPortIndex == (OMX_U32)PORT_INDEX_OUT) {
 if (venc_set_encode_framerate(frame_rate->xEncodeFramerate, 1) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Setting Encode Framerate failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_IndexConfigVideoFramerate");
 }

 break;
 }
 case QOMX_IndexConfigVideoIntraperiod:
 {
                DEBUG_PRINT_LOW("venc_set_param:QOMX_IndexConfigVideoIntraperiod");
                QOMX_VIDEO_INTRAPERIODTYPE *intraperiod =
 (QOMX_VIDEO_INTRAPERIODTYPE *)configData;

 if (intraperiod->nPortIndex == (OMX_U32) PORT_INDEX_OUT) {
 if (venc_set_intra_period(intraperiod->nPFrames, intraperiod->nBFrames) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Request for setting intra period failed");
 return false;
 }
 }

 break;
 }
 case OMX_IndexConfigVideoIntraVOPRefresh:
 {
                OMX_CONFIG_INTRAREFRESHVOPTYPE *intra_vop_refresh = (OMX_CONFIG_INTRAREFRESHVOPTYPE *)
                    configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_IndexConfigVideoIntraVOPRefresh");

 if (intra_vop_refresh->nPortIndex == (OMX_U32)PORT_INDEX_OUT) {
 if (venc_set_intra_vop_refresh(intra_vop_refresh->IntraRefreshVOP) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Setting Encode Framerate failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_IndexConfigVideoFramerate");
 }

 break;
 }
 case OMX_IndexConfigCommonRotate:
 {
                OMX_CONFIG_ROTATIONTYPE *config_rotation =
 reinterpret_cast<OMX_CONFIG_ROTATIONTYPE*>(configData);
                OMX_U32 nFrameWidth;
 if (!config_rotation) {
 return false;
 }
 if (true == deinterlace_enabled) {
                    DEBUG_PRINT_ERROR("ERROR: Rotation is not supported with deinterlacing");
 return false;
 }
                DEBUG_PRINT_HIGH("venc_set_config: updating the new Dims");
                nFrameWidth = m_sVenc_cfg.dvs_width;
                m_sVenc_cfg.dvs_width  = m_sVenc_cfg.dvs_height;
                m_sVenc_cfg.dvs_height = nFrameWidth;

 if(venc_set_vpe_rotation(config_rotation->nRotation) == false) {
                    DEBUG_PRINT_ERROR("ERROR: Dimension Change for Rotation failed");
 return false;
 }

 break;
 }
 case OMX_IndexConfigVideoAVCIntraPeriod:
 {
                OMX_VIDEO_CONFIG_AVCINTRAPERIOD *avc_iperiod = (OMX_VIDEO_CONFIG_AVCINTRAPERIOD*) configData;
                DEBUG_PRINT_LOW("venc_set_param: OMX_IndexConfigVideoAVCIntraPeriod");

 if (venc_set_idr_period(avc_iperiod->nPFrames, avc_iperiod->nIDRPeriod)
 == false) {
                    DEBUG_PRINT_ERROR("ERROR: Setting "
 "OMX_IndexConfigVideoAVCIntraPeriod failed");
 return false;
 }
 break;
 }
 case OMX_IndexConfigCommonDeinterlace:
 {
                OMX_VIDEO_CONFIG_DEINTERLACE *deinterlace = (OMX_VIDEO_CONFIG_DEINTERLACE *) configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_IndexConfigCommonDeinterlace");
 if(deinterlace->nPortIndex == (OMX_U32)PORT_INDEX_OUT) {
 if (m_sVenc_cfg.dvs_width == m_sVenc_cfg.input_height &&
                        m_sVenc_cfg.dvs_height == m_sVenc_cfg.input_width)
 {
                        DEBUG_PRINT_ERROR("ERROR: Deinterlace not supported with rotation");
 return false;
 }
 if(venc_set_deinterlace(deinterlace->nEnable) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Setting Deinterlace failed");
 return false;
 }
 } else {
                DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_IndexConfigCommonDeinterlace");
 }
 break;
 }
 case OMX_IndexConfigVideoVp8ReferenceFrame:
 {
               OMX_VIDEO_VP8REFERENCEFRAMETYPE* vp8refframe = (OMX_VIDEO_VP8REFERENCEFRAMETYPE*) configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_IndexConfigVideoVp8ReferenceFrame");
 if ((vp8refframe->nPortIndex == (OMX_U32)PORT_INDEX_IN) &&
 (vp8refframe->bUseGoldenFrame)) {
 if(venc_set_useltr(0x1) == false) {
                        DEBUG_PRINT_ERROR("ERROR: use goldenframe failed");
 return false;
 }
 } else if((vp8refframe->nPortIndex == (OMX_U32)PORT_INDEX_IN) &&
 (vp8refframe->bGoldenFrameRefresh)) {
 if(venc_set_markltr(0x1) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Setting goldenframe failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_IndexConfigVideoVp8ReferenceFrame");
 }
 break;
 }
 case OMX_QcomIndexConfigVideoLTRUse:
 {
                OMX_QCOM_VIDEO_CONFIG_LTRUSE_TYPE* pParam = (OMX_QCOM_VIDEO_CONFIG_LTRUSE_TYPE*)configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_QcomIndexConfigVideoLTRUse");
 if (pParam->nPortIndex == (OMX_U32)PORT_INDEX_IN) {
 if (venc_set_useltr(pParam->nID) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Use LTR failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_QcomIndexConfigVideoLTRUse");
 }
 break;
 }
 case OMX_QcomIndexConfigVideoLTRMark:
 {
                OMX_QCOM_VIDEO_CONFIG_LTRMARK_TYPE* pParam = (OMX_QCOM_VIDEO_CONFIG_LTRMARK_TYPE*)configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_QcomIndexConfigVideoLTRMark");
 if (pParam->nPortIndex == (OMX_U32)PORT_INDEX_IN) {
 if (venc_set_markltr(pParam->nID) == false) {
                        DEBUG_PRINT_ERROR("ERROR: Mark LTR failed");
 return false;
 }
 } else {
                    DEBUG_PRINT_ERROR("ERROR: Invalid Port Index for OMX_QcomIndexConfigVideoLTRMark");
 }
 break;
 }
 case OMX_QcomIndexConfigPerfLevel:
 {
                OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *perf =
 (OMX_QCOM_VIDEO_CONFIG_PERF_LEVEL *)configData;
                DEBUG_PRINT_LOW("Set perf level: %d", perf->ePerfLevel);
 if (!venc_set_perf_level(perf->ePerfLevel)) {
                    DEBUG_PRINT_ERROR("ERROR: Failed to set perf level to %d", perf->ePerfLevel);
 return false;
 } else {
                    performance_level.perflevel = (unsigned int) perf->ePerfLevel;
 }
 break;
 }
 case OMX_QcomIndexConfigVideoVencPerfMode:
 {
                QOMX_EXTNINDEX_VIDEO_PERFMODE *pParam = (QOMX_EXTNINDEX_VIDEO_PERFMODE *) configData;
                DEBUG_PRINT_LOW("venc_set_config: OMX_QcomIndexConfigVideoVencPerfMode");
 if (venc_set_perf_mode(pParam->nPerfMode) == false) {
                    DEBUG_PRINT_ERROR("Failed to set V4L2_CID_MPEG_VIDC_VIDEO_PERF_MODE");
 return false;
 }
 break;
 }
 case OMX_IndexConfigPriority:
 {
                OMX_PARAM_U32TYPE *priority = (OMX_PARAM_U32TYPE *)configData;
                DEBUG_PRINT_LOW("Set_config: priority %u",priority->nU32);
 if (!venc_set_session_priority(priority->nU32)) {
                    DEBUG_PRINT_ERROR("Failed to set priority");
 return false;
 }
 break;
 }
 case OMX_IndexConfigOperatingRate:
 {
                OMX_PARAM_U32TYPE *rate = (OMX_PARAM_U32TYPE *)configData;
                DEBUG_PRINT_LOW("Set_config: operating rate %d", rate->nU32);
 if (!venc_set_operatingrate(rate->nU32)) {
                    DEBUG_PRINT_ERROR("Failed to set operating rate");
 return false;
 }
 break;
 }
 default:
            DEBUG_PRINT_ERROR("Unsupported config index = %u", index);
 break;
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: list index out of range


Instruction: 
Input:  void SoftAVC::drainAllOutputBuffers(bool eos) {
 List<BufferInfo *> &outQueue = getPortQueue(kOutputPortIndex);
    H264SwDecPicture decodedPicture;

 if (mHeadersDecoded) {
 while (!outQueue.empty()
 && H264SWDEC_PIC_RDY == H264SwDecNextPicture(

                     mHandle, &decodedPicture, eos /* flush */)) {
             int32_t picId = decodedPicture.picId;
             uint8_t *data = (uint8_t *) decodedPicture.pOutputPicture;
            drainOneOutputBuffer(picId, data);
         }
     }
 
 if (!eos) {
 return;
 }

 while (!outQueue.empty()) {
 BufferInfo *outInfo = *outQueue.begin();
        outQueue.erase(outQueue.begin());
        OMX_BUFFERHEADERTYPE *outHeader = outInfo->mHeader;

        outHeader->nTimeStamp = 0;
        outHeader->nFilledLen = 0;
        outHeader->nFlags = OMX_BUFFERFLAG_EOS;

        outInfo->mOwnedByUs = false;
        notifyFillBufferDone(outHeader);

        mEOSStatus = OUTPUT_FRAMES_FLUSHED;
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void marshallSignalInfoRecord(Parcel &p,
            RIL_CDMA_SignalInfoRecord &p_signalInfoRecord) {
    p.writeInt32(p_signalInfoRecord.isPresent);
    p.writeInt32(p_signalInfoRecord.signalType);
    p.writeInt32(p_signalInfoRecord.alertPitch);
    p.writeInt32(p_signalInfoRecord.signal);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void SoftVPXEncoder::onQueueFilled(OMX_U32 /* portIndex */) {
 if (mCodecContext == NULL) {
 if (OK != initEncoder()) {
            ALOGE("Failed to initialize encoder");
            notify(OMX_EventError,
                   OMX_ErrorUndefined,
 0, // Extra notification data
                   NULL); // Notification data pointer
 return;
 }
 }

 vpx_codec_err_t codec_return;
 List<BufferInfo *> &inputBufferInfoQueue = getPortQueue(kInputPortIndex);
 List<BufferInfo *> &outputBufferInfoQueue = getPortQueue(kOutputPortIndex);

 while (!inputBufferInfoQueue.empty() && !outputBufferInfoQueue.empty()) {
 BufferInfo *inputBufferInfo = *inputBufferInfoQueue.begin();
        OMX_BUFFERHEADERTYPE *inputBufferHeader = inputBufferInfo->mHeader;

 BufferInfo *outputBufferInfo = *outputBufferInfoQueue.begin();
        OMX_BUFFERHEADERTYPE *outputBufferHeader = outputBufferInfo->mHeader;

 if ((inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) &&
                inputBufferHeader->nFilledLen == 0) {
            inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());
            inputBufferInfo->mOwnedByUs = false;
            notifyEmptyBufferDone(inputBufferHeader);

            outputBufferHeader->nFilledLen = 0;
            outputBufferHeader->nFlags = OMX_BUFFERFLAG_EOS;

            outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());
            outputBufferInfo->mOwnedByUs = false;
            notifyFillBufferDone(outputBufferHeader);
 return;
 }


         const uint8_t *source =
             inputBufferHeader->pBuffer + inputBufferHeader->nOffset;
 
         if (mInputDataIsMeta) {
             source = extractGraphicBuffer(
                    mConversionBuffer, mWidth * mHeight * 3 / 2,
                     source, inputBufferHeader->nFilledLen,
                     mWidth, mHeight);
             if (source == NULL) {
                ALOGE("Unable to extract gralloc buffer in metadata mode");

                 notify(OMX_EventError, OMX_ErrorUndefined, 0, 0);
                 return;
             }
        } else if (mColorFormat == OMX_COLOR_FormatYUV420SemiPlanar) {
            ConvertYUV420SemiPlanarToYUV420Planar(
                    source, mConversionBuffer, mWidth, mHeight);
 
            source = mConversionBuffer;
         }
         vpx_image_t raw_frame;
         vpx_img_wrap(&raw_frame, VPX_IMG_FMT_I420, mWidth, mHeight,
                     kInputBufferAlignment, (uint8_t *)source);

 vpx_enc_frame_flags_t flags = 0;
 if (mTemporalPatternLength > 0) {
            flags = getEncodeFlags();
 }
 if (mKeyFrameRequested) {
            flags |= VPX_EFLAG_FORCE_KF;
            mKeyFrameRequested = false;
 }

 if (mBitrateUpdated) {
            mCodecConfiguration->rc_target_bitrate = mBitrate/1000;
 vpx_codec_err_t res = vpx_codec_enc_config_set(mCodecContext,
                                                           mCodecConfiguration);
 if (res != VPX_CODEC_OK) {
                ALOGE("vp8 encoder failed to update bitrate: %s",
                      vpx_codec_err_to_string(res));
                notify(OMX_EventError,
                       OMX_ErrorUndefined,
 0, // Extra notification data
                       NULL); // Notification data pointer
 }
            mBitrateUpdated = false;
 }

 uint32_t frameDuration;
 if (inputBufferHeader->nTimeStamp > mLastTimestamp) {
            frameDuration = (uint32_t)(inputBufferHeader->nTimeStamp - mLastTimestamp);
 } else {
            frameDuration = (uint32_t)(((uint64_t)1000000 << 16) / mFramerate);
 }
        mLastTimestamp = inputBufferHeader->nTimeStamp;
        codec_return = vpx_codec_encode(
                mCodecContext,
 &raw_frame,
                inputBufferHeader->nTimeStamp, // in timebase units
                frameDuration, // frame duration in timebase units
                flags, // frame flags
                VPX_DL_REALTIME); // encoding deadline
 if (codec_return != VPX_CODEC_OK) {
            ALOGE("vpx encoder failed to encode frame");
            notify(OMX_EventError,
                   OMX_ErrorUndefined,
 0, // Extra notification data
                   NULL); // Notification data pointer
 return;
 }

 vpx_codec_iter_t encoded_packet_iterator = NULL;
 const vpx_codec_cx_pkt_t* encoded_packet;

 while ((encoded_packet = vpx_codec_get_cx_data(
                        mCodecContext, &encoded_packet_iterator))) {
 if (encoded_packet->kind == VPX_CODEC_CX_FRAME_PKT) {

                 outputBufferHeader->nTimeStamp = encoded_packet->data.frame.pts;
                 outputBufferHeader->nFlags = 0;
                 if (encoded_packet->data.frame.flags & VPX_FRAME_IS_KEY)
                  outputBufferHeader->nFlags |= OMX_BUFFERFLAG_SYNCFRAME;
                 outputBufferHeader->nOffset = 0;
                 outputBufferHeader->nFilledLen = encoded_packet->data.frame.sz;
                 memcpy(outputBufferHeader->pBuffer,
                        encoded_packet->data.frame.buf,
                        encoded_packet->data.frame.sz);
                outputBufferInfo->mOwnedByUs = false;
                outputBufferInfoQueue.erase(outputBufferInfoQueue.begin());
 if (inputBufferHeader->nFlags & OMX_BUFFERFLAG_EOS) {
                    outputBufferHeader->nFlags |= OMX_BUFFERFLAG_EOS;
 }
                notifyFillBufferDone(outputBufferHeader);
 }
 }

        inputBufferInfo->mOwnedByUs = false;
        inputBufferInfoQueue.erase(inputBufferInfoQueue.begin());
        notifyEmptyBufferDone(inputBufferHeader);
 }
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: void OMX::invalidateNodeID_l(node_id node) {
    mNodeIDToInstance.removeItem(node);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXCodec::onStateChange(OMX_STATETYPE newState) {
    CODEC_LOGV("onStateChange %d", newState);

 switch (newState) {
 case OMX_StateIdle:
 {
            CODEC_LOGV("Now Idle.");
 if (mState == LOADED_TO_IDLE) {
 status_t err = mOMX->sendCommand(
                        mNode, OMX_CommandStateSet, OMX_StateExecuting);

                CHECK_EQ(err, (status_t)OK);

                setState(IDLE_TO_EXECUTING);
 } else {
                CHECK_EQ((int)mState, (int)EXECUTING_TO_IDLE);

 if (countBuffersWeOwn(mPortBuffers[kPortIndexInput]) !=
                    mPortBuffers[kPortIndexInput].size()) {
                    ALOGE("Codec did not return all input buffers "
 "(received %zu / %zu)",
                            countBuffersWeOwn(mPortBuffers[kPortIndexInput]),
                            mPortBuffers[kPortIndexInput].size());
                    TRESPASS();
 }

 if (countBuffersWeOwn(mPortBuffers[kPortIndexOutput]) !=
                    mPortBuffers[kPortIndexOutput].size()) {
                    ALOGE("Codec did not return all output buffers "
 "(received %zu / %zu)",
                            countBuffersWeOwn(mPortBuffers[kPortIndexOutput]),
                            mPortBuffers[kPortIndexOutput].size());
                    TRESPASS();
 }

 status_t err = mOMX->sendCommand(
                        mNode, OMX_CommandStateSet, OMX_StateLoaded);

                CHECK_EQ(err, (status_t)OK);

                err = freeBuffersOnPort(kPortIndexInput);
                CHECK_EQ(err, (status_t)OK);

                err = freeBuffersOnPort(kPortIndexOutput);
                CHECK_EQ(err, (status_t)OK);

                mPortStatus[kPortIndexInput] = ENABLED;
                mPortStatus[kPortIndexOutput] = ENABLED;

 if ((mFlags & kEnableGrallocUsageProtected) &&
                        mNativeWindow != NULL) {
                    pushBlankBuffersToNativeWindow(mNativeWindow.get());
 }

                setState(IDLE_TO_LOADED);
 }
 break;
 }

 case OMX_StateExecuting:
 {
            CHECK_EQ((int)mState, (int)IDLE_TO_EXECUTING);

            CODEC_LOGV("Now Executing.");

            mOutputPortSettingsChangedPending = false;

            setState(EXECUTING);

 break;
 }

 case OMX_StateLoaded:
 {
            CHECK_EQ((int)mState, (int)IDLE_TO_LOADED);

            CODEC_LOGV("Now Loaded.");

            setState(LOADED);
 break;
 }

 case OMX_StateInvalid:
 {
            setState(ERROR);
 break;
 }

 default:
 {
            CHECK(!"should not be here.");
 break;
 }
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: inline Syscalls& getSyscallInstance() { return netdutils::sSyscalls.get(); }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::processCaptureResult(const camera3_capture_result *result) {
    ATRACE_CALL();

 status_t res;

 uint32_t frameNumber = result->frame_number;
 if (result->result == NULL && result->num_output_buffers == 0 &&
            result->input_buffer == NULL) {
        SET_ERR("No result data provided by HAL for frame %d",
                frameNumber);
 return;
 }

 if (!mUsePartialResult &&
            mDeviceVersion >= CAMERA_DEVICE_API_VERSION_3_2 &&
            result->result != NULL &&
            result->partial_result != 1) {
        SET_ERR("Result is malformed for frame %d: partial_result %u must be 1"
 " if partial result is not supported",
                frameNumber, result->partial_result);
 return;
 }

 bool isPartialResult = false;
 CameraMetadata collectedPartialResult;
 CaptureResultExtras resultExtras;
 bool hasInputBufferInRequest = false;

 nsecs_t shutterTimestamp = 0;

 {
 Mutex::Autolock l(mInFlightLock);
 ssize_t idx = mInFlightMap.indexOfKey(frameNumber);
 if (idx == NAME_NOT_FOUND) {
            SET_ERR("Unknown frame number for capture result: %d",
                    frameNumber);
 return;
 }
 InFlightRequest &request = mInFlightMap.editValueAt(idx);
        ALOGVV("%s: got InFlightRequest requestId = %" PRId32
 ", frameNumber = %" PRId64 ", burstId = %" PRId32
 ", partialResultCount = %d",
                __FUNCTION__, request.resultExtras.requestId,
                request.resultExtras.frameNumber, request.resultExtras.burstId,
                result->partial_result);
 if (result->partial_result != 0)
            request.resultExtras.partialResultCount = result->partial_result;

 if (mUsePartialResult && result->result != NULL) {
 if (mDeviceVersion >= CAMERA_DEVICE_API_VERSION_3_2) {
 if (result->partial_result > mNumPartialResults || result->partial_result < 1) {
                    SET_ERR("Result is malformed for frame %d: partial_result %u must be  in"
 " the range of [1, %d] when metadata is included in the result",
                            frameNumber, result->partial_result, mNumPartialResults);
 return;
 }
                isPartialResult = (result->partial_result < mNumPartialResults);
 if (isPartialResult) {
                    request.partialResult.collectedResult.append(result->result);
 }
 } else {
 camera_metadata_ro_entry_t partialResultEntry;
                res = find_camera_metadata_ro_entry(result->result,
                        ANDROID_QUIRKS_PARTIAL_RESULT, &partialResultEntry);
 if (res != NAME_NOT_FOUND &&
                        partialResultEntry.count > 0 &&
                        partialResultEntry.data.u8[0] ==
                        ANDROID_QUIRKS_PARTIAL_RESULT_PARTIAL) {
                    isPartialResult = true;
                    request.partialResult.collectedResult.append(
                        result->result);
                    request.partialResult.collectedResult.erase(
                        ANDROID_QUIRKS_PARTIAL_RESULT);
 }
 }

 if (isPartialResult) {
 if (!request.partialResult.haveSent3A) {
                    request.partialResult.haveSent3A =
                            processPartial3AResult(frameNumber,
                                    request.partialResult.collectedResult,
                                    request.resultExtras);
 }
 }
 }

        shutterTimestamp = request.shutterTimestamp;
        hasInputBufferInRequest = request.hasInputBuffer;

 if (result->result != NULL && !isPartialResult) {
 if (request.haveResultMetadata) {
                SET_ERR("Called multiple times with metadata for frame %d",
                        frameNumber);
 return;
 }
 if (mUsePartialResult &&
 !request.partialResult.collectedResult.isEmpty()) {
                collectedPartialResult.acquire(
                    request.partialResult.collectedResult);
 }
            request.haveResultMetadata = true;
 }

 uint32_t numBuffersReturned = result->num_output_buffers;
 if (result->input_buffer != NULL) {
 if (hasInputBufferInRequest) {
                numBuffersReturned += 1;
 } else {
                ALOGW("%s: Input buffer should be NULL if there is no input"
 " buffer sent in the request",
                        __FUNCTION__);
 }
 }
        request.numBuffersLeft -= numBuffersReturned;
 if (request.numBuffersLeft < 0) {
            SET_ERR("Too many buffers returned for frame %d",
                    frameNumber);
 return;
 }

 camera_metadata_ro_entry_t entry;
        res = find_camera_metadata_ro_entry(result->result,
                ANDROID_SENSOR_TIMESTAMP, &entry);
 if (res == OK && entry.count == 1) {
            request.sensorTimestamp = entry.data.i64[0];
 }

 if (shutterTimestamp == 0) {
            request.pendingOutputBuffers.appendArray(result->output_buffers,
                result->num_output_buffers);
 } else {
            returnOutputBuffers(result->output_buffers,
                result->num_output_buffers, shutterTimestamp);
 }

 if (result->result != NULL && !isPartialResult) {
 if (shutterTimestamp == 0) {
                request.pendingMetadata = result->result;
                request.partialResult.collectedResult = collectedPartialResult;
 } else {
 CameraMetadata metadata;
                metadata = result->result;
                sendCaptureResult(metadata, request.resultExtras,
                    collectedPartialResult, frameNumber, hasInputBufferInRequest,
                    request.aeTriggerCancelOverride);
 }
 }

        removeInFlightRequestIfReadyLocked(idx);
 } // scope for mInFlightLock

 if (result->input_buffer != NULL) {
 if (hasInputBufferInRequest) {
 Camera3Stream *stream =
 Camera3Stream::cast(result->input_buffer->stream);
            res = stream->returnInputBuffer(*(result->input_buffer));
 if (res != OK) {
                ALOGE("%s: RequestThread: Can't return input buffer for frame %d to"
 "  its stream:%s (%d)",  __FUNCTION__,
                      frameNumber, strerror(-res), res);
 }
 } else {
            ALOGW("%s: Input buffer should be NULL if there is no input"
 " buffer sent in the request, skipping input buffer return.",
                    __FUNCTION__);
 }
 }
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: xmlFatalErrMsgInt(xmlParserCtxtPtr ctxt, xmlParserErrors error,
 const char *msg, int val)
{
 if ((ctxt != NULL) && (ctxt->disableSAX != 0) &&
 (ctxt->instate == XML_PARSER_EOF))
 return;
 if (ctxt != NULL)
	ctxt->errNo = error;
    __xmlRaiseError(NULL, NULL, NULL,
                    ctxt, NULL, XML_FROM_PARSER, error, XML_ERR_FATAL,
                    NULL, 0, NULL, NULL, NULL, val, 0, msg, val);
 if (ctxt != NULL) {
	ctxt->wellFormed = 0;
 if (ctxt->recovery == 0)
	    ctxt->disableSAX = 1;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: xmlCtxtReadMemory(xmlParserCtxtPtr ctxt, const char *buffer, int size,
 const char *URL, const char *encoding, int options)
{
    xmlParserInputBufferPtr input;
    xmlParserInputPtr stream;

 if (ctxt == NULL)
 return (NULL);
 if (buffer == NULL)
 return (NULL);
    xmlInitParser();

    xmlCtxtReset(ctxt);

    input = xmlParserInputBufferCreateMem(buffer, size, XML_CHAR_ENCODING_NONE);
 if (input == NULL) {
 return(NULL);
 }

    stream = xmlNewIOInputStream(ctxt, input, XML_CHAR_ENCODING_NONE);
 if (stream == NULL) {
	xmlFreeParserInputBuffer(input);
 return(NULL);
 }

    inputPush(ctxt, stream);
 return (xmlDoRead(ctxt, URL, encoding, options, 1));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_video::allocate_done(void)
{
 bool bRet = false;
 bool bRet_In = false;
 bool bRet_Out = false;

    bRet_In = allocate_input_done();
    bRet_Out = allocate_output_done();

 if (bRet_In && bRet_Out) {
        bRet = true;
 }

 return bRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: WORD32 ih264d_mark_err_slice_skip(dec_struct_t * ps_dec,
                                WORD32 num_mb_skip,
                                UWORD8 u1_is_idr_slice,
                                UWORD16 u2_frame_num,
 pocstruct_t *ps_cur_poc,
                                WORD32 prev_slice_err)
{
    WORD32 i2_cur_mb_addr;
    UWORD32 u1_num_mbs, u1_num_mbsNby2;
    UWORD32 u1_mb_idx = ps_dec->u1_mb_idx;
    UWORD32 i2_mb_skip_run;

    UWORD32 u1_num_mbs_next, u1_end_of_row;
 const UWORD32 i2_pic_wdin_mbs = ps_dec->u2_frm_wd_in_mbs;
    UWORD32 u1_slice_end;
    UWORD32 u1_tfr_n_mb;
    UWORD32 u1_decode_nmb;
 dec_bit_stream_t * const ps_bitstrm = ps_dec->ps_bitstrm;
 dec_slice_params_t * ps_slice = ps_dec->ps_cur_slice;
    UWORD32 *pu4_bitstrm_buf = ps_bitstrm->pu4_buffer;
    UWORD32 *pu4_bitstrm_ofst = &ps_bitstrm->u4_ofst;
 deblk_mb_t *ps_cur_deblk_mb;
 dec_mb_info_t *ps_cur_mb_info;
 parse_pmbarams_t *ps_parse_mb_data;
    UWORD32 u1_inter_mb_type;
    UWORD32 u1_deblk_mb_type;
    UWORD16 u2_total_mbs_coded;
    UWORD32 u1_mbaff = ps_slice->u1_mbaff_frame_flag;
 parse_part_params_t *ps_part_info;
    WORD32 ret;


 if(ps_dec->ps_dec_err_status->u1_err_flag & REJECT_CUR_PIC)
 {
        ih264d_err_pic_dispbuf_mgr(ps_dec);
 return 0;
 }

 if(ps_dec->ps_cur_slice->u1_mbaff_frame_flag && (num_mb_skip & 1))
 {
        num_mb_skip++;
 }
    ps_dec->ps_dpb_cmds->u1_long_term_reference_flag = 0;
 if(prev_slice_err == 1)
 {
 /* first slice - missing/header corruption */
        ps_dec->ps_cur_slice->u2_frame_num = u2_frame_num;


 if(!ps_dec->u1_first_slice_in_stream)
 {
            ih264d_end_of_pic(ps_dec, u1_is_idr_slice,
                ps_dec->ps_cur_slice->u2_frame_num);
            ps_dec->s_cur_pic_poc.u2_frame_num =
                ps_dec->ps_cur_slice->u2_frame_num;
 }

 {
            WORD32 i, j, poc = 0;

            ps_dec->ps_cur_slice->u2_first_mb_in_slice = 0;

            ps_dec->pf_mvpred = ih264d_mvpred_nonmbaff;
            ps_dec->p_form_mb_part_info = ih264d_form_mb_part_info_bp;
            ps_dec->p_motion_compensate = ih264d_motion_compensate_bp;

 if(ps_dec->ps_cur_pic != NULL)
                poc = ps_dec->ps_cur_pic->i4_poc + 2;

            j = -1;
 for(i = 0; i < MAX_NUM_PIC_PARAMS; i++)
 {
 if(ps_dec->ps_pps[i].u1_is_valid == TRUE)
 {
 if(ps_dec->ps_pps[i].ps_sps->u1_is_valid == TRUE)
 {
                           j = i;
 break;
 }
 }
 }


             if(j == -1)
             {
                return ERROR_INV_SPS_PPS_T;
             }
 
             /* call ih264d_start_of_pic only if it was not called earlier*/
 if(ps_dec->u4_pic_buf_got == 0)
 {
                ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
                ps_dec->ps_cur_slice->u1_nal_ref_idc = 1;
                ps_dec->ps_cur_slice->u1_nal_unit_type = 1;
                ret = ih264d_start_of_pic(ps_dec, poc, ps_cur_poc,
                        ps_dec->ps_cur_slice->u2_frame_num,
 &ps_dec->ps_pps[j]);

 if(ret != OK)
 {
 return ret;
 }
 }

            ps_dec->ps_ref_pic_buf_lx[0][0]->u1_pic_buf_id = 0;

            ps_dec->u4_output_present = 0;

 {
                ih264d_get_next_display_field(ps_dec,
                                              ps_dec->ps_out_buffer,
 &(ps_dec->s_disp_op));
 /* If error code is non-zero then there is no buffer available for display,
                 hence avoid format conversion */

 if(0 != ps_dec->s_disp_op.u4_error_code)
 {
                    ps_dec->u4_fmt_conv_cur_row = ps_dec->s_disp_frame_info.u4_y_ht;
 }
 else
                    ps_dec->u4_output_present = 1;
 }

 if(ps_dec->u1_separate_parse == 1)
 {
 if(ps_dec->u4_dec_thread_created == 0)
 {
                    ithread_create(ps_dec->pv_dec_thread_handle, NULL,
 (void *)ih264d_decode_picture_thread,
 (void *)ps_dec);

                    ps_dec->u4_dec_thread_created = 1;
 }

 if((ps_dec->u4_num_cores == 3) &&
 ((ps_dec->u4_app_disable_deblk_frm == 0) || ps_dec->i1_recon_in_thread3_flag)
 && (ps_dec->u4_bs_deblk_thread_created == 0))
 {
                    ps_dec->u4_start_recon_deblk = 0;
                    ithread_create(ps_dec->pv_bs_deblk_thread_handle, NULL,
 (void *)ih264d_recon_deblk_thread,
 (void *)ps_dec);
                    ps_dec->u4_bs_deblk_thread_created = 1;
 }
 }
 }
        ps_dec->u4_first_slice_in_pic = 0;
 }
 else
 {

 dec_slice_struct_t *ps_parse_cur_slice;
        ps_parse_cur_slice = ps_dec->ps_dec_slice_buf + ps_dec->u2_cur_slice_num;

 if(ps_dec->u1_slice_header_done
 && ps_parse_cur_slice == ps_dec->ps_parse_cur_slice)
 {
 if((u1_mbaff) && (ps_dec->u4_num_mbs_cur_nmb & 1))
 {
                ps_dec->u4_num_mbs_cur_nmb = ps_dec->u4_num_mbs_cur_nmb - 1;
                ps_dec->u2_cur_mb_addr--;
 }

            u1_num_mbs = ps_dec->u4_num_mbs_cur_nmb;
 if(u1_num_mbs)
 {
                ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs - 1;
 }
 else
 {
 if(ps_dec->u1_separate_parse)
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info;
 }
 else
 {
                    ps_cur_mb_info = ps_dec->ps_nmb_info
 + ps_dec->u4_num_mbs_prev_nmb - 1;
 }
 }

            ps_dec->u2_mby = ps_cur_mb_info->u2_mby;
            ps_dec->u2_mbx = ps_cur_mb_info->u2_mbx;

            ps_dec->u1_mb_ngbr_availablity =
                    ps_cur_mb_info->u1_mb_ngbr_availablity;

 if(u1_num_mbs)
 {
                ps_dec->pv_parse_tu_coeff_data = ps_dec->pv_prev_mb_parse_tu_coeff_data;
                ps_dec->u2_cur_mb_addr--;
                ps_dec->i4_submb_ofst -= SUB_BLK_SIZE;

 if (ps_dec->u1_pr_sl_type == P_SLICE
 || ps_dec->u1_pr_sl_type == B_SLICE)
 {
                    ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx,    u1_num_mbs);
                    ps_dec->ps_part = ps_dec->ps_parse_part_params;
 }

                u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
                u1_end_of_row = (!u1_num_mbs_next)
 && (!(u1_mbaff && (u1_num_mbs & 0x01)));
                u1_slice_end = 1;
                u1_tfr_n_mb = 1;
                ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(ps_dec->u1_separate_parse)
 {
                    ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                    ps_dec->ps_nmb_info += u1_num_mbs;
 }
 else
 {
                    ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                            u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
 }
                ps_dec->u2_total_mbs_coded += u1_num_mbs;
                ps_dec->u1_mb_idx = 0;
                ps_dec->u4_num_mbs_cur_nmb = 0;
 }

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
                ps_dec->u1_pic_decode_done = 1;
 return 0;
 }

 /* Inserting new slice only if the current slice has atleast 1 MB*/
 if(ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice <
 (UWORD32)(ps_dec->u2_total_mbs_coded >> ps_slice->u1_mbaff_frame_flag))
 {
                ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
                ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;
                ps_dec->u2_cur_slice_num++;
                ps_dec->ps_parse_cur_slice++;
 }

 }
 else
 {
            ps_dec->ps_parse_cur_slice = ps_dec->ps_dec_slice_buf
 + ps_dec->u2_cur_slice_num;
 }
 }

 /******************************************************/
 /* Initializations to new slice                       */
 /******************************************************/
 {
        WORD32 num_entries;
        WORD32 size;
        UWORD8 *pu1_buf;

        num_entries = MIN(MAX_FRAMES, ps_dec->u4_num_ref_frames_at_init);
        num_entries = 2 * ((2 * num_entries) + 1);

        size = num_entries * sizeof(void *);
        size += PAD_MAP_IDX_POC * sizeof(void *);

        pu1_buf = (UWORD8 *)ps_dec->pv_map_ref_idx_to_poc_buf;
        pu1_buf += size * ps_dec->u2_cur_slice_num;
        ps_dec->ps_parse_cur_slice->ppv_map_ref_idx_to_poc = (volatile void **)pu1_buf;
 }

    ps_dec->ps_cur_slice->u2_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_cur_slice->i1_slice_alpha_c0_offset = 0;
    ps_dec->ps_cur_slice->i1_slice_beta_offset = 0;

 if(ps_dec->ps_cur_slice->u1_field_pic_flag)
        ps_dec->u2_prv_frame_num = ps_dec->ps_cur_slice->u2_frame_num;

    ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice = ps_dec->u2_total_mbs_coded >> u1_mbaff;
    ps_dec->ps_parse_cur_slice->u2_log2Y_crwd =    ps_dec->ps_cur_slice->u2_log2Y_crwd;


 if(ps_dec->u1_separate_parse)
 {
        ps_dec->ps_parse_cur_slice->pv_tu_coeff_data_start = ps_dec->pv_parse_tu_coeff_data;
 }
 else
 {
        ps_dec->pv_proc_tu_coeff_data = ps_dec->pv_parse_tu_coeff_data;
 }

 /******************************************************/
 /* Initializations specific to P slice                */
 /******************************************************/
    u1_inter_mb_type = P_MB;
    u1_deblk_mb_type = D_INTER_MB;

    ps_dec->ps_cur_slice->u1_slice_type = P_SLICE;
    ps_dec->ps_parse_cur_slice->slice_type = P_SLICE;
    ps_dec->pf_mvpred_ref_tfr_nby2mb = ih264d_mv_pred_ref_tfr_nby2_pmb;
    ps_dec->ps_part = ps_dec->ps_parse_part_params;
    ps_dec->u2_mbx =
 (MOD(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby =
 (DIV(ps_dec->ps_cur_slice->u2_first_mb_in_slice - 1, ps_dec->u2_frm_wd_in_mbs));
    ps_dec->u2_mby <<= u1_mbaff;

 /******************************************************/
 /* Parsing / decoding the slice                       */
 /******************************************************/
    ps_dec->u1_slice_header_done = 2;
    ps_dec->u1_qp = ps_slice->u1_slice_qp;
    ih264d_update_qp(ps_dec, 0);
    u1_mb_idx = ps_dec->u1_mb_idx;
    ps_parse_mb_data = ps_dec->ps_parse_mb_data;
    u1_num_mbs = u1_mb_idx;

    u1_slice_end = 0;
    u1_tfr_n_mb = 0;
    u1_decode_nmb = 0;
    u1_num_mbsNby2 = 0;
    i2_cur_mb_addr = ps_dec->u2_total_mbs_coded;
    i2_mb_skip_run = num_mb_skip;

 while(!u1_slice_end)
 {
        UWORD8 u1_mb_type;

 if(i2_cur_mb_addr > ps_dec->ps_cur_sps->u2_max_mb_addr)
 break;

        ps_cur_mb_info = ps_dec->ps_nmb_info + u1_num_mbs;
        ps_dec->u4_num_mbs_cur_nmb = u1_num_mbs;

        ps_cur_mb_info->u1_Mux = 0;
        ps_dec->u4_num_pmbair = (u1_num_mbs >> u1_mbaff);
        ps_cur_deblk_mb = ps_dec->ps_deblk_mbn + u1_num_mbs;

        ps_cur_mb_info->u1_end_of_slice = 0;

 /* Storing Default partition info */
        ps_parse_mb_data->u1_num_part = 1;
        ps_parse_mb_data->u1_isI_mb = 0;

 /**************************************************************/
 /* Get the required information for decoding of MB            */
 /**************************************************************/
 /* mb_x, mb_y, neighbor availablity, */
 if (u1_mbaff)
            ih264d_get_mb_info_cavlc_mbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);
 else
            ih264d_get_mb_info_cavlc_nonmbaff(ps_dec, i2_cur_mb_addr, ps_cur_mb_info, i2_mb_skip_run);

 /* Set the deblocking parameters for this MB */
 if(ps_dec->u4_app_disable_deblk_frm == 0)
 {
            ih264d_set_deblocking_parameters(ps_cur_deblk_mb, ps_slice,
                                             ps_dec->u1_mb_ngbr_availablity,
                                             ps_dec->u1_cur_mb_fld_dec_flag);
 }

 /* Set appropriate flags in ps_cur_mb_info and ps_dec */
        ps_dec->i1_prev_mb_qp_delta = 0;
        ps_dec->u1_sub_mb_num = 0;
        ps_cur_mb_info->u1_mb_type = MB_SKIP;
        ps_cur_mb_info->u1_mb_mc_mode = PRED_16x16;
        ps_cur_mb_info->u1_cbp = 0;

 /* Storing Skip partition info */
        ps_part_info = ps_dec->ps_part;
        ps_part_info->u1_is_direct = PART_DIRECT_16x16;
        ps_part_info->u1_sub_mb_num = 0;
        ps_dec->ps_part++;

 /* Update Nnzs */
        ih264d_update_nnz_for_skipmb(ps_dec, ps_cur_mb_info, CAVLC);

        ps_cur_mb_info->ps_curmb->u1_mb_type = u1_inter_mb_type;
        ps_cur_deblk_mb->u1_mb_type |= u1_deblk_mb_type;

        i2_mb_skip_run--;

        ps_cur_deblk_mb->u1_mb_qp = ps_dec->u1_qp;

 if (u1_mbaff)
 {
            ih264d_update_mbaff_left_nnz(ps_dec, ps_cur_mb_info);
 }

 /**************************************************************/
 /* Get next Macroblock address                                */
 /**************************************************************/
        i2_cur_mb_addr++;

        u1_num_mbs++;
        u1_num_mbsNby2++;
        ps_parse_mb_data++;

 /****************************************************************/
 /* Check for End Of Row and other flags that determine when to  */
 /* do DMA setup for N/2-Mb, Decode for N-Mb, and Transfer for   */
 /* N-Mb                                                         */
 /****************************************************************/
        u1_num_mbs_next = i2_pic_wdin_mbs - ps_dec->u2_mbx - 1;
        u1_end_of_row = (!u1_num_mbs_next) && (!(u1_mbaff && (u1_num_mbs & 0x01)));
        u1_slice_end = !i2_mb_skip_run;
        u1_tfr_n_mb = (u1_num_mbs == ps_dec->u1_recon_mb_grp) || u1_end_of_row
 || u1_slice_end;
        u1_decode_nmb = u1_tfr_n_mb || u1_slice_end;
        ps_cur_mb_info->u1_end_of_slice = u1_slice_end;

 if(u1_decode_nmb)
 {
            ps_dec->pf_mvpred_ref_tfr_nby2mb(ps_dec, u1_mb_idx, u1_num_mbs);
            u1_num_mbsNby2 = 0;

            ps_parse_mb_data = ps_dec->ps_parse_mb_data;
            ps_dec->ps_part = ps_dec->ps_parse_part_params;

 if(ps_dec->u1_separate_parse)
 {
                ih264d_parse_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs,
                                     u1_num_mbs_next, u1_tfr_n_mb, u1_end_of_row);
                ps_dec->ps_nmb_info +=  u1_num_mbs;
 }
 else
 {
                ih264d_decode_recon_tfr_nmb(ps_dec, u1_mb_idx, u1_num_mbs, u1_num_mbs_next,
                                            u1_tfr_n_mb, u1_end_of_row);
 }
            ps_dec->u2_total_mbs_coded += u1_num_mbs;
 if(u1_tfr_n_mb)
                u1_num_mbs = 0;
            u1_mb_idx = u1_num_mbs;
            ps_dec->u1_mb_idx = u1_num_mbs;
 }
 }

    ps_dec->u4_num_mbs_cur_nmb = 0;
    ps_dec->ps_cur_slice->u4_mbs_in_slice = i2_cur_mb_addr
 - ps_dec->ps_parse_cur_slice->u4_first_mb_in_slice;

    H264_DEC_DEBUG_PRINT("Mbs in slice: %d\n", ps_dec->ps_cur_slice->u4_mbs_in_slice);


 /* incremented here only if first slice is inserted */
 if(ps_dec->u4_first_slice_in_pic != 0)
 {
        ps_dec->ps_parse_cur_slice++;
        ps_dec->u2_cur_slice_num++;
 }

    ps_dec->i2_prev_slice_mbx = ps_dec->u2_mbx;
    ps_dec->i2_prev_slice_mby = ps_dec->u2_mby;

 if(ps_dec->u2_total_mbs_coded
 >= ps_dec->u2_frm_ht_in_mbs * ps_dec->u2_frm_wd_in_mbs)
 {
        ps_dec->u1_pic_decode_done = 1;
 }

 return 0;

}

Labels: Yes
----------------lora model----------------
Response: list index out of range


Instruction: 
Input: status_t OMX::updateGraphicBufferInMeta(
        node_id node, OMX_U32 port_index,
 const sp<GraphicBuffer> &graphicBuffer, buffer_id buffer) {
 return findInstance(node)->updateGraphicBufferInMeta(
            port_index, graphicBuffer, buffer);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int init_uinput (void)
{
 char *name = "AVRCP";

    BTIF_TRACE_DEBUG("%s", __FUNCTION__);
    uinput_fd = uinput_create(name);
 if (uinput_fd < 0) {
        BTIF_TRACE_ERROR("%s AVRCP: Failed to initialize uinput for %s (%d)",
                          __FUNCTION__, name, uinput_fd);
 } else {
        BTIF_TRACE_DEBUG("%s AVRCP: Initialized uinput for %s (fd=%d)",
                          __FUNCTION__, name, uinput_fd);
 }
 return uinput_fd;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void dump_thread(Backtrace* backtrace, log_t* log) {
  dump_registers(log, backtrace->Tid());
  dump_backtrace_and_stack(backtrace, log);

  dump_memory_and_code(log, backtrace->Tid());
  dump_nearby_maps(backtrace->GetMap(), log, backtrace->Tid());
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t SoftAACEncoder::setAudioParams() {

    ALOGV("setAudioParams: %lu Hz, %lu channels, %lu bps",
         mSampleRate, mNumChannels, mBitRate);

 status_t err = setAudioSpecificConfigData();

 if (err != OK) {
 return err;
 }

    AACENC_PARAM params;
    memset(&params, 0, sizeof(params));
    params.sampleRate = mSampleRate;
    params.bitRate = mBitRate;
    params.nChannels = mNumChannels;
    params.adtsUsed = 0; // We add adts header in the file writer if needed.
 if (VO_ERR_NONE != mApiHandle->SetParam(
                mEncoderHandle, VO_PID_AAC_ENCPARAM, &params)) {
        ALOGE("Failed to set AAC encoder parameters");
 return UNKNOWN_ERROR;
 }

 return OK;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void onScanResultsAvailable(wifi_request_id id, unsigned num_results) {

 JNIHelper helper(mVM);


    helper.reportEvent(mCls, "onScanResultsAvailable", "(I)V", id);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: InputDispatcher::InjectionState::InjectionState(int32_t injectorPid, int32_t injectorUid) :
        refCount(1),
        injectorPid(injectorPid), injectorUid(injectorUid),
        injectionResult(INPUT_EVENT_INJECTION_PENDING), injectionIsAsync(false),
        pendingForegroundDispatches(0) {
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void NuPlayer::GenericSource::onPollBuffering() {
 status_t finalStatus = UNKNOWN_ERROR;
 int64_t cachedDurationUs = 0ll;

 if (mCachedSource != NULL) {
 size_t cachedDataRemaining =
                mCachedSource->approxDataRemaining(&finalStatus);

 if (finalStatus == OK) {
 off64_t size;
 int64_t bitrate = 0ll;
 if (mDurationUs > 0 && mCachedSource->getSize(&size) == OK) {
                bitrate = size * 8000000ll / mDurationUs;
 } else if (mBitrate > 0) {
                bitrate = mBitrate;
 }
 if (bitrate > 0) {
                cachedDurationUs = cachedDataRemaining * 8000000ll / bitrate;
 }
 }
 } else if (mWVMExtractor != NULL) {
        cachedDurationUs
 = mWVMExtractor->getCachedDurationUs(&finalStatus);
 }

 if (finalStatus == ERROR_END_OF_STREAM) {
        notifyBufferingUpdate(100);
        cancelPollBuffering();
 return;
 } else if (cachedDurationUs > 0ll && mDurationUs > 0ll) {
 int percentage = 100.0 * cachedDurationUs / mDurationUs;
 if (percentage > 100) {
            percentage = 100;
 }

        notifyBufferingUpdate(percentage);
 }

    schedulePollBuffering();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVCEncoder::internalSetParameter(
        OMX_INDEXTYPE index, const OMX_PTR params) {
 int32_t indexFull = index;

 switch (indexFull) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *) params;
 
             if (bitRate->nPortIndex != 1 ||
                 bitRate->eControlRate != OMX_Video_ControlRateVariable) {
                 return OMX_ErrorUndefined;
 }

            mBitrate = bitRate->nTargetBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoAvc:
 {

             OMX_VIDEO_PARAM_AVCTYPE *avcType =
                 (OMX_VIDEO_PARAM_AVCTYPE *)params;
 
             if (avcType->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

 if (avcType->eProfile != OMX_VIDEO_AVCProfileBaseline ||
                avcType->nRefFrames != 1 ||
                avcType->nBFrames != 0 ||
                avcType->bUseHadamard != OMX_TRUE ||
 (avcType->nAllowedPictureTypes & OMX_VIDEO_PictureTypeB) != 0 ||
                avcType->nRefIdx10ActiveMinus1 != 0 ||
                avcType->nRefIdx11ActiveMinus1 != 0 ||
                avcType->bWeightedPPrediction != OMX_FALSE ||
                avcType->bEntropyCodingCABAC != OMX_FALSE ||
                avcType->bconstIpred != OMX_FALSE ||
                avcType->bDirect8x8Inference != OMX_FALSE ||
                avcType->bDirectSpatialTemporal != OMX_FALSE ||
                avcType->nCabacInitIdc != 0) {
 return OMX_ErrorUndefined;
 }

 if (OK != ConvertOmxAvcLevelToAvcSpecLevel(avcType->eLevel, &mAVCEncLevel)) {
 return OMX_ErrorUndefined;
 }

 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalSetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: int SparseBitSet::CountLeadingZeros(element x) {
 return sizeof(element) <= sizeof(int) ? __builtin_clz(x) : __builtin_clzl(x);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: IMkvReader::~IMkvReader() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  explicit FastDoubleElementsAccessor(const char* name)
 : FastElementsAccessor<Subclass, KindTraits>(name) {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void OMXNodeInstance::invalidateBufferID(OMX::buffer_id buffer) {
 if (buffer == 0) {
 return;
 }
 Mutex::Autolock autoLock(mBufferIDLock);
    mBufferHeaderToBufferID.removeItem(mBufferIDToBufferHeader.valueFor(buffer));
    mBufferIDToBufferHeader.removeItem(buffer);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: String8::String8(const char* o)
 : mString(allocFromUTF8(o, strlen(o)))
{
 if (mString == NULL) {
        mString = getEmptyString();
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: emit_error(struct file *file, int code, const char *what)
 /* Generic error message routine, takes a 'stop' code but can be used
    * elsewhere.  Always outputs a message.
    */
{
 const char *reason;
 int err = 0;

 switch (code)
 {
 case LIBPNG_WARNING_CODE:   reason = "libpng warning:"; break;
 case LIBPNG_ERROR_CODE:     reason = "libpng error:"; break;
 case ZLIB_ERROR_CODE:       reason = "zlib error:"; break;
 case INVALID_ERROR_CODE:    reason = "invalid"; break;
 case READ_ERROR_CODE:       reason = "read failure:";
                                  err = file->read_errno;
 break;
 case WRITE_ERROR_CODE:      reason = "write error";
                                  err = file->write_errno;
 break;
 case UNEXPECTED_ERROR_CODE: reason = "unexpected error:";
                                  err = file->read_errno;
 if (err == 0)
                                     err = file->write_errno;
 break;
 default:                    reason = "INVALID (internal error):"; break;
 }

 if (err != 0)
      fprintf(stderr, "%s: %s %s [%s]\n", file->file_name, reason, what,
         strerror(err));

 else
      fprintf(stderr, "%s: %s %s\n", file->file_name, reason, what);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: print_opts(png_uint_32 opts)
{
 if (opts & READ_FILE)
      printf(" --file");
 if (opts & USE_STDIO)
      printf(" --stdio");
 if (opts & STRICT)
      printf(" --strict");
 if (opts & VERBOSE)
      printf(" --verbose");
 if (opts & KEEP_TMPFILES)
      printf(" --preserve");
 if (opts & KEEP_GOING)
      printf(" --keep-going");
 if (opts & ACCUMULATE)
      printf(" --accumulate");
 if (!(opts & FAST_WRITE)) /* --fast is currently the default */
      printf(" --slow");
 if (opts & sRGB_16BIT)
      printf(" --sRGB-16bit");
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: OMX_ERRORTYPE SoftAVC::internalGetParameter(OMX_INDEXTYPE index, OMX_PTR params) {
 switch (index) {
 case OMX_IndexParamVideoBitrate:
 {

             OMX_VIDEO_PARAM_BITRATETYPE *bitRate =
                 (OMX_VIDEO_PARAM_BITRATETYPE *)params;
 
             if (bitRate->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            bitRate->eControlRate = OMX_Video_ControlRateVariable;
            bitRate->nTargetBitrate = mBitrate;
 return OMX_ErrorNone;
 }

 case OMX_IndexParamVideoAvc:

         {
             OMX_VIDEO_PARAM_AVCTYPE *avcParams = (OMX_VIDEO_PARAM_AVCTYPE *)params;
 
             if (avcParams->nPortIndex != 1) {
                 return OMX_ErrorUndefined;
             }

            OMX_VIDEO_AVCLEVELTYPE omxLevel = OMX_VIDEO_AVCLevel41;
 if (OMX_ErrorNone
 != ConvertAvcSpecLevelToOmxAvcLevel(mAVCEncLevel, &omxLevel)) {
 return OMX_ErrorUndefined;
 }

            avcParams->eProfile = OMX_VIDEO_AVCProfileBaseline;
            avcParams->eLevel = omxLevel;
            avcParams->nRefFrames = 1;
            avcParams->bUseHadamard = OMX_TRUE;
            avcParams->nAllowedPictureTypes = (OMX_VIDEO_PictureTypeI
 | OMX_VIDEO_PictureTypeP | OMX_VIDEO_PictureTypeB);
            avcParams->nRefIdx10ActiveMinus1 = 0;
            avcParams->nRefIdx11ActiveMinus1 = 0;
            avcParams->bWeightedPPrediction = OMX_FALSE;
            avcParams->bconstIpred = OMX_FALSE;
            avcParams->bDirect8x8Inference = OMX_FALSE;
            avcParams->bDirectSpatialTemporal = OMX_FALSE;
            avcParams->nCabacInitIdc = 0;
 return OMX_ErrorNone;
 }

 default:
 return SoftVideoEncoderOMXComponent::internalGetParameter(index, params);
 }
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_vdec::execute_output_flush()
{
 unsigned long p1 = 0; // Parameter - 1
 unsigned long p2 = 0; // Parameter - 2
 unsigned long ident = 0;
 bool bRet = true;

 /*Generate FBD for all Buffers in the FTBq*/
    pthread_mutex_lock(&m_lock);
    DEBUG_PRINT_LOW("Initiate Output Flush");

 if(m_last_rendered_TS > 0) {
        m_last_rendered_TS = 0;
 }

 while (m_ftb_q.m_size) {
        DEBUG_PRINT_LOW("Buffer queue size %lu pending buf cnt %d",
                m_ftb_q.m_size,pending_output_buffers);
        m_ftb_q.pop_entry(&p1,&p2,&ident);
        DEBUG_PRINT_LOW("ID(%lx) P1(%lx) P2(%lx)", ident, p1, p2);
 if (ident == m_fill_output_msg ) {
            m_cb.FillBufferDone(&m_cmp, m_app_data, (OMX_BUFFERHEADERTYPE *)(intptr_t)p2);
 } else if (ident == OMX_COMPONENT_GENERATE_FBD) {
            fill_buffer_done(&m_cmp,(OMX_BUFFERHEADERTYPE *)(intptr_t)p1);
 }
 }
    pthread_mutex_unlock(&m_lock);
    output_flush_progress = false;

 if (arbitrary_bytes) {
        prev_ts = LLONG_MAX;
        rst_prev_ts = true;
 }
    DEBUG_PRINT_HIGH("OMX flush o/p Port complete PenBuf(%d)", pending_output_buffers);
 return bRet;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t Camera3Device::deleteStream(int id) {
    ATRACE_CALL();
 Mutex::Autolock il(mInterfaceLock);
 Mutex::Autolock l(mLock);
 status_t res;

    ALOGV("%s: Camera %d: Deleting stream %d", __FUNCTION__, mId, id);

 if (mStatus == STATUS_ACTIVE) {
        ALOGV("%s: Camera %d: Device not idle", __FUNCTION__, mId);
 return -EBUSY;
 }

    sp<Camera3StreamInterface> deletedStream;
 ssize_t outputStreamIdx = mOutputStreams.indexOfKey(id);
 if (mInputStream != NULL && id == mInputStream->getId()) {
        deletedStream = mInputStream;
        mInputStream.clear();
 } else {
 if (outputStreamIdx == NAME_NOT_FOUND) {
            CLOGE("Stream %d does not exist", id);
 return BAD_VALUE;
 }
 }

 if (outputStreamIdx != NAME_NOT_FOUND) {
        deletedStream = mOutputStreams.editValueAt(outputStreamIdx);
        mOutputStreams.removeItem(id);
 }

    res = deletedStream->disconnect();
 if (res != OK) {
        SET_ERR_L("Can't disconnect deleted stream %d", id);
 }
    mDeletedStreams.add(deletedStream);
    mNeedConfig = true;

 return res;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void *atomic_thread(void *context) {
   struct atomic_test_s32_s *at = (struct atomic_test_s32_s *)context;
   for (int i = 0; i < at->max_val; i++) {
    usleep(1);
     atomic_inc_prefix_s32(&at->data[i]);
   }
   return NULL;
}

Labels: Yes
----------------lora model----------------
Response: No</s>


Instruction: 
Input: bool omx_video::omx_cmd_queue::insert_entry(unsigned long p1, unsigned long p2, unsigned long id)
{
 bool ret = true;
 if (m_size < OMX_CORE_CONTROL_CMDQ_SIZE) {
        m_q[m_write].id       = id;
        m_q[m_write].param1   = p1;
        m_q[m_write].param2   = p2;
        m_write++;
        m_size ++;
 if (m_write >= OMX_CORE_CONTROL_CMDQ_SIZE) {
            m_write = 0;
 }
 } else {
        ret = false;
        DEBUG_PRINT_ERROR("ERROR!!! Command Queue Full");
 }
 return ret;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t ACodec::setupEAC3Codec(
 bool encoder, int32_t numChannels, int32_t sampleRate) {
 status_t err = setupRawAudioFormat(
            encoder ? kPortIndexInput : kPortIndexOutput, sampleRate, numChannels);

 if (err != OK) {
 return err;
 }

 if (encoder) {
        ALOGW("EAC3 encoding is not supported.");
 return INVALID_OPERATION;
 }

    OMX_AUDIO_PARAM_ANDROID_EAC3TYPE def;
 InitOMXParams(&def);
    def.nPortIndex = kPortIndexInput;

    err = mOMX->getParameter(
            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidEac3,
 &def,
 sizeof(def));

 if (err != OK) {
 return err;
 }

    def.nChannels = numChannels;
    def.nSampleRate = sampleRate;

 return mOMX->setParameter(
            mNode,
 (OMX_INDEXTYPE)OMX_IndexParamAudioAndroidEac3,
 &def,
 sizeof(def));
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t AudioSource::initCheck() const {
 return mInitCheck;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static char* out_get_parameters(const struct audio_stream *stream, const char *keys)
{
 struct stream_out *out = (struct stream_out *)stream;
 struct str_parms *query = str_parms_create_str(keys);
 char *str;
 char value[256];
 struct str_parms *reply = str_parms_create();
 size_t i, j;
 int ret;
 bool first = true;
    ALOGV("%s: enter: keys - %s", __func__, keys);
    ret = str_parms_get_str(query, AUDIO_PARAMETER_STREAM_SUP_CHANNELS, value, sizeof(value));
 if (ret >= 0) {
        value[0] = '\0';
        i = 0;
 while (out->supported_channel_masks[i] != 0) {
 for (j = 0; j < ARRAY_SIZE(out_channels_name_to_enum_table); j++) {
 if (out_channels_name_to_enum_table[j].value == out->supported_channel_masks[i]) {
 if (!first) {
                        strcat(value, "|");
 }
                    strcat(value, out_channels_name_to_enum_table[j].name);
                    first = false;
 break;
 }
 }
            i++;
 }
        str_parms_add_str(reply, AUDIO_PARAMETER_STREAM_SUP_CHANNELS, value);
        str = str_parms_to_str(reply);
 } else {
        str = strdup(keys);
 }
    str_parms_destroy(query);
    str_parms_destroy(reply);
    ALOGV("%s: exit: returns - %s", __func__, str);
 return str;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  void OpenMD5File(const std::string& md5_file_name_) {
    md5_file_ = libvpx_test::OpenTestDataFile(md5_file_name_);
    ASSERT_TRUE(md5_file_ != NULL) << "Md5 file open failed. Filename: "
 << md5_file_name_;
 }

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MPEG4DataSource::initCheck() const {
 return mSource->initCheck();
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void RilSapSocket::sOnRequestComplete (RIL_Token t,
        RIL_Errno e,
 void *response,
 size_t responselen) {
 RilSapSocket *sap_socket;
 SapSocketRequest *request = (SapSocketRequest*) t;

    RLOGD("Socket id:%d", request->socketId);

    sap_socket = getSocketById(request->socketId);

 if (sap_socket) {
        sap_socket->onRequestComplete(t,e,response,responselen);
 } else {
        RLOGE("Invalid socket id");
 if (request->curr->payload) {
            free(request->curr->payload);
 }
        free(request->curr);
        free(request);
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: status_t MediaPlayer::setDataSource(const sp<IDataSource> &source)
{
    ALOGV("setDataSource(IDataSource)");
 status_t err = UNKNOWN_ERROR;
 const sp<IMediaPlayerService>& service(getMediaPlayerService());
 if (service != 0) {
        sp<IMediaPlayer> player(service->create(this, mAudioSessionId));
 if ((NO_ERROR != doSetRetransmitEndpoint(player)) ||
 (NO_ERROR != player->setDataSource(source))) {
            player.clear();
 }
        err = attachNewPlayer(player);
 }
 return err;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: FLAC__bool seek_to_absolute_sample_ogg_(FLAC__StreamDecoder *decoder, FLAC__uint64 stream_length, FLAC__uint64 target_sample)
{
	FLAC__uint64 left_pos = 0, right_pos = stream_length;
	FLAC__uint64 left_sample = 0, right_sample = FLAC__stream_decoder_get_total_samples(decoder);
	FLAC__uint64 this_frame_sample = (FLAC__uint64)0 - 1;
	FLAC__uint64 pos = 0; /* only initialized to avoid compiler warning */
	FLAC__bool did_a_seek;
 unsigned iteration = 0;

 /* In the first iterations, we will calculate the target byte position
	 * by the distance from the target sample to left_sample and
	 * right_sample (let's call it "proportional search").  After that, we
	 * will switch to binary search.
	 */
 unsigned BINARY_SEARCH_AFTER_ITERATION = 2;

 /* We will switch to a linear search once our current sample is less
	 * than this number of samples ahead of the target sample
	 */
 static const FLAC__uint64 LINEAR_SEARCH_WITHIN_SAMPLES = FLAC__MAX_BLOCK_SIZE * 2;

 /* If the total number of samples is unknown, use a large value, and
	 * force binary search immediately.
	 */
 if(right_sample == 0) {
		right_sample = (FLAC__uint64)(-1);
		BINARY_SEARCH_AFTER_ITERATION = 0;
 }

	decoder->private_->target_sample = target_sample;
 for( ; ; iteration++) {
 if (iteration == 0 || this_frame_sample > target_sample || target_sample - this_frame_sample > LINEAR_SEARCH_WITHIN_SAMPLES) {
 if (iteration >= BINARY_SEARCH_AFTER_ITERATION) {
				pos = (right_pos + left_pos) / 2;
 }
 else {
#ifndef FLAC__INTEGER_ONLY_LIBRARY
				pos = (FLAC__uint64)((FLAC__double)(target_sample - left_sample) / (FLAC__double)(right_sample - left_sample) * (FLAC__double)(right_pos - left_pos));
#else
 /* a little less accurate: */
 if ((target_sample-left_sample <= 0xffffffff) && (right_pos-left_pos <= 0xffffffff))
					pos = (FLAC__int64)(((target_sample-left_sample) * (right_pos-left_pos)) / (right_sample-left_sample));
 else /* @@@ WATCHOUT, ~2TB limit */
					pos = (FLAC__int64)((((target_sample-left_sample)>>8) * ((right_pos-left_pos)>>8)) / ((right_sample-left_sample)>>16));
#endif
 /* @@@ TODO: might want to limit pos to some distance
				 * before EOF, to make sure we land before the last frame,
				 * thereby getting a this_frame_sample and so having a better
				 * estimate.
				 */
 }

 /* physical seek */
 if(decoder->private_->seek_callback((FLAC__StreamDecoder*)decoder, (FLAC__uint64)pos, decoder->private_->client_data) != FLAC__STREAM_DECODER_SEEK_STATUS_OK) {
				decoder->protected_->state = FLAC__STREAM_DECODER_SEEK_ERROR;
 return false;
 }
 if(!FLAC__stream_decoder_flush(decoder)) {
 /* above call sets the state for us */
 return false;
 }
			did_a_seek = true;
 }
 else
			did_a_seek = false;

		decoder->private_->got_a_frame = false;
 if(!FLAC__stream_decoder_process_single(decoder)) {
			decoder->protected_->state = FLAC__STREAM_DECODER_SEEK_ERROR;
 return false;
 }
 if(!decoder->private_->got_a_frame) {
 if(did_a_seek) {
 /* this can happen if we seek to a point after the last frame; we drop
				 * to binary search right away in this case to avoid any wasted
				 * iterations of proportional search.
				 */
				right_pos = pos;
				BINARY_SEARCH_AFTER_ITERATION = 0;
 }
 else {
 /* this can probably only happen if total_samples is unknown and the
				 * target_sample is past the end of the stream
				 */
				decoder->protected_->state = FLAC__STREAM_DECODER_SEEK_ERROR;
 return false;
 }
 }
 /* our write callback will change the state when it gets to the target frame */
 else if(!decoder->private_->is_seeking) {
 break;
 }
 else {
			this_frame_sample = decoder->private_->last_frame.header.number.sample_number;
			FLAC__ASSERT(decoder->private_->last_frame.header.number_type == FLAC__FRAME_NUMBER_TYPE_SAMPLE_NUMBER);

 if (did_a_seek) {
 if (this_frame_sample <= target_sample) {
 /* The 'equal' case should not happen, since
					 * FLAC__stream_decoder_process_single()
					 * should recognize that it has hit the
					 * target sample and we would exit through
					 * the 'break' above.
					 */
					FLAC__ASSERT(this_frame_sample != target_sample);

					left_sample = this_frame_sample;
 /* sanity check to avoid infinite loop */
 if (left_pos == pos) {
						decoder->protected_->state = FLAC__STREAM_DECODER_SEEK_ERROR;
 return false;
 }
					left_pos = pos;
 }
 else if(this_frame_sample > target_sample) {
					right_sample = this_frame_sample;
 /* sanity check to avoid infinite loop */
 if (right_pos == pos) {
						decoder->protected_->state = FLAC__STREAM_DECODER_SEEK_ERROR;
 return false;
 }
					right_pos = pos;
 }
 }
 }
 }

 return true;
}

Labels: No
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: static bool check_caller_access_to_node(struct fuse* fuse,
 const struct fuse_in_header *hdr, const struct node* node, int mode) {
 return check_caller_access_to_name(fuse, hdr, node->parent, node->name, mode);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void BTM_SecSetConnectFilterCallback (tBTM_FILTER_CB *p_callback)
{
    btm_cb.p_conn_filter_cb = p_callback;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void remove_node_from_parent_locked(struct node* node)
{
 if (node->parent) {
 if (node->parent->child == node) {
            node->parent->child = node->parent->child->next;
 } else {
 struct node *node2;
            node2 = node->parent->child;
 while (node2->next != node)
                node2 = node2->next;
            node2->next = node->next;
 }
        release_node_locked(node->parent);
        node->parent = NULL;
        node->next = NULL;
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void vp9_init_context_buffers(VP9_COMMON *cm) {
  cm->setup_mi(cm);
 if (cm->last_frame_seg_map && !cm->frame_parallel_decode)
    memset(cm->last_frame_seg_map, 0, cm->mi_rows * cm->mi_cols);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static void btif_hl_free_app_idx(UINT8 app_idx){

 if ((app_idx < BTA_HL_NUM_APPS) && btif_hl_cb.acb[app_idx].in_use )
 {
        btif_hl_cb.acb[app_idx].in_use = FALSE;
        memset (&btif_hl_cb.acb[app_idx], 0, sizeof(btif_hl_app_cb_t));
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void ReverbSetDensity(ReverbContext *pContext, int16_t level){

    LVREV_ControlParams_st    ActiveParams; /* Current control Parameters */
    LVREV_ReturnStatus_en     LvmStatus=LVREV_SUCCESS; /* Function call status */

 /* Get the current settings */
 LvmStatus = LVREV_GetControlParameters(pContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVREV_GetControlParameters", "ReverbSetDensity")

 ActiveParams.RoomSize = (LVM_INT16)(((level * 99) / 1000) + 1);

 /* Activate the initial settings */
 LvmStatus = LVREV_SetControlParameters(pContext->hInstance, &ActiveParams);
    LVM_ERROR_CHECK(LvmStatus, "LVREV_SetControlParameters", "ReverbSetDensity")

    pContext->SavedDensity = level;
 return;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:    virtual ~Trans4x4TestBase() {}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: void Camera3Device::setErrorState(const char *fmt, ...) {
 Mutex::Autolock l(mLock);
    va_list args;
    va_start(args, fmt);

    setErrorStateLockedV(fmt, args);

    va_end(args);
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static vpx_codec_err_t ctrl_get_frame_size(vpx_codec_alg_priv_t *ctx,
                                           va_list args) {
 int *const frame_size = va_arg(args, int *);

 if (ctx->frame_parallel_decode) {
    set_error_detail(ctx, "Not supported in frame parallel decode");
 return VPX_CODEC_INCAPABLE;
 }

 if (frame_size) {
 if (ctx->frame_workers) {
 VPxWorker *const worker = ctx->frame_workers;
 FrameWorkerData *const frame_worker_data =
 (FrameWorkerData *)worker->data1;
 const VP9_COMMON *const cm = &frame_worker_data->pbi->common;
      frame_size[0] = cm->width;
      frame_size[1] = cm->height;
 return VPX_CODEC_OK;
 } else {
 return VPX_CODEC_ERROR;
 }
 }

 return VPX_CODEC_INVALID_PARAM;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:  long vorbis_book_decodev_set(codebook *book,ogg_int32_t *a,
			     oggpack_buffer *b,int n,int point){
   if(book->used_entries>0){
     ogg_int32_t *v = book->dec_buf;//(ogg_int32_t *)alloca(sizeof(*v)*book->dim);
     int i,j;


     if (!v) return -1;
     for(i=0;i<n;){
       if(decode_map(book,b,v,point))return -1;
      for (j=0;j<book->dim;j++)
	a[i++]=v[j];
     }
   }else{
     int i,j;
 
     for(i=0;i<n;){
      for (j=0;j<book->dim;j++)
	a[i++]=0;
     }
   }
 
 return 0;
}

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: int Track::Info::CopyStr(char* Info::*str, Info& dst_) const
{
    if (str == static_cast<char* Info::*>(NULL))
        return -1;
    char*& dst = dst_.*str;
    if (dst)  //should be NULL already
        return -1;
    const char* const src = this->*str;
    if (src == NULL)
        return 0;
    const size_t len = strlen(src);
    dst = new (std::nothrow) char[len+1];
    if (dst == NULL)
        return -1;
    strcpy(dst, src);
     return 0;
 }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input: String8 InputDispatcher::getApplicationWindowLabelLocked(
 const sp<InputApplicationHandle>& applicationHandle,
 const sp<InputWindowHandle>& windowHandle) {
 if (applicationHandle != NULL) {
 if (windowHandle != NULL) {
 String8 label(applicationHandle->getName());
            label.append(" - ");
            label.append(windowHandle->getName());
 return label;
 } else {
 return applicationHandle->getName();
 }
 } else if (windowHandle != NULL) {
 return windowHandle->getName();
 } else {
 return String8("<unknown application or window>");
 }
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input: static jboolean android_net_wifi_getScanCapabilities(
 JNIEnv *env, jclass cls, jint iface, jobject capabilities) {

 JNIHelper helper(env);
    wifi_interface_handle handle = getIfaceHandle(helper, cls, iface);

    wifi_gscan_capabilities c;
    memset(&c, 0, sizeof(c));
 int result = hal_fn.wifi_get_gscan_capabilities(handle, &c);
 if (result != WIFI_SUCCESS) {
        ALOGD("failed to get capabilities : %d", result);
 return JNI_FALSE;
 }

    helper.setIntField(capabilities, "max_scan_cache_size", c.max_scan_cache_size);
    helper.setIntField(capabilities, "max_scan_buckets", c.max_scan_buckets);
    helper.setIntField(capabilities, "max_ap_cache_per_scan", c.max_ap_cache_per_scan);
    helper.setIntField(capabilities, "max_rssi_sample_size", c.max_rssi_sample_size);
    helper.setIntField(capabilities, "max_scan_reporting_threshold", c.max_scan_reporting_threshold);
    helper.setIntField(capabilities, "max_hotlist_bssids", c.max_hotlist_bssids);
    helper.setIntField(capabilities, "max_significant_wifi_change_aps",
                c.max_significant_wifi_change_aps);

 return JNI_TRUE;
}

Labels: No
----------------lora model----------------
Response: No</s>


Instruction: 
Input:   void RunFwdTxfm(const int16_t *in, int16_t *out, int stride) {
     fwd_txfm_(in, out, stride);
   }

Labels: Yes
----------------lora model----------------
Response: Yes</s>


Instruction: 
Input:  ssize_t MPEG4DataSource::readAt(off64_t offset, void *data, size_t size) {
     Mutex::Autolock autoLock(mLock);
 
    if (offset >= mCachedOffset
            && offset + size <= mCachedOffset + mCachedSize) {
         memcpy(data, &mCache[offset - mCachedOffset], size);
         return size;
     }

 return mSource->readAt(offset, data, size);
}

Labels: Yes
----------------lora model----------------
Response: No</s>


